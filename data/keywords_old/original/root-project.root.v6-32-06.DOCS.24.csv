id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:9056,Security,secur,security,9056,"list of all public disclosures, as well as statistics on time to fix issues, length of embargo periods, and so on. The transparency reports are published at :doc:`SecurityTransparencyReports`. Privileges and Responsibilities of LLVM Security Group Members; ==============================================================. Access; ------. LLVM Security Group members will be subscribed to a private `Discussion Medium`_ (*FUTURE*: see section below). It will be used for technical discussions of security issues, as well as process discussions about matters such as disclosure timelines and group membership. Members have access to all security issues. Confidentiality; ---------------. Members of the LLVM Security Group will be expected to treat LLVM security issue information shared with the group as confidential until publicly disclosed:. * Members should not disclose security issue information to non-members unless both members are employed by the same vendor of a LLVM based product, in which case information can be shared within that organization on a need-to-know basis and handled as confidential information normally is within that organization.; * If the LLVM Security Group agrees, designated members may share issues with vendors of non-LLVM based products if their product suffers from the same issue. The non-LLVM vendor should be asked to respect the issue’s embargo date, and to not share the information beyond the need-to-know people within their organization.; * If the LLVM Security Group agrees, key experts can be brought in to help address particular issues. The key expert should be asked to respect the issue’s embargo date, and to not share the information. Disclosure; ----------. Following the process below, the LLVM Security Group decides on embargo date for public disclosure for each Security issue. An embargo may be lifted before the agreed-upon date if all vendors planning to ship a fix have already done so, and if the reporter does not object. Collaboration;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:9279,Security,confidential,confidential,9279,"list of all public disclosures, as well as statistics on time to fix issues, length of embargo periods, and so on. The transparency reports are published at :doc:`SecurityTransparencyReports`. Privileges and Responsibilities of LLVM Security Group Members; ==============================================================. Access; ------. LLVM Security Group members will be subscribed to a private `Discussion Medium`_ (*FUTURE*: see section below). It will be used for technical discussions of security issues, as well as process discussions about matters such as disclosure timelines and group membership. Members have access to all security issues. Confidentiality; ---------------. Members of the LLVM Security Group will be expected to treat LLVM security issue information shared with the group as confidential until publicly disclosed:. * Members should not disclose security issue information to non-members unless both members are employed by the same vendor of a LLVM based product, in which case information can be shared within that organization on a need-to-know basis and handled as confidential information normally is within that organization.; * If the LLVM Security Group agrees, designated members may share issues with vendors of non-LLVM based products if their product suffers from the same issue. The non-LLVM vendor should be asked to respect the issue’s embargo date, and to not share the information beyond the need-to-know people within their organization.; * If the LLVM Security Group agrees, key experts can be brought in to help address particular issues. The key expert should be asked to respect the issue’s embargo date, and to not share the information. Disclosure; ----------. Following the process below, the LLVM Security Group decides on embargo date for public disclosure for each Security issue. An embargo may be lifted before the agreed-upon date if all vendors planning to ship a fix have already done so, and if the reporter does not object. Collaboration;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:10448,Security,secur,security,10448,"on-LLVM based products if their product suffers from the same issue. The non-LLVM vendor should be asked to respect the issue’s embargo date, and to not share the information beyond the need-to-know people within their organization.; * If the LLVM Security Group agrees, key experts can be brought in to help address particular issues. The key expert should be asked to respect the issue’s embargo date, and to not share the information. Disclosure; ----------. Following the process below, the LLVM Security Group decides on embargo date for public disclosure for each Security issue. An embargo may be lifted before the agreed-upon date if all vendors planning to ship a fix have already done so, and if the reporter does not object. Collaboration; -------------. Members of the LLVM Security Group are expected to:. * Promptly share any LLVM vulnerabilities they become aware of.; * Volunteer to drive issues forward.; * Help evaluate the severity of incoming issues.; * Help write and review patches to address security issues.; * Participate in the member nomination and removal processes. Discussion Medium; =================. *FUTURE*: this section needs more work! Where discussions occur is influenced by other factors that are still open in this document. We can finalize it later.; It seems like bugzilla and email don't meet security requirements. The medium used to host LLVM Security Group discussions is security-sensitive. It should therefore run on infrastructure which can meet our security expectations. We are currently using the `chromium issue tracker`_ (as the `llvm` project) to have security discussions:. * File security issues.; * Discuss security improvements to LLVM. When a new issue is filed, a template is provided to help issue reporters provide all relevant information. *FUTURE*: The `Github security`_ workflow allows publicly disclosing resolved security issues on the github project page, and we would be interested in adopting it for that purpose. However, it do",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:10770,Security,secur,security,10770,"ar issues. The key expert should be asked to respect the issue’s embargo date, and to not share the information. Disclosure; ----------. Following the process below, the LLVM Security Group decides on embargo date for public disclosure for each Security issue. An embargo may be lifted before the agreed-upon date if all vendors planning to ship a fix have already done so, and if the reporter does not object. Collaboration; -------------. Members of the LLVM Security Group are expected to:. * Promptly share any LLVM vulnerabilities they become aware of.; * Volunteer to drive issues forward.; * Help evaluate the severity of incoming issues.; * Help write and review patches to address security issues.; * Participate in the member nomination and removal processes. Discussion Medium; =================. *FUTURE*: this section needs more work! Where discussions occur is influenced by other factors that are still open in this document. We can finalize it later.; It seems like bugzilla and email don't meet security requirements. The medium used to host LLVM Security Group discussions is security-sensitive. It should therefore run on infrastructure which can meet our security expectations. We are currently using the `chromium issue tracker`_ (as the `llvm` project) to have security discussions:. * File security issues.; * Discuss security improvements to LLVM. When a new issue is filed, a template is provided to help issue reporters provide all relevant information. *FUTURE*: The `Github security`_ workflow allows publicly disclosing resolved security issues on the github project page, and we would be interested in adopting it for that purpose. However, it does not easily allow confidential reporting of security issues, as creating Github Security Advisories is currently restricted to Github project admins. That is why we have started with the `chromium issue tracker`_ instead. We also occasionally need to discuss logistics of the LLVM Security Group itself:. * Nominate new me",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:10852,Security,secur,security-sensitive,10852,"date, and to not share the information. Disclosure; ----------. Following the process below, the LLVM Security Group decides on embargo date for public disclosure for each Security issue. An embargo may be lifted before the agreed-upon date if all vendors planning to ship a fix have already done so, and if the reporter does not object. Collaboration; -------------. Members of the LLVM Security Group are expected to:. * Promptly share any LLVM vulnerabilities they become aware of.; * Volunteer to drive issues forward.; * Help evaluate the severity of incoming issues.; * Help write and review patches to address security issues.; * Participate in the member nomination and removal processes. Discussion Medium; =================. *FUTURE*: this section needs more work! Where discussions occur is influenced by other factors that are still open in this document. We can finalize it later.; It seems like bugzilla and email don't meet security requirements. The medium used to host LLVM Security Group discussions is security-sensitive. It should therefore run on infrastructure which can meet our security expectations. We are currently using the `chromium issue tracker`_ (as the `llvm` project) to have security discussions:. * File security issues.; * Discuss security improvements to LLVM. When a new issue is filed, a template is provided to help issue reporters provide all relevant information. *FUTURE*: The `Github security`_ workflow allows publicly disclosing resolved security issues on the github project page, and we would be interested in adopting it for that purpose. However, it does not easily allow confidential reporting of security issues, as creating Github Security Advisories is currently restricted to Github project admins. That is why we have started with the `chromium issue tracker`_ instead. We also occasionally need to discuss logistics of the LLVM Security Group itself:. * Nominate new members.; * Propose member removal.; * Suggest policy changes. We often have",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:10933,Security,secur,security,10933,"ess below, the LLVM Security Group decides on embargo date for public disclosure for each Security issue. An embargo may be lifted before the agreed-upon date if all vendors planning to ship a fix have already done so, and if the reporter does not object. Collaboration; -------------. Members of the LLVM Security Group are expected to:. * Promptly share any LLVM vulnerabilities they become aware of.; * Volunteer to drive issues forward.; * Help evaluate the severity of incoming issues.; * Help write and review patches to address security issues.; * Participate in the member nomination and removal processes. Discussion Medium; =================. *FUTURE*: this section needs more work! Where discussions occur is influenced by other factors that are still open in this document. We can finalize it later.; It seems like bugzilla and email don't meet security requirements. The medium used to host LLVM Security Group discussions is security-sensitive. It should therefore run on infrastructure which can meet our security expectations. We are currently using the `chromium issue tracker`_ (as the `llvm` project) to have security discussions:. * File security issues.; * Discuss security improvements to LLVM. When a new issue is filed, a template is provided to help issue reporters provide all relevant information. *FUTURE*: The `Github security`_ workflow allows publicly disclosing resolved security issues on the github project page, and we would be interested in adopting it for that purpose. However, it does not easily allow confidential reporting of security issues, as creating Github Security Advisories is currently restricted to Github project admins. That is why we have started with the `chromium issue tracker`_ instead. We also occasionally need to discuss logistics of the LLVM Security Group itself:. * Nominate new members.; * Propose member removal.; * Suggest policy changes. We often have these discussions publicly, in our :ref:`monthly public sync-up call <online-syn",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:11041,Security,secur,security,11041,"ty issue. An embargo may be lifted before the agreed-upon date if all vendors planning to ship a fix have already done so, and if the reporter does not object. Collaboration; -------------. Members of the LLVM Security Group are expected to:. * Promptly share any LLVM vulnerabilities they become aware of.; * Volunteer to drive issues forward.; * Help evaluate the severity of incoming issues.; * Help write and review patches to address security issues.; * Participate in the member nomination and removal processes. Discussion Medium; =================. *FUTURE*: this section needs more work! Where discussions occur is influenced by other factors that are still open in this document. We can finalize it later.; It seems like bugzilla and email don't meet security requirements. The medium used to host LLVM Security Group discussions is security-sensitive. It should therefore run on infrastructure which can meet our security expectations. We are currently using the `chromium issue tracker`_ (as the `llvm` project) to have security discussions:. * File security issues.; * Discuss security improvements to LLVM. When a new issue is filed, a template is provided to help issue reporters provide all relevant information. *FUTURE*: The `Github security`_ workflow allows publicly disclosing resolved security issues on the github project page, and we would be interested in adopting it for that purpose. However, it does not easily allow confidential reporting of security issues, as creating Github Security Advisories is currently restricted to Github project admins. That is why we have started with the `chromium issue tracker`_ instead. We also occasionally need to discuss logistics of the LLVM Security Group itself:. * Nominate new members.; * Propose member removal.; * Suggest policy changes. We often have these discussions publicly, in our :ref:`monthly public sync-up call <online-sync-ups>` and on the Discourse forums. For internal or confidential discussions, we also use a pri",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:11071,Security,secur,security,11071,"all vendors planning to ship a fix have already done so, and if the reporter does not object. Collaboration; -------------. Members of the LLVM Security Group are expected to:. * Promptly share any LLVM vulnerabilities they become aware of.; * Volunteer to drive issues forward.; * Help evaluate the severity of incoming issues.; * Help write and review patches to address security issues.; * Participate in the member nomination and removal processes. Discussion Medium; =================. *FUTURE*: this section needs more work! Where discussions occur is influenced by other factors that are still open in this document. We can finalize it later.; It seems like bugzilla and email don't meet security requirements. The medium used to host LLVM Security Group discussions is security-sensitive. It should therefore run on infrastructure which can meet our security expectations. We are currently using the `chromium issue tracker`_ (as the `llvm` project) to have security discussions:. * File security issues.; * Discuss security improvements to LLVM. When a new issue is filed, a template is provided to help issue reporters provide all relevant information. *FUTURE*: The `Github security`_ workflow allows publicly disclosing resolved security issues on the github project page, and we would be interested in adopting it for that purpose. However, it does not easily allow confidential reporting of security issues, as creating Github Security Advisories is currently restricted to Github project admins. That is why we have started with the `chromium issue tracker`_ instead. We also occasionally need to discuss logistics of the LLVM Security Group itself:. * Nominate new members.; * Propose member removal.; * Suggest policy changes. We often have these discussions publicly, in our :ref:`monthly public sync-up call <online-sync-ups>` and on the Discourse forums. For internal or confidential discussions, we also use a private mailing list. Process; =======. The following process occurs ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:11099,Security,secur,security,11099,"x have already done so, and if the reporter does not object. Collaboration; -------------. Members of the LLVM Security Group are expected to:. * Promptly share any LLVM vulnerabilities they become aware of.; * Volunteer to drive issues forward.; * Help evaluate the severity of incoming issues.; * Help write and review patches to address security issues.; * Participate in the member nomination and removal processes. Discussion Medium; =================. *FUTURE*: this section needs more work! Where discussions occur is influenced by other factors that are still open in this document. We can finalize it later.; It seems like bugzilla and email don't meet security requirements. The medium used to host LLVM Security Group discussions is security-sensitive. It should therefore run on infrastructure which can meet our security expectations. We are currently using the `chromium issue tracker`_ (as the `llvm` project) to have security discussions:. * File security issues.; * Discuss security improvements to LLVM. When a new issue is filed, a template is provided to help issue reporters provide all relevant information. *FUTURE*: The `Github security`_ workflow allows publicly disclosing resolved security issues on the github project page, and we would be interested in adopting it for that purpose. However, it does not easily allow confidential reporting of security issues, as creating Github Security Advisories is currently restricted to Github project admins. That is why we have started with the `chromium issue tracker`_ instead. We also occasionally need to discuss logistics of the LLVM Security Group itself:. * Nominate new members.; * Propose member removal.; * Suggest policy changes. We often have these discussions publicly, in our :ref:`monthly public sync-up call <online-sync-ups>` and on the Discourse forums. For internal or confidential discussions, we also use a private mailing list. Process; =======. The following process occurs on the discussion medium for each",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:11260,Security,secur,security,11260," to drive issues forward.; * Help evaluate the severity of incoming issues.; * Help write and review patches to address security issues.; * Participate in the member nomination and removal processes. Discussion Medium; =================. *FUTURE*: this section needs more work! Where discussions occur is influenced by other factors that are still open in this document. We can finalize it later.; It seems like bugzilla and email don't meet security requirements. The medium used to host LLVM Security Group discussions is security-sensitive. It should therefore run on infrastructure which can meet our security expectations. We are currently using the `chromium issue tracker`_ (as the `llvm` project) to have security discussions:. * File security issues.; * Discuss security improvements to LLVM. When a new issue is filed, a template is provided to help issue reporters provide all relevant information. *FUTURE*: The `Github security`_ workflow allows publicly disclosing resolved security issues on the github project page, and we would be interested in adopting it for that purpose. However, it does not easily allow confidential reporting of security issues, as creating Github Security Advisories is currently restricted to Github project admins. That is why we have started with the `chromium issue tracker`_ instead. We also occasionally need to discuss logistics of the LLVM Security Group itself:. * Nominate new members.; * Propose member removal.; * Suggest policy changes. We often have these discussions publicly, in our :ref:`monthly public sync-up call <online-sync-ups>` and on the Discourse forums. For internal or confidential discussions, we also use a private mailing list. Process; =======. The following process occurs on the discussion medium for each reported issue:. * A security issue reporter (not necessarily an LLVM contributor) reports an issue.; * Within two business days, a member of the Security Group is put in charge of driving the issue to an acceptable res",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:11316,Security,secur,security,11316," to drive issues forward.; * Help evaluate the severity of incoming issues.; * Help write and review patches to address security issues.; * Participate in the member nomination and removal processes. Discussion Medium; =================. *FUTURE*: this section needs more work! Where discussions occur is influenced by other factors that are still open in this document. We can finalize it later.; It seems like bugzilla and email don't meet security requirements. The medium used to host LLVM Security Group discussions is security-sensitive. It should therefore run on infrastructure which can meet our security expectations. We are currently using the `chromium issue tracker`_ (as the `llvm` project) to have security discussions:. * File security issues.; * Discuss security improvements to LLVM. When a new issue is filed, a template is provided to help issue reporters provide all relevant information. *FUTURE*: The `Github security`_ workflow allows publicly disclosing resolved security issues on the github project page, and we would be interested in adopting it for that purpose. However, it does not easily allow confidential reporting of security issues, as creating Github Security Advisories is currently restricted to Github project admins. That is why we have started with the `chromium issue tracker`_ instead. We also occasionally need to discuss logistics of the LLVM Security Group itself:. * Nominate new members.; * Propose member removal.; * Suggest policy changes. We often have these discussions publicly, in our :ref:`monthly public sync-up call <online-sync-ups>` and on the Discourse forums. For internal or confidential discussions, we also use a private mailing list. Process; =======. The following process occurs on the discussion medium for each reported issue:. * A security issue reporter (not necessarily an LLVM contributor) reports an issue.; * Within two business days, a member of the Security Group is put in charge of driving the issue to an acceptable res",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:11454,Security,confidential,confidential,11454,"on and removal processes. Discussion Medium; =================. *FUTURE*: this section needs more work! Where discussions occur is influenced by other factors that are still open in this document. We can finalize it later.; It seems like bugzilla and email don't meet security requirements. The medium used to host LLVM Security Group discussions is security-sensitive. It should therefore run on infrastructure which can meet our security expectations. We are currently using the `chromium issue tracker`_ (as the `llvm` project) to have security discussions:. * File security issues.; * Discuss security improvements to LLVM. When a new issue is filed, a template is provided to help issue reporters provide all relevant information. *FUTURE*: The `Github security`_ workflow allows publicly disclosing resolved security issues on the github project page, and we would be interested in adopting it for that purpose. However, it does not easily allow confidential reporting of security issues, as creating Github Security Advisories is currently restricted to Github project admins. That is why we have started with the `chromium issue tracker`_ instead. We also occasionally need to discuss logistics of the LLVM Security Group itself:. * Nominate new members.; * Propose member removal.; * Suggest policy changes. We often have these discussions publicly, in our :ref:`monthly public sync-up call <online-sync-ups>` and on the Discourse forums. For internal or confidential discussions, we also use a private mailing list. Process; =======. The following process occurs on the discussion medium for each reported issue:. * A security issue reporter (not necessarily an LLVM contributor) reports an issue.; * Within two business days, a member of the Security Group is put in charge of driving the issue to an acceptable resolution. This champion doesn’t need to be the same person for each issue. This person can self-nominate.; * Members of the Security Group discuss in which circumstances (if a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:11480,Security,secur,security,11480,"on and removal processes. Discussion Medium; =================. *FUTURE*: this section needs more work! Where discussions occur is influenced by other factors that are still open in this document. We can finalize it later.; It seems like bugzilla and email don't meet security requirements. The medium used to host LLVM Security Group discussions is security-sensitive. It should therefore run on infrastructure which can meet our security expectations. We are currently using the `chromium issue tracker`_ (as the `llvm` project) to have security discussions:. * File security issues.; * Discuss security improvements to LLVM. When a new issue is filed, a template is provided to help issue reporters provide all relevant information. *FUTURE*: The `Github security`_ workflow allows publicly disclosing resolved security issues on the github project page, and we would be interested in adopting it for that purpose. However, it does not easily allow confidential reporting of security issues, as creating Github Security Advisories is currently restricted to Github project admins. That is why we have started with the `chromium issue tracker`_ instead. We also occasionally need to discuss logistics of the LLVM Security Group itself:. * Nominate new members.; * Propose member removal.; * Suggest policy changes. We often have these discussions publicly, in our :ref:`monthly public sync-up call <online-sync-ups>` and on the Discourse forums. For internal or confidential discussions, we also use a private mailing list. Process; =======. The following process occurs on the discussion medium for each reported issue:. * A security issue reporter (not necessarily an LLVM contributor) reports an issue.; * Within two business days, a member of the Security Group is put in charge of driving the issue to an acceptable resolution. This champion doesn’t need to be the same person for each issue. This person can self-nominate.; * Members of the Security Group discuss in which circumstances (if a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:11966,Security,confidential,confidential,11966,"mium issue tracker`_ (as the `llvm` project) to have security discussions:. * File security issues.; * Discuss security improvements to LLVM. When a new issue is filed, a template is provided to help issue reporters provide all relevant information. *FUTURE*: The `Github security`_ workflow allows publicly disclosing resolved security issues on the github project page, and we would be interested in adopting it for that purpose. However, it does not easily allow confidential reporting of security issues, as creating Github Security Advisories is currently restricted to Github project admins. That is why we have started with the `chromium issue tracker`_ instead. We also occasionally need to discuss logistics of the LLVM Security Group itself:. * Nominate new members.; * Propose member removal.; * Suggest policy changes. We often have these discussions publicly, in our :ref:`monthly public sync-up call <online-sync-ups>` and on the Discourse forums. For internal or confidential discussions, we also use a private mailing list. Process; =======. The following process occurs on the discussion medium for each reported issue:. * A security issue reporter (not necessarily an LLVM contributor) reports an issue.; * Within two business days, a member of the Security Group is put in charge of driving the issue to an acceptable resolution. This champion doesn’t need to be the same person for each issue. This person can self-nominate.; * Members of the Security Group discuss in which circumstances (if any) an issue is relevant to security, and determine if it is a security issue.; * Negotiate an embargo date for public disclosure, with a default minimum time limit of ninety days.; * Security Group members can recommend that key experts be pulled in to specific issue discussions. The key expert can be pulled in unless there are objections from other Security Group members.; * Patches are written and reviewed.; * Backporting security patches from recent versions to old versions can",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:12130,Security,secur,security,12130," is provided to help issue reporters provide all relevant information. *FUTURE*: The `Github security`_ workflow allows publicly disclosing resolved security issues on the github project page, and we would be interested in adopting it for that purpose. However, it does not easily allow confidential reporting of security issues, as creating Github Security Advisories is currently restricted to Github project admins. That is why we have started with the `chromium issue tracker`_ instead. We also occasionally need to discuss logistics of the LLVM Security Group itself:. * Nominate new members.; * Propose member removal.; * Suggest policy changes. We often have these discussions publicly, in our :ref:`monthly public sync-up call <online-sync-ups>` and on the Discourse forums. For internal or confidential discussions, we also use a private mailing list. Process; =======. The following process occurs on the discussion medium for each reported issue:. * A security issue reporter (not necessarily an LLVM contributor) reports an issue.; * Within two business days, a member of the Security Group is put in charge of driving the issue to an acceptable resolution. This champion doesn’t need to be the same person for each issue. This person can self-nominate.; * Members of the Security Group discuss in which circumstances (if any) an issue is relevant to security, and determine if it is a security issue.; * Negotiate an embargo date for public disclosure, with a default minimum time limit of ninety days.; * Security Group members can recommend that key experts be pulled in to specific issue discussions. The key expert can be pulled in unless there are objections from other Security Group members.; * Patches are written and reviewed.; * Backporting security patches from recent versions to old versions cannot always work. It is up to the Security Group to decide if such backporting should be done, and how far back.; * The Security Group figures out how the LLVM project’s own releas",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:12530,Security,secur,security,12530,"ng Github Security Advisories is currently restricted to Github project admins. That is why we have started with the `chromium issue tracker`_ instead. We also occasionally need to discuss logistics of the LLVM Security Group itself:. * Nominate new members.; * Propose member removal.; * Suggest policy changes. We often have these discussions publicly, in our :ref:`monthly public sync-up call <online-sync-ups>` and on the Discourse forums. For internal or confidential discussions, we also use a private mailing list. Process; =======. The following process occurs on the discussion medium for each reported issue:. * A security issue reporter (not necessarily an LLVM contributor) reports an issue.; * Within two business days, a member of the Security Group is put in charge of driving the issue to an acceptable resolution. This champion doesn’t need to be the same person for each issue. This person can self-nominate.; * Members of the Security Group discuss in which circumstances (if any) an issue is relevant to security, and determine if it is a security issue.; * Negotiate an embargo date for public disclosure, with a default minimum time limit of ninety days.; * Security Group members can recommend that key experts be pulled in to specific issue discussions. The key expert can be pulled in unless there are objections from other Security Group members.; * Patches are written and reviewed.; * Backporting security patches from recent versions to old versions cannot always work. It is up to the Security Group to decide if such backporting should be done, and how far back.; * The Security Group figures out how the LLVM project’s own releases, as well as individual vendors’ releases, can be timed to patch the issue simultaneously.; * Embargo date can be delayed or pulled forward at the Security Group’s discretion.; * The issue champion obtains a CVE entry from MITRE_.; * Once the embargo expires, the patch is posted publicly according to LLVM’s usual code review process.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:12565,Security,secur,security,12565,"ng Github Security Advisories is currently restricted to Github project admins. That is why we have started with the `chromium issue tracker`_ instead. We also occasionally need to discuss logistics of the LLVM Security Group itself:. * Nominate new members.; * Propose member removal.; * Suggest policy changes. We often have these discussions publicly, in our :ref:`monthly public sync-up call <online-sync-ups>` and on the Discourse forums. For internal or confidential discussions, we also use a private mailing list. Process; =======. The following process occurs on the discussion medium for each reported issue:. * A security issue reporter (not necessarily an LLVM contributor) reports an issue.; * Within two business days, a member of the Security Group is put in charge of driving the issue to an acceptable resolution. This champion doesn’t need to be the same person for each issue. This person can self-nominate.; * Members of the Security Group discuss in which circumstances (if any) an issue is relevant to security, and determine if it is a security issue.; * Negotiate an embargo date for public disclosure, with a default minimum time limit of ninety days.; * Security Group members can recommend that key experts be pulled in to specific issue discussions. The key expert can be pulled in unless there are objections from other Security Group members.; * Patches are written and reviewed.; * Backporting security patches from recent versions to old versions cannot always work. It is up to the Security Group to decide if such backporting should be done, and how far back.; * The Security Group figures out how the LLVM project’s own releases, as well as individual vendors’ releases, can be timed to patch the issue simultaneously.; * Embargo date can be delayed or pulled forward at the Security Group’s discretion.; * The issue champion obtains a CVE entry from MITRE_.; * Once the embargo expires, the patch is posted publicly according to LLVM’s usual code review process.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:12931,Security,secur,security,12931,"nal or confidential discussions, we also use a private mailing list. Process; =======. The following process occurs on the discussion medium for each reported issue:. * A security issue reporter (not necessarily an LLVM contributor) reports an issue.; * Within two business days, a member of the Security Group is put in charge of driving the issue to an acceptable resolution. This champion doesn’t need to be the same person for each issue. This person can self-nominate.; * Members of the Security Group discuss in which circumstances (if any) an issue is relevant to security, and determine if it is a security issue.; * Negotiate an embargo date for public disclosure, with a default minimum time limit of ninety days.; * Security Group members can recommend that key experts be pulled in to specific issue discussions. The key expert can be pulled in unless there are objections from other Security Group members.; * Patches are written and reviewed.; * Backporting security patches from recent versions to old versions cannot always work. It is up to the Security Group to decide if such backporting should be done, and how far back.; * The Security Group figures out how the LLVM project’s own releases, as well as individual vendors’ releases, can be timed to patch the issue simultaneously.; * Embargo date can be delayed or pulled forward at the Security Group’s discretion.; * The issue champion obtains a CVE entry from MITRE_.; * Once the embargo expires, the patch is posted publicly according to LLVM’s usual code review process.; * All security issues (as well as nomination / removal discussions) become public within approximately fourteen weeks of the fix landing in the LLVM repository. Precautions should be taken to avoid disclosing particularly sensitive data included in the report (e.g. username and password pairs). Changes to the Policy; =====================. The LLVM Security Policy may be changed by majority vote of the LLVM Security Group. Such changes also need to b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:13512,Security,secur,security,13512,"egotiate an embargo date for public disclosure, with a default minimum time limit of ninety days.; * Security Group members can recommend that key experts be pulled in to specific issue discussions. The key expert can be pulled in unless there are objections from other Security Group members.; * Patches are written and reviewed.; * Backporting security patches from recent versions to old versions cannot always work. It is up to the Security Group to decide if such backporting should be done, and how far back.; * The Security Group figures out how the LLVM project’s own releases, as well as individual vendors’ releases, can be timed to patch the issue simultaneously.; * Embargo date can be delayed or pulled forward at the Security Group’s discretion.; * The issue champion obtains a CVE entry from MITRE_.; * Once the embargo expires, the patch is posted publicly according to LLVM’s usual code review process.; * All security issues (as well as nomination / removal discussions) become public within approximately fourteen weeks of the fix landing in the LLVM repository. Precautions should be taken to avoid disclosing particularly sensitive data included in the report (e.g. username and password pairs). Changes to the Policy; =====================. The LLVM Security Policy may be changed by majority vote of the LLVM Security Group. Such changes also need to be approved by the LLVM Board. What is considered a security issue?; ====================================. The LLVM Project has a significant amount of code, and not all of it is; considered security-sensitive. This is particularly true because LLVM is used in; a wide variety of circumstances: there are different threat models, untrusted; inputs differ, and the environment LLVM runs in is varied. Therefore, what the; LLVM Project considers a security issue is what its members have signed up to; maintain securely. As this security process matures, members of the LLVM community can propose that; a part of the codebase be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:13785,Security,password,password,13785,"e key expert can be pulled in unless there are objections from other Security Group members.; * Patches are written and reviewed.; * Backporting security patches from recent versions to old versions cannot always work. It is up to the Security Group to decide if such backporting should be done, and how far back.; * The Security Group figures out how the LLVM project’s own releases, as well as individual vendors’ releases, can be timed to patch the issue simultaneously.; * Embargo date can be delayed or pulled forward at the Security Group’s discretion.; * The issue champion obtains a CVE entry from MITRE_.; * Once the embargo expires, the patch is posted publicly according to LLVM’s usual code review process.; * All security issues (as well as nomination / removal discussions) become public within approximately fourteen weeks of the fix landing in the LLVM repository. Precautions should be taken to avoid disclosing particularly sensitive data included in the report (e.g. username and password pairs). Changes to the Policy; =====================. The LLVM Security Policy may be changed by majority vote of the LLVM Security Group. Such changes also need to be approved by the LLVM Board. What is considered a security issue?; ====================================. The LLVM Project has a significant amount of code, and not all of it is; considered security-sensitive. This is particularly true because LLVM is used in; a wide variety of circumstances: there are different threat models, untrusted; inputs differ, and the environment LLVM runs in is varied. Therefore, what the; LLVM Project considers a security issue is what its members have signed up to; maintain securely. As this security process matures, members of the LLVM community can propose that; a part of the codebase be designated as security-sensitive (or no longer; security-sensitive). This requires a rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handle",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:14011,Security,secur,security,14011,"ty Group to decide if such backporting should be done, and how far back.; * The Security Group figures out how the LLVM project’s own releases, as well as individual vendors’ releases, can be timed to patch the issue simultaneously.; * Embargo date can be delayed or pulled forward at the Security Group’s discretion.; * The issue champion obtains a CVE entry from MITRE_.; * Once the embargo expires, the patch is posted publicly according to LLVM’s usual code review process.; * All security issues (as well as nomination / removal discussions) become public within approximately fourteen weeks of the fix landing in the LLVM repository. Precautions should be taken to avoid disclosing particularly sensitive data included in the report (e.g. username and password pairs). Changes to the Policy; =====================. The LLVM Security Policy may be changed by majority vote of the LLVM Security Group. Such changes also need to be approved by the LLVM Board. What is considered a security issue?; ====================================. The LLVM Project has a significant amount of code, and not all of it is; considered security-sensitive. This is particularly true because LLVM is used in; a wide variety of circumstances: there are different threat models, untrusted; inputs differ, and the environment LLVM runs in is varied. Therefore, what the; LLVM Project considers a security issue is what its members have signed up to; maintain securely. As this security process matures, members of the LLVM community can propose that; a part of the codebase be designated as security-sensitive (or no longer; security-sensitive). This requires a rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; pro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:14150,Security,secur,security-sensitive,14150,"roup figures out how the LLVM project’s own releases, as well as individual vendors’ releases, can be timed to patch the issue simultaneously.; * Embargo date can be delayed or pulled forward at the Security Group’s discretion.; * The issue champion obtains a CVE entry from MITRE_.; * Once the embargo expires, the patch is posted publicly according to LLVM’s usual code review process.; * All security issues (as well as nomination / removal discussions) become public within approximately fourteen weeks of the fix landing in the LLVM repository. Precautions should be taken to avoid disclosing particularly sensitive data included in the report (e.g. username and password pairs). Changes to the Policy; =====================. The LLVM Security Policy may be changed by majority vote of the LLVM Security Group. Such changes also need to be approved by the LLVM Board. What is considered a security issue?; ====================================. The LLVM Project has a significant amount of code, and not all of it is; considered security-sensitive. This is particularly true because LLVM is used in; a wide variety of circumstances: there are different threat models, untrusted; inputs differ, and the environment LLVM runs in is varied. Therefore, what the; LLVM Project considers a security issue is what its members have signed up to; maintain securely. As this security process matures, members of the LLVM community can propose that; a part of the codebase be designated as security-sensitive (or no longer; security-sensitive). This requires a rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; properties over time. In all cases the LLVM Security Group should be consulted,; since they'l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:14274,Security,threat,threat,14274,"Embargo date can be delayed or pulled forward at the Security Group’s discretion.; * The issue champion obtains a CVE entry from MITRE_.; * Once the embargo expires, the patch is posted publicly according to LLVM’s usual code review process.; * All security issues (as well as nomination / removal discussions) become public within approximately fourteen weeks of the fix landing in the LLVM repository. Precautions should be taken to avoid disclosing particularly sensitive data included in the report (e.g. username and password pairs). Changes to the Policy; =====================. The LLVM Security Policy may be changed by majority vote of the LLVM Security Group. Such changes also need to be approved by the LLVM Board. What is considered a security issue?; ====================================. The LLVM Project has a significant amount of code, and not all of it is; considered security-sensitive. This is particularly true because LLVM is used in; a wide variety of circumstances: there are different threat models, untrusted; inputs differ, and the environment LLVM runs in is varied. Therefore, what the; LLVM Project considers a security issue is what its members have signed up to; maintain securely. As this security process matures, members of the LLVM community can propose that; a part of the codebase be designated as security-sensitive (or no longer; security-sensitive). This requires a rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; properties over time. In all cases the LLVM Security Group should be consulted,; since they'll be responding to security issues filed against these parts of the; codebase. If you're not sure whether an issue is in-scope for this security pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:14405,Security,secur,security,14405,"go expires, the patch is posted publicly according to LLVM’s usual code review process.; * All security issues (as well as nomination / removal discussions) become public within approximately fourteen weeks of the fix landing in the LLVM repository. Precautions should be taken to avoid disclosing particularly sensitive data included in the report (e.g. username and password pairs). Changes to the Policy; =====================. The LLVM Security Policy may be changed by majority vote of the LLVM Security Group. Such changes also need to be approved by the LLVM Board. What is considered a security issue?; ====================================. The LLVM Project has a significant amount of code, and not all of it is; considered security-sensitive. This is particularly true because LLVM is used in; a wide variety of circumstances: there are different threat models, untrusted; inputs differ, and the environment LLVM runs in is varied. Therefore, what the; LLVM Project considers a security issue is what its members have signed up to; maintain securely. As this security process matures, members of the LLVM community can propose that; a part of the codebase be designated as security-sensitive (or no longer; security-sensitive). This requires a rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; properties over time. In all cases the LLVM Security Group should be consulted,; since they'll be responding to security issues filed against these parts of the; codebase. If you're not sure whether an issue is in-scope for this security process or; not, err towards assuming that it is. The Security Group might agree or disagree; and will explain its rationale in the report, as well as updat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:14468,Security,secur,securely,14468,"go expires, the patch is posted publicly according to LLVM’s usual code review process.; * All security issues (as well as nomination / removal discussions) become public within approximately fourteen weeks of the fix landing in the LLVM repository. Precautions should be taken to avoid disclosing particularly sensitive data included in the report (e.g. username and password pairs). Changes to the Policy; =====================. The LLVM Security Policy may be changed by majority vote of the LLVM Security Group. Such changes also need to be approved by the LLVM Board. What is considered a security issue?; ====================================. The LLVM Project has a significant amount of code, and not all of it is; considered security-sensitive. This is particularly true because LLVM is used in; a wide variety of circumstances: there are different threat models, untrusted; inputs differ, and the environment LLVM runs in is varied. Therefore, what the; LLVM Project considers a security issue is what its members have signed up to; maintain securely. As this security process matures, members of the LLVM community can propose that; a part of the codebase be designated as security-sensitive (or no longer; security-sensitive). This requires a rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; properties over time. In all cases the LLVM Security Group should be consulted,; since they'll be responding to security issues filed against these parts of the; codebase. If you're not sure whether an issue is in-scope for this security process or; not, err towards assuming that it is. The Security Group might agree or disagree; and will explain its rationale in the report, as well as updat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:14486,Security,secur,security,14486,"ussions) become public within approximately fourteen weeks of the fix landing in the LLVM repository. Precautions should be taken to avoid disclosing particularly sensitive data included in the report (e.g. username and password pairs). Changes to the Policy; =====================. The LLVM Security Policy may be changed by majority vote of the LLVM Security Group. Such changes also need to be approved by the LLVM Board. What is considered a security issue?; ====================================. The LLVM Project has a significant amount of code, and not all of it is; considered security-sensitive. This is particularly true because LLVM is used in; a wide variety of circumstances: there are different threat models, untrusted; inputs differ, and the environment LLVM runs in is varied. Therefore, what the; LLVM Project considers a security issue is what its members have signed up to; maintain securely. As this security process matures, members of the LLVM community can propose that; a part of the codebase be designated as security-sensitive (or no longer; security-sensitive). This requires a rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; properties over time. In all cases the LLVM Security Group should be consulted,; since they'll be responding to security issues filed against these parts of the; codebase. If you're not sure whether an issue is in-scope for this security process or; not, err towards assuming that it is. The Security Group might agree or disagree; and will explain its rationale in the report, as well as update this document; through the above process. The security-sensitive parts of the LLVM Project currently are the following.; Note that this list can c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:14600,Security,secur,security-sensitive,14600,"ussions) become public within approximately fourteen weeks of the fix landing in the LLVM repository. Precautions should be taken to avoid disclosing particularly sensitive data included in the report (e.g. username and password pairs). Changes to the Policy; =====================. The LLVM Security Policy may be changed by majority vote of the LLVM Security Group. Such changes also need to be approved by the LLVM Board. What is considered a security issue?; ====================================. The LLVM Project has a significant amount of code, and not all of it is; considered security-sensitive. This is particularly true because LLVM is used in; a wide variety of circumstances: there are different threat models, untrusted; inputs differ, and the environment LLVM runs in is varied. Therefore, what the; LLVM Project considers a security issue is what its members have signed up to; maintain securely. As this security process matures, members of the LLVM community can propose that; a part of the codebase be designated as security-sensitive (or no longer; security-sensitive). This requires a rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; properties over time. In all cases the LLVM Security Group should be consulted,; since they'll be responding to security issues filed against these parts of the; codebase. If you're not sure whether an issue is in-scope for this security process or; not, err towards assuming that it is. The Security Group might agree or disagree; and will explain its rationale in the report, as well as update this document; through the above process. The security-sensitive parts of the LLVM Project currently are the following.; Note that this list can c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:14634,Security,secur,security-sensitive,14634,"ussions) become public within approximately fourteen weeks of the fix landing in the LLVM repository. Precautions should be taken to avoid disclosing particularly sensitive data included in the report (e.g. username and password pairs). Changes to the Policy; =====================. The LLVM Security Policy may be changed by majority vote of the LLVM Security Group. Such changes also need to be approved by the LLVM Board. What is considered a security issue?; ====================================. The LLVM Project has a significant amount of code, and not all of it is; considered security-sensitive. This is particularly true because LLVM is used in; a wide variety of circumstances: there are different threat models, untrusted; inputs differ, and the environment LLVM runs in is varied. Therefore, what the; LLVM Project considers a security issue is what its members have signed up to; maintain securely. As this security process matures, members of the LLVM community can propose that; a part of the codebase be designated as security-sensitive (or no longer; security-sensitive). This requires a rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; properties over time. In all cases the LLVM Security Group should be consulted,; since they'll be responding to security issues filed against these parts of the; codebase. If you're not sure whether an issue is in-scope for this security process or; not, err towards assuming that it is. The Security Group might agree or disagree; and will explain its rationale in the report, as well as update this document; through the above process. The security-sensitive parts of the LLVM Project currently are the following.; Note that this list can c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:14792,Security,secur,security-sensitive,14792,"es to the Policy; =====================. The LLVM Security Policy may be changed by majority vote of the LLVM Security Group. Such changes also need to be approved by the LLVM Board. What is considered a security issue?; ====================================. The LLVM Project has a significant amount of code, and not all of it is; considered security-sensitive. This is particularly true because LLVM is used in; a wide variety of circumstances: there are different threat models, untrusted; inputs differ, and the environment LLVM runs in is varied. Therefore, what the; LLVM Project considers a security issue is what its members have signed up to; maintain securely. As this security process matures, members of the LLVM community can propose that; a part of the codebase be designated as security-sensitive (or no longer; security-sensitive). This requires a rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; properties over time. In all cases the LLVM Security Group should be consulted,; since they'll be responding to security issues filed against these parts of the; codebase. If you're not sure whether an issue is in-scope for this security process or; not, err towards assuming that it is. The Security Group might agree or disagree; and will explain its rationale in the report, as well as update this document; through the above process. The security-sensitive parts of the LLVM Project currently are the following.; Note that this list can change over time. * None are currently defined. Please don't let this stop you from reporting; issues to the security group that you believe are security-sensitive. The parts of the LLVM Project which are currently treated as non-security; sen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:14984,Security,secur,securable,14984,"pproved by the LLVM Board. What is considered a security issue?; ====================================. The LLVM Project has a significant amount of code, and not all of it is; considered security-sensitive. This is particularly true because LLVM is used in; a wide variety of circumstances: there are different threat models, untrusted; inputs differ, and the environment LLVM runs in is varied. Therefore, what the; LLVM Project considers a security issue is what its members have signed up to; maintain securely. As this security process matures, members of the LLVM community can propose that; a part of the codebase be designated as security-sensitive (or no longer; security-sensitive). This requires a rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; properties over time. In all cases the LLVM Security Group should be consulted,; since they'll be responding to security issues filed against these parts of the; codebase. If you're not sure whether an issue is in-scope for this security process or; not, err towards assuming that it is. The Security Group might agree or disagree; and will explain its rationale in the report, as well as update this document; through the above process. The security-sensitive parts of the LLVM Project currently are the following.; Note that this list can change over time. * None are currently defined. Please don't let this stop you from reporting; issues to the security group that you believe are security-sensitive. The parts of the LLVM Project which are currently treated as non-security; sensitive are the following. Note that this list can change over time. * Language front-ends, such as clang, for which a malicious input file can cause; undesi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:15014,Security,secur,security,15014,"pproved by the LLVM Board. What is considered a security issue?; ====================================. The LLVM Project has a significant amount of code, and not all of it is; considered security-sensitive. This is particularly true because LLVM is used in; a wide variety of circumstances: there are different threat models, untrusted; inputs differ, and the environment LLVM runs in is varied. Therefore, what the; LLVM Project considers a security issue is what its members have signed up to; maintain securely. As this security process matures, members of the LLVM community can propose that; a part of the codebase be designated as security-sensitive (or no longer; security-sensitive). This requires a rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; properties over time. In all cases the LLVM Security Group should be consulted,; since they'll be responding to security issues filed against these parts of the; codebase. If you're not sure whether an issue is in-scope for this security process or; not, err towards assuming that it is. The Security Group might agree or disagree; and will explain its rationale in the report, as well as update this document; through the above process. The security-sensitive parts of the LLVM Project currently are the following.; Note that this list can change over time. * None are currently defined. Please don't let this stop you from reporting; issues to the security group that you believe are security-sensitive. The parts of the LLVM Project which are currently treated as non-security; sensitive are the following. Note that this list can change over time. * Language front-ends, such as clang, for which a malicious input file can cause; undesi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:15136,Security,secur,security,15136," not all of it is; considered security-sensitive. This is particularly true because LLVM is used in; a wide variety of circumstances: there are different threat models, untrusted; inputs differ, and the environment LLVM runs in is varied. Therefore, what the; LLVM Project considers a security issue is what its members have signed up to; maintain securely. As this security process matures, members of the LLVM community can propose that; a part of the codebase be designated as security-sensitive (or no longer; security-sensitive). This requires a rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; properties over time. In all cases the LLVM Security Group should be consulted,; since they'll be responding to security issues filed against these parts of the; codebase. If you're not sure whether an issue is in-scope for this security process or; not, err towards assuming that it is. The Security Group might agree or disagree; and will explain its rationale in the report, as well as update this document; through the above process. The security-sensitive parts of the LLVM Project currently are the following.; Note that this list can change over time. * None are currently defined. Please don't let this stop you from reporting; issues to the security group that you believe are security-sensitive. The parts of the LLVM Project which are currently treated as non-security; sensitive are the following. Note that this list can change over time. * Language front-ends, such as clang, for which a malicious input file can cause; undesirable behavior. For example, a maliciously crafted C or Rust source file; can cause arbitrary code to execute in LLVM. These parts of LLVM haven't been; har",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:15253,Security,secur,security,15253," there are different threat models, untrusted; inputs differ, and the environment LLVM runs in is varied. Therefore, what the; LLVM Project considers a security issue is what its members have signed up to; maintain securely. As this security process matures, members of the LLVM community can propose that; a part of the codebase be designated as security-sensitive (or no longer; security-sensitive). This requires a rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; properties over time. In all cases the LLVM Security Group should be consulted,; since they'll be responding to security issues filed against these parts of the; codebase. If you're not sure whether an issue is in-scope for this security process or; not, err towards assuming that it is. The Security Group might agree or disagree; and will explain its rationale in the report, as well as update this document; through the above process. The security-sensitive parts of the LLVM Project currently are the following.; Note that this list can change over time. * None are currently defined. Please don't let this stop you from reporting; issues to the security group that you believe are security-sensitive. The parts of the LLVM Project which are currently treated as non-security; sensitive are the following. Note that this list can change over time. * Language front-ends, such as clang, for which a malicious input file can cause; undesirable behavior. For example, a maliciously crafted C or Rust source file; can cause arbitrary code to execute in LLVM. These parts of LLVM haven't been; hardened, and compiling untrusted code usually also includes running utilities; such as `make` which can more readily perform malicious ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:15466,Security,secur,security-sensitive,15466,"ss matures, members of the LLVM community can propose that; a part of the codebase be designated as security-sensitive (or no longer; security-sensitive). This requires a rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; properties over time. In all cases the LLVM Security Group should be consulted,; since they'll be responding to security issues filed against these parts of the; codebase. If you're not sure whether an issue is in-scope for this security process or; not, err towards assuming that it is. The Security Group might agree or disagree; and will explain its rationale in the report, as well as update this document; through the above process. The security-sensitive parts of the LLVM Project currently are the following.; Note that this list can change over time. * None are currently defined. Please don't let this stop you from reporting; issues to the security group that you believe are security-sensitive. The parts of the LLVM Project which are currently treated as non-security; sensitive are the following. Note that this list can change over time. * Language front-ends, such as clang, for which a malicious input file can cause; undesirable behavior. For example, a maliciously crafted C or Rust source file; can cause arbitrary code to execute in LLVM. These parts of LLVM haven't been; hardened, and compiling untrusted code usually also includes running utilities; such as `make` which can more readily perform malicious things. .. _CVE process: https://cve.mitre.org; .. _open a new issue: https://bugs.chromium.org/p/llvm/issues/entry; .. _chromium issue tracker: https://crbug.com; .. _GitHub security: https://help.github.com/en/articles/about-maintainer-security-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:15674,Security,secur,security,15674," rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; properties over time. In all cases the LLVM Security Group should be consulted,; since they'll be responding to security issues filed against these parts of the; codebase. If you're not sure whether an issue is in-scope for this security process or; not, err towards assuming that it is. The Security Group might agree or disagree; and will explain its rationale in the report, as well as update this document; through the above process. The security-sensitive parts of the LLVM Project currently are the following.; Note that this list can change over time. * None are currently defined. Please don't let this stop you from reporting; issues to the security group that you believe are security-sensitive. The parts of the LLVM Project which are currently treated as non-security; sensitive are the following. Note that this list can change over time. * Language front-ends, such as clang, for which a malicious input file can cause; undesirable behavior. For example, a maliciously crafted C or Rust source file; can cause arbitrary code to execute in LLVM. These parts of LLVM haven't been; hardened, and compiling untrusted code usually also includes running utilities; such as `make` which can more readily perform malicious things. .. _CVE process: https://cve.mitre.org; .. _open a new issue: https://bugs.chromium.org/p/llvm/issues/entry; .. _chromium issue tracker: https://crbug.com; .. _GitHub security: https://help.github.com/en/articles/about-maintainer-security-advisories; .. _Discourse forums: https://discourse.llvm.org; .. _MITRE: https://cve.mitre.org; .. _example nomination is available here: https://reviews.llvm.org/D99232; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:15710,Security,secur,security-sensitive,15710," rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; properties over time. In all cases the LLVM Security Group should be consulted,; since they'll be responding to security issues filed against these parts of the; codebase. If you're not sure whether an issue is in-scope for this security process or; not, err towards assuming that it is. The Security Group might agree or disagree; and will explain its rationale in the report, as well as update this document; through the above process. The security-sensitive parts of the LLVM Project currently are the following.; Note that this list can change over time. * None are currently defined. Please don't let this stop you from reporting; issues to the security group that you believe are security-sensitive. The parts of the LLVM Project which are currently treated as non-security; sensitive are the following. Note that this list can change over time. * Language front-ends, such as clang, for which a malicious input file can cause; undesirable behavior. For example, a maliciously crafted C or Rust source file; can cause arbitrary code to execute in LLVM. These parts of LLVM haven't been; hardened, and compiling untrusted code usually also includes running utilities; such as `make` which can more readily perform malicious things. .. _CVE process: https://cve.mitre.org; .. _open a new issue: https://bugs.chromium.org/p/llvm/issues/entry; .. _chromium issue tracker: https://crbug.com; .. _GitHub security: https://help.github.com/en/articles/about-maintainer-security-advisories; .. _Discourse forums: https://discourse.llvm.org; .. _MITRE: https://cve.mitre.org; .. _example nomination is available here: https://reviews.llvm.org/D99232; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:15795,Security,secur,security,15795,"rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; properties over time. In all cases the LLVM Security Group should be consulted,; since they'll be responding to security issues filed against these parts of the; codebase. If you're not sure whether an issue is in-scope for this security process or; not, err towards assuming that it is. The Security Group might agree or disagree; and will explain its rationale in the report, as well as update this document; through the above process. The security-sensitive parts of the LLVM Project currently are the following.; Note that this list can change over time. * None are currently defined. Please don't let this stop you from reporting; issues to the security group that you believe are security-sensitive. The parts of the LLVM Project which are currently treated as non-security; sensitive are the following. Note that this list can change over time. * Language front-ends, such as clang, for which a malicious input file can cause; undesirable behavior. For example, a maliciously crafted C or Rust source file; can cause arbitrary code to execute in LLVM. These parts of LLVM haven't been; hardened, and compiling untrusted code usually also includes running utilities; such as `make` which can more readily perform malicious things. .. _CVE process: https://cve.mitre.org; .. _open a new issue: https://bugs.chromium.org/p/llvm/issues/entry; .. _chromium issue tracker: https://crbug.com; .. _GitHub security: https://help.github.com/en/articles/about-maintainer-security-advisories; .. _Discourse forums: https://discourse.llvm.org; .. _MITRE: https://cve.mitre.org; .. _example nomination is available here: https://reviews.llvm.org/D99232; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:16428,Security,secur,security,16428,"rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; properties over time. In all cases the LLVM Security Group should be consulted,; since they'll be responding to security issues filed against these parts of the; codebase. If you're not sure whether an issue is in-scope for this security process or; not, err towards assuming that it is. The Security Group might agree or disagree; and will explain its rationale in the report, as well as update this document; through the above process. The security-sensitive parts of the LLVM Project currently are the following.; Note that this list can change over time. * None are currently defined. Please don't let this stop you from reporting; issues to the security group that you believe are security-sensitive. The parts of the LLVM Project which are currently treated as non-security; sensitive are the following. Note that this list can change over time. * Language front-ends, such as clang, for which a malicious input file can cause; undesirable behavior. For example, a maliciously crafted C or Rust source file; can cause arbitrary code to execute in LLVM. These parts of LLVM haven't been; hardened, and compiling untrusted code usually also includes running utilities; such as `make` which can more readily perform malicious things. .. _CVE process: https://cve.mitre.org; .. _open a new issue: https://bugs.chromium.org/p/llvm/issues/entry; .. _chromium issue tracker: https://crbug.com; .. _GitHub security: https://help.github.com/en/articles/about-maintainer-security-advisories; .. _Discourse forums: https://discourse.llvm.org; .. _MITRE: https://cve.mitre.org; .. _example nomination is available here: https://reviews.llvm.org/D99232; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:16491,Security,secur,security-advisories,16491,"rationale, and buy-in from the LLVM; community as for any RFC. In some cases, parts of the codebase could be handled; as security-sensitive but need significant work to get to the stage where that's; manageable. The LLVM community will need to decide whether it wants to invest in; making these parts of the code securable, and maintain these security; properties over time. In all cases the LLVM Security Group should be consulted,; since they'll be responding to security issues filed against these parts of the; codebase. If you're not sure whether an issue is in-scope for this security process or; not, err towards assuming that it is. The Security Group might agree or disagree; and will explain its rationale in the report, as well as update this document; through the above process. The security-sensitive parts of the LLVM Project currently are the following.; Note that this list can change over time. * None are currently defined. Please don't let this stop you from reporting; issues to the security group that you believe are security-sensitive. The parts of the LLVM Project which are currently treated as non-security; sensitive are the following. Note that this list can change over time. * Language front-ends, such as clang, for which a malicious input file can cause; undesirable behavior. For example, a maliciously crafted C or Rust source file; can cause arbitrary code to execute in LLVM. These parts of LLVM haven't been; hardened, and compiling untrusted code usually also includes running utilities; such as `make` which can more readily perform malicious things. .. _CVE process: https://cve.mitre.org; .. _open a new issue: https://bugs.chromium.org/p/llvm/issues/entry; .. _chromium issue tracker: https://crbug.com; .. _GitHub security: https://help.github.com/en/articles/about-maintainer-security-advisories; .. _Discourse forums: https://discourse.llvm.org; .. _MITRE: https://cve.mitre.org; .. _example nomination is available here: https://reviews.llvm.org/D99232; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:797,Testability,test,testing,797,"===================; LLVM Security Group; ===================. The LLVM Security Group has the following goals:. 1. Allow LLVM contributors and security researchers to disclose security-related issues affecting the LLVM project to members of the LLVM community.; 2. Organize fixes, code reviews, and release management for said issues.; 3. Allow distributors time to investigate and deploy fixes before wide dissemination of vulnerabilities or mitigation shortcomings.; 4. Ensure timely notification and release to vendors who package and distribute LLVM-based toolchains and projects.; 5. Ensure timely notification to users of LLVM-based toolchains whose compiled code is security-sensitive, through the `CVE process`_.; 6. Strive to improve security over time, for example by adding additional testing, fuzzing, and hardening after fixing issues. *Note*: these goals ensure timely action, provide disclosure timing when issues are reported, and respect vendors' / packagers' / users' constraints. The LLVM Security Group is private. It is composed of trusted LLVM contributors. Its discussions remain within the Security Group (plus issue reporter and key experts) while an issue is being investigated. After an issue becomes public, the entirety of the group’s discussions pertaining to that issue also become public. .. _report-security-issue:. How to report a security issue?; ===============================. To report a security issue in the LLVM Project, please `open a new issue`_ in the LLVM project page, on the chromium issue tracker. Be sure to use the ""Security bug report"" template. We aim to acknowledge your report within two business days since you first reach out. If you do not receive any response by then, you can escalate by posting on the `Discourse forums`_ asking to get in touch with someone from the LLVM Security Group. **The escalation mailing list is public**: avoid discussing or mentioning the specific issue when posting on it. Group Composition; =================. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:11695,Testability,log,logistics,11695," We can finalize it later.; It seems like bugzilla and email don't meet security requirements. The medium used to host LLVM Security Group discussions is security-sensitive. It should therefore run on infrastructure which can meet our security expectations. We are currently using the `chromium issue tracker`_ (as the `llvm` project) to have security discussions:. * File security issues.; * Discuss security improvements to LLVM. When a new issue is filed, a template is provided to help issue reporters provide all relevant information. *FUTURE*: The `Github security`_ workflow allows publicly disclosing resolved security issues on the github project page, and we would be interested in adopting it for that purpose. However, it does not easily allow confidential reporting of security issues, as creating Github Security Advisories is currently restricted to Github project admins. That is why we have started with the `chromium issue tracker`_ instead. We also occasionally need to discuss logistics of the LLVM Security Group itself:. * Nominate new members.; * Propose member removal.; * Suggest policy changes. We often have these discussions publicly, in our :ref:`monthly public sync-up call <online-sync-ups>` and on the Discourse forums. For internal or confidential discussions, we also use a private mailing list. Process; =======. The following process occurs on the discussion medium for each reported issue:. * A security issue reporter (not necessarily an LLVM contributor) reports an issue.; * Within two business days, a member of the Security Group is put in charge of driving the issue to an acceptable resolution. This champion doesn’t need to be the same person for each issue. This person can self-nominate.; * Members of the Security Group discuss in which circumstances (if any) an issue is relevant to security, and determine if it is a security issue.; * Negotiate an embargo date for public disclosure, with a default minimum time limit of ninety days.; * Security Grou",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst:5374,Usability,clear,clearly,5374,"ipated in one (if any) security issue in the last year.; - If already in the LLVM Security Group, has actively participated in most membership discussions in the last year.; - If already in the LLVM Security Group, has actively participated in writing or reviewing a transparency report in the last year.; - When employed by a company or other entity, the parent entity has no more than three members already in the LLVM Security Group.; - When nominated as a vendor contact, their position with that vendor remains the same as when originally nominated.; - Nominees are trusted by existing Security Group members to keep communications embargoed while still active. Nomination process; ------------------. Anyone who feels they meet these criteria can nominate themselves, or may be nominated by a third party such as an existing LLVM Security Group member. The nomination should state whether the nominee is nominated as an individual, researcher, or as a vendor contact. It should clearly describe the grounds for nomination. For the moment, nominations are generally proposed, discussed, and voted on using Phabricator. An `example nomination is available here`_. The use of Phabricator helps keep membership discussions open, transparent, and easily accessible to LLVM developers in many ways. If, for any reason, a fully-world-readable nomination seems inappropriate, you may `open a new issue`_, and a discussion can be had about the best way to approach nomination, given the constraints that individuals are under. Our recommended method of nomination may change as our `Discussion Medium`_ story evolves over time. Choosing new members; --------------------. If a nomination for LLVM Security Group membership is supported by a majority of existing LLVM Security Group members, then it carries within five business days unless an existing member of the Security Group objects. If an objection is raised, the LLVM Security Group members should discuss the matter and try to come to consensus;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Security.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Security.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst:1585,Deployability,release,release,1585,"esses were defined well enough to enable; the group to operate reasonably well:. * We defined details on how to report security issues, see `this commit on; 20th of May 2021 <https://github.com/llvm/llvm-project/commit/c9dbaa4c86d2>`_; * We refined the nomination process for new group members, see `this; commit on 30th of July 2021 <https://github.com/llvm/llvm-project/commit/4c98e9455aad>`_; * We started writing an annual transparency report (you're reading the 2021; report here). Over the course of 2021, we had 2 people leave the LLVM Security group and 4; people join. In 2021, the security group received 13 issue reports that were made publicly; visible before 31st of December 2021. The security group judged 2 of these; reports to be security issues:. * https://bugs.chromium.org/p/llvm/issues/detail?id=5; * https://bugs.chromium.org/p/llvm/issues/detail?id=11. Both issues were addressed with source changes: #5 in clangd/vscode-clangd, and; #11 in llvm-project. No dedicated LLVM release was made for either. We believe that with the publishing of this first annual transparency report,; the security group now has implemented all necessary processes for the group to; operate as promised. The group's processes can be improved further, and we do; expect further improvements to get implemented in 2022. Many of the potential; improvements end up being discussed on the `monthly public call on LLVM's; security group <https://llvm.org/docs/GettingInvolved.html#online-sync-ups>`_. 2022; ----. In this section we report on the issues the group received in 2022, or on issues; that were received earlier, but were disclosed in 2022. In 2022, the llvm security group received 15 issues that have been disclosed at; the time of writing this transparency report. 5 of these were judged to be security issues:. * https://bugs.chromium.org/p/llvm/issues/detail?id=17 reports a miscompile in; LLVM that can result in the frame pointer and return address being; overwritten. This was fixed. * h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst:3371,Deployability,release,releases,3371,"bugs.chromium.org/p/llvm/issues/detail?id=11. Both issues were addressed with source changes: #5 in clangd/vscode-clangd, and; #11 in llvm-project. No dedicated LLVM release was made for either. We believe that with the publishing of this first annual transparency report,; the security group now has implemented all necessary processes for the group to; operate as promised. The group's processes can be improved further, and we do; expect further improvements to get implemented in 2022. Many of the potential; improvements end up being discussed on the `monthly public call on LLVM's; security group <https://llvm.org/docs/GettingInvolved.html#online-sync-ups>`_. 2022; ----. In this section we report on the issues the group received in 2022, or on issues; that were received earlier, but were disclosed in 2022. In 2022, the llvm security group received 15 issues that have been disclosed at; the time of writing this transparency report. 5 of these were judged to be security issues:. * https://bugs.chromium.org/p/llvm/issues/detail?id=17 reports a miscompile in; LLVM that can result in the frame pointer and return address being; overwritten. This was fixed. * https://bugs.chromium.org/p/llvm/issues/detail?id=19 reports a vulnerability; in `std::filesystem::remove_all` in libc++. This was fixed. * https://bugs.chromium.org/p/llvm/issues/detail?id=23 reports a new Spectre; gadget variant that Speculative Load Hardening (SLH) does not mitigate. No; extension to SLH was implemented to also mitigate against this variant. * https://bugs.chromium.org/p/llvm/issues/detail?id=30 reports missing memory; safety protection on the (C++) exception handling path. A number of fixes; were implemented. * https://bugs.chromium.org/p/llvm/issues/detail?id=33 reports the RETBLEED; vulnerability. The outcome was clang growing a new security hardening feature; `-mfunction-return=thunk-extern`, see https://reviews.llvm.org/D129572. No dedicated LLVM releases were made for any of the above issues. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst:3032,Safety,safe,safety,3032,"bugs.chromium.org/p/llvm/issues/detail?id=11. Both issues were addressed with source changes: #5 in clangd/vscode-clangd, and; #11 in llvm-project. No dedicated LLVM release was made for either. We believe that with the publishing of this first annual transparency report,; the security group now has implemented all necessary processes for the group to; operate as promised. The group's processes can be improved further, and we do; expect further improvements to get implemented in 2022. Many of the potential; improvements end up being discussed on the `monthly public call on LLVM's; security group <https://llvm.org/docs/GettingInvolved.html#online-sync-ups>`_. 2022; ----. In this section we report on the issues the group received in 2022, or on issues; that were received earlier, but were disclosed in 2022. In 2022, the llvm security group received 15 issues that have been disclosed at; the time of writing this transparency report. 5 of these were judged to be security issues:. * https://bugs.chromium.org/p/llvm/issues/detail?id=17 reports a miscompile in; LLVM that can result in the frame pointer and return address being; overwritten. This was fixed. * https://bugs.chromium.org/p/llvm/issues/detail?id=19 reports a vulnerability; in `std::filesystem::remove_all` in libc++. This was fixed. * https://bugs.chromium.org/p/llvm/issues/detail?id=23 reports a new Spectre; gadget variant that Speculative Load Hardening (SLH) does not mitigate. No; extension to SLH was implemented to also mitigate against this variant. * https://bugs.chromium.org/p/llvm/issues/detail?id=30 reports missing memory; safety protection on the (C++) exception handling path. A number of fixes; were implemented. * https://bugs.chromium.org/p/llvm/issues/detail?id=33 reports the RETBLEED; vulnerability. The outcome was clang growing a new security hardening feature; `-mfunction-return=thunk-extern`, see https://reviews.llvm.org/D129572. No dedicated LLVM releases were made for any of the above issues. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst:222,Security,secur,security,222,"========================================; LLVM Security Group Transparency Reports; ========================================. This page lists the yearly LLVM Security group transparency reports. 2021; ----. The :doc:`LLVM security group <Security>` was established on the 10th of July; 2020 by the act of the `initial; commit <https://github.com/llvm/llvm-project/commit/7bf73bcf6d93>`_ describing; the purpose of the group and the processes it follows. Many of the group's; processes were still not well-defined enough for the group to operate well.; Over the course of 2021, the key processes were defined well enough to enable; the group to operate reasonably well:. * We defined details on how to report security issues, see `this commit on; 20th of May 2021 <https://github.com/llvm/llvm-project/commit/c9dbaa4c86d2>`_; * We refined the nomination process for new group members, see `this; commit on 30th of July 2021 <https://github.com/llvm/llvm-project/commit/4c98e9455aad>`_; * We started writing an annual transparency report (you're reading the 2021; report here). Over the course of 2021, we had 2 people leave the LLVM Security group and 4; people join. In 2021, the security group received 13 issue reports that were made publicly; visible before 31st of December 2021. The security group judged 2 of these; reports to be security issues:. * https://bugs.chromium.org/p/llvm/issues/detail?id=5; * https://bugs.chromium.org/p/llvm/issues/detail?id=11. Both issues were addressed with source changes: #5 in clangd/vscode-clangd, and; #11 in llvm-project. No dedicated LLVM release was made for either. We believe that with the publishing of this first annual transparency report,; the security group now has implemented all necessary processes for the group to; operate as promised. The group's processes can be improved further, and we do; expect further improvements to get implemented in 2022. Many of the potential; improvements end up being discussed on the `monthly public call on LL",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst:708,Security,secur,security,708,"========================================; LLVM Security Group Transparency Reports; ========================================. This page lists the yearly LLVM Security group transparency reports. 2021; ----. The :doc:`LLVM security group <Security>` was established on the 10th of July; 2020 by the act of the `initial; commit <https://github.com/llvm/llvm-project/commit/7bf73bcf6d93>`_ describing; the purpose of the group and the processes it follows. Many of the group's; processes were still not well-defined enough for the group to operate well.; Over the course of 2021, the key processes were defined well enough to enable; the group to operate reasonably well:. * We defined details on how to report security issues, see `this commit on; 20th of May 2021 <https://github.com/llvm/llvm-project/commit/c9dbaa4c86d2>`_; * We refined the nomination process for new group members, see `this; commit on 30th of July 2021 <https://github.com/llvm/llvm-project/commit/4c98e9455aad>`_; * We started writing an annual transparency report (you're reading the 2021; report here). Over the course of 2021, we had 2 people leave the LLVM Security group and 4; people join. In 2021, the security group received 13 issue reports that were made publicly; visible before 31st of December 2021. The security group judged 2 of these; reports to be security issues:. * https://bugs.chromium.org/p/llvm/issues/detail?id=5; * https://bugs.chromium.org/p/llvm/issues/detail?id=11. Both issues were addressed with source changes: #5 in clangd/vscode-clangd, and; #11 in llvm-project. No dedicated LLVM release was made for either. We believe that with the publishing of this first annual transparency report,; the security group now has implemented all necessary processes for the group to; operate as promised. The group's processes can be improved further, and we do; expect further improvements to get implemented in 2022. Many of the potential; improvements end up being discussed on the `monthly public call on LL",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst:1180,Security,secur,security,1180,"curity group <Security>` was established on the 10th of July; 2020 by the act of the `initial; commit <https://github.com/llvm/llvm-project/commit/7bf73bcf6d93>`_ describing; the purpose of the group and the processes it follows. Many of the group's; processes were still not well-defined enough for the group to operate well.; Over the course of 2021, the key processes were defined well enough to enable; the group to operate reasonably well:. * We defined details on how to report security issues, see `this commit on; 20th of May 2021 <https://github.com/llvm/llvm-project/commit/c9dbaa4c86d2>`_; * We refined the nomination process for new group members, see `this; commit on 30th of July 2021 <https://github.com/llvm/llvm-project/commit/4c98e9455aad>`_; * We started writing an annual transparency report (you're reading the 2021; report here). Over the course of 2021, we had 2 people leave the LLVM Security group and 4; people join. In 2021, the security group received 13 issue reports that were made publicly; visible before 31st of December 2021. The security group judged 2 of these; reports to be security issues:. * https://bugs.chromium.org/p/llvm/issues/detail?id=5; * https://bugs.chromium.org/p/llvm/issues/detail?id=11. Both issues were addressed with source changes: #5 in clangd/vscode-clangd, and; #11 in llvm-project. No dedicated LLVM release was made for either. We believe that with the publishing of this first annual transparency report,; the security group now has implemented all necessary processes for the group to; operate as promised. The group's processes can be improved further, and we do; expect further improvements to get implemented in 2022. Many of the potential; improvements end up being discussed on the `monthly public call on LLVM's; security group <https://llvm.org/docs/GettingInvolved.html#online-sync-ups>`_. 2022; ----. In this section we report on the issues the group received in 2022, or on issues; that were received earlier, but were disclose",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst:1288,Security,secur,security,1288," commit <https://github.com/llvm/llvm-project/commit/7bf73bcf6d93>`_ describing; the purpose of the group and the processes it follows. Many of the group's; processes were still not well-defined enough for the group to operate well.; Over the course of 2021, the key processes were defined well enough to enable; the group to operate reasonably well:. * We defined details on how to report security issues, see `this commit on; 20th of May 2021 <https://github.com/llvm/llvm-project/commit/c9dbaa4c86d2>`_; * We refined the nomination process for new group members, see `this; commit on 30th of July 2021 <https://github.com/llvm/llvm-project/commit/4c98e9455aad>`_; * We started writing an annual transparency report (you're reading the 2021; report here). Over the course of 2021, we had 2 people leave the LLVM Security group and 4; people join. In 2021, the security group received 13 issue reports that were made publicly; visible before 31st of December 2021. The security group judged 2 of these; reports to be security issues:. * https://bugs.chromium.org/p/llvm/issues/detail?id=5; * https://bugs.chromium.org/p/llvm/issues/detail?id=11. Both issues were addressed with source changes: #5 in clangd/vscode-clangd, and; #11 in llvm-project. No dedicated LLVM release was made for either. We believe that with the publishing of this first annual transparency report,; the security group now has implemented all necessary processes for the group to; operate as promised. The group's processes can be improved further, and we do; expect further improvements to get implemented in 2022. Many of the potential; improvements end up being discussed on the `monthly public call on LLVM's; security group <https://llvm.org/docs/GettingInvolved.html#online-sync-ups>`_. 2022; ----. In this section we report on the issues the group received in 2022, or on issues; that were received earlier, but were disclosed in 2022. In 2022, the llvm security group received 15 issues that have been disclosed at; t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst:1336,Security,secur,security,1336," commit <https://github.com/llvm/llvm-project/commit/7bf73bcf6d93>`_ describing; the purpose of the group and the processes it follows. Many of the group's; processes were still not well-defined enough for the group to operate well.; Over the course of 2021, the key processes were defined well enough to enable; the group to operate reasonably well:. * We defined details on how to report security issues, see `this commit on; 20th of May 2021 <https://github.com/llvm/llvm-project/commit/c9dbaa4c86d2>`_; * We refined the nomination process for new group members, see `this; commit on 30th of July 2021 <https://github.com/llvm/llvm-project/commit/4c98e9455aad>`_; * We started writing an annual transparency report (you're reading the 2021; report here). Over the course of 2021, we had 2 people leave the LLVM Security group and 4; people join. In 2021, the security group received 13 issue reports that were made publicly; visible before 31st of December 2021. The security group judged 2 of these; reports to be security issues:. * https://bugs.chromium.org/p/llvm/issues/detail?id=5; * https://bugs.chromium.org/p/llvm/issues/detail?id=11. Both issues were addressed with source changes: #5 in clangd/vscode-clangd, and; #11 in llvm-project. No dedicated LLVM release was made for either. We believe that with the publishing of this first annual transparency report,; the security group now has implemented all necessary processes for the group to; operate as promised. The group's processes can be improved further, and we do; expect further improvements to get implemented in 2022. Many of the potential; improvements end up being discussed on the `monthly public call on LLVM's; security group <https://llvm.org/docs/GettingInvolved.html#online-sync-ups>`_. 2022; ----. In this section we report on the issues the group received in 2022, or on issues; that were received earlier, but were disclosed in 2022. In 2022, the llvm security group received 15 issues that have been disclosed at; t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst:1697,Security,secur,security,1697,"port security issues, see `this commit on; 20th of May 2021 <https://github.com/llvm/llvm-project/commit/c9dbaa4c86d2>`_; * We refined the nomination process for new group members, see `this; commit on 30th of July 2021 <https://github.com/llvm/llvm-project/commit/4c98e9455aad>`_; * We started writing an annual transparency report (you're reading the 2021; report here). Over the course of 2021, we had 2 people leave the LLVM Security group and 4; people join. In 2021, the security group received 13 issue reports that were made publicly; visible before 31st of December 2021. The security group judged 2 of these; reports to be security issues:. * https://bugs.chromium.org/p/llvm/issues/detail?id=5; * https://bugs.chromium.org/p/llvm/issues/detail?id=11. Both issues were addressed with source changes: #5 in clangd/vscode-clangd, and; #11 in llvm-project. No dedicated LLVM release was made for either. We believe that with the publishing of this first annual transparency report,; the security group now has implemented all necessary processes for the group to; operate as promised. The group's processes can be improved further, and we do; expect further improvements to get implemented in 2022. Many of the potential; improvements end up being discussed on the `monthly public call on LLVM's; security group <https://llvm.org/docs/GettingInvolved.html#online-sync-ups>`_. 2022; ----. In this section we report on the issues the group received in 2022, or on issues; that were received earlier, but were disclosed in 2022. In 2022, the llvm security group received 15 issues that have been disclosed at; the time of writing this transparency report. 5 of these were judged to be security issues:. * https://bugs.chromium.org/p/llvm/issues/detail?id=17 reports a miscompile in; LLVM that can result in the frame pointer and return address being; overwritten. This was fixed. * https://bugs.chromium.org/p/llvm/issues/detail?id=19 reports a vulnerability; in `std::filesystem::remove_all` in l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst:2007,Security,secur,security,2007,"e9455aad>`_; * We started writing an annual transparency report (you're reading the 2021; report here). Over the course of 2021, we had 2 people leave the LLVM Security group and 4; people join. In 2021, the security group received 13 issue reports that were made publicly; visible before 31st of December 2021. The security group judged 2 of these; reports to be security issues:. * https://bugs.chromium.org/p/llvm/issues/detail?id=5; * https://bugs.chromium.org/p/llvm/issues/detail?id=11. Both issues were addressed with source changes: #5 in clangd/vscode-clangd, and; #11 in llvm-project. No dedicated LLVM release was made for either. We believe that with the publishing of this first annual transparency report,; the security group now has implemented all necessary processes for the group to; operate as promised. The group's processes can be improved further, and we do; expect further improvements to get implemented in 2022. Many of the potential; improvements end up being discussed on the `monthly public call on LLVM's; security group <https://llvm.org/docs/GettingInvolved.html#online-sync-ups>`_. 2022; ----. In this section we report on the issues the group received in 2022, or on issues; that were received earlier, but were disclosed in 2022. In 2022, the llvm security group received 15 issues that have been disclosed at; the time of writing this transparency report. 5 of these were judged to be security issues:. * https://bugs.chromium.org/p/llvm/issues/detail?id=17 reports a miscompile in; LLVM that can result in the frame pointer and return address being; overwritten. This was fixed. * https://bugs.chromium.org/p/llvm/issues/detail?id=19 reports a vulnerability; in `std::filesystem::remove_all` in libc++. This was fixed. * https://bugs.chromium.org/p/llvm/issues/detail?id=23 reports a new Spectre; gadget variant that Speculative Load Hardening (SLH) does not mitigate. No; extension to SLH was implemented to also mitigate against this variant. * https://bugs.chro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst:2254,Security,secur,security,2254,"roup judged 2 of these; reports to be security issues:. * https://bugs.chromium.org/p/llvm/issues/detail?id=5; * https://bugs.chromium.org/p/llvm/issues/detail?id=11. Both issues were addressed with source changes: #5 in clangd/vscode-clangd, and; #11 in llvm-project. No dedicated LLVM release was made for either. We believe that with the publishing of this first annual transparency report,; the security group now has implemented all necessary processes for the group to; operate as promised. The group's processes can be improved further, and we do; expect further improvements to get implemented in 2022. Many of the potential; improvements end up being discussed on the `monthly public call on LLVM's; security group <https://llvm.org/docs/GettingInvolved.html#online-sync-ups>`_. 2022; ----. In this section we report on the issues the group received in 2022, or on issues; that were received earlier, but were disclosed in 2022. In 2022, the llvm security group received 15 issues that have been disclosed at; the time of writing this transparency report. 5 of these were judged to be security issues:. * https://bugs.chromium.org/p/llvm/issues/detail?id=17 reports a miscompile in; LLVM that can result in the frame pointer and return address being; overwritten. This was fixed. * https://bugs.chromium.org/p/llvm/issues/detail?id=19 reports a vulnerability; in `std::filesystem::remove_all` in libc++. This was fixed. * https://bugs.chromium.org/p/llvm/issues/detail?id=23 reports a new Spectre; gadget variant that Speculative Load Hardening (SLH) does not mitigate. No; extension to SLH was implemented to also mitigate against this variant. * https://bugs.chromium.org/p/llvm/issues/detail?id=30 reports missing memory; safety protection on the (C++) exception handling path. A number of fixes; were implemented. * https://bugs.chromium.org/p/llvm/issues/detail?id=33 reports the RETBLEED; vulnerability. The outcome was clang growing a new security hardening feature; `-mfunction-return",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst:2392,Security,secur,security,2392,"lvm/issues/detail?id=5; * https://bugs.chromium.org/p/llvm/issues/detail?id=11. Both issues were addressed with source changes: #5 in clangd/vscode-clangd, and; #11 in llvm-project. No dedicated LLVM release was made for either. We believe that with the publishing of this first annual transparency report,; the security group now has implemented all necessary processes for the group to; operate as promised. The group's processes can be improved further, and we do; expect further improvements to get implemented in 2022. Many of the potential; improvements end up being discussed on the `monthly public call on LLVM's; security group <https://llvm.org/docs/GettingInvolved.html#online-sync-ups>`_. 2022; ----. In this section we report on the issues the group received in 2022, or on issues; that were received earlier, but were disclosed in 2022. In 2022, the llvm security group received 15 issues that have been disclosed at; the time of writing this transparency report. 5 of these were judged to be security issues:. * https://bugs.chromium.org/p/llvm/issues/detail?id=17 reports a miscompile in; LLVM that can result in the frame pointer and return address being; overwritten. This was fixed. * https://bugs.chromium.org/p/llvm/issues/detail?id=19 reports a vulnerability; in `std::filesystem::remove_all` in libc++. This was fixed. * https://bugs.chromium.org/p/llvm/issues/detail?id=23 reports a new Spectre; gadget variant that Speculative Load Hardening (SLH) does not mitigate. No; extension to SLH was implemented to also mitigate against this variant. * https://bugs.chromium.org/p/llvm/issues/detail?id=30 reports missing memory; safety protection on the (C++) exception handling path. A number of fixes; were implemented. * https://bugs.chromium.org/p/llvm/issues/detail?id=33 reports the RETBLEED; vulnerability. The outcome was clang growing a new security hardening feature; `-mfunction-return=thunk-extern`, see https://reviews.llvm.org/D129572. No dedicated LLVM releases were m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst:3253,Security,secur,security,3253,"bugs.chromium.org/p/llvm/issues/detail?id=11. Both issues were addressed with source changes: #5 in clangd/vscode-clangd, and; #11 in llvm-project. No dedicated LLVM release was made for either. We believe that with the publishing of this first annual transparency report,; the security group now has implemented all necessary processes for the group to; operate as promised. The group's processes can be improved further, and we do; expect further improvements to get implemented in 2022. Many of the potential; improvements end up being discussed on the `monthly public call on LLVM's; security group <https://llvm.org/docs/GettingInvolved.html#online-sync-ups>`_. 2022; ----. In this section we report on the issues the group received in 2022, or on issues; that were received earlier, but were disclosed in 2022. In 2022, the llvm security group received 15 issues that have been disclosed at; the time of writing this transparency report. 5 of these were judged to be security issues:. * https://bugs.chromium.org/p/llvm/issues/detail?id=17 reports a miscompile in; LLVM that can result in the frame pointer and return address being; overwritten. This was fixed. * https://bugs.chromium.org/p/llvm/issues/detail?id=19 reports a vulnerability; in `std::filesystem::remove_all` in libc++. This was fixed. * https://bugs.chromium.org/p/llvm/issues/detail?id=23 reports a new Spectre; gadget variant that Speculative Load Hardening (SLH) does not mitigate. No; extension to SLH was implemented to also mitigate against this variant. * https://bugs.chromium.org/p/llvm/issues/detail?id=30 reports missing memory; safety protection on the (C++) exception handling path. A number of fixes; were implemented. * https://bugs.chromium.org/p/llvm/issues/detail?id=33 reports the RETBLEED; vulnerability. The outcome was clang growing a new security hardening feature; `-mfunction-return=thunk-extern`, see https://reviews.llvm.org/D129572. No dedicated LLVM releases were made for any of the above issues. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SecurityTransparencyReports.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst:171,Energy Efficiency,allocate,allocated,171,"========================; Segmented Stacks in LLVM; ========================. .. contents::; :local:. Introduction; ============. Segmented stack allows stack space to be allocated incrementally than as a; monolithic chunk (of some worst case size) at thread initialization. This is; done by allocating stack blocks (henceforth called *stacklets*) and linking them; into a doubly linked list. The function prologue is responsible for checking if; the current stacklet has enough space for the function to execute; and if not,; call into the libgcc runtime to allocate more stack space. Segmented stacks are; enabled with the ``""split-stack""`` attribute on LLVM functions. The runtime functionality is `already there in libgcc; <http://gcc.gnu.org/wiki/SplitStacks>`_. Implementation Details; ======================. .. _allocating stacklets:. Allocating Stacklets; --------------------. As mentioned above, the function prologue checks if the current stacklet has; enough space. The current approach is to use a slot in the TCB to store the; current stack limit (minus the amount of space needed to allocate a new block) -; this slot's offset is again dictated by ``libgcc``. The generated; assembly looks like this on x86-64:. .. code-block:: text. leaq -8(%rsp), %r10; cmpq %fs:112, %r10; jg .LBB0_2. # More stack space needs to be allocated; movabsq $8, %r10 # The amount of space needed; movabsq $0, %r11 # The total size of arguments passed on stack; callq __morestack; ret # The reason for this extra return is explained below; .LBB0_2:; # Usual prologue continues here. The size of function arguments on the stack needs to be passed to; ``__morestack`` (this function is implemented in ``libgcc``) since that number; of bytes has to be copied from the previous stacklet to the current one. This is; so that SP (and FP) relative addressing of function arguments work as expected. The unusual ``ret`` is needed to have the function which made a call to; ``__morestack`` return correctly. ``__more",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst:559,Energy Efficiency,allocate,allocate,559,"========================; Segmented Stacks in LLVM; ========================. .. contents::; :local:. Introduction; ============. Segmented stack allows stack space to be allocated incrementally than as a; monolithic chunk (of some worst case size) at thread initialization. This is; done by allocating stack blocks (henceforth called *stacklets*) and linking them; into a doubly linked list. The function prologue is responsible for checking if; the current stacklet has enough space for the function to execute; and if not,; call into the libgcc runtime to allocate more stack space. Segmented stacks are; enabled with the ``""split-stack""`` attribute on LLVM functions. The runtime functionality is `already there in libgcc; <http://gcc.gnu.org/wiki/SplitStacks>`_. Implementation Details; ======================. .. _allocating stacklets:. Allocating Stacklets; --------------------. As mentioned above, the function prologue checks if the current stacklet has; enough space. The current approach is to use a slot in the TCB to store the; current stack limit (minus the amount of space needed to allocate a new block) -; this slot's offset is again dictated by ``libgcc``. The generated; assembly looks like this on x86-64:. .. code-block:: text. leaq -8(%rsp), %r10; cmpq %fs:112, %r10; jg .LBB0_2. # More stack space needs to be allocated; movabsq $8, %r10 # The amount of space needed; movabsq $0, %r11 # The total size of arguments passed on stack; callq __morestack; ret # The reason for this extra return is explained below; .LBB0_2:; # Usual prologue continues here. The size of function arguments on the stack needs to be passed to; ``__morestack`` (this function is implemented in ``libgcc``) since that number; of bytes has to be copied from the previous stacklet to the current one. This is; so that SP (and FP) relative addressing of function arguments work as expected. The unusual ``ret`` is needed to have the function which made a call to; ``__morestack`` return correctly. ``__more",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst:1099,Energy Efficiency,allocate,allocate,1099,". .. contents::; :local:. Introduction; ============. Segmented stack allows stack space to be allocated incrementally than as a; monolithic chunk (of some worst case size) at thread initialization. This is; done by allocating stack blocks (henceforth called *stacklets*) and linking them; into a doubly linked list. The function prologue is responsible for checking if; the current stacklet has enough space for the function to execute; and if not,; call into the libgcc runtime to allocate more stack space. Segmented stacks are; enabled with the ``""split-stack""`` attribute on LLVM functions. The runtime functionality is `already there in libgcc; <http://gcc.gnu.org/wiki/SplitStacks>`_. Implementation Details; ======================. .. _allocating stacklets:. Allocating Stacklets; --------------------. As mentioned above, the function prologue checks if the current stacklet has; enough space. The current approach is to use a slot in the TCB to store the; current stack limit (minus the amount of space needed to allocate a new block) -; this slot's offset is again dictated by ``libgcc``. The generated; assembly looks like this on x86-64:. .. code-block:: text. leaq -8(%rsp), %r10; cmpq %fs:112, %r10; jg .LBB0_2. # More stack space needs to be allocated; movabsq $8, %r10 # The amount of space needed; movabsq $0, %r11 # The total size of arguments passed on stack; callq __morestack; ret # The reason for this extra return is explained below; .LBB0_2:; # Usual prologue continues here. The size of function arguments on the stack needs to be passed to; ``__morestack`` (this function is implemented in ``libgcc``) since that number; of bytes has to be copied from the previous stacklet to the current one. This is; so that SP (and FP) relative addressing of function arguments work as expected. The unusual ``ret`` is needed to have the function which made a call to; ``__morestack`` return correctly. ``__morestack``, instead of returning, calls; into ``.LBB0_2``. This is possible sin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst:1334,Energy Efficiency,allocate,allocated,1334,"responsible for checking if; the current stacklet has enough space for the function to execute; and if not,; call into the libgcc runtime to allocate more stack space. Segmented stacks are; enabled with the ``""split-stack""`` attribute on LLVM functions. The runtime functionality is `already there in libgcc; <http://gcc.gnu.org/wiki/SplitStacks>`_. Implementation Details; ======================. .. _allocating stacklets:. Allocating Stacklets; --------------------. As mentioned above, the function prologue checks if the current stacklet has; enough space. The current approach is to use a slot in the TCB to store the; current stack limit (minus the amount of space needed to allocate a new block) -; this slot's offset is again dictated by ``libgcc``. The generated; assembly looks like this on x86-64:. .. code-block:: text. leaq -8(%rsp), %r10; cmpq %fs:112, %r10; jg .LBB0_2. # More stack space needs to be allocated; movabsq $8, %r10 # The amount of space needed; movabsq $0, %r11 # The total size of arguments passed on stack; callq __morestack; ret # The reason for this extra return is explained below; .LBB0_2:; # Usual prologue continues here. The size of function arguments on the stack needs to be passed to; ``__morestack`` (this function is implemented in ``libgcc``) since that number; of bytes has to be copied from the previous stacklet to the current one. This is; so that SP (and FP) relative addressing of function arguments work as expected. The unusual ``ret`` is needed to have the function which made a call to; ``__morestack`` return correctly. ``__morestack``, instead of returning, calls; into ``.LBB0_2``. This is possible since both, the size of the ``ret``; instruction and the PC of call to ``__morestack`` are known. When the function; body returns, control is transferred back to ``__morestack``. ``__morestack``; then de-allocates the new stacklet, restores the correct SP value, and does a; second return, which returns control to the correct caller. Variable S",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst:2278,Energy Efficiency,allocate,allocates,2278,"eeded to allocate a new block) -; this slot's offset is again dictated by ``libgcc``. The generated; assembly looks like this on x86-64:. .. code-block:: text. leaq -8(%rsp), %r10; cmpq %fs:112, %r10; jg .LBB0_2. # More stack space needs to be allocated; movabsq $8, %r10 # The amount of space needed; movabsq $0, %r11 # The total size of arguments passed on stack; callq __morestack; ret # The reason for this extra return is explained below; .LBB0_2:; # Usual prologue continues here. The size of function arguments on the stack needs to be passed to; ``__morestack`` (this function is implemented in ``libgcc``) since that number; of bytes has to be copied from the previous stacklet to the current one. This is; so that SP (and FP) relative addressing of function arguments work as expected. The unusual ``ret`` is needed to have the function which made a call to; ``__morestack`` return correctly. ``__morestack``, instead of returning, calls; into ``.LBB0_2``. This is possible since both, the size of the ``ret``; instruction and the PC of call to ``__morestack`` are known. When the function; body returns, control is transferred back to ``__morestack``. ``__morestack``; then de-allocates the new stacklet, restores the correct SP value, and does a; second return, which returns control to the correct caller. Variable Sized Allocas; ----------------------. The section on `allocating stacklets`_ automatically assumes that every stack; frame will be of fixed size. However, LLVM allows the use of the ``llvm.alloca``; intrinsic to allocate dynamically sized blocks of memory on the stack. When; faced with such a variable-sized alloca, code is generated to:. * Check if the current stacklet has enough space. If yes, just bump the SP, like; in the normal case.; * If not, generate a call to ``libgcc``, which allocates the memory from the; heap. The memory allocated from the heap is linked into a list in the current; stacklet, and freed along with the same. This prevents a memory leak.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst:2631,Energy Efficiency,allocate,allocate,2631,"eeded to allocate a new block) -; this slot's offset is again dictated by ``libgcc``. The generated; assembly looks like this on x86-64:. .. code-block:: text. leaq -8(%rsp), %r10; cmpq %fs:112, %r10; jg .LBB0_2. # More stack space needs to be allocated; movabsq $8, %r10 # The amount of space needed; movabsq $0, %r11 # The total size of arguments passed on stack; callq __morestack; ret # The reason for this extra return is explained below; .LBB0_2:; # Usual prologue continues here. The size of function arguments on the stack needs to be passed to; ``__morestack`` (this function is implemented in ``libgcc``) since that number; of bytes has to be copied from the previous stacklet to the current one. This is; so that SP (and FP) relative addressing of function arguments work as expected. The unusual ``ret`` is needed to have the function which made a call to; ``__morestack`` return correctly. ``__morestack``, instead of returning, calls; into ``.LBB0_2``. This is possible since both, the size of the ``ret``; instruction and the PC of call to ``__morestack`` are known. When the function; body returns, control is transferred back to ``__morestack``. ``__morestack``; then de-allocates the new stacklet, restores the correct SP value, and does a; second return, which returns control to the correct caller. Variable Sized Allocas; ----------------------. The section on `allocating stacklets`_ automatically assumes that every stack; frame will be of fixed size. However, LLVM allows the use of the ``llvm.alloca``; intrinsic to allocate dynamically sized blocks of memory on the stack. When; faced with such a variable-sized alloca, code is generated to:. * Check if the current stacklet has enough space. If yes, just bump the SP, like; in the normal case.; * If not, generate a call to ``libgcc``, which allocates the memory from the; heap. The memory allocated from the heap is linked into a list in the current; stacklet, and freed along with the same. This prevents a memory leak.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst:2909,Energy Efficiency,allocate,allocates,2909,"eeded to allocate a new block) -; this slot's offset is again dictated by ``libgcc``. The generated; assembly looks like this on x86-64:. .. code-block:: text. leaq -8(%rsp), %r10; cmpq %fs:112, %r10; jg .LBB0_2. # More stack space needs to be allocated; movabsq $8, %r10 # The amount of space needed; movabsq $0, %r11 # The total size of arguments passed on stack; callq __morestack; ret # The reason for this extra return is explained below; .LBB0_2:; # Usual prologue continues here. The size of function arguments on the stack needs to be passed to; ``__morestack`` (this function is implemented in ``libgcc``) since that number; of bytes has to be copied from the previous stacklet to the current one. This is; so that SP (and FP) relative addressing of function arguments work as expected. The unusual ``ret`` is needed to have the function which made a call to; ``__morestack`` return correctly. ``__morestack``, instead of returning, calls; into ``.LBB0_2``. This is possible since both, the size of the ``ret``; instruction and the PC of call to ``__morestack`` are known. When the function; body returns, control is transferred back to ``__morestack``. ``__morestack``; then de-allocates the new stacklet, restores the correct SP value, and does a; second return, which returns control to the correct caller. Variable Sized Allocas; ----------------------. The section on `allocating stacklets`_ automatically assumes that every stack; frame will be of fixed size. However, LLVM allows the use of the ``llvm.alloca``; intrinsic to allocate dynamically sized blocks of memory on the stack. When; faced with such a variable-sized alloca, code is generated to:. * Check if the current stacklet has enough space. If yes, just bump the SP, like; in the normal case.; * If not, generate a call to ``libgcc``, which allocates the memory from the; heap. The memory allocated from the heap is linked into a list in the current; stacklet, and freed along with the same. This prevents a memory leak.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst:2957,Energy Efficiency,allocate,allocated,2957,"eeded to allocate a new block) -; this slot's offset is again dictated by ``libgcc``. The generated; assembly looks like this on x86-64:. .. code-block:: text. leaq -8(%rsp), %r10; cmpq %fs:112, %r10; jg .LBB0_2. # More stack space needs to be allocated; movabsq $8, %r10 # The amount of space needed; movabsq $0, %r11 # The total size of arguments passed on stack; callq __morestack; ret # The reason for this extra return is explained below; .LBB0_2:; # Usual prologue continues here. The size of function arguments on the stack needs to be passed to; ``__morestack`` (this function is implemented in ``libgcc``) since that number; of bytes has to be copied from the previous stacklet to the current one. This is; so that SP (and FP) relative addressing of function arguments work as expected. The unusual ``ret`` is needed to have the function which made a call to; ``__morestack`` return correctly. ``__morestack``, instead of returning, calls; into ``.LBB0_2``. This is possible since both, the size of the ``ret``; instruction and the PC of call to ``__morestack`` are known. When the function; body returns, control is transferred back to ``__morestack``. ``__morestack``; then de-allocates the new stacklet, restores the correct SP value, and does a; second return, which returns control to the correct caller. Variable Sized Allocas; ----------------------. The section on `allocating stacklets`_ automatically assumes that every stack; frame will be of fixed size. However, LLVM allows the use of the ``llvm.alloca``; intrinsic to allocate dynamically sized blocks of memory on the stack. When; faced with such a variable-sized alloca, code is generated to:. * Check if the current stacklet has enough space. If yes, just bump the SP, like; in the normal case.; * If not, generate a call to ``libgcc``, which allocates the memory from the; heap. The memory allocated from the heap is linked into a list in the current; stacklet, and freed along with the same. This prevents a memory leak.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst:2713,Modifiability,variab,variable-sized,2713,"eeded to allocate a new block) -; this slot's offset is again dictated by ``libgcc``. The generated; assembly looks like this on x86-64:. .. code-block:: text. leaq -8(%rsp), %r10; cmpq %fs:112, %r10; jg .LBB0_2. # More stack space needs to be allocated; movabsq $8, %r10 # The amount of space needed; movabsq $0, %r11 # The total size of arguments passed on stack; callq __morestack; ret # The reason for this extra return is explained below; .LBB0_2:; # Usual prologue continues here. The size of function arguments on the stack needs to be passed to; ``__morestack`` (this function is implemented in ``libgcc``) since that number; of bytes has to be copied from the previous stacklet to the current one. This is; so that SP (and FP) relative addressing of function arguments work as expected. The unusual ``ret`` is needed to have the function which made a call to; ``__morestack`` return correctly. ``__morestack``, instead of returning, calls; into ``.LBB0_2``. This is possible since both, the size of the ``ret``; instruction and the PC of call to ``__morestack`` are known. When the function; body returns, control is transferred back to ``__morestack``. ``__morestack``; then de-allocates the new stacklet, restores the correct SP value, and does a; second return, which returns control to the correct caller. Variable Sized Allocas; ----------------------. The section on `allocating stacklets`_ automatically assumes that every stack; frame will be of fixed size. However, LLVM allows the use of the ``llvm.alloca``; intrinsic to allocate dynamically sized blocks of memory on the stack. When; faced with such a variable-sized alloca, code is generated to:. * Check if the current stacklet has enough space. If yes, just bump the SP, like; in the normal case.; * If not, generate a call to ``libgcc``, which allocates the memory from the; heap. The memory allocated from the heap is linked into a list in the current; stacklet, and freed along with the same. This prevents a memory leak.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SegmentedStacks.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SegmentedStacks.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:5416,Availability,avail,available,5416,"bles, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimiz",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:6115,Availability,failure,failure,6115," linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids duplicated debugging information from; the beginning, and the global dead code elimination pass automatically deletes; debugging information for a function if it decides to delete the function. To do this, most of the debugging information (descriptors for types,; variables, functions, source files, etc) is inserted by the language front-end; in the form of LLVM metadata. Debug information is designed to be agnostic about the target debugger and; debugging information representation (e.g. DWARF/Stabs/etc). I",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:9916,Availability,avail,available,9916,"ression>`_. An `llvm.dbg.declare` intrinsic describes the; *address* of a source variable. .. code-block:: text. %i.addr = alloca i32, align 4; call void @llvm.dbg.declare(metadata i32* %i.addr, metadata !1,; metadata !DIExpression()), !dbg !2; !1 = !DILocalVariable(name: ""i"", ...) ; int i; !2 = !DILocation(...); ...; %buffer = alloca [256 x i8], align 8; ; The address of i is buffer+64.; call void @llvm.dbg.declare(metadata [256 x i8]* %buffer, metadata !3,; metadata !DIExpression(DW_OP_plus, 64)), !dbg !4; !3 = !DILocalVariable(name: ""i"", ...) ; int i; !4 = !DILocation(...). A frontend should generate exactly one call to ``llvm.dbg.declare`` at the point; of declaration of a source variable. Optimization passes that fully promote the; variable from memory to SSA values will replace this call with possibly multiple; calls to `llvm.dbg.value`. Passes that delete stores are effectively partial; promotion, and they will insert a mix of calls to ``llvm.dbg.value`` to track; the source variable value when it is available. After optimization, there may be; multiple calls to ``llvm.dbg.declare`` describing the program points where the; variables lives in memory. All calls for the same concrete source variable must; agree on the memory location. ``llvm.dbg.value``; ^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.value(metadata, metadata, metadata). This intrinsic provides information when a user source variable is set to a new; value. The first argument is the new value (wrapped as metadata). The second; argument is a `local variable <LangRef.html#dilocalvariable>`_ containing a; description of the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.value` intrinsic describes the *value* of a source variable; directly, not its address. Note that the value operand of this intrinsic may; be indirect (i.e, a pointer to the source variable), provided that interpreting; the complex expression derives the direct value. ``llv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:19439,Availability,redundant,redundant,19439,"fect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from the developer diminishes the; amount of available debug information, but increases the reliability of the; remaining information. To illustrate some potential issues, consider the following example:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); br i1 %cond, label %truebr, label %falsebr; truebr:; %tval = add i32 %bar, 1; call @llvm.dbg.value(metadata i32 %tval, metadata !1, metadata !2); %g1 = call i32 @gazonk(); br label %exit; falsebr:; %fval = add i32 %bar, 2; call @llvm.dbg.value(metadata i32 %fval, metadata !1, metadata !2); %g2 = call i32 @gazonk(); br label %exit; exit:; %merge = phi [ %tval, %tr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:19760,Availability,avail,available,19760,"rinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from the developer diminishes the; amount of available debug information, but increases the reliability of the; remaining information. To illustrate some potential issues, consider the following example:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); br i1 %cond, label %truebr, label %falsebr; truebr:; %tval = add i32 %bar, 1; call @llvm.dbg.value(metadata i32 %tval, metadata !1, metadata !2); %g1 = call i32 @gazonk(); br label %exit; falsebr:; %fval = add i32 %bar, 2; call @llvm.dbg.value(metadata i32 %fval, metadata !1, metadata !2); %g2 = call i32 @gazonk(); br label %exit; exit:; %merge = phi [ %tval, %truebr ], [ %fval, %falsebr ]; %g = phi [ %g1, %truebr ], [ %g2, %falsebr ]; call @llvm.dbg.value(metadata i32 %merge, metadata !1, metadata !2); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %plusten = add i32 %merge, 10; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:19807,Availability,reliab,reliability,19807,"rinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from the developer diminishes the; amount of available debug information, but increases the reliability of the; remaining information. To illustrate some potential issues, consider the following example:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); br i1 %cond, label %truebr, label %falsebr; truebr:; %tval = add i32 %bar, 1; call @llvm.dbg.value(metadata i32 %tval, metadata !1, metadata !2); %g1 = call i32 @gazonk(); br label %exit; falsebr:; %fval = add i32 %bar, 2; call @llvm.dbg.value(metadata i32 %fval, metadata !1, metadata !2); %g2 = call i32 @gazonk(); br label %exit; exit:; %merge = phi [ %tval, %truebr ], [ %fval, %falsebr ]; %g = phi [ %g1, %truebr ], [ %g2, %falsebr ]; call @llvm.dbg.value(metadata i32 %merge, metadata !1, metadata !2); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %plusten = add i32 %merge, 10; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:21412,Availability,recover,recover,21412,"fval, %falsebr ]; %g = phi [ %g1, %truebr ], [ %g2, %falsebr ]; call @llvm.dbg.value(metadata i32 %merge, metadata !1, metadata !2); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %plusten = add i32 %merge, 10; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. Containing two source-level variables in ``!1`` and ``!3``. The function could,; perhaps, be optimized into the following code:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; %g = call i32 @gazonk(); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; ret i32 %toret; }. What ``llvm.dbg.value`` intrinsics should be placed to represent the original variable; locations in this code? Unfortunately the second, third and fourth; dbg.values for ``!1`` in the source function have had their operands; (%tval, %fval, %merge) optimized out. Assuming we cannot recover them, we; might consider this placement of dbg.values:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); %g = call i32 @gazonk(); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. However, this will cause ``!3`` to have the return value of ``@gazonk()`` at; the same time as ``!1`` has the constant value zero -- a pair of assignments; that never occurred in the unoptimized program. To avoid this, we must terminate; the range that ``!1`` has the constant value assignment by inserting a poison; dbg.value before the dbg.value for ``!3``:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); %g = call i32 @gazonk(); call @llvm.dbg",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:23634,Availability,recover,recovered,23634,"doper; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. There are a few other dbg.value configurations that mean it terminates; dominating location definitions without adding a new location. The complete; list is:. * Any location operand is ``poison`` (or ``undef``).; * Any location operand is an empty metadata tuple (``!{}``) (which cannot; occur in a ``!DIArgList``).; * There are no location operands (empty ``DIArgList``) and the ``DIExpression``; is empty. This class of dbg.value that kills variable locations is called a ""kill; dbg.value"" or ""kill location"", and for legacy reasons the term ""undef; dbg.value"" may be used in existing code. The ``DbgVariableIntrinsic`` methods; ``isKillLocation`` and ``setKillLocation`` should be used where possible rather; than inspecting location operands directly to check or set whether a dbg.value; is a kill location. In general, if any dbg.value has its operand optimized out and cannot be; recovered, then a kill dbg.value is necessary to terminate earlier variable; locations. Additional kill dbg.values may be necessary when the debugger can; observe re-ordering of assignments. How variable location metadata is transformed during CodeGen; ============================================================. LLVM preserves debug information throughout mid-level and backend passes,; ultimately producing a mapping between source-level information and; instruction ranges. This; is relatively straightforwards for line number information, as mapping; instructions to line numbers is a simple association. For variable locations; however the story is more complex. As each ``llvm.dbg.value`` intrinsic; represents a source-level assignment of a value to a source variable, the; variable location intrinsics effectively embed a small imperative program; within the LLVM IR. By the end of CodeGen, this becomes a mapping from each; variable to their machine locations over ranges of in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:29250,Availability,avail,available,29250,"ds:; * The first operand is the Variable field of the original debug intrinsic.; * The second operand is the Expression field of the original debug intrinsic.; * Any number of operands, from the 3rd onwards, record a sequence of variable; location operands, which may take any of the same values as the first; operand of the ``DBG_VALUE`` instruction above. These variable location; operands are inserted into the final DWARF Expression in positions indicated; by the DW_OP_LLVM_arg operator in the `DIExpression; <LangRef.html#diexpression>`_. The position at which the DBG_VALUEs are inserted should correspond to the; positions of their matching ``llvm.dbg.value`` intrinsics in the IR block. As; with optimization, LLVM aims to preserve the order in which variable; assignments occurred in the source program. However SelectionDAG performs some; instruction scheduling, which can reorder assignments (discussed below).; Function parameter locations are moved to the beginning of the function if; they're not already, to ensure they're immediately available on function entry. To demonstrate variable locations during instruction selection, consider; the following example:. .. code-block:: llvm. define i32 @foo(i32* %addr) {; entry:; call void @llvm.dbg.value(metadata i32 0, metadata !3, metadata !DIExpression()), !dbg !5; br label %bb1, !dbg !5. bb1: ; preds = %bb1, %entry; %bar.0 = phi i32 [ 0, %entry ], [ %add, %bb1 ]; call void @llvm.dbg.value(metadata i32 %bar.0, metadata !3, metadata !DIExpression()), !dbg !5; %addr1 = getelementptr i32, i32 *%addr, i32 1, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr1, metadata !3, metadata !DIExpression()), !dbg !5; %loaded1 = load i32, i32* %addr1, !dbg !5; %addr2 = getelementptr i32, i32 *%addr, i32 %bar.0, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr2, metadata !3, metadata !DIExpression()), !dbg !5; %loaded2 = load i32, i32* %addr2, !dbg !5; %add = add i32 %bar.0, 1, !dbg !5; call void @llvm.dbg.value(metadata i32 %ad",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:35166,Availability,avail,available,35166,"oreg, !5, !6. In this circumstance LLVM would leave the MIR as shown above. Were we to move; the DBG_VALUE of virtual register %7 upwards with the SUB32rr, we would re-order; assignments and introduce a new state of the program. Whereas with the solution; above, the debugger will see one fewer combination of variable values, because; ``!3`` and ``!5`` will change value at the same time. This is preferred over; misrepresenting the original program. In comparison, if one sunk the MOV32rm, LLVM would produce the following:. .. code-block:: text. DBG_VALUE $noreg, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2. Here, to avoid presenting a state in which the first assignment to ``!1``; disappears, the DBG_VALUE at the top of the block assigns the variable the; undefined location, until its value is available at the end of the block where; an additional DBG_VALUE is added. Were any other DBG_VALUE for ``!1`` to occur; in the instructions that the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:35487,Availability,avail,available,35487," This is preferred over; misrepresenting the original program. In comparison, if one sunk the MOV32rm, LLVM would produce the following:. .. code-block:: text. DBG_VALUE $noreg, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2. Here, to avoid presenting a state in which the first assignment to ``!1``; disappears, the DBG_VALUE at the top of the block assigns the variable the; undefined location, until its value is available at the end of the block where; an additional DBG_VALUE is added. Were any other DBG_VALUE for ``!1`` to occur; in the instructions that the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; ------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:36299,Availability,redundant,redundant,36299," the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; corresponding to a source-level assignment where the variable may change value,; it asserts the location of a variable in a block, and loses effect outside the; block. Propagating variable locations through copies and spills is; straightforwards: determining the variable location in every basic block; requires the consideration of control flow. Consider the following IR, which; presents several difficulties:. .. code-block:: text. defi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:40279,Availability,down,down,40279,"reg does not insert the PHI node to avoid changing; codegen when debugging is enabled, and does not insert the other dbg.values; to avoid adding very large numbers of intrinsics. Instead, LiveDebugValues determines variable locations when control; flow merges. A dataflow analysis is used to propagate locations between blocks:; when control flow merges, if a variable has the same location in all; predecessors then that location is propagated into the successor. If the; predecessor locations disagree, the location becomes undefined. Once LiveDebugValues has run, every block should have all valid variable; locations described by DBG_VALUE instructions within the block. Very little; effort is then required by supporting classes (such as; DbgEntityHistoryCalculator) to build a map of each instruction to every; valid variable location, without the need to consider control flow. From; the example above, it is otherwise difficult to determine that the location; of variable ``!30`` should flow ""up"" into block ``%bb1``, but that the location; of variable ``!23`` should not flow ""down"" into the ``%exit`` block. .. _ccxx_frontend:. C/C++ front-end specific debug information; ==========================================. The C and C++ front-ends represent information about the program in a; format that is effectively identical to `DWARF <http://www.dwarfstd.org/>`_; in terms of information content. This allows code generators to; trivially support native debuggers by generating standard dwarf; information, and contains enough information for non-dwarf targets to; translate it as needed. This section describes the forms used to represent C and C++ programs. Other; languages could pattern themselves after this (which itself is tuned to; representing programs in the same way that DWARF does), or they could choose; to provide completely different forms if they don't fit into the DWARF model.; As support for debugging information gets added to the various LLVM; source-language front-end",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:75311,Availability,down,down,75311,"es``"" (all functions +; globals), the ""``.apple_types``"" (names of all types that are defined), and; the ""``.apple_namespaces``"" (all namespaces), we currently set the ``Atom``; array to be:. .. code-block:: c. HeaderData.atom_count = 1;; HeaderData.atoms[0].type = eAtomTypeDIEOffset;; HeaderData.atoms[0].form = DW_FORM_data4;. This defines the contents to be the DIE offset (eAtomTypeDIEOffset) that is; encoded as a 32 bit value (DW_FORM_data4). This allows a single name to have; multiple matching DIEs in a single file, which could come up with an inlined; function for instance. Future tables could include more information about the; DIE such as flags indicating if the DIE is a function, method, block,; or inlined. The KeyType for the DWARF table is a 32 bit string table offset into the; "".debug_str"" table. The "".debug_str"" is the string table for the DWARF which; may already contain copies of all of the strings. This helps make sure, with; help from the compiler, that we reuse the strings between all of the DWARF; sections and keeps the hash table size down. Another benefit to having the; compiler generate all strings as DW_FORM_strp in the debug info, is that; DWARF parsing can be made much faster. After a lookup is made, we get an offset into the hash data. The hash data; needs to be able to deal with 32 bit hash collisions, so the chunk of data; at the offset in the hash data consists of a triple:. .. code-block:: c. uint32_t str_offset; uint32_t hash_data_count; HashData[hash_data_count]. If ""str_offset"" is zero, then the bucket contents are done. 99.9% of the; hash data chunks contain a single item (no 32 bit hash collision):. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x........ | uint32_t HashData[2] DIE offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:78135,Availability,avail,available,78135,"e exactly what is included in the; different tables. For DWARF, we have 3 tables: ""``.apple_names``"",; ""``.apple_types``"", and ""``.apple_namespaces``"". ""``.apple_names``"" sections should contain an entry for each DWARF DIE whose; ``DW_TAG`` is a ``DW_TAG_label``, ``DW_TAG_inlined_subroutine``, or; ``DW_TAG_subprogram`` that has address attributes: ``DW_AT_low_pc``,; ``DW_AT_high_pc``, ``DW_AT_ranges`` or ``DW_AT_entry_pc``. It also contains; ``DW_TAG_variable`` DIEs that have a ``DW_OP_addr`` in the location (global and; static variables). All global and static variables should be included,; including those scoped within functions and classes. For example using the; following code:. .. code-block:: c. static int var = 0;. void f (); {; static int var = 0;; }. Both of the static ``var`` variables would be included in the table. All; functions should emit both their full names and their basenames. For C or C++,; the full name is the mangled name (if available) which is usually in the; ``DW_AT_MIPS_linkage_name`` attribute, and the ``DW_AT_name`` contains the; function basename. If global or static variables have a mangled name in a; ``DW_AT_MIPS_linkage_name`` attribute, this should be emitted along with the; simple name found in the ``DW_AT_name`` attribute. ""``.apple_types``"" sections should contain an entry for each DWARF DIE whose; tag is one of:. * DW_TAG_array_type; * DW_TAG_class_type; * DW_TAG_enumeration_type; * DW_TAG_pointer_type; * DW_TAG_reference_type; * DW_TAG_string_type; * DW_TAG_structure_type; * DW_TAG_subroutine_type; * DW_TAG_typedef; * DW_TAG_union_type; * DW_TAG_ptr_to_member_type; * DW_TAG_set_type; * DW_TAG_subrange_type; * DW_TAG_base_type; * DW_TAG_const_type; * DW_TAG_immutable_type; * DW_TAG_file_type; * DW_TAG_namelist; * DW_TAG_packed_type; * DW_TAG_volatile_type; * DW_TAG_restrict_type; * DW_TAG_atomic_type; * DW_TAG_interface_type; * DW_TAG_unspecified_type; * DW_TAG_shared_type. Only entries with a ``DW_AT_name`` attribute are include",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:80831,Availability,down,down,80831,"espace, and; the name should be output as ""``(anonymous namespace)``"" (without the quotes).; Why? This matches the output of the ``abi::cxa_demangle()`` that is in the; standard C++ library that demangles mangled names. Language Extensions and File Format Changes; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Objective-C Extensions; """""""""""""""""""""""""""""""""""""""""""". ""``.apple_objc``"" section should contain all ``DW_TAG_subprogram`` DIEs for an; Objective-C class. The name used in the hash table is the name of the; Objective-C class itself. If the Objective-C class has a category, then an; entry is made for both the class name without the category, and for the class; name with the category. So if we have a DIE at offset 0x1234 with a name of; method ""``-[NSString(my_additions) stringWithSpecialString:]``"", we would add; an entry for ""``NSString``"" that points to DIE 0x1234, and an entry for; ""``NSString(my_additions)``"" that points to 0x1234. This allows us to quickly; track down all Objective-C methods for an Objective-C class when doing; expressions. It is needed because of the dynamic nature of Objective-C where; anyone can add methods to a class. The DWARF for Objective-C methods is also; emitted differently from C++ classes where the methods are not usually; contained in the class definition, they are scattered about across one or more; compile units. Categories can also be defined in different shared libraries.; So we need to be able to quickly find all of the methods and class functions; given the Objective-C class name, or quickly find all methods and class; functions for a class + category name. This table does not contain any; selector names, it just maps Objective-C class names (or class names +; category) to all of the methods and class functions. The selectors are added; as function basenames in the ""``.debug_names``"" section. In the ""``.apple_names``"" section for Objective-C functions, the full name is; the entire function name with the brackets (""``-[NSString; st",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:4104,Deployability,update,updated,4104,"nfo format, which is usable with Microsoft debuggers such; as Visual Studio and WinDBG. LLVM's debug information format is mostly derived; from and inspired by DWARF, but it is feasible to translate into other target; debug info formats such as STABS. It would also be reasonable to use debug information to feed profiling tools; for analysis of generated code, or, tools for reconstructing the original; source from generated code. .. _intro_debugopt:. Debug information and optimizations; -----------------------------------. An extremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:4482,Deployability,upgrade,upgraded,4482,"ng the original; source from generated code. .. _intro_debugopt:. Debug information and optimizations; -----------------------------------. An extremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:4547,Deployability,update,update,4547,"ng the original; source from generated code. .. _intro_debugopt:. Debug information and optimizations; -----------------------------------. An extremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:18726,Deployability,update,update,18726,"rovides a straightforward; way to find instructions covered by a scope. Object lifetime in optimized code; =================================. In the example above, every variable assignment uniquely corresponds to a; memory store to the variable's position on the stack. However in heavily; optimized code LLVM promotes most variables into SSA values, which can; eventually be placed in physical registers or memory locations. To track SSA; values through compilation, when objects are promoted to SSA values an; ``llvm.dbg.value`` intrinsic is created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:22780,Deployability,configurat,configurations,22780,"e(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. However, this will cause ``!3`` to have the return value of ``@gazonk()`` at; the same time as ``!1`` has the constant value zero -- a pair of assignments; that never occurred in the unoptimized program. To avoid this, we must terminate; the range that ``!1`` has the constant value assignment by inserting a poison; dbg.value before the dbg.value for ``!3``:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); %g = call i32 @gazonk(); call @llvm.dbg.value(metadata i32 poison, metadata !1, metadata !2); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. There are a few other dbg.value configurations that mean it terminates; dominating location definitions without adding a new location. The complete; list is:. * Any location operand is ``poison`` (or ``undef``).; * Any location operand is an empty metadata tuple (``!{}``) (which cannot; occur in a ``!DIArgList``).; * There are no location operands (empty ``DIArgList``) and the ``DIExpression``; is empty. This class of dbg.value that kills variable locations is called a ""kill; dbg.value"" or ""kill location"", and for legacy reasons the term ""undef; dbg.value"" may be used in existing code. The ``DbgVariableIntrinsic`` methods; ``isKillLocation`` and ``setKillLocation`` should be used where possible rather; than inspecting location operands directly to check or set whether a dbg.value; is a kill location. In general, if any dbg.value has its operand optimized out and cannot be; recovered, then a kill dbg.value is necessary to terminate earlier variable; locations. Additional kill dbg.values may be necessary when the debugger can; observe re-ordering of assignments. How",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:24863,Energy Efficiency,schedul,scheduling,24863,"==========================================. LLVM preserves debug information throughout mid-level and backend passes,; ultimately producing a mapping between source-level information and; instruction ranges. This; is relatively straightforwards for line number information, as mapping; instructions to line numbers is a simple association. For variable locations; however the story is more complex. As each ``llvm.dbg.value`` intrinsic; represents a source-level assignment of a value to a source variable, the; variable location intrinsics effectively embed a small imperative program; within the LLVM IR. By the end of CodeGen, this becomes a mapping from each; variable to their machine locations over ranges of instructions.; From IR to object emission, the major transformations which affect variable; location fidelity are:. 1. Instruction Selection; 2. Register allocation; 3. Block layout. each of which are discussed below. In addition, instruction scheduling can; significantly change the ordering of the program, and occurs in a number of; different passes. Some variable locations are not transformed during CodeGen. Stack locations; specified by ``llvm.dbg.declare`` are valid and unchanging for the entire; duration of the function, and are recorded in a simple MachineFunction table.; Location changes in the prologue and epilogue of a function are also ignored:; frame setup and destruction may take several instructions, require a; disproportionate amount of debugging information in the output binary to; describe, and should be stepped over by debuggers anyway. Variable locations in Instruction Selection and MIR; ---------------------------------------------------. Instruction selection creates a MIR function from an IR function, and just as; it transforms ``intermediate`` instructions into machine instructions, so must; ``intermediate`` variable locations become machine variable locations.; Within IR, variable locations are always identified by a Value, but in MIR; there ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:26342,Energy Efficiency,allocate,allocated,26342,"d:; frame setup and destruction may take several instructions, require a; disproportionate amount of debugging information in the output binary to; describe, and should be stepped over by debuggers anyway. Variable locations in Instruction Selection and MIR; ---------------------------------------------------. Instruction selection creates a MIR function from an IR function, and just as; it transforms ``intermediate`` instructions into machine instructions, so must; ``intermediate`` variable locations become machine variable locations.; Within IR, variable locations are always identified by a Value, but in MIR; there can be different types of variable locations. In addition, some IR; locations become unavailable, for example if the operation of multiple IR; instructions are combined into one machine instruction (such as; multiply-and-accumulate) then intermediate Values are lost. To track variable; locations through instruction selection, they are first separated into; locations that do not depend on code generation (constants, stack locations,; allocated virtual registers) and those that do. For those that do, debug; metadata is attached to SDNodes in SelectionDAGs. After instruction selection; has occurred and a MIR function is created, if the SDNode associated with debug; metadata is allocated a virtual register, that virtual register is used as the; variable location. If the SDNode is folded into a machine instruction or; otherwise transformed into a non-register, the variable location becomes; unavailable. Locations that are unavailable are treated as if they have been optimized out:; in IR the location would be assigned ``undef`` by a debug intrinsic, and in MIR; the equivalent location is used. After MIR locations are assigned to each variable, machine pseudo-instructions; corresponding to each ``llvm.dbg.value`` intrinsic are inserted. There are two; forms of this type of instruction. The first form, ``DBG_VALUE``, appears thus:. .. code-block:: text. DBG_VAL",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:26588,Energy Efficiency,allocate,allocated,26588,"---------------------. Instruction selection creates a MIR function from an IR function, and just as; it transforms ``intermediate`` instructions into machine instructions, so must; ``intermediate`` variable locations become machine variable locations.; Within IR, variable locations are always identified by a Value, but in MIR; there can be different types of variable locations. In addition, some IR; locations become unavailable, for example if the operation of multiple IR; instructions are combined into one machine instruction (such as; multiply-and-accumulate) then intermediate Values are lost. To track variable; locations through instruction selection, they are first separated into; locations that do not depend on code generation (constants, stack locations,; allocated virtual registers) and those that do. For those that do, debug; metadata is attached to SDNodes in SelectionDAGs. After instruction selection; has occurred and a MIR function is created, if the SDNode associated with debug; metadata is allocated a virtual register, that virtual register is used as the; variable location. If the SDNode is folded into a machine instruction or; otherwise transformed into a non-register, the variable location becomes; unavailable. Locations that are unavailable are treated as if they have been optimized out:; in IR the location would be assigned ``undef`` by a debug intrinsic, and in MIR; the equivalent location is used. After MIR locations are assigned to each variable, machine pseudo-instructions; corresponding to each ``llvm.dbg.value`` intrinsic are inserted. There are two; forms of this type of instruction. The first form, ``DBG_VALUE``, appears thus:. .. code-block:: text. DBG_VALUE %1, $noreg, !123, !DIExpression(). And has the following operands:; * The first operand can record the variable location as a register,; a frame index, an immediate, or the base address register if the original; debug intrinsic referred to memory. ``$noreg`` indicates the variable; loc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:29061,Energy Efficiency,schedul,scheduling,29061,"ck:: text. DBG_VALUE_LIST !123, !DIExpression(DW_OP_LLVM_arg, 0, DW_OP_LLVM_arg, 1, DW_OP_plus), %1, %2. And has the following operands:; * The first operand is the Variable field of the original debug intrinsic.; * The second operand is the Expression field of the original debug intrinsic.; * Any number of operands, from the 3rd onwards, record a sequence of variable; location operands, which may take any of the same values as the first; operand of the ``DBG_VALUE`` instruction above. These variable location; operands are inserted into the final DWARF Expression in positions indicated; by the DW_OP_LLVM_arg operator in the `DIExpression; <LangRef.html#diexpression>`_. The position at which the DBG_VALUEs are inserted should correspond to the; positions of their matching ``llvm.dbg.value`` intrinsics in the IR block. As; with optimization, LLVM aims to preserve the order in which variable; assignments occurred in the source program. However SelectionDAG performs some; instruction scheduling, which can reorder assignments (discussed below).; Function parameter locations are moved to the beginning of the function if; they're not already, to ensure they're immediately available on function entry. To demonstrate variable locations during instruction selection, consider; the following example:. .. code-block:: llvm. define i32 @foo(i32* %addr) {; entry:; call void @llvm.dbg.value(metadata i32 0, metadata !3, metadata !DIExpression()), !dbg !5; br label %bb1, !dbg !5. bb1: ; preds = %bb1, %entry; %bar.0 = phi i32 [ 0, %entry ], [ %add, %bb1 ]; call void @llvm.dbg.value(metadata i32 %bar.0, metadata !3, metadata !DIExpression()), !dbg !5; %addr1 = getelementptr i32, i32 *%addr, i32 1, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr1, metadata !3, metadata !DIExpression()), !dbg !5; %loaded1 = load i32, i32* %addr1, !dbg !5; %addr2 = getelementptr i32, i32 *%addr, i32 %bar.0, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr2, metadata !3, metadata !DIExpression(",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:32803,Energy Efficiency,schedul,schedulers,32803,"n !5. Observe first that there is a DBG_VALUE instruction for every ``llvm.dbg.value``; intrinsic in the source IR, ensuring no source level assignments go missing.; Then consider the different ways in which variable locations have been recorded:. * For the first dbg.value an immediate operand is used to record a zero value.; * The dbg.value of the PHI instruction leads to a DBG_VALUE of virtual register; ``%0``.; * The first GEP has its effect folded into the first load instruction; (as a 4-byte offset), but the variable location is salvaged by folding; the GEPs effect into the DIExpression.; * The second GEP is also folded into the corresponding load. However, it is; insufficiently simple to be salvaged, and is emitted as a ``$noreg``; DBG_VALUE, indicating that the variable takes on an undefined location.; * The final dbg.value has its Value placed in virtual register ``%1``. Instruction Scheduling; ----------------------. A number of passes can reschedule instructions, notably instruction selection; and the pre-and-post RA machine schedulers. Instruction scheduling can; significantly change the nature of the program -- in the (very unlikely) worst; case the instruction sequence could be completely reversed. In such; circumstances LLVM follows the principle applied to optimizations, that it is; better for the debugger not to display any state than a misleading state.; Thus, whenever instructions are advanced in order of execution, any; corresponding DBG_VALUE is kept in its original position, and if an instruction; is delayed then the variable is given an undefined location for the duration; of the delay. To illustrate, consider this pseudo-MIR:. .. code-block:: text. %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6. Imagine that th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:32827,Energy Efficiency,schedul,scheduling,32827,"nments go missing.; Then consider the different ways in which variable locations have been recorded:. * For the first dbg.value an immediate operand is used to record a zero value.; * The dbg.value of the PHI instruction leads to a DBG_VALUE of virtual register; ``%0``.; * The first GEP has its effect folded into the first load instruction; (as a 4-byte offset), but the variable location is salvaged by folding; the GEPs effect into the DIExpression.; * The second GEP is also folded into the corresponding load. However, it is; insufficiently simple to be salvaged, and is emitted as a ``$noreg``; DBG_VALUE, indicating that the variable takes on an undefined location.; * The final dbg.value has its Value placed in virtual register ``%1``. Instruction Scheduling; ----------------------. A number of passes can reschedule instructions, notably instruction selection; and the pre-and-post RA machine schedulers. Instruction scheduling can; significantly change the nature of the program -- in the (very unlikely) worst; case the instruction sequence could be completely reversed. In such; circumstances LLVM follows the principle applied to optimizations, that it is; better for the debugger not to display any state than a misleading state.; Thus, whenever instructions are advanced in order of execution, any; corresponding DBG_VALUE is kept in its original position, and if an instruction; is delayed then the variable is given an undefined location for the duration; of the delay. To illustrate, consider this pseudo-MIR:. .. code-block:: text. %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6. Imagine that the SUB32rr were moved forward to give us the following MIR:. .. code-block:: text. %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; %1:gr32 = ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:63432,Energy Efficiency,efficient,efficiently,63432,"et 0x000034f0 and start looking to see if our 32 bit hash matches. To; do so, we need to read the next pointer, then read the hash, compare it, and; skip to the next bucket. Each time we are skipping many bytes in memory and; touching new pages just to do the compare on the full 32 bit hash. All of; these accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the hash tables a bit; differently: a header, buckets, an array of all unique 32 bit hash values,; followed by an array of hash value data offsets, one for each hash value, then; the data for all hash values:. .. code-block:: none. .-------------.; | HEADER |; |-------------|; | BUCKETS |; |-------------|; | HASHES |; |-------------|; | OFFSETS |; |-------------|; | DATA |; `-------------'. The ``BUCKETS`` in the name tables are an index into the ``HASHES`` array. By; making all of the full 32 bit hash values contiguous in memory, we allow; ourselves to efficiently check for a match while touching as little memory as; possible. Most often checking the 32 bit hash values is as far as the lookup; goes. If it does match, it usually is a match with no collisions. So for a; table with ""``n_buckets``"" buckets, and ""``n_hashes``"" unique 32 bit hash; values, we can clarify the contents of the ``BUCKETS``, ``HASHES`` and; ``OFFSETS`` as:. .. code-block:: none. .-------------------------.; | HEADER.magic | uint32_t; | HEADER.version | uint16_t; | HEADER.hash_function | uint16_t; | HEADER.bucket_count | uint32_t; | HEADER.hashes_count | uint32_t; | HEADER.header_data_len | uint32_t; | HEADER_DATA | HeaderData; |-------------------------|; | BUCKETS | uint32_t[n_buckets] // 32 bit hash indexes; |-------------------------|; | HASHES | uint32_t[n_hashes] // 32 bit hash values; |-------------------------|; | OFFSETS | uint32_t[n_hashes] // 32 bit offsets to hash value data; |-------------------------|; | ALL HASH DATA |; `-------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:67106,Energy Efficiency,efficient,efficiently,67106," into .debug_str (""collision""); | 0x00000002 | A 32 bit array count - number of HashData with name ""collision""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x00001203 | String offset into .debug_str (""dump""); | 0x00000003 | A 32 bit array count - number of HashData with name ""dump""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x00000000 | String offset into .debug_str (terminate data for hash); |------------|; 0x00003550: | 0x00001203 | String offset into .debug_str (""main""); | 0x00000009 | A 32 bit array count - number of HashData with name ""main""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x........ | HashData[3]; | 0x........ | HashData[4]; | 0x........ | HashData[5]; | 0x........ | HashData[6]; | 0x........ | HashData[7]; | 0x........ | HashData[8]; | 0x00000000 | String offset into .debug_str (terminate data for hash); `------------'. So we still have all of the same data, we just organize it more efficiently for; debugger lookup. If we repeat the same ""``printf``"" lookup from above, we; would hash ""``printf``"" and find it matches ``BUCKETS[3]`` by taking the 32 bit; hash value and modulo it by ``n_buckets``. ``BUCKETS[3]`` contains ""6"" which; is the index into the ``HASHES`` table. We would then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:71455,Energy Efficiency,efficient,efficient,71455,"ed versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables can be implemented in a variety of ways and can store a lot; of information for each name. We want to make the DWARF tables extensible and; able to store the data efficiently so we have used some of the DWARF features; that enable efficient data storage to define exactly what kind of data we store; for each name. The ``HeaderData`` contains a definition of the contents of each HashData chunk.; We might want to store an offset to all of the debug information entries (DIEs); for each name. To keep things extensible, we create a list of items, or; Atoms, that are contained in the data for each name. First comes the type of; the data in each atom:. .. code-block:: c. enum AtomType; {; eAtomTypeNULL = 0u,; eAtomTypeDIEOffset = 1u, // DIE offset, check form for encoding; eAtomTypeCUOffset = 2u, // DIE offset of the compiler unit header that contains the item in question; eAtomTypeTag = 3u, // DW_TAG_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:71688,Energy Efficiency,efficient,efficiently,71688,"r.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables can be implemented in a variety of ways and can store a lot; of information for each name. We want to make the DWARF tables extensible and; able to store the data efficiently so we have used some of the DWARF features; that enable efficient data storage to define exactly what kind of data we store; for each name. The ``HeaderData`` contains a definition of the contents of each HashData chunk.; We might want to store an offset to all of the debug information entries (DIEs); for each name. To keep things extensible, we create a list of items, or; Atoms, that are contained in the data for each name. First comes the type of; the data in each atom:. .. code-block:: c. enum AtomType; {; eAtomTypeNULL = 0u,; eAtomTypeDIEOffset = 1u, // DIE offset, check form for encoding; eAtomTypeCUOffset = 2u, // DIE offset of the compiler unit header that contains the item in question; eAtomTypeTag = 3u, // DW_TAG_xxx value, should be encoded as DW_FORM_data1 (if no tags exceed 255) or DW_FORM_data2; eAtomTypeNameFlags = 4u, // Flags from enum NameFlags; eAtomTypeTypeFlags = 5u, // Flags from enum TypeFlags; };. The enumeration values and their meanings are:. .. code-block:: none. eAtomTypeNULL - a termi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:71756,Energy Efficiency,efficient,efficient,71756,"r.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables can be implemented in a variety of ways and can store a lot; of information for each name. We want to make the DWARF tables extensible and; able to store the data efficiently so we have used some of the DWARF features; that enable efficient data storage to define exactly what kind of data we store; for each name. The ``HeaderData`` contains a definition of the contents of each HashData chunk.; We might want to store an offset to all of the debug information entries (DIEs); for each name. To keep things extensible, we create a list of items, or; Atoms, that are contained in the data for each name. First comes the type of; the data in each atom:. .. code-block:: c. enum AtomType; {; eAtomTypeNULL = 0u,; eAtomTypeDIEOffset = 1u, // DIE offset, check form for encoding; eAtomTypeCUOffset = 2u, // DIE offset of the compiler unit header that contains the item in question; eAtomTypeTag = 3u, // DW_TAG_xxx value, should be encoded as DW_FORM_data1 (if no tags exceed 255) or DW_FORM_data2; eAtomTypeNameFlags = 4u, // Flags from enum NameFlags; eAtomTypeTypeFlags = 5u, // Flags from enum TypeFlags; };. The enumeration values and their meanings are:. .. code-block:: none. eAtomTypeNULL - a termi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:82906,Energy Efficiency,efficient,efficiently,82906,"g; stringWithCString:]``"") and the basename is the selector only; (""``stringWithCString:``""). Mach-O Changes; """""""""""""""""""""""""""". The sections names for the apple hash tables are for non-mach-o files. For; mach-o files, the sections should be contained in the ``__DWARF`` segment with; names as follows:. * ""``.apple_names``"" -> ""``__apple_names``""; * ""``.apple_types``"" -> ""``__apple_types``""; * ""``.apple_namespaces``"" -> ""``__apple_namespac``"" (16 character limit); * ""``.apple_objc``"" -> ""``__apple_objc``"". .. _codeview:. CodeView Debug Info Format; ==========================. LLVM supports emitting CodeView, the Microsoft debug info format, and this; section describes the design and implementation of that support. Format Background; -----------------. CodeView as a format is clearly oriented around C++ debugging, and in C++, the; majority of debug information tends to be type information. Therefore, the; overriding design constraint of CodeView is the separation of type information; from other ""symbol"" information so that type information can be efficiently; merged across translation units. Both type information and symbol information is; generally stored as a sequence of records, where each record begins with a; 16-bit record size and a 16-bit record kind. Type information is usually stored in the ``.debug$T`` section of the object; file. All other debug info, such as line info, string table, symbol info, and; inlinee info, is stored in one or more ``.debug$S`` sections. There may only be; one ``.debug$T`` section per object file, since all other debug info refers to; it. If a PDB (enabled by the ``/Zi`` MSVC option) was used during compilation,; the ``.debug$T`` section will contain only an ``LF_TYPESERVER2`` record pointing; to the PDB. When using PDBs, symbol information appears to remain in the object; file ``.debug$S`` sections. Type records are referred to by their index, which is the number of records in; the stream before a given record plus ``0x1000``. Many co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:10391,Integrability,wrap,wrapped,10391,"_OP_plus, 64)), !dbg !4; !3 = !DILocalVariable(name: ""i"", ...) ; int i; !4 = !DILocation(...). A frontend should generate exactly one call to ``llvm.dbg.declare`` at the point; of declaration of a source variable. Optimization passes that fully promote the; variable from memory to SSA values will replace this call with possibly multiple; calls to `llvm.dbg.value`. Passes that delete stores are effectively partial; promotion, and they will insert a mix of calls to ``llvm.dbg.value`` to track; the source variable value when it is available. After optimization, there may be; multiple calls to ``llvm.dbg.declare`` describing the program points where the; variables lives in memory. All calls for the same concrete source variable must; agree on the memory location. ``llvm.dbg.value``; ^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.value(metadata, metadata, metadata). This intrinsic provides information when a user source variable is set to a new; value. The first argument is the new value (wrapped as metadata). The second; argument is a `local variable <LangRef.html#dilocalvariable>`_ containing a; description of the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.value` intrinsic describes the *value* of a source variable; directly, not its address. Note that the value operand of this intrinsic may; be indirect (i.e, a pointer to the source variable), provided that interpreting; the complex expression derives the direct value. ``llvm.dbg.assign``; ^^^^^^^^^^^^^^^^^^^; .. toctree::; :hidden:. AssignmentTracking. .. code-block:: llvm. void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression). This intrinsic marks the position in IR where a source assignment occurred. It; encodes the value of the variable. It references the store, if any, that; performs the assignment, and the destination address. The first thr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:11551,Integrability,wrap,wrapped,11551,"expression; <LangRef.html#diexpression>`_. An `llvm.dbg.value` intrinsic describes the *value* of a source variable; directly, not its address. Note that the value operand of this intrinsic may; be indirect (i.e, a pointer to the source variable), provided that interpreting; the complex expression derives the direct value. ``llvm.dbg.assign``; ^^^^^^^^^^^^^^^^^^^; .. toctree::; :hidden:. AssignmentTracking. .. code-block:: llvm. void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression). This intrinsic marks the position in IR where a source assignment occurred. It; encodes the value of the variable. It references the store, if any, that; performs the assignment, and the destination address. The first three arguments are the same as for an ``llvm.dbg.value``. The fourth; argument is a ``DIAssignID`` used to reference a store. The fifth is the; destination of the store (wrapped as metadata), and the sixth is a `complex; expression <LangRef.html#diexpression>`_ that modifies it. The formal LLVM-IR signature is:. .. code-block:: llvm. void @llvm.dbg.assign(metadata, metadata, metadata, metadata, metadata, metadata). See :doc:`AssignmentTracking` for more info. Object lifetimes and scoping; ============================. In many languages, the local variables in functions can have their lifetimes or; scopes limited to a subset of a function. In the C family of languages, for; example, variables are only live (readable and writable) within the source; block that they are defined in. In functional languages, values are only; readable after they have been defined. Though this is a very obvious concept,; it is non-trivial to model in LLVM, because it has no notion of scoping in this; sense, and does not want to be tied to a language's scoping rules. In order to handle this, the LLVM debug format uses the metadata attached to; llvm instructions to encode line number and sc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:26286,Integrability,depend,depend,26286,"d:; frame setup and destruction may take several instructions, require a; disproportionate amount of debugging information in the output binary to; describe, and should be stepped over by debuggers anyway. Variable locations in Instruction Selection and MIR; ---------------------------------------------------. Instruction selection creates a MIR function from an IR function, and just as; it transforms ``intermediate`` instructions into machine instructions, so must; ``intermediate`` variable locations become machine variable locations.; Within IR, variable locations are always identified by a Value, but in MIR; there can be different types of variable locations. In addition, some IR; locations become unavailable, for example if the operation of multiple IR; instructions are combined into one machine instruction (such as; multiply-and-accumulate) then intermediate Values are lost. To track variable; locations through instruction selection, they are first separated into; locations that do not depend on code generation (constants, stack locations,; allocated virtual registers) and those that do. For those that do, debug; metadata is attached to SDNodes in SelectionDAGs. After instruction selection; has occurred and a MIR function is created, if the SDNode associated with debug; metadata is allocated a virtual register, that virtual register is used as the; variable location. If the SDNode is folded into a machine instruction or; otherwise transformed into a non-register, the variable location becomes; unavailable. Locations that are unavailable are treated as if they have been optimized out:; in IR the location would be assigned ``undef`` by a debug intrinsic, and in MIR; the equivalent location is used. After MIR locations are assigned to each variable, machine pseudo-instructions; corresponding to each ``llvm.dbg.value`` intrinsic are inserted. There are two; forms of this type of instruction. The first form, ``DBG_VALUE``, appears thus:. .. code-block:: text. DBG_VAL",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:49506,Integrability,interface,interfaces,49506,"wing descriptor for the trampoline function:. .. code-block:: text. !DISubprogram(name: ""sub1_.t0p"", linkageName: ""sub1_.t0p"", scope: !4, file: !4, type: !5, spFlags: DISPFlagLocalToUnit | DISPFlagDefinition, unit: !7, retainedNodes: !24, targetFuncName: ""sub1_""). The targetFuncName field is the name of the function that the trampoline; calls. This descriptor results in the following DWARF tag:. .. code-block:: text. DW_TAG_subprogram; ...; DW_AT_linkage_name	(""sub1_.t0p""); DW_AT_name	(""sub1_.t0p""); DW_AT_trampoline	(""sub1_""). Debugging information format; ============================. Debugging Information Extension for Objective C Properties; ----------------------------------------------------------. Introduction; ^^^^^^^^^^^^. Objective C provides a simpler way to declare and define accessor methods using; declared properties. The language provides features to declare a property and; to let compiler synthesize accessor methods. The debugger lets developer inspect Objective C interfaces and their instance; variables and class variables. However, the debugger does not know anything; about the properties defined in Objective C interfaces. The debugger consumes; information generated by compiler in DWARF format. The format does not support; encoding of Objective C properties. This proposal describes DWARF extensions to; encode Objective C properties, which the debugger can use to let developers; inspect Objective C properties. Proposal; ^^^^^^^^. Objective C properties exist separately from class members. A property can be; defined only by ""setter"" and ""getter"" selectors, and be calculated anew on each; access. Or a property can just be a direct access to some declared ivar.; Finally it can have an ivar ""automatically synthesized"" for it by the compiler,; in which case the property can be referred to in user code directly using the; standard C dereference syntax as well as through the property ""dot"" syntax, but; there is no entry in the ``@interface`` declaration co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:49658,Integrability,interface,interfaces,49658,"geName: ""sub1_.t0p"", scope: !4, file: !4, type: !5, spFlags: DISPFlagLocalToUnit | DISPFlagDefinition, unit: !7, retainedNodes: !24, targetFuncName: ""sub1_""). The targetFuncName field is the name of the function that the trampoline; calls. This descriptor results in the following DWARF tag:. .. code-block:: text. DW_TAG_subprogram; ...; DW_AT_linkage_name	(""sub1_.t0p""); DW_AT_name	(""sub1_.t0p""); DW_AT_trampoline	(""sub1_""). Debugging information format; ============================. Debugging Information Extension for Objective C Properties; ----------------------------------------------------------. Introduction; ^^^^^^^^^^^^. Objective C provides a simpler way to declare and define accessor methods using; declared properties. The language provides features to declare a property and; to let compiler synthesize accessor methods. The debugger lets developer inspect Objective C interfaces and their instance; variables and class variables. However, the debugger does not know anything; about the properties defined in Objective C interfaces. The debugger consumes; information generated by compiler in DWARF format. The format does not support; encoding of Objective C properties. This proposal describes DWARF extensions to; encode Objective C properties, which the debugger can use to let developers; inspect Objective C properties. Proposal; ^^^^^^^^. Objective C properties exist separately from class members. A property can be; defined only by ""setter"" and ""getter"" selectors, and be calculated anew on each; access. Or a property can just be a direct access to some declared ivar.; Finally it can have an ivar ""automatically synthesized"" for it by the compiler,; in which case the property can be referred to in user code directly using the; standard C dereference syntax as well as through the property ""dot"" syntax, but; there is no entry in the ``@interface`` declaration corresponding to this ivar. To facilitate debugging, these properties we will add a new DWARF TAG into the; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:50486,Integrability,interface,interface,50486," features to declare a property and; to let compiler synthesize accessor methods. The debugger lets developer inspect Objective C interfaces and their instance; variables and class variables. However, the debugger does not know anything; about the properties defined in Objective C interfaces. The debugger consumes; information generated by compiler in DWARF format. The format does not support; encoding of Objective C properties. This proposal describes DWARF extensions to; encode Objective C properties, which the debugger can use to let developers; inspect Objective C properties. Proposal; ^^^^^^^^. Objective C properties exist separately from class members. A property can be; defined only by ""setter"" and ""getter"" selectors, and be calculated anew on each; access. Or a property can just be a direct access to some declared ivar.; Finally it can have an ivar ""automatically synthesized"" for it by the compiler,; in which case the property can be referred to in user code directly using the; standard C dereference syntax as well as through the property ""dot"" syntax, but; there is no entry in the ``@interface`` declaration corresponding to this ivar. To facilitate debugging, these properties we will add a new DWARF TAG into the; ``DW_TAG_structure_type`` definition for the class to hold the description of a; given property, and a set of DWARF attributes that provide said description.; The property tag will also contain the name and declared type of the property. If there is a related ivar, there will also be a DWARF property attribute placed; in the ``DW_TAG_member`` DIE for that ivar referring back to the property TAG; for that property. And in the case where the compiler synthesizes the ivar; directly, the compiler is expected to generate a ``DW_TAG_member`` for that; ivar (with the ``DW_AT_artificial`` set to 1), whose name will be the name used; to access this ivar directly in code, and with the property attribute pointing; back to the property it is backing. The follo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:51461,Integrability,interface,interface,51461,"ry in the ``@interface`` declaration corresponding to this ivar. To facilitate debugging, these properties we will add a new DWARF TAG into the; ``DW_TAG_structure_type`` definition for the class to hold the description of a; given property, and a set of DWARF attributes that provide said description.; The property tag will also contain the name and declared type of the property. If there is a related ivar, there will also be a DWARF property attribute placed; in the ``DW_TAG_member`` DIE for that ivar referring back to the property TAG; for that property. And in the case where the compiler synthesizes the ivar; directly, the compiler is expected to generate a ``DW_TAG_member`` for that; ivar (with the ``DW_AT_artificial`` set to 1), whose name will be the name used; to access this ivar directly in code, and with the property attribute pointing; back to the property it is backing. The following examples will serve as illustration for our discussion:. .. code-block:: objc. @interface I1 {; int n2;; }. @property int p1;; @property int p2;; @end. @implementation I1; @synthesize p1;; @synthesize p2 = n2;; @end. This produces the following DWARF (this is a ""pseudo dwarfdump"" output):. .. code-block:: none. 0x00000100: TAG_structure_type [7] *; AT_APPLE_runtime_class( 0x10 ); AT_name( ""I1"" ); AT_decl_file( ""Objc_Property.m"" ); AT_decl_line( 3 ). 0x00000110 TAG_APPLE_property; AT_name ( ""p1"" ); AT_type ( {0x00000150} ( int ) ). 0x00000120: TAG_APPLE_property; AT_name ( ""p2"" ); AT_type ( {0x00000150} ( int ) ). 0x00000130: TAG_member [8]; AT_name( ""_p1"" ); AT_APPLE_property ( {0x00000110} ""p1"" ); AT_type( {0x00000150} ( int ) ); AT_artificial ( 0x1 ). 0x00000140: TAG_member [8]; AT_name( ""n2"" ); AT_APPLE_property ( {0x00000120} ""p2"" ); AT_type( {0x00000150} ( int ) ). 0x00000150: AT_type( ( int ) ). Note, the current convention is that the name of the ivar for an; auto-synthesized property is the name of the property from which it derives; with an underscore prepended, as is",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:52686,Integrability,interface,interface,52686,""" output):. .. code-block:: none. 0x00000100: TAG_structure_type [7] *; AT_APPLE_runtime_class( 0x10 ); AT_name( ""I1"" ); AT_decl_file( ""Objc_Property.m"" ); AT_decl_line( 3 ). 0x00000110 TAG_APPLE_property; AT_name ( ""p1"" ); AT_type ( {0x00000150} ( int ) ). 0x00000120: TAG_APPLE_property; AT_name ( ""p2"" ); AT_type ( {0x00000150} ( int ) ). 0x00000130: TAG_member [8]; AT_name( ""_p1"" ); AT_APPLE_property ( {0x00000110} ""p1"" ); AT_type( {0x00000150} ( int ) ); AT_artificial ( 0x1 ). 0x00000140: TAG_member [8]; AT_name( ""n2"" ); AT_APPLE_property ( {0x00000120} ""p2"" ); AT_type( {0x00000150} ( int ) ). 0x00000150: AT_type( ( int ) ). Note, the current convention is that the name of the ivar for an; auto-synthesized property is the name of the property from which it derives; with an underscore prepended, as is shown in the example. But we actually; don't need to know this convention, since we are given the name of the ivar; directly. Also, it is common practice in ObjC to have different property declarations in; the @interface and @implementation - e.g. to provide a read-only property in; the interface, and a read-write interface in the implementation. In that case,; the compiler should emit whichever property declaration will be in force in the; current translation unit. Developers can decorate a property with attributes which are encoded using; ``DW_AT_APPLE_property_attribute``. .. code-block:: objc. @property (readonly, nonatomic) int pr;. .. code-block:: none. TAG_APPLE_property [8]; AT_name( ""pr"" ); AT_type ( {0x00000147} (int) ); AT_APPLE_property_attribute (DW_APPLE_PROPERTY_readonly, DW_APPLE_PROPERTY_nonatomic). The setter and getter method names are attached to the property using; ``DW_AT_APPLE_property_setter`` and ``DW_AT_APPLE_property_getter`` attributes. .. code-block:: objc. @interface I1; @property (setter=myOwnP3Setter:) int p3;; -(void)myOwnP3Setter:(int)a;; @end. @implementation I1; @synthesize p3;; -(void)myOwnP3Setter:(int)a{ }; @end. The DWARF for t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:52763,Integrability,interface,interface,52763," ""I1"" ); AT_decl_file( ""Objc_Property.m"" ); AT_decl_line( 3 ). 0x00000110 TAG_APPLE_property; AT_name ( ""p1"" ); AT_type ( {0x00000150} ( int ) ). 0x00000120: TAG_APPLE_property; AT_name ( ""p2"" ); AT_type ( {0x00000150} ( int ) ). 0x00000130: TAG_member [8]; AT_name( ""_p1"" ); AT_APPLE_property ( {0x00000110} ""p1"" ); AT_type( {0x00000150} ( int ) ); AT_artificial ( 0x1 ). 0x00000140: TAG_member [8]; AT_name( ""n2"" ); AT_APPLE_property ( {0x00000120} ""p2"" ); AT_type( {0x00000150} ( int ) ). 0x00000150: AT_type( ( int ) ). Note, the current convention is that the name of the ivar for an; auto-synthesized property is the name of the property from which it derives; with an underscore prepended, as is shown in the example. But we actually; don't need to know this convention, since we are given the name of the ivar; directly. Also, it is common practice in ObjC to have different property declarations in; the @interface and @implementation - e.g. to provide a read-only property in; the interface, and a read-write interface in the implementation. In that case,; the compiler should emit whichever property declaration will be in force in the; current translation unit. Developers can decorate a property with attributes which are encoded using; ``DW_AT_APPLE_property_attribute``. .. code-block:: objc. @property (readonly, nonatomic) int pr;. .. code-block:: none. TAG_APPLE_property [8]; AT_name( ""pr"" ); AT_type ( {0x00000147} (int) ); AT_APPLE_property_attribute (DW_APPLE_PROPERTY_readonly, DW_APPLE_PROPERTY_nonatomic). The setter and getter method names are attached to the property using; ``DW_AT_APPLE_property_setter`` and ``DW_AT_APPLE_property_getter`` attributes. .. code-block:: objc. @interface I1; @property (setter=myOwnP3Setter:) int p3;; -(void)myOwnP3Setter:(int)a;; @end. @implementation I1; @synthesize p3;; -(void)myOwnP3Setter:(int)a{ }; @end. The DWARF for this would be:. .. code-block:: none. 0x000003bd: TAG_structure_type [7] *; AT_APPLE_runtime_class( 0x10 ); AT_nam",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:52791,Integrability,interface,interface,52791," ""I1"" ); AT_decl_file( ""Objc_Property.m"" ); AT_decl_line( 3 ). 0x00000110 TAG_APPLE_property; AT_name ( ""p1"" ); AT_type ( {0x00000150} ( int ) ). 0x00000120: TAG_APPLE_property; AT_name ( ""p2"" ); AT_type ( {0x00000150} ( int ) ). 0x00000130: TAG_member [8]; AT_name( ""_p1"" ); AT_APPLE_property ( {0x00000110} ""p1"" ); AT_type( {0x00000150} ( int ) ); AT_artificial ( 0x1 ). 0x00000140: TAG_member [8]; AT_name( ""n2"" ); AT_APPLE_property ( {0x00000120} ""p2"" ); AT_type( {0x00000150} ( int ) ). 0x00000150: AT_type( ( int ) ). Note, the current convention is that the name of the ivar for an; auto-synthesized property is the name of the property from which it derives; with an underscore prepended, as is shown in the example. But we actually; don't need to know this convention, since we are given the name of the ivar; directly. Also, it is common practice in ObjC to have different property declarations in; the @interface and @implementation - e.g. to provide a read-only property in; the interface, and a read-write interface in the implementation. In that case,; the compiler should emit whichever property declaration will be in force in the; current translation unit. Developers can decorate a property with attributes which are encoded using; ``DW_AT_APPLE_property_attribute``. .. code-block:: objc. @property (readonly, nonatomic) int pr;. .. code-block:: none. TAG_APPLE_property [8]; AT_name( ""pr"" ); AT_type ( {0x00000147} (int) ); AT_APPLE_property_attribute (DW_APPLE_PROPERTY_readonly, DW_APPLE_PROPERTY_nonatomic). The setter and getter method names are attached to the property using; ``DW_AT_APPLE_property_setter`` and ``DW_AT_APPLE_property_getter`` attributes. .. code-block:: objc. @interface I1; @property (setter=myOwnP3Setter:) int p3;; -(void)myOwnP3Setter:(int)a;; @end. @implementation I1; @synthesize p3;; -(void)myOwnP3Setter:(int)a{ }; @end. The DWARF for this would be:. .. code-block:: none. 0x000003bd: TAG_structure_type [7] *; AT_APPLE_runtime_class( 0x10 ); AT_nam",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:53477,Integrability,interface,interface,53477,"ed to know this convention, since we are given the name of the ivar; directly. Also, it is common practice in ObjC to have different property declarations in; the @interface and @implementation - e.g. to provide a read-only property in; the interface, and a read-write interface in the implementation. In that case,; the compiler should emit whichever property declaration will be in force in the; current translation unit. Developers can decorate a property with attributes which are encoded using; ``DW_AT_APPLE_property_attribute``. .. code-block:: objc. @property (readonly, nonatomic) int pr;. .. code-block:: none. TAG_APPLE_property [8]; AT_name( ""pr"" ); AT_type ( {0x00000147} (int) ); AT_APPLE_property_attribute (DW_APPLE_PROPERTY_readonly, DW_APPLE_PROPERTY_nonatomic). The setter and getter method names are attached to the property using; ``DW_AT_APPLE_property_setter`` and ``DW_AT_APPLE_property_getter`` attributes. .. code-block:: objc. @interface I1; @property (setter=myOwnP3Setter:) int p3;; -(void)myOwnP3Setter:(int)a;; @end. @implementation I1; @synthesize p3;; -(void)myOwnP3Setter:(int)a{ }; @end. The DWARF for this would be:. .. code-block:: none. 0x000003bd: TAG_structure_type [7] *; AT_APPLE_runtime_class( 0x10 ); AT_name( ""I1"" ); AT_decl_file( ""Objc_Property.m"" ); AT_decl_line( 3 ). 0x000003cd TAG_APPLE_property; AT_name ( ""p3"" ); AT_APPLE_property_setter ( ""myOwnP3Setter:"" ); AT_type( {0x00000147} ( int ) ). 0x000003f3: TAG_member [8]; AT_name( ""_p3"" ); AT_type ( {0x00000147} ( int ) ); AT_APPLE_property ( {0x000003cd} ); AT_artificial ( 0x1 ). New DWARF Tags; ^^^^^^^^^^^^^^. +-----------------------+--------+; | TAG | Value |; +=======================+========+; | DW_TAG_APPLE_property | 0x4200 |; +-----------------------+--------+. New DWARF Attributes; ^^^^^^^^^^^^^^^^^^^^. +--------------------------------+--------+-----------+; | Attribute | Value | Classes |; +================================+========+===========+; | DW_AT_APPLE_property | 0x3fed ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:4386,Modifiability,variab,variables,4386,"to other target; debug info formats such as STABS. It would also be reasonable to use debug information to feed profiling tools; for analysis of generated code, or, tools for reconstructing the original; source from generated code. .. _intro_debugopt:. Debug information and optimizations; -----------------------------------. An extremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a pro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:6827,Modifiability,variab,variables,6827,"-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids duplicated debugging information from; the beginning, and the global dead code elimination pass automatically deletes; debugging information for a function if it decides to delete the function. To do this, most of the debugging information (descriptors for types,; variables, functions, source files, etc) is inserted by the language front-end; in the form of LLVM metadata. Debug information is designed to be agnostic about the target debugger and; debugging information representation (e.g. DWARF/Stabs/etc). It uses a generic; pass to decode the information that represents variables, types, functions,; namespaces, etc: this allows for arbitrary source-language semantics and; type-systems to be used, as long as there is a module written for the target; debugger to interpret the information. To provide basic functionality, the LLVM debugger does have to make some; assumptions about the source-level language being debugged, though it keeps; these to a minimum. The only common features that the LLVM debugger assumes; exist are `source files <LangRef.html#difile>`_, and `program objects; <LangRef.html#diglobalvariable>`_. These abstract objects are used by a; debugger to form stack traces, show information about local variables, etc. This section of the documentation fir",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:7140,Modifiability,variab,variables,7140,"ious tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids duplicated debugging information from; the beginning, and the global dead code elimination pass automatically deletes; debugging information for a function if it decides to delete the function. To do this, most of the debugging information (descriptors for types,; variables, functions, source files, etc) is inserted by the language front-end; in the form of LLVM metadata. Debug information is designed to be agnostic about the target debugger and; debugging information representation (e.g. DWARF/Stabs/etc). It uses a generic; pass to decode the information that represents variables, types, functions,; namespaces, etc: this allows for arbitrary source-language semantics and; type-systems to be used, as long as there is a module written for the target; debugger to interpret the information. To provide basic functionality, the LLVM debugger does have to make some; assumptions about the source-level language being debugged, though it keeps; these to a minimum. The only common features that the LLVM debugger assumes; exist are `source files <LangRef.html#difile>`_, and `program objects; <LangRef.html#diglobalvariable>`_. These abstract objects are used by a; debugger to form stack traces, show information about local variables, etc. This section of the documentation first describes the representation aspects; common to any source-language. :ref:`ccxx_frontend` describes the data layout; conventions used by the C and C++ front-ends. Debug information descriptors are `specialized metadata nodes; <LangRef.html#specialized-metadata>`_, first-class subclasses of ``Metadata``. .. _format_common_intrinsics:. Debugger intrinsic functions; --",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:7793,Modifiability,variab,variables,7793,"ion. To do this, most of the debugging information (descriptors for types,; variables, functions, source files, etc) is inserted by the language front-end; in the form of LLVM metadata. Debug information is designed to be agnostic about the target debugger and; debugging information representation (e.g. DWARF/Stabs/etc). It uses a generic; pass to decode the information that represents variables, types, functions,; namespaces, etc: this allows for arbitrary source-language semantics and; type-systems to be used, as long as there is a module written for the target; debugger to interpret the information. To provide basic functionality, the LLVM debugger does have to make some; assumptions about the source-level language being debugged, though it keeps; these to a minimum. The only common features that the LLVM debugger assumes; exist are `source files <LangRef.html#difile>`_, and `program objects; <LangRef.html#diglobalvariable>`_. These abstract objects are used by a; debugger to form stack traces, show information about local variables, etc. This section of the documentation first describes the representation aspects; common to any source-language. :ref:`ccxx_frontend` describes the data layout; conventions used by the C and C++ front-ends. Debug information descriptors are `specialized metadata nodes; <LangRef.html#specialized-metadata>`_, first-class subclasses of ``Metadata``. .. _format_common_intrinsics:. Debugger intrinsic functions; ----------------------------. LLVM uses several intrinsic functions (name prefixed with ""``llvm.dbg``"") to; track source local variables through optimization and code generation. ``llvm.dbg.declare``; ^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.declare(metadata, metadata, metadata). This intrinsic provides information about a local element (e.g., variable).; The first argument is metadata holding the address of variable, typically a; static alloca in the function entry block. The second argument is a; `local variabl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:8342,Modifiability,variab,variables,8342,"rmation. To provide basic functionality, the LLVM debugger does have to make some; assumptions about the source-level language being debugged, though it keeps; these to a minimum. The only common features that the LLVM debugger assumes; exist are `source files <LangRef.html#difile>`_, and `program objects; <LangRef.html#diglobalvariable>`_. These abstract objects are used by a; debugger to form stack traces, show information about local variables, etc. This section of the documentation first describes the representation aspects; common to any source-language. :ref:`ccxx_frontend` describes the data layout; conventions used by the C and C++ front-ends. Debug information descriptors are `specialized metadata nodes; <LangRef.html#specialized-metadata>`_, first-class subclasses of ``Metadata``. .. _format_common_intrinsics:. Debugger intrinsic functions; ----------------------------. LLVM uses several intrinsic functions (name prefixed with ""``llvm.dbg``"") to; track source local variables through optimization and code generation. ``llvm.dbg.declare``; ^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.declare(metadata, metadata, metadata). This intrinsic provides information about a local element (e.g., variable).; The first argument is metadata holding the address of variable, typically a; static alloca in the function entry block. The second argument is a; `local variable <LangRef.html#dilocalvariable>`_ containing a description of; the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.declare` intrinsic describes the; *address* of a source variable. .. code-block:: text. %i.addr = alloca i32, align 4; call void @llvm.dbg.declare(metadata i32* %i.addr, metadata !1,; metadata !DIExpression()), !dbg !2; !1 = !DILocalVariable(name: ""i"", ...) ; int i; !2 = !DILocation(...); ...; %buffer = alloca [256 x i8], align 8; ; The address of i is buffer+64.; call void @llvm.dbg.declare(metadata [256 x i8]* %buffer, metadata ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:8579,Modifiability,variab,variable,8579,"umes; exist are `source files <LangRef.html#difile>`_, and `program objects; <LangRef.html#diglobalvariable>`_. These abstract objects are used by a; debugger to form stack traces, show information about local variables, etc. This section of the documentation first describes the representation aspects; common to any source-language. :ref:`ccxx_frontend` describes the data layout; conventions used by the C and C++ front-ends. Debug information descriptors are `specialized metadata nodes; <LangRef.html#specialized-metadata>`_, first-class subclasses of ``Metadata``. .. _format_common_intrinsics:. Debugger intrinsic functions; ----------------------------. LLVM uses several intrinsic functions (name prefixed with ""``llvm.dbg``"") to; track source local variables through optimization and code generation. ``llvm.dbg.declare``; ^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.declare(metadata, metadata, metadata). This intrinsic provides information about a local element (e.g., variable).; The first argument is metadata holding the address of variable, typically a; static alloca in the function entry block. The second argument is a; `local variable <LangRef.html#dilocalvariable>`_ containing a description of; the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.declare` intrinsic describes the; *address* of a source variable. .. code-block:: text. %i.addr = alloca i32, align 4; call void @llvm.dbg.declare(metadata i32* %i.addr, metadata !1,; metadata !DIExpression()), !dbg !2; !1 = !DILocalVariable(name: ""i"", ...) ; int i; !2 = !DILocation(...); ...; %buffer = alloca [256 x i8], align 8; ; The address of i is buffer+64.; call void @llvm.dbg.declare(metadata [256 x i8]* %buffer, metadata !3,; metadata !DIExpression(DW_OP_plus, 64)), !dbg !4; !3 = !DILocalVariable(name: ""i"", ...) ; int i; !4 = !DILocation(...). A frontend should generate exactly one call to ``llvm.dbg.declare`` at the point; of declaration of a sour",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:8645,Modifiability,variab,variable,8645,"m objects; <LangRef.html#diglobalvariable>`_. These abstract objects are used by a; debugger to form stack traces, show information about local variables, etc. This section of the documentation first describes the representation aspects; common to any source-language. :ref:`ccxx_frontend` describes the data layout; conventions used by the C and C++ front-ends. Debug information descriptors are `specialized metadata nodes; <LangRef.html#specialized-metadata>`_, first-class subclasses of ``Metadata``. .. _format_common_intrinsics:. Debugger intrinsic functions; ----------------------------. LLVM uses several intrinsic functions (name prefixed with ""``llvm.dbg``"") to; track source local variables through optimization and code generation. ``llvm.dbg.declare``; ^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.declare(metadata, metadata, metadata). This intrinsic provides information about a local element (e.g., variable).; The first argument is metadata holding the address of variable, typically a; static alloca in the function entry block. The second argument is a; `local variable <LangRef.html#dilocalvariable>`_ containing a description of; the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.declare` intrinsic describes the; *address* of a source variable. .. code-block:: text. %i.addr = alloca i32, align 4; call void @llvm.dbg.declare(metadata i32* %i.addr, metadata !1,; metadata !DIExpression()), !dbg !2; !1 = !DILocalVariable(name: ""i"", ...) ; int i; !2 = !DILocation(...); ...; %buffer = alloca [256 x i8], align 8; ; The address of i is buffer+64.; call void @llvm.dbg.declare(metadata [256 x i8]* %buffer, metadata !3,; metadata !DIExpression(DW_OP_plus, 64)), !dbg !4; !3 = !DILocalVariable(name: ""i"", ...) ; int i; !4 = !DILocation(...). A frontend should generate exactly one call to ``llvm.dbg.declare`` at the point; of declaration of a source variable. Optimization passes that fully promote the; variable f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:8744,Modifiability,variab,variable,8744,"ugger to form stack traces, show information about local variables, etc. This section of the documentation first describes the representation aspects; common to any source-language. :ref:`ccxx_frontend` describes the data layout; conventions used by the C and C++ front-ends. Debug information descriptors are `specialized metadata nodes; <LangRef.html#specialized-metadata>`_, first-class subclasses of ``Metadata``. .. _format_common_intrinsics:. Debugger intrinsic functions; ----------------------------. LLVM uses several intrinsic functions (name prefixed with ""``llvm.dbg``"") to; track source local variables through optimization and code generation. ``llvm.dbg.declare``; ^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.declare(metadata, metadata, metadata). This intrinsic provides information about a local element (e.g., variable).; The first argument is metadata holding the address of variable, typically a; static alloca in the function entry block. The second argument is a; `local variable <LangRef.html#dilocalvariable>`_ containing a description of; the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.declare` intrinsic describes the; *address* of a source variable. .. code-block:: text. %i.addr = alloca i32, align 4; call void @llvm.dbg.declare(metadata i32* %i.addr, metadata !1,; metadata !DIExpression()), !dbg !2; !1 = !DILocalVariable(name: ""i"", ...) ; int i; !2 = !DILocation(...); ...; %buffer = alloca [256 x i8], align 8; ; The address of i is buffer+64.; call void @llvm.dbg.declare(metadata [256 x i8]* %buffer, metadata !3,; metadata !DIExpression(DW_OP_plus, 64)), !dbg !4; !3 = !DILocalVariable(name: ""i"", ...) ; int i; !4 = !DILocation(...). A frontend should generate exactly one call to ``llvm.dbg.declare`` at the point; of declaration of a source variable. Optimization passes that fully promote the; variable from memory to SSA values will replace this call with possibly multiple; calls to `llvm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:8819,Modifiability,variab,variable,8819,"riables, etc. This section of the documentation first describes the representation aspects; common to any source-language. :ref:`ccxx_frontend` describes the data layout; conventions used by the C and C++ front-ends. Debug information descriptors are `specialized metadata nodes; <LangRef.html#specialized-metadata>`_, first-class subclasses of ``Metadata``. .. _format_common_intrinsics:. Debugger intrinsic functions; ----------------------------. LLVM uses several intrinsic functions (name prefixed with ""``llvm.dbg``"") to; track source local variables through optimization and code generation. ``llvm.dbg.declare``; ^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.declare(metadata, metadata, metadata). This intrinsic provides information about a local element (e.g., variable).; The first argument is metadata holding the address of variable, typically a; static alloca in the function entry block. The second argument is a; `local variable <LangRef.html#dilocalvariable>`_ containing a description of; the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.declare` intrinsic describes the; *address* of a source variable. .. code-block:: text. %i.addr = alloca i32, align 4; call void @llvm.dbg.declare(metadata i32* %i.addr, metadata !1,; metadata !DIExpression()), !dbg !2; !1 = !DILocalVariable(name: ""i"", ...) ; int i; !2 = !DILocation(...); ...; %buffer = alloca [256 x i8], align 8; ; The address of i is buffer+64.; call void @llvm.dbg.declare(metadata [256 x i8]* %buffer, metadata !3,; metadata !DIExpression(DW_OP_plus, 64)), !dbg !4; !3 = !DILocalVariable(name: ""i"", ...) ; int i; !4 = !DILocation(...). A frontend should generate exactly one call to ``llvm.dbg.declare`` at the point; of declaration of a source variable. Optimization passes that fully promote the; variable from memory to SSA values will replace this call with possibly multiple; calls to `llvm.dbg.value`. Passes that delete stores are effectively part",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:8974,Modifiability,variab,variable,8974,"he data layout; conventions used by the C and C++ front-ends. Debug information descriptors are `specialized metadata nodes; <LangRef.html#specialized-metadata>`_, first-class subclasses of ``Metadata``. .. _format_common_intrinsics:. Debugger intrinsic functions; ----------------------------. LLVM uses several intrinsic functions (name prefixed with ""``llvm.dbg``"") to; track source local variables through optimization and code generation. ``llvm.dbg.declare``; ^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.declare(metadata, metadata, metadata). This intrinsic provides information about a local element (e.g., variable).; The first argument is metadata holding the address of variable, typically a; static alloca in the function entry block. The second argument is a; `local variable <LangRef.html#dilocalvariable>`_ containing a description of; the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.declare` intrinsic describes the; *address* of a source variable. .. code-block:: text. %i.addr = alloca i32, align 4; call void @llvm.dbg.declare(metadata i32* %i.addr, metadata !1,; metadata !DIExpression()), !dbg !2; !1 = !DILocalVariable(name: ""i"", ...) ; int i; !2 = !DILocation(...); ...; %buffer = alloca [256 x i8], align 8; ; The address of i is buffer+64.; call void @llvm.dbg.declare(metadata [256 x i8]* %buffer, metadata !3,; metadata !DIExpression(DW_OP_plus, 64)), !dbg !4; !3 = !DILocalVariable(name: ""i"", ...) ; int i; !4 = !DILocation(...). A frontend should generate exactly one call to ``llvm.dbg.declare`` at the point; of declaration of a source variable. Optimization passes that fully promote the; variable from memory to SSA values will replace this call with possibly multiple; calls to `llvm.dbg.value`. Passes that delete stores are effectively partial; promotion, and they will insert a mix of calls to ``llvm.dbg.value`` to track; the source variable value when it is available. After optimization, ther",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:9586,Modifiability,variab,variable,9586,"lement (e.g., variable).; The first argument is metadata holding the address of variable, typically a; static alloca in the function entry block. The second argument is a; `local variable <LangRef.html#dilocalvariable>`_ containing a description of; the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.declare` intrinsic describes the; *address* of a source variable. .. code-block:: text. %i.addr = alloca i32, align 4; call void @llvm.dbg.declare(metadata i32* %i.addr, metadata !1,; metadata !DIExpression()), !dbg !2; !1 = !DILocalVariable(name: ""i"", ...) ; int i; !2 = !DILocation(...); ...; %buffer = alloca [256 x i8], align 8; ; The address of i is buffer+64.; call void @llvm.dbg.declare(metadata [256 x i8]* %buffer, metadata !3,; metadata !DIExpression(DW_OP_plus, 64)), !dbg !4; !3 = !DILocalVariable(name: ""i"", ...) ; int i; !4 = !DILocation(...). A frontend should generate exactly one call to ``llvm.dbg.declare`` at the point; of declaration of a source variable. Optimization passes that fully promote the; variable from memory to SSA values will replace this call with possibly multiple; calls to `llvm.dbg.value`. Passes that delete stores are effectively partial; promotion, and they will insert a mix of calls to ``llvm.dbg.value`` to track; the source variable value when it is available. After optimization, there may be; multiple calls to ``llvm.dbg.declare`` describing the program points where the; variables lives in memory. All calls for the same concrete source variable must; agree on the memory location. ``llvm.dbg.value``; ^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.value(metadata, metadata, metadata). This intrinsic provides information when a user source variable is set to a new; value. The first argument is the new value (wrapped as metadata). The second; argument is a `local variable <LangRef.html#dilocalvariable>`_ containing a; description of the variable. The third argument is a `complex e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:9640,Modifiability,variab,variable,9640,"; static alloca in the function entry block. The second argument is a; `local variable <LangRef.html#dilocalvariable>`_ containing a description of; the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.declare` intrinsic describes the; *address* of a source variable. .. code-block:: text. %i.addr = alloca i32, align 4; call void @llvm.dbg.declare(metadata i32* %i.addr, metadata !1,; metadata !DIExpression()), !dbg !2; !1 = !DILocalVariable(name: ""i"", ...) ; int i; !2 = !DILocation(...); ...; %buffer = alloca [256 x i8], align 8; ; The address of i is buffer+64.; call void @llvm.dbg.declare(metadata [256 x i8]* %buffer, metadata !3,; metadata !DIExpression(DW_OP_plus, 64)), !dbg !4; !3 = !DILocalVariable(name: ""i"", ...) ; int i; !4 = !DILocation(...). A frontend should generate exactly one call to ``llvm.dbg.declare`` at the point; of declaration of a source variable. Optimization passes that fully promote the; variable from memory to SSA values will replace this call with possibly multiple; calls to `llvm.dbg.value`. Passes that delete stores are effectively partial; promotion, and they will insert a mix of calls to ``llvm.dbg.value`` to track; the source variable value when it is available. After optimization, there may be; multiple calls to ``llvm.dbg.declare`` describing the program points where the; variables lives in memory. All calls for the same concrete source variable must; agree on the memory location. ``llvm.dbg.value``; ^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.value(metadata, metadata, metadata). This intrinsic provides information when a user source variable is set to a new; value. The first argument is the new value (wrapped as metadata). The second; argument is a `local variable <LangRef.html#dilocalvariable>`_ containing a; description of the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.value` intrinsic describes the *value* of a so",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:9890,Modifiability,variab,variable,9890,"ression>`_. An `llvm.dbg.declare` intrinsic describes the; *address* of a source variable. .. code-block:: text. %i.addr = alloca i32, align 4; call void @llvm.dbg.declare(metadata i32* %i.addr, metadata !1,; metadata !DIExpression()), !dbg !2; !1 = !DILocalVariable(name: ""i"", ...) ; int i; !2 = !DILocation(...); ...; %buffer = alloca [256 x i8], align 8; ; The address of i is buffer+64.; call void @llvm.dbg.declare(metadata [256 x i8]* %buffer, metadata !3,; metadata !DIExpression(DW_OP_plus, 64)), !dbg !4; !3 = !DILocalVariable(name: ""i"", ...) ; int i; !4 = !DILocation(...). A frontend should generate exactly one call to ``llvm.dbg.declare`` at the point; of declaration of a source variable. Optimization passes that fully promote the; variable from memory to SSA values will replace this call with possibly multiple; calls to `llvm.dbg.value`. Passes that delete stores are effectively partial; promotion, and they will insert a mix of calls to ``llvm.dbg.value`` to track; the source variable value when it is available. After optimization, there may be; multiple calls to ``llvm.dbg.declare`` describing the program points where the; variables lives in memory. All calls for the same concrete source variable must; agree on the memory location. ``llvm.dbg.value``; ^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.value(metadata, metadata, metadata). This intrinsic provides information when a user source variable is set to a new; value. The first argument is the new value (wrapped as metadata). The second; argument is a `local variable <LangRef.html#dilocalvariable>`_ containing a; description of the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.value` intrinsic describes the *value* of a source variable; directly, not its address. Note that the value operand of this intrinsic may; be indirect (i.e, a pointer to the source variable), provided that interpreting; the complex expression derives the direct value. ``llv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:10041,Modifiability,variab,variables,10041,"align 4; call void @llvm.dbg.declare(metadata i32* %i.addr, metadata !1,; metadata !DIExpression()), !dbg !2; !1 = !DILocalVariable(name: ""i"", ...) ; int i; !2 = !DILocation(...); ...; %buffer = alloca [256 x i8], align 8; ; The address of i is buffer+64.; call void @llvm.dbg.declare(metadata [256 x i8]* %buffer, metadata !3,; metadata !DIExpression(DW_OP_plus, 64)), !dbg !4; !3 = !DILocalVariable(name: ""i"", ...) ; int i; !4 = !DILocation(...). A frontend should generate exactly one call to ``llvm.dbg.declare`` at the point; of declaration of a source variable. Optimization passes that fully promote the; variable from memory to SSA values will replace this call with possibly multiple; calls to `llvm.dbg.value`. Passes that delete stores are effectively partial; promotion, and they will insert a mix of calls to ``llvm.dbg.value`` to track; the source variable value when it is available. After optimization, there may be; multiple calls to ``llvm.dbg.declare`` describing the program points where the; variables lives in memory. All calls for the same concrete source variable must; agree on the memory location. ``llvm.dbg.value``; ^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.value(metadata, metadata, metadata). This intrinsic provides information when a user source variable is set to a new; value. The first argument is the new value (wrapped as metadata). The second; argument is a `local variable <LangRef.html#dilocalvariable>`_ containing a; description of the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.value` intrinsic describes the *value* of a source variable; directly, not its address. Note that the value operand of this intrinsic may; be indirect (i.e, a pointer to the source variable), provided that interpreting; the complex expression derives the direct value. ``llvm.dbg.assign``; ^^^^^^^^^^^^^^^^^^^; .. toctree::; :hidden:. AssignmentTracking. .. code-block:: llvm. void @llvm.dbg.assign(Value *Val",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:10107,Modifiability,variab,variable,10107,"a !DIExpression()), !dbg !2; !1 = !DILocalVariable(name: ""i"", ...) ; int i; !2 = !DILocation(...); ...; %buffer = alloca [256 x i8], align 8; ; The address of i is buffer+64.; call void @llvm.dbg.declare(metadata [256 x i8]* %buffer, metadata !3,; metadata !DIExpression(DW_OP_plus, 64)), !dbg !4; !3 = !DILocalVariable(name: ""i"", ...) ; int i; !4 = !DILocation(...). A frontend should generate exactly one call to ``llvm.dbg.declare`` at the point; of declaration of a source variable. Optimization passes that fully promote the; variable from memory to SSA values will replace this call with possibly multiple; calls to `llvm.dbg.value`. Passes that delete stores are effectively partial; promotion, and they will insert a mix of calls to ``llvm.dbg.value`` to track; the source variable value when it is available. After optimization, there may be; multiple calls to ``llvm.dbg.declare`` describing the program points where the; variables lives in memory. All calls for the same concrete source variable must; agree on the memory location. ``llvm.dbg.value``; ^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.value(metadata, metadata, metadata). This intrinsic provides information when a user source variable is set to a new; value. The first argument is the new value (wrapped as metadata). The second; argument is a `local variable <LangRef.html#dilocalvariable>`_ containing a; description of the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.value` intrinsic describes the *value* of a source variable; directly, not its address. Note that the value operand of this intrinsic may; be indirect (i.e, a pointer to the source variable), provided that interpreting; the complex expression derives the direct value. ``llvm.dbg.assign``; ^^^^^^^^^^^^^^^^^^^; .. toctree::; :hidden:. AssignmentTracking. .. code-block:: llvm. void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:10321,Modifiability,variab,variable,10321,"are(metadata [256 x i8]* %buffer, metadata !3,; metadata !DIExpression(DW_OP_plus, 64)), !dbg !4; !3 = !DILocalVariable(name: ""i"", ...) ; int i; !4 = !DILocation(...). A frontend should generate exactly one call to ``llvm.dbg.declare`` at the point; of declaration of a source variable. Optimization passes that fully promote the; variable from memory to SSA values will replace this call with possibly multiple; calls to `llvm.dbg.value`. Passes that delete stores are effectively partial; promotion, and they will insert a mix of calls to ``llvm.dbg.value`` to track; the source variable value when it is available. After optimization, there may be; multiple calls to ``llvm.dbg.declare`` describing the program points where the; variables lives in memory. All calls for the same concrete source variable must; agree on the memory location. ``llvm.dbg.value``; ^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.value(metadata, metadata, metadata). This intrinsic provides information when a user source variable is set to a new; value. The first argument is the new value (wrapped as metadata). The second; argument is a `local variable <LangRef.html#dilocalvariable>`_ containing a; description of the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.value` intrinsic describes the *value* of a source variable; directly, not its address. Note that the value operand of this intrinsic may; be indirect (i.e, a pointer to the source variable), provided that interpreting; the complex expression derives the direct value. ``llvm.dbg.assign``; ^^^^^^^^^^^^^^^^^^^; .. toctree::; :hidden:. AssignmentTracking. .. code-block:: llvm. void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression). This intrinsic marks the position in IR where a source assignment occurred. It; encodes the value of the variable. It references the store, if any,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:10446,Modifiability,variab,variable,10446,", ...) ; int i; !4 = !DILocation(...). A frontend should generate exactly one call to ``llvm.dbg.declare`` at the point; of declaration of a source variable. Optimization passes that fully promote the; variable from memory to SSA values will replace this call with possibly multiple; calls to `llvm.dbg.value`. Passes that delete stores are effectively partial; promotion, and they will insert a mix of calls to ``llvm.dbg.value`` to track; the source variable value when it is available. After optimization, there may be; multiple calls to ``llvm.dbg.declare`` describing the program points where the; variables lives in memory. All calls for the same concrete source variable must; agree on the memory location. ``llvm.dbg.value``; ^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.value(metadata, metadata, metadata). This intrinsic provides information when a user source variable is set to a new; value. The first argument is the new value (wrapped as metadata). The second; argument is a `local variable <LangRef.html#dilocalvariable>`_ containing a; description of the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.value` intrinsic describes the *value* of a source variable; directly, not its address. Note that the value operand of this intrinsic may; be indirect (i.e, a pointer to the source variable), provided that interpreting; the complex expression derives the direct value. ``llvm.dbg.assign``; ^^^^^^^^^^^^^^^^^^^; .. toctree::; :hidden:. AssignmentTracking. .. code-block:: llvm. void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression). This intrinsic marks the position in IR where a source assignment occurred. It; encodes the value of the variable. It references the store, if any, that; performs the assignment, and the destination address. The first three arguments are the same as for an ``llvm.dbg.value``.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:10521,Modifiability,variab,variable,10521,"nerate exactly one call to ``llvm.dbg.declare`` at the point; of declaration of a source variable. Optimization passes that fully promote the; variable from memory to SSA values will replace this call with possibly multiple; calls to `llvm.dbg.value`. Passes that delete stores are effectively partial; promotion, and they will insert a mix of calls to ``llvm.dbg.value`` to track; the source variable value when it is available. After optimization, there may be; multiple calls to ``llvm.dbg.declare`` describing the program points where the; variables lives in memory. All calls for the same concrete source variable must; agree on the memory location. ``llvm.dbg.value``; ^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.value(metadata, metadata, metadata). This intrinsic provides information when a user source variable is set to a new; value. The first argument is the new value (wrapped as metadata). The second; argument is a `local variable <LangRef.html#dilocalvariable>`_ containing a; description of the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.value` intrinsic describes the *value* of a source variable; directly, not its address. Note that the value operand of this intrinsic may; be indirect (i.e, a pointer to the source variable), provided that interpreting; the complex expression derives the direct value. ``llvm.dbg.assign``; ^^^^^^^^^^^^^^^^^^^; .. toctree::; :hidden:. AssignmentTracking. .. code-block:: llvm. void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression). This intrinsic marks the position in IR where a source assignment occurred. It; encodes the value of the variable. It references the store, if any, that; performs the assignment, and the destination address. The first three arguments are the same as for an ``llvm.dbg.value``. The fourth; argument is a ``DIAssignID`` used to reference",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:10671,Modifiability,variab,variable,10671," SSA values will replace this call with possibly multiple; calls to `llvm.dbg.value`. Passes that delete stores are effectively partial; promotion, and they will insert a mix of calls to ``llvm.dbg.value`` to track; the source variable value when it is available. After optimization, there may be; multiple calls to ``llvm.dbg.declare`` describing the program points where the; variables lives in memory. All calls for the same concrete source variable must; agree on the memory location. ``llvm.dbg.value``; ^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.value(metadata, metadata, metadata). This intrinsic provides information when a user source variable is set to a new; value. The first argument is the new value (wrapped as metadata). The second; argument is a `local variable <LangRef.html#dilocalvariable>`_ containing a; description of the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.value` intrinsic describes the *value* of a source variable; directly, not its address. Note that the value operand of this intrinsic may; be indirect (i.e, a pointer to the source variable), provided that interpreting; the complex expression derives the direct value. ``llvm.dbg.assign``; ^^^^^^^^^^^^^^^^^^^; .. toctree::; :hidden:. AssignmentTracking. .. code-block:: llvm. void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression). This intrinsic marks the position in IR where a source assignment occurred. It; encodes the value of the variable. It references the store, if any, that; performs the assignment, and the destination address. The first three arguments are the same as for an ``llvm.dbg.value``. The fourth; argument is a ``DIAssignID`` used to reference a store. The fifth is the; destination of the store (wrapped as metadata), and the sixth is a `complex; expression <LangRef.html#diexpression>`_ that modifies it. The",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:10801,Modifiability,variab,variable,10801," a mix of calls to ``llvm.dbg.value`` to track; the source variable value when it is available. After optimization, there may be; multiple calls to ``llvm.dbg.declare`` describing the program points where the; variables lives in memory. All calls for the same concrete source variable must; agree on the memory location. ``llvm.dbg.value``; ^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.value(metadata, metadata, metadata). This intrinsic provides information when a user source variable is set to a new; value. The first argument is the new value (wrapped as metadata). The second; argument is a `local variable <LangRef.html#dilocalvariable>`_ containing a; description of the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.value` intrinsic describes the *value* of a source variable; directly, not its address. Note that the value operand of this intrinsic may; be indirect (i.e, a pointer to the source variable), provided that interpreting; the complex expression derives the direct value. ``llvm.dbg.assign``; ^^^^^^^^^^^^^^^^^^^; .. toctree::; :hidden:. AssignmentTracking. .. code-block:: llvm. void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression). This intrinsic marks the position in IR where a source assignment occurred. It; encodes the value of the variable. It references the store, if any, that; performs the assignment, and the destination address. The first three arguments are the same as for an ``llvm.dbg.value``. The fourth; argument is a ``DIAssignID`` used to reference a store. The fifth is the; destination of the store (wrapped as metadata), and the sixth is a `complex; expression <LangRef.html#diexpression>`_ that modifies it. The formal LLVM-IR signature is:. .. code-block:: llvm. void @llvm.dbg.assign(metadata, metadata, metadata, metadata, metadata, metadata). See :doc:`AssignmentTracking` f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:11267,Modifiability,variab,variable,11267,"etadata). This intrinsic provides information when a user source variable is set to a new; value. The first argument is the new value (wrapped as metadata). The second; argument is a `local variable <LangRef.html#dilocalvariable>`_ containing a; description of the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.value` intrinsic describes the *value* of a source variable; directly, not its address. Note that the value operand of this intrinsic may; be indirect (i.e, a pointer to the source variable), provided that interpreting; the complex expression derives the direct value. ``llvm.dbg.assign``; ^^^^^^^^^^^^^^^^^^^; .. toctree::; :hidden:. AssignmentTracking. .. code-block:: llvm. void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression). This intrinsic marks the position in IR where a source assignment occurred. It; encodes the value of the variable. It references the store, if any, that; performs the assignment, and the destination address. The first three arguments are the same as for an ``llvm.dbg.value``. The fourth; argument is a ``DIAssignID`` used to reference a store. The fifth is the; destination of the store (wrapped as metadata), and the sixth is a `complex; expression <LangRef.html#diexpression>`_ that modifies it. The formal LLVM-IR signature is:. .. code-block:: llvm. void @llvm.dbg.assign(metadata, metadata, metadata, metadata, metadata, metadata). See :doc:`AssignmentTracking` for more info. Object lifetimes and scoping; ============================. In many languages, the local variables in functions can have their lifetimes or; scopes limited to a subset of a function. In the C family of languages, for; example, variables are only live (readable and writable) within the source; block that they are defined in. In functional languages, values are only; readable after they have been defined. Thoug",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:11934,Modifiability,variab,variables,11934,"Tracking. .. code-block:: llvm. void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression). This intrinsic marks the position in IR where a source assignment occurred. It; encodes the value of the variable. It references the store, if any, that; performs the assignment, and the destination address. The first three arguments are the same as for an ``llvm.dbg.value``. The fourth; argument is a ``DIAssignID`` used to reference a store. The fifth is the; destination of the store (wrapped as metadata), and the sixth is a `complex; expression <LangRef.html#diexpression>`_ that modifies it. The formal LLVM-IR signature is:. .. code-block:: llvm. void @llvm.dbg.assign(metadata, metadata, metadata, metadata, metadata, metadata). See :doc:`AssignmentTracking` for more info. Object lifetimes and scoping; ============================. In many languages, the local variables in functions can have their lifetimes or; scopes limited to a subset of a function. In the C family of languages, for; example, variables are only live (readable and writable) within the source; block that they are defined in. In functional languages, values are only; readable after they have been defined. Though this is a very obvious concept,; it is non-trivial to model in LLVM, because it has no notion of scoping in this; sense, and does not want to be tied to a language's scoping rules. In order to handle this, the LLVM debug format uses the metadata attached to; llvm instructions to encode line number and scoping information. Consider the; following C fragment, for example:. .. code-block:: c. 1. void foo() {; 2. int X = 21;; 3. int Y = 22;; 4. {; 5. int Z = 23;; 6. Z = X;; 7. }; 8. X = Y;; 9. }. Compiled to LLVM, this function would be represented like this:. .. code-block:: text. ; Function Attrs: nounwind ssp uwtable; define void @foo() #0 !dbg !4 {; entry:; %X = alloca i32, align 4; %Y = alloca i32",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:12072,Modifiability,variab,variables,12072,"signID *ID,; Value *Address,; DIExpression *AddressExpression). This intrinsic marks the position in IR where a source assignment occurred. It; encodes the value of the variable. It references the store, if any, that; performs the assignment, and the destination address. The first three arguments are the same as for an ``llvm.dbg.value``. The fourth; argument is a ``DIAssignID`` used to reference a store. The fifth is the; destination of the store (wrapped as metadata), and the sixth is a `complex; expression <LangRef.html#diexpression>`_ that modifies it. The formal LLVM-IR signature is:. .. code-block:: llvm. void @llvm.dbg.assign(metadata, metadata, metadata, metadata, metadata, metadata). See :doc:`AssignmentTracking` for more info. Object lifetimes and scoping; ============================. In many languages, the local variables in functions can have their lifetimes or; scopes limited to a subset of a function. In the C family of languages, for; example, variables are only live (readable and writable) within the source; block that they are defined in. In functional languages, values are only; readable after they have been defined. Though this is a very obvious concept,; it is non-trivial to model in LLVM, because it has no notion of scoping in this; sense, and does not want to be tied to a language's scoping rules. In order to handle this, the LLVM debug format uses the metadata attached to; llvm instructions to encode line number and scoping information. Consider the; following C fragment, for example:. .. code-block:: c. 1. void foo() {; 2. int X = 21;; 3. int Y = 22;; 4. {; 5. int Z = 23;; 6. Z = X;; 7. }; 8. X = Y;; 9. }. Compiled to LLVM, this function would be represented like this:. .. code-block:: text. ; Function Attrs: nounwind ssp uwtable; define void @foo() #0 !dbg !4 {; entry:; %X = alloca i32, align 4; %Y = alloca i32, align 4; %Z = alloca i32, align 4; call void @llvm.dbg.declare(metadata i32* %X, metadata !11, metadata !13), !dbg !14; store i32 2",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:15920,Modifiability,variab,variable,15920,"ne: 2, type: !12); !12 = !DIBasicType(name: ""int"", size: 32, align: 32, encoding: DW_ATE_signed); !13 = !DIExpression(); !14 = !DILocation(line: 2, column: 9, scope: !4); !15 = !DILocalVariable(name: ""Y"", scope: !4, file: !1, line: 3, type: !12); !16 = !DILocation(line: 3, column: 9, scope: !4); !17 = !DILocalVariable(name: ""Z"", scope: !18, file: !1, line: 5, type: !12); !18 = distinct !DILexicalBlock(scope: !4, file: !1, line: 4, column: 5); !19 = !DILocation(line: 5, column: 11, scope: !18); !20 = !DILocation(line: 6, column: 11, scope: !18); !21 = !DILocation(line: 6, column: 9, scope: !18); !22 = !DILocation(line: 8, column: 9, scope: !4); !23 = !DILocation(line: 8, column: 7, scope: !4); !24 = !DILocation(line: 9, column: 3, scope: !4). This example illustrates a few important details about LLVM debugging; information. In particular, it shows how the ``llvm.dbg.declare`` intrinsic and; location information, which are attached to an instruction, are applied; together to allow a debugger to analyze the relationship between statements,; variable definitions, and the code used to implement the function. .. code-block:: llvm. call void @llvm.dbg.declare(metadata i32* %X, metadata !11, metadata !13), !dbg !14; ; [debug line = 2:7] [debug variable = X]. The first intrinsic ``%llvm.dbg.declare`` encodes debugging information for the; variable ``X``. The metadata ``!dbg !14`` attached to the intrinsic provides; scope information for the variable ``X``. .. code-block:: text. !14 = !DILocation(line: 2, column: 9, scope: !4); !4 = distinct !DISubprogram(name: ""foo"", scope: !1, file: !1, line: 1, type: !5,; isLocal: false, isDefinition: true, scopeLine: 1,; isOptimized: false, retainedNodes: !2). Here ``!14`` is metadata providing `location information; <LangRef.html#dilocation>`_. In this example, scope is encoded by ``!4``, a; `subprogram descriptor <LangRef.html#disubprogram>`_. This way the location; information attached to the intrinsics indicates that the variable ``X",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:16122,Modifiability,variab,variable,16122,"ile: !1, line: 3, type: !12); !16 = !DILocation(line: 3, column: 9, scope: !4); !17 = !DILocalVariable(name: ""Z"", scope: !18, file: !1, line: 5, type: !12); !18 = distinct !DILexicalBlock(scope: !4, file: !1, line: 4, column: 5); !19 = !DILocation(line: 5, column: 11, scope: !18); !20 = !DILocation(line: 6, column: 11, scope: !18); !21 = !DILocation(line: 6, column: 9, scope: !18); !22 = !DILocation(line: 8, column: 9, scope: !4); !23 = !DILocation(line: 8, column: 7, scope: !4); !24 = !DILocation(line: 9, column: 3, scope: !4). This example illustrates a few important details about LLVM debugging; information. In particular, it shows how the ``llvm.dbg.declare`` intrinsic and; location information, which are attached to an instruction, are applied; together to allow a debugger to analyze the relationship between statements,; variable definitions, and the code used to implement the function. .. code-block:: llvm. call void @llvm.dbg.declare(metadata i32* %X, metadata !11, metadata !13), !dbg !14; ; [debug line = 2:7] [debug variable = X]. The first intrinsic ``%llvm.dbg.declare`` encodes debugging information for the; variable ``X``. The metadata ``!dbg !14`` attached to the intrinsic provides; scope information for the variable ``X``. .. code-block:: text. !14 = !DILocation(line: 2, column: 9, scope: !4); !4 = distinct !DISubprogram(name: ""foo"", scope: !1, file: !1, line: 1, type: !5,; isLocal: false, isDefinition: true, scopeLine: 1,; isOptimized: false, retainedNodes: !2). Here ``!14`` is metadata providing `location information; <LangRef.html#dilocation>`_. In this example, scope is encoded by ``!4``, a; `subprogram descriptor <LangRef.html#disubprogram>`_. This way the location; information attached to the intrinsics indicates that the variable ``X`` is; declared at line number 2 at a function level scope in function ``foo``. Now lets take another example. .. code-block:: llvm. call void @llvm.dbg.declare(metadata i32* %Z, metadata !17, metadata !13), !dbg !19; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:16218,Modifiability,variab,variable,16218,": !18, file: !1, line: 5, type: !12); !18 = distinct !DILexicalBlock(scope: !4, file: !1, line: 4, column: 5); !19 = !DILocation(line: 5, column: 11, scope: !18); !20 = !DILocation(line: 6, column: 11, scope: !18); !21 = !DILocation(line: 6, column: 9, scope: !18); !22 = !DILocation(line: 8, column: 9, scope: !4); !23 = !DILocation(line: 8, column: 7, scope: !4); !24 = !DILocation(line: 9, column: 3, scope: !4). This example illustrates a few important details about LLVM debugging; information. In particular, it shows how the ``llvm.dbg.declare`` intrinsic and; location information, which are attached to an instruction, are applied; together to allow a debugger to analyze the relationship between statements,; variable definitions, and the code used to implement the function. .. code-block:: llvm. call void @llvm.dbg.declare(metadata i32* %X, metadata !11, metadata !13), !dbg !14; ; [debug line = 2:7] [debug variable = X]. The first intrinsic ``%llvm.dbg.declare`` encodes debugging information for the; variable ``X``. The metadata ``!dbg !14`` attached to the intrinsic provides; scope information for the variable ``X``. .. code-block:: text. !14 = !DILocation(line: 2, column: 9, scope: !4); !4 = distinct !DISubprogram(name: ""foo"", scope: !1, file: !1, line: 1, type: !5,; isLocal: false, isDefinition: true, scopeLine: 1,; isOptimized: false, retainedNodes: !2). Here ``!14`` is metadata providing `location information; <LangRef.html#dilocation>`_. In this example, scope is encoded by ``!4``, a; `subprogram descriptor <LangRef.html#disubprogram>`_. This way the location; information attached to the intrinsics indicates that the variable ``X`` is; declared at line number 2 at a function level scope in function ``foo``. Now lets take another example. .. code-block:: llvm. call void @llvm.dbg.declare(metadata i32* %Z, metadata !17, metadata !13), !dbg !19; ; [debug line = 5:9] [debug variable = Z]. The third intrinsic ``%llvm.dbg.declare`` encodes debugging information for",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:16322,Modifiability,variab,variable,16322,": !1, line: 4, column: 5); !19 = !DILocation(line: 5, column: 11, scope: !18); !20 = !DILocation(line: 6, column: 11, scope: !18); !21 = !DILocation(line: 6, column: 9, scope: !18); !22 = !DILocation(line: 8, column: 9, scope: !4); !23 = !DILocation(line: 8, column: 7, scope: !4); !24 = !DILocation(line: 9, column: 3, scope: !4). This example illustrates a few important details about LLVM debugging; information. In particular, it shows how the ``llvm.dbg.declare`` intrinsic and; location information, which are attached to an instruction, are applied; together to allow a debugger to analyze the relationship between statements,; variable definitions, and the code used to implement the function. .. code-block:: llvm. call void @llvm.dbg.declare(metadata i32* %X, metadata !11, metadata !13), !dbg !14; ; [debug line = 2:7] [debug variable = X]. The first intrinsic ``%llvm.dbg.declare`` encodes debugging information for the; variable ``X``. The metadata ``!dbg !14`` attached to the intrinsic provides; scope information for the variable ``X``. .. code-block:: text. !14 = !DILocation(line: 2, column: 9, scope: !4); !4 = distinct !DISubprogram(name: ""foo"", scope: !1, file: !1, line: 1, type: !5,; isLocal: false, isDefinition: true, scopeLine: 1,; isOptimized: false, retainedNodes: !2). Here ``!14`` is metadata providing `location information; <LangRef.html#dilocation>`_. In this example, scope is encoded by ``!4``, a; `subprogram descriptor <LangRef.html#disubprogram>`_. This way the location; information attached to the intrinsics indicates that the variable ``X`` is; declared at line number 2 at a function level scope in function ``foo``. Now lets take another example. .. code-block:: llvm. call void @llvm.dbg.declare(metadata i32* %Z, metadata !17, metadata !13), !dbg !19; ; [debug line = 5:9] [debug variable = Z]. The third intrinsic ``%llvm.dbg.declare`` encodes debugging information for; variable ``Z``. The metadata ``!dbg !19`` attached to the intrinsic provides; scop",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:16853,Modifiability,variab,variable,16853,"ow a debugger to analyze the relationship between statements,; variable definitions, and the code used to implement the function. .. code-block:: llvm. call void @llvm.dbg.declare(metadata i32* %X, metadata !11, metadata !13), !dbg !14; ; [debug line = 2:7] [debug variable = X]. The first intrinsic ``%llvm.dbg.declare`` encodes debugging information for the; variable ``X``. The metadata ``!dbg !14`` attached to the intrinsic provides; scope information for the variable ``X``. .. code-block:: text. !14 = !DILocation(line: 2, column: 9, scope: !4); !4 = distinct !DISubprogram(name: ""foo"", scope: !1, file: !1, line: 1, type: !5,; isLocal: false, isDefinition: true, scopeLine: 1,; isOptimized: false, retainedNodes: !2). Here ``!14`` is metadata providing `location information; <LangRef.html#dilocation>`_. In this example, scope is encoded by ``!4``, a; `subprogram descriptor <LangRef.html#disubprogram>`_. This way the location; information attached to the intrinsics indicates that the variable ``X`` is; declared at line number 2 at a function level scope in function ``foo``. Now lets take another example. .. code-block:: llvm. call void @llvm.dbg.declare(metadata i32* %Z, metadata !17, metadata !13), !dbg !19; ; [debug line = 5:9] [debug variable = Z]. The third intrinsic ``%llvm.dbg.declare`` encodes debugging information for; variable ``Z``. The metadata ``!dbg !19`` attached to the intrinsic provides; scope information for the variable ``Z``. .. code-block:: text. !18 = distinct !DILexicalBlock(scope: !4, file: !1, line: 4, column: 5); !19 = !DILocation(line: 5, column: 11, scope: !18). Here ``!19`` indicates that ``Z`` is declared at line number 5 and column; number 11 inside of lexical scope ``!18``. The lexical scope itself resides; inside of subprogram ``!4`` described above. The scope information attached with each instruction provides a straightforward; way to find instructions covered by a scope. Object lifetime in optimized code; ==============================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:17111,Modifiability,variab,variable,17111,"tadata !13), !dbg !14; ; [debug line = 2:7] [debug variable = X]. The first intrinsic ``%llvm.dbg.declare`` encodes debugging information for the; variable ``X``. The metadata ``!dbg !14`` attached to the intrinsic provides; scope information for the variable ``X``. .. code-block:: text. !14 = !DILocation(line: 2, column: 9, scope: !4); !4 = distinct !DISubprogram(name: ""foo"", scope: !1, file: !1, line: 1, type: !5,; isLocal: false, isDefinition: true, scopeLine: 1,; isOptimized: false, retainedNodes: !2). Here ``!14`` is metadata providing `location information; <LangRef.html#dilocation>`_. In this example, scope is encoded by ``!4``, a; `subprogram descriptor <LangRef.html#disubprogram>`_. This way the location; information attached to the intrinsics indicates that the variable ``X`` is; declared at line number 2 at a function level scope in function ``foo``. Now lets take another example. .. code-block:: llvm. call void @llvm.dbg.declare(metadata i32* %Z, metadata !17, metadata !13), !dbg !19; ; [debug line = 5:9] [debug variable = Z]. The third intrinsic ``%llvm.dbg.declare`` encodes debugging information for; variable ``Z``. The metadata ``!dbg !19`` attached to the intrinsic provides; scope information for the variable ``Z``. .. code-block:: text. !18 = distinct !DILexicalBlock(scope: !4, file: !1, line: 4, column: 5); !19 = !DILocation(line: 5, column: 11, scope: !18). Here ``!19`` indicates that ``Z`` is declared at line number 5 and column; number 11 inside of lexical scope ``!18``. The lexical scope itself resides; inside of subprogram ``!4`` described above. The scope information attached with each instruction provides a straightforward; way to find instructions covered by a scope. Object lifetime in optimized code; =================================. In the example above, every variable assignment uniquely corresponds to a; memory store to the variable's position on the stack. However in heavily; optimized code LLVM promotes most variables into SSA values,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:17203,Modifiability,variab,variable,17203,"ebugging information for the; variable ``X``. The metadata ``!dbg !14`` attached to the intrinsic provides; scope information for the variable ``X``. .. code-block:: text. !14 = !DILocation(line: 2, column: 9, scope: !4); !4 = distinct !DISubprogram(name: ""foo"", scope: !1, file: !1, line: 1, type: !5,; isLocal: false, isDefinition: true, scopeLine: 1,; isOptimized: false, retainedNodes: !2). Here ``!14`` is metadata providing `location information; <LangRef.html#dilocation>`_. In this example, scope is encoded by ``!4``, a; `subprogram descriptor <LangRef.html#disubprogram>`_. This way the location; information attached to the intrinsics indicates that the variable ``X`` is; declared at line number 2 at a function level scope in function ``foo``. Now lets take another example. .. code-block:: llvm. call void @llvm.dbg.declare(metadata i32* %Z, metadata !17, metadata !13), !dbg !19; ; [debug line = 5:9] [debug variable = Z]. The third intrinsic ``%llvm.dbg.declare`` encodes debugging information for; variable ``Z``. The metadata ``!dbg !19`` attached to the intrinsic provides; scope information for the variable ``Z``. .. code-block:: text. !18 = distinct !DILexicalBlock(scope: !4, file: !1, line: 4, column: 5); !19 = !DILocation(line: 5, column: 11, scope: !18). Here ``!19`` indicates that ``Z`` is declared at line number 5 and column; number 11 inside of lexical scope ``!18``. The lexical scope itself resides; inside of subprogram ``!4`` described above. The scope information attached with each instruction provides a straightforward; way to find instructions covered by a scope. Object lifetime in optimized code; =================================. In the example above, every variable assignment uniquely corresponds to a; memory store to the variable's position on the stack. However in heavily; optimized code LLVM promotes most variables into SSA values, which can; eventually be placed in physical registers or memory locations. To track SSA; values through compilation",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:17307,Modifiability,variab,variable,17307,"o the intrinsic provides; scope information for the variable ``X``. .. code-block:: text. !14 = !DILocation(line: 2, column: 9, scope: !4); !4 = distinct !DISubprogram(name: ""foo"", scope: !1, file: !1, line: 1, type: !5,; isLocal: false, isDefinition: true, scopeLine: 1,; isOptimized: false, retainedNodes: !2). Here ``!14`` is metadata providing `location information; <LangRef.html#dilocation>`_. In this example, scope is encoded by ``!4``, a; `subprogram descriptor <LangRef.html#disubprogram>`_. This way the location; information attached to the intrinsics indicates that the variable ``X`` is; declared at line number 2 at a function level scope in function ``foo``. Now lets take another example. .. code-block:: llvm. call void @llvm.dbg.declare(metadata i32* %Z, metadata !17, metadata !13), !dbg !19; ; [debug line = 5:9] [debug variable = Z]. The third intrinsic ``%llvm.dbg.declare`` encodes debugging information for; variable ``Z``. The metadata ``!dbg !19`` attached to the intrinsic provides; scope information for the variable ``Z``. .. code-block:: text. !18 = distinct !DILexicalBlock(scope: !4, file: !1, line: 4, column: 5); !19 = !DILocation(line: 5, column: 11, scope: !18). Here ``!19`` indicates that ``Z`` is declared at line number 5 and column; number 11 inside of lexical scope ``!18``. The lexical scope itself resides; inside of subprogram ``!4`` described above. The scope information attached with each instruction provides a straightforward; way to find instructions covered by a scope. Object lifetime in optimized code; =================================. In the example above, every variable assignment uniquely corresponds to a; memory store to the variable's position on the stack. However in heavily; optimized code LLVM promotes most variables into SSA values, which can; eventually be placed in physical registers or memory locations. To track SSA; values through compilation, when objects are promoted to SSA values an; ``llvm.dbg.value`` intrinsic is crea",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:17891,Modifiability,variab,variable,17891," function ``foo``. Now lets take another example. .. code-block:: llvm. call void @llvm.dbg.declare(metadata i32* %Z, metadata !17, metadata !13), !dbg !19; ; [debug line = 5:9] [debug variable = Z]. The third intrinsic ``%llvm.dbg.declare`` encodes debugging information for; variable ``Z``. The metadata ``!dbg !19`` attached to the intrinsic provides; scope information for the variable ``Z``. .. code-block:: text. !18 = distinct !DILexicalBlock(scope: !4, file: !1, line: 4, column: 5); !19 = !DILocation(line: 5, column: 11, scope: !18). Here ``!19`` indicates that ``Z`` is declared at line number 5 and column; number 11 inside of lexical scope ``!18``. The lexical scope itself resides; inside of subprogram ``!4`` described above. The scope information attached with each instruction provides a straightforward; way to find instructions covered by a scope. Object lifetime in optimized code; =================================. In the example above, every variable assignment uniquely corresponds to a; memory store to the variable's position on the stack. However in heavily; optimized code LLVM promotes most variables into SSA values, which can; eventually be placed in physical registers or memory locations. To track SSA; values through compilation, when objects are promoted to SSA values an; ``llvm.dbg.value`` intrinsic is created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:17958,Modifiability,variab,variable,17958," function ``foo``. Now lets take another example. .. code-block:: llvm. call void @llvm.dbg.declare(metadata i32* %Z, metadata !17, metadata !13), !dbg !19; ; [debug line = 5:9] [debug variable = Z]. The third intrinsic ``%llvm.dbg.declare`` encodes debugging information for; variable ``Z``. The metadata ``!dbg !19`` attached to the intrinsic provides; scope information for the variable ``Z``. .. code-block:: text. !18 = distinct !DILexicalBlock(scope: !4, file: !1, line: 4, column: 5); !19 = !DILocation(line: 5, column: 11, scope: !18). Here ``!19`` indicates that ``Z`` is declared at line number 5 and column; number 11 inside of lexical scope ``!18``. The lexical scope itself resides; inside of subprogram ``!4`` described above. The scope information attached with each instruction provides a straightforward; way to find instructions covered by a scope. Object lifetime in optimized code; =================================. In the example above, every variable assignment uniquely corresponds to a; memory store to the variable's position on the stack. However in heavily; optimized code LLVM promotes most variables into SSA values, which can; eventually be placed in physical registers or memory locations. To track SSA; values through compilation, when objects are promoted to SSA values an; ``llvm.dbg.value`` intrinsic is created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:18046,Modifiability,variab,variables,18046,"3), !dbg !19; ; [debug line = 5:9] [debug variable = Z]. The third intrinsic ``%llvm.dbg.declare`` encodes debugging information for; variable ``Z``. The metadata ``!dbg !19`` attached to the intrinsic provides; scope information for the variable ``Z``. .. code-block:: text. !18 = distinct !DILexicalBlock(scope: !4, file: !1, line: 4, column: 5); !19 = !DILocation(line: 5, column: 11, scope: !18). Here ``!19`` indicates that ``Z`` is declared at line number 5 and column; number 11 inside of lexical scope ``!18``. The lexical scope itself resides; inside of subprogram ``!4`` described above. The scope information attached with each instruction provides a straightforward; way to find instructions covered by a scope. Object lifetime in optimized code; =================================. In the example above, every variable assignment uniquely corresponds to a; memory store to the variable's position on the stack. However in heavily; optimized code LLVM promotes most variables into SSA values, which can; eventually be placed in physical registers or memory locations. To track SSA; values through compilation, when objects are promoted to SSA values an; ``llvm.dbg.value`` intrinsic is created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:18310,Modifiability,variab,variable,18310,"formation for the variable ``Z``. .. code-block:: text. !18 = distinct !DILexicalBlock(scope: !4, file: !1, line: 4, column: 5); !19 = !DILocation(line: 5, column: 11, scope: !18). Here ``!19`` indicates that ``Z`` is declared at line number 5 and column; number 11 inside of lexical scope ``!18``. The lexical scope itself resides; inside of subprogram ``!4`` described above. The scope information attached with each instruction provides a straightforward; way to find instructions covered by a scope. Object lifetime in optimized code; =================================. In the example above, every variable assignment uniquely corresponds to a; memory store to the variable's position on the stack. However in heavily; optimized code LLVM promotes most variables into SSA values, which can; eventually be placed in physical registers or memory locations. To track SSA; values through compilation, when objects are promoted to SSA values an; ``llvm.dbg.value`` intrinsic is created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:18500,Modifiability,variab,variable,18500,"`!19`` indicates that ``Z`` is declared at line number 5 and column; number 11 inside of lexical scope ``!18``. The lexical scope itself resides; inside of subprogram ``!4`` described above. The scope information attached with each instruction provides a straightforward; way to find instructions covered by a scope. Object lifetime in optimized code; =================================. In the example above, every variable assignment uniquely corresponds to a; memory store to the variable's position on the stack. However in heavily; optimized code LLVM promotes most variables into SSA values, which can; eventually be placed in physical registers or memory locations. To track SSA; values through compilation, when objects are promoted to SSA values an; ``llvm.dbg.value`` intrinsic is created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized ou",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:18593,Modifiability,variab,variable,18593,"cal scope ``!18``. The lexical scope itself resides; inside of subprogram ``!4`` described above. The scope information attached with each instruction provides a straightforward; way to find instructions covered by a scope. Object lifetime in optimized code; =================================. In the example above, every variable assignment uniquely corresponds to a; memory store to the variable's position on the stack. However in heavily; optimized code LLVM promotes most variables into SSA values, which can; eventually be placed in physical registers or memory locations. To track SSA; values through compilation, when objects are promoted to SSA values an; ``llvm.dbg.value`` intrinsic is created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:18664,Modifiability,variab,variable,18664,"above. The scope information attached with each instruction provides a straightforward; way to find instructions covered by a scope. Object lifetime in optimized code; =================================. In the example above, every variable assignment uniquely corresponds to a; memory store to the variable's position on the stack. However in heavily; optimized code LLVM promotes most variables into SSA values, which can; eventually be placed in physical registers or memory locations. To track SSA; values through compilation, when objects are promoted to SSA values an; ``llvm.dbg.value`` intrinsic is created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:18898,Modifiability,variab,variables,18898,"======================. In the example above, every variable assignment uniquely corresponds to a; memory store to the variable's position on the stack. However in heavily; optimized code LLVM promotes most variables into SSA values, which can; eventually be placed in physical registers or memory locations. To track SSA; values through compilation, when objects are promoted to SSA values an; ``llvm.dbg.value`` intrinsic is created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from the developer diminishes the; amount of available debug information, but increases the reliability of the; remaining inf",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:18992,Modifiability,variab,variable,18992,"s into SSA values, which can; eventually be placed in physical registers or memory locations. To track SSA; values through compilation, when objects are promoted to SSA values an; ``llvm.dbg.value`` intrinsic is created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from the developer diminishes the; amount of available debug information, but increases the reliability of the; remaining information. To illustrate some potential issues, consider the following example:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:19389,Modifiability,variab,variable,19389,"fect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from the developer diminishes the; amount of available debug information, but increases the reliability of the; remaining information. To illustrate some potential issues, consider the following example:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); br i1 %cond, label %truebr, label %falsebr; truebr:; %tval = add i32 %bar, 1; call @llvm.dbg.value(metadata i32 %tval, metadata !1, metadata !2); %g1 = call i32 @gazonk(); br label %exit; falsebr:; %fval = add i32 %bar, 2; call @llvm.dbg.value(metadata i32 %fval, metadata !1, metadata !2); %g2 = call i32 @gazonk(); br label %exit; exit:; %merge = phi [ %tval, %tr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:19577,Modifiability,variab,variable,19577,"eam; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from the developer diminishes the; amount of available debug information, but increases the reliability of the; remaining information. To illustrate some potential issues, consider the following example:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); br i1 %cond, label %truebr, label %falsebr; truebr:; %tval = add i32 %bar, 1; call @llvm.dbg.value(metadata i32 %tval, metadata !1, metadata !2); %g1 = call i32 @gazonk(); br label %exit; falsebr:; %fval = add i32 %bar, 2; call @llvm.dbg.value(metadata i32 %fval, metadata !1, metadata !2); %g2 = call i32 @gazonk(); br label %exit; exit:; %merge = phi [ %tval, %truebr ], [ %fval, %falsebr ]; %g = phi [ %g1, %truebr ], [ %g2, %falsebr ]; call @llvm.dbg.value(metadata i32 %merge, metadata !1, metadata !2); call @llvm.dbg.value(m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:19699,Modifiability,variab,variable,19699,"rinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from the developer diminishes the; amount of available debug information, but increases the reliability of the; remaining information. To illustrate some potential issues, consider the following example:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); br i1 %cond, label %truebr, label %falsebr; truebr:; %tval = add i32 %bar, 1; call @llvm.dbg.value(metadata i32 %tval, metadata !1, metadata !2); %g1 = call i32 @gazonk(); br label %exit; falsebr:; %fval = add i32 %bar, 2; call @llvm.dbg.value(metadata i32 %fval, metadata !1, metadata !2); %g2 = call i32 @gazonk(); br label %exit; exit:; %merge = phi [ %tval, %truebr ], [ %fval, %falsebr ]; %g = phi [ %g1, %truebr ], [ %g2, %falsebr ]; call @llvm.dbg.value(metadata i32 %merge, metadata !1, metadata !2); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %plusten = add i32 %merge, 10; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:20805,Modifiability,variab,variables,20805," reliability of the; remaining information. To illustrate some potential issues, consider the following example:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); br i1 %cond, label %truebr, label %falsebr; truebr:; %tval = add i32 %bar, 1; call @llvm.dbg.value(metadata i32 %tval, metadata !1, metadata !2); %g1 = call i32 @gazonk(); br label %exit; falsebr:; %fval = add i32 %bar, 2; call @llvm.dbg.value(metadata i32 %fval, metadata !1, metadata !2); %g2 = call i32 @gazonk(); br label %exit; exit:; %merge = phi [ %tval, %truebr ], [ %fval, %falsebr ]; %g = phi [ %g1, %truebr ], [ %g2, %falsebr ]; call @llvm.dbg.value(metadata i32 %merge, metadata !1, metadata !2); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %plusten = add i32 %merge, 10; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. Containing two source-level variables in ``!1`` and ``!3``. The function could,; perhaps, be optimized into the following code:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; %g = call i32 @gazonk(); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; ret i32 %toret; }. What ``llvm.dbg.value`` intrinsics should be placed to represent the original variable; locations in this code? Unfortunately the second, third and fourth; dbg.values for ``!1`` in the source function have had their operands; (%tval, %fval, %merge) optimized out. Assuming we cannot recover them, we; might consider this placement of dbg.values:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); %g = call i32 @gazonk(); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:21207,Modifiability,variab,variable,21207,"zonk(); br label %exit; falsebr:; %fval = add i32 %bar, 2; call @llvm.dbg.value(metadata i32 %fval, metadata !1, metadata !2); %g2 = call i32 @gazonk(); br label %exit; exit:; %merge = phi [ %tval, %truebr ], [ %fval, %falsebr ]; %g = phi [ %g1, %truebr ], [ %g2, %falsebr ]; call @llvm.dbg.value(metadata i32 %merge, metadata !1, metadata !2); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %plusten = add i32 %merge, 10; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. Containing two source-level variables in ``!1`` and ``!3``. The function could,; perhaps, be optimized into the following code:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; %g = call i32 @gazonk(); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; ret i32 %toret; }. What ``llvm.dbg.value`` intrinsics should be placed to represent the original variable; locations in this code? Unfortunately the second, third and fourth; dbg.values for ``!1`` in the source function have had their operands; (%tval, %fval, %merge) optimized out. Assuming we cannot recover them, we; might consider this placement of dbg.values:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); %g = call i32 @gazonk(); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. However, this will cause ``!3`` to have the return value of ``@gazonk()`` at; the same time as ``!1`` has the constant value zero -- a pair of assignments; that never occurred in the unoptimized program. To avoid this, we must terminate; the range that ``!1`` has the constant value assignment by inserting a poison; dbg",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:22780,Modifiability,config,configurations,22780,"e(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. However, this will cause ``!3`` to have the return value of ``@gazonk()`` at; the same time as ``!1`` has the constant value zero -- a pair of assignments; that never occurred in the unoptimized program. To avoid this, we must terminate; the range that ``!1`` has the constant value assignment by inserting a poison; dbg.value before the dbg.value for ``!3``:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); %g = call i32 @gazonk(); call @llvm.dbg.value(metadata i32 poison, metadata !1, metadata !2); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. There are a few other dbg.value configurations that mean it terminates; dominating location definitions without adding a new location. The complete; list is:. * Any location operand is ``poison`` (or ``undef``).; * Any location operand is an empty metadata tuple (``!{}``) (which cannot; occur in a ``!DIArgList``).; * There are no location operands (empty ``DIArgList``) and the ``DIExpression``; is empty. This class of dbg.value that kills variable locations is called a ""kill; dbg.value"" or ""kill location"", and for legacy reasons the term ""undef; dbg.value"" may be used in existing code. The ``DbgVariableIntrinsic`` methods; ``isKillLocation`` and ``setKillLocation`` should be used where possible rather; than inspecting location operands directly to check or set whether a dbg.value; is a kill location. In general, if any dbg.value has its operand optimized out and cannot be; recovered, then a kill dbg.value is necessary to terminate earlier variable; locations. Additional kill dbg.values may be necessary when the debugger can; observe re-ordering of assignments. How",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:23191,Modifiability,variab,variable,23191," a poison; dbg.value before the dbg.value for ``!3``:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); %g = call i32 @gazonk(); call @llvm.dbg.value(metadata i32 poison, metadata !1, metadata !2); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. There are a few other dbg.value configurations that mean it terminates; dominating location definitions without adding a new location. The complete; list is:. * Any location operand is ``poison`` (or ``undef``).; * Any location operand is an empty metadata tuple (``!{}``) (which cannot; occur in a ``!DIArgList``).; * There are no location operands (empty ``DIArgList``) and the ``DIExpression``; is empty. This class of dbg.value that kills variable locations is called a ""kill; dbg.value"" or ""kill location"", and for legacy reasons the term ""undef; dbg.value"" may be used in existing code. The ``DbgVariableIntrinsic`` methods; ``isKillLocation`` and ``setKillLocation`` should be used where possible rather; than inspecting location operands directly to check or set whether a dbg.value; is a kill location. In general, if any dbg.value has its operand optimized out and cannot be; recovered, then a kill dbg.value is necessary to terminate earlier variable; locations. Additional kill dbg.values may be necessary when the debugger can; observe re-ordering of assignments. How variable location metadata is transformed during CodeGen; ============================================================. LLVM preserves debug information throughout mid-level and backend passes,; ultimately producing a mapping between source-level information and; instruction ranges. This; is relatively straightforwards for line number information, as mapping; instructions ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:23701,Modifiability,variab,variable,23701,"32 %toret, metadata !1, metadata !2); ret i32 %toret; }. There are a few other dbg.value configurations that mean it terminates; dominating location definitions without adding a new location. The complete; list is:. * Any location operand is ``poison`` (or ``undef``).; * Any location operand is an empty metadata tuple (``!{}``) (which cannot; occur in a ``!DIArgList``).; * There are no location operands (empty ``DIArgList``) and the ``DIExpression``; is empty. This class of dbg.value that kills variable locations is called a ""kill; dbg.value"" or ""kill location"", and for legacy reasons the term ""undef; dbg.value"" may be used in existing code. The ``DbgVariableIntrinsic`` methods; ``isKillLocation`` and ``setKillLocation`` should be used where possible rather; than inspecting location operands directly to check or set whether a dbg.value; is a kill location. In general, if any dbg.value has its operand optimized out and cannot be; recovered, then a kill dbg.value is necessary to terminate earlier variable; locations. Additional kill dbg.values may be necessary when the debugger can; observe re-ordering of assignments. How variable location metadata is transformed during CodeGen; ============================================================. LLVM preserves debug information throughout mid-level and backend passes,; ultimately producing a mapping between source-level information and; instruction ranges. This; is relatively straightforwards for line number information, as mapping; instructions to line numbers is a simple association. For variable locations; however the story is more complex. As each ``llvm.dbg.value`` intrinsic; represents a source-level assignment of a value to a source variable, the; variable location intrinsics effectively embed a small imperative program; within the LLVM IR. By the end of CodeGen, this becomes a mapping from each; variable to their machine locations over ranges of instructions.; From IR to object emission, the major transformations wh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:23829,Modifiability,variab,variable,23829," complete; list is:. * Any location operand is ``poison`` (or ``undef``).; * Any location operand is an empty metadata tuple (``!{}``) (which cannot; occur in a ``!DIArgList``).; * There are no location operands (empty ``DIArgList``) and the ``DIExpression``; is empty. This class of dbg.value that kills variable locations is called a ""kill; dbg.value"" or ""kill location"", and for legacy reasons the term ""undef; dbg.value"" may be used in existing code. The ``DbgVariableIntrinsic`` methods; ``isKillLocation`` and ``setKillLocation`` should be used where possible rather; than inspecting location operands directly to check or set whether a dbg.value; is a kill location. In general, if any dbg.value has its operand optimized out and cannot be; recovered, then a kill dbg.value is necessary to terminate earlier variable; locations. Additional kill dbg.values may be necessary when the debugger can; observe re-ordering of assignments. How variable location metadata is transformed during CodeGen; ============================================================. LLVM preserves debug information throughout mid-level and backend passes,; ultimately producing a mapping between source-level information and; instruction ranges. This; is relatively straightforwards for line number information, as mapping; instructions to line numbers is a simple association. For variable locations; however the story is more complex. As each ``llvm.dbg.value`` intrinsic; represents a source-level assignment of a value to a source variable, the; variable location intrinsics effectively embed a small imperative program; within the LLVM IR. By the end of CodeGen, this becomes a mapping from each; variable to their machine locations over ranges of instructions.; From IR to object emission, the major transformations which affect variable; location fidelity are:. 1. Instruction Selection; 2. Register allocation; 3. Block layout. each of which are discussed below. In addition, instruction scheduling can; signifi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:24249,Modifiability,variab,variable,24249,"y reasons the term ""undef; dbg.value"" may be used in existing code. The ``DbgVariableIntrinsic`` methods; ``isKillLocation`` and ``setKillLocation`` should be used where possible rather; than inspecting location operands directly to check or set whether a dbg.value; is a kill location. In general, if any dbg.value has its operand optimized out and cannot be; recovered, then a kill dbg.value is necessary to terminate earlier variable; locations. Additional kill dbg.values may be necessary when the debugger can; observe re-ordering of assignments. How variable location metadata is transformed during CodeGen; ============================================================. LLVM preserves debug information throughout mid-level and backend passes,; ultimately producing a mapping between source-level information and; instruction ranges. This; is relatively straightforwards for line number information, as mapping; instructions to line numbers is a simple association. For variable locations; however the story is more complex. As each ``llvm.dbg.value`` intrinsic; represents a source-level assignment of a value to a source variable, the; variable location intrinsics effectively embed a small imperative program; within the LLVM IR. By the end of CodeGen, this becomes a mapping from each; variable to their machine locations over ranges of instructions.; From IR to object emission, the major transformations which affect variable; location fidelity are:. 1. Instruction Selection; 2. Register allocation; 3. Block layout. each of which are discussed below. In addition, instruction scheduling can; significantly change the ordering of the program, and occurs in a number of; different passes. Some variable locations are not transformed during CodeGen. Stack locations; specified by ``llvm.dbg.declare`` are valid and unchanging for the entire; duration of the function, and are recorded in a simple MachineFunction table.; Location changes in the prologue and epilogue of a function are also ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:24402,Modifiability,variab,variable,24402,"on`` should be used where possible rather; than inspecting location operands directly to check or set whether a dbg.value; is a kill location. In general, if any dbg.value has its operand optimized out and cannot be; recovered, then a kill dbg.value is necessary to terminate earlier variable; locations. Additional kill dbg.values may be necessary when the debugger can; observe re-ordering of assignments. How variable location metadata is transformed during CodeGen; ============================================================. LLVM preserves debug information throughout mid-level and backend passes,; ultimately producing a mapping between source-level information and; instruction ranges. This; is relatively straightforwards for line number information, as mapping; instructions to line numbers is a simple association. For variable locations; however the story is more complex. As each ``llvm.dbg.value`` intrinsic; represents a source-level assignment of a value to a source variable, the; variable location intrinsics effectively embed a small imperative program; within the LLVM IR. By the end of CodeGen, this becomes a mapping from each; variable to their machine locations over ranges of instructions.; From IR to object emission, the major transformations which affect variable; location fidelity are:. 1. Instruction Selection; 2. Register allocation; 3. Block layout. each of which are discussed below. In addition, instruction scheduling can; significantly change the ordering of the program, and occurs in a number of; different passes. Some variable locations are not transformed during CodeGen. Stack locations; specified by ``llvm.dbg.declare`` are valid and unchanging for the entire; duration of the function, and are recorded in a simple MachineFunction table.; Location changes in the prologue and epilogue of a function are also ignored:; frame setup and destruction may take several instructions, require a; disproportionate amount of debugging information in the output ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:24417,Modifiability,variab,variable,24417,"on`` should be used where possible rather; than inspecting location operands directly to check or set whether a dbg.value; is a kill location. In general, if any dbg.value has its operand optimized out and cannot be; recovered, then a kill dbg.value is necessary to terminate earlier variable; locations. Additional kill dbg.values may be necessary when the debugger can; observe re-ordering of assignments. How variable location metadata is transformed during CodeGen; ============================================================. LLVM preserves debug information throughout mid-level and backend passes,; ultimately producing a mapping between source-level information and; instruction ranges. This; is relatively straightforwards for line number information, as mapping; instructions to line numbers is a simple association. For variable locations; however the story is more complex. As each ``llvm.dbg.value`` intrinsic; represents a source-level assignment of a value to a source variable, the; variable location intrinsics effectively embed a small imperative program; within the LLVM IR. By the end of CodeGen, this becomes a mapping from each; variable to their machine locations over ranges of instructions.; From IR to object emission, the major transformations which affect variable; location fidelity are:. 1. Instruction Selection; 2. Register allocation; 3. Block layout. each of which are discussed below. In addition, instruction scheduling can; significantly change the ordering of the program, and occurs in a number of; different passes. Some variable locations are not transformed during CodeGen. Stack locations; specified by ``llvm.dbg.declare`` are valid and unchanging for the entire; duration of the function, and are recorded in a simple MachineFunction table.; Location changes in the prologue and epilogue of a function are also ignored:; frame setup and destruction may take several instructions, require a; disproportionate amount of debugging information in the output ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:24569,Modifiability,variab,variable,24569,"if any dbg.value has its operand optimized out and cannot be; recovered, then a kill dbg.value is necessary to terminate earlier variable; locations. Additional kill dbg.values may be necessary when the debugger can; observe re-ordering of assignments. How variable location metadata is transformed during CodeGen; ============================================================. LLVM preserves debug information throughout mid-level and backend passes,; ultimately producing a mapping between source-level information and; instruction ranges. This; is relatively straightforwards for line number information, as mapping; instructions to line numbers is a simple association. For variable locations; however the story is more complex. As each ``llvm.dbg.value`` intrinsic; represents a source-level assignment of a value to a source variable, the; variable location intrinsics effectively embed a small imperative program; within the LLVM IR. By the end of CodeGen, this becomes a mapping from each; variable to their machine locations over ranges of instructions.; From IR to object emission, the major transformations which affect variable; location fidelity are:. 1. Instruction Selection; 2. Register allocation; 3. Block layout. each of which are discussed below. In addition, instruction scheduling can; significantly change the ordering of the program, and occurs in a number of; different passes. Some variable locations are not transformed during CodeGen. Stack locations; specified by ``llvm.dbg.declare`` are valid and unchanging for the entire; duration of the function, and are recorded in a simple MachineFunction table.; Location changes in the prologue and epilogue of a function are also ignored:; frame setup and destruction may take several instructions, require a; disproportionate amount of debugging information in the output binary to; describe, and should be stepped over by debuggers anyway. Variable locations in Instruction Selection and MIR; ---------------------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:24702,Modifiability,variab,variable,24702,"erminate earlier variable; locations. Additional kill dbg.values may be necessary when the debugger can; observe re-ordering of assignments. How variable location metadata is transformed during CodeGen; ============================================================. LLVM preserves debug information throughout mid-level and backend passes,; ultimately producing a mapping between source-level information and; instruction ranges. This; is relatively straightforwards for line number information, as mapping; instructions to line numbers is a simple association. For variable locations; however the story is more complex. As each ``llvm.dbg.value`` intrinsic; represents a source-level assignment of a value to a source variable, the; variable location intrinsics effectively embed a small imperative program; within the LLVM IR. By the end of CodeGen, this becomes a mapping from each; variable to their machine locations over ranges of instructions.; From IR to object emission, the major transformations which affect variable; location fidelity are:. 1. Instruction Selection; 2. Register allocation; 3. Block layout. each of which are discussed below. In addition, instruction scheduling can; significantly change the ordering of the program, and occurs in a number of; different passes. Some variable locations are not transformed during CodeGen. Stack locations; specified by ``llvm.dbg.declare`` are valid and unchanging for the entire; duration of the function, and are recorded in a simple MachineFunction table.; Location changes in the prologue and epilogue of a function are also ignored:; frame setup and destruction may take several instructions, require a; disproportionate amount of debugging information in the output binary to; describe, and should be stepped over by debuggers anyway. Variable locations in Instruction Selection and MIR; ---------------------------------------------------. Instruction selection creates a MIR function from an IR function, and just as; it transforms",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:24979,Modifiability,variab,variable,24979,"and backend passes,; ultimately producing a mapping between source-level information and; instruction ranges. This; is relatively straightforwards for line number information, as mapping; instructions to line numbers is a simple association. For variable locations; however the story is more complex. As each ``llvm.dbg.value`` intrinsic; represents a source-level assignment of a value to a source variable, the; variable location intrinsics effectively embed a small imperative program; within the LLVM IR. By the end of CodeGen, this becomes a mapping from each; variable to their machine locations over ranges of instructions.; From IR to object emission, the major transformations which affect variable; location fidelity are:. 1. Instruction Selection; 2. Register allocation; 3. Block layout. each of which are discussed below. In addition, instruction scheduling can; significantly change the ordering of the program, and occurs in a number of; different passes. Some variable locations are not transformed during CodeGen. Stack locations; specified by ``llvm.dbg.declare`` are valid and unchanging for the entire; duration of the function, and are recorded in a simple MachineFunction table.; Location changes in the prologue and epilogue of a function are also ignored:; frame setup and destruction may take several instructions, require a; disproportionate amount of debugging information in the output binary to; describe, and should be stepped over by debuggers anyway. Variable locations in Instruction Selection and MIR; ---------------------------------------------------. Instruction selection creates a MIR function from an IR function, and just as; it transforms ``intermediate`` instructions into machine instructions, so must; ``intermediate`` variable locations become machine variable locations.; Within IR, variable locations are always identified by a Value, but in MIR; there can be different types of variable locations. In addition, some IR; locations become unavailable, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:25768,Modifiability,variab,variable,25768,"able; location fidelity are:. 1. Instruction Selection; 2. Register allocation; 3. Block layout. each of which are discussed below. In addition, instruction scheduling can; significantly change the ordering of the program, and occurs in a number of; different passes. Some variable locations are not transformed during CodeGen. Stack locations; specified by ``llvm.dbg.declare`` are valid and unchanging for the entire; duration of the function, and are recorded in a simple MachineFunction table.; Location changes in the prologue and epilogue of a function are also ignored:; frame setup and destruction may take several instructions, require a; disproportionate amount of debugging information in the output binary to; describe, and should be stepped over by debuggers anyway. Variable locations in Instruction Selection and MIR; ---------------------------------------------------. Instruction selection creates a MIR function from an IR function, and just as; it transforms ``intermediate`` instructions into machine instructions, so must; ``intermediate`` variable locations become machine variable locations.; Within IR, variable locations are always identified by a Value, but in MIR; there can be different types of variable locations. In addition, some IR; locations become unavailable, for example if the operation of multiple IR; instructions are combined into one machine instruction (such as; multiply-and-accumulate) then intermediate Values are lost. To track variable; locations through instruction selection, they are first separated into; locations that do not depend on code generation (constants, stack locations,; allocated virtual registers) and those that do. For those that do, debug; metadata is attached to SDNodes in SelectionDAGs. After instruction selection; has occurred and a MIR function is created, if the SDNode associated with debug; metadata is allocated a virtual register, that virtual register is used as the; variable location. If the SDNode is folded into a ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:25802,Modifiability,variab,variable,25802,"able; location fidelity are:. 1. Instruction Selection; 2. Register allocation; 3. Block layout. each of which are discussed below. In addition, instruction scheduling can; significantly change the ordering of the program, and occurs in a number of; different passes. Some variable locations are not transformed during CodeGen. Stack locations; specified by ``llvm.dbg.declare`` are valid and unchanging for the entire; duration of the function, and are recorded in a simple MachineFunction table.; Location changes in the prologue and epilogue of a function are also ignored:; frame setup and destruction may take several instructions, require a; disproportionate amount of debugging information in the output binary to; describe, and should be stepped over by debuggers anyway. Variable locations in Instruction Selection and MIR; ---------------------------------------------------. Instruction selection creates a MIR function from an IR function, and just as; it transforms ``intermediate`` instructions into machine instructions, so must; ``intermediate`` variable locations become machine variable locations.; Within IR, variable locations are always identified by a Value, but in MIR; there can be different types of variable locations. In addition, some IR; locations become unavailable, for example if the operation of multiple IR; instructions are combined into one machine instruction (such as; multiply-and-accumulate) then intermediate Values are lost. To track variable; locations through instruction selection, they are first separated into; locations that do not depend on code generation (constants, stack locations,; allocated virtual registers) and those that do. For those that do, debug; metadata is attached to SDNodes in SelectionDAGs. After instruction selection; has occurred and a MIR function is created, if the SDNode associated with debug; metadata is allocated a virtual register, that virtual register is used as the; variable location. If the SDNode is folded into a ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:25834,Modifiability,variab,variable,25834,"icantly change the ordering of the program, and occurs in a number of; different passes. Some variable locations are not transformed during CodeGen. Stack locations; specified by ``llvm.dbg.declare`` are valid and unchanging for the entire; duration of the function, and are recorded in a simple MachineFunction table.; Location changes in the prologue and epilogue of a function are also ignored:; frame setup and destruction may take several instructions, require a; disproportionate amount of debugging information in the output binary to; describe, and should be stepped over by debuggers anyway. Variable locations in Instruction Selection and MIR; ---------------------------------------------------. Instruction selection creates a MIR function from an IR function, and just as; it transforms ``intermediate`` instructions into machine instructions, so must; ``intermediate`` variable locations become machine variable locations.; Within IR, variable locations are always identified by a Value, but in MIR; there can be different types of variable locations. In addition, some IR; locations become unavailable, for example if the operation of multiple IR; instructions are combined into one machine instruction (such as; multiply-and-accumulate) then intermediate Values are lost. To track variable; locations through instruction selection, they are first separated into; locations that do not depend on code generation (constants, stack locations,; allocated virtual registers) and those that do. For those that do, debug; metadata is attached to SDNodes in SelectionDAGs. After instruction selection; has occurred and a MIR function is created, if the SDNode associated with debug; metadata is allocated a virtual register, that virtual register is used as the; variable location. If the SDNode is folded into a machine instruction or; otherwise transformed into a non-register, the variable location becomes; unavailable. Locations that are unavailable are treated as if they have been optim",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:25931,Modifiability,variab,variable,25931,"icantly change the ordering of the program, and occurs in a number of; different passes. Some variable locations are not transformed during CodeGen. Stack locations; specified by ``llvm.dbg.declare`` are valid and unchanging for the entire; duration of the function, and are recorded in a simple MachineFunction table.; Location changes in the prologue and epilogue of a function are also ignored:; frame setup and destruction may take several instructions, require a; disproportionate amount of debugging information in the output binary to; describe, and should be stepped over by debuggers anyway. Variable locations in Instruction Selection and MIR; ---------------------------------------------------. Instruction selection creates a MIR function from an IR function, and just as; it transforms ``intermediate`` instructions into machine instructions, so must; ``intermediate`` variable locations become machine variable locations.; Within IR, variable locations are always identified by a Value, but in MIR; there can be different types of variable locations. In addition, some IR; locations become unavailable, for example if the operation of multiple IR; instructions are combined into one machine instruction (such as; multiply-and-accumulate) then intermediate Values are lost. To track variable; locations through instruction selection, they are first separated into; locations that do not depend on code generation (constants, stack locations,; allocated virtual registers) and those that do. For those that do, debug; metadata is attached to SDNodes in SelectionDAGs. After instruction selection; has occurred and a MIR function is created, if the SDNode associated with debug; metadata is allocated a virtual register, that virtual register is used as the; variable location. If the SDNode is folded into a machine instruction or; otherwise transformed into a non-register, the variable location becomes; unavailable. Locations that are unavailable are treated as if they have been optim",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:26182,Modifiability,variab,variable,26182,"d:; frame setup and destruction may take several instructions, require a; disproportionate amount of debugging information in the output binary to; describe, and should be stepped over by debuggers anyway. Variable locations in Instruction Selection and MIR; ---------------------------------------------------. Instruction selection creates a MIR function from an IR function, and just as; it transforms ``intermediate`` instructions into machine instructions, so must; ``intermediate`` variable locations become machine variable locations.; Within IR, variable locations are always identified by a Value, but in MIR; there can be different types of variable locations. In addition, some IR; locations become unavailable, for example if the operation of multiple IR; instructions are combined into one machine instruction (such as; multiply-and-accumulate) then intermediate Values are lost. To track variable; locations through instruction selection, they are first separated into; locations that do not depend on code generation (constants, stack locations,; allocated virtual registers) and those that do. For those that do, debug; metadata is attached to SDNodes in SelectionDAGs. After instruction selection; has occurred and a MIR function is created, if the SDNode associated with debug; metadata is allocated a virtual register, that virtual register is used as the; variable location. If the SDNode is folded into a machine instruction or; otherwise transformed into a non-register, the variable location becomes; unavailable. Locations that are unavailable are treated as if they have been optimized out:; in IR the location would be assigned ``undef`` by a debug intrinsic, and in MIR; the equivalent location is used. After MIR locations are assigned to each variable, machine pseudo-instructions; corresponding to each ``llvm.dbg.value`` intrinsic are inserted. There are two; forms of this type of instruction. The first form, ``DBG_VALUE``, appears thus:. .. code-block:: text. DBG_VAL",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:26656,Modifiability,variab,variable,26656,"---------------------. Instruction selection creates a MIR function from an IR function, and just as; it transforms ``intermediate`` instructions into machine instructions, so must; ``intermediate`` variable locations become machine variable locations.; Within IR, variable locations are always identified by a Value, but in MIR; there can be different types of variable locations. In addition, some IR; locations become unavailable, for example if the operation of multiple IR; instructions are combined into one machine instruction (such as; multiply-and-accumulate) then intermediate Values are lost. To track variable; locations through instruction selection, they are first separated into; locations that do not depend on code generation (constants, stack locations,; allocated virtual registers) and those that do. For those that do, debug; metadata is attached to SDNodes in SelectionDAGs. After instruction selection; has occurred and a MIR function is created, if the SDNode associated with debug; metadata is allocated a virtual register, that virtual register is used as the; variable location. If the SDNode is folded into a machine instruction or; otherwise transformed into a non-register, the variable location becomes; unavailable. Locations that are unavailable are treated as if they have been optimized out:; in IR the location would be assigned ``undef`` by a debug intrinsic, and in MIR; the equivalent location is used. After MIR locations are assigned to each variable, machine pseudo-instructions; corresponding to each ``llvm.dbg.value`` intrinsic are inserted. There are two; forms of this type of instruction. The first form, ``DBG_VALUE``, appears thus:. .. code-block:: text. DBG_VALUE %1, $noreg, !123, !DIExpression(). And has the following operands:; * The first operand can record the variable location as a register,; a frame index, an immediate, or the base address register if the original; debug intrinsic referred to memory. ``$noreg`` indicates the variable; loc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:26777,Modifiability,variab,variable,26777,"must; ``intermediate`` variable locations become machine variable locations.; Within IR, variable locations are always identified by a Value, but in MIR; there can be different types of variable locations. In addition, some IR; locations become unavailable, for example if the operation of multiple IR; instructions are combined into one machine instruction (such as; multiply-and-accumulate) then intermediate Values are lost. To track variable; locations through instruction selection, they are first separated into; locations that do not depend on code generation (constants, stack locations,; allocated virtual registers) and those that do. For those that do, debug; metadata is attached to SDNodes in SelectionDAGs. After instruction selection; has occurred and a MIR function is created, if the SDNode associated with debug; metadata is allocated a virtual register, that virtual register is used as the; variable location. If the SDNode is folded into a machine instruction or; otherwise transformed into a non-register, the variable location becomes; unavailable. Locations that are unavailable are treated as if they have been optimized out:; in IR the location would be assigned ``undef`` by a debug intrinsic, and in MIR; the equivalent location is used. After MIR locations are assigned to each variable, machine pseudo-instructions; corresponding to each ``llvm.dbg.value`` intrinsic are inserted. There are two; forms of this type of instruction. The first form, ``DBG_VALUE``, appears thus:. .. code-block:: text. DBG_VALUE %1, $noreg, !123, !DIExpression(). And has the following operands:; * The first operand can record the variable location as a register,; a frame index, an immediate, or the base address register if the original; debug intrinsic referred to memory. ``$noreg`` indicates the variable; location is undefined, equivalent to an ``undef`` dbg.value operand.; * The type of the second operand indicates whether the variable location is; directly referred to by the DBG",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:27052,Modifiability,variab,variable,27052,"combined into one machine instruction (such as; multiply-and-accumulate) then intermediate Values are lost. To track variable; locations through instruction selection, they are first separated into; locations that do not depend on code generation (constants, stack locations,; allocated virtual registers) and those that do. For those that do, debug; metadata is attached to SDNodes in SelectionDAGs. After instruction selection; has occurred and a MIR function is created, if the SDNode associated with debug; metadata is allocated a virtual register, that virtual register is used as the; variable location. If the SDNode is folded into a machine instruction or; otherwise transformed into a non-register, the variable location becomes; unavailable. Locations that are unavailable are treated as if they have been optimized out:; in IR the location would be assigned ``undef`` by a debug intrinsic, and in MIR; the equivalent location is used. After MIR locations are assigned to each variable, machine pseudo-instructions; corresponding to each ``llvm.dbg.value`` intrinsic are inserted. There are two; forms of this type of instruction. The first form, ``DBG_VALUE``, appears thus:. .. code-block:: text. DBG_VALUE %1, $noreg, !123, !DIExpression(). And has the following operands:; * The first operand can record the variable location as a register,; a frame index, an immediate, or the base address register if the original; debug intrinsic referred to memory. ``$noreg`` indicates the variable; location is undefined, equivalent to an ``undef`` dbg.value operand.; * The type of the second operand indicates whether the variable location is; directly referred to by the DBG_VALUE, or whether it is indirect. The; ``$noreg`` register signifies the former, an immediate operand (0) the; latter.; * Operand 3 is the Variable field of the original debug intrinsic.; * Operand 4 is the Expression field of the original debug intrinsic. The second form, ``DBG_VALUE_LIST``, appears thus:. .. code-bl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:27387,Modifiability,variab,variable,27387," is attached to SDNodes in SelectionDAGs. After instruction selection; has occurred and a MIR function is created, if the SDNode associated with debug; metadata is allocated a virtual register, that virtual register is used as the; variable location. If the SDNode is folded into a machine instruction or; otherwise transformed into a non-register, the variable location becomes; unavailable. Locations that are unavailable are treated as if they have been optimized out:; in IR the location would be assigned ``undef`` by a debug intrinsic, and in MIR; the equivalent location is used. After MIR locations are assigned to each variable, machine pseudo-instructions; corresponding to each ``llvm.dbg.value`` intrinsic are inserted. There are two; forms of this type of instruction. The first form, ``DBG_VALUE``, appears thus:. .. code-block:: text. DBG_VALUE %1, $noreg, !123, !DIExpression(). And has the following operands:; * The first operand can record the variable location as a register,; a frame index, an immediate, or the base address register if the original; debug intrinsic referred to memory. ``$noreg`` indicates the variable; location is undefined, equivalent to an ``undef`` dbg.value operand.; * The type of the second operand indicates whether the variable location is; directly referred to by the DBG_VALUE, or whether it is indirect. The; ``$noreg`` register signifies the former, an immediate operand (0) the; latter.; * Operand 3 is the Variable field of the original debug intrinsic.; * Operand 4 is the Expression field of the original debug intrinsic. The second form, ``DBG_VALUE_LIST``, appears thus:. .. code-block:: text. DBG_VALUE_LIST !123, !DIExpression(DW_OP_LLVM_arg, 0, DW_OP_LLVM_arg, 1, DW_OP_plus), %1, %2. And has the following operands:; * The first operand is the Variable field of the original debug intrinsic.; * The second operand is the Expression field of the original debug intrinsic.; * Any number of operands, from the 3rd onwards, record a sequence ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:27557,Modifiability,variab,variable,27557,"metadata is allocated a virtual register, that virtual register is used as the; variable location. If the SDNode is folded into a machine instruction or; otherwise transformed into a non-register, the variable location becomes; unavailable. Locations that are unavailable are treated as if they have been optimized out:; in IR the location would be assigned ``undef`` by a debug intrinsic, and in MIR; the equivalent location is used. After MIR locations are assigned to each variable, machine pseudo-instructions; corresponding to each ``llvm.dbg.value`` intrinsic are inserted. There are two; forms of this type of instruction. The first form, ``DBG_VALUE``, appears thus:. .. code-block:: text. DBG_VALUE %1, $noreg, !123, !DIExpression(). And has the following operands:; * The first operand can record the variable location as a register,; a frame index, an immediate, or the base address register if the original; debug intrinsic referred to memory. ``$noreg`` indicates the variable; location is undefined, equivalent to an ``undef`` dbg.value operand.; * The type of the second operand indicates whether the variable location is; directly referred to by the DBG_VALUE, or whether it is indirect. The; ``$noreg`` register signifies the former, an immediate operand (0) the; latter.; * Operand 3 is the Variable field of the original debug intrinsic.; * Operand 4 is the Expression field of the original debug intrinsic. The second form, ``DBG_VALUE_LIST``, appears thus:. .. code-block:: text. DBG_VALUE_LIST !123, !DIExpression(DW_OP_LLVM_arg, 0, DW_OP_LLVM_arg, 1, DW_OP_plus), %1, %2. And has the following operands:; * The first operand is the Variable field of the original debug intrinsic.; * The second operand is the Expression field of the original debug intrinsic.; * Any number of operands, from the 3rd onwards, record a sequence of variable; location operands, which may take any of the same values as the first; operand of the ``DBG_VALUE`` instruction above. These variable loca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:27692,Modifiability,variab,variable,27692,"achine instruction or; otherwise transformed into a non-register, the variable location becomes; unavailable. Locations that are unavailable are treated as if they have been optimized out:; in IR the location would be assigned ``undef`` by a debug intrinsic, and in MIR; the equivalent location is used. After MIR locations are assigned to each variable, machine pseudo-instructions; corresponding to each ``llvm.dbg.value`` intrinsic are inserted. There are two; forms of this type of instruction. The first form, ``DBG_VALUE``, appears thus:. .. code-block:: text. DBG_VALUE %1, $noreg, !123, !DIExpression(). And has the following operands:; * The first operand can record the variable location as a register,; a frame index, an immediate, or the base address register if the original; debug intrinsic referred to memory. ``$noreg`` indicates the variable; location is undefined, equivalent to an ``undef`` dbg.value operand.; * The type of the second operand indicates whether the variable location is; directly referred to by the DBG_VALUE, or whether it is indirect. The; ``$noreg`` register signifies the former, an immediate operand (0) the; latter.; * Operand 3 is the Variable field of the original debug intrinsic.; * Operand 4 is the Expression field of the original debug intrinsic. The second form, ``DBG_VALUE_LIST``, appears thus:. .. code-block:: text. DBG_VALUE_LIST !123, !DIExpression(DW_OP_LLVM_arg, 0, DW_OP_LLVM_arg, 1, DW_OP_plus), %1, %2. And has the following operands:; * The first operand is the Variable field of the original debug intrinsic.; * The second operand is the Expression field of the original debug intrinsic.; * Any number of operands, from the 3rd onwards, record a sequence of variable; location operands, which may take any of the same values as the first; operand of the ``DBG_VALUE`` instruction above. These variable location; operands are inserted into the final DWARF Expression in positions indicated; by the DW_OP_LLVM_arg operator in the `DIExpres",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:28428,Modifiability,variab,variable,28428," base address register if the original; debug intrinsic referred to memory. ``$noreg`` indicates the variable; location is undefined, equivalent to an ``undef`` dbg.value operand.; * The type of the second operand indicates whether the variable location is; directly referred to by the DBG_VALUE, or whether it is indirect. The; ``$noreg`` register signifies the former, an immediate operand (0) the; latter.; * Operand 3 is the Variable field of the original debug intrinsic.; * Operand 4 is the Expression field of the original debug intrinsic. The second form, ``DBG_VALUE_LIST``, appears thus:. .. code-block:: text. DBG_VALUE_LIST !123, !DIExpression(DW_OP_LLVM_arg, 0, DW_OP_LLVM_arg, 1, DW_OP_plus), %1, %2. And has the following operands:; * The first operand is the Variable field of the original debug intrinsic.; * The second operand is the Expression field of the original debug intrinsic.; * Any number of operands, from the 3rd onwards, record a sequence of variable; location operands, which may take any of the same values as the first; operand of the ``DBG_VALUE`` instruction above. These variable location; operands are inserted into the final DWARF Expression in positions indicated; by the DW_OP_LLVM_arg operator in the `DIExpression; <LangRef.html#diexpression>`_. The position at which the DBG_VALUEs are inserted should correspond to the; positions of their matching ``llvm.dbg.value`` intrinsics in the IR block. As; with optimization, LLVM aims to preserve the order in which variable; assignments occurred in the source program. However SelectionDAG performs some; instruction scheduling, which can reorder assignments (discussed below).; Function parameter locations are moved to the beginning of the function if; they're not already, to ensure they're immediately available on function entry. To demonstrate variable locations during instruction selection, consider; the following example:. .. code-block:: llvm. define i32 @foo(i32* %addr) {; entry:; call void @llvm.dbg",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:28563,Modifiability,variab,variable,28563,"The type of the second operand indicates whether the variable location is; directly referred to by the DBG_VALUE, or whether it is indirect. The; ``$noreg`` register signifies the former, an immediate operand (0) the; latter.; * Operand 3 is the Variable field of the original debug intrinsic.; * Operand 4 is the Expression field of the original debug intrinsic. The second form, ``DBG_VALUE_LIST``, appears thus:. .. code-block:: text. DBG_VALUE_LIST !123, !DIExpression(DW_OP_LLVM_arg, 0, DW_OP_LLVM_arg, 1, DW_OP_plus), %1, %2. And has the following operands:; * The first operand is the Variable field of the original debug intrinsic.; * The second operand is the Expression field of the original debug intrinsic.; * Any number of operands, from the 3rd onwards, record a sequence of variable; location operands, which may take any of the same values as the first; operand of the ``DBG_VALUE`` instruction above. These variable location; operands are inserted into the final DWARF Expression in positions indicated; by the DW_OP_LLVM_arg operator in the `DIExpression; <LangRef.html#diexpression>`_. The position at which the DBG_VALUEs are inserted should correspond to the; positions of their matching ``llvm.dbg.value`` intrinsics in the IR block. As; with optimization, LLVM aims to preserve the order in which variable; assignments occurred in the source program. However SelectionDAG performs some; instruction scheduling, which can reorder assignments (discussed below).; Function parameter locations are moved to the beginning of the function if; they're not already, to ensure they're immediately available on function entry. To demonstrate variable locations during instruction selection, consider; the following example:. .. code-block:: llvm. define i32 @foo(i32* %addr) {; entry:; call void @llvm.dbg.value(metadata i32 0, metadata !3, metadata !DIExpression()), !dbg !5; br label %bb1, !dbg !5. bb1: ; preds = %bb1, %entry; %bar.0 = phi i32 [ 0, %entry ], [ %add, %bb1 ]; call void",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:28959,Modifiability,variab,variable,28959,"Expression field of the original debug intrinsic. The second form, ``DBG_VALUE_LIST``, appears thus:. .. code-block:: text. DBG_VALUE_LIST !123, !DIExpression(DW_OP_LLVM_arg, 0, DW_OP_LLVM_arg, 1, DW_OP_plus), %1, %2. And has the following operands:; * The first operand is the Variable field of the original debug intrinsic.; * The second operand is the Expression field of the original debug intrinsic.; * Any number of operands, from the 3rd onwards, record a sequence of variable; location operands, which may take any of the same values as the first; operand of the ``DBG_VALUE`` instruction above. These variable location; operands are inserted into the final DWARF Expression in positions indicated; by the DW_OP_LLVM_arg operator in the `DIExpression; <LangRef.html#diexpression>`_. The position at which the DBG_VALUEs are inserted should correspond to the; positions of their matching ``llvm.dbg.value`` intrinsics in the IR block. As; with optimization, LLVM aims to preserve the order in which variable; assignments occurred in the source program. However SelectionDAG performs some; instruction scheduling, which can reorder assignments (discussed below).; Function parameter locations are moved to the beginning of the function if; they're not already, to ensure they're immediately available on function entry. To demonstrate variable locations during instruction selection, consider; the following example:. .. code-block:: llvm. define i32 @foo(i32* %addr) {; entry:; call void @llvm.dbg.value(metadata i32 0, metadata !3, metadata !DIExpression()), !dbg !5; br label %bb1, !dbg !5. bb1: ; preds = %bb1, %entry; %bar.0 = phi i32 [ 0, %entry ], [ %add, %bb1 ]; call void @llvm.dbg.value(metadata i32 %bar.0, metadata !3, metadata !DIExpression()), !dbg !5; %addr1 = getelementptr i32, i32 *%addr, i32 1, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr1, metadata !3, metadata !DIExpression()), !dbg !5; %loaded1 = load i32, i32* %addr1, !dbg !5; %addr2 = getelementptr i32, i32",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:29294,Modifiability,variab,variable,29294," the original debug intrinsic.; * Any number of operands, from the 3rd onwards, record a sequence of variable; location operands, which may take any of the same values as the first; operand of the ``DBG_VALUE`` instruction above. These variable location; operands are inserted into the final DWARF Expression in positions indicated; by the DW_OP_LLVM_arg operator in the `DIExpression; <LangRef.html#diexpression>`_. The position at which the DBG_VALUEs are inserted should correspond to the; positions of their matching ``llvm.dbg.value`` intrinsics in the IR block. As; with optimization, LLVM aims to preserve the order in which variable; assignments occurred in the source program. However SelectionDAG performs some; instruction scheduling, which can reorder assignments (discussed below).; Function parameter locations are moved to the beginning of the function if; they're not already, to ensure they're immediately available on function entry. To demonstrate variable locations during instruction selection, consider; the following example:. .. code-block:: llvm. define i32 @foo(i32* %addr) {; entry:; call void @llvm.dbg.value(metadata i32 0, metadata !3, metadata !DIExpression()), !dbg !5; br label %bb1, !dbg !5. bb1: ; preds = %bb1, %entry; %bar.0 = phi i32 [ 0, %entry ], [ %add, %bb1 ]; call void @llvm.dbg.value(metadata i32 %bar.0, metadata !3, metadata !DIExpression()), !dbg !5; %addr1 = getelementptr i32, i32 *%addr, i32 1, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr1, metadata !3, metadata !DIExpression()), !dbg !5; %loaded1 = load i32, i32* %addr1, !dbg !5; %addr2 = getelementptr i32, i32 *%addr, i32 %bar.0, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr2, metadata !3, metadata !DIExpression()), !dbg !5; %loaded2 = load i32, i32* %addr2, !dbg !5; %add = add i32 %bar.0, 1, !dbg !5; call void @llvm.dbg.value(metadata i32 %add, metadata !3, metadata !DIExpression()), !dbg !5; %added = add i32 %loaded1, %loaded2; %cond = icmp ult i32 %added, %bar.0, !",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:31960,Modifiability,variab,variable,31960,"2, $noreg, !3, !DIExpression(DW_OP_plus_uconst, 4, DW_OP_stack_value), debug-location !5; %4:gr32 = MOV32rm %2, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); %5:gr64_nosp = MOVSX64rr32 %0, debug-location !5; DBG_VALUE $noreg, $noreg, !3, !DIExpression(), debug-location !5; %1:gr32 = INC32r %0, implicit-def dead $eflags, debug-location !5; DBG_VALUE %1, $noreg, !3, !DIExpression(), debug-location !5; %6:gr32 = ADD32rm %4, %2, 4, killed %5, 0, $noreg, implicit-def dead $eflags :: (load 4 from %ir.addr2); %7:gr32 = SUB32rr %6, %0, implicit-def $eflags, debug-location !5; JB_1 %bb.1, implicit $eflags, debug-location !5; JMP_1 %bb.2, debug-location !5. bb.2.bb2:; %8:gr32 = MOV32r0 implicit-def dead $eflags; $eax = COPY %8, debug-location !5; RET 0, $eax, debug-location !5. Observe first that there is a DBG_VALUE instruction for every ``llvm.dbg.value``; intrinsic in the source IR, ensuring no source level assignments go missing.; Then consider the different ways in which variable locations have been recorded:. * For the first dbg.value an immediate operand is used to record a zero value.; * The dbg.value of the PHI instruction leads to a DBG_VALUE of virtual register; ``%0``.; * The first GEP has its effect folded into the first load instruction; (as a 4-byte offset), but the variable location is salvaged by folding; the GEPs effect into the DIExpression.; * The second GEP is also folded into the corresponding load. However, it is; insufficiently simple to be salvaged, and is emitted as a ``$noreg``; DBG_VALUE, indicating that the variable takes on an undefined location.; * The final dbg.value has its Value placed in virtual register ``%1``. Instruction Scheduling; ----------------------. A number of passes can reschedule instructions, notably instruction selection; and the pre-and-post RA machine schedulers. Instruction scheduling can; significantly change the nature of the program -- in the (very unlikely) worst; case the instruction sequence could",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:32271,Modifiability,variab,variable,32271,"2 = INC32r %0, implicit-def dead $eflags, debug-location !5; DBG_VALUE %1, $noreg, !3, !DIExpression(), debug-location !5; %6:gr32 = ADD32rm %4, %2, 4, killed %5, 0, $noreg, implicit-def dead $eflags :: (load 4 from %ir.addr2); %7:gr32 = SUB32rr %6, %0, implicit-def $eflags, debug-location !5; JB_1 %bb.1, implicit $eflags, debug-location !5; JMP_1 %bb.2, debug-location !5. bb.2.bb2:; %8:gr32 = MOV32r0 implicit-def dead $eflags; $eax = COPY %8, debug-location !5; RET 0, $eax, debug-location !5. Observe first that there is a DBG_VALUE instruction for every ``llvm.dbg.value``; intrinsic in the source IR, ensuring no source level assignments go missing.; Then consider the different ways in which variable locations have been recorded:. * For the first dbg.value an immediate operand is used to record a zero value.; * The dbg.value of the PHI instruction leads to a DBG_VALUE of virtual register; ``%0``.; * The first GEP has its effect folded into the first load instruction; (as a 4-byte offset), but the variable location is salvaged by folding; the GEPs effect into the DIExpression.; * The second GEP is also folded into the corresponding load. However, it is; insufficiently simple to be salvaged, and is emitted as a ``$noreg``; DBG_VALUE, indicating that the variable takes on an undefined location.; * The final dbg.value has its Value placed in virtual register ``%1``. Instruction Scheduling; ----------------------. A number of passes can reschedule instructions, notably instruction selection; and the pre-and-post RA machine schedulers. Instruction scheduling can; significantly change the nature of the program -- in the (very unlikely) worst; case the instruction sequence could be completely reversed. In such; circumstances LLVM follows the principle applied to optimizations, that it is; better for the debugger not to display any state than a misleading state.; Thus, whenever instructions are advanced in order of execution, any; corresponding DBG_VALUE is kept in its origin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:32531,Modifiability,variab,variable,32531,"32 = SUB32rr %6, %0, implicit-def $eflags, debug-location !5; JB_1 %bb.1, implicit $eflags, debug-location !5; JMP_1 %bb.2, debug-location !5. bb.2.bb2:; %8:gr32 = MOV32r0 implicit-def dead $eflags; $eax = COPY %8, debug-location !5; RET 0, $eax, debug-location !5. Observe first that there is a DBG_VALUE instruction for every ``llvm.dbg.value``; intrinsic in the source IR, ensuring no source level assignments go missing.; Then consider the different ways in which variable locations have been recorded:. * For the first dbg.value an immediate operand is used to record a zero value.; * The dbg.value of the PHI instruction leads to a DBG_VALUE of virtual register; ``%0``.; * The first GEP has its effect folded into the first load instruction; (as a 4-byte offset), but the variable location is salvaged by folding; the GEPs effect into the DIExpression.; * The second GEP is also folded into the corresponding load. However, it is; insufficiently simple to be salvaged, and is emitted as a ``$noreg``; DBG_VALUE, indicating that the variable takes on an undefined location.; * The final dbg.value has its Value placed in virtual register ``%1``. Instruction Scheduling; ----------------------. A number of passes can reschedule instructions, notably instruction selection; and the pre-and-post RA machine schedulers. Instruction scheduling can; significantly change the nature of the program -- in the (very unlikely) worst; case the instruction sequence could be completely reversed. In such; circumstances LLVM follows the principle applied to optimizations, that it is; better for the debugger not to display any state than a misleading state.; Thus, whenever instructions are advanced in order of execution, any; corresponding DBG_VALUE is kept in its original position, and if an instruction; is delayed then the variable is given an undefined location for the duration; of the delay. To illustrate, consider this pseudo-MIR:. .. code-block:: text. %1:gr32 = MOV32rm %0, 1, $noreg, 4, $nor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:33316,Modifiability,variab,variable,33316,"t the variable location is salvaged by folding; the GEPs effect into the DIExpression.; * The second GEP is also folded into the corresponding load. However, it is; insufficiently simple to be salvaged, and is emitted as a ``$noreg``; DBG_VALUE, indicating that the variable takes on an undefined location.; * The final dbg.value has its Value placed in virtual register ``%1``. Instruction Scheduling; ----------------------. A number of passes can reschedule instructions, notably instruction selection; and the pre-and-post RA machine schedulers. Instruction scheduling can; significantly change the nature of the program -- in the (very unlikely) worst; case the instruction sequence could be completely reversed. In such; circumstances LLVM follows the principle applied to optimizations, that it is; better for the debugger not to display any state than a misleading state.; Thus, whenever instructions are advanced in order of execution, any; corresponding DBG_VALUE is kept in its original position, and if an instruction; is delayed then the variable is given an undefined location for the duration; of the delay. To illustrate, consider this pseudo-MIR:. .. code-block:: text. %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6. Imagine that the SUB32rr were moved forward to give us the following MIR:. .. code-block:: text. %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; DBG_VALUE %7, $noreg, !5, !6. In this circumstance LLVM would leave the MIR as shown above. Were we to move; the DBG_VALUE of virtual register %7 upwards with the SUB32rr, we ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:34417,Modifiability,variab,variable,34417,"s pseudo-MIR:. .. code-block:: text. %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6. Imagine that the SUB32rr were moved forward to give us the following MIR:. .. code-block:: text. %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; DBG_VALUE %7, $noreg, !5, !6. In this circumstance LLVM would leave the MIR as shown above. Were we to move; the DBG_VALUE of virtual register %7 upwards with the SUB32rr, we would re-order; assignments and introduce a new state of the program. Whereas with the solution; above, the debugger will see one fewer combination of variable values, because; ``!3`` and ``!5`` will change value at the same time. This is preferred over; misrepresenting the original program. In comparison, if one sunk the MOV32rm, LLVM would produce the following:. .. code-block:: text. DBG_VALUE $noreg, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2. Here, to avoid presenting a state in which the first assignment to ``!1``; disappears, the DBG_VALUE at the top of the block assigns the variable the; undefined location, until its value is available at the end of the block where; an additional DBG_VALUE is added. Were any other DBG_VALUE for ``!1`` to occur; in the instructions that the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never obser",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:35113,Modifiability,variab,variable,35113,"oreg, !5, !6. In this circumstance LLVM would leave the MIR as shown above. Were we to move; the DBG_VALUE of virtual register %7 upwards with the SUB32rr, we would re-order; assignments and introduce a new state of the program. Whereas with the solution; above, the debugger will see one fewer combination of variable values, because; ``!3`` and ``!5`` will change value at the same time. This is preferred over; misrepresenting the original program. In comparison, if one sunk the MOV32rm, LLVM would produce the following:. .. code-block:: text. DBG_VALUE $noreg, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2. Here, to avoid presenting a state in which the first assignment to ``!1``; disappears, the DBG_VALUE at the top of the block assigns the variable the; undefined location, until its value is available at the end of the block where; an additional DBG_VALUE is added. Were any other DBG_VALUE for ``!1`` to occur; in the instructions that the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:35429,Modifiability,variab,variable,35429,"reas with the solution; above, the debugger will see one fewer combination of variable values, because; ``!3`` and ``!5`` will change value at the same time. This is preferred over; misrepresenting the original program. In comparison, if one sunk the MOV32rm, LLVM would produce the following:. .. code-block:: text. DBG_VALUE $noreg, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2. Here, to avoid presenting a state in which the first assignment to ``!1``; disappears, the DBG_VALUE at the top of the block assigns the variable the; undefined location, until its value is available at the end of the block where; an additional DBG_VALUE is added. Were any other DBG_VALUE for ``!1`` to occur; in the instructions that the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:35757,Modifiability,variab,variable,35757,"LUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2. Here, to avoid presenting a state in which the first assignment to ``!1``; disappears, the DBG_VALUE at the top of the block assigns the variable the; undefined location, until its value is available at the end of the block where; an additional DBG_VALUE is added. Were any other DBG_VALUE for ``!1`` to occur; in the instructions that the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:36137,Modifiability,variab,variable,36137," of the block where; an additional DBG_VALUE is added. Were any other DBG_VALUE for ``!1`` to occur; in the instructions that the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; corresponding to a source-level assignment where the variable may change value,; it asserts the location of a variable in a block, and loses effect outside the; block. Propagating variable locations through copies and spills is; straightforwards: determining the variable location in every basic block; requires t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:36465,Modifiability,variab,variable,36465,"ot available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; corresponding to a source-level assignment where the variable may change value,; it asserts the location of a variable in a block, and loses effect outside the; block. Propagating variable locations through copies and spills is; straightforwards: determining the variable location in every basic block; requires the consideration of control flow. Consider the following IR, which; presents several difficulties:. .. code-block:: text. define dso_local i32 @foo(i1 %cond, i32 %input) !dbg !12 {; entry:; br i1 %cond, label %truebr, label %falsebr. bb1:; %value = phi i32 [ %value1, %truebr ], [ %value2, %falsebr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:36680,Modifiability,variab,variables,36680,"LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; corresponding to a source-level assignment where the variable may change value,; it asserts the location of a variable in a block, and loses effect outside the; block. Propagating variable locations through copies and spills is; straightforwards: determining the variable location in every basic block; requires the consideration of control flow. Consider the following IR, which; presents several difficulties:. .. code-block:: text. define dso_local i32 @foo(i1 %cond, i32 %input) !dbg !12 {; entry:; br i1 %cond, label %truebr, label %falsebr. bb1:; %value = phi i32 [ %value1, %truebr ], [ %value2, %falsebr ]; br label %exit, !dbg !26. truebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 1, metadata !23, metadata !DIExpression()), !dbg !24; %value1 = ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:36768,Modifiability,variab,variable,36768,"LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; corresponding to a source-level assignment where the variable may change value,; it asserts the location of a variable in a block, and loses effect outside the; block. Propagating variable locations through copies and spills is; straightforwards: determining the variable location in every basic block; requires the consideration of control flow. Consider the following IR, which; presents several difficulties:. .. code-block:: text. define dso_local i32 @foo(i1 %cond, i32 %input) !dbg !12 {; entry:; br i1 %cond, label %truebr, label %falsebr. bb1:; %value = phi i32 [ %value1, %truebr ], [ %value2, %falsebr ]; br label %exit, !dbg !26. truebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 1, metadata !23, metadata !DIExpression()), !dbg !24; %value1 = ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:36926,Modifiability,variab,variable,36926,"gister allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; corresponding to a source-level assignment where the variable may change value,; it asserts the location of a variable in a block, and loses effect outside the; block. Propagating variable locations through copies and spills is; straightforwards: determining the variable location in every basic block; requires the consideration of control flow. Consider the following IR, which; presents several difficulties:. .. code-block:: text. define dso_local i32 @foo(i1 %cond, i32 %input) !dbg !12 {; entry:; br i1 %cond, label %truebr, label %falsebr. bb1:; %value = phi i32 [ %value1, %truebr ], [ %value2, %falsebr ]; br label %exit, !dbg !26. truebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 1, metadata !23, metadata !DIExpression()), !dbg !24; %value1 = add i32 %input, 1; br label %bb1. falsebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 2, metadata !23",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:36983,Modifiability,variab,variable,36983,"gister allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; corresponding to a source-level assignment where the variable may change value,; it asserts the location of a variable in a block, and loses effect outside the; block. Propagating variable locations through copies and spills is; straightforwards: determining the variable location in every basic block; requires the consideration of control flow. Consider the following IR, which; presents several difficulties:. .. code-block:: text. define dso_local i32 @foo(i1 %cond, i32 %input) !dbg !12 {; entry:; br i1 %cond, label %truebr, label %falsebr. bb1:; %value = phi i32 [ %value1, %truebr ], [ %value2, %falsebr ]; br label %exit, !dbg !26. truebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 1, metadata !23, metadata !DIExpression()), !dbg !24; %value1 = add i32 %input, 1; br label %bb1. falsebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 2, metadata !23",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:37053,Modifiability,variab,variable,37053,"correct variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; corresponding to a source-level assignment where the variable may change value,; it asserts the location of a variable in a block, and loses effect outside the; block. Propagating variable locations through copies and spills is; straightforwards: determining the variable location in every basic block; requires the consideration of control flow. Consider the following IR, which; presents several difficulties:. .. code-block:: text. define dso_local i32 @foo(i1 %cond, i32 %input) !dbg !12 {; entry:; br i1 %cond, label %truebr, label %falsebr. bb1:; %value = phi i32 [ %value1, %truebr ], [ %value2, %falsebr ]; br label %exit, !dbg !26. truebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 1, metadata !23, metadata !DIExpression()), !dbg !24; %value1 = add i32 %input, 1; br label %bb1. falsebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 2, metadata !23, metadata !DIExpression()), !dbg !24; %value2 = add i32 %input, 2; br label %bb1. exit:; ret i32 %value, !dbg !30; }. Here the difficulties are:. * The control flow is roughly the opposite of basic block order",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:37136,Modifiability,variab,variable,37136,"correct variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; corresponding to a source-level assignment where the variable may change value,; it asserts the location of a variable in a block, and loses effect outside the; block. Propagating variable locations through copies and spills is; straightforwards: determining the variable location in every basic block; requires the consideration of control flow. Consider the following IR, which; presents several difficulties:. .. code-block:: text. define dso_local i32 @foo(i1 %cond, i32 %input) !dbg !12 {; entry:; br i1 %cond, label %truebr, label %falsebr. bb1:; %value = phi i32 [ %value1, %truebr ], [ %value2, %falsebr ]; br label %exit, !dbg !26. truebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 1, metadata !23, metadata !DIExpression()), !dbg !24; %value1 = add i32 %input, 1; br label %bb1. falsebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 2, metadata !23, metadata !DIExpression()), !dbg !24; %value2 = add i32 %input, 2; br label %bb1. exit:; ret i32 %value, !dbg !30; }. Here the difficulties are:. * The control flow is roughly the opposite of basic block order",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:38159,Modifiability,variab,variable,38159,"ble location in every basic block; requires the consideration of control flow. Consider the following IR, which; presents several difficulties:. .. code-block:: text. define dso_local i32 @foo(i1 %cond, i32 %input) !dbg !12 {; entry:; br i1 %cond, label %truebr, label %falsebr. bb1:; %value = phi i32 [ %value1, %truebr ], [ %value2, %falsebr ]; br label %exit, !dbg !26. truebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 1, metadata !23, metadata !DIExpression()), !dbg !24; %value1 = add i32 %input, 1; br label %bb1. falsebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 2, metadata !23, metadata !DIExpression()), !dbg !24; %value2 = add i32 %input, 2; br label %bb1. exit:; ret i32 %value, !dbg !30; }. Here the difficulties are:. * The control flow is roughly the opposite of basic block order; * The value of the ``!23`` variable merges into ``%bb1``, but there is no PHI; node. As mentioned above, the ``llvm.dbg.value`` intrinsics essentially form an; imperative program embedded in the IR, with each intrinsic defining a variable; location. This *could* be converted to an SSA form by mem2reg, in the same way; that it uses use-def chains to identify control flow merges and insert phi; nodes for IR Values. However, because debug variable locations are defined for; every machine instruction, in effect every IR instruction uses every variable; location, which would lead to a large number of debugging intrinsics being; generated. Examining the example above, variable ``!30`` is assigned ``%input`` on both; conditional paths through the function, while ``!23`` is assigned differing; constant values on either path. Where control flow merges in ``%bb1`` we would; want ``!30`` to keep its location (``%input``), but ``!23`` to become undefined; as we cannot determine at runtime what value it sho",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:38362,Modifiability,variab,variable,38362,"so_local i32 @foo(i1 %cond, i32 %input) !dbg !12 {; entry:; br i1 %cond, label %truebr, label %falsebr. bb1:; %value = phi i32 [ %value1, %truebr ], [ %value2, %falsebr ]; br label %exit, !dbg !26. truebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 1, metadata !23, metadata !DIExpression()), !dbg !24; %value1 = add i32 %input, 1; br label %bb1. falsebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 2, metadata !23, metadata !DIExpression()), !dbg !24; %value2 = add i32 %input, 2; br label %bb1. exit:; ret i32 %value, !dbg !30; }. Here the difficulties are:. * The control flow is roughly the opposite of basic block order; * The value of the ``!23`` variable merges into ``%bb1``, but there is no PHI; node. As mentioned above, the ``llvm.dbg.value`` intrinsics essentially form an; imperative program embedded in the IR, with each intrinsic defining a variable; location. This *could* be converted to an SSA form by mem2reg, in the same way; that it uses use-def chains to identify control flow merges and insert phi; nodes for IR Values. However, because debug variable locations are defined for; every machine instruction, in effect every IR instruction uses every variable; location, which would lead to a large number of debugging intrinsics being; generated. Examining the example above, variable ``!30`` is assigned ``%input`` on both; conditional paths through the function, while ``!23`` is assigned differing; constant values on either path. Where control flow merges in ``%bb1`` we would; want ``!30`` to keep its location (``%input``), but ``!23`` to become undefined; as we cannot determine at runtime what value it should have in %bb1 without; inserting a PHI node. mem2reg does not insert the PHI node to avoid changing; codegen when debugging is enabled, and does not insert the other dbg.val",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:38572,Modifiability,variab,variable,38572,"1, metadata !23, metadata !DIExpression()), !dbg !24; %value1 = add i32 %input, 1; br label %bb1. falsebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 2, metadata !23, metadata !DIExpression()), !dbg !24; %value2 = add i32 %input, 2; br label %bb1. exit:; ret i32 %value, !dbg !30; }. Here the difficulties are:. * The control flow is roughly the opposite of basic block order; * The value of the ``!23`` variable merges into ``%bb1``, but there is no PHI; node. As mentioned above, the ``llvm.dbg.value`` intrinsics essentially form an; imperative program embedded in the IR, with each intrinsic defining a variable; location. This *could* be converted to an SSA form by mem2reg, in the same way; that it uses use-def chains to identify control flow merges and insert phi; nodes for IR Values. However, because debug variable locations are defined for; every machine instruction, in effect every IR instruction uses every variable; location, which would lead to a large number of debugging intrinsics being; generated. Examining the example above, variable ``!30`` is assigned ``%input`` on both; conditional paths through the function, while ``!23`` is assigned differing; constant values on either path. Where control flow merges in ``%bb1`` we would; want ``!30`` to keep its location (``%input``), but ``!23`` to become undefined; as we cannot determine at runtime what value it should have in %bb1 without; inserting a PHI node. mem2reg does not insert the PHI node to avoid changing; codegen when debugging is enabled, and does not insert the other dbg.values; to avoid adding very large numbers of intrinsics. Instead, LiveDebugValues determines variable locations when control; flow merges. A dataflow analysis is used to propagate locations between blocks:; when control flow merges, if a variable has the same location in all; predecessors then that location is propagated into the successor. If ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:38677,Modifiability,variab,variable,38677,"1, metadata !23, metadata !DIExpression()), !dbg !24; %value1 = add i32 %input, 1; br label %bb1. falsebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 2, metadata !23, metadata !DIExpression()), !dbg !24; %value2 = add i32 %input, 2; br label %bb1. exit:; ret i32 %value, !dbg !30; }. Here the difficulties are:. * The control flow is roughly the opposite of basic block order; * The value of the ``!23`` variable merges into ``%bb1``, but there is no PHI; node. As mentioned above, the ``llvm.dbg.value`` intrinsics essentially form an; imperative program embedded in the IR, with each intrinsic defining a variable; location. This *could* be converted to an SSA form by mem2reg, in the same way; that it uses use-def chains to identify control flow merges and insert phi; nodes for IR Values. However, because debug variable locations are defined for; every machine instruction, in effect every IR instruction uses every variable; location, which would lead to a large number of debugging intrinsics being; generated. Examining the example above, variable ``!30`` is assigned ``%input`` on both; conditional paths through the function, while ``!23`` is assigned differing; constant values on either path. Where control flow merges in ``%bb1`` we would; want ``!30`` to keep its location (``%input``), but ``!23`` to become undefined; as we cannot determine at runtime what value it should have in %bb1 without; inserting a PHI node. mem2reg does not insert the PHI node to avoid changing; codegen when debugging is enabled, and does not insert the other dbg.values; to avoid adding very large numbers of intrinsics. Instead, LiveDebugValues determines variable locations when control; flow merges. A dataflow analysis is used to propagate locations between blocks:; when control flow merges, if a variable has the same location in all; predecessors then that location is propagated into the successor. If ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:38803,Modifiability,variab,variable,38803,"call void @llvm.dbg.value(metadata i32 2, metadata !23, metadata !DIExpression()), !dbg !24; %value2 = add i32 %input, 2; br label %bb1. exit:; ret i32 %value, !dbg !30; }. Here the difficulties are:. * The control flow is roughly the opposite of basic block order; * The value of the ``!23`` variable merges into ``%bb1``, but there is no PHI; node. As mentioned above, the ``llvm.dbg.value`` intrinsics essentially form an; imperative program embedded in the IR, with each intrinsic defining a variable; location. This *could* be converted to an SSA form by mem2reg, in the same way; that it uses use-def chains to identify control flow merges and insert phi; nodes for IR Values. However, because debug variable locations are defined for; every machine instruction, in effect every IR instruction uses every variable; location, which would lead to a large number of debugging intrinsics being; generated. Examining the example above, variable ``!30`` is assigned ``%input`` on both; conditional paths through the function, while ``!23`` is assigned differing; constant values on either path. Where control flow merges in ``%bb1`` we would; want ``!30`` to keep its location (``%input``), but ``!23`` to become undefined; as we cannot determine at runtime what value it should have in %bb1 without; inserting a PHI node. mem2reg does not insert the PHI node to avoid changing; codegen when debugging is enabled, and does not insert the other dbg.values; to avoid adding very large numbers of intrinsics. Instead, LiveDebugValues determines variable locations when control; flow merges. A dataflow analysis is used to propagate locations between blocks:; when control flow merges, if a variable has the same location in all; predecessors then that location is propagated into the successor. If the; predecessor locations disagree, the location becomes undefined. Once LiveDebugValues has run, every block should have all valid variable; locations described by DBG_VALUE instructions within the block.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:39408,Modifiability,variab,variable,39408,"n SSA form by mem2reg, in the same way; that it uses use-def chains to identify control flow merges and insert phi; nodes for IR Values. However, because debug variable locations are defined for; every machine instruction, in effect every IR instruction uses every variable; location, which would lead to a large number of debugging intrinsics being; generated. Examining the example above, variable ``!30`` is assigned ``%input`` on both; conditional paths through the function, while ``!23`` is assigned differing; constant values on either path. Where control flow merges in ``%bb1`` we would; want ``!30`` to keep its location (``%input``), but ``!23`` to become undefined; as we cannot determine at runtime what value it should have in %bb1 without; inserting a PHI node. mem2reg does not insert the PHI node to avoid changing; codegen when debugging is enabled, and does not insert the other dbg.values; to avoid adding very large numbers of intrinsics. Instead, LiveDebugValues determines variable locations when control; flow merges. A dataflow analysis is used to propagate locations between blocks:; when control flow merges, if a variable has the same location in all; predecessors then that location is propagated into the successor. If the; predecessor locations disagree, the location becomes undefined. Once LiveDebugValues has run, every block should have all valid variable; locations described by DBG_VALUE instructions within the block. Very little; effort is then required by supporting classes (such as; DbgEntityHistoryCalculator) to build a map of each instruction to every; valid variable location, without the need to consider control flow. From; the example above, it is otherwise difficult to determine that the location; of variable ``!30`` should flow ""up"" into block ``%bb1``, but that the location; of variable ``!23`` should not flow ""down"" into the ``%exit`` block. .. _ccxx_frontend:. C/C++ front-end specific debug information; =====================================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:39553,Modifiability,variab,variable,39553,"r, because debug variable locations are defined for; every machine instruction, in effect every IR instruction uses every variable; location, which would lead to a large number of debugging intrinsics being; generated. Examining the example above, variable ``!30`` is assigned ``%input`` on both; conditional paths through the function, while ``!23`` is assigned differing; constant values on either path. Where control flow merges in ``%bb1`` we would; want ``!30`` to keep its location (``%input``), but ``!23`` to become undefined; as we cannot determine at runtime what value it should have in %bb1 without; inserting a PHI node. mem2reg does not insert the PHI node to avoid changing; codegen when debugging is enabled, and does not insert the other dbg.values; to avoid adding very large numbers of intrinsics. Instead, LiveDebugValues determines variable locations when control; flow merges. A dataflow analysis is used to propagate locations between blocks:; when control flow merges, if a variable has the same location in all; predecessors then that location is propagated into the successor. If the; predecessor locations disagree, the location becomes undefined. Once LiveDebugValues has run, every block should have all valid variable; locations described by DBG_VALUE instructions within the block. Very little; effort is then required by supporting classes (such as; DbgEntityHistoryCalculator) to build a map of each instruction to every; valid variable location, without the need to consider control flow. From; the example above, it is otherwise difficult to determine that the location; of variable ``!30`` should flow ""up"" into block ``%bb1``, but that the location; of variable ``!23`` should not flow ""down"" into the ``%exit`` block. .. _ccxx_frontend:. C/C++ front-end specific debug information; ==========================================. The C and C++ front-ends represent information about the program in a; format that is effectively identical to `DWARF <http://www.dwarfs",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:39794,Modifiability,variab,variable,39794,"ove, variable ``!30`` is assigned ``%input`` on both; conditional paths through the function, while ``!23`` is assigned differing; constant values on either path. Where control flow merges in ``%bb1`` we would; want ``!30`` to keep its location (``%input``), but ``!23`` to become undefined; as we cannot determine at runtime what value it should have in %bb1 without; inserting a PHI node. mem2reg does not insert the PHI node to avoid changing; codegen when debugging is enabled, and does not insert the other dbg.values; to avoid adding very large numbers of intrinsics. Instead, LiveDebugValues determines variable locations when control; flow merges. A dataflow analysis is used to propagate locations between blocks:; when control flow merges, if a variable has the same location in all; predecessors then that location is propagated into the successor. If the; predecessor locations disagree, the location becomes undefined. Once LiveDebugValues has run, every block should have all valid variable; locations described by DBG_VALUE instructions within the block. Very little; effort is then required by supporting classes (such as; DbgEntityHistoryCalculator) to build a map of each instruction to every; valid variable location, without the need to consider control flow. From; the example above, it is otherwise difficult to determine that the location; of variable ``!30`` should flow ""up"" into block ``%bb1``, but that the location; of variable ``!23`` should not flow ""down"" into the ``%exit`` block. .. _ccxx_frontend:. C/C++ front-end specific debug information; ==========================================. The C and C++ front-ends represent information about the program in a; format that is effectively identical to `DWARF <http://www.dwarfstd.org/>`_; in terms of information content. This allows code generators to; trivially support native debuggers by generating standard dwarf; information, and contains enough information for non-dwarf targets to; translate it as needed. This s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:40016,Modifiability,variab,variable,40016,"ol flow merges in ``%bb1`` we would; want ``!30`` to keep its location (``%input``), but ``!23`` to become undefined; as we cannot determine at runtime what value it should have in %bb1 without; inserting a PHI node. mem2reg does not insert the PHI node to avoid changing; codegen when debugging is enabled, and does not insert the other dbg.values; to avoid adding very large numbers of intrinsics. Instead, LiveDebugValues determines variable locations when control; flow merges. A dataflow analysis is used to propagate locations between blocks:; when control flow merges, if a variable has the same location in all; predecessors then that location is propagated into the successor. If the; predecessor locations disagree, the location becomes undefined. Once LiveDebugValues has run, every block should have all valid variable; locations described by DBG_VALUE instructions within the block. Very little; effort is then required by supporting classes (such as; DbgEntityHistoryCalculator) to build a map of each instruction to every; valid variable location, without the need to consider control flow. From; the example above, it is otherwise difficult to determine that the location; of variable ``!30`` should flow ""up"" into block ``%bb1``, but that the location; of variable ``!23`` should not flow ""down"" into the ``%exit`` block. .. _ccxx_frontend:. C/C++ front-end specific debug information; ==========================================. The C and C++ front-ends represent information about the program in a; format that is effectively identical to `DWARF <http://www.dwarfstd.org/>`_; in terms of information content. This allows code generators to; trivially support native debuggers by generating standard dwarf; information, and contains enough information for non-dwarf targets to; translate it as needed. This section describes the forms used to represent C and C++ programs. Other; languages could pattern themselves after this (which itself is tuned to; representing programs in the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:40164,Modifiability,variab,variable,40164,"reg does not insert the PHI node to avoid changing; codegen when debugging is enabled, and does not insert the other dbg.values; to avoid adding very large numbers of intrinsics. Instead, LiveDebugValues determines variable locations when control; flow merges. A dataflow analysis is used to propagate locations between blocks:; when control flow merges, if a variable has the same location in all; predecessors then that location is propagated into the successor. If the; predecessor locations disagree, the location becomes undefined. Once LiveDebugValues has run, every block should have all valid variable; locations described by DBG_VALUE instructions within the block. Very little; effort is then required by supporting classes (such as; DbgEntityHistoryCalculator) to build a map of each instruction to every; valid variable location, without the need to consider control flow. From; the example above, it is otherwise difficult to determine that the location; of variable ``!30`` should flow ""up"" into block ``%bb1``, but that the location; of variable ``!23`` should not flow ""down"" into the ``%exit`` block. .. _ccxx_frontend:. C/C++ front-end specific debug information; ==========================================. The C and C++ front-ends represent information about the program in a; format that is effectively identical to `DWARF <http://www.dwarfstd.org/>`_; in terms of information content. This allows code generators to; trivially support native debuggers by generating standard dwarf; information, and contains enough information for non-dwarf targets to; translate it as needed. This section describes the forms used to represent C and C++ programs. Other; languages could pattern themselves after this (which itself is tuned to; representing programs in the same way that DWARF does), or they could choose; to provide completely different forms if they don't fit into the DWARF model.; As support for debugging information gets added to the various LLVM; source-language front-end",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:40245,Modifiability,variab,variable,40245,"reg does not insert the PHI node to avoid changing; codegen when debugging is enabled, and does not insert the other dbg.values; to avoid adding very large numbers of intrinsics. Instead, LiveDebugValues determines variable locations when control; flow merges. A dataflow analysis is used to propagate locations between blocks:; when control flow merges, if a variable has the same location in all; predecessors then that location is propagated into the successor. If the; predecessor locations disagree, the location becomes undefined. Once LiveDebugValues has run, every block should have all valid variable; locations described by DBG_VALUE instructions within the block. Very little; effort is then required by supporting classes (such as; DbgEntityHistoryCalculator) to build a map of each instruction to every; valid variable location, without the need to consider control flow. From; the example above, it is otherwise difficult to determine that the location; of variable ``!30`` should flow ""up"" into block ``%bb1``, but that the location; of variable ``!23`` should not flow ""down"" into the ``%exit`` block. .. _ccxx_frontend:. C/C++ front-end specific debug information; ==========================================. The C and C++ front-ends represent information about the program in a; format that is effectively identical to `DWARF <http://www.dwarfstd.org/>`_; in terms of information content. This allows code generators to; trivially support native debuggers by generating standard dwarf; information, and contains enough information for non-dwarf targets to; translate it as needed. This section describes the forms used to represent C and C++ programs. Other; languages could pattern themselves after this (which itself is tuned to; representing programs in the same way that DWARF does), or they could choose; to provide completely different forms if they don't fit into the DWARF model.; As support for debugging information gets added to the various LLVM; source-language front-end",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:42529,Modifiability,variab,variable,42529,"uilder.cpp``. C/C++ source file information; -----------------------------. ``llvm::Instruction`` provides easy access to metadata attached with an; instruction. One can extract line number information encoded in LLVM IR using; ``Instruction::getDebugLoc()`` and ``DILocation::getLine()``. .. code-block:: c++. if (DILocation *Loc = I->getDebugLoc()) { // Here I is an LLVM instruction; unsigned Line = Loc->getLine();; StringRef File = Loc->getFilename();; StringRef Dir = Loc->getDirectory();; bool ImplicitCode = Loc->isImplicitCode();; }. When the flag ImplicitCode is true then it means that the Instruction has been; added by the front-end but doesn't correspond to source code written by the user. For example. .. code-block:: c++. if (MyBoolean) {; MyObject MO;; ...; }. At the end of the scope the MyObject's destructor is called but it isn't written; explicitly. This information is useful to avoid to have counters on brackets when; making code coverage. C/C++ global variable information; ---------------------------------. Given an integer global variable declared as follows:. .. code-block:: c. _Alignas(8) int MyGlobal = 100;. a C/C++ front-end would generate the following descriptors:. .. code-block:: text. ;;; ;; Define the global itself.; ;;; @MyGlobal = global i32 100, align 8, !dbg !0. ;;; ;; List of debug info of globals; ;;; !llvm.dbg.cu = !{!1}. ;; Some unrelated metadata.; !llvm.module.flags = !{!6, !7}; !llvm.ident = !{!8}. ;; Define the global variable itself; !0 = distinct !DIGlobalVariable(name: ""MyGlobal"", scope: !1, file: !2, line: 1, type: !5, isLocal: false, isDefinition: true, align: 64). ;; Define the compile unit.; !1 = distinct !DICompileUnit(language: DW_LANG_C99, file: !2,; producer: ""clang version 4.0.0"",; isOptimized: false, runtimeVersion: 0, emissionKind: FullDebug,; enums: !3, globals: !4). ;;; ;; Define the file; ;;; !2 = !DIFile(filename: ""/dev/stdin"",; directory: ""/Users/dexonsmith/data/llvm/debug-info""). ;; An empty array.; !3 = !{}. ;;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:42610,Modifiability,variab,variable,42610,"------------. ``llvm::Instruction`` provides easy access to metadata attached with an; instruction. One can extract line number information encoded in LLVM IR using; ``Instruction::getDebugLoc()`` and ``DILocation::getLine()``. .. code-block:: c++. if (DILocation *Loc = I->getDebugLoc()) { // Here I is an LLVM instruction; unsigned Line = Loc->getLine();; StringRef File = Loc->getFilename();; StringRef Dir = Loc->getDirectory();; bool ImplicitCode = Loc->isImplicitCode();; }. When the flag ImplicitCode is true then it means that the Instruction has been; added by the front-end but doesn't correspond to source code written by the user. For example. .. code-block:: c++. if (MyBoolean) {; MyObject MO;; ...; }. At the end of the scope the MyObject's destructor is called but it isn't written; explicitly. This information is useful to avoid to have counters on brackets when; making code coverage. C/C++ global variable information; ---------------------------------. Given an integer global variable declared as follows:. .. code-block:: c. _Alignas(8) int MyGlobal = 100;. a C/C++ front-end would generate the following descriptors:. .. code-block:: text. ;;; ;; Define the global itself.; ;;; @MyGlobal = global i32 100, align 8, !dbg !0. ;;; ;; List of debug info of globals; ;;; !llvm.dbg.cu = !{!1}. ;; Some unrelated metadata.; !llvm.module.flags = !{!6, !7}; !llvm.ident = !{!8}. ;; Define the global variable itself; !0 = distinct !DIGlobalVariable(name: ""MyGlobal"", scope: !1, file: !2, line: 1, type: !5, isLocal: false, isDefinition: true, align: 64). ;; Define the compile unit.; !1 = distinct !DICompileUnit(language: DW_LANG_C99, file: !2,; producer: ""clang version 4.0.0"",; isOptimized: false, runtimeVersion: 0, emissionKind: FullDebug,; enums: !3, globals: !4). ;;; ;; Define the file; ;;; !2 = !DIFile(filename: ""/dev/stdin"",; directory: ""/Users/dexonsmith/data/llvm/debug-info""). ;; An empty array.; !3 = !{}. ;; The Array of Global Variables; !4 = !{!0}. ;;; ;; Define the t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:43027,Modifiability,variab,variable,43027,"When the flag ImplicitCode is true then it means that the Instruction has been; added by the front-end but doesn't correspond to source code written by the user. For example. .. code-block:: c++. if (MyBoolean) {; MyObject MO;; ...; }. At the end of the scope the MyObject's destructor is called but it isn't written; explicitly. This information is useful to avoid to have counters on brackets when; making code coverage. C/C++ global variable information; ---------------------------------. Given an integer global variable declared as follows:. .. code-block:: c. _Alignas(8) int MyGlobal = 100;. a C/C++ front-end would generate the following descriptors:. .. code-block:: text. ;;; ;; Define the global itself.; ;;; @MyGlobal = global i32 100, align 8, !dbg !0. ;;; ;; List of debug info of globals; ;;; !llvm.dbg.cu = !{!1}. ;; Some unrelated metadata.; !llvm.module.flags = !{!6, !7}; !llvm.ident = !{!8}. ;; Define the global variable itself; !0 = distinct !DIGlobalVariable(name: ""MyGlobal"", scope: !1, file: !2, line: 1, type: !5, isLocal: false, isDefinition: true, align: 64). ;; Define the compile unit.; !1 = distinct !DICompileUnit(language: DW_LANG_C99, file: !2,; producer: ""clang version 4.0.0"",; isOptimized: false, runtimeVersion: 0, emissionKind: FullDebug,; enums: !3, globals: !4). ;;; ;; Define the file; ;;; !2 = !DIFile(filename: ""/dev/stdin"",; directory: ""/Users/dexonsmith/data/llvm/debug-info""). ;; An empty array.; !3 = !{}. ;; The Array of Global Variables; !4 = !{!0}. ;;; ;; Define the type; ;;; !5 = !DIBasicType(name: ""int"", size: 32, encoding: DW_ATE_signed). ;; Dwarf version to output.; !6 = !{i32 2, !""Dwarf Version"", i32 4}. ;; Debug info schema version.; !7 = !{i32 2, !""Debug Info Version"", i32 3}. ;; Compiler identification; !8 = !{!""clang version 4.0.0""}. The align value in DIGlobalVariable description specifies variable alignment in; case it was forced by C11 _Alignas(), C++11 alignas() keywords or compiler; attribute __attribute__((aligned ())). In ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:43952,Modifiability,variab,variable,43952,"ident = !{!8}. ;; Define the global variable itself; !0 = distinct !DIGlobalVariable(name: ""MyGlobal"", scope: !1, file: !2, line: 1, type: !5, isLocal: false, isDefinition: true, align: 64). ;; Define the compile unit.; !1 = distinct !DICompileUnit(language: DW_LANG_C99, file: !2,; producer: ""clang version 4.0.0"",; isOptimized: false, runtimeVersion: 0, emissionKind: FullDebug,; enums: !3, globals: !4). ;;; ;; Define the file; ;;; !2 = !DIFile(filename: ""/dev/stdin"",; directory: ""/Users/dexonsmith/data/llvm/debug-info""). ;; An empty array.; !3 = !{}. ;; The Array of Global Variables; !4 = !{!0}. ;;; ;; Define the type; ;;; !5 = !DIBasicType(name: ""int"", size: 32, encoding: DW_ATE_signed). ;; Dwarf version to output.; !6 = !{i32 2, !""Dwarf Version"", i32 4}. ;; Debug info schema version.; !7 = !{i32 2, !""Debug Info Version"", i32 3}. ;; Compiler identification; !8 = !{!""clang version 4.0.0""}. The align value in DIGlobalVariable description specifies variable alignment in; case it was forced by C11 _Alignas(), C++11 alignas() keywords or compiler; attribute __attribute__((aligned ())). In other case (when this field is missing); alignment is considered default. This is used when producing DWARF output; for DW_AT_alignment value. C/C++ function information; --------------------------. Given a function declared as follows:. .. code-block:: c. int main(int argc, char *argv[]) {; return 0;; }. a C/C++ front-end would generate the following descriptors:. .. code-block:: text. ;;; ;; Define the anchor for subprograms.; ;;; !4 = !DISubprogram(name: ""main"", scope: !1, file: !1, line: 1, type: !5,; isLocal: false, isDefinition: true, scopeLine: 1,; flags: DIFlagPrototyped, isOptimized: false,; retainedNodes: !2). ;;; ;; Define the subprogram itself.; ;;; define i32 @main(i32 %argc, i8** %argv) !dbg !4 {; ...; }. C++ specific debug information; ==============================. C++ special member functions information; ----------------------------------------. DWARF v5 introduces a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:45012,Modifiability,enhance,enhance,45012,"C++11 alignas() keywords or compiler; attribute __attribute__((aligned ())). In other case (when this field is missing); alignment is considered default. This is used when producing DWARF output; for DW_AT_alignment value. C/C++ function information; --------------------------. Given a function declared as follows:. .. code-block:: c. int main(int argc, char *argv[]) {; return 0;; }. a C/C++ front-end would generate the following descriptors:. .. code-block:: text. ;;; ;; Define the anchor for subprograms.; ;;; !4 = !DISubprogram(name: ""main"", scope: !1, file: !1, line: 1, type: !5,; isLocal: false, isDefinition: true, scopeLine: 1,; flags: DIFlagPrototyped, isOptimized: false,; retainedNodes: !2). ;;; ;; Define the subprogram itself.; ;;; define i32 @main(i32 %argc, i8** %argv) !dbg !4 {; ...; }. C++ specific debug information; ==============================. C++ special member functions information; ----------------------------------------. DWARF v5 introduces attributes defined to enhance debugging information of C++ programs. LLVM can generate (or omit) these appropriate DWARF attributes. In C++ a special member function Ctors, Dtors, Copy/Move Ctors, assignment operators can be declared with C++11 keyword deleted. This is represented in LLVM using spFlags value DISPFlagDeleted. Given a class declaration with copy constructor declared as deleted:. .. code-block:: c. class foo {; public:; foo(const foo&) = deleted;; };. A C++ frontend would generate following:. .. code-block:: text. !17 = !DISubprogram(name: ""foo"", scope: !11, file: !1, line: 5, type: !18, scopeLine: 5, flags: DIFlagPublic | DIFlagPrototyped, spFlags: DISPFlagDeleted). and this will produce an additional DWARF attribute as:. .. code-block:: text. DW_TAG_subprogram [7] *; DW_AT_name [DW_FORM_strx1] (indexed (00000006) string = ""foo""); DW_AT_decl_line [DW_FORM_data1] (5); ...; DW_AT_deleted [DW_FORM_flag_present] (true). Fortran specific debug information; ==================================. Fortran",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:49537,Modifiability,variab,variables,49537,"wing descriptor for the trampoline function:. .. code-block:: text. !DISubprogram(name: ""sub1_.t0p"", linkageName: ""sub1_.t0p"", scope: !4, file: !4, type: !5, spFlags: DISPFlagLocalToUnit | DISPFlagDefinition, unit: !7, retainedNodes: !24, targetFuncName: ""sub1_""). The targetFuncName field is the name of the function that the trampoline; calls. This descriptor results in the following DWARF tag:. .. code-block:: text. DW_TAG_subprogram; ...; DW_AT_linkage_name	(""sub1_.t0p""); DW_AT_name	(""sub1_.t0p""); DW_AT_trampoline	(""sub1_""). Debugging information format; ============================. Debugging Information Extension for Objective C Properties; ----------------------------------------------------------. Introduction; ^^^^^^^^^^^^. Objective C provides a simpler way to declare and define accessor methods using; declared properties. The language provides features to declare a property and; to let compiler synthesize accessor methods. The debugger lets developer inspect Objective C interfaces and their instance; variables and class variables. However, the debugger does not know anything; about the properties defined in Objective C interfaces. The debugger consumes; information generated by compiler in DWARF format. The format does not support; encoding of Objective C properties. This proposal describes DWARF extensions to; encode Objective C properties, which the debugger can use to let developers; inspect Objective C properties. Proposal; ^^^^^^^^. Objective C properties exist separately from class members. A property can be; defined only by ""setter"" and ""getter"" selectors, and be calculated anew on each; access. Or a property can just be a direct access to some declared ivar.; Finally it can have an ivar ""automatically synthesized"" for it by the compiler,; in which case the property can be referred to in user code directly using the; standard C dereference syntax as well as through the property ""dot"" syntax, but; there is no entry in the ``@interface`` declaration co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:49557,Modifiability,variab,variables,49557,"wing descriptor for the trampoline function:. .. code-block:: text. !DISubprogram(name: ""sub1_.t0p"", linkageName: ""sub1_.t0p"", scope: !4, file: !4, type: !5, spFlags: DISPFlagLocalToUnit | DISPFlagDefinition, unit: !7, retainedNodes: !24, targetFuncName: ""sub1_""). The targetFuncName field is the name of the function that the trampoline; calls. This descriptor results in the following DWARF tag:. .. code-block:: text. DW_TAG_subprogram; ...; DW_AT_linkage_name	(""sub1_.t0p""); DW_AT_name	(""sub1_.t0p""); DW_AT_trampoline	(""sub1_""). Debugging information format; ============================. Debugging Information Extension for Objective C Properties; ----------------------------------------------------------. Introduction; ^^^^^^^^^^^^. Objective C provides a simpler way to declare and define accessor methods using; declared properties. The language provides features to declare a property and; to let compiler synthesize accessor methods. The debugger lets developer inspect Objective C interfaces and their instance; variables and class variables. However, the debugger does not know anything; about the properties defined in Objective C interfaces. The debugger consumes; information generated by compiler in DWARF format. The format does not support; encoding of Objective C properties. This proposal describes DWARF extensions to; encode Objective C properties, which the debugger can use to let developers; inspect Objective C properties. Proposal; ^^^^^^^^. Objective C properties exist separately from class members. A property can be; defined only by ""setter"" and ""getter"" selectors, and be calculated anew on each; access. Or a property can just be a direct access to some declared ivar.; Finally it can have an ivar ""automatically synthesized"" for it by the compiler,; in which case the property can be referred to in user code directly using the; standard C dereference syntax as well as through the property ""dot"" syntax, but; there is no entry in the ``@interface`` declaration co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:56791,Modifiability,variab,variables,56791,"| 0x100 |; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_weak | 0x200 |; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_strong | 0x400 |; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_unsafe_unretained | 0x800 |; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_nullability | 0x1000|; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_null_resettable | 0x2000|; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_class | 0x4000|; +--------------------------------------+-------+. Name Accelerator Tables; -----------------------. Introduction; ^^^^^^^^^^^^. The ""``.debug_pubnames``"" and ""``.debug_pubtypes``"" formats are not what a; debugger needs. The ""``pub``"" in the section name indicates that the entries; in the table are publicly visible names only. This means no static or hidden; functions show up in the ""``.debug_pubnames``"". No static variables or private; class variables are in the ""``.debug_pubtypes``"". Many compilers add different; things to these tables, so we can't rely upon the contents between gcc, icc, or; clang. The typical query given by users tends not to match up with the contents of; these tables. For example, the DWARF spec states that ""In the case of the name; of a function member or static data member of a C++ structure, class or union,; the name presented in the ""``.debug_pubnames``"" section is not the simple name; given by the ``DW_AT_name attribute`` of the referenced debugging information; entry, but rather the fully qualified name of the data or function member.""; So the only names in these tables for complex C++ entries is a fully; qualified name. Debugger users tend not to enter their search strings as; ""``a::b::c(int,const Foo&) const``"", but rather as ""``c``"", ""``b::c``"" , or; ""``a::b::c``"". So the name entered in the name table must be demangled in; order to chop it up appropriately and additional names must be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:56819,Modifiability,variab,variables,56819,"| 0x100 |; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_weak | 0x200 |; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_strong | 0x400 |; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_unsafe_unretained | 0x800 |; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_nullability | 0x1000|; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_null_resettable | 0x2000|; +--------------------------------------+-------+; | DW_APPLE_PROPERTY_class | 0x4000|; +--------------------------------------+-------+. Name Accelerator Tables; -----------------------. Introduction; ^^^^^^^^^^^^. The ""``.debug_pubnames``"" and ""``.debug_pubtypes``"" formats are not what a; debugger needs. The ""``pub``"" in the section name indicates that the entries; in the table are publicly visible names only. This means no static or hidden; functions show up in the ""``.debug_pubnames``"". No static variables or private; class variables are in the ""``.debug_pubtypes``"". Many compilers add different; things to these tables, so we can't rely upon the contents between gcc, icc, or; clang. The typical query given by users tends not to match up with the contents of; these tables. For example, the DWARF spec states that ""In the case of the name; of a function member or static data member of a C++ structure, class or union,; the name presented in the ""``.debug_pubnames``"" section is not the simple name; given by the ``DW_AT_name attribute`` of the referenced debugging information; entry, but rather the fully qualified name of the data or function member.""; So the only names in these tables for complex C++ entries is a fully; qualified name. Debugger users tend not to enter their search strings as; ""``a::b::c(int,const Foo&) const``"", but rather as ""``c``"", ""``b::c``"" , or; ""``a::b::c``"". So the name entered in the name table must be demangled in; order to chop it up appropriately and additional names must be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:73125,Modifiability,variab,variables,73125,"le, we create a list of items, or; Atoms, that are contained in the data for each name. First comes the type of; the data in each atom:. .. code-block:: c. enum AtomType; {; eAtomTypeNULL = 0u,; eAtomTypeDIEOffset = 1u, // DIE offset, check form for encoding; eAtomTypeCUOffset = 2u, // DIE offset of the compiler unit header that contains the item in question; eAtomTypeTag = 3u, // DW_TAG_xxx value, should be encoded as DW_FORM_data1 (if no tags exceed 255) or DW_FORM_data2; eAtomTypeNameFlags = 4u, // Flags from enum NameFlags; eAtomTypeTypeFlags = 5u, // Flags from enum TypeFlags; };. The enumeration values and their meanings are:. .. code-block:: none. eAtomTypeNULL - a termination atom that specifies the end of the atom list; eAtomTypeDIEOffset - an offset into the .debug_info section for the DWARF DIE for this name; eAtomTypeCUOffset - an offset into the .debug_info section for the CU that contains the DIE; eAtomTypeDIETag - The DW_TAG_XXX enumeration value so you don't have to parse the DWARF to see what it is; eAtomTypeNameFlags - Flags for functions and global variables (isFunction, isInlined, isExternal...); eAtomTypeTypeFlags - Flags for types (isCXXClass, isObjCClass, ...). Then we allow each atom type to define the atom type and how the data for each; atom type data is encoded:. .. code-block:: c. struct Atom; {; uint16_t type; // AtomType enum value; uint16_t form; // DWARF DW_FORM_XXX defines; };. The ``form`` type above is from the DWARF specification and defines the exact; encoding of the data for the Atom type. See the DWARF specification for the; ``DW_FORM_`` definitions. .. code-block:: c. struct HeaderData; {; uint32_t die_offset_base;; uint32_t atom_count;; Atoms atoms[atom_count0];; };. ``HeaderData`` defines the base DIE offset that should be added to any atoms; that are encoded using the ``DW_FORM_ref1``, ``DW_FORM_ref2``,; ``DW_FORM_ref4``, ``DW_FORM_ref8`` or ``DW_FORM_ref_udata``. It also defines; what is contained in each ``HashData`` objec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:77707,Modifiability,variab,variables,77707," offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0x00002023 | uint32_t KeyType (.debug_str[0x0002023] => ""print""); | 0x00000002 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x00000000 | uint32_t KeyType (end of hash chain); `------------'. Current testing with real world C++ binaries has shown that there is around 1; 32 bit hash collision per 100,000 name entries. Contents; ^^^^^^^^. As we said, we want to strictly define exactly what is included in the; different tables. For DWARF, we have 3 tables: ""``.apple_names``"",; ""``.apple_types``"", and ""``.apple_namespaces``"". ""``.apple_names``"" sections should contain an entry for each DWARF DIE whose; ``DW_TAG`` is a ``DW_TAG_label``, ``DW_TAG_inlined_subroutine``, or; ``DW_TAG_subprogram`` that has address attributes: ``DW_AT_low_pc``,; ``DW_AT_high_pc``, ``DW_AT_ranges`` or ``DW_AT_entry_pc``. It also contains; ``DW_TAG_variable`` DIEs that have a ``DW_OP_addr`` in the location (global and; static variables). All global and static variables should be included,; including those scoped within functions and classes. For example using the; following code:. .. code-block:: c. static int var = 0;. void f (); {; static int var = 0;; }. Both of the static ``var`` variables would be included in the table. All; functions should emit both their full names and their basenames. For C or C++,; the full name is the mangled name (if available) which is usually in the; ``DW_AT_MIPS_linkage_name`` attribute, and the ``DW_AT_name`` contains the; function basename. If global or static variables have a mangled name in a; ``DW_AT_MIPS_linkage_name`` attribute, this should be emitted along with the; simple name found in the ``DW_AT_name`` attribute. ""``.apple_types``"" sections should contain an entry for each DWARF DIE whose; tag is one of:. * DW_TAG_array_type; * DW_TAG_class_type; * DW_TAG_enumeration_type; * DW_TAG_pointer_type; * DW_TAG_reference_typ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:77741,Modifiability,variab,variables,77741,"=> ""print""); | 0x00000002 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x00000000 | uint32_t KeyType (end of hash chain); `------------'. Current testing with real world C++ binaries has shown that there is around 1; 32 bit hash collision per 100,000 name entries. Contents; ^^^^^^^^. As we said, we want to strictly define exactly what is included in the; different tables. For DWARF, we have 3 tables: ""``.apple_names``"",; ""``.apple_types``"", and ""``.apple_namespaces``"". ""``.apple_names``"" sections should contain an entry for each DWARF DIE whose; ``DW_TAG`` is a ``DW_TAG_label``, ``DW_TAG_inlined_subroutine``, or; ``DW_TAG_subprogram`` that has address attributes: ``DW_AT_low_pc``,; ``DW_AT_high_pc``, ``DW_AT_ranges`` or ``DW_AT_entry_pc``. It also contains; ``DW_TAG_variable`` DIEs that have a ``DW_OP_addr`` in the location (global and; static variables). All global and static variables should be included,; including those scoped within functions and classes. For example using the; following code:. .. code-block:: c. static int var = 0;. void f (); {; static int var = 0;; }. Both of the static ``var`` variables would be included in the table. All; functions should emit both their full names and their basenames. For C or C++,; the full name is the mangled name (if available) which is usually in the; ``DW_AT_MIPS_linkage_name`` attribute, and the ``DW_AT_name`` contains the; function basename. If global or static variables have a mangled name in a; ``DW_AT_MIPS_linkage_name`` attribute, this should be emitted along with the; simple name found in the ``DW_AT_name`` attribute. ""``.apple_types``"" sections should contain an entry for each DWARF DIE whose; tag is one of:. * DW_TAG_array_type; * DW_TAG_class_type; * DW_TAG_enumeration_type; * DW_TAG_pointer_type; * DW_TAG_reference_type; * DW_TAG_string_type; * DW_TAG_structure_type; * DW_TAG_subroutine_type; * DW_TAG_typedef; * DW_TAG_union_typ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:77970,Modifiability,variab,variables,77970,"----------'. Current testing with real world C++ binaries has shown that there is around 1; 32 bit hash collision per 100,000 name entries. Contents; ^^^^^^^^. As we said, we want to strictly define exactly what is included in the; different tables. For DWARF, we have 3 tables: ""``.apple_names``"",; ""``.apple_types``"", and ""``.apple_namespaces``"". ""``.apple_names``"" sections should contain an entry for each DWARF DIE whose; ``DW_TAG`` is a ``DW_TAG_label``, ``DW_TAG_inlined_subroutine``, or; ``DW_TAG_subprogram`` that has address attributes: ``DW_AT_low_pc``,; ``DW_AT_high_pc``, ``DW_AT_ranges`` or ``DW_AT_entry_pc``. It also contains; ``DW_TAG_variable`` DIEs that have a ``DW_OP_addr`` in the location (global and; static variables). All global and static variables should be included,; including those scoped within functions and classes. For example using the; following code:. .. code-block:: c. static int var = 0;. void f (); {; static int var = 0;; }. Both of the static ``var`` variables would be included in the table. All; functions should emit both their full names and their basenames. For C or C++,; the full name is the mangled name (if available) which is usually in the; ``DW_AT_MIPS_linkage_name`` attribute, and the ``DW_AT_name`` contains the; function basename. If global or static variables have a mangled name in a; ``DW_AT_MIPS_linkage_name`` attribute, this should be emitted along with the; simple name found in the ``DW_AT_name`` attribute. ""``.apple_types``"" sections should contain an entry for each DWARF DIE whose; tag is one of:. * DW_TAG_array_type; * DW_TAG_class_type; * DW_TAG_enumeration_type; * DW_TAG_pointer_type; * DW_TAG_reference_type; * DW_TAG_string_type; * DW_TAG_structure_type; * DW_TAG_subroutine_type; * DW_TAG_typedef; * DW_TAG_union_type; * DW_TAG_ptr_to_member_type; * DW_TAG_set_type; * DW_TAG_subrange_type; * DW_TAG_base_type; * DW_TAG_const_type; * DW_TAG_immutable_type; * DW_TAG_file_type; * DW_TAG_namelist; * DW_TAG_packed_type; * DW",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:78286,Modifiability,variab,variables,78286,"ld contain an entry for each DWARF DIE whose; ``DW_TAG`` is a ``DW_TAG_label``, ``DW_TAG_inlined_subroutine``, or; ``DW_TAG_subprogram`` that has address attributes: ``DW_AT_low_pc``,; ``DW_AT_high_pc``, ``DW_AT_ranges`` or ``DW_AT_entry_pc``. It also contains; ``DW_TAG_variable`` DIEs that have a ``DW_OP_addr`` in the location (global and; static variables). All global and static variables should be included,; including those scoped within functions and classes. For example using the; following code:. .. code-block:: c. static int var = 0;. void f (); {; static int var = 0;; }. Both of the static ``var`` variables would be included in the table. All; functions should emit both their full names and their basenames. For C or C++,; the full name is the mangled name (if available) which is usually in the; ``DW_AT_MIPS_linkage_name`` attribute, and the ``DW_AT_name`` contains the; function basename. If global or static variables have a mangled name in a; ``DW_AT_MIPS_linkage_name`` attribute, this should be emitted along with the; simple name found in the ``DW_AT_name`` attribute. ""``.apple_types``"" sections should contain an entry for each DWARF DIE whose; tag is one of:. * DW_TAG_array_type; * DW_TAG_class_type; * DW_TAG_enumeration_type; * DW_TAG_pointer_type; * DW_TAG_reference_type; * DW_TAG_string_type; * DW_TAG_structure_type; * DW_TAG_subroutine_type; * DW_TAG_typedef; * DW_TAG_union_type; * DW_TAG_ptr_to_member_type; * DW_TAG_set_type; * DW_TAG_subrange_type; * DW_TAG_base_type; * DW_TAG_const_type; * DW_TAG_immutable_type; * DW_TAG_file_type; * DW_TAG_namelist; * DW_TAG_packed_type; * DW_TAG_volatile_type; * DW_TAG_restrict_type; * DW_TAG_atomic_type; * DW_TAG_interface_type; * DW_TAG_unspecified_type; * DW_TAG_shared_type. Only entries with a ``DW_AT_name`` attribute are included, and the entry must; not be a forward declaration (``DW_AT_declaration`` attribute with a non-zero; value). For example, using the following code:. .. code-block:: c. int main (); {; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:1083,Performance,optimiz,optimizations,1083,"=========. This document is the central repository for all information pertaining to debug; information in LLVM. It describes the :ref:`actual format that the LLVM debug; information takes <format>`, which is useful for those interested in creating; front-ends or dealing directly with the information. Further, this document; provides specific examples of what debug information for C/C++ looks like. Philosophy behind LLVM debugging information; --------------------------------------------. The idea of the LLVM debugging information is to capture how the important; pieces of the source-language's Abstract Syntax Tree map onto LLVM code.; Several design aspects have shaped the solution that appears here. The; important ones are:. * Debugging information should have very little impact on the rest of the; compiler. No transformations, analyses, or code generators should need to; be modified because of debugging information. * LLVM optimizations should interact in :ref:`well-defined and easily described; ways <intro_debugopt>` with the debugging information. * Because LLVM is designed to support arbitrary programming languages,; LLVM-to-LLVM tools should not need to know anything about the semantics of; the source-level-language. * Source-level languages are often **widely** different from one another.; LLVM should not put any restrictions of the flavor of the source-language,; and the debugging information should work with any language. * With code generator support, it should be possible to use an LLVM compiler; to compile a program to native machine code and standard debugging; formats. This allows compatibility with traditional machine-code level; debuggers, like GDB or DBX. The approach used by the LLVM implementation is to use a small set of; :ref:`intrinsic functions <format_common_intrinsics>` to define a mapping; between LLVM program objects and the source-level objects. The description of; the source-level program is maintained in LLVM metadata in an; :ref:`impl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:3619,Performance,optimiz,optimizations,3619,"--------------. The role of debug information is to provide meta information normally stripped; away during the compilation process. This meta information provides an LLVM; user a relationship between generated code and the original program source; code. Currently, there are two backend consumers of debug info: DwarfDebug and; CodeViewDebug. DwarfDebug produces DWARF suitable for use with GDB, LLDB, and; other DWARF-based debuggers. :ref:`CodeViewDebug <codeview>` produces CodeView,; the Microsoft debug info format, which is usable with Microsoft debuggers such; as Visual Studio and WinDBG. LLVM's debug information format is mostly derived; from and inspired by DWARF, but it is feasible to translate into other target; debug info formats such as STABS. It would also be reasonable to use debug information to feed profiling tools; for analysis of generated code, or, tools for reconstructing the original; source from generated code. .. _intro_debugopt:. Debug information and optimizations; -----------------------------------. An extremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:3762,Performance,optimiz,optimizations,3762,"away during the compilation process. This meta information provides an LLVM; user a relationship between generated code and the original program source; code. Currently, there are two backend consumers of debug info: DwarfDebug and; CodeViewDebug. DwarfDebug produces DWARF suitable for use with GDB, LLDB, and; other DWARF-based debuggers. :ref:`CodeViewDebug <codeview>` produces CodeView,; the Microsoft debug info format, which is usable with Microsoft debuggers such; as Visual Studio and WinDBG. LLVM's debug information format is mostly derived; from and inspired by DWARF, but it is feasible to translate into other target; debug info formats such as STABS. It would also be reasonable to use debug information to feed profiling tools; for analysis of generated code, or, tools for reconstructing the original; source from generated code. .. _intro_debugopt:. Debug information and optimizations; -----------------------------------. An extremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:4011,Performance,optimiz,optimizations,4011,"bug and; CodeViewDebug. DwarfDebug produces DWARF suitable for use with GDB, LLDB, and; other DWARF-based debuggers. :ref:`CodeViewDebug <codeview>` produces CodeView,; the Microsoft debug info format, which is usable with Microsoft debuggers such; as Visual Studio and WinDBG. LLVM's debug information format is mostly derived; from and inspired by DWARF, but it is feasible to translate into other target; debug info formats such as STABS. It would also be reasonable to use debug information to feed profiling tools; for analysis of generated code, or, tools for reconstructing the original; source from generated code. .. _intro_debugopt:. Debug information and optimizations; -----------------------------------. An extremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:4263,Performance,optimiz,optimizations,4263,"to other target; debug info formats such as STABS. It would also be reasonable to use debug information to feed profiling tools; for analysis of generated code, or, tools for reconstructing the original; source from generated code. .. _intro_debugopt:. Debug information and optimizations; -----------------------------------. An extremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a pro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:4461,Performance,optimiz,optimizations,4461,"ng the original; source from generated code. .. _intro_debugopt:. Debug information and optimizations; -----------------------------------. An extremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:4589,Performance,perform,perform,4589,"ng the original; source from generated code. .. _intro_debugopt:. Debug information and optimizations; -----------------------------------. An extremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:4608,Performance,optimiz,optimizations,4608,"ng the original; source from generated code. .. _intro_debugopt:. Debug information and optimizations; -----------------------------------. An extremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:4663,Performance,optimiz,optimizers,4663,"tremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:4680,Performance,optimiz,optimize,4680,"tremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:4774,Performance,optimiz,optimizations,4774,"VM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:4934,Performance,optimiz,optimized,4934,"ource-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:5619,Performance,optimiz,optimized,5619," information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids dupli",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:5764,Performance,optimiz,optimizer,5764,"g information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids duplicated debugging information from; the beginning, and the global dead code elimination pass automatically deletes; debugging information for a function if it decides to delete th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:6006,Performance,optimiz,optimization,6006,"sting facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids duplicated debugging information from; the beginning, and the global dead code elimination pass automatically deletes; debugging information for a function if it decides to delete the function. To do this, most of the debugging information (descriptors for types,; variables, functions, source files, etc) is inserted by the language front-end; in the form of LLVM metadata. Debug information is designed to be agnostic about the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:6064,Performance,optimiz,optimization,6064," linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids duplicated debugging information from; the beginning, and the global dead code elimination pass automatically deletes; debugging information for a function if it decides to delete the function. To do this, most of the debugging information (descriptors for types,; variables, functions, source files, etc) is inserted by the language front-end; in the form of LLVM metadata. Debug information is designed to be agnostic about the target debugger and; debugging information representation (e.g. DWARF/Stabs/etc). I",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:6385,Performance,optimiz,optimizer,6385,"always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids duplicated debugging information from; the beginning, and the global dead code elimination pass automatically deletes; debugging information for a function if it decides to delete the function. To do this, most of the debugging information (descriptors for types,; variables, functions, source files, etc) is inserted by the language front-end; in the form of LLVM metadata. Debug information is designed to be agnostic about the target debugger and; debugging information representation (e.g. DWARF/Stabs/etc). It uses a generic; pass to decode the information that represents variables, types, functions,; namespaces, etc: this allows for arbitrary source-language semantics and; type-systems to be used, as long as there is a module written for the target; debugger to interpret the information. To provide basic functionality, the LLVM debugge",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:6398,Performance,optimiz,optimize,6398,"always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids duplicated debugging information from; the beginning, and the global dead code elimination pass automatically deletes; debugging information for a function if it decides to delete the function. To do this, most of the debugging information (descriptors for types,; variables, functions, source files, etc) is inserted by the language front-end; in the form of LLVM metadata. Debug information is designed to be agnostic about the target debugger and; debugging information representation (e.g. DWARF/Stabs/etc). It uses a generic; pass to decode the information that represents variables, types, functions,; namespaces, etc: this allows for arbitrary source-language semantics and; type-systems to be used, as long as there is a module written for the target; debugger to interpret the information. To provide basic functionality, the LLVM debugge",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:8360,Performance,optimiz,optimization,8360,"rmation. To provide basic functionality, the LLVM debugger does have to make some; assumptions about the source-level language being debugged, though it keeps; these to a minimum. The only common features that the LLVM debugger assumes; exist are `source files <LangRef.html#difile>`_, and `program objects; <LangRef.html#diglobalvariable>`_. These abstract objects are used by a; debugger to form stack traces, show information about local variables, etc. This section of the documentation first describes the representation aspects; common to any source-language. :ref:`ccxx_frontend` describes the data layout; conventions used by the C and C++ front-ends. Debug information descriptors are `specialized metadata nodes; <LangRef.html#specialized-metadata>`_, first-class subclasses of ``Metadata``. .. _format_common_intrinsics:. Debugger intrinsic functions; ----------------------------. LLVM uses several intrinsic functions (name prefixed with ""``llvm.dbg``"") to; track source local variables through optimization and code generation. ``llvm.dbg.declare``; ^^^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.declare(metadata, metadata, metadata). This intrinsic provides information about a local element (e.g., variable).; The first argument is metadata holding the address of variable, typically a; static alloca in the function entry block. The second argument is a; `local variable <LangRef.html#dilocalvariable>`_ containing a description of; the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.declare` intrinsic describes the; *address* of a source variable. .. code-block:: text. %i.addr = alloca i32, align 4; call void @llvm.dbg.declare(metadata i32* %i.addr, metadata !1,; metadata !DIExpression()), !dbg !2; !1 = !DILocalVariable(name: ""i"", ...) ; int i; !2 = !DILocation(...); ...; %buffer = alloca [256 x i8], align 8; ; The address of i is buffer+64.; call void @llvm.dbg.declare(metadata [256 x i8]* %buffer, metadata ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:9933,Performance,optimiz,optimization,9933,"ress* of a source variable. .. code-block:: text. %i.addr = alloca i32, align 4; call void @llvm.dbg.declare(metadata i32* %i.addr, metadata !1,; metadata !DIExpression()), !dbg !2; !1 = !DILocalVariable(name: ""i"", ...) ; int i; !2 = !DILocation(...); ...; %buffer = alloca [256 x i8], align 8; ; The address of i is buffer+64.; call void @llvm.dbg.declare(metadata [256 x i8]* %buffer, metadata !3,; metadata !DIExpression(DW_OP_plus, 64)), !dbg !4; !3 = !DILocalVariable(name: ""i"", ...) ; int i; !4 = !DILocation(...). A frontend should generate exactly one call to ``llvm.dbg.declare`` at the point; of declaration of a source variable. Optimization passes that fully promote the; variable from memory to SSA values will replace this call with possibly multiple; calls to `llvm.dbg.value`. Passes that delete stores are effectively partial; promotion, and they will insert a mix of calls to ``llvm.dbg.value`` to track; the source variable value when it is available. After optimization, there may be; multiple calls to ``llvm.dbg.declare`` describing the program points where the; variables lives in memory. All calls for the same concrete source variable must; agree on the memory location. ``llvm.dbg.value``; ^^^^^^^^^^^^^^^^^^. .. code-block:: llvm. void @llvm.dbg.value(metadata, metadata, metadata). This intrinsic provides information when a user source variable is set to a new; value. The first argument is the new value (wrapped as metadata). The second; argument is a `local variable <LangRef.html#dilocalvariable>`_ containing a; description of the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.value` intrinsic describes the *value* of a source variable; directly, not its address. Note that the value operand of this intrinsic may; be indirect (i.e, a pointer to the source variable), provided that interpreting; the complex expression derives the direct value. ``llvm.dbg.assign``; ^^^^^^^^^^^^^^^^^^^; .. toctree::; :hidden:. A",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:11316,Performance,perform,performs,11316,"ariable is set to a new; value. The first argument is the new value (wrapped as metadata). The second; argument is a `local variable <LangRef.html#dilocalvariable>`_ containing a; description of the variable. The third argument is a `complex expression; <LangRef.html#diexpression>`_. An `llvm.dbg.value` intrinsic describes the *value* of a source variable; directly, not its address. Note that the value operand of this intrinsic may; be indirect (i.e, a pointer to the source variable), provided that interpreting; the complex expression derives the direct value. ``llvm.dbg.assign``; ^^^^^^^^^^^^^^^^^^^; .. toctree::; :hidden:. AssignmentTracking. .. code-block:: llvm. void @llvm.dbg.assign(Value *Value,; DIExpression *ValueExpression,; DILocalVariable *Variable,; DIAssignID *ID,; Value *Address,; DIExpression *AddressExpression). This intrinsic marks the position in IR where a source assignment occurred. It; encodes the value of the variable. It references the store, if any, that; performs the assignment, and the destination address. The first three arguments are the same as for an ``llvm.dbg.value``. The fourth; argument is a ``DIAssignID`` used to reference a store. The fifth is the; destination of the store (wrapped as metadata), and the sixth is a `complex; expression <LangRef.html#diexpression>`_ that modifies it. The formal LLVM-IR signature is:. .. code-block:: llvm. void @llvm.dbg.assign(metadata, metadata, metadata, metadata, metadata, metadata). See :doc:`AssignmentTracking` for more info. Object lifetimes and scoping; ============================. In many languages, the local variables in functions can have their lifetimes or; scopes limited to a subset of a function. In the C family of languages, for; example, variables are only live (readable and writable) within the source; block that they are defined in. In functional languages, values are only; readable after they have been defined. Though this is a very obvious concept,; it is non-trivial to model in L",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:13389,Performance,load,load,13389,"coping rules. In order to handle this, the LLVM debug format uses the metadata attached to; llvm instructions to encode line number and scoping information. Consider the; following C fragment, for example:. .. code-block:: c. 1. void foo() {; 2. int X = 21;; 3. int Y = 22;; 4. {; 5. int Z = 23;; 6. Z = X;; 7. }; 8. X = Y;; 9. }. Compiled to LLVM, this function would be represented like this:. .. code-block:: text. ; Function Attrs: nounwind ssp uwtable; define void @foo() #0 !dbg !4 {; entry:; %X = alloca i32, align 4; %Y = alloca i32, align 4; %Z = alloca i32, align 4; call void @llvm.dbg.declare(metadata i32* %X, metadata !11, metadata !13), !dbg !14; store i32 21, i32* %X, align 4, !dbg !14; call void @llvm.dbg.declare(metadata i32* %Y, metadata !15, metadata !13), !dbg !16; store i32 22, i32* %Y, align 4, !dbg !16; call void @llvm.dbg.declare(metadata i32* %Z, metadata !17, metadata !13), !dbg !19; store i32 23, i32* %Z, align 4, !dbg !19; %0 = load i32, i32* %X, align 4, !dbg !20; store i32 %0, i32* %Z, align 4, !dbg !21; %1 = load i32, i32* %Y, align 4, !dbg !22; store i32 %1, i32* %X, align 4, !dbg !23; ret void, !dbg !24; }. ; Function Attrs: nounwind readnone; declare void @llvm.dbg.declare(metadata, metadata, metadata) #1. attributes #0 = { nounwind ssp uwtable ""less-precise-fpmad""=""false"" ""frame-pointer""=""all"" ""no-infs-fp-math""=""false"" ""no-nans-fp-math""=""false"" ""stack-protector-buffer-size""=""8"" ""unsafe-fp-math""=""false"" ""use-soft-float""=""false"" }; attributes #1 = { nounwind readnone }. !llvm.dbg.cu = !{!0}; !llvm.module.flags = !{!7, !8, !9}; !llvm.ident = !{!10}. !0 = !DICompileUnit(language: DW_LANG_C99, file: !1, producer: ""clang version 3.7.0 (trunk 231150) (llvm/trunk 231154)"", isOptimized: false, runtimeVersion: 0, emissionKind: FullDebug, enums: !2, retainedTypes: !2, subprograms: !3, globals: !2, imports: !2); !1 = !DIFile(filename: ""/dev/stdin"", directory: ""/Users/dexonsmith/data/llvm/debug-info""); !2 = !{}; !3 = !{!4}; !4 = distinct !DISubprogram(",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:13474,Performance,load,load,13474,"coping rules. In order to handle this, the LLVM debug format uses the metadata attached to; llvm instructions to encode line number and scoping information. Consider the; following C fragment, for example:. .. code-block:: c. 1. void foo() {; 2. int X = 21;; 3. int Y = 22;; 4. {; 5. int Z = 23;; 6. Z = X;; 7. }; 8. X = Y;; 9. }. Compiled to LLVM, this function would be represented like this:. .. code-block:: text. ; Function Attrs: nounwind ssp uwtable; define void @foo() #0 !dbg !4 {; entry:; %X = alloca i32, align 4; %Y = alloca i32, align 4; %Z = alloca i32, align 4; call void @llvm.dbg.declare(metadata i32* %X, metadata !11, metadata !13), !dbg !14; store i32 21, i32* %X, align 4, !dbg !14; call void @llvm.dbg.declare(metadata i32* %Y, metadata !15, metadata !13), !dbg !16; store i32 22, i32* %Y, align 4, !dbg !16; call void @llvm.dbg.declare(metadata i32* %Z, metadata !17, metadata !13), !dbg !19; store i32 23, i32* %Z, align 4, !dbg !19; %0 = load i32, i32* %X, align 4, !dbg !20; store i32 %0, i32* %Z, align 4, !dbg !21; %1 = load i32, i32* %Y, align 4, !dbg !22; store i32 %1, i32* %X, align 4, !dbg !23; ret void, !dbg !24; }. ; Function Attrs: nounwind readnone; declare void @llvm.dbg.declare(metadata, metadata, metadata) #1. attributes #0 = { nounwind ssp uwtable ""less-precise-fpmad""=""false"" ""frame-pointer""=""all"" ""no-infs-fp-math""=""false"" ""no-nans-fp-math""=""false"" ""stack-protector-buffer-size""=""8"" ""unsafe-fp-math""=""false"" ""use-soft-float""=""false"" }; attributes #1 = { nounwind readnone }. !llvm.dbg.cu = !{!0}; !llvm.module.flags = !{!7, !8, !9}; !llvm.ident = !{!10}. !0 = !DICompileUnit(language: DW_LANG_C99, file: !1, producer: ""clang version 3.7.0 (trunk 231150) (llvm/trunk 231154)"", isOptimized: false, runtimeVersion: 0, emissionKind: FullDebug, enums: !2, retainedTypes: !2, subprograms: !3, globals: !2, imports: !2); !1 = !DIFile(filename: ""/dev/stdin"", directory: ""/Users/dexonsmith/data/llvm/debug-info""); !2 = !{}; !3 = !{!4}; !4 = distinct !DISubprogram(",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:17812,Performance,optimiz,optimized,17812,"insics indicates that the variable ``X`` is; declared at line number 2 at a function level scope in function ``foo``. Now lets take another example. .. code-block:: llvm. call void @llvm.dbg.declare(metadata i32* %Z, metadata !17, metadata !13), !dbg !19; ; [debug line = 5:9] [debug variable = Z]. The third intrinsic ``%llvm.dbg.declare`` encodes debugging information for; variable ``Z``. The metadata ``!dbg !19`` attached to the intrinsic provides; scope information for the variable ``Z``. .. code-block:: text. !18 = distinct !DILexicalBlock(scope: !4, file: !1, line: 4, column: 5); !19 = !DILocation(line: 5, column: 11, scope: !18). Here ``!19`` indicates that ``Z`` is declared at line number 5 and column; number 11 inside of lexical scope ``!18``. The lexical scope itself resides; inside of subprogram ``!4`` described above. The scope information attached with each instruction provides a straightforward; way to find instructions covered by a scope. Object lifetime in optimized code; =================================. In the example above, every variable assignment uniquely corresponds to a; memory store to the variable's position on the stack. However in heavily; optimized code LLVM promotes most variables into SSA values, which can; eventually be placed in physical registers or memory locations. To track SSA; values through compilation, when objects are promoted to SSA values an; ``llvm.dbg.value`` intrinsic is created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:18012,Performance,optimiz,optimized,18012,"3), !dbg !19; ; [debug line = 5:9] [debug variable = Z]. The third intrinsic ``%llvm.dbg.declare`` encodes debugging information for; variable ``Z``. The metadata ``!dbg !19`` attached to the intrinsic provides; scope information for the variable ``Z``. .. code-block:: text. !18 = distinct !DILexicalBlock(scope: !4, file: !1, line: 4, column: 5); !19 = !DILocation(line: 5, column: 11, scope: !18). Here ``!19`` indicates that ``Z`` is declared at line number 5 and column; number 11 inside of lexical scope ``!18``. The lexical scope itself resides; inside of subprogram ``!4`` described above. The scope information attached with each instruction provides a straightforward; way to find instructions covered by a scope. Object lifetime in optimized code; =================================. In the example above, every variable assignment uniquely corresponds to a; memory store to the variable's position on the stack. However in heavily; optimized code LLVM promotes most variables into SSA values, which can; eventually be placed in physical registers or memory locations. To track SSA; values through compilation, when objects are promoted to SSA values an; ``llvm.dbg.value`` intrinsic is created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:18768,Performance,optimiz,optimization,18768,"======================. In the example above, every variable assignment uniquely corresponds to a; memory store to the variable's position on the stack. However in heavily; optimized code LLVM promotes most variables into SSA values, which can; eventually be placed in physical registers or memory locations. To track SSA; values through compilation, when objects are promoted to SSA values an; ``llvm.dbg.value`` intrinsic is created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from the developer diminishes the; amount of available debug information, but increases the reliability of the; remaining inf",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:18962,Performance,optimiz,optimized,18962,"s into SSA values, which can; eventually be placed in physical registers or memory locations. To track SSA; values through compilation, when objects are promoted to SSA values an; ``llvm.dbg.value`` intrinsic is created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from the developer diminishes the; amount of available debug information, but increases the reliability of the; remaining information. To illustrate some potential issues, consider the following example:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:19294,Performance,optimiz,optimized,19294," created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from the developer diminishes the; amount of available debug information, but increases the reliability of the; remaining information. To illustrate some potential issues, consider the following example:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); br i1 %cond, label %truebr, label %falsebr; truebr:; %tval = add i32 %bar, 1; call @llvm.dbg.value(metadata i32 %tval, metadata !1, metadata !2); %g1 = call i32 @gazonk(); br label %exit; falsebr:; %fval = add i3",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:19464,Performance,optimiz,optimized,19464,"fect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from the developer diminishes the; amount of available debug information, but increases the reliability of the; remaining information. To illustrate some potential issues, consider the following example:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); br i1 %cond, label %truebr, label %falsebr; truebr:; %tval = add i32 %bar, 1; call @llvm.dbg.value(metadata i32 %tval, metadata !1, metadata !2); %g1 = call i32 @gazonk(); br label %exit; falsebr:; %fval = add i32 %bar, 2; call @llvm.dbg.value(metadata i32 %fval, metadata !1, metadata !2); %g2 = call i32 @gazonk(); br label %exit; exit:; %merge = phi [ %tval, %tr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:19628,Performance,optimiz,optimized,19628,"eam; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from the developer diminishes the; amount of available debug information, but increases the reliability of the; remaining information. To illustrate some potential issues, consider the following example:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); br i1 %cond, label %truebr, label %falsebr; truebr:; %tval = add i32 %bar, 1; call @llvm.dbg.value(metadata i32 %tval, metadata !1, metadata !2); %g1 = call i32 @gazonk(); br label %exit; falsebr:; %fval = add i32 %bar, 2; call @llvm.dbg.value(metadata i32 %fval, metadata !1, metadata !2); %g2 = call i32 @gazonk(); br label %exit; exit:; %merge = phi [ %tval, %truebr ], [ %fval, %falsebr ]; %g = phi [ %g1, %truebr ], [ %g2, %falsebr ]; call @llvm.dbg.value(metadata i32 %merge, metadata !1, metadata !2); call @llvm.dbg.value(m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:20870,Performance,optimiz,optimized,20870,"otential issues, consider the following example:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); br i1 %cond, label %truebr, label %falsebr; truebr:; %tval = add i32 %bar, 1; call @llvm.dbg.value(metadata i32 %tval, metadata !1, metadata !2); %g1 = call i32 @gazonk(); br label %exit; falsebr:; %fval = add i32 %bar, 2; call @llvm.dbg.value(metadata i32 %fval, metadata !1, metadata !2); %g2 = call i32 @gazonk(); br label %exit; exit:; %merge = phi [ %tval, %truebr ], [ %fval, %falsebr ]; %g = phi [ %g1, %truebr ], [ %g2, %falsebr ]; call @llvm.dbg.value(metadata i32 %merge, metadata !1, metadata !2); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %plusten = add i32 %merge, 10; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. Containing two source-level variables in ``!1`` and ``!3``. The function could,; perhaps, be optimized into the following code:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; %g = call i32 @gazonk(); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; ret i32 %toret; }. What ``llvm.dbg.value`` intrinsics should be placed to represent the original variable; locations in this code? Unfortunately the second, third and fourth; dbg.values for ``!1`` in the source function have had their operands; (%tval, %fval, %merge) optimized out. Assuming we cannot recover them, we; might consider this placement of dbg.values:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); %g = call i32 @gazonk(); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:21378,Performance,optimiz,optimized,21378,"2); %g2 = call i32 @gazonk(); br label %exit; exit:; %merge = phi [ %tval, %truebr ], [ %fval, %falsebr ]; %g = phi [ %g1, %truebr ], [ %g2, %falsebr ]; call @llvm.dbg.value(metadata i32 %merge, metadata !1, metadata !2); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %plusten = add i32 %merge, 10; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. Containing two source-level variables in ``!1`` and ``!3``. The function could,; perhaps, be optimized into the following code:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; %g = call i32 @gazonk(); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; ret i32 %toret; }. What ``llvm.dbg.value`` intrinsics should be placed to represent the original variable; locations in this code? Unfortunately the second, third and fourth; dbg.values for ``!1`` in the source function have had their operands; (%tval, %fval, %merge) optimized out. Assuming we cannot recover them, we; might consider this placement of dbg.values:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); %g = call i32 @gazonk(); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. However, this will cause ``!3`` to have the return value of ``@gazonk()`` at; the same time as ``!1`` has the constant value zero -- a pair of assignments; that never occurred in the unoptimized program. To avoid this, we must terminate; the range that ``!1`` has the constant value assignment by inserting a poison; dbg.value before the dbg.value for ``!3``:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:23605,Performance,optimiz,optimized,23605,"doper; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. There are a few other dbg.value configurations that mean it terminates; dominating location definitions without adding a new location. The complete; list is:. * Any location operand is ``poison`` (or ``undef``).; * Any location operand is an empty metadata tuple (``!{}``) (which cannot; occur in a ``!DIArgList``).; * There are no location operands (empty ``DIArgList``) and the ``DIExpression``; is empty. This class of dbg.value that kills variable locations is called a ""kill; dbg.value"" or ""kill location"", and for legacy reasons the term ""undef; dbg.value"" may be used in existing code. The ``DbgVariableIntrinsic`` methods; ``isKillLocation`` and ``setKillLocation`` should be used where possible rather; than inspecting location operands directly to check or set whether a dbg.value; is a kill location. In general, if any dbg.value has its operand optimized out and cannot be; recovered, then a kill dbg.value is necessary to terminate earlier variable; locations. Additional kill dbg.values may be necessary when the debugger can; observe re-ordering of assignments. How variable location metadata is transformed during CodeGen; ============================================================. LLVM preserves debug information throughout mid-level and backend passes,; ultimately producing a mapping between source-level information and; instruction ranges. This; is relatively straightforwards for line number information, as mapping; instructions to line numbers is a simple association. For variable locations; however the story is more complex. As each ``llvm.dbg.value`` intrinsic; represents a source-level assignment of a value to a source variable, the; variable location intrinsics effectively embed a small imperative program; within the LLVM IR. By the end of CodeGen, this becomes a mapping from each; variable to their machine locations over ranges of in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:26881,Performance,optimiz,optimized,26881,"ifferent types of variable locations. In addition, some IR; locations become unavailable, for example if the operation of multiple IR; instructions are combined into one machine instruction (such as; multiply-and-accumulate) then intermediate Values are lost. To track variable; locations through instruction selection, they are first separated into; locations that do not depend on code generation (constants, stack locations,; allocated virtual registers) and those that do. For those that do, debug; metadata is attached to SDNodes in SelectionDAGs. After instruction selection; has occurred and a MIR function is created, if the SDNode associated with debug; metadata is allocated a virtual register, that virtual register is used as the; variable location. If the SDNode is folded into a machine instruction or; otherwise transformed into a non-register, the variable location becomes; unavailable. Locations that are unavailable are treated as if they have been optimized out:; in IR the location would be assigned ``undef`` by a debug intrinsic, and in MIR; the equivalent location is used. After MIR locations are assigned to each variable, machine pseudo-instructions; corresponding to each ``llvm.dbg.value`` intrinsic are inserted. There are two; forms of this type of instruction. The first form, ``DBG_VALUE``, appears thus:. .. code-block:: text. DBG_VALUE %1, $noreg, !123, !DIExpression(). And has the following operands:; * The first operand can record the variable location as a register,; a frame index, an immediate, or the base address register if the original; debug intrinsic referred to memory. ``$noreg`` indicates the variable; location is undefined, equivalent to an ``undef`` dbg.value operand.; * The type of the second operand indicates whether the variable location is; directly referred to by the DBG_VALUE, or whether it is indirect. The; ``$noreg`` register signifies the former, an immediate operand (0) the; latter.; * Operand 3 is the Variable field of the origin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:28904,Performance,optimiz,optimization,28904,"Expression field of the original debug intrinsic. The second form, ``DBG_VALUE_LIST``, appears thus:. .. code-block:: text. DBG_VALUE_LIST !123, !DIExpression(DW_OP_LLVM_arg, 0, DW_OP_LLVM_arg, 1, DW_OP_plus), %1, %2. And has the following operands:; * The first operand is the Variable field of the original debug intrinsic.; * The second operand is the Expression field of the original debug intrinsic.; * Any number of operands, from the 3rd onwards, record a sequence of variable; location operands, which may take any of the same values as the first; operand of the ``DBG_VALUE`` instruction above. These variable location; operands are inserted into the final DWARF Expression in positions indicated; by the DW_OP_LLVM_arg operator in the `DIExpression; <LangRef.html#diexpression>`_. The position at which the DBG_VALUEs are inserted should correspond to the; positions of their matching ``llvm.dbg.value`` intrinsics in the IR block. As; with optimization, LLVM aims to preserve the order in which variable; assignments occurred in the source program. However SelectionDAG performs some; instruction scheduling, which can reorder assignments (discussed below).; Function parameter locations are moved to the beginning of the function if; they're not already, to ensure they're immediately available on function entry. To demonstrate variable locations during instruction selection, consider; the following example:. .. code-block:: llvm. define i32 @foo(i32* %addr) {; entry:; call void @llvm.dbg.value(metadata i32 0, metadata !3, metadata !DIExpression()), !dbg !5; br label %bb1, !dbg !5. bb1: ; preds = %bb1, %entry; %bar.0 = phi i32 [ 0, %entry ], [ %add, %bb1 ]; call void @llvm.dbg.value(metadata i32 %bar.0, metadata !3, metadata !DIExpression()), !dbg !5; %addr1 = getelementptr i32, i32 *%addr, i32 1, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr1, metadata !3, metadata !DIExpression()), !dbg !5; %loaded1 = load i32, i32* %addr1, !dbg !5; %addr2 = getelementptr i32, i32",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:29034,Performance,perform,performs,29034,"ck:: text. DBG_VALUE_LIST !123, !DIExpression(DW_OP_LLVM_arg, 0, DW_OP_LLVM_arg, 1, DW_OP_plus), %1, %2. And has the following operands:; * The first operand is the Variable field of the original debug intrinsic.; * The second operand is the Expression field of the original debug intrinsic.; * Any number of operands, from the 3rd onwards, record a sequence of variable; location operands, which may take any of the same values as the first; operand of the ``DBG_VALUE`` instruction above. These variable location; operands are inserted into the final DWARF Expression in positions indicated; by the DW_OP_LLVM_arg operator in the `DIExpression; <LangRef.html#diexpression>`_. The position at which the DBG_VALUEs are inserted should correspond to the; positions of their matching ``llvm.dbg.value`` intrinsics in the IR block. As; with optimization, LLVM aims to preserve the order in which variable; assignments occurred in the source program. However SelectionDAG performs some; instruction scheduling, which can reorder assignments (discussed below).; Function parameter locations are moved to the beginning of the function if; they're not already, to ensure they're immediately available on function entry. To demonstrate variable locations during instruction selection, consider; the following example:. .. code-block:: llvm. define i32 @foo(i32* %addr) {; entry:; call void @llvm.dbg.value(metadata i32 0, metadata !3, metadata !DIExpression()), !dbg !5; br label %bb1, !dbg !5. bb1: ; preds = %bb1, %entry; %bar.0 = phi i32 [ 0, %entry ], [ %add, %bb1 ]; call void @llvm.dbg.value(metadata i32 %bar.0, metadata !3, metadata !DIExpression()), !dbg !5; %addr1 = getelementptr i32, i32 *%addr, i32 1, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr1, metadata !3, metadata !DIExpression()), !dbg !5; %loaded1 = load i32, i32* %addr1, !dbg !5; %addr2 = getelementptr i32, i32 *%addr, i32 %bar.0, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr2, metadata !3, metadata !DIExpression(",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:29890,Performance,load,load,29890,"R block. As; with optimization, LLVM aims to preserve the order in which variable; assignments occurred in the source program. However SelectionDAG performs some; instruction scheduling, which can reorder assignments (discussed below).; Function parameter locations are moved to the beginning of the function if; they're not already, to ensure they're immediately available on function entry. To demonstrate variable locations during instruction selection, consider; the following example:. .. code-block:: llvm. define i32 @foo(i32* %addr) {; entry:; call void @llvm.dbg.value(metadata i32 0, metadata !3, metadata !DIExpression()), !dbg !5; br label %bb1, !dbg !5. bb1: ; preds = %bb1, %entry; %bar.0 = phi i32 [ 0, %entry ], [ %add, %bb1 ]; call void @llvm.dbg.value(metadata i32 %bar.0, metadata !3, metadata !DIExpression()), !dbg !5; %addr1 = getelementptr i32, i32 *%addr, i32 1, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr1, metadata !3, metadata !DIExpression()), !dbg !5; %loaded1 = load i32, i32* %addr1, !dbg !5; %addr2 = getelementptr i32, i32 *%addr, i32 %bar.0, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr2, metadata !3, metadata !DIExpression()), !dbg !5; %loaded2 = load i32, i32* %addr2, !dbg !5; %add = add i32 %bar.0, 1, !dbg !5; call void @llvm.dbg.value(metadata i32 %add, metadata !3, metadata !DIExpression()), !dbg !5; %added = add i32 %loaded1, %loaded2; %cond = icmp ult i32 %added, %bar.0, !dbg !5; br i1 %cond, label %bb1, label %bb2, !dbg !5. bb2: ; preds = %bb1; ret i32 0, !dbg !5; }. If one compiles this IR with ``llc -o - -start-after=codegen-prepare -stop-after=expand-isel-pseudos -mtriple=x86_64--``, the following MIR is produced:. .. code-block:: text. bb.0.entry:; successors: %bb.1(0x80000000); liveins: $rdi. %2:gr64 = COPY $rdi; %3:gr32 = MOV32r0 implicit-def dead $eflags; DBG_VALUE 0, $noreg, !3, !DIExpression(), debug-location !5. bb.1.bb1:; successors: %bb.1(0x7c000000), %bb.2(0x04000000). %0:gr32 = PHI %3, %bb.0, %1, %bb.1; DBG",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:30091,Performance,load,load,30091,"which can reorder assignments (discussed below).; Function parameter locations are moved to the beginning of the function if; they're not already, to ensure they're immediately available on function entry. To demonstrate variable locations during instruction selection, consider; the following example:. .. code-block:: llvm. define i32 @foo(i32* %addr) {; entry:; call void @llvm.dbg.value(metadata i32 0, metadata !3, metadata !DIExpression()), !dbg !5; br label %bb1, !dbg !5. bb1: ; preds = %bb1, %entry; %bar.0 = phi i32 [ 0, %entry ], [ %add, %bb1 ]; call void @llvm.dbg.value(metadata i32 %bar.0, metadata !3, metadata !DIExpression()), !dbg !5; %addr1 = getelementptr i32, i32 *%addr, i32 1, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr1, metadata !3, metadata !DIExpression()), !dbg !5; %loaded1 = load i32, i32* %addr1, !dbg !5; %addr2 = getelementptr i32, i32 *%addr, i32 %bar.0, !dbg !5; call void @llvm.dbg.value(metadata i32 *%addr2, metadata !3, metadata !DIExpression()), !dbg !5; %loaded2 = load i32, i32* %addr2, !dbg !5; %add = add i32 %bar.0, 1, !dbg !5; call void @llvm.dbg.value(metadata i32 %add, metadata !3, metadata !DIExpression()), !dbg !5; %added = add i32 %loaded1, %loaded2; %cond = icmp ult i32 %added, %bar.0, !dbg !5; br i1 %cond, label %bb1, label %bb2, !dbg !5. bb2: ; preds = %bb1; ret i32 0, !dbg !5; }. If one compiles this IR with ``llc -o - -start-after=codegen-prepare -stop-after=expand-isel-pseudos -mtriple=x86_64--``, the following MIR is produced:. .. code-block:: text. bb.0.entry:; successors: %bb.1(0x80000000); liveins: $rdi. %2:gr64 = COPY $rdi; %3:gr32 = MOV32r0 implicit-def dead $eflags; DBG_VALUE 0, $noreg, !3, !DIExpression(), debug-location !5. bb.1.bb1:; successors: %bb.1(0x7c000000), %bb.2(0x04000000). %0:gr32 = PHI %3, %bb.0, %1, %bb.1; DBG_VALUE %0, $noreg, !3, !DIExpression(), debug-location !5; DBG_VALUE %2, $noreg, !3, !DIExpression(DW_OP_plus_uconst, 4, DW_OP_stack_value), debug-location !5; %4:gr32 = MOV32rm %2, 1, $",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:31113,Performance,load,load,31113,"lue(metadata i32 *%addr2, metadata !3, metadata !DIExpression()), !dbg !5; %loaded2 = load i32, i32* %addr2, !dbg !5; %add = add i32 %bar.0, 1, !dbg !5; call void @llvm.dbg.value(metadata i32 %add, metadata !3, metadata !DIExpression()), !dbg !5; %added = add i32 %loaded1, %loaded2; %cond = icmp ult i32 %added, %bar.0, !dbg !5; br i1 %cond, label %bb1, label %bb2, !dbg !5. bb2: ; preds = %bb1; ret i32 0, !dbg !5; }. If one compiles this IR with ``llc -o - -start-after=codegen-prepare -stop-after=expand-isel-pseudos -mtriple=x86_64--``, the following MIR is produced:. .. code-block:: text. bb.0.entry:; successors: %bb.1(0x80000000); liveins: $rdi. %2:gr64 = COPY $rdi; %3:gr32 = MOV32r0 implicit-def dead $eflags; DBG_VALUE 0, $noreg, !3, !DIExpression(), debug-location !5. bb.1.bb1:; successors: %bb.1(0x7c000000), %bb.2(0x04000000). %0:gr32 = PHI %3, %bb.0, %1, %bb.1; DBG_VALUE %0, $noreg, !3, !DIExpression(), debug-location !5; DBG_VALUE %2, $noreg, !3, !DIExpression(DW_OP_plus_uconst, 4, DW_OP_stack_value), debug-location !5; %4:gr32 = MOV32rm %2, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); %5:gr64_nosp = MOVSX64rr32 %0, debug-location !5; DBG_VALUE $noreg, $noreg, !3, !DIExpression(), debug-location !5; %1:gr32 = INC32r %0, implicit-def dead $eflags, debug-location !5; DBG_VALUE %1, $noreg, !3, !DIExpression(), debug-location !5; %6:gr32 = ADD32rm %4, %2, 4, killed %5, 0, $noreg, implicit-def dead $eflags :: (load 4 from %ir.addr2); %7:gr32 = SUB32rr %6, %0, implicit-def $eflags, debug-location !5; JB_1 %bb.1, implicit $eflags, debug-location !5; JMP_1 %bb.2, debug-location !5. bb.2.bb2:; %8:gr32 = MOV32r0 implicit-def dead $eflags; $eax = COPY %8, debug-location !5; RET 0, $eax, debug-location !5. Observe first that there is a DBG_VALUE instruction for every ``llvm.dbg.value``; intrinsic in the source IR, ensuring no source level assignments go missing.; Then consider the different ways in which variable locations have been recorded:. * For",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:31463,Performance,load,load,31463,"t i32 %added, %bar.0, !dbg !5; br i1 %cond, label %bb1, label %bb2, !dbg !5. bb2: ; preds = %bb1; ret i32 0, !dbg !5; }. If one compiles this IR with ``llc -o - -start-after=codegen-prepare -stop-after=expand-isel-pseudos -mtriple=x86_64--``, the following MIR is produced:. .. code-block:: text. bb.0.entry:; successors: %bb.1(0x80000000); liveins: $rdi. %2:gr64 = COPY $rdi; %3:gr32 = MOV32r0 implicit-def dead $eflags; DBG_VALUE 0, $noreg, !3, !DIExpression(), debug-location !5. bb.1.bb1:; successors: %bb.1(0x7c000000), %bb.2(0x04000000). %0:gr32 = PHI %3, %bb.0, %1, %bb.1; DBG_VALUE %0, $noreg, !3, !DIExpression(), debug-location !5; DBG_VALUE %2, $noreg, !3, !DIExpression(DW_OP_plus_uconst, 4, DW_OP_stack_value), debug-location !5; %4:gr32 = MOV32rm %2, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); %5:gr64_nosp = MOVSX64rr32 %0, debug-location !5; DBG_VALUE $noreg, $noreg, !3, !DIExpression(), debug-location !5; %1:gr32 = INC32r %0, implicit-def dead $eflags, debug-location !5; DBG_VALUE %1, $noreg, !3, !DIExpression(), debug-location !5; %6:gr32 = ADD32rm %4, %2, 4, killed %5, 0, $noreg, implicit-def dead $eflags :: (load 4 from %ir.addr2); %7:gr32 = SUB32rr %6, %0, implicit-def $eflags, debug-location !5; JB_1 %bb.1, implicit $eflags, debug-location !5; JMP_1 %bb.2, debug-location !5. bb.2.bb2:; %8:gr32 = MOV32r0 implicit-def dead $eflags; $eax = COPY %8, debug-location !5; RET 0, $eax, debug-location !5. Observe first that there is a DBG_VALUE instruction for every ``llvm.dbg.value``; intrinsic in the source IR, ensuring no source level assignments go missing.; Then consider the different ways in which variable locations have been recorded:. * For the first dbg.value an immediate operand is used to record a zero value.; * The dbg.value of the PHI instruction leads to a DBG_VALUE of virtual register; ``%0``.; * The first GEP has its effect folded into the first load instruction; (as a 4-byte offset), but the variable location is salvaged by ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:32223,Performance,load,load,32223,"2 = INC32r %0, implicit-def dead $eflags, debug-location !5; DBG_VALUE %1, $noreg, !3, !DIExpression(), debug-location !5; %6:gr32 = ADD32rm %4, %2, 4, killed %5, 0, $noreg, implicit-def dead $eflags :: (load 4 from %ir.addr2); %7:gr32 = SUB32rr %6, %0, implicit-def $eflags, debug-location !5; JB_1 %bb.1, implicit $eflags, debug-location !5; JMP_1 %bb.2, debug-location !5. bb.2.bb2:; %8:gr32 = MOV32r0 implicit-def dead $eflags; $eax = COPY %8, debug-location !5; RET 0, $eax, debug-location !5. Observe first that there is a DBG_VALUE instruction for every ``llvm.dbg.value``; intrinsic in the source IR, ensuring no source level assignments go missing.; Then consider the different ways in which variable locations have been recorded:. * For the first dbg.value an immediate operand is used to record a zero value.; * The dbg.value of the PHI instruction leads to a DBG_VALUE of virtual register; ``%0``.; * The first GEP has its effect folded into the first load instruction; (as a 4-byte offset), but the variable location is salvaged by folding; the GEPs effect into the DIExpression.; * The second GEP is also folded into the corresponding load. However, it is; insufficiently simple to be salvaged, and is emitted as a ``$noreg``; DBG_VALUE, indicating that the variable takes on an undefined location.; * The final dbg.value has its Value placed in virtual register ``%1``. Instruction Scheduling; ----------------------. A number of passes can reschedule instructions, notably instruction selection; and the pre-and-post RA machine schedulers. Instruction scheduling can; significantly change the nature of the program -- in the (very unlikely) worst; case the instruction sequence could be completely reversed. In such; circumstances LLVM follows the principle applied to optimizations, that it is; better for the debugger not to display any state than a misleading state.; Thus, whenever instructions are advanced in order of execution, any; corresponding DBG_VALUE is kept in its origin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:32408,Performance,load,load,32408,"%6:gr32 = ADD32rm %4, %2, 4, killed %5, 0, $noreg, implicit-def dead $eflags :: (load 4 from %ir.addr2); %7:gr32 = SUB32rr %6, %0, implicit-def $eflags, debug-location !5; JB_1 %bb.1, implicit $eflags, debug-location !5; JMP_1 %bb.2, debug-location !5. bb.2.bb2:; %8:gr32 = MOV32r0 implicit-def dead $eflags; $eax = COPY %8, debug-location !5; RET 0, $eax, debug-location !5. Observe first that there is a DBG_VALUE instruction for every ``llvm.dbg.value``; intrinsic in the source IR, ensuring no source level assignments go missing.; Then consider the different ways in which variable locations have been recorded:. * For the first dbg.value an immediate operand is used to record a zero value.; * The dbg.value of the PHI instruction leads to a DBG_VALUE of virtual register; ``%0``.; * The first GEP has its effect folded into the first load instruction; (as a 4-byte offset), but the variable location is salvaged by folding; the GEPs effect into the DIExpression.; * The second GEP is also folded into the corresponding load. However, it is; insufficiently simple to be salvaged, and is emitted as a ``$noreg``; DBG_VALUE, indicating that the variable takes on an undefined location.; * The final dbg.value has its Value placed in virtual register ``%1``. Instruction Scheduling; ----------------------. A number of passes can reschedule instructions, notably instruction selection; and the pre-and-post RA machine schedulers. Instruction scheduling can; significantly change the nature of the program -- in the (very unlikely) worst; case the instruction sequence could be completely reversed. In such; circumstances LLVM follows the principle applied to optimizations, that it is; better for the debugger not to display any state than a misleading state.; Thus, whenever instructions are advanced in order of execution, any; corresponding DBG_VALUE is kept in its original position, and if an instruction; is delayed then the variable is given an undefined location for the duration; of the d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:33044,Performance,optimiz,optimizations,33044,"d a zero value.; * The dbg.value of the PHI instruction leads to a DBG_VALUE of virtual register; ``%0``.; * The first GEP has its effect folded into the first load instruction; (as a 4-byte offset), but the variable location is salvaged by folding; the GEPs effect into the DIExpression.; * The second GEP is also folded into the corresponding load. However, it is; insufficiently simple to be salvaged, and is emitted as a ``$noreg``; DBG_VALUE, indicating that the variable takes on an undefined location.; * The final dbg.value has its Value placed in virtual register ``%1``. Instruction Scheduling; ----------------------. A number of passes can reschedule instructions, notably instruction selection; and the pre-and-post RA machine schedulers. Instruction scheduling can; significantly change the nature of the program -- in the (very unlikely) worst; case the instruction sequence could be completely reversed. In such; circumstances LLVM follows the principle applied to optimizations, that it is; better for the debugger not to display any state than a misleading state.; Thus, whenever instructions are advanced in order of execution, any; corresponding DBG_VALUE is kept in its original position, and if an instruction; is delayed then the variable is given an undefined location for the duration; of the delay. To illustrate, consider this pseudo-MIR:. .. code-block:: text. %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6. Imagine that the SUB32rr were moved forward to give us the following MIR:. .. code-block:: text. %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DB",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:33518,Performance,load,load,33518,"oreg``; DBG_VALUE, indicating that the variable takes on an undefined location.; * The final dbg.value has its Value placed in virtual register ``%1``. Instruction Scheduling; ----------------------. A number of passes can reschedule instructions, notably instruction selection; and the pre-and-post RA machine schedulers. Instruction scheduling can; significantly change the nature of the program -- in the (very unlikely) worst; case the instruction sequence could be completely reversed. In such; circumstances LLVM follows the principle applied to optimizations, that it is; better for the debugger not to display any state than a misleading state.; Thus, whenever instructions are advanced in order of execution, any; corresponding DBG_VALUE is kept in its original position, and if an instruction; is delayed then the variable is given an undefined location for the duration; of the delay. To illustrate, consider this pseudo-MIR:. .. code-block:: text. %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6. Imagine that the SUB32rr were moved forward to give us the following MIR:. .. code-block:: text. %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; DBG_VALUE %7, $noreg, !5, !6. In this circumstance LLVM would leave the MIR as shown above. Were we to move; the DBG_VALUE of virtual register %7 upwards with the SUB32rr, we would re-order; assignments and introduce a new state of the program. Whereas with the solution; above, the debugger will see one fewer combination of variable values, because; ``!3`` and ``!5`` will change value at the same ti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:33954,Performance,load,load,33954,"ery unlikely) worst; case the instruction sequence could be completely reversed. In such; circumstances LLVM follows the principle applied to optimizations, that it is; better for the debugger not to display any state than a misleading state.; Thus, whenever instructions are advanced in order of execution, any; corresponding DBG_VALUE is kept in its original position, and if an instruction; is delayed then the variable is given an undefined location for the duration; of the delay. To illustrate, consider this pseudo-MIR:. .. code-block:: text. %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6. Imagine that the SUB32rr were moved forward to give us the following MIR:. .. code-block:: text. %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; DBG_VALUE %7, $noreg, !5, !6. In this circumstance LLVM would leave the MIR as shown above. Were we to move; the DBG_VALUE of virtual register %7 upwards with the SUB32rr, we would re-order; assignments and introduce a new state of the program. Whereas with the solution; above, the debugger will see one fewer combination of variable values, because; ``!3`` and ``!5`` will change value at the same time. This is preferred over; misrepresenting the original program. In comparison, if one sunk the MOV32rm, LLVM would produce the following:. .. code-block:: text. DBG_VALUE $noreg, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, de",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:34922,Performance,load,load,34922," following MIR:. .. code-block:: text. %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; DBG_VALUE %7, $noreg, !5, !6. In this circumstance LLVM would leave the MIR as shown above. Were we to move; the DBG_VALUE of virtual register %7 upwards with the SUB32rr, we would re-order; assignments and introduce a new state of the program. Whereas with the solution; above, the debugger will see one fewer combination of variable values, because; ``!3`` and ``!5`` will change value at the same time. This is preferred over; misrepresenting the original program. In comparison, if one sunk the MOV32rm, LLVM would produce the following:. .. code-block:: text. DBG_VALUE $noreg, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2. Here, to avoid presenting a state in which the first assignment to ``!1``; disappears, the DBG_VALUE at the top of the block assigns the variable the; undefined location, until its value is available at the end of the block where; an additional DBG_VALUE is added. Were any other DBG_VALUE for ``!1`` to occur; in the instructions that the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:35887,Performance,perform,performed,35887," $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2. Here, to avoid presenting a state in which the first assignment to ``!1``; disappears, the DBG_VALUE at the top of the block assigns the variable the; undefined location, until its value is available at the end of the block where; an additional DBG_VALUE is added. Were any other DBG_VALUE for ``!1`` to occur; in the instructions that the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; correspo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:36544,Performance,optimiz,optimizations,36544," Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; corresponding to a source-level assignment where the variable may change value,; it asserts the location of a variable in a block, and loses effect outside the; block. Propagating variable locations through copies and spills is; straightforwards: determining the variable location in every basic block; requires the consideration of control flow. Consider the following IR, which; presents several difficulties:. .. code-block:: text. define dso_local i32 @foo(i1 %cond, i32 %input) !dbg !12 {; entry:; br i1 %cond, label %truebr, label %falsebr. bb1:; %value = phi i32 [ %value1, %truebr ], [ %value2, %falsebr ]; br label %exit, !dbg !26. truebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:40933,Performance,tune,tuned,40933,"of each instruction to every; valid variable location, without the need to consider control flow. From; the example above, it is otherwise difficult to determine that the location; of variable ``!30`` should flow ""up"" into block ``%bb1``, but that the location; of variable ``!23`` should not flow ""down"" into the ``%exit`` block. .. _ccxx_frontend:. C/C++ front-end specific debug information; ==========================================. The C and C++ front-ends represent information about the program in a; format that is effectively identical to `DWARF <http://www.dwarfstd.org/>`_; in terms of information content. This allows code generators to; trivially support native debuggers by generating standard dwarf; information, and contains enough information for non-dwarf targets to; translate it as needed. This section describes the forms used to represent C and C++ programs. Other; languages could pattern themselves after this (which itself is tuned to; representing programs in the same way that DWARF does), or they could choose; to provide completely different forms if they don't fit into the DWARF model.; As support for debugging information gets added to the various LLVM; source-language front-ends, the information used should be documented here. The following sections provide examples of a few C/C++ constructs and; the debug information that would best describe those constructs. The; canonical references are the ``DINode`` classes defined in; ``include/llvm/IR/DebugInfoMetadata.h`` and the implementations of the; helper functions in ``lib/IR/DIBuilder.cpp``. C/C++ source file information; -----------------------------. ``llvm::Instruction`` provides easy access to metadata attached with an; instruction. One can extract line number information encoded in LLVM IR using; ``Instruction::getDebugLoc()`` and ``DILocation::getLine()``. .. code-block:: c++. if (DILocation *Loc = I->getDebugLoc()) { // Here I is an LLVM instruction; unsigned Line = Loc->getLine();; StringRef ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:59226,Performance,optimiz,optimized,59226,"e an inlined copy of the string values in the table; itself making the tables much larger than they need to be on disk, especially; for large C++ programs. Can't we just fix the sections by adding all of the names we need to this; table? No, because that is not what the tables are defined to contain and we; won't know the difference between the old bad tables and the new good tables.; At best we could make our own renamed sections that contain all of the data we; need. These tables are also insufficient for what a debugger like LLDB needs. LLDB; uses clang for its expression parsing where LLDB acts as a PCH. LLDB is then; often asked to look for type ""``foo``"" or namespace ""``bar``"", or list items in; namespace ""``baz``"". Namespaces are not included in the pubnames or pubtypes; tables. Since clang asks a lot of questions when it is parsing an expression,; we need to be very fast when looking up names, as it happens a lot. Having new; accelerator tables that are optimized for very quick lookups will benefit this; type of debugging experience greatly. We would like to generate name lookup tables that can be mapped into memory; from disk, and used as is, with little or no up-front parsing. We would also; be able to control the exact content of these different tables so they contain; exactly what we need. The Name Accelerator Tables were designed to fix these; issues. In order to solve these issues we need to:. * Have a format that can be mapped into memory from disk and used as is; * Lookups should be very fast; * Extensible table format so these tables can be made by many producers; * Contain all of the names needed for typical lookups out of the box; * Strict rules for the contents of tables. Table size is important and the accelerator table format should allow the reuse; of strings from common string tables so the strings for the names are not; duplicated. We also want to make sure the table is ready to be used as-is by; simply mapping the table into memory with min",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:60308,Performance,optimiz,optimized,60308,"ould like to generate name lookup tables that can be mapped into memory; from disk, and used as is, with little or no up-front parsing. We would also; be able to control the exact content of these different tables so they contain; exactly what we need. The Name Accelerator Tables were designed to fix these; issues. In order to solve these issues we need to:. * Have a format that can be mapped into memory from disk and used as is; * Lookups should be very fast; * Extensible table format so these tables can be made by many producers; * Contain all of the names needed for typical lookups out of the box; * Strict rules for the contents of tables. Table size is important and the accelerator table format should allow the reuse; of strings from common string tables so the strings for the names are not; duplicated. We also want to make sure the table is ready to be used as-is by; simply mapping the table into memory with minimal header parsing. The name lookups need to be fast and optimized for the kinds of lookups that; debuggers tend to do. Optimally we would like to touch as few parts of the; mapped table as possible when doing a name lookup and be able to quickly find; the name entry we are looking for, or discover there are no matches. In the; case of debuggers we optimized for lookups that fail most of the time. Each table that is defined should have strict rules on exactly what is in the; accelerator tables and documented so clients can rely on the content. Hash Tables; ^^^^^^^^^^^. Standard Hash Tables; """""""""""""""""""""""""""""""""""""""". Typical hash tables have a header, buckets, and each bucket points to the; bucket contents:. .. code-block:: none. .------------.; | HEADER |; |------------|; | BUCKETS |; |------------|; | DATA |; `------------'. The BUCKETS are an array of offsets to DATA for each hash:. .. code-block:: none. .------------.; | 0x00001000 | BUCKETS[0]; | 0x00002000 | BUCKETS[1]; | 0x00002200 | BUCKETS[2]; | 0x000034f0 | BUCKETS[3]; | | ...; | 0xXXXXXXXX | BUCKE",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:60602,Performance,optimiz,optimized,60602,"ned to fix these; issues. In order to solve these issues we need to:. * Have a format that can be mapped into memory from disk and used as is; * Lookups should be very fast; * Extensible table format so these tables can be made by many producers; * Contain all of the names needed for typical lookups out of the box; * Strict rules for the contents of tables. Table size is important and the accelerator table format should allow the reuse; of strings from common string tables so the strings for the names are not; duplicated. We also want to make sure the table is ready to be used as-is by; simply mapping the table into memory with minimal header parsing. The name lookups need to be fast and optimized for the kinds of lookups that; debuggers tend to do. Optimally we would like to touch as few parts of the; mapped table as possible when doing a name lookup and be able to quickly find; the name entry we are looking for, or discover there are no matches. In the; case of debuggers we optimized for lookups that fail most of the time. Each table that is defined should have strict rules on exactly what is in the; accelerator tables and documented so clients can rely on the content. Hash Tables; ^^^^^^^^^^^. Standard Hash Tables; """""""""""""""""""""""""""""""""""""""". Typical hash tables have a header, buckets, and each bucket points to the; bucket contents:. .. code-block:: none. .------------.; | HEADER |; |------------|; | BUCKETS |; |------------|; | DATA |; `------------'. The BUCKETS are an array of offsets to DATA for each hash:. .. code-block:: none. .------------.; | 0x00001000 | BUCKETS[0]; | 0x00002000 | BUCKETS[1]; | 0x00002200 | BUCKETS[2]; | 0x000034f0 | BUCKETS[3]; | | ...; | 0xXXXXXXXX | BUCKETS[n_buckets]; '------------'. So for ``bucket[3]`` in the example above, we have an offset into the table; 0x000034f0 which points to a chain of entries for the bucket. Each bucket must; contain a next pointer, full 32 bit hash value, the string itself, and the data; for the current string ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:62164,Performance,optimiz,optimize,62164,"--.; | 0x00001000 | BUCKETS[0]; | 0x00002000 | BUCKETS[1]; | 0x00002200 | BUCKETS[2]; | 0x000034f0 | BUCKETS[3]; | | ...; | 0xXXXXXXXX | BUCKETS[n_buckets]; '------------'. So for ``bucket[3]`` in the example above, we have an offset into the table; 0x000034f0 which points to a chain of entries for the bucket. Each bucket must; contain a next pointer, full 32 bit hash value, the string itself, and the data; for the current string value. .. code-block:: none. .------------.; 0x000034f0: | 0x00003500 | next pointer; | 0x12345678 | 32 bit hash; | ""erase"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003500: | 0x00003550 | next pointer; | 0x29273623 | 32 bit hash; | ""dump"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003550: | 0x00000000 | next pointer; | 0x82638293 | 32 bit hash; | ""main"" | string value; | data[n] | HashData for this bucket; `------------'. The problem with this layout for debuggers is that we need to optimize for the; negative lookup case where the symbol we're searching for is not present. So; if we were to lookup ""``printf``"" in the table above, we would make a 32-bit; hash for ""``printf``"", it might match ``bucket[3]``. We would need to go to; the offset 0x000034f0 and start looking to see if our 32 bit hash matches. To; do so, we need to read the next pointer, then read the hash, compare it, and; skip to the next bucket. Each time we are skipping many bytes in memory and; touching new pages just to do the compare on the full 32 bit hash. All of; these accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the hash tables a bit; differently: a header, buckets, an array of all unique 32 bit hash values,; followed by an array of hash value data offsets, one for each hash value, then; the data for all hash values:. .. code-block:: none. .-------------.; | HEADER |; |-------------|; | BUCKETS |; |-------------|",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:67896,Performance,cache,cache,67896,"5]; | 0x........ | HashData[6]; | 0x........ | HashData[7]; | 0x........ | HashData[8]; | 0x00000000 | String offset into .debug_str (terminate data for hash); `------------'. So we still have all of the same data, we just organize it more efficiently for; debugger lookup. If we repeat the same ""``printf``"" lookup from above, we; would hash ""``printf``"" and find it matches ``BUCKETS[3]`` by taking the 32 bit; hash value and modulo it by ``n_buckets``. ``BUCKETS[3]`` contains ""6"" which; is the index into the ``HASHES`` table. We would then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stored (""``KeyType``"") and the content of the data for each; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magic; // 'HASH' magic value to allow endian detection; uint16_t version; // Version number; uint16_t hash_function; // The hash function enumeration that was used; u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:4156,Safety,avoid,avoid,4156,"nfo format, which is usable with Microsoft debuggers such; as Visual Studio and WinDBG. LLVM's debug information format is mostly derived; from and inspired by DWARF, but it is feasible to translate into other target; debug info formats such as STABS. It would also be reasonable to use debug information to feed profiling tools; for analysis of generated code, or, tools for reconstructing the original; source from generated code. .. _intro_debugopt:. Debug information and optimizations; -----------------------------------. An extremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformations to avoid; breaking this guarantee, and how to preserve as much useful debug info as; possible. Note that some optimizations may impact the ability to modify the; current state of the program with a debugger, such as setting program; variables, or calling functions that have been deleted. * As desired, LLVM optimizations can be upgraded to be aware of debugging; information, allowing them to update the debugging information as they; perform aggressive optimizations. This means that, with effort, the LLVM; optimizers could optimize debug code just as well as non-debug code. * LLVM debug information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:6555,Safety,avoid,avoids,6555,"the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids duplicated debugging information from; the beginning, and the global dead code elimination pass automatically deletes; debugging information for a function if it decides to delete the function. To do this, most of the debugging information (descriptors for types,; variables, functions, source files, etc) is inserted by the language front-end; in the form of LLVM metadata. Debug information is designed to be agnostic about the target debugger and; debugging information representation (e.g. DWARF/Stabs/etc). It uses a generic; pass to decode the information that represents variables, types, functions,; namespaces, etc: this allows for arbitrary source-language semantics and; type-systems to be used, as long as there is a module written for the target; debugger to interpret the information. To provide basic functionality, the LLVM debugger does have to make some; assumptions about the source-level language being debugged, though it keeps; these to a minimum. The only common features that the LLVM debugger assumes; exist are `source files <LangRef.html#difile>`_,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:13856,Safety,unsafe,unsafe-fp-math,13856,"ke this:. .. code-block:: text. ; Function Attrs: nounwind ssp uwtable; define void @foo() #0 !dbg !4 {; entry:; %X = alloca i32, align 4; %Y = alloca i32, align 4; %Z = alloca i32, align 4; call void @llvm.dbg.declare(metadata i32* %X, metadata !11, metadata !13), !dbg !14; store i32 21, i32* %X, align 4, !dbg !14; call void @llvm.dbg.declare(metadata i32* %Y, metadata !15, metadata !13), !dbg !16; store i32 22, i32* %Y, align 4, !dbg !16; call void @llvm.dbg.declare(metadata i32* %Z, metadata !17, metadata !13), !dbg !19; store i32 23, i32* %Z, align 4, !dbg !19; %0 = load i32, i32* %X, align 4, !dbg !20; store i32 %0, i32* %Z, align 4, !dbg !21; %1 = load i32, i32* %Y, align 4, !dbg !22; store i32 %1, i32* %X, align 4, !dbg !23; ret void, !dbg !24; }. ; Function Attrs: nounwind readnone; declare void @llvm.dbg.declare(metadata, metadata, metadata) #1. attributes #0 = { nounwind ssp uwtable ""less-precise-fpmad""=""false"" ""frame-pointer""=""all"" ""no-infs-fp-math""=""false"" ""no-nans-fp-math""=""false"" ""stack-protector-buffer-size""=""8"" ""unsafe-fp-math""=""false"" ""use-soft-float""=""false"" }; attributes #1 = { nounwind readnone }. !llvm.dbg.cu = !{!0}; !llvm.module.flags = !{!7, !8, !9}; !llvm.ident = !{!10}. !0 = !DICompileUnit(language: DW_LANG_C99, file: !1, producer: ""clang version 3.7.0 (trunk 231150) (llvm/trunk 231154)"", isOptimized: false, runtimeVersion: 0, emissionKind: FullDebug, enums: !2, retainedTypes: !2, subprograms: !3, globals: !2, imports: !2); !1 = !DIFile(filename: ""/dev/stdin"", directory: ""/Users/dexonsmith/data/llvm/debug-info""); !2 = !{}; !3 = !{!4}; !4 = distinct !DISubprogram(name: ""foo"", scope: !1, file: !1, line: 1, type: !5, isLocal: false, isDefinition: true, scopeLine: 1, isOptimized: false, retainedNodes: !2); !5 = !DISubroutineType(types: !6); !6 = !{null}; !7 = !{i32 2, !""Dwarf Version"", i32 2}; !8 = !{i32 2, !""Debug Info Version"", i32 3}; !9 = !{i32 1, !""PIC Level"", i32 2}; !10 = !{!""clang version 3.7.0 (trunk 231150) (llvm/trunk 231154)""}; !11 ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:19184,Safety,risk,risks,19184," created for each assignment, recording the; variable's new location. Compared with the ``llvm.dbg.declare`` intrinsic:. * A dbg.value terminates the effect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from the developer diminishes the; amount of available debug information, but increases the reliability of the; remaining information. To illustrate some potential issues, consider the following example:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); br i1 %cond, label %truebr, label %falsebr; truebr:; %tval = add i32 %bar, 1; call @llvm.dbg.value(metadata i32 %tval, metadata !1, metadata !2); %g1 = call i32 @gazonk(); br label %exit; falsebr:; %fval = add i3",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:19439,Safety,redund,redundant,19439,"fect of any preceding dbg.values for (any; overlapping fragments of) the specified variable.; * The dbg.value's position in the IR defines where in the instruction stream; the variable's value changes.; * Operands can be constants, indicating the variable is assigned a; constant value. Care must be taken to update ``llvm.dbg.value`` intrinsics when optimization; passes alter or move instructions and blocks -- the developer could observe such; changes reflected in the value of variables when debugging the program. For any; execution of the optimized program, the set of variable values presented to the; developer by the debugger should not show a state that would never have existed; in the execution of the unoptimized program, given the same input. Doing so; risks misleading the developer by reporting a state that does not exist,; damaging their understanding of the optimized program and undermining their; trust in the debugger. Sometimes perfectly preserving variable locations is not possible, often when a; redundant calculation is optimized out. In such cases, a ``llvm.dbg.value``; with operand ``poison`` should be used, to terminate earlier variable locations; and let the debugger present ``optimized out`` to the developer. Withholding; these potentially stale variable values from the developer diminishes the; amount of available debug information, but increases the reliability of the; remaining information. To illustrate some potential issues, consider the following example:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); br i1 %cond, label %truebr, label %falsebr; truebr:; %tval = add i32 %bar, 1; call @llvm.dbg.value(metadata i32 %tval, metadata !1, metadata !2); %g1 = call i32 @gazonk(); br label %exit; falsebr:; %fval = add i32 %bar, 2; call @llvm.dbg.value(metadata i32 %fval, metadata !1, metadata !2); %g2 = call i32 @gazonk(); br label %exit; exit:; %merge = phi [ %tval, %tr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:21412,Safety,recover,recover,21412,"fval, %falsebr ]; %g = phi [ %g1, %truebr ], [ %g2, %falsebr ]; call @llvm.dbg.value(metadata i32 %merge, metadata !1, metadata !2); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %plusten = add i32 %merge, 10; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. Containing two source-level variables in ``!1`` and ``!3``. The function could,; perhaps, be optimized into the following code:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; %g = call i32 @gazonk(); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; ret i32 %toret; }. What ``llvm.dbg.value`` intrinsics should be placed to represent the original variable; locations in this code? Unfortunately the second, third and fourth; dbg.values for ``!1`` in the source function have had their operands; (%tval, %fval, %merge) optimized out. Assuming we cannot recover them, we; might consider this placement of dbg.values:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); %g = call i32 @gazonk(); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. However, this will cause ``!3`` to have the return value of ``@gazonk()`` at; the same time as ``!1`` has the constant value zero -- a pair of assignments; that never occurred in the unoptimized program. To avoid this, we must terminate; the range that ``!1`` has the constant value assignment by inserting a poison; dbg.value before the dbg.value for ``!3``:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); %g = call i32 @gazonk(); call @llvm.dbg",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:22104,Safety,avoid,avoid,22104,"sics should be placed to represent the original variable; locations in this code? Unfortunately the second, third and fourth; dbg.values for ``!1`` in the source function have had their operands; (%tval, %fval, %merge) optimized out. Assuming we cannot recover them, we; might consider this placement of dbg.values:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); %g = call i32 @gazonk(); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. However, this will cause ``!3`` to have the return value of ``@gazonk()`` at; the same time as ``!1`` has the constant value zero -- a pair of assignments; that never occurred in the unoptimized program. To avoid this, we must terminate; the range that ``!1`` has the constant value assignment by inserting a poison; dbg.value before the dbg.value for ``!3``:. .. code-block:: llvm. define i32 @foo(i32 %bar, i1 %cond) {; entry:; call @llvm.dbg.value(metadata i32 0, metadata !1, metadata !2); %g = call i32 @gazonk(); call @llvm.dbg.value(metadata i32 poison, metadata !1, metadata !2); call @llvm.dbg.value(metadata i32 %g, metadata !3, metadata !2); %addoper = select i1 %cond, i32 11, i32 12; %plusten = add i32 %bar, %addoper; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. There are a few other dbg.value configurations that mean it terminates; dominating location definitions without adding a new location. The complete; list is:. * Any location operand is ``poison`` (or ``undef``).; * Any location operand is an empty metadata tuple (``!{}``) (which cannot; occur in a ``!DIArgList``).; * There are no location operands (empty ``DIArgList``) and the ``DIExpression``; is empty. Thi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:23634,Safety,recover,recovered,23634,"doper; %toret = add i32 %plusten, %g; call @llvm.dbg.value(metadata i32 %toret, metadata !1, metadata !2); ret i32 %toret; }. There are a few other dbg.value configurations that mean it terminates; dominating location definitions without adding a new location. The complete; list is:. * Any location operand is ``poison`` (or ``undef``).; * Any location operand is an empty metadata tuple (``!{}``) (which cannot; occur in a ``!DIArgList``).; * There are no location operands (empty ``DIArgList``) and the ``DIExpression``; is empty. This class of dbg.value that kills variable locations is called a ""kill; dbg.value"" or ""kill location"", and for legacy reasons the term ""undef; dbg.value"" may be used in existing code. The ``DbgVariableIntrinsic`` methods; ``isKillLocation`` and ``setKillLocation`` should be used where possible rather; than inspecting location operands directly to check or set whether a dbg.value; is a kill location. In general, if any dbg.value has its operand optimized out and cannot be; recovered, then a kill dbg.value is necessary to terminate earlier variable; locations. Additional kill dbg.values may be necessary when the debugger can; observe re-ordering of assignments. How variable location metadata is transformed during CodeGen; ============================================================. LLVM preserves debug information throughout mid-level and backend passes,; ultimately producing a mapping between source-level information and; instruction ranges. This; is relatively straightforwards for line number information, as mapping; instructions to line numbers is a simple association. For variable locations; however the story is more complex. As each ``llvm.dbg.value`` intrinsic; represents a source-level assignment of a value to a source variable, the; variable location intrinsics effectively embed a small imperative program; within the LLVM IR. By the end of CodeGen, this becomes a mapping from each; variable to their machine locations over ranges of in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:34985,Safety,avoid,avoid,34985,"oreg, !5, !6. In this circumstance LLVM would leave the MIR as shown above. Were we to move; the DBG_VALUE of virtual register %7 upwards with the SUB32rr, we would re-order; assignments and introduce a new state of the program. Whereas with the solution; above, the debugger will see one fewer combination of variable values, because; ``!3`` and ``!5`` will change value at the same time. This is preferred over; misrepresenting the original program. In comparison, if one sunk the MOV32rm, LLVM would produce the following:. .. code-block:: text. DBG_VALUE $noreg, $noreg, !1, !2; %4:gr32 = ADD32rr %3, %2, implicit-def dead $eflags; DBG_VALUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2. Here, to avoid presenting a state in which the first assignment to ``!1``; disappears, the DBG_VALUE at the top of the block assigns the variable the; undefined location, until its value is available at the end of the block where; an additional DBG_VALUE is added. Were any other DBG_VALUE for ``!1`` to occur; in the instructions that the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:35653,Safety,avoid,avoid,35653,"LUE %4, $noreg, !3, !4; %7:gr32 = SUB32rr %6, %5, implicit-def dead $eflags; DBG_VALUE %7, $noreg, !5, !6; %1:gr32 = MOV32rm %0, 1, $noreg, 4, $noreg, debug-location !5 :: (load 4 from %ir.addr1); DBG_VALUE %1, $noreg, !1, !2. Here, to avoid presenting a state in which the first assignment to ``!1``; disappears, the DBG_VALUE at the top of the block assigns the variable the; undefined location, until its value is available at the end of the block where; an additional DBG_VALUE is added. Were any other DBG_VALUE for ``!1`` to occur; in the instructions that the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:36112,Safety,avoid,avoid,36112," of the block where; an additional DBG_VALUE is added. Were any other DBG_VALUE for ``!1`` to occur; in the instructions that the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; corresponding to a source-level assignment where the variable may change value,; it asserts the location of a variable in a block, and loses effect outside the; block. Propagating variable locations through copies and spills is; straightforwards: determining the variable location in every basic block; requires t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:36299,Safety,redund,redundant,36299," the MOV32rm was sunk past, the DBG_VALUE for ``%1``; would be dropped and the debugger would never observe it in the variable. This; accurately reflects that the value is not available during the corresponding; portion of the original program. Variable locations during Register Allocation; ---------------------------------------------. To avoid debug instructions interfering with the register allocator, the; LiveDebugVariables pass extracts variable locations from a MIR function and; deletes the corresponding DBG_VALUE instructions. Some localized copy; propagation is performed within blocks. After register allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; corresponding to a source-level assignment where the variable may change value,; it asserts the location of a variable in a block, and loses effect outside the; block. Propagating variable locations through copies and spills is; straightforwards: determining the variable location in every basic block; requires the consideration of control flow. Consider the following IR, which; presents several difficulties:. .. code-block:: text. defi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:39229,Safety,avoid,avoid,39229,".value`` intrinsics essentially form an; imperative program embedded in the IR, with each intrinsic defining a variable; location. This *could* be converted to an SSA form by mem2reg, in the same way; that it uses use-def chains to identify control flow merges and insert phi; nodes for IR Values. However, because debug variable locations are defined for; every machine instruction, in effect every IR instruction uses every variable; location, which would lead to a large number of debugging intrinsics being; generated. Examining the example above, variable ``!30`` is assigned ``%input`` on both; conditional paths through the function, while ``!23`` is assigned differing; constant values on either path. Where control flow merges in ``%bb1`` we would; want ``!30`` to keep its location (``%input``), but ``!23`` to become undefined; as we cannot determine at runtime what value it should have in %bb1 without; inserting a PHI node. mem2reg does not insert the PHI node to avoid changing; codegen when debugging is enabled, and does not insert the other dbg.values; to avoid adding very large numbers of intrinsics. Instead, LiveDebugValues determines variable locations when control; flow merges. A dataflow analysis is used to propagate locations between blocks:; when control flow merges, if a variable has the same location in all; predecessors then that location is propagated into the successor. If the; predecessor locations disagree, the location becomes undefined. Once LiveDebugValues has run, every block should have all valid variable; locations described by DBG_VALUE instructions within the block. Very little; effort is then required by supporting classes (such as; DbgEntityHistoryCalculator) to build a map of each instruction to every; valid variable location, without the need to consider control flow. From; the example above, it is otherwise difficult to determine that the location; of variable ``!30`` should flow ""up"" into block ``%bb1``, but that the location; of variab",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:39325,Safety,avoid,avoid,39325,"ntrinsic defining a variable; location. This *could* be converted to an SSA form by mem2reg, in the same way; that it uses use-def chains to identify control flow merges and insert phi; nodes for IR Values. However, because debug variable locations are defined for; every machine instruction, in effect every IR instruction uses every variable; location, which would lead to a large number of debugging intrinsics being; generated. Examining the example above, variable ``!30`` is assigned ``%input`` on both; conditional paths through the function, while ``!23`` is assigned differing; constant values on either path. Where control flow merges in ``%bb1`` we would; want ``!30`` to keep its location (``%input``), but ``!23`` to become undefined; as we cannot determine at runtime what value it should have in %bb1 without; inserting a PHI node. mem2reg does not insert the PHI node to avoid changing; codegen when debugging is enabled, and does not insert the other dbg.values; to avoid adding very large numbers of intrinsics. Instead, LiveDebugValues determines variable locations when control; flow merges. A dataflow analysis is used to propagate locations between blocks:; when control flow merges, if a variable has the same location in all; predecessors then that location is propagated into the successor. If the; predecessor locations disagree, the location becomes undefined. Once LiveDebugValues has run, every block should have all valid variable; locations described by DBG_VALUE instructions within the block. Very little; effort is then required by supporting classes (such as; DbgEntityHistoryCalculator) to build a map of each instruction to every; valid variable location, without the need to consider control flow. From; the example above, it is otherwise difficult to determine that the location; of variable ``!30`` should flow ""up"" into block ``%bb1``, but that the location; of variable ``!23`` should not flow ""down"" into the ``%exit`` block. .. _ccxx_frontend:. C/C++ front-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:42453,Safety,avoid,avoid,42453,"gInfoMetadata.h`` and the implementations of the; helper functions in ``lib/IR/DIBuilder.cpp``. C/C++ source file information; -----------------------------. ``llvm::Instruction`` provides easy access to metadata attached with an; instruction. One can extract line number information encoded in LLVM IR using; ``Instruction::getDebugLoc()`` and ``DILocation::getLine()``. .. code-block:: c++. if (DILocation *Loc = I->getDebugLoc()) { // Here I is an LLVM instruction; unsigned Line = Loc->getLine();; StringRef File = Loc->getFilename();; StringRef Dir = Loc->getDirectory();; bool ImplicitCode = Loc->isImplicitCode();; }. When the flag ImplicitCode is true then it means that the Instruction has been; added by the front-end but doesn't correspond to source code written by the user. For example. .. code-block:: c++. if (MyBoolean) {; MyObject MO;; ...; }. At the end of the scope the MyObject's destructor is called but it isn't written; explicitly. This information is useful to avoid to have counters on brackets when; making code coverage. C/C++ global variable information; ---------------------------------. Given an integer global variable declared as follows:. .. code-block:: c. _Alignas(8) int MyGlobal = 100;. a C/C++ front-end would generate the following descriptors:. .. code-block:: text. ;;; ;; Define the global itself.; ;;; @MyGlobal = global i32 100, align 8, !dbg !0. ;;; ;; List of debug info of globals; ;;; !llvm.dbg.cu = !{!1}. ;; Some unrelated metadata.; !llvm.module.flags = !{!6, !7}; !llvm.ident = !{!8}. ;; Define the global variable itself; !0 = distinct !DIGlobalVariable(name: ""MyGlobal"", scope: !1, file: !2, line: 1, type: !5, isLocal: false, isDefinition: true, align: 64). ;; Define the compile unit.; !1 = distinct !DICompileUnit(language: DW_LANG_C99, file: !2,; producer: ""clang version 4.0.0"",; isOptimized: false, runtimeVersion: 0, emissionKind: FullDebug,; enums: !3, globals: !4). ;;; ;; Define the file; ;;; !2 = !DIFile(filename: ""/dev/stdin"",; direc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:68746,Safety,detect,detection,68746,"he Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stored (""``KeyType``"") and the content of the data for each; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magic; // 'HASH' magic value to allow endian detection; uint16_t version; // Version number; uint16_t hash_function; // The hash function enumeration that was used; uint32_t bucket_count; // The number of buckets in this hash table; uint32_t hashes_count; // The total number of unique hash values and hash data offsets in this table; uint32_t header_data_len; // The bytes to skip to get to the hash indexes (buckets) for correct alignment; // Specifically the length of the following HeaderData field - this does not; // include the size of the preceding fields; HeaderData header_data; // Implementation specific header data; };. The header starts with a 32 bit ""``magic``"" value which must be ``'HASH'``; encoded as an ASCII integer. This allows the detection of the start of the; hash table and also allows the table's byte order to be determined so the table; can be correctly extracted. The ""``magic``"" value is followed by a 16 bit; ``version`` number which allows the table to be revised and modified in the; future. The current version number is 1. ``hash_function`` is a ``uint16_t``; enumeration that specifies which hash function was used to produce this table.; The current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:69455,Safety,detect,detection,69455,"ach; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magic; // 'HASH' magic value to allow endian detection; uint16_t version; // Version number; uint16_t hash_function; // The hash function enumeration that was used; uint32_t bucket_count; // The number of buckets in this hash table; uint32_t hashes_count; // The total number of unique hash values and hash data offsets in this table; uint32_t header_data_len; // The bytes to skip to get to the hash indexes (buckets) for correct alignment; // Specifically the length of the following HeaderData field - this does not; // include the size of the preceding fields; HeaderData header_data; // Implementation specific header data; };. The header starts with a 32 bit ""``magic``"" value which must be ``'HASH'``; encoded as an ASCII integer. This allows the detection of the start of the; hash table and also allows the table's byte order to be determined so the table; can be correctly extracted. The ""``magic``"" value is followed by a 16 bit; ``version`` number which allows the table to be revised and modified in the; future. The current version number is 1. ``hash_function`` is a ``uint16_t``; enumeration that specifies which hash function was used to produce this table.; The current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB = 0u, // Daniel J Bernstein hash function; };. ``bucket_count`` is a 32 bit unsigned integer that represents how many buckets; are in the ``BUCKETS`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:41662,Security,access,access,41662,"y generating standard dwarf; information, and contains enough information for non-dwarf targets to; translate it as needed. This section describes the forms used to represent C and C++ programs. Other; languages could pattern themselves after this (which itself is tuned to; representing programs in the same way that DWARF does), or they could choose; to provide completely different forms if they don't fit into the DWARF model.; As support for debugging information gets added to the various LLVM; source-language front-ends, the information used should be documented here. The following sections provide examples of a few C/C++ constructs and; the debug information that would best describe those constructs. The; canonical references are the ``DINode`` classes defined in; ``include/llvm/IR/DebugInfoMetadata.h`` and the implementations of the; helper functions in ``lib/IR/DIBuilder.cpp``. C/C++ source file information; -----------------------------. ``llvm::Instruction`` provides easy access to metadata attached with an; instruction. One can extract line number information encoded in LLVM IR using; ``Instruction::getDebugLoc()`` and ``DILocation::getLine()``. .. code-block:: c++. if (DILocation *Loc = I->getDebugLoc()) { // Here I is an LLVM instruction; unsigned Line = Loc->getLine();; StringRef File = Loc->getFilename();; StringRef Dir = Loc->getDirectory();; bool ImplicitCode = Loc->isImplicitCode();; }. When the flag ImplicitCode is true then it means that the Instruction has been; added by the front-end but doesn't correspond to source code written by the user. For example. .. code-block:: c++. if (MyBoolean) {; MyObject MO;; ...; }. At the end of the scope the MyObject's destructor is called but it isn't written; explicitly. This information is useful to avoid to have counters on brackets when; making code coverage. C/C++ global variable information; ---------------------------------. Given an integer global variable declared as follows:. .. code-block:: c. _Alignas",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:49310,Security,access,accessor,49310,"ref); ...; DW_AT_artificial (true). A Fortran front-end may need to generate a *trampoline* function to call a; function defined in a different compilation unit. In this case, the front-end; can emit the following descriptor for the trampoline function:. .. code-block:: text. !DISubprogram(name: ""sub1_.t0p"", linkageName: ""sub1_.t0p"", scope: !4, file: !4, type: !5, spFlags: DISPFlagLocalToUnit | DISPFlagDefinition, unit: !7, retainedNodes: !24, targetFuncName: ""sub1_""). The targetFuncName field is the name of the function that the trampoline; calls. This descriptor results in the following DWARF tag:. .. code-block:: text. DW_TAG_subprogram; ...; DW_AT_linkage_name	(""sub1_.t0p""); DW_AT_name	(""sub1_.t0p""); DW_AT_trampoline	(""sub1_""). Debugging information format; ============================. Debugging Information Extension for Objective C Properties; ----------------------------------------------------------. Introduction; ^^^^^^^^^^^^. Objective C provides a simpler way to declare and define accessor methods using; declared properties. The language provides features to declare a property and; to let compiler synthesize accessor methods. The debugger lets developer inspect Objective C interfaces and their instance; variables and class variables. However, the debugger does not know anything; about the properties defined in Objective C interfaces. The debugger consumes; information generated by compiler in DWARF format. The format does not support; encoding of Objective C properties. This proposal describes DWARF extensions to; encode Objective C properties, which the debugger can use to let developers; inspect Objective C properties. Proposal; ^^^^^^^^. Objective C properties exist separately from class members. A property can be; defined only by ""setter"" and ""getter"" selectors, and be calculated anew on each; access. Or a property can just be a direct access to some declared ivar.; Finally it can have an ivar ""automatically synthesized"" for it by the compiler,; in wh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:49440,Security,access,accessor,49440,"o call a; function defined in a different compilation unit. In this case, the front-end; can emit the following descriptor for the trampoline function:. .. code-block:: text. !DISubprogram(name: ""sub1_.t0p"", linkageName: ""sub1_.t0p"", scope: !4, file: !4, type: !5, spFlags: DISPFlagLocalToUnit | DISPFlagDefinition, unit: !7, retainedNodes: !24, targetFuncName: ""sub1_""). The targetFuncName field is the name of the function that the trampoline; calls. This descriptor results in the following DWARF tag:. .. code-block:: text. DW_TAG_subprogram; ...; DW_AT_linkage_name	(""sub1_.t0p""); DW_AT_name	(""sub1_.t0p""); DW_AT_trampoline	(""sub1_""). Debugging information format; ============================. Debugging Information Extension for Objective C Properties; ----------------------------------------------------------. Introduction; ^^^^^^^^^^^^. Objective C provides a simpler way to declare and define accessor methods using; declared properties. The language provides features to declare a property and; to let compiler synthesize accessor methods. The debugger lets developer inspect Objective C interfaces and their instance; variables and class variables. However, the debugger does not know anything; about the properties defined in Objective C interfaces. The debugger consumes; information generated by compiler in DWARF format. The format does not support; encoding of Objective C properties. This proposal describes DWARF extensions to; encode Objective C properties, which the debugger can use to let developers; inspect Objective C properties. Proposal; ^^^^^^^^. Objective C properties exist separately from class members. A property can be; defined only by ""setter"" and ""getter"" selectors, and be calculated anew on each; access. Or a property can just be a direct access to some declared ivar.; Finally it can have an ivar ""automatically synthesized"" for it by the compiler,; in which case the property can be referred to in user code directly using the; standard C dereference syntax",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:50143,Security,access,access,50143,"=======. Debugging Information Extension for Objective C Properties; ----------------------------------------------------------. Introduction; ^^^^^^^^^^^^. Objective C provides a simpler way to declare and define accessor methods using; declared properties. The language provides features to declare a property and; to let compiler synthesize accessor methods. The debugger lets developer inspect Objective C interfaces and their instance; variables and class variables. However, the debugger does not know anything; about the properties defined in Objective C interfaces. The debugger consumes; information generated by compiler in DWARF format. The format does not support; encoding of Objective C properties. This proposal describes DWARF extensions to; encode Objective C properties, which the debugger can use to let developers; inspect Objective C properties. Proposal; ^^^^^^^^. Objective C properties exist separately from class members. A property can be; defined only by ""setter"" and ""getter"" selectors, and be calculated anew on each; access. Or a property can just be a direct access to some declared ivar.; Finally it can have an ivar ""automatically synthesized"" for it by the compiler,; in which case the property can be referred to in user code directly using the; standard C dereference syntax as well as through the property ""dot"" syntax, but; there is no entry in the ``@interface`` declaration corresponding to this ivar. To facilitate debugging, these properties we will add a new DWARF TAG into the; ``DW_TAG_structure_type`` definition for the class to hold the description of a; given property, and a set of DWARF attributes that provide said description.; The property tag will also contain the name and declared type of the property. If there is a related ivar, there will also be a DWARF property attribute placed; in the ``DW_TAG_member`` DIE for that ivar referring back to the property TAG; for that property. And in the case where the compiler synthesizes the ivar; dir",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:50186,Security,access,access,50186,"-----------------------------------------. Introduction; ^^^^^^^^^^^^. Objective C provides a simpler way to declare and define accessor methods using; declared properties. The language provides features to declare a property and; to let compiler synthesize accessor methods. The debugger lets developer inspect Objective C interfaces and their instance; variables and class variables. However, the debugger does not know anything; about the properties defined in Objective C interfaces. The debugger consumes; information generated by compiler in DWARF format. The format does not support; encoding of Objective C properties. This proposal describes DWARF extensions to; encode Objective C properties, which the debugger can use to let developers; inspect Objective C properties. Proposal; ^^^^^^^^. Objective C properties exist separately from class members. A property can be; defined only by ""setter"" and ""getter"" selectors, and be calculated anew on each; access. Or a property can just be a direct access to some declared ivar.; Finally it can have an ivar ""automatically synthesized"" for it by the compiler,; in which case the property can be referred to in user code directly using the; standard C dereference syntax as well as through the property ""dot"" syntax, but; there is no entry in the ``@interface`` declaration corresponding to this ivar. To facilitate debugging, these properties we will add a new DWARF TAG into the; ``DW_TAG_structure_type`` definition for the class to hold the description of a; given property, and a set of DWARF attributes that provide said description.; The property tag will also contain the name and declared type of the property. If there is a related ivar, there will also be a DWARF property attribute placed; in the ``DW_TAG_member`` DIE for that ivar referring back to the property TAG; for that property. And in the case where the compiler synthesizes the ivar; directly, the compiler is expected to generate a ``DW_TAG_member`` for that; ivar (with th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:51254,Security,access,access,51254," declared ivar.; Finally it can have an ivar ""automatically synthesized"" for it by the compiler,; in which case the property can be referred to in user code directly using the; standard C dereference syntax as well as through the property ""dot"" syntax, but; there is no entry in the ``@interface`` declaration corresponding to this ivar. To facilitate debugging, these properties we will add a new DWARF TAG into the; ``DW_TAG_structure_type`` definition for the class to hold the description of a; given property, and a set of DWARF attributes that provide said description.; The property tag will also contain the name and declared type of the property. If there is a related ivar, there will also be a DWARF property attribute placed; in the ``DW_TAG_member`` DIE for that ivar referring back to the property TAG; for that property. And in the case where the compiler synthesizes the ivar; directly, the compiler is expected to generate a ``DW_TAG_member`` for that; ivar (with the ``DW_AT_artificial`` set to 1), whose name will be the name used; to access this ivar directly in code, and with the property attribute pointing; back to the property it is backing. The following examples will serve as illustration for our discussion:. .. code-block:: objc. @interface I1 {; int n2;; }. @property int p1;; @property int p2;; @end. @implementation I1; @synthesize p1;; @synthesize p2 = n2;; @end. This produces the following DWARF (this is a ""pseudo dwarfdump"" output):. .. code-block:: none. 0x00000100: TAG_structure_type [7] *; AT_APPLE_runtime_class( 0x10 ); AT_name( ""I1"" ); AT_decl_file( ""Objc_Property.m"" ); AT_decl_line( 3 ). 0x00000110 TAG_APPLE_property; AT_name ( ""p1"" ); AT_type ( {0x00000150} ( int ) ). 0x00000120: TAG_APPLE_property; AT_name ( ""p2"" ); AT_type ( {0x00000150} ( int ) ). 0x00000130: TAG_member [8]; AT_name( ""_p1"" ); AT_APPLE_property ( {0x00000110} ""p1"" ); AT_type( {0x00000150} ( int ) ); AT_artificial ( 0x1 ). 0x00000140: TAG_member [8]; AT_name( ""n2"" ); AT_APPLE_pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:60879,Security,hash,hash,60879,"of the box; * Strict rules for the contents of tables. Table size is important and the accelerator table format should allow the reuse; of strings from common string tables so the strings for the names are not; duplicated. We also want to make sure the table is ready to be used as-is by; simply mapping the table into memory with minimal header parsing. The name lookups need to be fast and optimized for the kinds of lookups that; debuggers tend to do. Optimally we would like to touch as few parts of the; mapped table as possible when doing a name lookup and be able to quickly find; the name entry we are looking for, or discover there are no matches. In the; case of debuggers we optimized for lookups that fail most of the time. Each table that is defined should have strict rules on exactly what is in the; accelerator tables and documented so clients can rely on the content. Hash Tables; ^^^^^^^^^^^. Standard Hash Tables; """""""""""""""""""""""""""""""""""""""". Typical hash tables have a header, buckets, and each bucket points to the; bucket contents:. .. code-block:: none. .------------.; | HEADER |; |------------|; | BUCKETS |; |------------|; | DATA |; `------------'. The BUCKETS are an array of offsets to DATA for each hash:. .. code-block:: none. .------------.; | 0x00001000 | BUCKETS[0]; | 0x00002000 | BUCKETS[1]; | 0x00002200 | BUCKETS[2]; | 0x000034f0 | BUCKETS[3]; | | ...; | 0xXXXXXXXX | BUCKETS[n_buckets]; '------------'. So for ``bucket[3]`` in the example above, we have an offset into the table; 0x000034f0 which points to a chain of entries for the bucket. Each bucket must; contain a next pointer, full 32 bit hash value, the string itself, and the data; for the current string value. .. code-block:: none. .------------.; 0x000034f0: | 0x00003500 | next pointer; | 0x12345678 | 32 bit hash; | ""erase"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003500: | 0x00003550 | next pointer; | 0x29273623 | 32 bit hash; | ""dump"" | string value; | data[n] | HashD",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:61138,Security,hash,hash,61138,"mes are not; duplicated. We also want to make sure the table is ready to be used as-is by; simply mapping the table into memory with minimal header parsing. The name lookups need to be fast and optimized for the kinds of lookups that; debuggers tend to do. Optimally we would like to touch as few parts of the; mapped table as possible when doing a name lookup and be able to quickly find; the name entry we are looking for, or discover there are no matches. In the; case of debuggers we optimized for lookups that fail most of the time. Each table that is defined should have strict rules on exactly what is in the; accelerator tables and documented so clients can rely on the content. Hash Tables; ^^^^^^^^^^^. Standard Hash Tables; """""""""""""""""""""""""""""""""""""""". Typical hash tables have a header, buckets, and each bucket points to the; bucket contents:. .. code-block:: none. .------------.; | HEADER |; |------------|; | BUCKETS |; |------------|; | DATA |; `------------'. The BUCKETS are an array of offsets to DATA for each hash:. .. code-block:: none. .------------.; | 0x00001000 | BUCKETS[0]; | 0x00002000 | BUCKETS[1]; | 0x00002200 | BUCKETS[2]; | 0x000034f0 | BUCKETS[3]; | | ...; | 0xXXXXXXXX | BUCKETS[n_buckets]; '------------'. So for ``bucket[3]`` in the example above, we have an offset into the table; 0x000034f0 which points to a chain of entries for the bucket. Each bucket must; contain a next pointer, full 32 bit hash value, the string itself, and the data; for the current string value. .. code-block:: none. .------------.; 0x000034f0: | 0x00003500 | next pointer; | 0x12345678 | 32 bit hash; | ""erase"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003500: | 0x00003550 | next pointer; | 0x29273623 | 32 bit hash; | ""dump"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003550: | 0x00000000 | next pointer; | 0x82638293 | 32 bit hash; | ""main"" | string value; | data[n] | HashData for this bucket; `------------'. The problem ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:61544,Security,hash,hash,61544,"ere are no matches. In the; case of debuggers we optimized for lookups that fail most of the time. Each table that is defined should have strict rules on exactly what is in the; accelerator tables and documented so clients can rely on the content. Hash Tables; ^^^^^^^^^^^. Standard Hash Tables; """""""""""""""""""""""""""""""""""""""". Typical hash tables have a header, buckets, and each bucket points to the; bucket contents:. .. code-block:: none. .------------.; | HEADER |; |------------|; | BUCKETS |; |------------|; | DATA |; `------------'. The BUCKETS are an array of offsets to DATA for each hash:. .. code-block:: none. .------------.; | 0x00001000 | BUCKETS[0]; | 0x00002000 | BUCKETS[1]; | 0x00002200 | BUCKETS[2]; | 0x000034f0 | BUCKETS[3]; | | ...; | 0xXXXXXXXX | BUCKETS[n_buckets]; '------------'. So for ``bucket[3]`` in the example above, we have an offset into the table; 0x000034f0 which points to a chain of entries for the bucket. Each bucket must; contain a next pointer, full 32 bit hash value, the string itself, and the data; for the current string value. .. code-block:: none. .------------.; 0x000034f0: | 0x00003500 | next pointer; | 0x12345678 | 32 bit hash; | ""erase"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003500: | 0x00003550 | next pointer; | 0x29273623 | 32 bit hash; | ""dump"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003550: | 0x00000000 | next pointer; | 0x82638293 | 32 bit hash; | ""main"" | string value; | data[n] | HashData for this bucket; `------------'. The problem with this layout for debuggers is that we need to optimize for the; negative lookup case where the symbol we're searching for is not present. So; if we were to lookup ""``printf``"" in the table above, we would make a 32-bit; hash for ""``printf``"", it might match ``bucket[3]``. We would need to go to; the offset 0x000034f0 and start looking to see if our 32 bit hash matches. To; do so, we need to read the next pointer, then read the hash,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:61720,Security,hash,hash,61720," hash tables have a header, buckets, and each bucket points to the; bucket contents:. .. code-block:: none. .------------.; | HEADER |; |------------|; | BUCKETS |; |------------|; | DATA |; `------------'. The BUCKETS are an array of offsets to DATA for each hash:. .. code-block:: none. .------------.; | 0x00001000 | BUCKETS[0]; | 0x00002000 | BUCKETS[1]; | 0x00002200 | BUCKETS[2]; | 0x000034f0 | BUCKETS[3]; | | ...; | 0xXXXXXXXX | BUCKETS[n_buckets]; '------------'. So for ``bucket[3]`` in the example above, we have an offset into the table; 0x000034f0 which points to a chain of entries for the bucket. Each bucket must; contain a next pointer, full 32 bit hash value, the string itself, and the data; for the current string value. .. code-block:: none. .------------.; 0x000034f0: | 0x00003500 | next pointer; | 0x12345678 | 32 bit hash; | ""erase"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003500: | 0x00003550 | next pointer; | 0x29273623 | 32 bit hash; | ""dump"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003550: | 0x00000000 | next pointer; | 0x82638293 | 32 bit hash; | ""main"" | string value; | data[n] | HashData for this bucket; `------------'. The problem with this layout for debuggers is that we need to optimize for the; negative lookup case where the symbol we're searching for is not present. So; if we were to lookup ""``printf``"" in the table above, we would make a 32-bit; hash for ""``printf``"", it might match ``bucket[3]``. We would need to go to; the offset 0x000034f0 and start looking to see if our 32 bit hash matches. To; do so, we need to read the next pointer, then read the hash, compare it, and; skip to the next bucket. Each time we are skipping many bytes in memory and; touching new pages just to do the compare on the full 32 bit hash. All of; these accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the ha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:61869,Security,hash,hash,61869," hash tables have a header, buckets, and each bucket points to the; bucket contents:. .. code-block:: none. .------------.; | HEADER |; |------------|; | BUCKETS |; |------------|; | DATA |; `------------'. The BUCKETS are an array of offsets to DATA for each hash:. .. code-block:: none. .------------.; | 0x00001000 | BUCKETS[0]; | 0x00002000 | BUCKETS[1]; | 0x00002200 | BUCKETS[2]; | 0x000034f0 | BUCKETS[3]; | | ...; | 0xXXXXXXXX | BUCKETS[n_buckets]; '------------'. So for ``bucket[3]`` in the example above, we have an offset into the table; 0x000034f0 which points to a chain of entries for the bucket. Each bucket must; contain a next pointer, full 32 bit hash value, the string itself, and the data; for the current string value. .. code-block:: none. .------------.; 0x000034f0: | 0x00003500 | next pointer; | 0x12345678 | 32 bit hash; | ""erase"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003500: | 0x00003550 | next pointer; | 0x29273623 | 32 bit hash; | ""dump"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003550: | 0x00000000 | next pointer; | 0x82638293 | 32 bit hash; | ""main"" | string value; | data[n] | HashData for this bucket; `------------'. The problem with this layout for debuggers is that we need to optimize for the; negative lookup case where the symbol we're searching for is not present. So; if we were to lookup ""``printf``"" in the table above, we would make a 32-bit; hash for ""``printf``"", it might match ``bucket[3]``. We would need to go to; the offset 0x000034f0 and start looking to see if our 32 bit hash matches. To; do so, we need to read the next pointer, then read the hash, compare it, and; skip to the next bucket. Each time we are skipping many bytes in memory and; touching new pages just to do the compare on the full 32 bit hash. All of; these accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the ha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:62017,Security,hash,hash,62017," hash tables have a header, buckets, and each bucket points to the; bucket contents:. .. code-block:: none. .------------.; | HEADER |; |------------|; | BUCKETS |; |------------|; | DATA |; `------------'. The BUCKETS are an array of offsets to DATA for each hash:. .. code-block:: none. .------------.; | 0x00001000 | BUCKETS[0]; | 0x00002000 | BUCKETS[1]; | 0x00002200 | BUCKETS[2]; | 0x000034f0 | BUCKETS[3]; | | ...; | 0xXXXXXXXX | BUCKETS[n_buckets]; '------------'. So for ``bucket[3]`` in the example above, we have an offset into the table; 0x000034f0 which points to a chain of entries for the bucket. Each bucket must; contain a next pointer, full 32 bit hash value, the string itself, and the data; for the current string value. .. code-block:: none. .------------.; 0x000034f0: | 0x00003500 | next pointer; | 0x12345678 | 32 bit hash; | ""erase"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003500: | 0x00003550 | next pointer; | 0x29273623 | 32 bit hash; | ""dump"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003550: | 0x00000000 | next pointer; | 0x82638293 | 32 bit hash; | ""main"" | string value; | data[n] | HashData for this bucket; `------------'. The problem with this layout for debuggers is that we need to optimize for the; negative lookup case where the symbol we're searching for is not present. So; if we were to lookup ""``printf``"" in the table above, we would make a 32-bit; hash for ""``printf``"", it might match ``bucket[3]``. We would need to go to; the offset 0x000034f0 and start looking to see if our 32 bit hash matches. To; do so, we need to read the next pointer, then read the hash, compare it, and; skip to the next bucket. Each time we are skipping many bytes in memory and; touching new pages just to do the compare on the full 32 bit hash. All of; these accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the ha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:62338,Security,hash,hash,62338,"[n_buckets]; '------------'. So for ``bucket[3]`` in the example above, we have an offset into the table; 0x000034f0 which points to a chain of entries for the bucket. Each bucket must; contain a next pointer, full 32 bit hash value, the string itself, and the data; for the current string value. .. code-block:: none. .------------.; 0x000034f0: | 0x00003500 | next pointer; | 0x12345678 | 32 bit hash; | ""erase"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003500: | 0x00003550 | next pointer; | 0x29273623 | 32 bit hash; | ""dump"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003550: | 0x00000000 | next pointer; | 0x82638293 | 32 bit hash; | ""main"" | string value; | data[n] | HashData for this bucket; `------------'. The problem with this layout for debuggers is that we need to optimize for the; negative lookup case where the symbol we're searching for is not present. So; if we were to lookup ""``printf``"" in the table above, we would make a 32-bit; hash for ""``printf``"", it might match ``bucket[3]``. We would need to go to; the offset 0x000034f0 and start looking to see if our 32 bit hash matches. To; do so, we need to read the next pointer, then read the hash, compare it, and; skip to the next bucket. Each time we are skipping many bytes in memory and; touching new pages just to do the compare on the full 32 bit hash. All of; these accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the hash tables a bit; differently: a header, buckets, an array of all unique 32 bit hash values,; followed by an array of hash value data offsets, one for each hash value, then; the data for all hash values:. .. code-block:: none. .-------------.; | HEADER |; |-------------|; | BUCKETS |; |-------------|; | HASHES |; |-------------|; | OFFSETS |; |-------------|; | DATA |; `-------------'. The ``BUCKETS`` in the name tables are an index into the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:62476,Security,hash,hash,62476,"which points to a chain of entries for the bucket. Each bucket must; contain a next pointer, full 32 bit hash value, the string itself, and the data; for the current string value. .. code-block:: none. .------------.; 0x000034f0: | 0x00003500 | next pointer; | 0x12345678 | 32 bit hash; | ""erase"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003500: | 0x00003550 | next pointer; | 0x29273623 | 32 bit hash; | ""dump"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003550: | 0x00000000 | next pointer; | 0x82638293 | 32 bit hash; | ""main"" | string value; | data[n] | HashData for this bucket; `------------'. The problem with this layout for debuggers is that we need to optimize for the; negative lookup case where the symbol we're searching for is not present. So; if we were to lookup ""``printf``"" in the table above, we would make a 32-bit; hash for ""``printf``"", it might match ``bucket[3]``. We would need to go to; the offset 0x000034f0 and start looking to see if our 32 bit hash matches. To; do so, we need to read the next pointer, then read the hash, compare it, and; skip to the next bucket. Each time we are skipping many bytes in memory and; touching new pages just to do the compare on the full 32 bit hash. All of; these accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the hash tables a bit; differently: a header, buckets, an array of all unique 32 bit hash values,; followed by an array of hash value data offsets, one for each hash value, then; the data for all hash values:. .. code-block:: none. .-------------.; | HEADER |; |-------------|; | BUCKETS |; |-------------|; | HASHES |; |-------------|; | OFFSETS |; |-------------|; | DATA |; `-------------'. The ``BUCKETS`` in the name tables are an index into the ``HASHES`` array. By; making all of the full 32 bit hash values contiguous in memory, we allow; ourselves to efficien",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:62549,Security,hash,hash,62549,"t hash value, the string itself, and the data; for the current string value. .. code-block:: none. .------------.; 0x000034f0: | 0x00003500 | next pointer; | 0x12345678 | 32 bit hash; | ""erase"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003500: | 0x00003550 | next pointer; | 0x29273623 | 32 bit hash; | ""dump"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003550: | 0x00000000 | next pointer; | 0x82638293 | 32 bit hash; | ""main"" | string value; | data[n] | HashData for this bucket; `------------'. The problem with this layout for debuggers is that we need to optimize for the; negative lookup case where the symbol we're searching for is not present. So; if we were to lookup ""``printf``"" in the table above, we would make a 32-bit; hash for ""``printf``"", it might match ``bucket[3]``. We would need to go to; the offset 0x000034f0 and start looking to see if our 32 bit hash matches. To; do so, we need to read the next pointer, then read the hash, compare it, and; skip to the next bucket. Each time we are skipping many bytes in memory and; touching new pages just to do the compare on the full 32 bit hash. All of; these accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the hash tables a bit; differently: a header, buckets, an array of all unique 32 bit hash values,; followed by an array of hash value data offsets, one for each hash value, then; the data for all hash values:. .. code-block:: none. .-------------.; | HEADER |; |-------------|; | BUCKETS |; |-------------|; | HASHES |; |-------------|; | OFFSETS |; |-------------|; | DATA |; `-------------'. The ``BUCKETS`` in the name tables are an index into the ``HASHES`` array. By; making all of the full 32 bit hash values contiguous in memory, we allow; ourselves to efficiently check for a match while touching as little memory as; possible. Most often checking the 32 bit hash",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:62710,Security,hash,hash,62710,"; 0x000034f0: | 0x00003500 | next pointer; | 0x12345678 | 32 bit hash; | ""erase"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003500: | 0x00003550 | next pointer; | 0x29273623 | 32 bit hash; | ""dump"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003550: | 0x00000000 | next pointer; | 0x82638293 | 32 bit hash; | ""main"" | string value; | data[n] | HashData for this bucket; `------------'. The problem with this layout for debuggers is that we need to optimize for the; negative lookup case where the symbol we're searching for is not present. So; if we were to lookup ""``printf``"" in the table above, we would make a 32-bit; hash for ""``printf``"", it might match ``bucket[3]``. We would need to go to; the offset 0x000034f0 and start looking to see if our 32 bit hash matches. To; do so, we need to read the next pointer, then read the hash, compare it, and; skip to the next bucket. Each time we are skipping many bytes in memory and; touching new pages just to do the compare on the full 32 bit hash. All of; these accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the hash tables a bit; differently: a header, buckets, an array of all unique 32 bit hash values,; followed by an array of hash value data offsets, one for each hash value, then; the data for all hash values:. .. code-block:: none. .-------------.; | HEADER |; |-------------|; | BUCKETS |; |-------------|; | HASHES |; |-------------|; | OFFSETS |; |-------------|; | DATA |; `-------------'. The ``BUCKETS`` in the name tables are an index into the ``HASHES`` array. By; making all of the full 32 bit hash values contiguous in memory, we allow; ourselves to efficiently check for a match while touching as little memory as; possible. Most often checking the 32 bit hash values is as far as the lookup; goes. If it does match, it usually is a match with no collisions. So for a; tabl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:62730,Security,access,accesses,62730,"lue; | data[n] | HashData for this bucket; |------------|; 0x00003500: | 0x00003550 | next pointer; | 0x29273623 | 32 bit hash; | ""dump"" | string value; | data[n] | HashData for this bucket; |------------|; 0x00003550: | 0x00000000 | next pointer; | 0x82638293 | 32 bit hash; | ""main"" | string value; | data[n] | HashData for this bucket; `------------'. The problem with this layout for debuggers is that we need to optimize for the; negative lookup case where the symbol we're searching for is not present. So; if we were to lookup ""``printf``"" in the table above, we would make a 32-bit; hash for ""``printf``"", it might match ``bucket[3]``. We would need to go to; the offset 0x000034f0 and start looking to see if our 32 bit hash matches. To; do so, we need to read the next pointer, then read the hash, compare it, and; skip to the next bucket. Each time we are skipping many bytes in memory and; touching new pages just to do the compare on the full 32 bit hash. All of; these accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the hash tables a bit; differently: a header, buckets, an array of all unique 32 bit hash values,; followed by an array of hash value data offsets, one for each hash value, then; the data for all hash values:. .. code-block:: none. .-------------.; | HEADER |; |-------------|; | BUCKETS |; |-------------|; | HASHES |; |-------------|; | OFFSETS |; |-------------|; | DATA |; `-------------'. The ``BUCKETS`` in the name tables are an index into the ``HASHES`` array. By; making all of the full 32 bit hash values contiguous in memory, we allow; ourselves to efficiently check for a match while touching as little memory as; possible. Most often checking the 32 bit hash values is as far as the lookup; goes. If it does match, it usually is a match with no collisions. So for a; table with ""``n_buckets``"" buckets, and ""``n_hashes``"" unique 32 bit hash; values, we can clarif",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:62876,Security,hash,hash,62876,"---|; 0x00003550: | 0x00000000 | next pointer; | 0x82638293 | 32 bit hash; | ""main"" | string value; | data[n] | HashData for this bucket; `------------'. The problem with this layout for debuggers is that we need to optimize for the; negative lookup case where the symbol we're searching for is not present. So; if we were to lookup ""``printf``"" in the table above, we would make a 32-bit; hash for ""``printf``"", it might match ``bucket[3]``. We would need to go to; the offset 0x000034f0 and start looking to see if our 32 bit hash matches. To; do so, we need to read the next pointer, then read the hash, compare it, and; skip to the next bucket. Each time we are skipping many bytes in memory and; touching new pages just to do the compare on the full 32 bit hash. All of; these accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the hash tables a bit; differently: a header, buckets, an array of all unique 32 bit hash values,; followed by an array of hash value data offsets, one for each hash value, then; the data for all hash values:. .. code-block:: none. .-------------.; | HEADER |; |-------------|; | BUCKETS |; |-------------|; | HASHES |; |-------------|; | OFFSETS |; |-------------|; | DATA |; `-------------'. The ``BUCKETS`` in the name tables are an index into the ``HASHES`` array. By; making all of the full 32 bit hash values contiguous in memory, we allow; ourselves to efficiently check for a match while touching as little memory as; possible. Most often checking the 32 bit hash values is as far as the lookup; goes. If it does match, it usually is a match with no collisions. So for a; table with ""``n_buckets``"" buckets, and ""``n_hashes``"" unique 32 bit hash; values, we can clarify the contents of the ``BUCKETS``, ``HASHES`` and; ``OFFSETS`` as:. .. code-block:: none. .-------------------------.; | HEADER.magic | uint32_t; | HEADER.version | uint16_t; | HEADER.hash_function | u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:62957,Security,hash,hash,62957,"---|; 0x00003550: | 0x00000000 | next pointer; | 0x82638293 | 32 bit hash; | ""main"" | string value; | data[n] | HashData for this bucket; `------------'. The problem with this layout for debuggers is that we need to optimize for the; negative lookup case where the symbol we're searching for is not present. So; if we were to lookup ""``printf``"" in the table above, we would make a 32-bit; hash for ""``printf``"", it might match ``bucket[3]``. We would need to go to; the offset 0x000034f0 and start looking to see if our 32 bit hash matches. To; do so, we need to read the next pointer, then read the hash, compare it, and; skip to the next bucket. Each time we are skipping many bytes in memory and; touching new pages just to do the compare on the full 32 bit hash. All of; these accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the hash tables a bit; differently: a header, buckets, an array of all unique 32 bit hash values,; followed by an array of hash value data offsets, one for each hash value, then; the data for all hash values:. .. code-block:: none. .-------------.; | HEADER |; |-------------|; | BUCKETS |; |-------------|; | HASHES |; |-------------|; | OFFSETS |; |-------------|; | DATA |; `-------------'. The ``BUCKETS`` in the name tables are an index into the ``HASHES`` array. By; making all of the full 32 bit hash values contiguous in memory, we allow; ourselves to efficiently check for a match while touching as little memory as; possible. Most often checking the 32 bit hash values is as far as the lookup; goes. If it does match, it usually is a match with no collisions. So for a; table with ""``n_buckets``"" buckets, and ""``n_hashes``"" unique 32 bit hash; values, we can clarify the contents of the ``BUCKETS``, ``HASHES`` and; ``OFFSETS`` as:. .. code-block:: none. .-------------------------.; | HEADER.magic | uint32_t; | HEADER.version | uint16_t; | HEADER.hash_function | u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:62995,Security,hash,hash,62995,"---|; 0x00003550: | 0x00000000 | next pointer; | 0x82638293 | 32 bit hash; | ""main"" | string value; | data[n] | HashData for this bucket; `------------'. The problem with this layout for debuggers is that we need to optimize for the; negative lookup case where the symbol we're searching for is not present. So; if we were to lookup ""``printf``"" in the table above, we would make a 32-bit; hash for ""``printf``"", it might match ``bucket[3]``. We would need to go to; the offset 0x000034f0 and start looking to see if our 32 bit hash matches. To; do so, we need to read the next pointer, then read the hash, compare it, and; skip to the next bucket. Each time we are skipping many bytes in memory and; touching new pages just to do the compare on the full 32 bit hash. All of; these accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the hash tables a bit; differently: a header, buckets, an array of all unique 32 bit hash values,; followed by an array of hash value data offsets, one for each hash value, then; the data for all hash values:. .. code-block:: none. .-------------.; | HEADER |; |-------------|; | BUCKETS |; |-------------|; | HASHES |; |-------------|; | OFFSETS |; |-------------|; | DATA |; `-------------'. The ``BUCKETS`` in the name tables are an index into the ``HASHES`` array. By; making all of the full 32 bit hash values contiguous in memory, we allow; ourselves to efficiently check for a match while touching as little memory as; possible. Most often checking the 32 bit hash values is as far as the lookup; goes. If it does match, it usually is a match with no collisions. So for a; table with ""``n_buckets``"" buckets, and ""``n_hashes``"" unique 32 bit hash; values, we can clarify the contents of the ``BUCKETS``, ``HASHES`` and; ``OFFSETS`` as:. .. code-block:: none. .-------------------------.; | HEADER.magic | uint32_t; | HEADER.version | uint16_t; | HEADER.hash_function | u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:63033,Security,hash,hash,63033,"---|; 0x00003550: | 0x00000000 | next pointer; | 0x82638293 | 32 bit hash; | ""main"" | string value; | data[n] | HashData for this bucket; `------------'. The problem with this layout for debuggers is that we need to optimize for the; negative lookup case where the symbol we're searching for is not present. So; if we were to lookup ""``printf``"" in the table above, we would make a 32-bit; hash for ""``printf``"", it might match ``bucket[3]``. We would need to go to; the offset 0x000034f0 and start looking to see if our 32 bit hash matches. To; do so, we need to read the next pointer, then read the hash, compare it, and; skip to the next bucket. Each time we are skipping many bytes in memory and; touching new pages just to do the compare on the full 32 bit hash. All of; these accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the hash tables a bit; differently: a header, buckets, an array of all unique 32 bit hash values,; followed by an array of hash value data offsets, one for each hash value, then; the data for all hash values:. .. code-block:: none. .-------------.; | HEADER |; |-------------|; | BUCKETS |; |-------------|; | HASHES |; |-------------|; | OFFSETS |; |-------------|; | DATA |; `-------------'. The ``BUCKETS`` in the name tables are an index into the ``HASHES`` array. By; making all of the full 32 bit hash values contiguous in memory, we allow; ourselves to efficiently check for a match while touching as little memory as; possible. Most often checking the 32 bit hash values is as far as the lookup; goes. If it does match, it usually is a match with no collisions. So for a; table with ""``n_buckets``"" buckets, and ""``n_hashes``"" unique 32 bit hash; values, we can clarify the contents of the ``BUCKETS``, ``HASHES`` and; ``OFFSETS`` as:. .. code-block:: none. .-------------------------.; | HEADER.magic | uint32_t; | HEADER.version | uint16_t; | HEADER.hash_function | u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:63068,Security,hash,hash,63068,"---|; 0x00003550: | 0x00000000 | next pointer; | 0x82638293 | 32 bit hash; | ""main"" | string value; | data[n] | HashData for this bucket; `------------'. The problem with this layout for debuggers is that we need to optimize for the; negative lookup case where the symbol we're searching for is not present. So; if we were to lookup ""``printf``"" in the table above, we would make a 32-bit; hash for ""``printf``"", it might match ``bucket[3]``. We would need to go to; the offset 0x000034f0 and start looking to see if our 32 bit hash matches. To; do so, we need to read the next pointer, then read the hash, compare it, and; skip to the next bucket. Each time we are skipping many bytes in memory and; touching new pages just to do the compare on the full 32 bit hash. All of; these accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the hash tables a bit; differently: a header, buckets, an array of all unique 32 bit hash values,; followed by an array of hash value data offsets, one for each hash value, then; the data for all hash values:. .. code-block:: none. .-------------.; | HEADER |; |-------------|; | BUCKETS |; |-------------|; | HASHES |; |-------------|; | OFFSETS |; |-------------|; | DATA |; `-------------'. The ``BUCKETS`` in the name tables are an index into the ``HASHES`` array. By; making all of the full 32 bit hash values contiguous in memory, we allow; ourselves to efficiently check for a match while touching as little memory as; possible. Most often checking the 32 bit hash values is as far as the lookup; goes. If it does match, it usually is a match with no collisions. So for a; table with ""``n_buckets``"" buckets, and ""``n_hashes``"" unique 32 bit hash; values, we can clarify the contents of the ``BUCKETS``, ``HASHES`` and; ``OFFSETS`` as:. .. code-block:: none. .-------------------------.; | HEADER.magic | uint32_t; | HEADER.version | uint16_t; | HEADER.hash_function | u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:63375,Security,hash,hash,63375,"et 0x000034f0 and start looking to see if our 32 bit hash matches. To; do so, we need to read the next pointer, then read the hash, compare it, and; skip to the next bucket. Each time we are skipping many bytes in memory and; touching new pages just to do the compare on the full 32 bit hash. All of; these accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the hash tables a bit; differently: a header, buckets, an array of all unique 32 bit hash values,; followed by an array of hash value data offsets, one for each hash value, then; the data for all hash values:. .. code-block:: none. .-------------.; | HEADER |; |-------------|; | BUCKETS |; |-------------|; | HASHES |; |-------------|; | OFFSETS |; |-------------|; | DATA |; `-------------'. The ``BUCKETS`` in the name tables are an index into the ``HASHES`` array. By; making all of the full 32 bit hash values contiguous in memory, we allow; ourselves to efficiently check for a match while touching as little memory as; possible. Most often checking the 32 bit hash values is as far as the lookup; goes. If it does match, it usually is a match with no collisions. So for a; table with ""``n_buckets``"" buckets, and ""``n_hashes``"" unique 32 bit hash; values, we can clarify the contents of the ``BUCKETS``, ``HASHES`` and; ``OFFSETS`` as:. .. code-block:: none. .-------------------------.; | HEADER.magic | uint32_t; | HEADER.version | uint16_t; | HEADER.hash_function | uint16_t; | HEADER.bucket_count | uint32_t; | HEADER.hashes_count | uint32_t; | HEADER.header_data_len | uint32_t; | HEADER_DATA | HeaderData; |-------------------------|; | BUCKETS | uint32_t[n_buckets] // 32 bit hash indexes; |-------------------------|; | HASHES | uint32_t[n_hashes] // 32 bit hash values; |-------------------------|; | OFFSETS | uint32_t[n_hashes] // 32 bit offsets to hash value data; |-------------------------|; | ALL HASH DATA |; `-------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:63539,Security,hash,hash,63539," the hash, compare it, and; skip to the next bucket. Each time we are skipping many bytes in memory and; touching new pages just to do the compare on the full 32 bit hash. All of; these accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the hash tables a bit; differently: a header, buckets, an array of all unique 32 bit hash values,; followed by an array of hash value data offsets, one for each hash value, then; the data for all hash values:. .. code-block:: none. .-------------.; | HEADER |; |-------------|; | BUCKETS |; |-------------|; | HASHES |; |-------------|; | OFFSETS |; |-------------|; | DATA |; `-------------'. The ``BUCKETS`` in the name tables are an index into the ``HASHES`` array. By; making all of the full 32 bit hash values contiguous in memory, we allow; ourselves to efficiently check for a match while touching as little memory as; possible. Most often checking the 32 bit hash values is as far as the lookup; goes. If it does match, it usually is a match with no collisions. So for a; table with ""``n_buckets``"" buckets, and ""``n_hashes``"" unique 32 bit hash; values, we can clarify the contents of the ``BUCKETS``, ``HASHES`` and; ``OFFSETS`` as:. .. code-block:: none. .-------------------------.; | HEADER.magic | uint32_t; | HEADER.version | uint16_t; | HEADER.hash_function | uint16_t; | HEADER.bucket_count | uint32_t; | HEADER.hashes_count | uint32_t; | HEADER.header_data_len | uint32_t; | HEADER_DATA | HeaderData; |-------------------------|; | BUCKETS | uint32_t[n_buckets] // 32 bit hash indexes; |-------------------------|; | HASHES | uint32_t[n_hashes] // 32 bit hash values; |-------------------------|; | OFFSETS | uint32_t[n_hashes] // 32 bit offsets to hash value data; |-------------------------|; | ALL HASH DATA |; `-------------------------'. So taking the exact same data from the standard hash example above we end up; with:. .. code-block:: none. .---",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:63721,Security,hash,hash,63721,"e accesses then tell us that we didn't have a match. Name Hash Tables; """""""""""""""""""""""""""""""". To solve the issues mentioned above we have structured the hash tables a bit; differently: a header, buckets, an array of all unique 32 bit hash values,; followed by an array of hash value data offsets, one for each hash value, then; the data for all hash values:. .. code-block:: none. .-------------.; | HEADER |; |-------------|; | BUCKETS |; |-------------|; | HASHES |; |-------------|; | OFFSETS |; |-------------|; | DATA |; `-------------'. The ``BUCKETS`` in the name tables are an index into the ``HASHES`` array. By; making all of the full 32 bit hash values contiguous in memory, we allow; ourselves to efficiently check for a match while touching as little memory as; possible. Most often checking the 32 bit hash values is as far as the lookup; goes. If it does match, it usually is a match with no collisions. So for a; table with ""``n_buckets``"" buckets, and ""``n_hashes``"" unique 32 bit hash; values, we can clarify the contents of the ``BUCKETS``, ``HASHES`` and; ``OFFSETS`` as:. .. code-block:: none. .-------------------------.; | HEADER.magic | uint32_t; | HEADER.version | uint16_t; | HEADER.hash_function | uint16_t; | HEADER.bucket_count | uint32_t; | HEADER.hashes_count | uint32_t; | HEADER.header_data_len | uint32_t; | HEADER_DATA | HeaderData; |-------------------------|; | BUCKETS | uint32_t[n_buckets] // 32 bit hash indexes; |-------------------------|; | HASHES | uint32_t[n_hashes] // 32 bit hash values; |-------------------------|; | OFFSETS | uint32_t[n_hashes] // 32 bit offsets to hash value data; |-------------------------|; | ALL HASH DATA |; `-------------------------'. So taking the exact same data from the standard hash example above we end up; with:. .. code-block:: none. .------------.; | HEADER |; |------------|; | 0 | BUCKETS[0]; | 2 | BUCKETS[1]; | 5 | BUCKETS[2]; | 6 | BUCKETS[3]; | | ...; | ... | BUCKETS[n_buckets]; |------------|; | 0x........ | HASH",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:64162,Security,hash,hash,64162,"---|; | DATA |; `-------------'. The ``BUCKETS`` in the name tables are an index into the ``HASHES`` array. By; making all of the full 32 bit hash values contiguous in memory, we allow; ourselves to efficiently check for a match while touching as little memory as; possible. Most often checking the 32 bit hash values is as far as the lookup; goes. If it does match, it usually is a match with no collisions. So for a; table with ""``n_buckets``"" buckets, and ""``n_hashes``"" unique 32 bit hash; values, we can clarify the contents of the ``BUCKETS``, ``HASHES`` and; ``OFFSETS`` as:. .. code-block:: none. .-------------------------.; | HEADER.magic | uint32_t; | HEADER.version | uint16_t; | HEADER.hash_function | uint16_t; | HEADER.bucket_count | uint32_t; | HEADER.hashes_count | uint32_t; | HEADER.header_data_len | uint32_t; | HEADER_DATA | HeaderData; |-------------------------|; | BUCKETS | uint32_t[n_buckets] // 32 bit hash indexes; |-------------------------|; | HASHES | uint32_t[n_hashes] // 32 bit hash values; |-------------------------|; | OFFSETS | uint32_t[n_hashes] // 32 bit offsets to hash value data; |-------------------------|; | ALL HASH DATA |; `-------------------------'. So taking the exact same data from the standard hash example above we end up; with:. .. code-block:: none. .------------.; | HEADER |; |------------|; | 0 | BUCKETS[0]; | 2 | BUCKETS[1]; | 5 | BUCKETS[2]; | 6 | BUCKETS[3]; | | ...; | ... | BUCKETS[n_buckets]; |------------|; | 0x........ | HASHES[0]; | 0x........ | HASHES[1]; | 0x........ | HASHES[2]; | 0x........ | HASHES[3]; | 0x........ | HASHES[4]; | 0x........ | HASHES[5]; | 0x12345678 | HASHES[6] hash for BUCKETS[3]; | 0x29273623 | HASHES[7] hash for BUCKETS[3]; | 0x82638293 | HASHES[8] hash for BUCKETS[3]; | 0x........ | HASHES[9]; | 0x........ | HASHES[10]; | 0x........ | HASHES[11]; | 0x........ | HASHES[12]; | 0x........ | HASHES[13]; | 0x........ | HASHES[n_hashes]; |------------|; | 0x........ | OFFSETS[0]; | 0x........ | OFFSET",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:64245,Security,hash,hash,64245,"---|; | DATA |; `-------------'. The ``BUCKETS`` in the name tables are an index into the ``HASHES`` array. By; making all of the full 32 bit hash values contiguous in memory, we allow; ourselves to efficiently check for a match while touching as little memory as; possible. Most often checking the 32 bit hash values is as far as the lookup; goes. If it does match, it usually is a match with no collisions. So for a; table with ""``n_buckets``"" buckets, and ""``n_hashes``"" unique 32 bit hash; values, we can clarify the contents of the ``BUCKETS``, ``HASHES`` and; ``OFFSETS`` as:. .. code-block:: none. .-------------------------.; | HEADER.magic | uint32_t; | HEADER.version | uint16_t; | HEADER.hash_function | uint16_t; | HEADER.bucket_count | uint32_t; | HEADER.hashes_count | uint32_t; | HEADER.header_data_len | uint32_t; | HEADER_DATA | HeaderData; |-------------------------|; | BUCKETS | uint32_t[n_buckets] // 32 bit hash indexes; |-------------------------|; | HASHES | uint32_t[n_hashes] // 32 bit hash values; |-------------------------|; | OFFSETS | uint32_t[n_hashes] // 32 bit offsets to hash value data; |-------------------------|; | ALL HASH DATA |; `-------------------------'. So taking the exact same data from the standard hash example above we end up; with:. .. code-block:: none. .------------.; | HEADER |; |------------|; | 0 | BUCKETS[0]; | 2 | BUCKETS[1]; | 5 | BUCKETS[2]; | 6 | BUCKETS[3]; | | ...; | ... | BUCKETS[n_buckets]; |------------|; | 0x........ | HASHES[0]; | 0x........ | HASHES[1]; | 0x........ | HASHES[2]; | 0x........ | HASHES[3]; | 0x........ | HASHES[4]; | 0x........ | HASHES[5]; | 0x12345678 | HASHES[6] hash for BUCKETS[3]; | 0x29273623 | HASHES[7] hash for BUCKETS[3]; | 0x82638293 | HASHES[8] hash for BUCKETS[3]; | 0x........ | HASHES[9]; | 0x........ | HASHES[10]; | 0x........ | HASHES[11]; | 0x........ | HASHES[12]; | 0x........ | HASHES[13]; | 0x........ | HASHES[n_hashes]; |------------|; | 0x........ | OFFSETS[0]; | 0x........ | OFFSET",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:64339,Security,hash,hash,64339,"---|; | DATA |; `-------------'. The ``BUCKETS`` in the name tables are an index into the ``HASHES`` array. By; making all of the full 32 bit hash values contiguous in memory, we allow; ourselves to efficiently check for a match while touching as little memory as; possible. Most often checking the 32 bit hash values is as far as the lookup; goes. If it does match, it usually is a match with no collisions. So for a; table with ""``n_buckets``"" buckets, and ""``n_hashes``"" unique 32 bit hash; values, we can clarify the contents of the ``BUCKETS``, ``HASHES`` and; ``OFFSETS`` as:. .. code-block:: none. .-------------------------.; | HEADER.magic | uint32_t; | HEADER.version | uint16_t; | HEADER.hash_function | uint16_t; | HEADER.bucket_count | uint32_t; | HEADER.hashes_count | uint32_t; | HEADER.header_data_len | uint32_t; | HEADER_DATA | HeaderData; |-------------------------|; | BUCKETS | uint32_t[n_buckets] // 32 bit hash indexes; |-------------------------|; | HASHES | uint32_t[n_hashes] // 32 bit hash values; |-------------------------|; | OFFSETS | uint32_t[n_hashes] // 32 bit offsets to hash value data; |-------------------------|; | ALL HASH DATA |; `-------------------------'. So taking the exact same data from the standard hash example above we end up; with:. .. code-block:: none. .------------.; | HEADER |; |------------|; | 0 | BUCKETS[0]; | 2 | BUCKETS[1]; | 5 | BUCKETS[2]; | 6 | BUCKETS[3]; | | ...; | ... | BUCKETS[n_buckets]; |------------|; | 0x........ | HASHES[0]; | 0x........ | HASHES[1]; | 0x........ | HASHES[2]; | 0x........ | HASHES[3]; | 0x........ | HASHES[4]; | 0x........ | HASHES[5]; | 0x12345678 | HASHES[6] hash for BUCKETS[3]; | 0x29273623 | HASHES[7] hash for BUCKETS[3]; | 0x82638293 | HASHES[8] hash for BUCKETS[3]; | 0x........ | HASHES[9]; | 0x........ | HASHES[10]; | 0x........ | HASHES[11]; | 0x........ | HASHES[12]; | 0x........ | HASHES[13]; | 0x........ | HASHES[n_hashes]; |------------|; | 0x........ | OFFSETS[0]; | 0x........ | OFFSET",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:64481,Security,hash,hash,64481,"ng as little memory as; possible. Most often checking the 32 bit hash values is as far as the lookup; goes. If it does match, it usually is a match with no collisions. So for a; table with ""``n_buckets``"" buckets, and ""``n_hashes``"" unique 32 bit hash; values, we can clarify the contents of the ``BUCKETS``, ``HASHES`` and; ``OFFSETS`` as:. .. code-block:: none. .-------------------------.; | HEADER.magic | uint32_t; | HEADER.version | uint16_t; | HEADER.hash_function | uint16_t; | HEADER.bucket_count | uint32_t; | HEADER.hashes_count | uint32_t; | HEADER.header_data_len | uint32_t; | HEADER_DATA | HeaderData; |-------------------------|; | BUCKETS | uint32_t[n_buckets] // 32 bit hash indexes; |-------------------------|; | HASHES | uint32_t[n_hashes] // 32 bit hash values; |-------------------------|; | OFFSETS | uint32_t[n_hashes] // 32 bit offsets to hash value data; |-------------------------|; | ALL HASH DATA |; `-------------------------'. So taking the exact same data from the standard hash example above we end up; with:. .. code-block:: none. .------------.; | HEADER |; |------------|; | 0 | BUCKETS[0]; | 2 | BUCKETS[1]; | 5 | BUCKETS[2]; | 6 | BUCKETS[3]; | | ...; | ... | BUCKETS[n_buckets]; |------------|; | 0x........ | HASHES[0]; | 0x........ | HASHES[1]; | 0x........ | HASHES[2]; | 0x........ | HASHES[3]; | 0x........ | HASHES[4]; | 0x........ | HASHES[5]; | 0x12345678 | HASHES[6] hash for BUCKETS[3]; | 0x29273623 | HASHES[7] hash for BUCKETS[3]; | 0x82638293 | HASHES[8] hash for BUCKETS[3]; | 0x........ | HASHES[9]; | 0x........ | HASHES[10]; | 0x........ | HASHES[11]; | 0x........ | HASHES[12]; | 0x........ | HASHES[13]; | 0x........ | HASHES[n_hashes]; |------------|; | 0x........ | OFFSETS[0]; | 0x........ | OFFSETS[1]; | 0x........ | OFFSETS[2]; | 0x........ | OFFSETS[3]; | 0x........ | OFFSETS[4]; | 0x........ | OFFSETS[5]; | 0x000034f0 | OFFSETS[6] offset for BUCKETS[3]; | 0x00003500 | OFFSETS[7] offset for BUCKETS[3]; | 0x00003550 | OFFSETS[8] off",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:64890,Security,hash,hash,64890,"ER.hash_function | uint16_t; | HEADER.bucket_count | uint32_t; | HEADER.hashes_count | uint32_t; | HEADER.header_data_len | uint32_t; | HEADER_DATA | HeaderData; |-------------------------|; | BUCKETS | uint32_t[n_buckets] // 32 bit hash indexes; |-------------------------|; | HASHES | uint32_t[n_hashes] // 32 bit hash values; |-------------------------|; | OFFSETS | uint32_t[n_hashes] // 32 bit offsets to hash value data; |-------------------------|; | ALL HASH DATA |; `-------------------------'. So taking the exact same data from the standard hash example above we end up; with:. .. code-block:: none. .------------.; | HEADER |; |------------|; | 0 | BUCKETS[0]; | 2 | BUCKETS[1]; | 5 | BUCKETS[2]; | 6 | BUCKETS[3]; | | ...; | ... | BUCKETS[n_buckets]; |------------|; | 0x........ | HASHES[0]; | 0x........ | HASHES[1]; | 0x........ | HASHES[2]; | 0x........ | HASHES[3]; | 0x........ | HASHES[4]; | 0x........ | HASHES[5]; | 0x12345678 | HASHES[6] hash for BUCKETS[3]; | 0x29273623 | HASHES[7] hash for BUCKETS[3]; | 0x82638293 | HASHES[8] hash for BUCKETS[3]; | 0x........ | HASHES[9]; | 0x........ | HASHES[10]; | 0x........ | HASHES[11]; | 0x........ | HASHES[12]; | 0x........ | HASHES[13]; | 0x........ | HASHES[n_hashes]; |------------|; | 0x........ | OFFSETS[0]; | 0x........ | OFFSETS[1]; | 0x........ | OFFSETS[2]; | 0x........ | OFFSETS[3]; | 0x........ | OFFSETS[4]; | 0x........ | OFFSETS[5]; | 0x000034f0 | OFFSETS[6] offset for BUCKETS[3]; | 0x00003500 | OFFSETS[7] offset for BUCKETS[3]; | 0x00003550 | OFFSETS[8] offset for BUCKETS[3]; | 0x........ | OFFSETS[9]; | 0x........ | OFFSETS[10]; | 0x........ | OFFSETS[11]; | 0x........ | OFFSETS[12]; | 0x........ | OFFSETS[13]; | 0x........ | OFFSETS[n_hashes]; |------------|; | |; | |; | |; | |; | |; |------------|; 0x000034f0: | 0x00001203 | .debug_str (""erase""); | 0x00000004 | A 32 bit array count - number of HashData with name ""erase""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:64936,Security,hash,hash,64936,"ER.hash_function | uint16_t; | HEADER.bucket_count | uint32_t; | HEADER.hashes_count | uint32_t; | HEADER.header_data_len | uint32_t; | HEADER_DATA | HeaderData; |-------------------------|; | BUCKETS | uint32_t[n_buckets] // 32 bit hash indexes; |-------------------------|; | HASHES | uint32_t[n_hashes] // 32 bit hash values; |-------------------------|; | OFFSETS | uint32_t[n_hashes] // 32 bit offsets to hash value data; |-------------------------|; | ALL HASH DATA |; `-------------------------'. So taking the exact same data from the standard hash example above we end up; with:. .. code-block:: none. .------------.; | HEADER |; |------------|; | 0 | BUCKETS[0]; | 2 | BUCKETS[1]; | 5 | BUCKETS[2]; | 6 | BUCKETS[3]; | | ...; | ... | BUCKETS[n_buckets]; |------------|; | 0x........ | HASHES[0]; | 0x........ | HASHES[1]; | 0x........ | HASHES[2]; | 0x........ | HASHES[3]; | 0x........ | HASHES[4]; | 0x........ | HASHES[5]; | 0x12345678 | HASHES[6] hash for BUCKETS[3]; | 0x29273623 | HASHES[7] hash for BUCKETS[3]; | 0x82638293 | HASHES[8] hash for BUCKETS[3]; | 0x........ | HASHES[9]; | 0x........ | HASHES[10]; | 0x........ | HASHES[11]; | 0x........ | HASHES[12]; | 0x........ | HASHES[13]; | 0x........ | HASHES[n_hashes]; |------------|; | 0x........ | OFFSETS[0]; | 0x........ | OFFSETS[1]; | 0x........ | OFFSETS[2]; | 0x........ | OFFSETS[3]; | 0x........ | OFFSETS[4]; | 0x........ | OFFSETS[5]; | 0x000034f0 | OFFSETS[6] offset for BUCKETS[3]; | 0x00003500 | OFFSETS[7] offset for BUCKETS[3]; | 0x00003550 | OFFSETS[8] offset for BUCKETS[3]; | 0x........ | OFFSETS[9]; | 0x........ | OFFSETS[10]; | 0x........ | OFFSETS[11]; | 0x........ | OFFSETS[12]; | 0x........ | OFFSETS[13]; | 0x........ | OFFSETS[n_hashes]; |------------|; | |; | |; | |; | |; | |; |------------|; 0x000034f0: | 0x00001203 | .debug_str (""erase""); | 0x00000004 | A 32 bit array count - number of HashData with name ""erase""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:64982,Security,hash,hash,64982,"ER.hash_function | uint16_t; | HEADER.bucket_count | uint32_t; | HEADER.hashes_count | uint32_t; | HEADER.header_data_len | uint32_t; | HEADER_DATA | HeaderData; |-------------------------|; | BUCKETS | uint32_t[n_buckets] // 32 bit hash indexes; |-------------------------|; | HASHES | uint32_t[n_hashes] // 32 bit hash values; |-------------------------|; | OFFSETS | uint32_t[n_hashes] // 32 bit offsets to hash value data; |-------------------------|; | ALL HASH DATA |; `-------------------------'. So taking the exact same data from the standard hash example above we end up; with:. .. code-block:: none. .------------.; | HEADER |; |------------|; | 0 | BUCKETS[0]; | 2 | BUCKETS[1]; | 5 | BUCKETS[2]; | 6 | BUCKETS[3]; | | ...; | ... | BUCKETS[n_buckets]; |------------|; | 0x........ | HASHES[0]; | 0x........ | HASHES[1]; | 0x........ | HASHES[2]; | 0x........ | HASHES[3]; | 0x........ | HASHES[4]; | 0x........ | HASHES[5]; | 0x12345678 | HASHES[6] hash for BUCKETS[3]; | 0x29273623 | HASHES[7] hash for BUCKETS[3]; | 0x82638293 | HASHES[8] hash for BUCKETS[3]; | 0x........ | HASHES[9]; | 0x........ | HASHES[10]; | 0x........ | HASHES[11]; | 0x........ | HASHES[12]; | 0x........ | HASHES[13]; | 0x........ | HASHES[n_hashes]; |------------|; | 0x........ | OFFSETS[0]; | 0x........ | OFFSETS[1]; | 0x........ | OFFSETS[2]; | 0x........ | OFFSETS[3]; | 0x........ | OFFSETS[4]; | 0x........ | OFFSETS[5]; | 0x000034f0 | OFFSETS[6] offset for BUCKETS[3]; | 0x00003500 | OFFSETS[7] offset for BUCKETS[3]; | 0x00003550 | OFFSETS[8] offset for BUCKETS[3]; | 0x........ | OFFSETS[9]; | 0x........ | OFFSETS[10]; | 0x........ | OFFSETS[11]; | 0x........ | OFFSETS[12]; | 0x........ | OFFSETS[13]; | 0x........ | OFFSETS[n_hashes]; |------------|; | |; | |; | |; | |; | |; |------------|; 0x000034f0: | 0x00001203 | .debug_str (""erase""); | 0x00000004 | A 32 bit array count - number of HashData with name ""erase""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:66027,Security,hash,hash,66027,"HES[10]; | 0x........ | HASHES[11]; | 0x........ | HASHES[12]; | 0x........ | HASHES[13]; | 0x........ | HASHES[n_hashes]; |------------|; | 0x........ | OFFSETS[0]; | 0x........ | OFFSETS[1]; | 0x........ | OFFSETS[2]; | 0x........ | OFFSETS[3]; | 0x........ | OFFSETS[4]; | 0x........ | OFFSETS[5]; | 0x000034f0 | OFFSETS[6] offset for BUCKETS[3]; | 0x00003500 | OFFSETS[7] offset for BUCKETS[3]; | 0x00003550 | OFFSETS[8] offset for BUCKETS[3]; | 0x........ | OFFSETS[9]; | 0x........ | OFFSETS[10]; | 0x........ | OFFSETS[11]; | 0x........ | OFFSETS[12]; | 0x........ | OFFSETS[13]; | 0x........ | OFFSETS[n_hashes]; |------------|; | |; | |; | |; | |; | |; |------------|; 0x000034f0: | 0x00001203 | .debug_str (""erase""); | 0x00000004 | A 32 bit array count - number of HashData with name ""erase""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x........ | HashData[3]; | 0x00000000 | String offset into .debug_str (terminate data for hash); |------------|; 0x00003500: | 0x00001203 | String offset into .debug_str (""collision""); | 0x00000002 | A 32 bit array count - number of HashData with name ""collision""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x00001203 | String offset into .debug_str (""dump""); | 0x00000003 | A 32 bit array count - number of HashData with name ""dump""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x00000000 | String offset into .debug_str (terminate data for hash); |------------|; 0x00003550: | 0x00001203 | String offset into .debug_str (""main""); | 0x00000009 | A 32 bit array count - number of HashData with name ""main""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x........ | HashData[3]; | 0x........ | HashData[4]; | 0x........ | HashData[5]; | 0x........ | HashData[6]; | 0x........ | HashData[7]; | 0x........ | HashData[8]; | 0x00000000 | String offset into .debug_str (terminate data for hash); `------------'. So we",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:66537,Security,hash,hash,66537,"..... | OFFSETS[11]; | 0x........ | OFFSETS[12]; | 0x........ | OFFSETS[13]; | 0x........ | OFFSETS[n_hashes]; |------------|; | |; | |; | |; | |; | |; |------------|; 0x000034f0: | 0x00001203 | .debug_str (""erase""); | 0x00000004 | A 32 bit array count - number of HashData with name ""erase""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x........ | HashData[3]; | 0x00000000 | String offset into .debug_str (terminate data for hash); |------------|; 0x00003500: | 0x00001203 | String offset into .debug_str (""collision""); | 0x00000002 | A 32 bit array count - number of HashData with name ""collision""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x00001203 | String offset into .debug_str (""dump""); | 0x00000003 | A 32 bit array count - number of HashData with name ""dump""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x00000000 | String offset into .debug_str (terminate data for hash); |------------|; 0x00003550: | 0x00001203 | String offset into .debug_str (""main""); | 0x00000009 | A 32 bit array count - number of HashData with name ""main""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x........ | HashData[3]; | 0x........ | HashData[4]; | 0x........ | HashData[5]; | 0x........ | HashData[6]; | 0x........ | HashData[7]; | 0x........ | HashData[8]; | 0x00000000 | String offset into .debug_str (terminate data for hash); `------------'. So we still have all of the same data, we just organize it more efficiently for; debugger lookup. If we repeat the same ""``printf``"" lookup from above, we; would hash ""``printf``"" and find it matches ``BUCKETS[3]`` by taking the 32 bit; hash value and modulo it by ``n_buckets``. ``BUCKETS[3]`` contains ""6"" which; is the index into the ``HASHES`` table. We would then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:67019,Security,hash,hash,67019,"te data for hash); |------------|; 0x00003500: | 0x00001203 | String offset into .debug_str (""collision""); | 0x00000002 | A 32 bit array count - number of HashData with name ""collision""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x00001203 | String offset into .debug_str (""dump""); | 0x00000003 | A 32 bit array count - number of HashData with name ""dump""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x00000000 | String offset into .debug_str (terminate data for hash); |------------|; 0x00003550: | 0x00001203 | String offset into .debug_str (""main""); | 0x00000009 | A 32 bit array count - number of HashData with name ""main""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x........ | HashData[3]; | 0x........ | HashData[4]; | 0x........ | HashData[5]; | 0x........ | HashData[6]; | 0x........ | HashData[7]; | 0x........ | HashData[8]; | 0x00000000 | String offset into .debug_str (terminate data for hash); `------------'. So we still have all of the same data, we just organize it more efficiently for; debugger lookup. If we repeat the same ""``printf``"" lookup from above, we; would hash ""``printf``"" and find it matches ``BUCKETS[3]`` by taking the 32 bit; hash value and modulo it by ``n_buckets``. ``BUCKETS[3]`` contains ""6"" which; is the index into the ``HASHES`` table. We would then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:67204,Security,hash,hash,67204,"| 0x........ | HashData[1]; | 0x00001203 | String offset into .debug_str (""dump""); | 0x00000003 | A 32 bit array count - number of HashData with name ""dump""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x00000000 | String offset into .debug_str (terminate data for hash); |------------|; 0x00003550: | 0x00001203 | String offset into .debug_str (""main""); | 0x00000009 | A 32 bit array count - number of HashData with name ""main""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x........ | HashData[3]; | 0x........ | HashData[4]; | 0x........ | HashData[5]; | 0x........ | HashData[6]; | 0x........ | HashData[7]; | 0x........ | HashData[8]; | 0x00000000 | String offset into .debug_str (terminate data for hash); `------------'. So we still have all of the same data, we just organize it more efficiently for; debugger lookup. If we repeat the same ""``printf``"" lookup from above, we; would hash ""``printf``"" and find it matches ``BUCKETS[3]`` by taking the 32 bit; hash value and modulo it by ``n_buckets``. ``BUCKETS[3]`` contains ""6"" which; is the index into the ``HASHES`` table. We would then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:67279,Security,hash,hash,67279,"| 0x........ | HashData[1]; | 0x00001203 | String offset into .debug_str (""dump""); | 0x00000003 | A 32 bit array count - number of HashData with name ""dump""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x00000000 | String offset into .debug_str (terminate data for hash); |------------|; 0x00003550: | 0x00001203 | String offset into .debug_str (""main""); | 0x00000009 | A 32 bit array count - number of HashData with name ""main""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x........ | HashData[3]; | 0x........ | HashData[4]; | 0x........ | HashData[5]; | 0x........ | HashData[6]; | 0x........ | HashData[7]; | 0x........ | HashData[8]; | 0x00000000 | String offset into .debug_str (terminate data for hash); `------------'. So we still have all of the same data, we just organize it more efficiently for; debugger lookup. If we repeat the same ""``printf``"" lookup from above, we; would hash ""``printf``"" and find it matches ``BUCKETS[3]`` by taking the 32 bit; hash value and modulo it by ``n_buckets``. ``BUCKETS[3]`` contains ""6"" which; is the index into the ``HASHES`` table. We would then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:67443,Security,hash,hashes,67443,"Data[2]; | 0x00000000 | String offset into .debug_str (terminate data for hash); |------------|; 0x00003550: | 0x00001203 | String offset into .debug_str (""main""); | 0x00000009 | A 32 bit array count - number of HashData with name ""main""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x........ | HashData[3]; | 0x........ | HashData[4]; | 0x........ | HashData[5]; | 0x........ | HashData[6]; | 0x........ | HashData[7]; | 0x........ | HashData[8]; | 0x00000000 | String offset into .debug_str (terminate data for hash); `------------'. So we still have all of the same data, we just organize it more efficiently for; debugger lookup. If we repeat the same ""``printf``"" lookup from above, we; would hash ""``printf``"" and find it matches ``BUCKETS[3]`` by taking the 32 bit; hash value and modulo it by ``n_buckets``. ``BUCKETS[3]`` contains ""6"" which; is the index into the ``HASHES`` table. We would then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:67496,Security,hash,hashes,67496,"Data[2]; | 0x00000000 | String offset into .debug_str (terminate data for hash); |------------|; 0x00003550: | 0x00001203 | String offset into .debug_str (""main""); | 0x00000009 | A 32 bit array count - number of HashData with name ""main""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x........ | HashData[3]; | 0x........ | HashData[4]; | 0x........ | HashData[5]; | 0x........ | HashData[6]; | 0x........ | HashData[7]; | 0x........ | HashData[8]; | 0x00000000 | String offset into .debug_str (terminate data for hash); `------------'. So we still have all of the same data, we just organize it more efficiently for; debugger lookup. If we repeat the same ""``printf``"" lookup from above, we; would hash ""``printf``"" and find it matches ``BUCKETS[3]`` by taking the 32 bit; hash value and modulo it by ``n_buckets``. ``BUCKETS[3]`` contains ""6"" which; is the index into the ``HASHES`` table. We would then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:67577,Security,hash,hash,67577,"00001203 | String offset into .debug_str (""main""); | 0x00000009 | A 32 bit array count - number of HashData with name ""main""; | 0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x........ | HashData[3]; | 0x........ | HashData[4]; | 0x........ | HashData[5]; | 0x........ | HashData[6]; | 0x........ | HashData[7]; | 0x........ | HashData[8]; | 0x00000000 | String offset into .debug_str (terminate data for hash); `------------'. So we still have all of the same data, we just organize it more efficiently for; debugger lookup. If we repeat the same ""``printf``"" lookup from above, we; would hash ""``printf``"" and find it matches ``BUCKETS[3]`` by taking the 32 bit; hash value and modulo it by ``n_buckets``. ``BUCKETS[3]`` contains ""6"" which; is the index into the ``HASHES`` table. We would then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stored (""``KeyType``"") and the content of the data for each; hash value. Header Layout; """""""""""""""""""""""""". The header ha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:67662,Security,access,access,67662,"0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x........ | HashData[3]; | 0x........ | HashData[4]; | 0x........ | HashData[5]; | 0x........ | HashData[6]; | 0x........ | HashData[7]; | 0x........ | HashData[8]; | 0x00000000 | String offset into .debug_str (terminate data for hash); `------------'. So we still have all of the same data, we just organize it more efficiently for; debugger lookup. If we repeat the same ""``printf``"" lookup from above, we; would hash ""``printf``"" and find it matches ``BUCKETS[3]`` by taking the 32 bit; hash value and modulo it by ``n_buckets``. ``BUCKETS[3]`` contains ""6"" which; is the index into the ``HASHES`` table. We would then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stored (""``KeyType``"") and the content of the data for each; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:67743,Security,hash,hashes,67743,"0x........ | HashData[0]; | 0x........ | HashData[1]; | 0x........ | HashData[2]; | 0x........ | HashData[3]; | 0x........ | HashData[4]; | 0x........ | HashData[5]; | 0x........ | HashData[6]; | 0x........ | HashData[7]; | 0x........ | HashData[8]; | 0x00000000 | String offset into .debug_str (terminate data for hash); `------------'. So we still have all of the same data, we just organize it more efficiently for; debugger lookup. If we repeat the same ""``printf``"" lookup from above, we; would hash ""``printf``"" and find it matches ``BUCKETS[3]`` by taking the 32 bit; hash value and modulo it by ``n_buckets``. ``BUCKETS[3]`` contains ""6"" which; is the index into the ``HASHES`` table. We would then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stored (""``KeyType``"") and the content of the data for each; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:67915,Security,access,accessed,67915,"5]; | 0x........ | HashData[6]; | 0x........ | HashData[7]; | 0x........ | HashData[8]; | 0x00000000 | String offset into .debug_str (terminate data for hash); `------------'. So we still have all of the same data, we just organize it more efficiently for; debugger lookup. If we repeat the same ""``printf``"" lookup from above, we; would hash ""``printf``"" and find it matches ``BUCKETS[3]`` by taking the 32 bit; hash value and modulo it by ``n_buckets``. ``BUCKETS[3]`` contains ""6"" which; is the index into the ``HASHES`` table. We would then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stored (""``KeyType``"") and the content of the data for each; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magic; // 'HASH' magic value to allow endian detection; uint16_t version; // Version number; uint16_t hash_function; // The hash function enumeration that was used; u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:67957,Security,hash,hash,67957,"et into .debug_str (terminate data for hash); `------------'. So we still have all of the same data, we just organize it more efficiently for; debugger lookup. If we repeat the same ""``printf``"" lookup from above, we; would hash ""``printf``"" and find it matches ``BUCKETS[3]`` by taking the 32 bit; hash value and modulo it by ``n_buckets``. ``BUCKETS[3]`` contains ""6"" which; is the index into the ``HASHES`` table. We would then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stored (""``KeyType``"") and the content of the data for each; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magic; // 'HASH' magic value to allow endian detection; uint16_t version; // Version number; uint16_t hash_function; // The hash function enumeration that was used; uint32_t bucket_count; // The number of buckets in this hash table; uint32_t hashes_count; // The total number of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:68027,Security,hash,hash,68027,"till have all of the same data, we just organize it more efficiently for; debugger lookup. If we repeat the same ""``printf``"" lookup from above, we; would hash ""``printf``"" and find it matches ``BUCKETS[3]`` by taking the 32 bit; hash value and modulo it by ``n_buckets``. ``BUCKETS[3]`` contains ""6"" which; is the index into the ``HASHES`` table. We would then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stored (""``KeyType``"") and the content of the data for each; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magic; // 'HASH' magic value to allow endian detection; uint16_t version; // Version number; uint16_t hash_function; // The hash function enumeration that was used; uint32_t bucket_count; // The number of buckets in this hash table; uint32_t hashes_count; // The total number of unique hash values and hash data offsets in this table; uint32_t heade",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:68104,Security,hash,hash,68104,"er lookup. If we repeat the same ""``printf``"" lookup from above, we; would hash ""``printf``"" and find it matches ``BUCKETS[3]`` by taking the 32 bit; hash value and modulo it by ``n_buckets``. ``BUCKETS[3]`` contains ""6"" which; is the index into the ``HASHES`` table. We would then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stored (""``KeyType``"") and the content of the data for each; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magic; // 'HASH' magic value to allow endian detection; uint16_t version; // Version number; uint16_t hash_function; // The hash function enumeration that was used; uint32_t bucket_count; // The number of buckets in this hash table; uint32_t hashes_count; // The total number of unique hash values and hash data offsets in this table; uint32_t header_data_len; // The bytes to skip to get to the hash indexes (buckets) for correc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:68158,Security,hash,hash,68158,"er lookup. If we repeat the same ""``printf``"" lookup from above, we; would hash ""``printf``"" and find it matches ``BUCKETS[3]`` by taking the 32 bit; hash value and modulo it by ``n_buckets``. ``BUCKETS[3]`` contains ""6"" which; is the index into the ``HASHES`` table. We would then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stored (""``KeyType``"") and the content of the data for each; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magic; // 'HASH' magic value to allow endian detection; uint16_t version; // Version number; uint16_t hash_function; // The hash function enumeration that was used; uint32_t bucket_count; // The number of buckets in this hash table; uint32_t hashes_count; // The total number of unique hash values and hash data offsets in this table; uint32_t header_data_len; // The bytes to skip to get to the hash indexes (buckets) for correc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:68225,Security,hash,hash,68225,"intf``"" and find it matches ``BUCKETS[3]`` by taking the 32 bit; hash value and modulo it by ``n_buckets``. ``BUCKETS[3]`` contains ""6"" which; is the index into the ``HASHES`` table. We would then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stored (""``KeyType``"") and the content of the data for each; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magic; // 'HASH' magic value to allow endian detection; uint16_t version; // Version number; uint16_t hash_function; // The hash function enumeration that was used; uint32_t bucket_count; // The number of buckets in this hash table; uint32_t hashes_count; // The total number of unique hash values and hash data offsets in this table; uint32_t header_data_len; // The bytes to skip to get to the hash indexes (buckets) for correct alignment; // Specifically the length of the following HeaderData field - this does",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:68284,Security,hash,hash,68284,"uld then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stored (""``KeyType``"") and the content of the data for each; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magic; // 'HASH' magic value to allow endian detection; uint16_t version; // Version number; uint16_t hash_function; // The hash function enumeration that was used; uint32_t bucket_count; // The number of buckets in this hash table; uint32_t hashes_count; // The total number of unique hash values and hash data offsets in this table; uint32_t header_data_len; // The bytes to skip to get to the hash indexes (buckets) for correct alignment; // Specifically the length of the following HeaderData field - this does not; // include the size of the preceding fields; HeaderData header_data; // Implementation specific header data; };. The header starts with a 32 bit ""``magic``"" value which must be ``'H",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:68521,Security,hash,hash,68521,"uld then compare any consecutive; 32 bit hashes values in the ``HASHES`` array as long as the hashes would be in; ``BUCKETS[3]``. We do this by verifying that each subsequent hash value modulo; ``n_buckets`` is still 3. In the case of a failed lookup we would access the; memory for ``BUCKETS[3]``, and then compare a few consecutive 32 bit hashes; before we know that we have no match. We don't end up marching through; multiple words of memory and we really keep the number of processor data cache; lines being accessed as small as possible. The string hash that is used for these lookup tables is the Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stored (""``KeyType``"") and the content of the data for each; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magic; // 'HASH' magic value to allow endian detection; uint16_t version; // Version number; uint16_t hash_function; // The hash function enumeration that was used; uint32_t bucket_count; // The number of buckets in this hash table; uint32_t hashes_count; // The total number of unique hash values and hash data offsets in this table; uint32_t header_data_len; // The bytes to skip to get to the hash indexes (buckets) for correct alignment; // Specifically the length of the following HeaderData field - this does not; // include the size of the preceding fields; HeaderData header_data; // Implementation specific header data; };. The header starts with a 32 bit ""``magic``"" value which must be ``'H",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:68825,Security,hash,hash,68825,"he Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stored (""``KeyType``"") and the content of the data for each; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magic; // 'HASH' magic value to allow endian detection; uint16_t version; // Version number; uint16_t hash_function; // The hash function enumeration that was used; uint32_t bucket_count; // The number of buckets in this hash table; uint32_t hashes_count; // The total number of unique hash values and hash data offsets in this table; uint32_t header_data_len; // The bytes to skip to get to the hash indexes (buckets) for correct alignment; // Specifically the length of the following HeaderData field - this does not; // include the size of the preceding fields; HeaderData header_data; // Implementation specific header data; };. The header starts with a 32 bit ""``magic``"" value which must be ``'HASH'``; encoded as an ASCII integer. This allows the detection of the start of the; hash table and also allows the table's byte order to be determined so the table; can be correctly extracted. The ""``magic``"" value is followed by a 16 bit; ``version`` number which allows the table to be revised and modified in the; future. The current version number is 1. ``hash_function`` is a ``uint16_t``; enumeration that specifies which hash function was used to produce this table.; The current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:68922,Security,hash,hash,68922,"he Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stored (""``KeyType``"") and the content of the data for each; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magic; // 'HASH' magic value to allow endian detection; uint16_t version; // Version number; uint16_t hash_function; // The hash function enumeration that was used; uint32_t bucket_count; // The number of buckets in this hash table; uint32_t hashes_count; // The total number of unique hash values and hash data offsets in this table; uint32_t header_data_len; // The bytes to skip to get to the hash indexes (buckets) for correct alignment; // Specifically the length of the following HeaderData field - this does not; // include the size of the preceding fields; HeaderData header_data; // Implementation specific header data; };. The header starts with a 32 bit ""``magic``"" value which must be ``'HASH'``; encoded as an ASCII integer. This allows the detection of the start of the; hash table and also allows the table's byte order to be determined so the table; can be correctly extracted. The ""``magic``"" value is followed by a 16 bit; ``version`` number which allows the table to be revised and modified in the; future. The current version number is 1. ``hash_function`` is a ``uint16_t``; enumeration that specifies which hash function was used to produce this table.; The current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:68987,Security,hash,hash,68987,"he Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stored (""``KeyType``"") and the content of the data for each; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magic; // 'HASH' magic value to allow endian detection; uint16_t version; // Version number; uint16_t hash_function; // The hash function enumeration that was used; uint32_t bucket_count; // The number of buckets in this hash table; uint32_t hashes_count; // The total number of unique hash values and hash data offsets in this table; uint32_t header_data_len; // The bytes to skip to get to the hash indexes (buckets) for correct alignment; // Specifically the length of the following HeaderData field - this does not; // include the size of the preceding fields; HeaderData header_data; // Implementation specific header data; };. The header starts with a 32 bit ""``magic``"" value which must be ``'HASH'``; encoded as an ASCII integer. This allows the detection of the start of the; hash table and also allows the table's byte order to be determined so the table; can be correctly extracted. The ""``magic``"" value is followed by a 16 bit; ``version`` number which allows the table to be revised and modified in the; future. The current version number is 1. ``hash_function`` is a ``uint16_t``; enumeration that specifies which hash function was used to produce this table.; The current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:69003,Security,hash,hash,69003,"he Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stored (""``KeyType``"") and the content of the data for each; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magic; // 'HASH' magic value to allow endian detection; uint16_t version; // Version number; uint16_t hash_function; // The hash function enumeration that was used; uint32_t bucket_count; // The number of buckets in this hash table; uint32_t hashes_count; // The total number of unique hash values and hash data offsets in this table; uint32_t header_data_len; // The bytes to skip to get to the hash indexes (buckets) for correct alignment; // Specifically the length of the following HeaderData field - this does not; // include the size of the preceding fields; HeaderData header_data; // Implementation specific header data; };. The header starts with a 32 bit ""``magic``"" value which must be ``'HASH'``; encoded as an ASCII integer. This allows the detection of the start of the; hash table and also allows the table's byte order to be determined so the table; can be correctly extracted. The ""``magic``"" value is followed by a 16 bit; ``version`` number which allows the table to be revised and modified in the; future. The current version number is 1. ``hash_function`` is a ``uint16_t``; enumeration that specifies which hash function was used to produce this table.; The current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:69097,Security,hash,hash,69097,"he Daniel J.; Bernstein hash which is also used in the ELF ``GNU_HASH`` sections. It is a; very good hash for all kinds of names in programs with very few hash; collisions. Empty buckets are designated by using an invalid hash index of ``UINT32_MAX``. Details; ^^^^^^^. These name hash tables are designed to be generic where specializations of the; table get to define additional data that goes into the header (""``HeaderData``""),; how the string value is stored (""``KeyType``"") and the content of the data for each; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magic; // 'HASH' magic value to allow endian detection; uint16_t version; // Version number; uint16_t hash_function; // The hash function enumeration that was used; uint32_t bucket_count; // The number of buckets in this hash table; uint32_t hashes_count; // The total number of unique hash values and hash data offsets in this table; uint32_t header_data_len; // The bytes to skip to get to the hash indexes (buckets) for correct alignment; // Specifically the length of the following HeaderData field - this does not; // include the size of the preceding fields; HeaderData header_data; // Implementation specific header data; };. The header starts with a 32 bit ""``magic``"" value which must be ``'HASH'``; encoded as an ASCII integer. This allows the detection of the start of the; hash table and also allows the table's byte order to be determined so the table; can be correctly extracted. The ""``magic``"" value is followed by a 16 bit; ``version`` number which allows the table to be revised and modified in the; future. The current version number is 1. ``hash_function`` is a ``uint16_t``; enumeration that specifies which hash function was used to produce this table.; The current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:69486,Security,hash,hash,69486,"ach; hash value. Header Layout; """""""""""""""""""""""""". The header has a fixed part, and the specialized part. The exact format of the; header is:. .. code-block:: c. struct Header; {; uint32_t magic; // 'HASH' magic value to allow endian detection; uint16_t version; // Version number; uint16_t hash_function; // The hash function enumeration that was used; uint32_t bucket_count; // The number of buckets in this hash table; uint32_t hashes_count; // The total number of unique hash values and hash data offsets in this table; uint32_t header_data_len; // The bytes to skip to get to the hash indexes (buckets) for correct alignment; // Specifically the length of the following HeaderData field - this does not; // include the size of the preceding fields; HeaderData header_data; // Implementation specific header data; };. The header starts with a 32 bit ""``magic``"" value which must be ``'HASH'``; encoded as an ASCII integer. This allows the detection of the start of the; hash table and also allows the table's byte order to be determined so the table; can be correctly extracted. The ""``magic``"" value is followed by a 16 bit; ``version`` number which allows the table to be revised and modified in the; future. The current version number is 1. ``hash_function`` is a ``uint16_t``; enumeration that specifies which hash function was used to produce this table.; The current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB = 0u, // Daniel J Bernstein hash function; };. ``bucket_count`` is a 32 bit unsigned integer that represents how many buckets; are in the ``BUCKETS`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:69830,Security,hash,hash,69830," // The hash function enumeration that was used; uint32_t bucket_count; // The number of buckets in this hash table; uint32_t hashes_count; // The total number of unique hash values and hash data offsets in this table; uint32_t header_data_len; // The bytes to skip to get to the hash indexes (buckets) for correct alignment; // Specifically the length of the following HeaderData field - this does not; // include the size of the preceding fields; HeaderData header_data; // Implementation specific header data; };. The header starts with a 32 bit ""``magic``"" value which must be ``'HASH'``; encoded as an ASCII integer. This allows the detection of the start of the; hash table and also allows the table's byte order to be determined so the table; can be correctly extracted. The ""``magic``"" value is followed by a 16 bit; ``version`` number which allows the table to be revised and modified in the; future. The current version number is 1. ``hash_function`` is a ``uint16_t``; enumeration that specifies which hash function was used to produce this table.; The current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB = 0u, // Daniel J Bernstein hash function; };. ``bucket_count`` is a 32 bit unsigned integer that represents how many buckets; are in the ``BUCKETS`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:69904,Security,hash,hash,69904,"uckets in this hash table; uint32_t hashes_count; // The total number of unique hash values and hash data offsets in this table; uint32_t header_data_len; // The bytes to skip to get to the hash indexes (buckets) for correct alignment; // Specifically the length of the following HeaderData field - this does not; // include the size of the preceding fields; HeaderData header_data; // Implementation specific header data; };. The header starts with a 32 bit ""``magic``"" value which must be ``'HASH'``; encoded as an ASCII integer. This allows the detection of the start of the; hash table and also allows the table's byte order to be determined so the table; can be correctly extracted. The ""``magic``"" value is followed by a 16 bit; ``version`` number which allows the table to be revised and modified in the; future. The current version number is 1. ``hash_function`` is a ``uint16_t``; enumeration that specifies which hash function was used to produce this table.; The current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB = 0u, // Daniel J Bernstein hash function; };. ``bucket_count`` is a 32 bit unsigned integer that represents how many buckets; are in the ``BUCKETS`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:70031,Security,hash,hash,70031,"ash data offsets in this table; uint32_t header_data_len; // The bytes to skip to get to the hash indexes (buckets) for correct alignment; // Specifically the length of the following HeaderData field - this does not; // include the size of the preceding fields; HeaderData header_data; // Implementation specific header data; };. The header starts with a 32 bit ""``magic``"" value which must be ``'HASH'``; encoded as an ASCII integer. This allows the detection of the start of the; hash table and also allows the table's byte order to be determined so the table; can be correctly extracted. The ""``magic``"" value is followed by a 16 bit; ``version`` number which allows the table to be revised and modified in the; future. The current version number is 1. ``hash_function`` is a ``uint16_t``; enumeration that specifies which hash function was used to produce this table.; The current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB = 0u, // Daniel J Bernstein hash function; };. ``bucket_count`` is a 32 bit unsigned integer that represents how many buckets; are in the ``BUCKETS`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:70209,Security,hash,hash,70209,"the preceding fields; HeaderData header_data; // Implementation specific header data; };. The header starts with a 32 bit ""``magic``"" value which must be ``'HASH'``; encoded as an ASCII integer. This allows the detection of the start of the; hash table and also allows the table's byte order to be determined so the table; can be correctly extracted. The ""``magic``"" value is followed by a 16 bit; ``version`` number which allows the table to be revised and modified in the; future. The current version number is 1. ``hash_function`` is a ``uint16_t``; enumeration that specifies which hash function was used to produce this table.; The current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB = 0u, // Daniel J Bernstein hash function; };. ``bucket_count`` is a 32 bit unsigned integer that represents how many buckets; are in the ``BUCKETS`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very eas",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:70526,Security,hash,hashes,70526," byte order to be determined so the table; can be correctly extracted. The ""``magic``"" value is followed by a 16 bit; ``version`` number which allows the table to be revised and modified in the; future. The current version number is 1. ``hash_function`` is a ``uint16_t``; enumeration that specifies which hash function was used to produce this table.; The current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB = 0u, // Daniel J Bernstein hash function; };. ``bucket_count`` is a 32 bit unsigned integer that represents how many buckets; are in the ``BUCKETS`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:70547,Security,hash,hash,70547," byte order to be determined so the table; can be correctly extracted. The ""``magic``"" value is followed by a 16 bit; ``version`` number which allows the table to be revised and modified in the; future. The current version number is 1. ``hash_function`` is a ``uint16_t``; enumeration that specifies which hash function was used to produce this table.; The current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB = 0u, // Daniel J Bernstein hash function; };. ``bucket_count`` is a 32 bit unsigned integer that represents how many buckets; are in the ``BUCKETS`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:70659,Security,hash,hash,70659,"able to be revised and modified in the; future. The current version number is 1. ``hash_function`` is a ``uint16_t``; enumeration that specifies which hash function was used to produce this table.; The current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB = 0u, // Daniel J Bernstein hash function; };. ``bucket_count`` is a 32 bit unsigned integer that represents how many buckets; are in the ``BUCKETS`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables can be implemented in a variety of ways and can store a lot; of information for each name. We want to make the DWARF tables extensible and; able to store ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:70682,Security,hash,hashes,70682,"able to be revised and modified in the; future. The current version number is 1. ``hash_function`` is a ``uint16_t``; enumeration that specifies which hash function was used to produce this table.; The current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB = 0u, // Daniel J Bernstein hash function; };. ``bucket_count`` is a 32 bit unsigned integer that represents how many buckets; are in the ``BUCKETS`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables can be implemented in a variety of ways and can store a lot; of information for each name. We want to make the DWARF tables extensible and; able to store ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:70714,Security,hash,hashes,70714,"able to be revised and modified in the; future. The current version number is 1. ``hash_function`` is a ``uint16_t``; enumeration that specifies which hash function was used to produce this table.; The current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB = 0u, // Daniel J Bernstein hash function; };. ``bucket_count`` is a 32 bit unsigned integer that represents how many buckets; are in the ``BUCKETS`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables can be implemented in a variety of ways and can store a lot; of information for each name. We want to make the DWARF tables extensible and; able to store ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:70767,Security,hash,hash,70767," ``uint16_t``; enumeration that specifies which hash function was used to produce this table.; The current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB = 0u, // Daniel J Bernstein hash function; };. ``bucket_count`` is a 32 bit unsigned integer that represents how many buckets; are in the ``BUCKETS`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables can be implemented in a variety of ways and can store a lot; of information for each name. We want to make the DWARF tables extensible and; able to store the data efficiently so we have used some of the DWARF features; that enable efficient data storage to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:70901,Security,hash,hashes,70901,"current values for the hash function enumerations include:. .. code-block:: c. enum HashFunctionType; {; eHashFunctionDJB = 0u, // Daniel J Bernstein hash function; };. ``bucket_count`` is a 32 bit unsigned integer that represents how many buckets; are in the ``BUCKETS`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables can be implemented in a variety of ways and can store a lot; of information for each name. We want to make the DWARF tables extensible and; able to store the data efficiently so we have used some of the DWARF features; that enable efficient data storage to define exactly what kind of data we store; for each name. The ``HeaderData`` contains a definition ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:70981,Security,hash,hashes,70981,"num HashFunctionType; {; eHashFunctionDJB = 0u, // Daniel J Bernstein hash function; };. ``bucket_count`` is a 32 bit unsigned integer that represents how many buckets; are in the ``BUCKETS`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables can be implemented in a variety of ways and can store a lot; of information for each name. We want to make the DWARF tables extensible and; able to store the data efficiently so we have used some of the DWARF features; that enable efficient data storage to define exactly what kind of data we store; for each name. The ``HeaderData`` contains a definition of the contents of each HashData chunk.; We might want to store an offset to all ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:71004,Security,hash,hashes,71004,"n; };. ``bucket_count`` is a 32 bit unsigned integer that represents how many buckets; are in the ``BUCKETS`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables can be implemented in a variety of ways and can store a lot; of information for each name. We want to make the DWARF tables extensible and; able to store the data efficiently so we have used some of the DWARF features; that enable efficient data storage to define exactly what kind of data we store; for each name. The ``HeaderData`` contains a definition of the contents of each HashData chunk.; We might want to store an offset to all of the debug information entries (DIEs); for each name. To keep things extensible,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:71046,Security,hash,hash,71046,"n; };. ``bucket_count`` is a 32 bit unsigned integer that represents how many buckets; are in the ``BUCKETS`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables can be implemented in a variety of ways and can store a lot; of information for each name. We want to make the DWARF tables extensible and; able to store the data efficiently so we have used some of the DWARF features; that enable efficient data storage to define exactly what kind of data we store; for each name. The ``HeaderData`` contains a definition of the contents of each HashData chunk.; We might want to store an offset to all of the debug information entries (DIEs); for each name. To keep things extensible,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:71080,Security,hash,hash,71080,"n; };. ``bucket_count`` is a 32 bit unsigned integer that represents how many buckets; are in the ``BUCKETS`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables can be implemented in a variety of ways and can store a lot; of information for each name. We want to make the DWARF tables extensible and; able to store the data efficiently so we have used some of the DWARF features; that enable efficient data storage to define exactly what kind of data we store; for each name. The ``HeaderData`` contains a definition of the contents of each HashData chunk.; We might want to store an offset to all of the debug information entries (DIEs); for each name. To keep things extensible,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:71097,Security,hash,hash,71097,"`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables can be implemented in a variety of ways and can store a lot; of information for each name. We want to make the DWARF tables extensible and; able to store the data efficiently so we have used some of the DWARF features; that enable efficient data storage to define exactly what kind of data we store; for each name. The ``HeaderData`` contains a definition of the contents of each HashData chunk.; We might want to store an offset to all of the debug information entries (DIEs); for each name. To keep things extensible, we create a list of items, or; Atoms, that are contained in the data for each name. First comes the type ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:71111,Security,hash,hashes,71111,"`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables can be implemented in a variety of ways and can store a lot; of information for each name. We want to make the DWARF tables extensible and; able to store the data efficiently so we have used some of the DWARF features; that enable efficient data storage to define exactly what kind of data we store; for each name. The ``HeaderData`` contains a definition of the contents of each HashData chunk.; We might want to store an offset to all of the debug information entries (DIEs); for each name. To keep things extensible, we create a list of items, or; Atoms, that are contained in the data for each name. First comes the type ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:71198,Security,hash,hash,71198,"`` array. ``hashes_count`` is the number of unique 32 bit; hash values that are in the ``HASHES`` array, and is the same number of offsets; are contained in the ``OFFSETS`` array. ``header_data_len`` specifies the size; in bytes of the ``HeaderData`` that is filled in by specialized versions of; this table. Fixed Lookup; """""""""""""""""""""""". The header is followed by the buckets, hashes, offsets, and hash value data. .. code-block:: c. struct FixedTable; {; uint32_t buckets[Header.bucket_count]; // An array of hash indexes into the ""hashes[]"" array below; uint32_t hashes [Header.hashes_count]; // Every unique 32 bit hash for the entire table is in this table; uint32_t offsets[Header.hashes_count]; // An offset that corresponds to each item in the ""hashes[]"" array above; };. ``buckets`` is an array of 32 bit indexes into the ``hashes`` array. The; ``hashes`` array contains all of the 32 bit hash values for all names in the; hash table. Each hash in the ``hashes`` table has an offset in the ``offsets``; array that points to the data for the hash value. This table setup makes it very easy to repurpose these tables to contain; different data, while keeping the lookup mechanism the same for all tables.; This layout also makes it possible to save the table to disk and map it in; later and do very efficient name lookups with little or no parsing. DWARF lookup tables can be implemented in a variety of ways and can store a lot; of information for each name. We want to make the DWARF tables extensible and; able to store the data efficiently so we have used some of the DWARF features; that enable efficient data storage to define exactly what kind of data we store; for each name. The ``HeaderData`` contains a definition of the contents of each HashData chunk.; We might want to store an offset to all of the debug information entries (DIEs); for each name. To keep things extensible, we create a list of items, or; Atoms, that are contained in the data for each name. First comes the type ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:75295,Security,hash,hash,75295,"es``"" (all functions +; globals), the ""``.apple_types``"" (names of all types that are defined), and; the ""``.apple_namespaces``"" (all namespaces), we currently set the ``Atom``; array to be:. .. code-block:: c. HeaderData.atom_count = 1;; HeaderData.atoms[0].type = eAtomTypeDIEOffset;; HeaderData.atoms[0].form = DW_FORM_data4;. This defines the contents to be the DIE offset (eAtomTypeDIEOffset) that is; encoded as a 32 bit value (DW_FORM_data4). This allows a single name to have; multiple matching DIEs in a single file, which could come up with an inlined; function for instance. Future tables could include more information about the; DIE such as flags indicating if the DIE is a function, method, block,; or inlined. The KeyType for the DWARF table is a 32 bit string table offset into the; "".debug_str"" table. The "".debug_str"" is the string table for the DWARF which; may already contain copies of all of the strings. This helps make sure, with; help from the compiler, that we reuse the strings between all of the DWARF; sections and keeps the hash table size down. Another benefit to having the; compiler generate all strings as DW_FORM_strp in the debug info, is that; DWARF parsing can be made much faster. After a lookup is made, we get an offset into the hash data. The hash data; needs to be able to deal with 32 bit hash collisions, so the chunk of data; at the offset in the hash data consists of a triple:. .. code-block:: c. uint32_t str_offset; uint32_t hash_data_count; HashData[hash_data_count]. If ""str_offset"" is zero, then the bucket contents are done. 99.9% of the; hash data chunks contain a single item (no 32 bit hash collision):. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x........ | uint32_t HashData[2] DIE offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:75511,Security,hash,hash,75511,".atoms[0].type = eAtomTypeDIEOffset;; HeaderData.atoms[0].form = DW_FORM_data4;. This defines the contents to be the DIE offset (eAtomTypeDIEOffset) that is; encoded as a 32 bit value (DW_FORM_data4). This allows a single name to have; multiple matching DIEs in a single file, which could come up with an inlined; function for instance. Future tables could include more information about the; DIE such as flags indicating if the DIE is a function, method, block,; or inlined. The KeyType for the DWARF table is a 32 bit string table offset into the; "".debug_str"" table. The "".debug_str"" is the string table for the DWARF which; may already contain copies of all of the strings. This helps make sure, with; help from the compiler, that we reuse the strings between all of the DWARF; sections and keeps the hash table size down. Another benefit to having the; compiler generate all strings as DW_FORM_strp in the debug info, is that; DWARF parsing can be made much faster. After a lookup is made, we get an offset into the hash data. The hash data; needs to be able to deal with 32 bit hash collisions, so the chunk of data; at the offset in the hash data consists of a triple:. .. code-block:: c. uint32_t str_offset; uint32_t hash_data_count; HashData[hash_data_count]. If ""str_offset"" is zero, then the bucket contents are done. 99.9% of the; hash data chunks contain a single item (no 32 bit hash collision):. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x........ | uint32_t HashData[2] DIE offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0x00000000 | uint32_t KeyType (end of hash chain); `------------'. If there are collisions, you will have multiple valid string offsets:. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x000",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:75526,Security,hash,hash,75526,"nts to be the DIE offset (eAtomTypeDIEOffset) that is; encoded as a 32 bit value (DW_FORM_data4). This allows a single name to have; multiple matching DIEs in a single file, which could come up with an inlined; function for instance. Future tables could include more information about the; DIE such as flags indicating if the DIE is a function, method, block,; or inlined. The KeyType for the DWARF table is a 32 bit string table offset into the; "".debug_str"" table. The "".debug_str"" is the string table for the DWARF which; may already contain copies of all of the strings. This helps make sure, with; help from the compiler, that we reuse the strings between all of the DWARF; sections and keeps the hash table size down. Another benefit to having the; compiler generate all strings as DW_FORM_strp in the debug info, is that; DWARF parsing can be made much faster. After a lookup is made, we get an offset into the hash data. The hash data; needs to be able to deal with 32 bit hash collisions, so the chunk of data; at the offset in the hash data consists of a triple:. .. code-block:: c. uint32_t str_offset; uint32_t hash_data_count; HashData[hash_data_count]. If ""str_offset"" is zero, then the bucket contents are done. 99.9% of the; hash data chunks contain a single item (no 32 bit hash collision):. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x........ | uint32_t HashData[2] DIE offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0x00000000 | uint32_t KeyType (end of hash chain); `------------'. If there are collisions, you will have multiple valid string offsets:. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:75574,Security,hash,hash,75574,"nts to be the DIE offset (eAtomTypeDIEOffset) that is; encoded as a 32 bit value (DW_FORM_data4). This allows a single name to have; multiple matching DIEs in a single file, which could come up with an inlined; function for instance. Future tables could include more information about the; DIE such as flags indicating if the DIE is a function, method, block,; or inlined. The KeyType for the DWARF table is a 32 bit string table offset into the; "".debug_str"" table. The "".debug_str"" is the string table for the DWARF which; may already contain copies of all of the strings. This helps make sure, with; help from the compiler, that we reuse the strings between all of the DWARF; sections and keeps the hash table size down. Another benefit to having the; compiler generate all strings as DW_FORM_strp in the debug info, is that; DWARF parsing can be made much faster. After a lookup is made, we get an offset into the hash data. The hash data; needs to be able to deal with 32 bit hash collisions, so the chunk of data; at the offset in the hash data consists of a triple:. .. code-block:: c. uint32_t str_offset; uint32_t hash_data_count; HashData[hash_data_count]. If ""str_offset"" is zero, then the bucket contents are done. 99.9% of the; hash data chunks contain a single item (no 32 bit hash collision):. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x........ | uint32_t HashData[2] DIE offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0x00000000 | uint32_t KeyType (end of hash chain); `------------'. If there are collisions, you will have multiple valid string offsets:. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:75634,Security,hash,hash,75634,"nts to be the DIE offset (eAtomTypeDIEOffset) that is; encoded as a 32 bit value (DW_FORM_data4). This allows a single name to have; multiple matching DIEs in a single file, which could come up with an inlined; function for instance. Future tables could include more information about the; DIE such as flags indicating if the DIE is a function, method, block,; or inlined. The KeyType for the DWARF table is a 32 bit string table offset into the; "".debug_str"" table. The "".debug_str"" is the string table for the DWARF which; may already contain copies of all of the strings. This helps make sure, with; help from the compiler, that we reuse the strings between all of the DWARF; sections and keeps the hash table size down. Another benefit to having the; compiler generate all strings as DW_FORM_strp in the debug info, is that; DWARF parsing can be made much faster. After a lookup is made, we get an offset into the hash data. The hash data; needs to be able to deal with 32 bit hash collisions, so the chunk of data; at the offset in the hash data consists of a triple:. .. code-block:: c. uint32_t str_offset; uint32_t hash_data_count; HashData[hash_data_count]. If ""str_offset"" is zero, then the bucket contents are done. 99.9% of the; hash data chunks contain a single item (no 32 bit hash collision):. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x........ | uint32_t HashData[2] DIE offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0x00000000 | uint32_t KeyType (end of hash chain); `------------'. If there are collisions, you will have multiple valid string offsets:. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:75834,Security,hash,hash,75834,"formation about the; DIE such as flags indicating if the DIE is a function, method, block,; or inlined. The KeyType for the DWARF table is a 32 bit string table offset into the; "".debug_str"" table. The "".debug_str"" is the string table for the DWARF which; may already contain copies of all of the strings. This helps make sure, with; help from the compiler, that we reuse the strings between all of the DWARF; sections and keeps the hash table size down. Another benefit to having the; compiler generate all strings as DW_FORM_strp in the debug info, is that; DWARF parsing can be made much faster. After a lookup is made, we get an offset into the hash data. The hash data; needs to be able to deal with 32 bit hash collisions, so the chunk of data; at the offset in the hash data consists of a triple:. .. code-block:: c. uint32_t str_offset; uint32_t hash_data_count; HashData[hash_data_count]. If ""str_offset"" is zero, then the bucket contents are done. 99.9% of the; hash data chunks contain a single item (no 32 bit hash collision):. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x........ | uint32_t HashData[2] DIE offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0x00000000 | uint32_t KeyType (end of hash chain); `------------'. If there are collisions, you will have multiple valid string offsets:. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x........ | uint32_t HashData[2] DIE offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0x00002023 | uint32_t KeyType (.debug_str[0x0002023] => ""print""); | 0x00000002 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DI",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:75884,Security,hash,hash,75884,"formation about the; DIE such as flags indicating if the DIE is a function, method, block,; or inlined. The KeyType for the DWARF table is a 32 bit string table offset into the; "".debug_str"" table. The "".debug_str"" is the string table for the DWARF which; may already contain copies of all of the strings. This helps make sure, with; help from the compiler, that we reuse the strings between all of the DWARF; sections and keeps the hash table size down. Another benefit to having the; compiler generate all strings as DW_FORM_strp in the debug info, is that; DWARF parsing can be made much faster. After a lookup is made, we get an offset into the hash data. The hash data; needs to be able to deal with 32 bit hash collisions, so the chunk of data; at the offset in the hash data consists of a triple:. .. code-block:: c. uint32_t str_offset; uint32_t hash_data_count; HashData[hash_data_count]. If ""str_offset"" is zero, then the bucket contents are done. 99.9% of the; hash data chunks contain a single item (no 32 bit hash collision):. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x........ | uint32_t HashData[2] DIE offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0x00000000 | uint32_t KeyType (end of hash chain); `------------'. If there are collisions, you will have multiple valid string offsets:. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x........ | uint32_t HashData[2] DIE offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0x00002023 | uint32_t KeyType (.debug_str[0x0002023] => ""print""); | 0x00000002 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DI",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:76279,Security,hash,hash,76279,"ll of the DWARF; sections and keeps the hash table size down. Another benefit to having the; compiler generate all strings as DW_FORM_strp in the debug info, is that; DWARF parsing can be made much faster. After a lookup is made, we get an offset into the hash data. The hash data; needs to be able to deal with 32 bit hash collisions, so the chunk of data; at the offset in the hash data consists of a triple:. .. code-block:: c. uint32_t str_offset; uint32_t hash_data_count; HashData[hash_data_count]. If ""str_offset"" is zero, then the bucket contents are done. 99.9% of the; hash data chunks contain a single item (no 32 bit hash collision):. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x........ | uint32_t HashData[2] DIE offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0x00000000 | uint32_t KeyType (end of hash chain); `------------'. If there are collisions, you will have multiple valid string offsets:. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x........ | uint32_t HashData[2] DIE offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0x00002023 | uint32_t KeyType (.debug_str[0x0002023] => ""print""); | 0x00000002 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x00000000 | uint32_t KeyType (end of hash chain); `------------'. Current testing with real world C++ binaries has shown that there is around 1; 32 bit hash collision per 100,000 name entries. Contents; ^^^^^^^^. As we said, we want to strictly define exactly what is included in the; different tables. For DWARF, we have 3 tables: ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:76960,Security,hash,hash,76960,"-.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x........ | uint32_t HashData[2] DIE offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0x00000000 | uint32_t KeyType (end of hash chain); `------------'. If there are collisions, you will have multiple valid string offsets:. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x........ | uint32_t HashData[2] DIE offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0x00002023 | uint32_t KeyType (.debug_str[0x0002023] => ""print""); | 0x00000002 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x00000000 | uint32_t KeyType (end of hash chain); `------------'. Current testing with real world C++ binaries has shown that there is around 1; 32 bit hash collision per 100,000 name entries. Contents; ^^^^^^^^. As we said, we want to strictly define exactly what is included in the; different tables. For DWARF, we have 3 tables: ""``.apple_names``"",; ""``.apple_types``"", and ""``.apple_namespaces``"". ""``.apple_names``"" sections should contain an entry for each DWARF DIE whose; ``DW_TAG`` is a ``DW_TAG_label``, ``DW_TAG_inlined_subroutine``, or; ``DW_TAG_subprogram`` that has address attributes: ``DW_AT_low_pc``,; ``DW_AT_high_pc``, ``DW_AT_ranges`` or ``DW_AT_entry_pc``. It also contains; ``DW_TAG_variable`` DIEs that have a ``DW_OP_addr`` in the location (global and; static variables). All global and static variables should be included,; including those scoped within functions and classes. For example using the; following code:. .. code-block:: c. static int var = 0;. void f (); {; static int var = ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:77075,Security,hash,hash,77075,"........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x........ | uint32_t HashData[2] DIE offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0x00000000 | uint32_t KeyType (end of hash chain); `------------'. If there are collisions, you will have multiple valid string offsets:. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x........ | uint32_t HashData[2] DIE offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0x00002023 | uint32_t KeyType (.debug_str[0x0002023] => ""print""); | 0x00000002 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x00000000 | uint32_t KeyType (end of hash chain); `------------'. Current testing with real world C++ binaries has shown that there is around 1; 32 bit hash collision per 100,000 name entries. Contents; ^^^^^^^^. As we said, we want to strictly define exactly what is included in the; different tables. For DWARF, we have 3 tables: ""``.apple_names``"",; ""``.apple_types``"", and ""``.apple_namespaces``"". ""``.apple_names``"" sections should contain an entry for each DWARF DIE whose; ``DW_TAG`` is a ``DW_TAG_label``, ``DW_TAG_inlined_subroutine``, or; ``DW_TAG_subprogram`` that has address attributes: ``DW_AT_low_pc``,; ``DW_AT_high_pc``, ``DW_AT_ranges`` or ``DW_AT_entry_pc``. It also contains; ``DW_TAG_variable`` DIEs that have a ``DW_OP_addr`` in the location (global and; static variables). All global and static variables should be included,; including those scoped within functions and classes. For example using the; following code:. .. code-block:: c. static int var = 0;. void f (); {; static int var = 0;; }. Both of the static ``var`` variables would be included in the table. All; functions should emit both their fu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:80331,Security,hash,hash,80331,"in (); {; int *b = 0;; return *b;; }. We get a few type DIEs:. .. code-block:: none. 0x00000067: TAG_base_type [5]; AT_encoding( DW_ATE_signed ); AT_name( ""int"" ); AT_byte_size( 0x04 ). 0x0000006e: TAG_pointer_type [6]; AT_type( {0x00000067} ( int ) ); AT_byte_size( 0x08 ). The DW_TAG_pointer_type is not included because it does not have a ``DW_AT_name``. ""``.apple_namespaces``"" section should contain all ``DW_TAG_namespace`` DIEs.; If we run into a namespace that has no name this is an anonymous namespace, and; the name should be output as ""``(anonymous namespace)``"" (without the quotes).; Why? This matches the output of the ``abi::cxa_demangle()`` that is in the; standard C++ library that demangles mangled names. Language Extensions and File Format Changes; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Objective-C Extensions; """""""""""""""""""""""""""""""""""""""""""". ""``.apple_objc``"" section should contain all ``DW_TAG_subprogram`` DIEs for an; Objective-C class. The name used in the hash table is the name of the; Objective-C class itself. If the Objective-C class has a category, then an; entry is made for both the class name without the category, and for the class; name with the category. So if we have a DIE at offset 0x1234 with a name of; method ""``-[NSString(my_additions) stringWithSpecialString:]``"", we would add; an entry for ""``NSString``"" that points to DIE 0x1234, and an entry for; ""``NSString(my_additions)``"" that points to 0x1234. This allows us to quickly; track down all Objective-C methods for an Objective-C class when doing; expressions. It is needed because of the dynamic nature of Objective-C where; anyone can add methods to a class. The DWARF for Objective-C methods is also; emitted differently from C++ classes where the methods are not usually; contained in the class definition, they are scattered about across one or more; compile units. Categories can also be defined in different shared libraries.; So we need to be able to quickly find all of the methods and clas",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:82007,Security,hash,hash,82007,". The DWARF for Objective-C methods is also; emitted differently from C++ classes where the methods are not usually; contained in the class definition, they are scattered about across one or more; compile units. Categories can also be defined in different shared libraries.; So we need to be able to quickly find all of the methods and class functions; given the Objective-C class name, or quickly find all methods and class; functions for a class + category name. This table does not contain any; selector names, it just maps Objective-C class names (or class names +; category) to all of the methods and class functions. The selectors are added; as function basenames in the ""``.debug_names``"" section. In the ""``.apple_names``"" section for Objective-C functions, the full name is; the entire function name with the brackets (""``-[NSString; stringWithCString:]``"") and the basename is the selector only; (""``stringWithCString:``""). Mach-O Changes; """""""""""""""""""""""""""". The sections names for the apple hash tables are for non-mach-o files. For; mach-o files, the sections should be contained in the ``__DWARF`` segment with; names as follows:. * ""``.apple_names``"" -> ""``__apple_names``""; * ""``.apple_types``"" -> ""``__apple_types``""; * ""``.apple_namespaces``"" -> ""``__apple_namespac``"" (16 character limit); * ""``.apple_objc``"" -> ""``__apple_objc``"". .. _codeview:. CodeView Debug Info Format; ==========================. LLVM supports emitting CodeView, the Microsoft debug info format, and this; section describes the design and implementation of that support. Format Background; -----------------. CodeView as a format is clearly oriented around C++ debugging, and in C++, the; majority of debug information tends to be type information. Therefore, the; overriding design constraint of CodeView is the separation of type information; from other ""symbol"" information so that type information can be efficiently; merged across translation units. Both type information and symbol information is; generall",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:5693,Testability,test,test-suite,5693,"g information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids duplicated debugging information from; the beginning, and the global dead code elimination pass automatically deletes; debugging information for a function if it decides to delete th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:5755,Testability,test,test,5755,"g information does not prevent optimizations from; happening (for example inlining, basic block reordering/merging/cleanup,; tail duplication, etc). * LLVM debug information is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids duplicated debugging information from; the beginning, and the global dead code elimination pass automatically deletes; debugging information for a function if it decides to delete th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:5879,Testability,test,test-suite,5879,"formation is automatically optimized along with the rest of; the program, using existing facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids duplicated debugging information from; the beginning, and the global dead code elimination pass automatically deletes; debugging information for a function if it decides to delete the function. To do this, most of the debugging information (descriptors for types,; variables, functions, source files, etc) is inserted by the language front-end; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:5966,Testability,test,test,5966,"sting facilities. For example, duplicate; information is automatically merged by the linker, and unused information; is automatically removed. Basically, the debug information allows you to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids duplicated debugging information from; the beginning, and the global dead code elimination pass automatically deletes; debugging information for a function if it decides to delete the function. To do this, most of the debugging information (descriptors for types,; variables, functions, source files, etc) is inserted by the language front-end; in the form of LLVM metadata. Debug information is designed to be agnostic about the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:6177,Testability,test,test,6177,"u to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids duplicated debugging information from; the beginning, and the global dead code elimination pass automatically deletes; debugging information for a function if it decides to delete the function. To do this, most of the debugging information (descriptors for types,; variables, functions, source files, etc) is inserted by the language front-end; in the form of LLVM metadata. Debug information is designed to be agnostic about the target debugger and; debugging information representation (e.g. DWARF/Stabs/etc). It uses a generic; pass to decode the information that represents variables, types, functions,; names",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:6221,Testability,test,tests,6221,"u to compile a program with; ""``-O0 -g``"" and get full debug information, allowing you to arbitrarily modify; the program as it executes from a debugger. Compiling a program with; ""``-O3 -g``"" gives you full debug information that is always available and; accurate for reading (e.g., you get accurate stack traces despite tail call; elimination and inlining), but you might lose the ability to modify the program; and call functions which were optimized out of the program, or inlined away; completely. The :doc:`LLVM test-suite <TestSuiteMakefileGuide>` provides a framework to; test the optimizer's handling of debugging information. It can be run like; this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=dbgopt. This will test impact of debugging information on optimization passes. If; debugging information influences optimization passes then it will be reported; as a failure. See :doc:`TestingGuide` for more information on LLVM test; infrastructure and how to run various tests. .. _format:. Debugging information format; ============================. LLVM debugging information has been carefully designed to make it possible for; the optimizer to optimize the program and debugging information without; necessarily having to know anything about debugging information. In; particular, the use of metadata avoids duplicated debugging information from; the beginning, and the global dead code elimination pass automatically deletes; debugging information for a function if it decides to delete the function. To do this, most of the debugging information (descriptors for types,; variables, functions, source files, etc) is inserted by the language front-end; in the form of LLVM metadata. Debug information is designed to be agnostic about the target debugger and; debugging information representation (e.g. DWARF/Stabs/etc). It uses a generic; pass to decode the information that represents variables, types, functions,; names",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:36957,Testability,assert,asserts,36957,"gister allocation, the; VirtRegRewriter pass re-inserts DBG_VALUE instructions in their original; positions, translating virtual register references into their physical; machine locations. To avoid encoding incorrect variable locations, in this; pass any DBG_VALUE of a virtual register that is not live, is replaced by; the undefined location. The LiveDebugVariables may insert redundant DBG_VALUEs; because of virtual register rewriting. These will be subsequently removed by; the RemoveRedundantDebugValues pass. LiveDebugValues expansion of variable locations; -----------------------------------------------. After all optimizations have run and shortly before emission, the; LiveDebugValues pass runs to achieve two aims:. * To propagate the location of variables through copies and register spills,; * For every block, to record every valid variable location in that block. After this pass the DBG_VALUE instruction changes meaning: rather than; corresponding to a source-level assignment where the variable may change value,; it asserts the location of a variable in a block, and loses effect outside the; block. Propagating variable locations through copies and spills is; straightforwards: determining the variable location in every basic block; requires the consideration of control flow. Consider the following IR, which; presents several difficulties:. .. code-block:: text. define dso_local i32 @foo(i1 %cond, i32 %input) !dbg !12 {; entry:; br i1 %cond, label %truebr, label %falsebr. bb1:; %value = phi i32 [ %value1, %truebr ], [ %value2, %falsebr ]; br label %exit, !dbg !26. truebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 1, metadata !23, metadata !DIExpression()), !dbg !24; %value1 = add i32 %input, 1; br label %bb1. falsebr:; call void @llvm.dbg.value(metadata i32 %input, metadata !30, metadata !DIExpression()), !dbg !24; call void @llvm.dbg.value(metadata i32 2, metadata !23",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:76997,Testability,test,testing,76997,"........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x........ | uint32_t HashData[2] DIE offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0x00000000 | uint32_t KeyType (end of hash chain); `------------'. If there are collisions, you will have multiple valid string offsets:. .. code-block:: none. .------------.; | 0x00001023 | uint32_t KeyType (.debug_str[0x0001023] => ""main""); | 0x00000004 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x........ | uint32_t HashData[2] DIE offset; | 0x........ | uint32_t HashData[3] DIE offset; | 0x00002023 | uint32_t KeyType (.debug_str[0x0002023] => ""print""); | 0x00000002 | uint32_t HashData count; | 0x........ | uint32_t HashData[0] DIE offset; | 0x........ | uint32_t HashData[1] DIE offset; | 0x00000000 | uint32_t KeyType (end of hash chain); `------------'. Current testing with real world C++ binaries has shown that there is around 1; 32 bit hash collision per 100,000 name entries. Contents; ^^^^^^^^. As we said, we want to strictly define exactly what is included in the; different tables. For DWARF, we have 3 tables: ""``.apple_names``"",; ""``.apple_types``"", and ""``.apple_namespaces``"". ""``.apple_names``"" sections should contain an entry for each DWARF DIE whose; ``DW_TAG`` is a ``DW_TAG_label``, ``DW_TAG_inlined_subroutine``, or; ``DW_TAG_subprogram`` that has address attributes: ``DW_AT_low_pc``,; ``DW_AT_high_pc``, ``DW_AT_ranges`` or ``DW_AT_entry_pc``. It also contains; ``DW_TAG_variable`` DIEs that have a ``DW_OP_addr`` in the location (global and; static variables). All global and static variables should be included,; including those scoped within functions and classes. For example using the; following code:. .. code-block:: c. static int var = 0;. void f (); {; static int var = 0;; }. Both of the static ``var`` variables would be included in the table. All; functions should emit both their fu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:85104,Testability,test,test,85104,"` record pointing; to the PDB. When using PDBs, symbol information appears to remain in the object; file ``.debug$S`` sections. Type records are referred to by their index, which is the number of records in; the stream before a given record plus ``0x1000``. Many common basic types, such; as the basic integral types and unqualified pointers to them, are represented; using type indices less than ``0x1000``. Such basic types are built in to; CodeView consumers and do not require type records. Each type record may only contain type indices that are less than its own type; index. This ensures that the graph of type stream references is acyclic. While; the source-level type graph may contain cycles through pointer types (consider a; linked list struct), these cycles are removed from the type stream by always; referring to the forward declaration record of user-defined record types. Only; ""symbol"" records in the ``.debug$S`` streams may refer to complete,; non-forward-declaration type records. Working with CodeView; ---------------------. These are instructions for some common tasks for developers working to improve; LLVM's CodeView support. Most of them revolve around using the CodeView dumper; embedded in ``llvm-readobj``. * Testing MSVC's output::. $ cl -c -Z7 foo.cpp # Use /Z7 to keep types in the object file; $ llvm-readobj --codeview foo.obj. * Getting LLVM IR debug info out of Clang::. $ clang -g -gcodeview --target=x86_64-windows-msvc foo.cpp -S -emit-llvm. Use this to generate LLVM IR for LLVM test cases. * Generate and dump CodeView from LLVM IR metadata::. $ llc foo.ll -filetype=obj -o foo.obj; $ llvm-readobj --codeview foo.obj > foo.txt. Use this pattern in lit test cases and FileCheck the output of llvm-readobj. Improving LLVM's CodeView support is a process of finding interesting type; records, constructing a C++ test case that makes MSVC emit those records,; dumping the records, understanding them, and then generating equivalent records; in LLVM's backend.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:85278,Testability,test,test,85278,"` record pointing; to the PDB. When using PDBs, symbol information appears to remain in the object; file ``.debug$S`` sections. Type records are referred to by their index, which is the number of records in; the stream before a given record plus ``0x1000``. Many common basic types, such; as the basic integral types and unqualified pointers to them, are represented; using type indices less than ``0x1000``. Such basic types are built in to; CodeView consumers and do not require type records. Each type record may only contain type indices that are less than its own type; index. This ensures that the graph of type stream references is acyclic. While; the source-level type graph may contain cycles through pointer types (consider a; linked list struct), these cycles are removed from the type stream by always; referring to the forward declaration record of user-defined record types. Only; ""symbol"" records in the ``.debug$S`` streams may refer to complete,; non-forward-declaration type records. Working with CodeView; ---------------------. These are instructions for some common tasks for developers working to improve; LLVM's CodeView support. Most of them revolve around using the CodeView dumper; embedded in ``llvm-readobj``. * Testing MSVC's output::. $ cl -c -Z7 foo.cpp # Use /Z7 to keep types in the object file; $ llvm-readobj --codeview foo.obj. * Getting LLVM IR debug info out of Clang::. $ clang -g -gcodeview --target=x86_64-windows-msvc foo.cpp -S -emit-llvm. Use this to generate LLVM IR for LLVM test cases. * Generate and dump CodeView from LLVM IR metadata::. $ llc foo.ll -filetype=obj -o foo.obj; $ llvm-readobj --codeview foo.obj > foo.txt. Use this pattern in lit test cases and FileCheck the output of llvm-readobj. Improving LLVM's CodeView support is a process of finding interesting type; records, constructing a C++ test case that makes MSVC emit those records,; dumping the records, understanding them, and then generating equivalent records; in LLVM's backend.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:85435,Testability,test,test,85435,"` record pointing; to the PDB. When using PDBs, symbol information appears to remain in the object; file ``.debug$S`` sections. Type records are referred to by their index, which is the number of records in; the stream before a given record plus ``0x1000``. Many common basic types, such; as the basic integral types and unqualified pointers to them, are represented; using type indices less than ``0x1000``. Such basic types are built in to; CodeView consumers and do not require type records. Each type record may only contain type indices that are less than its own type; index. This ensures that the graph of type stream references is acyclic. While; the source-level type graph may contain cycles through pointer types (consider a; linked list struct), these cycles are removed from the type stream by always; referring to the forward declaration record of user-defined record types. Only; ""symbol"" records in the ``.debug$S`` streams may refer to complete,; non-forward-declaration type records. Working with CodeView; ---------------------. These are instructions for some common tasks for developers working to improve; LLVM's CodeView support. Most of them revolve around using the CodeView dumper; embedded in ``llvm-readobj``. * Testing MSVC's output::. $ cl -c -Z7 foo.cpp # Use /Z7 to keep types in the object file; $ llvm-readobj --codeview foo.obj. * Getting LLVM IR debug info out of Clang::. $ clang -g -gcodeview --target=x86_64-windows-msvc foo.cpp -S -emit-llvm. Use this to generate LLVM IR for LLVM test cases. * Generate and dump CodeView from LLVM IR metadata::. $ llc foo.ll -filetype=obj -o foo.obj; $ llvm-readobj --codeview foo.obj > foo.txt. Use this pattern in lit test cases and FileCheck the output of llvm-readobj. Improving LLVM's CodeView support is a process of finding interesting type; records, constructing a C++ test case that makes MSVC emit those records,; dumping the records, understanding them, and then generating equivalent records; in LLVM's backend.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:3164,Usability,usab,usable,3164,"tion-defined format <ccxx_frontend>` (the C/C++ front-end; currently uses working draft 7 of the `DWARF 3 standard; <http://www.eagercon.com/dwarf/dwarf3std.htm>`_). When a program is being debugged, a debugger interacts with the user and turns; the stored debug information into source-language specific information. As; such, a debugger must be aware of the source-language, and is thus tied to a; specific language or family of languages. Debug information consumers; ---------------------------. The role of debug information is to provide meta information normally stripped; away during the compilation process. This meta information provides an LLVM; user a relationship between generated code and the original program source; code. Currently, there are two backend consumers of debug info: DwarfDebug and; CodeViewDebug. DwarfDebug produces DWARF suitable for use with GDB, LLDB, and; other DWARF-based debuggers. :ref:`CodeViewDebug <codeview>` produces CodeView,; the Microsoft debug info format, which is usable with Microsoft debuggers such; as Visual Studio and WinDBG. LLVM's debug information format is mostly derived; from and inspired by DWARF, but it is feasible to translate into other target; debug info formats such as STABS. It would also be reasonable to use debug information to feed profiling tools; for analysis of generated code, or, tools for reconstructing the original; source from generated code. .. _intro_debugopt:. Debug information and optimizations; -----------------------------------. An extremely high priority of LLVM debugging information is to make it interact; well with optimizations and analysis. In particular, the LLVM debug; information provides the following guarantees:. * LLVM debug information **always provides information to accurately read; the source-level state of the program**, regardless of which LLVM; optimizations have been run. :doc:`HowToUpdateDebugInfo` specifies how debug; info should be updated in various kinds of code transformatio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:24225,Usability,simpl,simple,24225,"e that kills variable locations is called a ""kill; dbg.value"" or ""kill location"", and for legacy reasons the term ""undef; dbg.value"" may be used in existing code. The ``DbgVariableIntrinsic`` methods; ``isKillLocation`` and ``setKillLocation`` should be used where possible rather; than inspecting location operands directly to check or set whether a dbg.value; is a kill location. In general, if any dbg.value has its operand optimized out and cannot be; recovered, then a kill dbg.value is necessary to terminate earlier variable; locations. Additional kill dbg.values may be necessary when the debugger can; observe re-ordering of assignments. How variable location metadata is transformed during CodeGen; ============================================================. LLVM preserves debug information throughout mid-level and backend passes,; ultimately producing a mapping between source-level information and; instruction ranges. This; is relatively straightforwards for line number information, as mapping; instructions to line numbers is a simple association. For variable locations; however the story is more complex. As each ``llvm.dbg.value`` intrinsic; represents a source-level assignment of a value to a source variable, the; variable location intrinsics effectively embed a small imperative program; within the LLVM IR. By the end of CodeGen, this becomes a mapping from each; variable to their machine locations over ranges of instructions.; From IR to object emission, the major transformations which affect variable; location fidelity are:. 1. Instruction Selection; 2. Register allocation; 3. Block layout. each of which are discussed below. In addition, instruction scheduling can; significantly change the ordering of the program, and occurs in a number of; different passes. Some variable locations are not transformed during CodeGen. Stack locations; specified by ``llvm.dbg.declare`` are valid and unchanging for the entire; duration of the function, and are recorded in a simp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:25174,Usability,simpl,simple,25174,"htforwards for line number information, as mapping; instructions to line numbers is a simple association. For variable locations; however the story is more complex. As each ``llvm.dbg.value`` intrinsic; represents a source-level assignment of a value to a source variable, the; variable location intrinsics effectively embed a small imperative program; within the LLVM IR. By the end of CodeGen, this becomes a mapping from each; variable to their machine locations over ranges of instructions.; From IR to object emission, the major transformations which affect variable; location fidelity are:. 1. Instruction Selection; 2. Register allocation; 3. Block layout. each of which are discussed below. In addition, instruction scheduling can; significantly change the ordering of the program, and occurs in a number of; different passes. Some variable locations are not transformed during CodeGen. Stack locations; specified by ``llvm.dbg.declare`` are valid and unchanging for the entire; duration of the function, and are recorded in a simple MachineFunction table.; Location changes in the prologue and epilogue of a function are also ignored:; frame setup and destruction may take several instructions, require a; disproportionate amount of debugging information in the output binary to; describe, and should be stepped over by debuggers anyway. Variable locations in Instruction Selection and MIR; ---------------------------------------------------. Instruction selection creates a MIR function from an IR function, and just as; it transforms ``intermediate`` instructions into machine instructions, so must; ``intermediate`` variable locations become machine variable locations.; Within IR, variable locations are always identified by a Value, but in MIR; there can be different types of variable locations. In addition, some IR; locations become unavailable, for example if the operation of multiple IR; instructions are combined into one machine instruction (such as; multiply-and-accumulate) t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:32445,Usability,simpl,simple,32445,"32 = SUB32rr %6, %0, implicit-def $eflags, debug-location !5; JB_1 %bb.1, implicit $eflags, debug-location !5; JMP_1 %bb.2, debug-location !5. bb.2.bb2:; %8:gr32 = MOV32r0 implicit-def dead $eflags; $eax = COPY %8, debug-location !5; RET 0, $eax, debug-location !5. Observe first that there is a DBG_VALUE instruction for every ``llvm.dbg.value``; intrinsic in the source IR, ensuring no source level assignments go missing.; Then consider the different ways in which variable locations have been recorded:. * For the first dbg.value an immediate operand is used to record a zero value.; * The dbg.value of the PHI instruction leads to a DBG_VALUE of virtual register; ``%0``.; * The first GEP has its effect folded into the first load instruction; (as a 4-byte offset), but the variable location is salvaged by folding; the GEPs effect into the DIExpression.; * The second GEP is also folded into the corresponding load. However, it is; insufficiently simple to be salvaged, and is emitted as a ``$noreg``; DBG_VALUE, indicating that the variable takes on an undefined location.; * The final dbg.value has its Value placed in virtual register ``%1``. Instruction Scheduling; ----------------------. A number of passes can reschedule instructions, notably instruction selection; and the pre-and-post RA machine schedulers. Instruction scheduling can; significantly change the nature of the program -- in the (very unlikely) worst; case the instruction sequence could be completely reversed. In such; circumstances LLVM follows the principle applied to optimizations, that it is; better for the debugger not to display any state than a misleading state.; Thus, whenever instructions are advanced in order of execution, any; corresponding DBG_VALUE is kept in its original position, and if an instruction; is delayed then the variable is given an undefined location for the duration; of the delay. To illustrate, consider this pseudo-MIR:. .. code-block:: text. %1:gr32 = MOV32rm %0, 1, $noreg, 4, $nor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:49276,Usability,simpl,simpler,49276,"ref); ...; DW_AT_artificial (true). A Fortran front-end may need to generate a *trampoline* function to call a; function defined in a different compilation unit. In this case, the front-end; can emit the following descriptor for the trampoline function:. .. code-block:: text. !DISubprogram(name: ""sub1_.t0p"", linkageName: ""sub1_.t0p"", scope: !4, file: !4, type: !5, spFlags: DISPFlagLocalToUnit | DISPFlagDefinition, unit: !7, retainedNodes: !24, targetFuncName: ""sub1_""). The targetFuncName field is the name of the function that the trampoline; calls. This descriptor results in the following DWARF tag:. .. code-block:: text. DW_TAG_subprogram; ...; DW_AT_linkage_name	(""sub1_.t0p""); DW_AT_name	(""sub1_.t0p""); DW_AT_trampoline	(""sub1_""). Debugging information format; ============================. Debugging Information Extension for Objective C Properties; ----------------------------------------------------------. Introduction; ^^^^^^^^^^^^. Objective C provides a simpler way to declare and define accessor methods using; declared properties. The language provides features to declare a property and; to let compiler synthesize accessor methods. The debugger lets developer inspect Objective C interfaces and their instance; variables and class variables. However, the debugger does not know anything; about the properties defined in Objective C interfaces. The debugger consumes; information generated by compiler in DWARF format. The format does not support; encoding of Objective C properties. This proposal describes DWARF extensions to; encode Objective C properties, which the debugger can use to let developers; inspect Objective C properties. Proposal; ^^^^^^^^. Objective C properties exist separately from class members. A property can be; defined only by ""setter"" and ""getter"" selectors, and be calculated anew on each; access. Or a property can just be a direct access to some declared ivar.; Finally it can have an ivar ""automatically synthesized"" for it by the compiler,; in wh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:57285,Usability,simpl,simple,57285,"OPERTY_class | 0x4000|; +--------------------------------------+-------+. Name Accelerator Tables; -----------------------. Introduction; ^^^^^^^^^^^^. The ""``.debug_pubnames``"" and ""``.debug_pubtypes``"" formats are not what a; debugger needs. The ""``pub``"" in the section name indicates that the entries; in the table are publicly visible names only. This means no static or hidden; functions show up in the ""``.debug_pubnames``"". No static variables or private; class variables are in the ""``.debug_pubtypes``"". Many compilers add different; things to these tables, so we can't rely upon the contents between gcc, icc, or; clang. The typical query given by users tends not to match up with the contents of; these tables. For example, the DWARF spec states that ""In the case of the name; of a function member or static data member of a C++ structure, class or union,; the name presented in the ""``.debug_pubnames``"" section is not the simple name; given by the ``DW_AT_name attribute`` of the referenced debugging information; entry, but rather the fully qualified name of the data or function member.""; So the only names in these tables for complex C++ entries is a fully; qualified name. Debugger users tend not to enter their search strings as; ""``a::b::c(int,const Foo&) const``"", but rather as ""``c``"", ""``b::c``"" , or; ""``a::b::c``"". So the name entered in the name table must be demangled in; order to chop it up appropriately and additional names must be manually entered; into the table to make it effective as a name lookup table for debuggers to; use. All debuggers currently ignore the ""``.debug_pubnames``"" table as a result of; its inconsistent and useless public-only name content making it a waste of; space in the object file. These tables, when they are written to disk, are not; sorted in any way, leaving every debugger to do its own parsing and sorting.; These tables also include an inlined copy of the string values in the table; itself making the tables much larger than they ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:60205,Usability,simpl,simply,60205,"rator tables that are optimized for very quick lookups will benefit this; type of debugging experience greatly. We would like to generate name lookup tables that can be mapped into memory; from disk, and used as is, with little or no up-front parsing. We would also; be able to control the exact content of these different tables so they contain; exactly what we need. The Name Accelerator Tables were designed to fix these; issues. In order to solve these issues we need to:. * Have a format that can be mapped into memory from disk and used as is; * Lookups should be very fast; * Extensible table format so these tables can be made by many producers; * Contain all of the names needed for typical lookups out of the box; * Strict rules for the contents of tables. Table size is important and the accelerator table format should allow the reuse; of strings from common string tables so the strings for the names are not; duplicated. We also want to make sure the table is ready to be used as-is by; simply mapping the table into memory with minimal header parsing. The name lookups need to be fast and optimized for the kinds of lookups that; debuggers tend to do. Optimally we would like to touch as few parts of the; mapped table as possible when doing a name lookup and be able to quickly find; the name entry we are looking for, or discover there are no matches. In the; case of debuggers we optimized for lookups that fail most of the time. Each table that is defined should have strict rules on exactly what is in the; accelerator tables and documented so clients can rely on the content. Hash Tables; ^^^^^^^^^^^. Standard Hash Tables; """""""""""""""""""""""""""""""""""""""". Typical hash tables have a header, buckets, and each bucket points to the; bucket contents:. .. code-block:: none. .------------.; | HEADER |; |------------|; | BUCKETS |; |------------|; | DATA |; `------------'. The BUCKETS are an array of offsets to DATA for each hash:. .. code-block:: none. .------------.; | 0x00001000 | BUCKET",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:78400,Usability,simpl,simple,78400,"ld contain an entry for each DWARF DIE whose; ``DW_TAG`` is a ``DW_TAG_label``, ``DW_TAG_inlined_subroutine``, or; ``DW_TAG_subprogram`` that has address attributes: ``DW_AT_low_pc``,; ``DW_AT_high_pc``, ``DW_AT_ranges`` or ``DW_AT_entry_pc``. It also contains; ``DW_TAG_variable`` DIEs that have a ``DW_OP_addr`` in the location (global and; static variables). All global and static variables should be included,; including those scoped within functions and classes. For example using the; following code:. .. code-block:: c. static int var = 0;. void f (); {; static int var = 0;; }. Both of the static ``var`` variables would be included in the table. All; functions should emit both their full names and their basenames. For C or C++,; the full name is the mangled name (if available) which is usually in the; ``DW_AT_MIPS_linkage_name`` attribute, and the ``DW_AT_name`` contains the; function basename. If global or static variables have a mangled name in a; ``DW_AT_MIPS_linkage_name`` attribute, this should be emitted along with the; simple name found in the ``DW_AT_name`` attribute. ""``.apple_types``"" sections should contain an entry for each DWARF DIE whose; tag is one of:. * DW_TAG_array_type; * DW_TAG_class_type; * DW_TAG_enumeration_type; * DW_TAG_pointer_type; * DW_TAG_reference_type; * DW_TAG_string_type; * DW_TAG_structure_type; * DW_TAG_subroutine_type; * DW_TAG_typedef; * DW_TAG_union_type; * DW_TAG_ptr_to_member_type; * DW_TAG_set_type; * DW_TAG_subrange_type; * DW_TAG_base_type; * DW_TAG_const_type; * DW_TAG_immutable_type; * DW_TAG_file_type; * DW_TAG_namelist; * DW_TAG_packed_type; * DW_TAG_volatile_type; * DW_TAG_restrict_type; * DW_TAG_atomic_type; * DW_TAG_interface_type; * DW_TAG_unspecified_type; * DW_TAG_shared_type. Only entries with a ``DW_AT_name`` attribute are included, and the entry must; not be a forward declaration (``DW_AT_declaration`` attribute with a non-zero; value). For example, using the following code:. .. code-block:: c. int main (); {; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst:82630,Usability,clear,clearly,82630,"es in the ""``.debug_names``"" section. In the ""``.apple_names``"" section for Objective-C functions, the full name is; the entire function name with the brackets (""``-[NSString; stringWithCString:]``"") and the basename is the selector only; (""``stringWithCString:``""). Mach-O Changes; """""""""""""""""""""""""""". The sections names for the apple hash tables are for non-mach-o files. For; mach-o files, the sections should be contained in the ``__DWARF`` segment with; names as follows:. * ""``.apple_names``"" -> ""``__apple_names``""; * ""``.apple_types``"" -> ""``__apple_types``""; * ""``.apple_namespaces``"" -> ""``__apple_namespac``"" (16 character limit); * ""``.apple_objc``"" -> ""``__apple_objc``"". .. _codeview:. CodeView Debug Info Format; ==========================. LLVM supports emitting CodeView, the Microsoft debug info format, and this; section describes the design and implementation of that support. Format Background; -----------------. CodeView as a format is clearly oriented around C++ debugging, and in C++, the; majority of debug information tends to be type information. Therefore, the; overriding design constraint of CodeView is the separation of type information; from other ""symbol"" information so that type information can be efficiently; merged across translation units. Both type information and symbol information is; generally stored as a sequence of records, where each record begins with a; 16-bit record size and a 16-bit record kind. Type information is usually stored in the ``.debug$T`` section of the object; file. All other debug info, such as line info, string table, symbol info, and; inlinee info, is stored in one or more ``.debug$S`` sections. There may only be; one ``.debug$T`` section per object file, since all other debug info refers to; it. If a PDB (enabled by the ``/Zi`` MSVC option) was used during compilation,; the ``.debug$T`` section will contain only an ``LF_TYPESERVER2`` record pointing; to the PDB. When using PDBs, symbol information appears to remain in the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SourceLevelDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst:4655,Availability,echo,echo,4655,"l#sections. Text Formatting; ===============. Text can be *emphasized*, **bold**, or ``monospace``. To create a new paragraph, simply insert a blank line. Links; =====. You can format a link `like this <https://llvm.org/>`_. A more `sophisticated syntax`_ allows you to place the ``.. _`link text`: <URL>`` block; pretty much anywhere else in the document. This is useful when linking to especially long URLs. .. _`sophisticated syntax`: http://en.wikipedia.org/wiki/LLVM. Lists; =====. restructuredText allows you to create ordered lists... #. A list starting with ``#.`` will be automatically numbered. #. This is a second list element. #. Use indentation to create nested lists. ...as well as unordered lists:. * Stuff. + Deeper stuff. * More stuff. Code Blocks; ===========. You can make blocks of code like this:. .. code-block:: c++. int main() {; return 0;; }. For a shell session, use a ``console`` code block (some existing docs use; ``bash``):. .. code-block:: console. $ echo ""Goodbye cruel world!""; $ rm -rf /. If you need to show LLVM IR use the ``llvm`` code block. .. code-block:: llvm. define i32 @test1() {; entry:; ret i32 0; }. Some other common code blocks you might need are ``c``, ``objc``, ``make``,; and ``cmake``. If you need something beyond that, you can look at the `full; list`_ of supported code blocks. .. _`full list`: http://pygments.org/docs/lexers/. However, don't waste time fiddling with syntax highlighting when you could; be adding meaningful content. When in doubt, show preformatted text; without any syntax highlighting like this:. ::. .; +:.; ..:: ::; .++:+:: ::+:.:.; .:+ :; ::.::..:: .+.; ..:+ :: :; ......+:. ..; :++. .. :; .+:::+:: :; .. . .+ ::; +.: .::+.; ...+. .: .; .++:..; ... Generating the documentation; ============================. You can generate the HTML documentation from the sources locally if you want to; see what they would look like. In addition to the normal; `build tools <GettingStarted.html>`_; you need to install `Sphinx`_ and t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst:5651,Deployability,install,install,5651,"ically numbered. #. This is a second list element. #. Use indentation to create nested lists. ...as well as unordered lists:. * Stuff. + Deeper stuff. * More stuff. Code Blocks; ===========. You can make blocks of code like this:. .. code-block:: c++. int main() {; return 0;; }. For a shell session, use a ``console`` code block (some existing docs use; ``bash``):. .. code-block:: console. $ echo ""Goodbye cruel world!""; $ rm -rf /. If you need to show LLVM IR use the ``llvm`` code block. .. code-block:: llvm. define i32 @test1() {; entry:; ret i32 0; }. Some other common code blocks you might need are ``c``, ``objc``, ``make``,; and ``cmake``. If you need something beyond that, you can look at the `full; list`_ of supported code blocks. .. _`full list`: http://pygments.org/docs/lexers/. However, don't waste time fiddling with syntax highlighting when you could; be adding meaningful content. When in doubt, show preformatted text; without any syntax highlighting like this:. ::. .; +:.; ..:: ::; .++:+:: ::+:.:.; .:+ :; ::.::..:: .+.; ..:+ :: :; ......+:. ..; :++. .. :; .+:::+:: :; .. . .+ ::; +.: .::+.; ...+. .: .; .++:..; ... Generating the documentation; ============================. You can generate the HTML documentation from the sources locally if you want to; see what they would look like. In addition to the normal; `build tools <GettingStarted.html>`_; you need to install `Sphinx`_ and the necessary extensions; using the following command inside the ``llvm-project`` checkout:. .. code-block:: console. pip install --user -r ./llvm/docs/requirements.txt. Then run cmake to build the documentation inside the ``llvm-project`` checkout:. .. code-block:: console. mkdir build; cd build; cmake -DLLVM_ENABLE_SPHINX=On ../llvm; cmake --build . --target docs-llvm-html. In case you already have the Cmake build set up and want to reuse that,; just set the CMake variable ``LLVM_ENABLE_SPHINX=On``. After that you find the generated documentation in ``build/docs/html``; folder.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst:5795,Deployability,install,install,5795,"ically numbered. #. This is a second list element. #. Use indentation to create nested lists. ...as well as unordered lists:. * Stuff. + Deeper stuff. * More stuff. Code Blocks; ===========. You can make blocks of code like this:. .. code-block:: c++. int main() {; return 0;; }. For a shell session, use a ``console`` code block (some existing docs use; ``bash``):. .. code-block:: console. $ echo ""Goodbye cruel world!""; $ rm -rf /. If you need to show LLVM IR use the ``llvm`` code block. .. code-block:: llvm. define i32 @test1() {; entry:; ret i32 0; }. Some other common code blocks you might need are ``c``, ``objc``, ``make``,; and ``cmake``. If you need something beyond that, you can look at the `full; list`_ of supported code blocks. .. _`full list`: http://pygments.org/docs/lexers/. However, don't waste time fiddling with syntax highlighting when you could; be adding meaningful content. When in doubt, show preformatted text; without any syntax highlighting like this:. ::. .; +:.; ..:: ::; .++:+:: ::+:.:.; .:+ :; ::.::..:: .+.; ..:+ :: :; ......+:. ..; :++. .. :; .+:::+:: :; .. . .+ ::; +.: .::+.; ...+. .: .; .++:..; ... Generating the documentation; ============================. You can generate the HTML documentation from the sources locally if you want to; see what they would look like. In addition to the normal; `build tools <GettingStarted.html>`_; you need to install `Sphinx`_ and the necessary extensions; using the following command inside the ``llvm-project`` checkout:. .. code-block:: console. pip install --user -r ./llvm/docs/requirements.txt. Then run cmake to build the documentation inside the ``llvm-project`` checkout:. .. code-block:: console. mkdir build; cd build; cmake -DLLVM_ENABLE_SPHINX=On ../llvm; cmake --build . --target docs-llvm-html. In case you already have the Cmake build set up and want to reuse that,; just set the CMake variable ``LLVM_ENABLE_SPHINX=On``. After that you find the generated documentation in ``build/docs/html``; folder.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst:457,Energy Efficiency,power,powerful,457,"==========================; Sphinx Quickstart Template; ==========================. This article is intended to take someone in the state of “I want to write documentation and get it added to LLVM’s docs” and help them start writing documentation as fast as possible and with as little nonsense as possible. .. contents::; :local:. Overview; ========. LLVM documentation is written in `reStructuredText`_, a markup syntax similar to markdown (but much more powerful). The LLVM documentation site itself uses `Sphinx`_, a documentation generator originally written for Python documentation. .. _`reStructuredText`: http://www.sphinx-doc.org/en/master/usage/restructuredtext/basics.html; .. _`Sphinx`: http://www.sphinx-doc.org. How to use this template; ========================. This article is located in ``docs/SphinxQuickstartTemplate.rst``. To use it as a template, make a copy and open it in a text editor. You can then write your docs, and then send the new article to llvm-commits for review. To view the restructuredText source file for this article, click **Show Source** on the right sidebar. Authoring Guidelines; ====================. Focus on *content*. It is easy to fix the Sphinx (reStructuredText) syntax; later if necessary, although reStructuredText tries to imitate common; plain-text conventions so it should be quite natural. A basic knowledge of; reStructuredText syntax is useful when writing the document, so the last; ~half of this document (starting with `Example Section`_) gives examples; which should cover 99% of use cases. Let me say that again: focus on *content*. But if you really need to verify; Sphinx's output, see ``docs/README.txt`` for information. Once you have finished with the content, please send the ``.rst`` file to; llvm-commits for review. Creating New Articles; ---------------------. Before creating a new article, consider the following questions:. #. Why would I want to read this document?. #. What should I know to be able to follow along with t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst:6144,Modifiability,variab,variable,6144,"ically numbered. #. This is a second list element. #. Use indentation to create nested lists. ...as well as unordered lists:. * Stuff. + Deeper stuff. * More stuff. Code Blocks; ===========. You can make blocks of code like this:. .. code-block:: c++. int main() {; return 0;; }. For a shell session, use a ``console`` code block (some existing docs use; ``bash``):. .. code-block:: console. $ echo ""Goodbye cruel world!""; $ rm -rf /. If you need to show LLVM IR use the ``llvm`` code block. .. code-block:: llvm. define i32 @test1() {; entry:; ret i32 0; }. Some other common code blocks you might need are ``c``, ``objc``, ``make``,; and ``cmake``. If you need something beyond that, you can look at the `full; list`_ of supported code blocks. .. _`full list`: http://pygments.org/docs/lexers/. However, don't waste time fiddling with syntax highlighting when you could; be adding meaningful content. When in doubt, show preformatted text; without any syntax highlighting like this:. ::. .; +:.; ..:: ::; .++:+:: ::+:.:.; .:+ :; ::.::..:: .+.; ..:+ :: :; ......+:. ..; :++. .. :; .+:::+:: :; .. . .+ ::; +.: .::+.; ...+. .: .; .++:..; ... Generating the documentation; ============================. You can generate the HTML documentation from the sources locally if you want to; see what they would look like. In addition to the normal; `build tools <GettingStarted.html>`_; you need to install `Sphinx`_ and the necessary extensions; using the following command inside the ``llvm-project`` checkout:. .. code-block:: console. pip install --user -r ./llvm/docs/requirements.txt. Then run cmake to build the documentation inside the ``llvm-project`` checkout:. .. code-block:: console. mkdir build; cd build; cmake -DLLVM_ENABLE_SPHINX=On ../llvm; cmake --build . --target docs-llvm-html. In case you already have the Cmake build set up and want to reuse that,; just set the CMake variable ``LLVM_ENABLE_SPHINX=On``. After that you find the generated documentation in ``build/docs/html``; folder.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst:2036,Usability,learn,learned,2036,"this article, click **Show Source** on the right sidebar. Authoring Guidelines; ====================. Focus on *content*. It is easy to fix the Sphinx (reStructuredText) syntax; later if necessary, although reStructuredText tries to imitate common; plain-text conventions so it should be quite natural. A basic knowledge of; reStructuredText syntax is useful when writing the document, so the last; ~half of this document (starting with `Example Section`_) gives examples; which should cover 99% of use cases. Let me say that again: focus on *content*. But if you really need to verify; Sphinx's output, see ``docs/README.txt`` for information. Once you have finished with the content, please send the ``.rst`` file to; llvm-commits for review. Creating New Articles; ---------------------. Before creating a new article, consider the following questions:. #. Why would I want to read this document?. #. What should I know to be able to follow along with this document?. #. What will I have learned by the end of this document?. A standard best practice is to make your articles task-oriented. You generally should not be writing documentation that isn't based around ""how to"" do something; unless there's already an existing ""how to"" article for the topic you're documenting. The reason for this is that without a ""how to"" article to read first, it might be difficult for; someone unfamiliar with the topic to understand a more advanced, conceptual article. When creating a task-oriented article, follow existing LLVM articles by giving it a filename that starts with ``HowTo*.rst``. This format is usually the easiest for another person to understand and also the most useful. Focus on content (yes, I had to say it again). The rest of this document shows example reStructuredText markup constructs; that are meant to be read by you in your text editor after you have copied; this file into a new file for the documentation you are about to write. Example Section; ===============. An article can co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst:3800,Usability,simpl,simply,3800,"ows example reStructuredText markup constructs; that are meant to be read by you in your text editor after you have copied; this file into a new file for the documentation you are about to write. Example Section; ===============. An article can contain one or more sections (i.e., headings). Sections (like ``Example Section`` above) help give your document its; structure. Use the same kind of adornments (e.g. ``======`` vs. ``------``); as are used in this document. The adornment must be the same length as the; text above it. For Vim users, variations of ``yypVr=`` might be handy. Example Nested Subsection; -------------------------. Subsections can also be nested beneath other subsections. For more information on sections, see Sphinx's `reStructuredText Primer`_. .. _`reStructuredText Primer`: http://www.sphinx-doc.org/en/master/usage/restructuredtext/basics.html#sections. Text Formatting; ===============. Text can be *emphasized*, **bold**, or ``monospace``. To create a new paragraph, simply insert a blank line. Links; =====. You can format a link `like this <https://llvm.org/>`_. A more `sophisticated syntax`_ allows you to place the ``.. _`link text`: <URL>`` block; pretty much anywhere else in the document. This is useful when linking to especially long URLs. .. _`sophisticated syntax`: http://en.wikipedia.org/wiki/LLVM. Lists; =====. restructuredText allows you to create ordered lists... #. A list starting with ``#.`` will be automatically numbered. #. This is a second list element. #. Use indentation to create nested lists. ...as well as unordered lists:. * Stuff. + Deeper stuff. * More stuff. Code Blocks; ===========. You can make blocks of code like this:. .. code-block:: c++. int main() {; return 0;; }. For a shell session, use a ``console`` code block (some existing docs use; ``bash``):. .. code-block:: console. $ echo ""Goodbye cruel world!""; $ rm -rf /. If you need to show LLVM IR use the ``llvm`` code block. .. code-block:: llvm. define i32 @test1() {; en",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SphinxQuickstartTemplate.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SPIRVUsage.rst:3396,Security,access,access,3396,"=============== ==============================================================; *<empty>*/``unknown`` Defaults to the OpenCL environment.; ===================== ==============================================================. Example:. ``-target spirv64v1.0`` can be used to compile for SPIR-V version 1.0 with 64-bit pointer width. .. _spirv-types:. Representing special types in SPIR-V; ====================================. SPIR-V specifies several kinds of opaque types. These types are represented; using target extension types. These types are represented as follows:. .. table:: SPIR-V Opaque Types. ================== ====================== =========================================================================================; SPIR-V Type LLVM type name LLVM type arguments; ================== ====================== =========================================================================================; OpTypeImage ``spirv.Image`` sampled type, dimensionality, depth, arrayed, MS, sampled, image format, access qualifier; OpTypeSampler ``spirv.Sampler`` (none); OpTypeSampledImage ``spirv.SampledImage`` sampled type, dimensionality, depth, arrayed, MS, sampled, image format, access qualifier; OpTypeEvent ``spirv.Event`` (none); OpTypeDeviceEvent ``spirv.DeviceEvent`` (none); OpTypeReserveId ``spirv.ReserveId`` (none); OpTypeQueue ``spirv.Queue`` (none); OpTypePipe ``spirv.Pipe`` access qualifier; OpTypePipeStorage ``spirv.PipeStorage`` (none); ================== ====================== =========================================================================================. All integer arguments take the same value as they do in their `corresponding; SPIR-V instruction <https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#_type_declaration_instructions>`_.; For example, the OpenCL type ``image2d_depth_ro_t`` would be represented in; SPIR-V IR as ``target(""spirv.Image"", void, 1, 1, 0, 0, 0, 0, 0)``, with its; dimensionality parameter as ``1`` meaning 2D. Samp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SPIRVUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SPIRVUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SPIRVUsage.rst:3569,Security,access,access,3569,"======================================================. Example:. ``-target spirv64v1.0`` can be used to compile for SPIR-V version 1.0 with 64-bit pointer width. .. _spirv-types:. Representing special types in SPIR-V; ====================================. SPIR-V specifies several kinds of opaque types. These types are represented; using target extension types. These types are represented as follows:. .. table:: SPIR-V Opaque Types. ================== ====================== =========================================================================================; SPIR-V Type LLVM type name LLVM type arguments; ================== ====================== =========================================================================================; OpTypeImage ``spirv.Image`` sampled type, dimensionality, depth, arrayed, MS, sampled, image format, access qualifier; OpTypeSampler ``spirv.Sampler`` (none); OpTypeSampledImage ``spirv.SampledImage`` sampled type, dimensionality, depth, arrayed, MS, sampled, image format, access qualifier; OpTypeEvent ``spirv.Event`` (none); OpTypeDeviceEvent ``spirv.DeviceEvent`` (none); OpTypeReserveId ``spirv.ReserveId`` (none); OpTypeQueue ``spirv.Queue`` (none); OpTypePipe ``spirv.Pipe`` access qualifier; OpTypePipeStorage ``spirv.PipeStorage`` (none); ================== ====================== =========================================================================================. All integer arguments take the same value as they do in their `corresponding; SPIR-V instruction <https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#_type_declaration_instructions>`_.; For example, the OpenCL type ``image2d_depth_ro_t`` would be represented in; SPIR-V IR as ``target(""spirv.Image"", void, 1, 1, 0, 0, 0, 0, 0)``, with its; dimensionality parameter as ``1`` meaning 2D. Sampled image types include the; parameters of its underlying image type, so that a sampled image for the; previous type has the representation; ``target(""spirv.SampledImag",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SPIRVUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SPIRVUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SPIRVUsage.rst:3777,Security,access,access,3777,"====================. Example:. ``-target spirv64v1.0`` can be used to compile for SPIR-V version 1.0 with 64-bit pointer width. .. _spirv-types:. Representing special types in SPIR-V; ====================================. SPIR-V specifies several kinds of opaque types. These types are represented; using target extension types. These types are represented as follows:. .. table:: SPIR-V Opaque Types. ================== ====================== =========================================================================================; SPIR-V Type LLVM type name LLVM type arguments; ================== ====================== =========================================================================================; OpTypeImage ``spirv.Image`` sampled type, dimensionality, depth, arrayed, MS, sampled, image format, access qualifier; OpTypeSampler ``spirv.Sampler`` (none); OpTypeSampledImage ``spirv.SampledImage`` sampled type, dimensionality, depth, arrayed, MS, sampled, image format, access qualifier; OpTypeEvent ``spirv.Event`` (none); OpTypeDeviceEvent ``spirv.DeviceEvent`` (none); OpTypeReserveId ``spirv.ReserveId`` (none); OpTypeQueue ``spirv.Queue`` (none); OpTypePipe ``spirv.Pipe`` access qualifier; OpTypePipeStorage ``spirv.PipeStorage`` (none); ================== ====================== =========================================================================================. All integer arguments take the same value as they do in their `corresponding; SPIR-V instruction <https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#_type_declaration_instructions>`_.; For example, the OpenCL type ``image2d_depth_ro_t`` would be represented in; SPIR-V IR as ``target(""spirv.Image"", void, 1, 1, 0, 0, 0, 0, 0)``, with its; dimensionality parameter as ``1`` meaning 2D. Sampled image types include the; parameters of its underlying image type, so that a sampled image for the; previous type has the representation; ``target(""spirv.SampledImage, void, 1, 1, 0, 0, 0, 0, 0)``.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SPIRVUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SPIRVUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:13749,Availability,avail,available,13749," be 0); uint16 : Location Size; uint16 : Dwarf RegNum; uint16 : Reserved (expected to be 0); int32 : Offset or SmallConstant; }; uint32 : Padding (only if required to align to 8 byte); uint16 : Padding; uint16 : NumLiveOuts; LiveOuts[NumLiveOuts]; uint16 : Dwarf RegNum; uint8 : Reserved; uint8 : Size in Bytes; }; uint32 : Padding (only if required to align to 8 byte); }. The first byte of each location encodes a type that indicates how to; interpret the ``RegNum`` and ``Offset`` fields as follows:. ======== ========== =================== ===========================; Encoding Type Value Description; -------- ---------- ------------------- ---------------------------; 0x1 Register Reg Value in a register; 0x2 Direct Reg + Offset Frame index value; 0x3 Indirect [Reg + Offset] Spilled value; 0x4 Constant Offset Small constant; 0x5 ConstIndex Constants[Offset] Large constant; ======== ========== =================== ===========================. In the common case, a value is available in a register, and the; ``Offset`` field will be zero. Values spilled to the stack are encoded; as ``Indirect`` locations. The runtime must load those values from a; stack address, typically in the form ``[BP + Offset]``. If an; ``alloca`` value is passed directly to a stack map intrinsic, then; LLVM may fold the frame index into the stack map as an optimization to; avoid allocating a register or stack slot. These frame indices will be; encoded as ``Direct`` locations in the form ``BP + Offset``. LLVM may; also optimize constants by emitting them directly in the stack map,; either in the ``Offset`` of a ``Constant`` location or in the constant; pool, referred to by ``ConstantIndex`` locations. At each callsite, a ""liveout"" register list is also recorded. These; are the registers that are live across the stackmap and therefore must; be saved by the runtime. This is an important optimization when the; patchpoint intrinsic is used with a calling convention that by default; preserves most regist",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:16612,Availability,recover,recover,16612," motivated by; simplicity and extensibility. Compactness of the representation is; secondary because the runtime is expected to parse the data; immediately after compiling a module and encode the information in its; own format. Since the runtime controls the allocation of sections, it; can reuse the same stack map space for multiple modules. Stackmap support is currently only implemented for 64-bit; platforms. However, a 32-bit implementation should be able to use the; same format with an insignificant amount of wasted space. .. _stackmap-section:. Stack Map Section; ^^^^^^^^^^^^^^^^^. A JIT compiler can easily access this section by providing its own; memory manager via the LLVM C API; ``LLVMCreateSimpleMCJITMemoryManager()``. When creating the memory; manager, the JIT provides a callback:; ``LLVMMemoryManagerAllocateDataSectionCallback()``. When LLVM creates; this section, it invokes the callback and passes the section name. The; JIT can record the in-memory address of the section at this time and; later parse it to recover the stack map data. For MachO (e.g. on Darwin), the stack map section name is; ""__llvm_stackmaps"". The segment name is ""__LLVM_STACKMAPS"". For ELF (e.g. on Linux), the stack map section name is; "".llvm_stackmaps"". The segment name is ""__LLVM_STACKMAPS"". Stack Map Usage; ===============. The stack map support described in this document can be used to; precisely determine the location of values at a specific position in; the code. LLVM does not maintain any mapping between those values and; any higher-level entity. The runtime must be able to interpret the; stack map record given only the ID, offset, and the order of the; locations, records, and functions, which LLVM preserves. Note that this is quite different from the goal of debug information,; which is a best-effort attempt to track the location of named; variables at every instruction. An important motivation for this design is to allow a runtime to; commandeer a stack frame when execution re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:52,Deployability,patch,patch,52,"===================================; Stack maps and patch points in LLVM; ===================================. .. contents::; :local:; :depth: 2. Definitions; ===========. In this document we refer to the ""runtime"" collectively as all; components that serve as the LLVM client, including the LLVM IR; generator, object code consumer, and code patcher. A stack map records the location of ``live values`` at a particular; instruction address. These ``live values`` do not refer to all the; LLVM values live across the stack map. Instead, they are only the; values that the runtime requires to be live at this point. For; example, they may be the values the runtime will need to resume; program execution at that point independent of the compiled function; containing the stack map. LLVM emits stack map data into the object code within a designated; :ref:`stackmap-section`. This stack map data contains a record for; each stack map. The record stores the stack map's instruction address; and contains an entry for each mapped value. Each entry encodes a; value's location as a register, stack offset, or constant. A patch point is an instruction address at which space is reserved for; patching a new instruction sequence at run time. Patch points look; much like calls to LLVM. They take arguments that follow a calling; convention and may return a value. They also imply stack map; generation, which allows the runtime to locate the patchpoint and; find the location of ``live values`` at that point. Motivation; ==========. This functionality is currently experimental but is potentially useful; in a variety of settings, the most obvious being a runtime (JIT); compiler. Example applications of the patchpoint intrinsics are; implementing an inline call cache for polymorphic method dispatch or; optimizing the retrieval of properties in dynamically typed languages; such as JavaScript. The intrinsics documented here are currently used by the JavaScript; compiler within the open source WebKit pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:343,Deployability,patch,patcher,343,"===================================; Stack maps and patch points in LLVM; ===================================. .. contents::; :local:; :depth: 2. Definitions; ===========. In this document we refer to the ""runtime"" collectively as all; components that serve as the LLVM client, including the LLVM IR; generator, object code consumer, and code patcher. A stack map records the location of ``live values`` at a particular; instruction address. These ``live values`` do not refer to all the; LLVM values live across the stack map. Instead, they are only the; values that the runtime requires to be live at this point. For; example, they may be the values the runtime will need to resume; program execution at that point independent of the compiled function; containing the stack map. LLVM emits stack map data into the object code within a designated; :ref:`stackmap-section`. This stack map data contains a record for; each stack map. The record stores the stack map's instruction address; and contains an entry for each mapped value. Each entry encodes a; value's location as a register, stack offset, or constant. A patch point is an instruction address at which space is reserved for; patching a new instruction sequence at run time. Patch points look; much like calls to LLVM. They take arguments that follow a calling; convention and may return a value. They also imply stack map; generation, which allows the runtime to locate the patchpoint and; find the location of ``live values`` at that point. Motivation; ==========. This functionality is currently experimental but is potentially useful; in a variety of settings, the most obvious being a runtime (JIT); compiler. Example applications of the patchpoint intrinsics are; implementing an inline call cache for polymorphic method dispatch or; optimizing the retrieval of properties in dynamically typed languages; such as JavaScript. The intrinsics documented here are currently used by the JavaScript; compiler within the open source WebKit pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:1116,Deployability,patch,patch,1116,"n this document we refer to the ""runtime"" collectively as all; components that serve as the LLVM client, including the LLVM IR; generator, object code consumer, and code patcher. A stack map records the location of ``live values`` at a particular; instruction address. These ``live values`` do not refer to all the; LLVM values live across the stack map. Instead, they are only the; values that the runtime requires to be live at this point. For; example, they may be the values the runtime will need to resume; program execution at that point independent of the compiled function; containing the stack map. LLVM emits stack map data into the object code within a designated; :ref:`stackmap-section`. This stack map data contains a record for; each stack map. The record stores the stack map's instruction address; and contains an entry for each mapped value. Each entry encodes a; value's location as a register, stack offset, or constant. A patch point is an instruction address at which space is reserved for; patching a new instruction sequence at run time. Patch points look; much like calls to LLVM. They take arguments that follow a calling; convention and may return a value. They also imply stack map; generation, which allows the runtime to locate the patchpoint and; find the location of ``live values`` at that point. Motivation; ==========. This functionality is currently experimental but is potentially useful; in a variety of settings, the most obvious being a runtime (JIT); compiler. Example applications of the patchpoint intrinsics are; implementing an inline call cache for polymorphic method dispatch or; optimizing the retrieval of properties in dynamically typed languages; such as JavaScript. The intrinsics documented here are currently used by the JavaScript; compiler within the open source WebKit project, see the `FTL JIT; <https://trac.webkit.org/wiki/FTLJIT>`_, but they are designed to be; used whenever stack maps or code patching are needed. Because the; intrinsics ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:1186,Deployability,patch,patching,1186,"n this document we refer to the ""runtime"" collectively as all; components that serve as the LLVM client, including the LLVM IR; generator, object code consumer, and code patcher. A stack map records the location of ``live values`` at a particular; instruction address. These ``live values`` do not refer to all the; LLVM values live across the stack map. Instead, they are only the; values that the runtime requires to be live at this point. For; example, they may be the values the runtime will need to resume; program execution at that point independent of the compiled function; containing the stack map. LLVM emits stack map data into the object code within a designated; :ref:`stackmap-section`. This stack map data contains a record for; each stack map. The record stores the stack map's instruction address; and contains an entry for each mapped value. Each entry encodes a; value's location as a register, stack offset, or constant. A patch point is an instruction address at which space is reserved for; patching a new instruction sequence at run time. Patch points look; much like calls to LLVM. They take arguments that follow a calling; convention and may return a value. They also imply stack map; generation, which allows the runtime to locate the patchpoint and; find the location of ``live values`` at that point. Motivation; ==========. This functionality is currently experimental but is potentially useful; in a variety of settings, the most obvious being a runtime (JIT); compiler. Example applications of the patchpoint intrinsics are; implementing an inline call cache for polymorphic method dispatch or; optimizing the retrieval of properties in dynamically typed languages; such as JavaScript. The intrinsics documented here are currently used by the JavaScript; compiler within the open source WebKit project, see the `FTL JIT; <https://trac.webkit.org/wiki/FTLJIT>`_, but they are designed to be; used whenever stack maps or code patching are needed. Because the; intrinsics ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:1435,Deployability,patch,patchpoint,1435,"ion address. These ``live values`` do not refer to all the; LLVM values live across the stack map. Instead, they are only the; values that the runtime requires to be live at this point. For; example, they may be the values the runtime will need to resume; program execution at that point independent of the compiled function; containing the stack map. LLVM emits stack map data into the object code within a designated; :ref:`stackmap-section`. This stack map data contains a record for; each stack map. The record stores the stack map's instruction address; and contains an entry for each mapped value. Each entry encodes a; value's location as a register, stack offset, or constant. A patch point is an instruction address at which space is reserved for; patching a new instruction sequence at run time. Patch points look; much like calls to LLVM. They take arguments that follow a calling; convention and may return a value. They also imply stack map; generation, which allows the runtime to locate the patchpoint and; find the location of ``live values`` at that point. Motivation; ==========. This functionality is currently experimental but is potentially useful; in a variety of settings, the most obvious being a runtime (JIT); compiler. Example applications of the patchpoint intrinsics are; implementing an inline call cache for polymorphic method dispatch or; optimizing the retrieval of properties in dynamically typed languages; such as JavaScript. The intrinsics documented here are currently used by the JavaScript; compiler within the open source WebKit project, see the `FTL JIT; <https://trac.webkit.org/wiki/FTLJIT>`_, but they are designed to be; used whenever stack maps or code patching are needed. Because the; intrinsics have experimental status, compatibility across LLVM; releases is not guaranteed. The stack map functionality described in this document is separate; from the functionality described in; :ref:`stack-map`. `GCFunctionMetadata` provides the location of; poin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:1703,Deployability,patch,patchpoint,1703,"LVM emits stack map data into the object code within a designated; :ref:`stackmap-section`. This stack map data contains a record for; each stack map. The record stores the stack map's instruction address; and contains an entry for each mapped value. Each entry encodes a; value's location as a register, stack offset, or constant. A patch point is an instruction address at which space is reserved for; patching a new instruction sequence at run time. Patch points look; much like calls to LLVM. They take arguments that follow a calling; convention and may return a value. They also imply stack map; generation, which allows the runtime to locate the patchpoint and; find the location of ``live values`` at that point. Motivation; ==========. This functionality is currently experimental but is potentially useful; in a variety of settings, the most obvious being a runtime (JIT); compiler. Example applications of the patchpoint intrinsics are; implementing an inline call cache for polymorphic method dispatch or; optimizing the retrieval of properties in dynamically typed languages; such as JavaScript. The intrinsics documented here are currently used by the JavaScript; compiler within the open source WebKit project, see the `FTL JIT; <https://trac.webkit.org/wiki/FTLJIT>`_, but they are designed to be; used whenever stack maps or code patching are needed. Because the; intrinsics have experimental status, compatibility across LLVM; releases is not guaranteed. The stack map functionality described in this document is separate; from the functionality described in; :ref:`stack-map`. `GCFunctionMetadata` provides the location of; pointers into a collected heap captured by the `GCRoot` intrinsic,; which can also be considered a ""stack map"". Unlike the stack maps; defined above, the `GCFunctionMetadata` stack map interface does not; provide a way to associate live register values of arbitrary type with; an instruction address, nor does it specify a format for the resulting; stack ma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:2129,Deployability,patch,patching,2129,"t, or constant. A patch point is an instruction address at which space is reserved for; patching a new instruction sequence at run time. Patch points look; much like calls to LLVM. They take arguments that follow a calling; convention and may return a value. They also imply stack map; generation, which allows the runtime to locate the patchpoint and; find the location of ``live values`` at that point. Motivation; ==========. This functionality is currently experimental but is potentially useful; in a variety of settings, the most obvious being a runtime (JIT); compiler. Example applications of the patchpoint intrinsics are; implementing an inline call cache for polymorphic method dispatch or; optimizing the retrieval of properties in dynamically typed languages; such as JavaScript. The intrinsics documented here are currently used by the JavaScript; compiler within the open source WebKit project, see the `FTL JIT; <https://trac.webkit.org/wiki/FTLJIT>`_, but they are designed to be; used whenever stack maps or code patching are needed. Because the; intrinsics have experimental status, compatibility across LLVM; releases is not guaranteed. The stack map functionality described in this document is separate; from the functionality described in; :ref:`stack-map`. `GCFunctionMetadata` provides the location of; pointers into a collected heap captured by the `GCRoot` intrinsic,; which can also be considered a ""stack map"". Unlike the stack maps; defined above, the `GCFunctionMetadata` stack map interface does not; provide a way to associate live register values of arbitrary type with; an instruction address, nor does it specify a format for the resulting; stack map. The stack maps described here could potentially provide; richer information to a garbage collecting runtime, but that usage; will not be discussed in this document. Intrinsics; ==========. The following two kinds of intrinsics can be used to implement stack; maps and patch points: ``llvm.experimental.stackmap`` ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:2227,Deployability,release,releases,2227,"instruction sequence at run time. Patch points look; much like calls to LLVM. They take arguments that follow a calling; convention and may return a value. They also imply stack map; generation, which allows the runtime to locate the patchpoint and; find the location of ``live values`` at that point. Motivation; ==========. This functionality is currently experimental but is potentially useful; in a variety of settings, the most obvious being a runtime (JIT); compiler. Example applications of the patchpoint intrinsics are; implementing an inline call cache for polymorphic method dispatch or; optimizing the retrieval of properties in dynamically typed languages; such as JavaScript. The intrinsics documented here are currently used by the JavaScript; compiler within the open source WebKit project, see the `FTL JIT; <https://trac.webkit.org/wiki/FTLJIT>`_, but they are designed to be; used whenever stack maps or code patching are needed. Because the; intrinsics have experimental status, compatibility across LLVM; releases is not guaranteed. The stack map functionality described in this document is separate; from the functionality described in; :ref:`stack-map`. `GCFunctionMetadata` provides the location of; pointers into a collected heap captured by the `GCRoot` intrinsic,; which can also be considered a ""stack map"". Unlike the stack maps; defined above, the `GCFunctionMetadata` stack map interface does not; provide a way to associate live register values of arbitrary type with; an instruction address, nor does it specify a format for the resulting; stack map. The stack maps described here could potentially provide; richer information to a garbage collecting runtime, but that usage; will not be discussed in this document. Intrinsics; ==========. The following two kinds of intrinsics can be used to implement stack; maps and patch points: ``llvm.experimental.stackmap`` and; ``llvm.experimental.patchpoint``. Both kinds of intrinsics generate a; stack map record, and they b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:3053,Deployability,patch,patch,3053,"T; <https://trac.webkit.org/wiki/FTLJIT>`_, but they are designed to be; used whenever stack maps or code patching are needed. Because the; intrinsics have experimental status, compatibility across LLVM; releases is not guaranteed. The stack map functionality described in this document is separate; from the functionality described in; :ref:`stack-map`. `GCFunctionMetadata` provides the location of; pointers into a collected heap captured by the `GCRoot` intrinsic,; which can also be considered a ""stack map"". Unlike the stack maps; defined above, the `GCFunctionMetadata` stack map interface does not; provide a way to associate live register values of arbitrary type with; an instruction address, nor does it specify a format for the resulting; stack map. The stack maps described here could potentially provide; richer information to a garbage collecting runtime, but that usage; will not be discussed in this document. Intrinsics; ==========. The following two kinds of intrinsics can be used to implement stack; maps and patch points: ``llvm.experimental.stackmap`` and; ``llvm.experimental.patchpoint``. Both kinds of intrinsics generate a; stack map record, and they both allow some form of code patching. They; can be used independently (i.e. ``llvm.experimental.patchpoint``; implicitly generates a stack map without the need for an additional; call to ``llvm.experimental.stackmap``). The choice of which to use; depends on whether it is necessary to reserve space for code patching; and whether any of the intrinsic arguments should be lowered according; to calling conventions. ``llvm.experimental.stackmap`` does not; reserve any space, nor does it expect any call arguments. If the; runtime patches code at the stack map's address, it will destructively; overwrite the program text. This is unlike; ``llvm.experimental.patchpoint``, which reserves space for in-place; patching without overwriting surrounding code. The; ``llvm.experimental.patchpoint`` intrinsic also lowers a specif",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:3123,Deployability,patch,patchpoint,3123,"patching are needed. Because the; intrinsics have experimental status, compatibility across LLVM; releases is not guaranteed. The stack map functionality described in this document is separate; from the functionality described in; :ref:`stack-map`. `GCFunctionMetadata` provides the location of; pointers into a collected heap captured by the `GCRoot` intrinsic,; which can also be considered a ""stack map"". Unlike the stack maps; defined above, the `GCFunctionMetadata` stack map interface does not; provide a way to associate live register values of arbitrary type with; an instruction address, nor does it specify a format for the resulting; stack map. The stack maps described here could potentially provide; richer information to a garbage collecting runtime, but that usage; will not be discussed in this document. Intrinsics; ==========. The following two kinds of intrinsics can be used to implement stack; maps and patch points: ``llvm.experimental.stackmap`` and; ``llvm.experimental.patchpoint``. Both kinds of intrinsics generate a; stack map record, and they both allow some form of code patching. They; can be used independently (i.e. ``llvm.experimental.patchpoint``; implicitly generates a stack map without the need for an additional; call to ``llvm.experimental.stackmap``). The choice of which to use; depends on whether it is necessary to reserve space for code patching; and whether any of the intrinsic arguments should be lowered according; to calling conventions. ``llvm.experimental.stackmap`` does not; reserve any space, nor does it expect any call arguments. If the; runtime patches code at the stack map's address, it will destructively; overwrite the program text. This is unlike; ``llvm.experimental.patchpoint``, which reserves space for in-place; patching without overwriting surrounding code. The; ``llvm.experimental.patchpoint`` intrinsic also lowers a specified; number of arguments according to its calling convention. This allows; patched code to make in-place f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:3230,Deployability,patch,patching,3230,"ntal status, compatibility across LLVM; releases is not guaranteed. The stack map functionality described in this document is separate; from the functionality described in; :ref:`stack-map`. `GCFunctionMetadata` provides the location of; pointers into a collected heap captured by the `GCRoot` intrinsic,; which can also be considered a ""stack map"". Unlike the stack maps; defined above, the `GCFunctionMetadata` stack map interface does not; provide a way to associate live register values of arbitrary type with; an instruction address, nor does it specify a format for the resulting; stack map. The stack maps described here could potentially provide; richer information to a garbage collecting runtime, but that usage; will not be discussed in this document. Intrinsics; ==========. The following two kinds of intrinsics can be used to implement stack; maps and patch points: ``llvm.experimental.stackmap`` and; ``llvm.experimental.patchpoint``. Both kinds of intrinsics generate a; stack map record, and they both allow some form of code patching. They; can be used independently (i.e. ``llvm.experimental.patchpoint``; implicitly generates a stack map without the need for an additional; call to ``llvm.experimental.stackmap``). The choice of which to use; depends on whether it is necessary to reserve space for code patching; and whether any of the intrinsic arguments should be lowered according; to calling conventions. ``llvm.experimental.stackmap`` does not; reserve any space, nor does it expect any call arguments. If the; runtime patches code at the stack map's address, it will destructively; overwrite the program text. This is unlike; ``llvm.experimental.patchpoint``, which reserves space for in-place; patching without overwriting surrounding code. The; ``llvm.experimental.patchpoint`` intrinsic also lowers a specified; number of arguments according to its calling convention. This allows; patched code to make in-place function calls without marshaling. Each instance of one of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:3298,Deployability,patch,patchpoint,3298,"escribed in; :ref:`stack-map`. `GCFunctionMetadata` provides the location of; pointers into a collected heap captured by the `GCRoot` intrinsic,; which can also be considered a ""stack map"". Unlike the stack maps; defined above, the `GCFunctionMetadata` stack map interface does not; provide a way to associate live register values of arbitrary type with; an instruction address, nor does it specify a format for the resulting; stack map. The stack maps described here could potentially provide; richer information to a garbage collecting runtime, but that usage; will not be discussed in this document. Intrinsics; ==========. The following two kinds of intrinsics can be used to implement stack; maps and patch points: ``llvm.experimental.stackmap`` and; ``llvm.experimental.patchpoint``. Both kinds of intrinsics generate a; stack map record, and they both allow some form of code patching. They; can be used independently (i.e. ``llvm.experimental.patchpoint``; implicitly generates a stack map without the need for an additional; call to ``llvm.experimental.stackmap``). The choice of which to use; depends on whether it is necessary to reserve space for code patching; and whether any of the intrinsic arguments should be lowered according; to calling conventions. ``llvm.experimental.stackmap`` does not; reserve any space, nor does it expect any call arguments. If the; runtime patches code at the stack map's address, it will destructively; overwrite the program text. This is unlike; ``llvm.experimental.patchpoint``, which reserves space for in-place; patching without overwriting surrounding code. The; ``llvm.experimental.patchpoint`` intrinsic also lowers a specified; number of arguments according to its calling convention. This allows; patched code to make in-place function calls without marshaling. Each instance of one of these intrinsics generates a stack map record; in the :ref:`stackmap-section`. The record includes an ID, allowing; the runtime to uniquely identify the stack ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:3511,Deployability,patch,patching,3511,"red a ""stack map"". Unlike the stack maps; defined above, the `GCFunctionMetadata` stack map interface does not; provide a way to associate live register values of arbitrary type with; an instruction address, nor does it specify a format for the resulting; stack map. The stack maps described here could potentially provide; richer information to a garbage collecting runtime, but that usage; will not be discussed in this document. Intrinsics; ==========. The following two kinds of intrinsics can be used to implement stack; maps and patch points: ``llvm.experimental.stackmap`` and; ``llvm.experimental.patchpoint``. Both kinds of intrinsics generate a; stack map record, and they both allow some form of code patching. They; can be used independently (i.e. ``llvm.experimental.patchpoint``; implicitly generates a stack map without the need for an additional; call to ``llvm.experimental.stackmap``). The choice of which to use; depends on whether it is necessary to reserve space for code patching; and whether any of the intrinsic arguments should be lowered according; to calling conventions. ``llvm.experimental.stackmap`` does not; reserve any space, nor does it expect any call arguments. If the; runtime patches code at the stack map's address, it will destructively; overwrite the program text. This is unlike; ``llvm.experimental.patchpoint``, which reserves space for in-place; patching without overwriting surrounding code. The; ``llvm.experimental.patchpoint`` intrinsic also lowers a specified; number of arguments according to its calling convention. This allows; patched code to make in-place function calls without marshaling. Each instance of one of these intrinsics generates a stack map record; in the :ref:`stackmap-section`. The record includes an ID, allowing; the runtime to uniquely identify the stack map, and the offset within; the code from the beginning of the enclosing function. '``llvm.experimental.stackmap``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. S",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:3732,Deployability,patch,patches,3732,"ing; stack map. The stack maps described here could potentially provide; richer information to a garbage collecting runtime, but that usage; will not be discussed in this document. Intrinsics; ==========. The following two kinds of intrinsics can be used to implement stack; maps and patch points: ``llvm.experimental.stackmap`` and; ``llvm.experimental.patchpoint``. Both kinds of intrinsics generate a; stack map record, and they both allow some form of code patching. They; can be used independently (i.e. ``llvm.experimental.patchpoint``; implicitly generates a stack map without the need for an additional; call to ``llvm.experimental.stackmap``). The choice of which to use; depends on whether it is necessary to reserve space for code patching; and whether any of the intrinsic arguments should be lowered according; to calling conventions. ``llvm.experimental.stackmap`` does not; reserve any space, nor does it expect any call arguments. If the; runtime patches code at the stack map's address, it will destructively; overwrite the program text. This is unlike; ``llvm.experimental.patchpoint``, which reserves space for in-place; patching without overwriting surrounding code. The; ``llvm.experimental.patchpoint`` intrinsic also lowers a specified; number of arguments according to its calling convention. This allows; patched code to make in-place function calls without marshaling. Each instance of one of these intrinsics generates a stack map record; in the :ref:`stackmap-section`. The record includes an ID, allowing; the runtime to uniquely identify the stack map, and the offset within; the code from the beginning of the enclosing function. '``llvm.experimental.stackmap``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.stackmap(i64 <id>, i32 <numShadowBytes>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.stackmap``' intrinsic records the location of; specified values in the stack map without generating an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:3860,Deployability,patch,patchpoint,3860,"e; will not be discussed in this document. Intrinsics; ==========. The following two kinds of intrinsics can be used to implement stack; maps and patch points: ``llvm.experimental.stackmap`` and; ``llvm.experimental.patchpoint``. Both kinds of intrinsics generate a; stack map record, and they both allow some form of code patching. They; can be used independently (i.e. ``llvm.experimental.patchpoint``; implicitly generates a stack map without the need for an additional; call to ``llvm.experimental.stackmap``). The choice of which to use; depends on whether it is necessary to reserve space for code patching; and whether any of the intrinsic arguments should be lowered according; to calling conventions. ``llvm.experimental.stackmap`` does not; reserve any space, nor does it expect any call arguments. If the; runtime patches code at the stack map's address, it will destructively; overwrite the program text. This is unlike; ``llvm.experimental.patchpoint``, which reserves space for in-place; patching without overwriting surrounding code. The; ``llvm.experimental.patchpoint`` intrinsic also lowers a specified; number of arguments according to its calling convention. This allows; patched code to make in-place function calls without marshaling. Each instance of one of these intrinsics generates a stack map record; in the :ref:`stackmap-section`. The record includes an ID, allowing; the runtime to uniquely identify the stack map, and the offset within; the code from the beginning of the enclosing function. '``llvm.experimental.stackmap``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.stackmap(i64 <id>, i32 <numShadowBytes>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.stackmap``' intrinsic records the location of; specified values in the stack map without generating any code. Operands:; """""""""""""""""". The first operand is an ID to be encoded within the stack map. The; second operand is the number of shadow by",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:3909,Deployability,patch,patching,3909,"e; will not be discussed in this document. Intrinsics; ==========. The following two kinds of intrinsics can be used to implement stack; maps and patch points: ``llvm.experimental.stackmap`` and; ``llvm.experimental.patchpoint``. Both kinds of intrinsics generate a; stack map record, and they both allow some form of code patching. They; can be used independently (i.e. ``llvm.experimental.patchpoint``; implicitly generates a stack map without the need for an additional; call to ``llvm.experimental.stackmap``). The choice of which to use; depends on whether it is necessary to reserve space for code patching; and whether any of the intrinsic arguments should be lowered according; to calling conventions. ``llvm.experimental.stackmap`` does not; reserve any space, nor does it expect any call arguments. If the; runtime patches code at the stack map's address, it will destructively; overwrite the program text. This is unlike; ``llvm.experimental.patchpoint``, which reserves space for in-place; patching without overwriting surrounding code. The; ``llvm.experimental.patchpoint`` intrinsic also lowers a specified; number of arguments according to its calling convention. This allows; patched code to make in-place function calls without marshaling. Each instance of one of these intrinsics generates a stack map record; in the :ref:`stackmap-section`. The record includes an ID, allowing; the runtime to uniquely identify the stack map, and the offset within; the code from the beginning of the enclosing function. '``llvm.experimental.stackmap``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.stackmap(i64 <id>, i32 <numShadowBytes>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.stackmap``' intrinsic records the location of; specified values in the stack map without generating any code. Operands:; """""""""""""""""". The first operand is an ID to be encoded within the stack map. The; second operand is the number of shadow by",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:3981,Deployability,patch,patchpoint,3981,"ent stack; maps and patch points: ``llvm.experimental.stackmap`` and; ``llvm.experimental.patchpoint``. Both kinds of intrinsics generate a; stack map record, and they both allow some form of code patching. They; can be used independently (i.e. ``llvm.experimental.patchpoint``; implicitly generates a stack map without the need for an additional; call to ``llvm.experimental.stackmap``). The choice of which to use; depends on whether it is necessary to reserve space for code patching; and whether any of the intrinsic arguments should be lowered according; to calling conventions. ``llvm.experimental.stackmap`` does not; reserve any space, nor does it expect any call arguments. If the; runtime patches code at the stack map's address, it will destructively; overwrite the program text. This is unlike; ``llvm.experimental.patchpoint``, which reserves space for in-place; patching without overwriting surrounding code. The; ``llvm.experimental.patchpoint`` intrinsic also lowers a specified; number of arguments according to its calling convention. This allows; patched code to make in-place function calls without marshaling. Each instance of one of these intrinsics generates a stack map record; in the :ref:`stackmap-section`. The record includes an ID, allowing; the runtime to uniquely identify the stack map, and the offset within; the code from the beginning of the enclosing function. '``llvm.experimental.stackmap``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.stackmap(i64 <id>, i32 <numShadowBytes>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.stackmap``' intrinsic records the location of; specified values in the stack map without generating any code. Operands:; """""""""""""""""". The first operand is an ID to be encoded within the stack map. The; second operand is the number of shadow bytes following the; intrinsic. The variable number of operands that follow are the ``live; values`` for which locations will b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:4099,Deployability,patch,patched,4099,"atchpoint``. Both kinds of intrinsics generate a; stack map record, and they both allow some form of code patching. They; can be used independently (i.e. ``llvm.experimental.patchpoint``; implicitly generates a stack map without the need for an additional; call to ``llvm.experimental.stackmap``). The choice of which to use; depends on whether it is necessary to reserve space for code patching; and whether any of the intrinsic arguments should be lowered according; to calling conventions. ``llvm.experimental.stackmap`` does not; reserve any space, nor does it expect any call arguments. If the; runtime patches code at the stack map's address, it will destructively; overwrite the program text. This is unlike; ``llvm.experimental.patchpoint``, which reserves space for in-place; patching without overwriting surrounding code. The; ``llvm.experimental.patchpoint`` intrinsic also lowers a specified; number of arguments according to its calling convention. This allows; patched code to make in-place function calls without marshaling. Each instance of one of these intrinsics generates a stack map record; in the :ref:`stackmap-section`. The record includes an ID, allowing; the runtime to uniquely identify the stack map, and the offset within; the code from the beginning of the enclosing function. '``llvm.experimental.stackmap``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.stackmap(i64 <id>, i32 <numShadowBytes>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.stackmap``' intrinsic records the location of; specified values in the stack map without generating any code. Operands:; """""""""""""""""". The first operand is an ID to be encoded within the stack map. The; second operand is the number of shadow bytes following the; intrinsic. The variable number of operands that follow are the ``live; values`` for which locations will be recorded in the stack map. To use this intrinsic as a bare-bones stack map, with no code ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:5124,Deployability,patch,patching,5124,"ace function calls without marshaling. Each instance of one of these intrinsics generates a stack map record; in the :ref:`stackmap-section`. The record includes an ID, allowing; the runtime to uniquely identify the stack map, and the offset within; the code from the beginning of the enclosing function. '``llvm.experimental.stackmap``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.stackmap(i64 <id>, i32 <numShadowBytes>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.stackmap``' intrinsic records the location of; specified values in the stack map without generating any code. Operands:; """""""""""""""""". The first operand is an ID to be encoded within the stack map. The; second operand is the number of shadow bytes following the; intrinsic. The variable number of operands that follow are the ``live; values`` for which locations will be recorded in the stack map. To use this intrinsic as a bare-bones stack map, with no code patching; support, the number of shadow bytes can be set to zero. Semantics:; """""""""""""""""""". The stack map intrinsic generates no code in place, unless nops are; needed to cover its shadow (see below). However, its offset from; function entry is stored in the stack map. This is the relative; instruction address immediately following the instructions that; precede the stack map. The stack map ID allows a runtime to locate the desired stack map; record. LLVM passes this ID through directly to the stack map; record without checking uniqueness. LLVM guarantees a shadow of instructions following the stack map's; instruction offset during which neither the end of the basic block nor; another call to ``llvm.experimental.stackmap`` or; ``llvm.experimental.patchpoint`` may occur. This allows the runtime to; patch the code at this point in response to an event triggered from; outside the code. The code for instructions following the stack map; may be emitted in the stack map's shadow, and these inst",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:5879,Deployability,patch,patchpoint,5879,"umber of shadow bytes following the; intrinsic. The variable number of operands that follow are the ``live; values`` for which locations will be recorded in the stack map. To use this intrinsic as a bare-bones stack map, with no code patching; support, the number of shadow bytes can be set to zero. Semantics:; """""""""""""""""""". The stack map intrinsic generates no code in place, unless nops are; needed to cover its shadow (see below). However, its offset from; function entry is stored in the stack map. This is the relative; instruction address immediately following the instructions that; precede the stack map. The stack map ID allows a runtime to locate the desired stack map; record. LLVM passes this ID through directly to the stack map; record without checking uniqueness. LLVM guarantees a shadow of instructions following the stack map's; instruction offset during which neither the end of the basic block nor; another call to ``llvm.experimental.stackmap`` or; ``llvm.experimental.patchpoint`` may occur. This allows the runtime to; patch the code at this point in response to an event triggered from; outside the code. The code for instructions following the stack map; may be emitted in the stack map's shadow, and these instructions may; be overwritten by destructive patching. Without shadow bytes, this; destructive patching could overwrite program text or data outside the; current function. We disallow overlapping stack map shadows so that; the runtime does not need to consider this corner case. For example, a stack map with 8 byte shadow:. .. code-block:: llvm. call void @runtime(); call void (i64, i32, ...) @llvm.experimental.stackmap(i64 77, i32 8,; ptr %ptr); %val = load i64, ptr %ptr; %add = add i64 %val, 3; ret i64 %add. May require one byte of nop-padding:. .. code-block:: none. 0x00 callq _runtime; 0x05 nop <--- stack map address; 0x06 movq (%rdi), %rax; 0x07 addq $3, %rax; 0x0a popq %rdx; 0x0b ret <---- end of 8-byte shadow. Now, if the runtime needs to invalidate t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:5931,Deployability,patch,patch,5931,"f operands that follow are the ``live; values`` for which locations will be recorded in the stack map. To use this intrinsic as a bare-bones stack map, with no code patching; support, the number of shadow bytes can be set to zero. Semantics:; """""""""""""""""""". The stack map intrinsic generates no code in place, unless nops are; needed to cover its shadow (see below). However, its offset from; function entry is stored in the stack map. This is the relative; instruction address immediately following the instructions that; precede the stack map. The stack map ID allows a runtime to locate the desired stack map; record. LLVM passes this ID through directly to the stack map; record without checking uniqueness. LLVM guarantees a shadow of instructions following the stack map's; instruction offset during which neither the end of the basic block nor; another call to ``llvm.experimental.stackmap`` or; ``llvm.experimental.patchpoint`` may occur. This allows the runtime to; patch the code at this point in response to an event triggered from; outside the code. The code for instructions following the stack map; may be emitted in the stack map's shadow, and these instructions may; be overwritten by destructive patching. Without shadow bytes, this; destructive patching could overwrite program text or data outside the; current function. We disallow overlapping stack map shadows so that; the runtime does not need to consider this corner case. For example, a stack map with 8 byte shadow:. .. code-block:: llvm. call void @runtime(); call void (i64, i32, ...) @llvm.experimental.stackmap(i64 77, i32 8,; ptr %ptr); %val = load i64, ptr %ptr; %add = add i64 %val, 3; ret i64 %add. May require one byte of nop-padding:. .. code-block:: none. 0x00 callq _runtime; 0x05 nop <--- stack map address; 0x06 movq (%rdi), %rax; 0x07 addq $3, %rax; 0x0a popq %rdx; 0x0b ret <---- end of 8-byte shadow. Now, if the runtime needs to invalidate the compiled code, it may; patch 8 bytes of code at the stack map's ad",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:6169,Deployability,patch,patching,6169,"es stack map, with no code patching; support, the number of shadow bytes can be set to zero. Semantics:; """""""""""""""""""". The stack map intrinsic generates no code in place, unless nops are; needed to cover its shadow (see below). However, its offset from; function entry is stored in the stack map. This is the relative; instruction address immediately following the instructions that; precede the stack map. The stack map ID allows a runtime to locate the desired stack map; record. LLVM passes this ID through directly to the stack map; record without checking uniqueness. LLVM guarantees a shadow of instructions following the stack map's; instruction offset during which neither the end of the basic block nor; another call to ``llvm.experimental.stackmap`` or; ``llvm.experimental.patchpoint`` may occur. This allows the runtime to; patch the code at this point in response to an event triggered from; outside the code. The code for instructions following the stack map; may be emitted in the stack map's shadow, and these instructions may; be overwritten by destructive patching. Without shadow bytes, this; destructive patching could overwrite program text or data outside the; current function. We disallow overlapping stack map shadows so that; the runtime does not need to consider this corner case. For example, a stack map with 8 byte shadow:. .. code-block:: llvm. call void @runtime(); call void (i64, i32, ...) @llvm.experimental.stackmap(i64 77, i32 8,; ptr %ptr); %val = load i64, ptr %ptr; %add = add i64 %val, 3; ret i64 %add. May require one byte of nop-padding:. .. code-block:: none. 0x00 callq _runtime; 0x05 nop <--- stack map address; 0x06 movq (%rdi), %rax; 0x07 addq $3, %rax; 0x0a popq %rdx; 0x0b ret <---- end of 8-byte shadow. Now, if the runtime needs to invalidate the compiled code, it may; patch 8 bytes of code at the stack map's address at follows:. .. code-block:: none. 0x00 callq _runtime; 0x05 movl $0xffff, %rax <--- patched code at stack map address; 0x0a callq *",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:6219,Deployability,patch,patching,6219,"c generates no code in place, unless nops are; needed to cover its shadow (see below). However, its offset from; function entry is stored in the stack map. This is the relative; instruction address immediately following the instructions that; precede the stack map. The stack map ID allows a runtime to locate the desired stack map; record. LLVM passes this ID through directly to the stack map; record without checking uniqueness. LLVM guarantees a shadow of instructions following the stack map's; instruction offset during which neither the end of the basic block nor; another call to ``llvm.experimental.stackmap`` or; ``llvm.experimental.patchpoint`` may occur. This allows the runtime to; patch the code at this point in response to an event triggered from; outside the code. The code for instructions following the stack map; may be emitted in the stack map's shadow, and these instructions may; be overwritten by destructive patching. Without shadow bytes, this; destructive patching could overwrite program text or data outside the; current function. We disallow overlapping stack map shadows so that; the runtime does not need to consider this corner case. For example, a stack map with 8 byte shadow:. .. code-block:: llvm. call void @runtime(); call void (i64, i32, ...) @llvm.experimental.stackmap(i64 77, i32 8,; ptr %ptr); %val = load i64, ptr %ptr; %add = add i64 %val, 3; ret i64 %add. May require one byte of nop-padding:. .. code-block:: none. 0x00 callq _runtime; 0x05 nop <--- stack map address; 0x06 movq (%rdi), %rax; 0x07 addq $3, %rax; 0x0a popq %rdx; 0x0b ret <---- end of 8-byte shadow. Now, if the runtime needs to invalidate the compiled code, it may; patch 8 bytes of code at the stack map's address at follows:. .. code-block:: none. 0x00 callq _runtime; 0x05 movl $0xffff, %rax <--- patched code at stack map address; 0x0a callq *%rax <---- end of 8-byte shadow. This way, after the normal call to the runtime returns, the code will; execute a patched call to a special",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:6917,Deployability,patch,patch,6917,"s the runtime to; patch the code at this point in response to an event triggered from; outside the code. The code for instructions following the stack map; may be emitted in the stack map's shadow, and these instructions may; be overwritten by destructive patching. Without shadow bytes, this; destructive patching could overwrite program text or data outside the; current function. We disallow overlapping stack map shadows so that; the runtime does not need to consider this corner case. For example, a stack map with 8 byte shadow:. .. code-block:: llvm. call void @runtime(); call void (i64, i32, ...) @llvm.experimental.stackmap(i64 77, i32 8,; ptr %ptr); %val = load i64, ptr %ptr; %add = add i64 %val, 3; ret i64 %add. May require one byte of nop-padding:. .. code-block:: none. 0x00 callq _runtime; 0x05 nop <--- stack map address; 0x06 movq (%rdi), %rax; 0x07 addq $3, %rax; 0x0a popq %rdx; 0x0b ret <---- end of 8-byte shadow. Now, if the runtime needs to invalidate the compiled code, it may; patch 8 bytes of code at the stack map's address at follows:. .. code-block:: none. 0x00 callq _runtime; 0x05 movl $0xffff, %rax <--- patched code at stack map address; 0x0a callq *%rax <---- end of 8-byte shadow. This way, after the normal call to the runtime returns, the code will; execute a patched call to a special entry point that can rebuild a; stack frame from the values located by the stack map. '``llvm.experimental.patchpoint.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.patchpoint.void(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...); declare i64; @llvm.experimental.patchpoint.i64(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.patchpoint.*``' intrinsics creates a function; call to the specified ``<target>`` and records the location of specified; values in the stack map. Operands:; """""""""""""""""". The first operand is an ID, the secon",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:7051,Deployability,patch,patched,7051,"ap; may be emitted in the stack map's shadow, and these instructions may; be overwritten by destructive patching. Without shadow bytes, this; destructive patching could overwrite program text or data outside the; current function. We disallow overlapping stack map shadows so that; the runtime does not need to consider this corner case. For example, a stack map with 8 byte shadow:. .. code-block:: llvm. call void @runtime(); call void (i64, i32, ...) @llvm.experimental.stackmap(i64 77, i32 8,; ptr %ptr); %val = load i64, ptr %ptr; %add = add i64 %val, 3; ret i64 %add. May require one byte of nop-padding:. .. code-block:: none. 0x00 callq _runtime; 0x05 nop <--- stack map address; 0x06 movq (%rdi), %rax; 0x07 addq $3, %rax; 0x0a popq %rdx; 0x0b ret <---- end of 8-byte shadow. Now, if the runtime needs to invalidate the compiled code, it may; patch 8 bytes of code at the stack map's address at follows:. .. code-block:: none. 0x00 callq _runtime; 0x05 movl $0xffff, %rax <--- patched code at stack map address; 0x0a callq *%rax <---- end of 8-byte shadow. This way, after the normal call to the runtime returns, the code will; execute a patched call to a special entry point that can rebuild a; stack frame from the values located by the stack map. '``llvm.experimental.patchpoint.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.patchpoint.void(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...); declare i64; @llvm.experimental.patchpoint.i64(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.patchpoint.*``' intrinsics creates a function; call to the specified ``<target>`` and records the location of specified; values in the stack map. Operands:; """""""""""""""""". The first operand is an ID, the second operand is the number of bytes; reserved for the patchable region, the third operand is the target; address of a function (optionally null), and the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:7212,Deployability,patch,patched,7212,"g could overwrite program text or data outside the; current function. We disallow overlapping stack map shadows so that; the runtime does not need to consider this corner case. For example, a stack map with 8 byte shadow:. .. code-block:: llvm. call void @runtime(); call void (i64, i32, ...) @llvm.experimental.stackmap(i64 77, i32 8,; ptr %ptr); %val = load i64, ptr %ptr; %add = add i64 %val, 3; ret i64 %add. May require one byte of nop-padding:. .. code-block:: none. 0x00 callq _runtime; 0x05 nop <--- stack map address; 0x06 movq (%rdi), %rax; 0x07 addq $3, %rax; 0x0a popq %rdx; 0x0b ret <---- end of 8-byte shadow. Now, if the runtime needs to invalidate the compiled code, it may; patch 8 bytes of code at the stack map's address at follows:. .. code-block:: none. 0x00 callq _runtime; 0x05 movl $0xffff, %rax <--- patched code at stack map address; 0x0a callq *%rax <---- end of 8-byte shadow. This way, after the normal call to the runtime returns, the code will; execute a patched call to a special entry point that can rebuild a; stack frame from the values located by the stack map. '``llvm.experimental.patchpoint.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.patchpoint.void(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...); declare i64; @llvm.experimental.patchpoint.i64(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.patchpoint.*``' intrinsics creates a function; call to the specified ``<target>`` and records the location of specified; values in the stack map. Operands:; """""""""""""""""". The first operand is an ID, the second operand is the number of bytes; reserved for the patchable region, the third operand is the target; address of a function (optionally null), and the fourth operand; specifies how many of the following variable operands are considered; function call arguments. The remaining variable number of operands are; the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:7345,Deployability,patch,patchpoint,7345," runtime does not need to consider this corner case. For example, a stack map with 8 byte shadow:. .. code-block:: llvm. call void @runtime(); call void (i64, i32, ...) @llvm.experimental.stackmap(i64 77, i32 8,; ptr %ptr); %val = load i64, ptr %ptr; %add = add i64 %val, 3; ret i64 %add. May require one byte of nop-padding:. .. code-block:: none. 0x00 callq _runtime; 0x05 nop <--- stack map address; 0x06 movq (%rdi), %rax; 0x07 addq $3, %rax; 0x0a popq %rdx; 0x0b ret <---- end of 8-byte shadow. Now, if the runtime needs to invalidate the compiled code, it may; patch 8 bytes of code at the stack map's address at follows:. .. code-block:: none. 0x00 callq _runtime; 0x05 movl $0xffff, %rax <--- patched code at stack map address; 0x0a callq *%rax <---- end of 8-byte shadow. This way, after the normal call to the runtime returns, the code will; execute a patched call to a special entry point that can rebuild a; stack frame from the values located by the stack map. '``llvm.experimental.patchpoint.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.patchpoint.void(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...); declare i64; @llvm.experimental.patchpoint.i64(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.patchpoint.*``' intrinsics creates a function; call to the specified ``<target>`` and records the location of specified; values in the stack map. Operands:; """""""""""""""""". The first operand is an ID, the second operand is the number of bytes; reserved for the patchable region, the third operand is the target; address of a function (optionally null), and the fourth operand; specifies how many of the following variable operands are considered; function call arguments. The remaining variable number of operands are; the ``live values`` for which locations will be recorded in the stack; map. Semantics:; """""""""""""""""""". The patch point intrinsic ge",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:7475,Deployability,patch,patchpoint,7475," @runtime(); call void (i64, i32, ...) @llvm.experimental.stackmap(i64 77, i32 8,; ptr %ptr); %val = load i64, ptr %ptr; %add = add i64 %val, 3; ret i64 %add. May require one byte of nop-padding:. .. code-block:: none. 0x00 callq _runtime; 0x05 nop <--- stack map address; 0x06 movq (%rdi), %rax; 0x07 addq $3, %rax; 0x0a popq %rdx; 0x0b ret <---- end of 8-byte shadow. Now, if the runtime needs to invalidate the compiled code, it may; patch 8 bytes of code at the stack map's address at follows:. .. code-block:: none. 0x00 callq _runtime; 0x05 movl $0xffff, %rax <--- patched code at stack map address; 0x0a callq *%rax <---- end of 8-byte shadow. This way, after the normal call to the runtime returns, the code will; execute a patched call to a special entry point that can rebuild a; stack frame from the values located by the stack map. '``llvm.experimental.patchpoint.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.patchpoint.void(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...); declare i64; @llvm.experimental.patchpoint.i64(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.patchpoint.*``' intrinsics creates a function; call to the specified ``<target>`` and records the location of specified; values in the stack map. Operands:; """""""""""""""""". The first operand is an ID, the second operand is the number of bytes; reserved for the patchable region, the third operand is the target; address of a function (optionally null), and the fourth operand; specifies how many of the following variable operands are considered; function call arguments. The remaining variable number of operands are; the ``live values`` for which locations will be recorded in the stack; map. Semantics:; """""""""""""""""""". The patch point intrinsic generates a stack map. It also emits a; function call to the address specified by ``<target>`` if the address; is not a constant nul",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:7585,Deployability,patch,patchpoint,7585," ptr %ptr; %add = add i64 %val, 3; ret i64 %add. May require one byte of nop-padding:. .. code-block:: none. 0x00 callq _runtime; 0x05 nop <--- stack map address; 0x06 movq (%rdi), %rax; 0x07 addq $3, %rax; 0x0a popq %rdx; 0x0b ret <---- end of 8-byte shadow. Now, if the runtime needs to invalidate the compiled code, it may; patch 8 bytes of code at the stack map's address at follows:. .. code-block:: none. 0x00 callq _runtime; 0x05 movl $0xffff, %rax <--- patched code at stack map address; 0x0a callq *%rax <---- end of 8-byte shadow. This way, after the normal call to the runtime returns, the code will; execute a patched call to a special entry point that can rebuild a; stack frame from the values located by the stack map. '``llvm.experimental.patchpoint.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.patchpoint.void(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...); declare i64; @llvm.experimental.patchpoint.i64(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.patchpoint.*``' intrinsics creates a function; call to the specified ``<target>`` and records the location of specified; values in the stack map. Operands:; """""""""""""""""". The first operand is an ID, the second operand is the number of bytes; reserved for the patchable region, the third operand is the target; address of a function (optionally null), and the fourth operand; specifies how many of the following variable operands are considered; function call arguments. The remaining variable number of operands are; the ``live values`` for which locations will be recorded in the stack; map. Semantics:; """""""""""""""""""". The patch point intrinsic generates a stack map. It also emits a; function call to the address specified by ``<target>`` if the address; is not a constant null. The function call and its arguments are; lowered according to the calling convention specified at the; intr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:7709,Deployability,patch,patchpoint,7709,"time; 0x05 nop <--- stack map address; 0x06 movq (%rdi), %rax; 0x07 addq $3, %rax; 0x0a popq %rdx; 0x0b ret <---- end of 8-byte shadow. Now, if the runtime needs to invalidate the compiled code, it may; patch 8 bytes of code at the stack map's address at follows:. .. code-block:: none. 0x00 callq _runtime; 0x05 movl $0xffff, %rax <--- patched code at stack map address; 0x0a callq *%rax <---- end of 8-byte shadow. This way, after the normal call to the runtime returns, the code will; execute a patched call to a special entry point that can rebuild a; stack frame from the values located by the stack map. '``llvm.experimental.patchpoint.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.patchpoint.void(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...); declare i64; @llvm.experimental.patchpoint.i64(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.patchpoint.*``' intrinsics creates a function; call to the specified ``<target>`` and records the location of specified; values in the stack map. Operands:; """""""""""""""""". The first operand is an ID, the second operand is the number of bytes; reserved for the patchable region, the third operand is the target; address of a function (optionally null), and the fourth operand; specifies how many of the following variable operands are considered; function call arguments. The remaining variable number of operands are; the ``live values`` for which locations will be recorded in the stack; map. Semantics:; """""""""""""""""""". The patch point intrinsic generates a stack map. It also emits a; function call to the address specified by ``<target>`` if the address; is not a constant null. The function call and its arguments are; lowered according to the calling convention specified at the; intrinsic's callsite. Variants of the intrinsic with non-void return; type also return a value according to calling convention. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:7965,Deployability,patch,patchable,7965,"5 movl $0xffff, %rax <--- patched code at stack map address; 0x0a callq *%rax <---- end of 8-byte shadow. This way, after the normal call to the runtime returns, the code will; execute a patched call to a special entry point that can rebuild a; stack frame from the values located by the stack map. '``llvm.experimental.patchpoint.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.patchpoint.void(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...); declare i64; @llvm.experimental.patchpoint.i64(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.patchpoint.*``' intrinsics creates a function; call to the specified ``<target>`` and records the location of specified; values in the stack map. Operands:; """""""""""""""""". The first operand is an ID, the second operand is the number of bytes; reserved for the patchable region, the third operand is the target; address of a function (optionally null), and the fourth operand; specifies how many of the following variable operands are considered; function call arguments. The remaining variable number of operands are; the ``live values`` for which locations will be recorded in the stack; map. Semantics:; """""""""""""""""""". The patch point intrinsic generates a stack map. It also emits a; function call to the address specified by ``<target>`` if the address; is not a constant null. The function call and its arguments are; lowered according to the calling convention specified at the; intrinsic's callsite. Variants of the intrinsic with non-void return; type also return a value according to calling convention. On PowerPC, note that ``<target>`` must be the ABI function pointer for the; intended target of the indirect call. Specifically, when compiling for the; ELF V1 ABI, ``<target>`` is the function-descriptor address normally used as; the C/C++ function-pointer representation. Requesting zero patch point arguments",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:8327,Deployability,patch,patch,8327,"atchpoint.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.patchpoint.void(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...); declare i64; @llvm.experimental.patchpoint.i64(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.patchpoint.*``' intrinsics creates a function; call to the specified ``<target>`` and records the location of specified; values in the stack map. Operands:; """""""""""""""""". The first operand is an ID, the second operand is the number of bytes; reserved for the patchable region, the third operand is the target; address of a function (optionally null), and the fourth operand; specifies how many of the following variable operands are considered; function call arguments. The remaining variable number of operands are; the ``live values`` for which locations will be recorded in the stack; map. Semantics:; """""""""""""""""""". The patch point intrinsic generates a stack map. It also emits a; function call to the address specified by ``<target>`` if the address; is not a constant null. The function call and its arguments are; lowered according to the calling convention specified at the; intrinsic's callsite. Variants of the intrinsic with non-void return; type also return a value according to calling convention. On PowerPC, note that ``<target>`` must be the ABI function pointer for the; intended target of the indirect call. Specifically, when compiling for the; ELF V1 ABI, ``<target>`` is the function-descriptor address normally used as; the C/C++ function-pointer representation. Requesting zero patch point arguments is valid. In this case, all; variable operands are handled just like; ``llvm.experimental.stackmap.*``. The difference is that space will; still be reserved for patching, a call will be emitted, and a return; value is allowed. The location of the arguments are not normally recorded in the stack; map because they are al",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:9005,Deployability,patch,patch,9005,"et; address of a function (optionally null), and the fourth operand; specifies how many of the following variable operands are considered; function call arguments. The remaining variable number of operands are; the ``live values`` for which locations will be recorded in the stack; map. Semantics:; """""""""""""""""""". The patch point intrinsic generates a stack map. It also emits a; function call to the address specified by ``<target>`` if the address; is not a constant null. The function call and its arguments are; lowered according to the calling convention specified at the; intrinsic's callsite. Variants of the intrinsic with non-void return; type also return a value according to calling convention. On PowerPC, note that ``<target>`` must be the ABI function pointer for the; intended target of the indirect call. Specifically, when compiling for the; ELF V1 ABI, ``<target>`` is the function-descriptor address normally used as; the C/C++ function-pointer representation. Requesting zero patch point arguments is valid. In this case, all; variable operands are handled just like; ``llvm.experimental.stackmap.*``. The difference is that space will; still be reserved for patching, a call will be emitted, and a return; value is allowed. The location of the arguments are not normally recorded in the stack; map because they are already fixed by the calling convention. The; remaining ``live values`` will have their location recorded, which; could be a register, stack location, or constant. A special calling; convention has been introduced for use with stack maps, anyregcc,; which forces the arguments to be loaded into registers but allows; those register to be dynamically allocated. These argument registers; will have their register locations recorded in the stack map in; addition to the remaining ``live values``. The patch point also emits nops to cover at least ``<numBytes>`` of; instruction encoding space. Hence, the client must ensure that; ``<numBytes>`` is enough to encode a ca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:9188,Deployability,patch,patching,9188,"ariable number of operands are; the ``live values`` for which locations will be recorded in the stack; map. Semantics:; """""""""""""""""""". The patch point intrinsic generates a stack map. It also emits a; function call to the address specified by ``<target>`` if the address; is not a constant null. The function call and its arguments are; lowered according to the calling convention specified at the; intrinsic's callsite. Variants of the intrinsic with non-void return; type also return a value according to calling convention. On PowerPC, note that ``<target>`` must be the ABI function pointer for the; intended target of the indirect call. Specifically, when compiling for the; ELF V1 ABI, ``<target>`` is the function-descriptor address normally used as; the C/C++ function-pointer representation. Requesting zero patch point arguments is valid. In this case, all; variable operands are handled just like; ``llvm.experimental.stackmap.*``. The difference is that space will; still be reserved for patching, a call will be emitted, and a return; value is allowed. The location of the arguments are not normally recorded in the stack; map because they are already fixed by the calling convention. The; remaining ``live values`` will have their location recorded, which; could be a register, stack location, or constant. A special calling; convention has been introduced for use with stack maps, anyregcc,; which forces the arguments to be loaded into registers but allows; those register to be dynamically allocated. These argument registers; will have their register locations recorded in the stack map in; addition to the remaining ``live values``. The patch point also emits nops to cover at least ``<numBytes>`` of; instruction encoding space. Hence, the client must ensure that; ``<numBytes>`` is enough to encode a call to the target address on the; supported targets. If the call target is constant null, then there is; no minimum requirement. A zero-byte null target patchpoint is; valid. The ru",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:9844,Deployability,patch,patch,9844,"et>`` is the function-descriptor address normally used as; the C/C++ function-pointer representation. Requesting zero patch point arguments is valid. In this case, all; variable operands are handled just like; ``llvm.experimental.stackmap.*``. The difference is that space will; still be reserved for patching, a call will be emitted, and a return; value is allowed. The location of the arguments are not normally recorded in the stack; map because they are already fixed by the calling convention. The; remaining ``live values`` will have their location recorded, which; could be a register, stack location, or constant. A special calling; convention has been introduced for use with stack maps, anyregcc,; which forces the arguments to be loaded into registers but allows; those register to be dynamically allocated. These argument registers; will have their register locations recorded in the stack map in; addition to the remaining ``live values``. The patch point also emits nops to cover at least ``<numBytes>`` of; instruction encoding space. Hence, the client must ensure that; ``<numBytes>`` is enough to encode a call to the target address on the; supported targets. If the call target is constant null, then there is; no minimum requirement. A zero-byte null target patchpoint is; valid. The runtime may patch the code emitted for the patch point, including; the call sequence and nops. However, the runtime may not assume; anything about the code LLVM emits within the reserved space. Partial; patching is not allowed. The runtime must patch all reserved bytes,; padding with nops if necessary. This example shows a patch point reserving 15 bytes, with one argument; in $rdi, and a return value in $rax per native calling convention:. .. code-block:: llvm. %target = inttoptr i64 -281474976710654 to ptr; %val = call i64 (i64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:10164,Deployability,patch,patchpoint,10164,"ll; still be reserved for patching, a call will be emitted, and a return; value is allowed. The location of the arguments are not normally recorded in the stack; map because they are already fixed by the calling convention. The; remaining ``live values`` will have their location recorded, which; could be a register, stack location, or constant. A special calling; convention has been introduced for use with stack maps, anyregcc,; which forces the arguments to be loaded into registers but allows; those register to be dynamically allocated. These argument registers; will have their register locations recorded in the stack map in; addition to the remaining ``live values``. The patch point also emits nops to cover at least ``<numBytes>`` of; instruction encoding space. Hence, the client must ensure that; ``<numBytes>`` is enough to encode a call to the target address on the; supported targets. If the call target is constant null, then there is; no minimum requirement. A zero-byte null target patchpoint is; valid. The runtime may patch the code emitted for the patch point, including; the call sequence and nops. However, the runtime may not assume; anything about the code LLVM emits within the reserved space. Partial; patching is not allowed. The runtime must patch all reserved bytes,; padding with nops if necessary. This example shows a patch point reserving 15 bytes, with one argument; in $rdi, and a return value in $rax per native calling convention:. .. code-block:: llvm. %target = inttoptr i64 -281474976710654 to ptr; %val = call i64 (i64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does no",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:10202,Deployability,patch,patch,10202,"; value is allowed. The location of the arguments are not normally recorded in the stack; map because they are already fixed by the calling convention. The; remaining ``live values`` will have their location recorded, which; could be a register, stack location, or constant. A special calling; convention has been introduced for use with stack maps, anyregcc,; which forces the arguments to be loaded into registers but allows; those register to be dynamically allocated. These argument registers; will have their register locations recorded in the stack map in; addition to the remaining ``live values``. The patch point also emits nops to cover at least ``<numBytes>`` of; instruction encoding space. Hence, the client must ensure that; ``<numBytes>`` is enough to encode a call to the target address on the; supported targets. If the call target is constant null, then there is; no minimum requirement. A zero-byte null target patchpoint is; valid. The runtime may patch the code emitted for the patch point, including; the call sequence and nops. However, the runtime may not assume; anything about the code LLVM emits within the reserved space. Partial; patching is not allowed. The runtime must patch all reserved bytes,; padding with nops if necessary. This example shows a patch point reserving 15 bytes, with one argument; in $rdi, and a return value in $rax per native calling convention:. .. code-block:: llvm. %target = inttoptr i64 -281474976710654 to ptr; %val = call i64 (i64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:10233,Deployability,patch,patch,10233,"; value is allowed. The location of the arguments are not normally recorded in the stack; map because they are already fixed by the calling convention. The; remaining ``live values`` will have their location recorded, which; could be a register, stack location, or constant. A special calling; convention has been introduced for use with stack maps, anyregcc,; which forces the arguments to be loaded into registers but allows; those register to be dynamically allocated. These argument registers; will have their register locations recorded in the stack map in; addition to the remaining ``live values``. The patch point also emits nops to cover at least ``<numBytes>`` of; instruction encoding space. Hence, the client must ensure that; ``<numBytes>`` is enough to encode a call to the target address on the; supported targets. If the call target is constant null, then there is; no minimum requirement. A zero-byte null target patchpoint is; valid. The runtime may patch the code emitted for the patch point, including; the call sequence and nops. However, the runtime may not assume; anything about the code LLVM emits within the reserved space. Partial; patching is not allowed. The runtime must patch all reserved bytes,; padding with nops if necessary. This example shows a patch point reserving 15 bytes, with one argument; in $rdi, and a return value in $rax per native calling convention:. .. code-block:: llvm. %target = inttoptr i64 -281474976710654 to ptr; %val = call i64 (i64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:10393,Deployability,patch,patching,10393," ``live values`` will have their location recorded, which; could be a register, stack location, or constant. A special calling; convention has been introduced for use with stack maps, anyregcc,; which forces the arguments to be loaded into registers but allows; those register to be dynamically allocated. These argument registers; will have their register locations recorded in the stack map in; addition to the remaining ``live values``. The patch point also emits nops to cover at least ``<numBytes>`` of; instruction encoding space. Hence, the client must ensure that; ``<numBytes>`` is enough to encode a call to the target address on the; supported targets. If the call target is constant null, then there is; no minimum requirement. A zero-byte null target patchpoint is; valid. The runtime may patch the code emitted for the patch point, including; the call sequence and nops. However, the runtime may not assume; anything about the code LLVM emits within the reserved space. Partial; patching is not allowed. The runtime must patch all reserved bytes,; padding with nops if necessary. This example shows a patch point reserving 15 bytes, with one argument; in $rdi, and a return value in $rax per native calling convention:. .. code-block:: llvm. %target = inttoptr i64 -281474976710654 to ptr; %val = call i64 (i64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then the ``anyregcc`` convention may be used:. .. code-block:: none. %val = call anyregcc @llvm.experimental.patchpoint(i64 78, i32 15,; ptr %target, i32 1,; ptr %ptr). The",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:10435,Deployability,patch,patch,10435,"ch; could be a register, stack location, or constant. A special calling; convention has been introduced for use with stack maps, anyregcc,; which forces the arguments to be loaded into registers but allows; those register to be dynamically allocated. These argument registers; will have their register locations recorded in the stack map in; addition to the remaining ``live values``. The patch point also emits nops to cover at least ``<numBytes>`` of; instruction encoding space. Hence, the client must ensure that; ``<numBytes>`` is enough to encode a call to the target address on the; supported targets. If the call target is constant null, then there is; no minimum requirement. A zero-byte null target patchpoint is; valid. The runtime may patch the code emitted for the patch point, including; the call sequence and nops. However, the runtime may not assume; anything about the code LLVM emits within the reserved space. Partial; patching is not allowed. The runtime must patch all reserved bytes,; padding with nops if necessary. This example shows a patch point reserving 15 bytes, with one argument; in $rdi, and a return value in $rax per native calling convention:. .. code-block:: llvm. %target = inttoptr i64 -281474976710654 to ptr; %val = call i64 (i64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then the ``anyregcc`` convention may be used:. .. code-block:: none. %val = call anyregcc @llvm.experimental.patchpoint(i64 78, i32 15,; ptr %target, i32 1,; ptr %ptr). The stack map now indicates the location of the %ptr argum",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:10515,Deployability,patch,patch,10515,"use with stack maps, anyregcc,; which forces the arguments to be loaded into registers but allows; those register to be dynamically allocated. These argument registers; will have their register locations recorded in the stack map in; addition to the remaining ``live values``. The patch point also emits nops to cover at least ``<numBytes>`` of; instruction encoding space. Hence, the client must ensure that; ``<numBytes>`` is enough to encode a call to the target address on the; supported targets. If the call target is constant null, then there is; no minimum requirement. A zero-byte null target patchpoint is; valid. The runtime may patch the code emitted for the patch point, including; the call sequence and nops. However, the runtime may not assume; anything about the code LLVM emits within the reserved space. Partial; patching is not allowed. The runtime must patch all reserved bytes,; padding with nops if necessary. This example shows a patch point reserving 15 bytes, with one argument; in $rdi, and a return value in $rax per native calling convention:. .. code-block:: llvm. %target = inttoptr i64 -281474976710654 to ptr; %val = call i64 (i64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then the ``anyregcc`` convention may be used:. .. code-block:: none. %val = call anyregcc @llvm.experimental.patchpoint(i64 78, i32 15,; ptr %target, i32 1,; ptr %ptr). The stack map now indicates the location of the %ptr argument and; return value:. .. code-block:: none. Stack Map: ID=78, Loc0=%r9 Loc1=%r8. The patch code sequence m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:10756,Deployability,patch,patchpoint,10756,"tions recorded in the stack map in; addition to the remaining ``live values``. The patch point also emits nops to cover at least ``<numBytes>`` of; instruction encoding space. Hence, the client must ensure that; ``<numBytes>`` is enough to encode a call to the target address on the; supported targets. If the call target is constant null, then there is; no minimum requirement. A zero-byte null target patchpoint is; valid. The runtime may patch the code emitted for the patch point, including; the call sequence and nops. However, the runtime may not assume; anything about the code LLVM emits within the reserved space. Partial; patching is not allowed. The runtime must patch all reserved bytes,; padding with nops if necessary. This example shows a patch point reserving 15 bytes, with one argument; in $rdi, and a return value in $rax per native calling convention:. .. code-block:: llvm. %target = inttoptr i64 -281474976710654 to ptr; %val = call i64 (i64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then the ``anyregcc`` convention may be used:. .. code-block:: none. %val = call anyregcc @llvm.experimental.patchpoint(i64 78, i32 15,; ptr %target, i32 1,; ptr %ptr). The stack map now indicates the location of the %ptr argument and; return value:. .. code-block:: none. Stack Map: ID=78, Loc0=%r9 Loc1=%r8. The patch code sequence may now use the argument that happened to be; allocated in %r8 and return a value allocated in %r9:. .. code-block:: none. 0x00 movslq 4(%r8) %r9 <--- patched code at patch point address; 0x03 nop; ..",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:10938,Deployability,patch,patch,10938,"s>`` is enough to encode a call to the target address on the; supported targets. If the call target is constant null, then there is; no minimum requirement. A zero-byte null target patchpoint is; valid. The runtime may patch the code emitted for the patch point, including; the call sequence and nops. However, the runtime may not assume; anything about the code LLVM emits within the reserved space. Partial; patching is not allowed. The runtime must patch all reserved bytes,; padding with nops if necessary. This example shows a patch point reserving 15 bytes, with one argument; in $rdi, and a return value in $rax per native calling convention:. .. code-block:: llvm. %target = inttoptr i64 -281474976710654 to ptr; %val = call i64 (i64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then the ``anyregcc`` convention may be used:. .. code-block:: none. %val = call anyregcc @llvm.experimental.patchpoint(i64 78, i32 15,; ptr %target, i32 1,; ptr %ptr). The stack map now indicates the location of the %ptr argument and; return value:. .. code-block:: none. Stack Map: ID=78, Loc0=%r9 Loc1=%r8. The patch code sequence may now use the argument that happened to be; allocated in %r8 and return a value allocated in %r9:. .. code-block:: none. 0x00 movslq 4(%r8) %r9 <--- patched code at patch point address; 0x03 nop; ...; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %r9; 0x10 movl %r9, 8(%rsp). .. _stackmap-format:. Stack Map Format; ================. The existence of a stack map or patch point intrinsic within an LLVM; Modul",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:11132,Deployability,patch,patched,11132,"ay patch the code emitted for the patch point, including; the call sequence and nops. However, the runtime may not assume; anything about the code LLVM emits within the reserved space. Partial; patching is not allowed. The runtime must patch all reserved bytes,; padding with nops if necessary. This example shows a patch point reserving 15 bytes, with one argument; in $rdi, and a return value in $rax per native calling convention:. .. code-block:: llvm. %target = inttoptr i64 -281474976710654 to ptr; %val = call i64 (i64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then the ``anyregcc`` convention may be used:. .. code-block:: none. %val = call anyregcc @llvm.experimental.patchpoint(i64 78, i32 15,; ptr %target, i32 1,; ptr %ptr). The stack map now indicates the location of the %ptr argument and; return value:. .. code-block:: none. Stack Map: ID=78, Loc0=%r9 Loc1=%r8. The patch code sequence may now use the argument that happened to be; allocated in %r8 and return a value allocated in %r9:. .. code-block:: none. 0x00 movslq 4(%r8) %r9 <--- patched code at patch point address; 0x03 nop; ...; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %r9; 0x10 movl %r9, 8(%rsp). .. _stackmap-format:. Stack Map Format; ================. The existence of a stack map or patch point intrinsic within an LLVM; Module forces code emission to create a :ref:`stackmap-section`. The; format of this section follows:. .. code-block:: none. Header {; uint8 : Stack Map Version (current version is 3); uint8 : Reserved (expected to be 0);",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:11337,Deployability,patch,patchpoint,11337,"e reserved space. Partial; patching is not allowed. The runtime must patch all reserved bytes,; padding with nops if necessary. This example shows a patch point reserving 15 bytes, with one argument; in $rdi, and a return value in $rax per native calling convention:. .. code-block:: llvm. %target = inttoptr i64 -281474976710654 to ptr; %val = call i64 (i64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then the ``anyregcc`` convention may be used:. .. code-block:: none. %val = call anyregcc @llvm.experimental.patchpoint(i64 78, i32 15,; ptr %target, i32 1,; ptr %ptr). The stack map now indicates the location of the %ptr argument and; return value:. .. code-block:: none. Stack Map: ID=78, Loc0=%r9 Loc1=%r8. The patch code sequence may now use the argument that happened to be; allocated in %r8 and return a value allocated in %r9:. .. code-block:: none. 0x00 movslq 4(%r8) %r9 <--- patched code at patch point address; 0x03 nop; ...; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %r9; 0x10 movl %r9, 8(%rsp). .. _stackmap-format:. Stack Map Format; ================. The existence of a stack map or patch point intrinsic within an LLVM; Module forces code emission to create a :ref:`stackmap-section`. The; format of this section follows:. .. code-block:: none. Header {; uint8 : Stack Map Version (current version is 3); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; uint32 : NumConstants; uint32 : NumRecords; StkSizeRecord[NumFunctions] {; uint64 : Function Address; u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:11542,Deployability,patch,patch,11542,"ax per native calling convention:. .. code-block:: llvm. %target = inttoptr i64 -281474976710654 to ptr; %val = call i64 (i64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then the ``anyregcc`` convention may be used:. .. code-block:: none. %val = call anyregcc @llvm.experimental.patchpoint(i64 78, i32 15,; ptr %target, i32 1,; ptr %ptr). The stack map now indicates the location of the %ptr argument and; return value:. .. code-block:: none. Stack Map: ID=78, Loc0=%r9 Loc1=%r8. The patch code sequence may now use the argument that happened to be; allocated in %r8 and return a value allocated in %r9:. .. code-block:: none. 0x00 movslq 4(%r8) %r9 <--- patched code at patch point address; 0x03 nop; ...; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %r9; 0x10 movl %r9, 8(%rsp). .. _stackmap-format:. Stack Map Format; ================. The existence of a stack map or patch point intrinsic within an LLVM; Module forces code emission to create a :ref:`stackmap-section`. The; format of this section follows:. .. code-block:: none. Header {; uint8 : Stack Map Version (current version is 3); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; uint32 : NumConstants; uint32 : NumRecords; StkSizeRecord[NumFunctions] {; uint64 : Function Address; uint64 : Stack Size (or UINT64_MAX if not statically known); uint64 : Record Count; }; Constants[NumConstants] {; uint64 : LargeConstant; }; StkMapRecord[NumRecords] {; uint64 : PatchPoint ID; uint32 : Instruction Offset; uint16 : Res",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:11713,Deployability,patch,patched,11713,"64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then the ``anyregcc`` convention may be used:. .. code-block:: none. %val = call anyregcc @llvm.experimental.patchpoint(i64 78, i32 15,; ptr %target, i32 1,; ptr %ptr). The stack map now indicates the location of the %ptr argument and; return value:. .. code-block:: none. Stack Map: ID=78, Loc0=%r9 Loc1=%r8. The patch code sequence may now use the argument that happened to be; allocated in %r8 and return a value allocated in %r9:. .. code-block:: none. 0x00 movslq 4(%r8) %r9 <--- patched code at patch point address; 0x03 nop; ...; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %r9; 0x10 movl %r9, 8(%rsp). .. _stackmap-format:. Stack Map Format; ================. The existence of a stack map or patch point intrinsic within an LLVM; Module forces code emission to create a :ref:`stackmap-section`. The; format of this section follows:. .. code-block:: none. Header {; uint8 : Stack Map Version (current version is 3); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; uint32 : NumConstants; uint32 : NumRecords; StkSizeRecord[NumFunctions] {; uint64 : Function Address; uint64 : Stack Size (or UINT64_MAX if not statically known); uint64 : Record Count; }; Constants[NumConstants] {; uint64 : LargeConstant; }; StkMapRecord[NumRecords] {; uint64 : PatchPoint ID; uint32 : Instruction Offset; uint16 : Reserved (record flags); uint16 : NumLocations; Location[NumLocations] {; uint8 : Register | Direct | Indirect | Constant | Co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:11729,Deployability,patch,patch,11729,"64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then the ``anyregcc`` convention may be used:. .. code-block:: none. %val = call anyregcc @llvm.experimental.patchpoint(i64 78, i32 15,; ptr %target, i32 1,; ptr %ptr). The stack map now indicates the location of the %ptr argument and; return value:. .. code-block:: none. Stack Map: ID=78, Loc0=%r9 Loc1=%r8. The patch code sequence may now use the argument that happened to be; allocated in %r8 and return a value allocated in %r9:. .. code-block:: none. 0x00 movslq 4(%r8) %r9 <--- patched code at patch point address; 0x03 nop; ...; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %r9; 0x10 movl %r9, 8(%rsp). .. _stackmap-format:. Stack Map Format; ================. The existence of a stack map or patch point intrinsic within an LLVM; Module forces code emission to create a :ref:`stackmap-section`. The; format of this section follows:. .. code-block:: none. Header {; uint8 : Stack Map Version (current version is 3); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; uint32 : NumConstants; uint32 : NumRecords; StkSizeRecord[NumFunctions] {; uint64 : Function Address; uint64 : Stack Size (or UINT64_MAX if not statically known); uint64 : Record Count; }; Constants[NumConstants] {; uint64 : LargeConstant; }; StkMapRecord[NumRecords] {; uint64 : PatchPoint ID; uint32 : Instruction Offset; uint16 : Reserved (record flags); uint16 : NumLocations; Location[NumLocations] {; uint8 : Register | Direct | Indirect | Constant | Co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:11940,Deployability,patch,patch,11940,"1; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then the ``anyregcc`` convention may be used:. .. code-block:: none. %val = call anyregcc @llvm.experimental.patchpoint(i64 78, i32 15,; ptr %target, i32 1,; ptr %ptr). The stack map now indicates the location of the %ptr argument and; return value:. .. code-block:: none. Stack Map: ID=78, Loc0=%r9 Loc1=%r8. The patch code sequence may now use the argument that happened to be; allocated in %r8 and return a value allocated in %r9:. .. code-block:: none. 0x00 movslq 4(%r8) %r9 <--- patched code at patch point address; 0x03 nop; ...; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %r9; 0x10 movl %r9, 8(%rsp). .. _stackmap-format:. Stack Map Format; ================. The existence of a stack map or patch point intrinsic within an LLVM; Module forces code emission to create a :ref:`stackmap-section`. The; format of this section follows:. .. code-block:: none. Header {; uint8 : Stack Map Version (current version is 3); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; uint32 : NumConstants; uint32 : NumRecords; StkSizeRecord[NumFunctions] {; uint64 : Function Address; uint64 : Stack Size (or UINT64_MAX if not statically known); uint64 : Record Count; }; Constants[NumConstants] {; uint64 : LargeConstant; }; StkMapRecord[NumRecords] {; uint64 : PatchPoint ID; uint32 : Instruction Offset; uint16 : Reserved (record flags); uint16 : NumLocations; Location[NumLocations] {; uint8 : Register | Direct | Indirect | Constant | ConstantIndex; uint8 : Reserved (expected to be 0); uint16 : Location Size; uint16 : Dwarf RegNum; uint16 : Reserved (expected to be 0); int32 : Offset or SmallConstant; }; uint32 : Padding (only if required to align to 8 byte); uint16 : Padding; uint16 ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:14672,Deployability,patch,patchpoint,14672,"===========. In the common case, a value is available in a register, and the; ``Offset`` field will be zero. Values spilled to the stack are encoded; as ``Indirect`` locations. The runtime must load those values from a; stack address, typically in the form ``[BP + Offset]``. If an; ``alloca`` value is passed directly to a stack map intrinsic, then; LLVM may fold the frame index into the stack map as an optimization to; avoid allocating a register or stack slot. These frame indices will be; encoded as ``Direct`` locations in the form ``BP + Offset``. LLVM may; also optimize constants by emitting them directly in the stack map,; either in the ``Offset`` of a ``Constant`` location or in the constant; pool, referred to by ``ConstantIndex`` locations. At each callsite, a ""liveout"" register list is also recorded. These; are the registers that are live across the stackmap and therefore must; be saved by the runtime. This is an important optimization when the; patchpoint intrinsic is used with a calling convention that by default; preserves most registers as callee-save. Each entry in the liveout register list contains a DWARF register; number and size in bytes. The stackmap format deliberately omits; specific subregister information. Instead the runtime must interpret; this information conservatively. For example, if the stackmap reports; one byte at ``%rax``, then the value may be in either ``%al`` or; ``%ah``. It doesn't matter in practice, because the runtime will; simply save ``%rax``. However, if the stackmap reports 16 bytes at; ``%ymm0``, then the runtime can safely optimize by saving only; ``%xmm0``. The stack map format is a contract between an LLVM SVN revision and; the runtime. It is currently experimental and may change in the short; term, but minimizing the need to update the runtime is; important. Consequently, the stack map design is motivated by; simplicity and extensibility. Compactness of the representation is; secondary because the runtime is expected to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:15507,Deployability,update,update,15507,"e, a ""liveout"" register list is also recorded. These; are the registers that are live across the stackmap and therefore must; be saved by the runtime. This is an important optimization when the; patchpoint intrinsic is used with a calling convention that by default; preserves most registers as callee-save. Each entry in the liveout register list contains a DWARF register; number and size in bytes. The stackmap format deliberately omits; specific subregister information. Instead the runtime must interpret; this information conservatively. For example, if the stackmap reports; one byte at ``%rax``, then the value may be in either ``%al`` or; ``%ah``. It doesn't matter in practice, because the runtime will; simply save ``%rax``. However, if the stackmap reports 16 bytes at; ``%ymm0``, then the runtime can safely optimize by saving only; ``%xmm0``. The stack map format is a contract between an LLVM SVN revision and; the runtime. It is currently experimental and may change in the short; term, but minimizing the need to update the runtime is; important. Consequently, the stack map design is motivated by; simplicity and extensibility. Compactness of the representation is; secondary because the runtime is expected to parse the data; immediately after compiling a module and encode the information in its; own format. Since the runtime controls the allocation of sections, it; can reuse the same stack map space for multiple modules. Stackmap support is currently only implemented for 64-bit; platforms. However, a 32-bit implementation should be able to use the; same format with an insignificant amount of wasted space. .. _stackmap-section:. Stack Map Section; ^^^^^^^^^^^^^^^^^. A JIT compiler can easily access this section by providing its own; memory manager via the LLVM C API; ``LLVMCreateSimpleMCJITMemoryManager()``. When creating the memory; manager, the JIT provides a callback:; ``LLVMMemoryManagerAllocateDataSectionCallback()``. When LLVM creates; this section, it invokes t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:18434,Deployability,patch,patching,18434,"ivation for this design is to allow a runtime to; commandeer a stack frame when execution reaches an instruction address; associated with a stack map. The runtime must be able to rebuild a; stack frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; records the address of frame index. This address is itself the value; that the runtime requested. This differs from Indirect locations,; which refer to a stack locations from which the requested ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:18558,Deployability,patch,patch,18558,"ivation for this design is to allow a runtime to; commandeer a stack frame when execution reaches an instruction address; associated with a stack map. The runtime must be able to rebuild a; stack frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; records the address of frame index. This address is itself the value; that the runtime requested. This differs from Indirect locations,; which refer to a stack locations from which the requested ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:18791,Deployability,patch,patchpoint,18791,"interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; records the address of frame index. This address is itself the value; that the runtime requested. This differs from Indirect locations,; which refer to a stack locations from which the requested values must; be loaded. Direct locations can communicate the address if an alloca,; while Indirect locations handle register spills. For example:. .. code-block:: none. entry:; %a = alloca i64...; llvm.experimental.stackmap(i64 <ID>, i32 <shadowBytes>, ptr %a). The runtime can determine this alloca's relative location on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:9695,Energy Efficiency,allocate,allocated,9695,"e. Variants of the intrinsic with non-void return; type also return a value according to calling convention. On PowerPC, note that ``<target>`` must be the ABI function pointer for the; intended target of the indirect call. Specifically, when compiling for the; ELF V1 ABI, ``<target>`` is the function-descriptor address normally used as; the C/C++ function-pointer representation. Requesting zero patch point arguments is valid. In this case, all; variable operands are handled just like; ``llvm.experimental.stackmap.*``. The difference is that space will; still be reserved for patching, a call will be emitted, and a return; value is allowed. The location of the arguments are not normally recorded in the stack; map because they are already fixed by the calling convention. The; remaining ``live values`` will have their location recorded, which; could be a register, stack location, or constant. A special calling; convention has been introduced for use with stack maps, anyregcc,; which forces the arguments to be loaded into registers but allows; those register to be dynamically allocated. These argument registers; will have their register locations recorded in the stack map in; addition to the remaining ``live values``. The patch point also emits nops to cover at least ``<numBytes>`` of; instruction encoding space. Hence, the client must ensure that; ``<numBytes>`` is enough to encode a call to the target address on the; supported targets. If the call target is constant null, then there is; no minimum requirement. A zero-byte null target patchpoint is; valid. The runtime may patch the code emitted for the patch point, including; the call sequence and nops. However, the runtime may not assume; anything about the code LLVM emits within the reserved space. Partial; patching is not allowed. The runtime must patch all reserved bytes,; padding with nops if necessary. This example shows a patch point reserving 15 bytes, with one argument; in $rdi, and a return value in $rax per n",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:11608,Energy Efficiency,allocate,allocated,11608,"ax per native calling convention:. .. code-block:: llvm. %target = inttoptr i64 -281474976710654 to ptr; %val = call i64 (i64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then the ``anyregcc`` convention may be used:. .. code-block:: none. %val = call anyregcc @llvm.experimental.patchpoint(i64 78, i32 15,; ptr %target, i32 1,; ptr %ptr). The stack map now indicates the location of the %ptr argument and; return value:. .. code-block:: none. Stack Map: ID=78, Loc0=%r9 Loc1=%r8. The patch code sequence may now use the argument that happened to be; allocated in %r8 and return a value allocated in %r9:. .. code-block:: none. 0x00 movslq 4(%r8) %r9 <--- patched code at patch point address; 0x03 nop; ...; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %r9; 0x10 movl %r9, 8(%rsp). .. _stackmap-format:. Stack Map Format; ================. The existence of a stack map or patch point intrinsic within an LLVM; Module forces code emission to create a :ref:`stackmap-section`. The; format of this section follows:. .. code-block:: none. Header {; uint8 : Stack Map Version (current version is 3); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; uint32 : NumConstants; uint32 : NumRecords; StkSizeRecord[NumFunctions] {; uint64 : Function Address; uint64 : Stack Size (or UINT64_MAX if not statically known); uint64 : Record Count; }; Constants[NumConstants] {; uint64 : LargeConstant; }; StkMapRecord[NumRecords] {; uint64 : PatchPoint ID; uint32 : Instruction Offset; uint16 : Res",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:11644,Energy Efficiency,allocate,allocated,11644,"ax per native calling convention:. .. code-block:: llvm. %target = inttoptr i64 -281474976710654 to ptr; %val = call i64 (i64, i32, ...); @llvm.experimental.patchpoint.i64(i64 78, i32 15,; ptr %target, i32 1, ptr %ptr); %add = add i64 %val, 3; ret i64 %add. May generate:. .. code-block:: none. 0x00 movabsq $0xffff000000000002, %r11 <--- patch point address; 0x0a callq *%r11; 0x0d nop; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %rax; 0x10 movl %rax, 8(%rsp). Note that no stack map locations will be recorded. If the patched code; sequence does not need arguments fixed to specific calling convention; registers, then the ``anyregcc`` convention may be used:. .. code-block:: none. %val = call anyregcc @llvm.experimental.patchpoint(i64 78, i32 15,; ptr %target, i32 1,; ptr %ptr). The stack map now indicates the location of the %ptr argument and; return value:. .. code-block:: none. Stack Map: ID=78, Loc0=%r9 Loc1=%r8. The patch code sequence may now use the argument that happened to be; allocated in %r8 and return a value allocated in %r9:. .. code-block:: none. 0x00 movslq 4(%r8) %r9 <--- patched code at patch point address; 0x03 nop; ...; 0x0e nop <--- end of reserved 15-bytes; 0x0f addq $0x3, %r9; 0x10 movl %r9, 8(%rsp). .. _stackmap-format:. Stack Map Format; ================. The existence of a stack map or patch point intrinsic within an LLVM; Module forces code emission to create a :ref:`stackmap-section`. The; format of this section follows:. .. code-block:: none. Header {; uint8 : Stack Map Version (current version is 3); uint8 : Reserved (expected to be 0); uint16 : Reserved (expected to be 0); }; uint32 : NumFunctions; uint32 : NumConstants; uint32 : NumRecords; StkSizeRecord[NumFunctions] {; uint64 : Function Address; uint64 : Stack Size (or UINT64_MAX if not statically known); uint64 : Record Count; }; Constants[NumConstants] {; uint64 : LargeConstant; }; StkMapRecord[NumRecords] {; uint64 : PatchPoint ID; uint32 : Instruction Offset; uint16 : Res",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:2610,Integrability,interface,interface,2610,"IT); compiler. Example applications of the patchpoint intrinsics are; implementing an inline call cache for polymorphic method dispatch or; optimizing the retrieval of properties in dynamically typed languages; such as JavaScript. The intrinsics documented here are currently used by the JavaScript; compiler within the open source WebKit project, see the `FTL JIT; <https://trac.webkit.org/wiki/FTLJIT>`_, but they are designed to be; used whenever stack maps or code patching are needed. Because the; intrinsics have experimental status, compatibility across LLVM; releases is not guaranteed. The stack map functionality described in this document is separate; from the functionality described in; :ref:`stack-map`. `GCFunctionMetadata` provides the location of; pointers into a collected heap captured by the `GCRoot` intrinsic,; which can also be considered a ""stack map"". Unlike the stack maps; defined above, the `GCFunctionMetadata` stack map interface does not; provide a way to associate live register values of arbitrary type with; an instruction address, nor does it specify a format for the resulting; stack map. The stack maps described here could potentially provide; richer information to a garbage collecting runtime, but that usage; will not be discussed in this document. Intrinsics; ==========. The following two kinds of intrinsics can be used to implement stack; maps and patch points: ``llvm.experimental.stackmap`` and; ``llvm.experimental.patchpoint``. Both kinds of intrinsics generate a; stack map record, and they both allow some form of code patching. They; can be used independently (i.e. ``llvm.experimental.patchpoint``; implicitly generates a stack map without the need for an additional; call to ``llvm.experimental.stackmap``). The choice of which to use; depends on whether it is necessary to reserve space for code patching; and whether any of the intrinsic arguments should be lowered according; to calling conventions. ``llvm.experimental.stackmap`` does not; re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:3450,Integrability,depend,depends,3450,"red a ""stack map"". Unlike the stack maps; defined above, the `GCFunctionMetadata` stack map interface does not; provide a way to associate live register values of arbitrary type with; an instruction address, nor does it specify a format for the resulting; stack map. The stack maps described here could potentially provide; richer information to a garbage collecting runtime, but that usage; will not be discussed in this document. Intrinsics; ==========. The following two kinds of intrinsics can be used to implement stack; maps and patch points: ``llvm.experimental.stackmap`` and; ``llvm.experimental.patchpoint``. Both kinds of intrinsics generate a; stack map record, and they both allow some form of code patching. They; can be used independently (i.e. ``llvm.experimental.patchpoint``; implicitly generates a stack map without the need for an additional; call to ``llvm.experimental.stackmap``). The choice of which to use; depends on whether it is necessary to reserve space for code patching; and whether any of the intrinsic arguments should be lowered according; to calling conventions. ``llvm.experimental.stackmap`` does not; reserve any space, nor does it expect any call arguments. If the; runtime patches code at the stack map's address, it will destructively; overwrite the program text. This is unlike; ``llvm.experimental.patchpoint``, which reserves space for in-place; patching without overwriting surrounding code. The; ``llvm.experimental.patchpoint`` intrinsic also lowers a specified; number of arguments according to its calling convention. This allows; patched code to make in-place function calls without marshaling. Each instance of one of these intrinsics generates a stack map record; in the :ref:`stackmap-section`. The record includes an ID, allowing; the runtime to uniquely identify the stack map, and the offset within; the code from the beginning of the enclosing function. '``llvm.experimental.stackmap``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. S",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:15360,Integrability,contract,contract,15360,"nstant`` location or in the constant; pool, referred to by ``ConstantIndex`` locations. At each callsite, a ""liveout"" register list is also recorded. These; are the registers that are live across the stackmap and therefore must; be saved by the runtime. This is an important optimization when the; patchpoint intrinsic is used with a calling convention that by default; preserves most registers as callee-save. Each entry in the liveout register list contains a DWARF register; number and size in bytes. The stackmap format deliberately omits; specific subregister information. Instead the runtime must interpret; this information conservatively. For example, if the stackmap reports; one byte at ``%rax``, then the value may be in either ``%al`` or; ``%ah``. It doesn't matter in practice, because the runtime will; simply save ``%rax``. However, if the stackmap reports 16 bytes at; ``%ymm0``, then the runtime can safely optimize by saving only; ``%xmm0``. The stack map format is a contract between an LLVM SVN revision and; the runtime. It is currently experimental and may change in the short; term, but minimizing the need to update the runtime is; important. Consequently, the stack map design is motivated by; simplicity and extensibility. Compactness of the representation is; secondary because the runtime is expected to parse the data; immediately after compiling a module and encode the information in its; own format. Since the runtime controls the allocation of sections, it; can reuse the same stack map space for multiple modules. Stackmap support is currently only implemented for 64-bit; platforms. However, a 32-bit implementation should be able to use the; same format with an insignificant amount of wasted space. .. _stackmap-section:. Stack Map Section; ^^^^^^^^^^^^^^^^^. A JIT compiler can easily access this section by providing its own; memory manager via the LLVM C API; ``LLVMCreateSimpleMCJITMemoryManager()``. When creating the memory; manager, the JIT provides a call",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:1768,Modifiability,polymorphi,polymorphic,1768,"LVM emits stack map data into the object code within a designated; :ref:`stackmap-section`. This stack map data contains a record for; each stack map. The record stores the stack map's instruction address; and contains an entry for each mapped value. Each entry encodes a; value's location as a register, stack offset, or constant. A patch point is an instruction address at which space is reserved for; patching a new instruction sequence at run time. Patch points look; much like calls to LLVM. They take arguments that follow a calling; convention and may return a value. They also imply stack map; generation, which allows the runtime to locate the patchpoint and; find the location of ``live values`` at that point. Motivation; ==========. This functionality is currently experimental but is potentially useful; in a variety of settings, the most obvious being a runtime (JIT); compiler. Example applications of the patchpoint intrinsics are; implementing an inline call cache for polymorphic method dispatch or; optimizing the retrieval of properties in dynamically typed languages; such as JavaScript. The intrinsics documented here are currently used by the JavaScript; compiler within the open source WebKit project, see the `FTL JIT; <https://trac.webkit.org/wiki/FTLJIT>`_, but they are designed to be; used whenever stack maps or code patching are needed. Because the; intrinsics have experimental status, compatibility across LLVM; releases is not guaranteed. The stack map functionality described in this document is separate; from the functionality described in; :ref:`stack-map`. `GCFunctionMetadata` provides the location of; pointers into a collected heap captured by the `GCRoot` intrinsic,; which can also be considered a ""stack map"". Unlike the stack maps; defined above, the `GCFunctionMetadata` stack map interface does not; provide a way to associate live register values of arbitrary type with; an instruction address, nor does it specify a format for the resulting; stack ma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:4942,Modifiability,variab,variable,4942,"nsic also lowers a specified; number of arguments according to its calling convention. This allows; patched code to make in-place function calls without marshaling. Each instance of one of these intrinsics generates a stack map record; in the :ref:`stackmap-section`. The record includes an ID, allowing; the runtime to uniquely identify the stack map, and the offset within; the code from the beginning of the enclosing function. '``llvm.experimental.stackmap``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.stackmap(i64 <id>, i32 <numShadowBytes>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.stackmap``' intrinsic records the location of; specified values in the stack map without generating any code. Operands:; """""""""""""""""". The first operand is an ID to be encoded within the stack map. The; second operand is the number of shadow bytes following the; intrinsic. The variable number of operands that follow are the ``live; values`` for which locations will be recorded in the stack map. To use this intrinsic as a bare-bones stack map, with no code patching; support, the number of shadow bytes can be set to zero. Semantics:; """""""""""""""""""". The stack map intrinsic generates no code in place, unless nops are; needed to cover its shadow (see below). However, its offset from; function entry is stored in the stack map. This is the relative; instruction address immediately following the instructions that; precede the stack map. The stack map ID allows a runtime to locate the desired stack map; record. LLVM passes this ID through directly to the stack map; record without checking uniqueness. LLVM guarantees a shadow of instructions following the stack map's; instruction offset during which neither the end of the basic block nor; another call to ``llvm.experimental.stackmap`` or; ``llvm.experimental.patchpoint`` may occur. This allows the runtime to; patch the code at this point in response to an event triggered from;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:8117,Modifiability,variab,variable,8117,"5 movl $0xffff, %rax <--- patched code at stack map address; 0x0a callq *%rax <---- end of 8-byte shadow. This way, after the normal call to the runtime returns, the code will; execute a patched call to a special entry point that can rebuild a; stack frame from the values located by the stack map. '``llvm.experimental.patchpoint.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.patchpoint.void(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...); declare i64; @llvm.experimental.patchpoint.i64(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.patchpoint.*``' intrinsics creates a function; call to the specified ``<target>`` and records the location of specified; values in the stack map. Operands:; """""""""""""""""". The first operand is an ID, the second operand is the number of bytes; reserved for the patchable region, the third operand is the target; address of a function (optionally null), and the fourth operand; specifies how many of the following variable operands are considered; function call arguments. The remaining variable number of operands are; the ``live values`` for which locations will be recorded in the stack; map. Semantics:; """""""""""""""""""". The patch point intrinsic generates a stack map. It also emits a; function call to the address specified by ``<target>`` if the address; is not a constant null. The function call and its arguments are; lowered according to the calling convention specified at the; intrinsic's callsite. Variants of the intrinsic with non-void return; type also return a value according to calling convention. On PowerPC, note that ``<target>`` must be the ABI function pointer for the; intended target of the indirect call. Specifically, when compiling for the; ELF V1 ABI, ``<target>`` is the function-descriptor address normally used as; the C/C++ function-pointer representation. Requesting zero patch point arguments",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:8190,Modifiability,variab,variable,8190,"l entry point that can rebuild a; stack frame from the values located by the stack map. '``llvm.experimental.patchpoint.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.patchpoint.void(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...); declare i64; @llvm.experimental.patchpoint.i64(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...). Overview:; """""""""""""""""". The '``llvm.experimental.patchpoint.*``' intrinsics creates a function; call to the specified ``<target>`` and records the location of specified; values in the stack map. Operands:; """""""""""""""""". The first operand is an ID, the second operand is the number of bytes; reserved for the patchable region, the third operand is the target; address of a function (optionally null), and the fourth operand; specifies how many of the following variable operands are considered; function call arguments. The remaining variable number of operands are; the ``live values`` for which locations will be recorded in the stack; map. Semantics:; """""""""""""""""""". The patch point intrinsic generates a stack map. It also emits a; function call to the address specified by ``<target>`` if the address; is not a constant null. The function call and its arguments are; lowered according to the calling convention specified at the; intrinsic's callsite. Variants of the intrinsic with non-void return; type also return a value according to calling convention. On PowerPC, note that ``<target>`` must be the ABI function pointer for the; intended target of the indirect call. Specifically, when compiling for the; ELF V1 ABI, ``<target>`` is the function-descriptor address normally used as; the C/C++ function-pointer representation. Requesting zero patch point arguments is valid. In this case, all; variable operands are handled just like; ``llvm.experimental.stackmap.*``. The difference is that space will; still be reserved for patching, a call will be emitted, and a return; v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:9056,Modifiability,variab,variable,9056,"h operand; specifies how many of the following variable operands are considered; function call arguments. The remaining variable number of operands are; the ``live values`` for which locations will be recorded in the stack; map. Semantics:; """""""""""""""""""". The patch point intrinsic generates a stack map. It also emits a; function call to the address specified by ``<target>`` if the address; is not a constant null. The function call and its arguments are; lowered according to the calling convention specified at the; intrinsic's callsite. Variants of the intrinsic with non-void return; type also return a value according to calling convention. On PowerPC, note that ``<target>`` must be the ABI function pointer for the; intended target of the indirect call. Specifically, when compiling for the; ELF V1 ABI, ``<target>`` is the function-descriptor address normally used as; the C/C++ function-pointer representation. Requesting zero patch point arguments is valid. In this case, all; variable operands are handled just like; ``llvm.experimental.stackmap.*``. The difference is that space will; still be reserved for patching, a call will be emitted, and a return; value is allowed. The location of the arguments are not normally recorded in the stack; map because they are already fixed by the calling convention. The; remaining ``live values`` will have their location recorded, which; could be a register, stack location, or constant. A special calling; convention has been introduced for use with stack maps, anyregcc,; which forces the arguments to be loaded into registers but allows; those register to be dynamically allocated. These argument registers; will have their register locations recorded in the stack map in; addition to the remaining ``live values``. The patch point also emits nops to cover at least ``<numBytes>`` of; instruction encoding space. Hence, the client must ensure that; ``<numBytes>`` is enough to encode a call to the target address on the; supported targets. If the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:17439,Modifiability,variab,variables,17439,"MemoryManagerAllocateDataSectionCallback()``. When LLVM creates; this section, it invokes the callback and passes the section name. The; JIT can record the in-memory address of the section at this time and; later parse it to recover the stack map data. For MachO (e.g. on Darwin), the stack map section name is; ""__llvm_stackmaps"". The segment name is ""__LLVM_STACKMAPS"". For ELF (e.g. on Linux), the stack map section name is; "".llvm_stackmaps"". The segment name is ""__LLVM_STACKMAPS"". Stack Map Usage; ===============. The stack map support described in this document can be used to; precisely determine the location of values at a specific position in; the code. LLVM does not maintain any mapping between those values and; any higher-level entity. The runtime must be able to interpret the; stack map record given only the ID, offset, and the order of the; locations, records, and functions, which LLVM preserves. Note that this is quite different from the goal of debug information,; which is a best-effort attempt to track the location of named; variables at every instruction. An important motivation for this design is to allow a runtime to; commandeer a stack frame when execution reaches an instruction address; associated with a stack map. The runtime must be able to rebuild a; stack frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent sub",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:1758,Performance,cache,cache,1758,"LVM emits stack map data into the object code within a designated; :ref:`stackmap-section`. This stack map data contains a record for; each stack map. The record stores the stack map's instruction address; and contains an entry for each mapped value. Each entry encodes a; value's location as a register, stack offset, or constant. A patch point is an instruction address at which space is reserved for; patching a new instruction sequence at run time. Patch points look; much like calls to LLVM. They take arguments that follow a calling; convention and may return a value. They also imply stack map; generation, which allows the runtime to locate the patchpoint and; find the location of ``live values`` at that point. Motivation; ==========. This functionality is currently experimental but is potentially useful; in a variety of settings, the most obvious being a runtime (JIT); compiler. Example applications of the patchpoint intrinsics are; implementing an inline call cache for polymorphic method dispatch or; optimizing the retrieval of properties in dynamically typed languages; such as JavaScript. The intrinsics documented here are currently used by the JavaScript; compiler within the open source WebKit project, see the `FTL JIT; <https://trac.webkit.org/wiki/FTLJIT>`_, but they are designed to be; used whenever stack maps or code patching are needed. Because the; intrinsics have experimental status, compatibility across LLVM; releases is not guaranteed. The stack map functionality described in this document is separate; from the functionality described in; :ref:`stack-map`. `GCFunctionMetadata` provides the location of; pointers into a collected heap captured by the `GCRoot` intrinsic,; which can also be considered a ""stack map"". Unlike the stack maps; defined above, the `GCFunctionMetadata` stack map interface does not; provide a way to associate live register values of arbitrary type with; an instruction address, nor does it specify a format for the resulting; stack ma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:1800,Performance,optimiz,optimizing,1800,"LVM emits stack map data into the object code within a designated; :ref:`stackmap-section`. This stack map data contains a record for; each stack map. The record stores the stack map's instruction address; and contains an entry for each mapped value. Each entry encodes a; value's location as a register, stack offset, or constant. A patch point is an instruction address at which space is reserved for; patching a new instruction sequence at run time. Patch points look; much like calls to LLVM. They take arguments that follow a calling; convention and may return a value. They also imply stack map; generation, which allows the runtime to locate the patchpoint and; find the location of ``live values`` at that point. Motivation; ==========. This functionality is currently experimental but is potentially useful; in a variety of settings, the most obvious being a runtime (JIT); compiler. Example applications of the patchpoint intrinsics are; implementing an inline call cache for polymorphic method dispatch or; optimizing the retrieval of properties in dynamically typed languages; such as JavaScript. The intrinsics documented here are currently used by the JavaScript; compiler within the open source WebKit project, see the `FTL JIT; <https://trac.webkit.org/wiki/FTLJIT>`_, but they are designed to be; used whenever stack maps or code patching are needed. Because the; intrinsics have experimental status, compatibility across LLVM; releases is not guaranteed. The stack map functionality described in this document is separate; from the functionality described in; :ref:`stack-map`. `GCFunctionMetadata` provides the location of; pointers into a collected heap captured by the `GCRoot` intrinsic,; which can also be considered a ""stack map"". Unlike the stack maps; defined above, the `GCFunctionMetadata` stack map interface does not; provide a way to associate live register values of arbitrary type with; an instruction address, nor does it specify a format for the resulting; stack ma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:6581,Performance,load,load,6581," this ID through directly to the stack map; record without checking uniqueness. LLVM guarantees a shadow of instructions following the stack map's; instruction offset during which neither the end of the basic block nor; another call to ``llvm.experimental.stackmap`` or; ``llvm.experimental.patchpoint`` may occur. This allows the runtime to; patch the code at this point in response to an event triggered from; outside the code. The code for instructions following the stack map; may be emitted in the stack map's shadow, and these instructions may; be overwritten by destructive patching. Without shadow bytes, this; destructive patching could overwrite program text or data outside the; current function. We disallow overlapping stack map shadows so that; the runtime does not need to consider this corner case. For example, a stack map with 8 byte shadow:. .. code-block:: llvm. call void @runtime(); call void (i64, i32, ...) @llvm.experimental.stackmap(i64 77, i32 8,; ptr %ptr); %val = load i64, ptr %ptr; %add = add i64 %val, 3; ret i64 %add. May require one byte of nop-padding:. .. code-block:: none. 0x00 callq _runtime; 0x05 nop <--- stack map address; 0x06 movq (%rdi), %rax; 0x07 addq $3, %rax; 0x0a popq %rdx; 0x0b ret <---- end of 8-byte shadow. Now, if the runtime needs to invalidate the compiled code, it may; patch 8 bytes of code at the stack map's address at follows:. .. code-block:: none. 0x00 callq _runtime; 0x05 movl $0xffff, %rax <--- patched code at stack map address; 0x0a callq *%rax <---- end of 8-byte shadow. This way, after the normal call to the runtime returns, the code will; execute a patched call to a special entry point that can rebuild a; stack frame from the values located by the stack map. '``llvm.experimental.patchpoint.*``' Intrinsic; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Syntax:; """""""""""""". ::. declare void; @llvm.experimental.patchpoint.void(i64 <id>, i32 <numBytes>,; ptr <target>, i32 <numArgs>, ...); declare i64; @llvm.experimental.pat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:9628,Performance,load,loaded,9628,"e. Variants of the intrinsic with non-void return; type also return a value according to calling convention. On PowerPC, note that ``<target>`` must be the ABI function pointer for the; intended target of the indirect call. Specifically, when compiling for the; ELF V1 ABI, ``<target>`` is the function-descriptor address normally used as; the C/C++ function-pointer representation. Requesting zero patch point arguments is valid. In this case, all; variable operands are handled just like; ``llvm.experimental.stackmap.*``. The difference is that space will; still be reserved for patching, a call will be emitted, and a return; value is allowed. The location of the arguments are not normally recorded in the stack; map because they are already fixed by the calling convention. The; remaining ``live values`` will have their location recorded, which; could be a register, stack location, or constant. A special calling; convention has been introduced for use with stack maps, anyregcc,; which forces the arguments to be loaded into registers but allows; those register to be dynamically allocated. These argument registers; will have their register locations recorded in the stack map in; addition to the remaining ``live values``. The patch point also emits nops to cover at least ``<numBytes>`` of; instruction encoding space. Hence, the client must ensure that; ``<numBytes>`` is enough to encode a call to the target address on the; supported targets. If the call target is constant null, then there is; no minimum requirement. A zero-byte null target patchpoint is; valid. The runtime may patch the code emitted for the patch point, including; the call sequence and nops. However, the runtime may not assume; anything about the code LLVM emits within the reserved space. Partial; patching is not allowed. The runtime must patch all reserved bytes,; padding with nops if necessary. This example shows a patch point reserving 15 bytes, with one argument; in $rdi, and a return value in $rax per n",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:13899,Performance,load,load,13899,"o align to 8 byte); uint16 : Padding; uint16 : NumLiveOuts; LiveOuts[NumLiveOuts]; uint16 : Dwarf RegNum; uint8 : Reserved; uint8 : Size in Bytes; }; uint32 : Padding (only if required to align to 8 byte); }. The first byte of each location encodes a type that indicates how to; interpret the ``RegNum`` and ``Offset`` fields as follows:. ======== ========== =================== ===========================; Encoding Type Value Description; -------- ---------- ------------------- ---------------------------; 0x1 Register Reg Value in a register; 0x2 Direct Reg + Offset Frame index value; 0x3 Indirect [Reg + Offset] Spilled value; 0x4 Constant Offset Small constant; 0x5 ConstIndex Constants[Offset] Large constant; ======== ========== =================== ===========================. In the common case, a value is available in a register, and the; ``Offset`` field will be zero. Values spilled to the stack are encoded; as ``Indirect`` locations. The runtime must load those values from a; stack address, typically in the form ``[BP + Offset]``. If an; ``alloca`` value is passed directly to a stack map intrinsic, then; LLVM may fold the frame index into the stack map as an optimization to; avoid allocating a register or stack slot. These frame indices will be; encoded as ``Direct`` locations in the form ``BP + Offset``. LLVM may; also optimize constants by emitting them directly in the stack map,; either in the ``Offset`` of a ``Constant`` location or in the constant; pool, referred to by ``ConstantIndex`` locations. At each callsite, a ""liveout"" register list is also recorded. These; are the registers that are live across the stackmap and therefore must; be saved by the runtime. This is an important optimization when the; patchpoint intrinsic is used with a calling convention that by default; preserves most registers as callee-save. Each entry in the liveout register list contains a DWARF register; number and size in bytes. The stackmap format deliberately omits; specific subr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:14111,Performance,optimiz,optimization,14111,"; }; uint32 : Padding (only if required to align to 8 byte); }. The first byte of each location encodes a type that indicates how to; interpret the ``RegNum`` and ``Offset`` fields as follows:. ======== ========== =================== ===========================; Encoding Type Value Description; -------- ---------- ------------------- ---------------------------; 0x1 Register Reg Value in a register; 0x2 Direct Reg + Offset Frame index value; 0x3 Indirect [Reg + Offset] Spilled value; 0x4 Constant Offset Small constant; 0x5 ConstIndex Constants[Offset] Large constant; ======== ========== =================== ===========================. In the common case, a value is available in a register, and the; ``Offset`` field will be zero. Values spilled to the stack are encoded; as ``Indirect`` locations. The runtime must load those values from a; stack address, typically in the form ``[BP + Offset]``. If an; ``alloca`` value is passed directly to a stack map intrinsic, then; LLVM may fold the frame index into the stack map as an optimization to; avoid allocating a register or stack slot. These frame indices will be; encoded as ``Direct`` locations in the form ``BP + Offset``. LLVM may; also optimize constants by emitting them directly in the stack map,; either in the ``Offset`` of a ``Constant`` location or in the constant; pool, referred to by ``ConstantIndex`` locations. At each callsite, a ""liveout"" register list is also recorded. These; are the registers that are live across the stackmap and therefore must; be saved by the runtime. This is an important optimization when the; patchpoint intrinsic is used with a calling convention that by default; preserves most registers as callee-save. Each entry in the liveout register list contains a DWARF register; number and size in bytes. The stackmap format deliberately omits; specific subregister information. Instead the runtime must interpret; this information conservatively. For example, if the stackmap reports; one byte at ``%r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:14276,Performance,optimiz,optimize,14276,"scription; -------- ---------- ------------------- ---------------------------; 0x1 Register Reg Value in a register; 0x2 Direct Reg + Offset Frame index value; 0x3 Indirect [Reg + Offset] Spilled value; 0x4 Constant Offset Small constant; 0x5 ConstIndex Constants[Offset] Large constant; ======== ========== =================== ===========================. In the common case, a value is available in a register, and the; ``Offset`` field will be zero. Values spilled to the stack are encoded; as ``Indirect`` locations. The runtime must load those values from a; stack address, typically in the form ``[BP + Offset]``. If an; ``alloca`` value is passed directly to a stack map intrinsic, then; LLVM may fold the frame index into the stack map as an optimization to; avoid allocating a register or stack slot. These frame indices will be; encoded as ``Direct`` locations in the form ``BP + Offset``. LLVM may; also optimize constants by emitting them directly in the stack map,; either in the ``Offset`` of a ``Constant`` location or in the constant; pool, referred to by ``ConstantIndex`` locations. At each callsite, a ""liveout"" register list is also recorded. These; are the registers that are live across the stackmap and therefore must; be saved by the runtime. This is an important optimization when the; patchpoint intrinsic is used with a calling convention that by default; preserves most registers as callee-save. Each entry in the liveout register list contains a DWARF register; number and size in bytes. The stackmap format deliberately omits; specific subregister information. Instead the runtime must interpret; this information conservatively. For example, if the stackmap reports; one byte at ``%rax``, then the value may be in either ``%al`` or; ``%ah``. It doesn't matter in practice, because the runtime will; simply save ``%rax``. However, if the stackmap reports 16 bytes at; ``%ymm0``, then the runtime can safely optimize by saving only; ``%xmm0``. The stack map format is a c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:14649,Performance,optimiz,optimization,14649,"===========. In the common case, a value is available in a register, and the; ``Offset`` field will be zero. Values spilled to the stack are encoded; as ``Indirect`` locations. The runtime must load those values from a; stack address, typically in the form ``[BP + Offset]``. If an; ``alloca`` value is passed directly to a stack map intrinsic, then; LLVM may fold the frame index into the stack map as an optimization to; avoid allocating a register or stack slot. These frame indices will be; encoded as ``Direct`` locations in the form ``BP + Offset``. LLVM may; also optimize constants by emitting them directly in the stack map,; either in the ``Offset`` of a ``Constant`` location or in the constant; pool, referred to by ``ConstantIndex`` locations. At each callsite, a ""liveout"" register list is also recorded. These; are the registers that are live across the stackmap and therefore must; be saved by the runtime. This is an important optimization when the; patchpoint intrinsic is used with a calling convention that by default; preserves most registers as callee-save. Each entry in the liveout register list contains a DWARF register; number and size in bytes. The stackmap format deliberately omits; specific subregister information. Instead the runtime must interpret; this information conservatively. For example, if the stackmap reports; one byte at ``%rax``, then the value may be in either ``%al`` or; ``%ah``. It doesn't matter in practice, because the runtime will; simply save ``%rax``. However, if the stackmap reports 16 bytes at; ``%ymm0``, then the runtime can safely optimize by saving only; ``%xmm0``. The stack map format is a contract between an LLVM SVN revision and; the runtime. It is currently experimental and may change in the short; term, but minimizing the need to update the runtime is; important. Consequently, the stack map design is motivated by; simplicity and extensibility. Compactness of the representation is; secondary because the runtime is expected to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:15298,Performance,optimiz,optimize,15298,"lso optimize constants by emitting them directly in the stack map,; either in the ``Offset`` of a ``Constant`` location or in the constant; pool, referred to by ``ConstantIndex`` locations. At each callsite, a ""liveout"" register list is also recorded. These; are the registers that are live across the stackmap and therefore must; be saved by the runtime. This is an important optimization when the; patchpoint intrinsic is used with a calling convention that by default; preserves most registers as callee-save. Each entry in the liveout register list contains a DWARF register; number and size in bytes. The stackmap format deliberately omits; specific subregister information. Instead the runtime must interpret; this information conservatively. For example, if the stackmap reports; one byte at ``%rax``, then the value may be in either ``%al`` or; ``%ah``. It doesn't matter in practice, because the runtime will; simply save ``%rax``. However, if the stackmap reports 16 bytes at; ``%ymm0``, then the runtime can safely optimize by saving only; ``%xmm0``. The stack map format is a contract between an LLVM SVN revision and; the runtime. It is currently experimental and may change in the short; term, but minimizing the need to update the runtime is; important. Consequently, the stack map design is motivated by; simplicity and extensibility. Compactness of the representation is; secondary because the runtime is expected to parse the data; immediately after compiling a module and encode the information in its; own format. Since the runtime controls the allocation of sections, it; can reuse the same stack map space for multiple modules. Stackmap support is currently only implemented for 64-bit; platforms. However, a 32-bit implementation should be able to use the; same format with an insignificant amount of wasted space. .. _stackmap-section:. Stack Map Section; ^^^^^^^^^^^^^^^^^. A JIT compiler can easily access this section by providing its own; memory manager via the LLVM C API;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:17893,Performance,optimiz,optimization,17893,"age; ===============. The stack map support described in this document can be used to; precisely determine the location of values at a specific position in; the code. LLVM does not maintain any mapping between those values and; any higher-level entity. The runtime must be able to interpret the; stack map record given only the ID, offset, and the order of the; locations, records, and functions, which LLVM preserves. Note that this is quite different from the goal of debug information,; which is a best-effort attempt to track the location of named; variables at every instruction. An important motivation for this design is to allow a runtime to; commandeer a stack frame when execution reaches an instruction address; associated with a stack map. The runtime must be able to rebuild a; stack frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:17972,Performance,load,loads,17972,"mine the location of values at a specific position in; the code. LLVM does not maintain any mapping between those values and; any higher-level entity. The runtime must be able to interpret the; stack map record given only the ID, offset, and the order of the; locations, records, and functions, which LLVM preserves. Note that this is quite different from the goal of debug information,; which is a best-effort attempt to track the location of named; variables at every instruction. An important motivation for this design is to allow a runtime to; commandeer a stack frame when execution reaches an instruction address; associated with a stack map. The runtime must be able to rebuild a; stack frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:18023,Performance,load,load,18023,"does not maintain any mapping between those values and; any higher-level entity. The runtime must be able to interpret the; stack map record given only the ID, offset, and the order of the; locations, records, and functions, which LLVM preserves. Note that this is quite different from the goal of debug information,; which is a best-effort attempt to track the location of named; variables at every instruction. An important motivation for this design is to allow a runtime to; commandeer a stack frame when execution reaches an instruction address; associated with a stack map. The runtime must be able to rebuild a; stack frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:18150,Performance,load,load,18150,"erpret the; stack map record given only the ID, offset, and the order of the; locations, records, and functions, which LLVM preserves. Note that this is quite different from the goal of debug information,; which is a best-effort attempt to track the location of named; variables at every instruction. An important motivation for this design is to allow a runtime to; commandeer a stack frame when execution reaches an instruction address; associated with a stack map. The runtime must be able to rebuild a; stack frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack ma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:18297,Performance,load,load,18297,"rves. Note that this is quite different from the goal of debug information,; which is a best-effort attempt to track the location of named; variables at every instruction. An important motivation for this design is to allow a runtime to; commandeer a stack frame when execution reaches an instruction address; associated with a stack map. The runtime must be able to rebuild a; stack frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; record",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:18338,Performance,load,load,18338,"rves. Note that this is quite different from the goal of debug information,; which is a best-effort attempt to track the location of named; variables at every instruction. An important motivation for this design is to allow a runtime to; commandeer a stack frame when execution reaches an instruction address; associated with a stack map. The runtime must be able to rebuild a; stack frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; record",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:18414,Performance,load,load,18414,"ivation for this design is to allow a runtime to; commandeer a stack frame when execution reaches an instruction address; associated with a stack map. The runtime must be able to rebuild a; stack frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; records the address of frame index. This address is itself the value; that the runtime requested. This differs from Indirect locations,; which refer to a stack locations from which the requested ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:18515,Performance,load,load,18515,"ivation for this design is to allow a runtime to; commandeer a stack frame when execution reaches an instruction address; associated with a stack map. The runtime must be able to rebuild a; stack frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; records the address of frame index. This address is itself the value; that the runtime requested. This differs from Indirect locations,; which refer to a stack locations from which the requested ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:18650,Performance,load,load,18650," frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; records the address of frame index. This address is itself the value; that the runtime requested. This differs from Indirect locations,; which refer to a stack locations from which the requested values must; be loaded. Direct locations can communicate the address if an alloca,; while Indirect locations handle register spills. For example:. .. code-block:: none. entry:; %a = alloca i64...",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:18887,Performance,optimiz,optimization,18887,"ation. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; records the address of frame index. This address is itself the value; that the runtime requested. This differs from Indirect locations,; which refer to a stack locations from which the requested values must; be loaded. Direct locations can communicate the address if an alloca,; while Indirect locations handle register spills. For example:. .. code-block:: none. entry:; %a = alloca i64...; llvm.experimental.stackmap(i64 <ID>, i32 <shadowBytes>, ptr %a). The runtime can determine this alloca's relative location on the; stack immediately after compilation, or at any time thereafter. This; differs from R",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:19119,Performance,optimiz,optimizations,19119,"ld be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; records the address of frame index. This address is itself the value; that the runtime requested. This differs from Indirect locations,; which refer to a stack locations from which the requested values must; be loaded. Direct locations can communicate the address if an alloca,; while Indirect locations handle register spills. For example:. .. code-block:: none. entry:; %a = alloca i64...; llvm.experimental.stackmap(i64 <ID>, i32 <shadowBytes>, ptr %a). The runtime can determine this alloca's relative location on the; stack immediately after compilation, or at any time thereafter. This; differs from Register and Indirect locations, because the runtime can; only read the values in those locations when execution reaches the; instruction address of the stack map. This functionality requir",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:19150,Performance,load,loads,19150,"ld be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; records the address of frame index. This address is itself the value; that the runtime requested. This differs from Indirect locations,; which refer to a stack locations from which the requested values must; be loaded. Direct locations can communicate the address if an alloca,; while Indirect locations handle register spills. For example:. .. code-block:: none. entry:; %a = alloca i64...; llvm.experimental.stackmap(i64 <ID>, i32 <shadowBytes>, ptr %a). The runtime can determine this alloca's relative location on the; stack immediately after compilation, or at any time thereafter. This; differs from Register and Indirect locations, because the runtime can; only read the values in those locations when execution reaches the; instruction address of the stack map. This functionality requir",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:19504,Performance,load,loaded,19504,"ck map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; records the address of frame index. This address is itself the value; that the runtime requested. This differs from Indirect locations,; which refer to a stack locations from which the requested values must; be loaded. Direct locations can communicate the address if an alloca,; while Indirect locations handle register spills. For example:. .. code-block:: none. entry:; %a = alloca i64...; llvm.experimental.stackmap(i64 <ID>, i32 <shadowBytes>, ptr %a). The runtime can determine this alloca's relative location on the; stack immediately after compilation, or at any time thereafter. This; differs from Register and Indirect locations, because the runtime can; only read the values in those locations when execution reaches the; instruction address of the stack map. This functionality requires LLVM to treat entry-block allocas; specially when they are directly consumed by an intrinsics. (This is; the same requirement imposed by the llvm.gcroot intrinsic.) LLVM; transformations must not substitute the alloca with any intervening; value. This can be verified by the runtime simply by checking that the; stack map's location is a Direct location type. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:14128,Safety,avoid,avoid,14128,"; }; uint32 : Padding (only if required to align to 8 byte); }. The first byte of each location encodes a type that indicates how to; interpret the ``RegNum`` and ``Offset`` fields as follows:. ======== ========== =================== ===========================; Encoding Type Value Description; -------- ---------- ------------------- ---------------------------; 0x1 Register Reg Value in a register; 0x2 Direct Reg + Offset Frame index value; 0x3 Indirect [Reg + Offset] Spilled value; 0x4 Constant Offset Small constant; 0x5 ConstIndex Constants[Offset] Large constant; ======== ========== =================== ===========================. In the common case, a value is available in a register, and the; ``Offset`` field will be zero. Values spilled to the stack are encoded; as ``Indirect`` locations. The runtime must load those values from a; stack address, typically in the form ``[BP + Offset]``. If an; ``alloca`` value is passed directly to a stack map intrinsic, then; LLVM may fold the frame index into the stack map as an optimization to; avoid allocating a register or stack slot. These frame indices will be; encoded as ``Direct`` locations in the form ``BP + Offset``. LLVM may; also optimize constants by emitting them directly in the stack map,; either in the ``Offset`` of a ``Constant`` location or in the constant; pool, referred to by ``ConstantIndex`` locations. At each callsite, a ""liveout"" register list is also recorded. These; are the registers that are live across the stackmap and therefore must; be saved by the runtime. This is an important optimization when the; patchpoint intrinsic is used with a calling convention that by default; preserves most registers as callee-save. Each entry in the liveout register list contains a DWARF register; number and size in bytes. The stackmap format deliberately omits; specific subregister information. Instead the runtime must interpret; this information conservatively. For example, if the stackmap reports; one byte at ``%r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:15291,Safety,safe,safely,15291,"lso optimize constants by emitting them directly in the stack map,; either in the ``Offset`` of a ``Constant`` location or in the constant; pool, referred to by ``ConstantIndex`` locations. At each callsite, a ""liveout"" register list is also recorded. These; are the registers that are live across the stackmap and therefore must; be saved by the runtime. This is an important optimization when the; patchpoint intrinsic is used with a calling convention that by default; preserves most registers as callee-save. Each entry in the liveout register list contains a DWARF register; number and size in bytes. The stackmap format deliberately omits; specific subregister information. Instead the runtime must interpret; this information conservatively. For example, if the stackmap reports; one byte at ``%rax``, then the value may be in either ``%al`` or; ``%ah``. It doesn't matter in practice, because the runtime will; simply save ``%rax``. However, if the stackmap reports 16 bytes at; ``%ymm0``, then the runtime can safely optimize by saving only; ``%xmm0``. The stack map format is a contract between an LLVM SVN revision and; the runtime. It is currently experimental and may change in the short; term, but minimizing the need to update the runtime is; important. Consequently, the stack map design is motivated by; simplicity and extensibility. Compactness of the representation is; secondary because the runtime is expected to parse the data; immediately after compiling a module and encode the information in its; own format. Since the runtime controls the allocation of sections, it; can reuse the same stack map space for multiple modules. Stackmap support is currently only implemented for 64-bit; platforms. However, a 32-bit implementation should be able to use the; same format with an insignificant amount of wasted space. .. _stackmap-section:. Stack Map Section; ^^^^^^^^^^^^^^^^^. A JIT compiler can easily access this section by providing its own; memory manager via the LLVM C API;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:16612,Safety,recover,recover,16612," motivated by; simplicity and extensibility. Compactness of the representation is; secondary because the runtime is expected to parse the data; immediately after compiling a module and encode the information in its; own format. Since the runtime controls the allocation of sections, it; can reuse the same stack map space for multiple modules. Stackmap support is currently only implemented for 64-bit; platforms. However, a 32-bit implementation should be able to use the; same format with an insignificant amount of wasted space. .. _stackmap-section:. Stack Map Section; ^^^^^^^^^^^^^^^^^. A JIT compiler can easily access this section by providing its own; memory manager via the LLVM C API; ``LLVMCreateSimpleMCJITMemoryManager()``. When creating the memory; manager, the JIT provides a callback:; ``LLVMMemoryManagerAllocateDataSectionCallback()``. When LLVM creates; this section, it invokes the callback and passes the section name. The; JIT can record the in-memory address of the section at this time and; later parse it to recover the stack map data. For MachO (e.g. on Darwin), the stack map section name is; ""__llvm_stackmaps"". The segment name is ""__LLVM_STACKMAPS"". For ELF (e.g. on Linux), the stack map section name is; "".llvm_stackmaps"". The segment name is ""__LLVM_STACKMAPS"". Stack Map Usage; ===============. The stack map support described in this document can be used to; precisely determine the location of values at a specific position in; the code. LLVM does not maintain any mapping between those values and; any higher-level entity. The runtime must be able to interpret the; stack map record given only the ID, offset, and the order of the; locations, records, and functions, which LLVM preserves. Note that this is quite different from the goal of debug information,; which is a best-effort attempt to track the location of named; variables at every instruction. An important motivation for this design is to allow a runtime to; commandeer a stack frame when execution re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:18158,Safety,safe,safe,18158,"erpret the; stack map record given only the ID, offset, and the order of the; locations, records, and functions, which LLVM preserves. Note that this is quite different from the goal of debug information,; which is a best-effort attempt to track the location of named; variables at every instruction. An important motivation for this design is to allow a runtime to; commandeer a stack frame when execution reaches an instruction address; associated with a stack map. The runtime must be able to rebuild a; stack frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack ma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:18352,Safety,unsafe,unsafe,18352,"rves. Note that this is quite different from the goal of debug information,; which is a best-effort attempt to track the location of named; variables at every instruction. An important motivation for this design is to allow a runtime to; commandeer a stack frame when execution reaches an instruction address; associated with a stack map. The runtime must be able to rebuild a; stack frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; record",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:18955,Safety,avoid,avoided,18955,"ever, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; records the address of frame index. This address is itself the value; that the runtime requested. This differs from Indirect locations,; which refer to a stack locations from which the requested values must; be loaded. Direct locations can communicate the address if an alloca,; while Indirect locations handle register spills. For example:. .. code-block:: none. entry:; %a = alloca i64...; llvm.experimental.stackmap(i64 <ID>, i32 <shadowBytes>, ptr %a). The runtime can determine this alloca's relative location on the; stack immediately after compilation, or at any time thereafter. This; differs from Register and Indirect locations, because the runtime can; only read",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:16197,Security,access,access,16197,"rts 16 bytes at; ``%ymm0``, then the runtime can safely optimize by saving only; ``%xmm0``. The stack map format is a contract between an LLVM SVN revision and; the runtime. It is currently experimental and may change in the short; term, but minimizing the need to update the runtime is; important. Consequently, the stack map design is motivated by; simplicity and extensibility. Compactness of the representation is; secondary because the runtime is expected to parse the data; immediately after compiling a module and encode the information in its; own format. Since the runtime controls the allocation of sections, it; can reuse the same stack map space for multiple modules. Stackmap support is currently only implemented for 64-bit; platforms. However, a 32-bit implementation should be able to use the; same format with an insignificant amount of wasted space. .. _stackmap-section:. Stack Map Section; ^^^^^^^^^^^^^^^^^. A JIT compiler can easily access this section by providing its own; memory manager via the LLVM C API; ``LLVMCreateSimpleMCJITMemoryManager()``. When creating the memory; manager, the JIT provides a callback:; ``LLVMMemoryManagerAllocateDataSectionCallback()``. When LLVM creates; this section, it invokes the callback and passes the section name. The; JIT can record the in-memory address of the section at this time and; later parse it to recover the stack map data. For MachO (e.g. on Darwin), the stack map section name is; ""__llvm_stackmaps"". The segment name is ""__LLVM_STACKMAPS"". For ELF (e.g. on Linux), the stack map section name is; "".llvm_stackmaps"". The segment name is ""__LLVM_STACKMAPS"". Stack Map Usage; ===============. The stack map support described in this document can be used to; precisely determine the location of values at a specific position in; the code. LLVM does not maintain any mapping between those values and; any higher-level entity. The runtime must be able to interpret the; stack map record given only the ID, offset, and the order of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:677,Usability,resume,resume,677,"===================================; Stack maps and patch points in LLVM; ===================================. .. contents::; :local:; :depth: 2. Definitions; ===========. In this document we refer to the ""runtime"" collectively as all; components that serve as the LLVM client, including the LLVM IR; generator, object code consumer, and code patcher. A stack map records the location of ``live values`` at a particular; instruction address. These ``live values`` do not refer to all the; LLVM values live across the stack map. Instead, they are only the; values that the runtime requires to be live at this point. For; example, they may be the values the runtime will need to resume; program execution at that point independent of the compiled function; containing the stack map. LLVM emits stack map data into the object code within a designated; :ref:`stackmap-section`. This stack map data contains a record for; each stack map. The record stores the stack map's instruction address; and contains an entry for each mapped value. Each entry encodes a; value's location as a register, stack offset, or constant. A patch point is an instruction address at which space is reserved for; patching a new instruction sequence at run time. Patch points look; much like calls to LLVM. They take arguments that follow a calling; convention and may return a value. They also imply stack map; generation, which allows the runtime to locate the patchpoint and; find the location of ``live values`` at that point. Motivation; ==========. This functionality is currently experimental but is potentially useful; in a variety of settings, the most obvious being a runtime (JIT); compiler. Example applications of the patchpoint intrinsics are; implementing an inline call cache for polymorphic method dispatch or; optimizing the retrieval of properties in dynamically typed languages; such as JavaScript. The intrinsics documented here are currently used by the JavaScript; compiler within the open source WebKit pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:15191,Usability,simpl,simply,15191,"hese frame indices will be; encoded as ``Direct`` locations in the form ``BP + Offset``. LLVM may; also optimize constants by emitting them directly in the stack map,; either in the ``Offset`` of a ``Constant`` location or in the constant; pool, referred to by ``ConstantIndex`` locations. At each callsite, a ""liveout"" register list is also recorded. These; are the registers that are live across the stackmap and therefore must; be saved by the runtime. This is an important optimization when the; patchpoint intrinsic is used with a calling convention that by default; preserves most registers as callee-save. Each entry in the liveout register list contains a DWARF register; number and size in bytes. The stackmap format deliberately omits; specific subregister information. Instead the runtime must interpret; this information conservatively. For example, if the stackmap reports; one byte at ``%rax``, then the value may be in either ``%al`` or; ``%ah``. It doesn't matter in practice, because the runtime will; simply save ``%rax``. However, if the stackmap reports 16 bytes at; ``%ymm0``, then the runtime can safely optimize by saving only; ``%xmm0``. The stack map format is a contract between an LLVM SVN revision and; the runtime. It is currently experimental and may change in the short; term, but minimizing the need to update the runtime is; important. Consequently, the stack map design is motivated by; simplicity and extensibility. Compactness of the representation is; secondary because the runtime is expected to parse the data; immediately after compiling a module and encode the information in its; own format. Since the runtime controls the allocation of sections, it; can reuse the same stack map space for multiple modules. Stackmap support is currently only implemented for 64-bit; platforms. However, a 32-bit implementation should be able to use the; same format with an insignificant amount of wasted space. .. _stackmap-section:. Stack Map Section; ^^^^^^^^^^^^^^^^^. A ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:15593,Usability,simpl,simplicity,15593,"p and therefore must; be saved by the runtime. This is an important optimization when the; patchpoint intrinsic is used with a calling convention that by default; preserves most registers as callee-save. Each entry in the liveout register list contains a DWARF register; number and size in bytes. The stackmap format deliberately omits; specific subregister information. Instead the runtime must interpret; this information conservatively. For example, if the stackmap reports; one byte at ``%rax``, then the value may be in either ``%al`` or; ``%ah``. It doesn't matter in practice, because the runtime will; simply save ``%rax``. However, if the stackmap reports 16 bytes at; ``%ymm0``, then the runtime can safely optimize by saving only; ``%xmm0``. The stack map format is a contract between an LLVM SVN revision and; the runtime. It is currently experimental and may change in the short; term, but minimizing the need to update the runtime is; important. Consequently, the stack map design is motivated by; simplicity and extensibility. Compactness of the representation is; secondary because the runtime is expected to parse the data; immediately after compiling a module and encode the information in its; own format. Since the runtime controls the allocation of sections, it; can reuse the same stack map space for multiple modules. Stackmap support is currently only implemented for 64-bit; platforms. However, a 32-bit implementation should be able to use the; same format with an insignificant amount of wasted space. .. _stackmap-section:. Stack Map Section; ^^^^^^^^^^^^^^^^^. A JIT compiler can easily access this section by providing its own; memory manager via the LLVM C API; ``LLVMCreateSimpleMCJITMemoryManager()``. When creating the memory; manager, the JIT provides a callback:; ``LLVMMemoryManagerAllocateDataSectionCallback()``. When LLVM creates; this section, it invokes the callback and passes the section name. The; JIT can record the in-memory address of the section at th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:17693,Usability,resume,resume,17693,"llvm_stackmaps"". The segment name is ""__LLVM_STACKMAPS"". For ELF (e.g. on Linux), the stack map section name is; "".llvm_stackmaps"". The segment name is ""__LLVM_STACKMAPS"". Stack Map Usage; ===============. The stack map support described in this document can be used to; precisely determine the location of values at a specific position in; the code. LLVM does not maintain any mapping between those values and; any higher-level entity. The runtime must be able to interpret the; stack map record given only the ID, offset, and the order of the; locations, records, and functions, which LLVM preserves. Note that this is quite different from the goal of debug information,; which is a best-effort attempt to track the location of named; variables at every instruction. An important motivation for this design is to allow a runtime to; commandeer a stack frame when execution reaches an instruction address; associated with a stack map. The runtime must be able to rebuild a; stack frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could cr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:17795,Usability,resume,resume,17795,".llvm_stackmaps"". The segment name is ""__LLVM_STACKMAPS"". Stack Map Usage; ===============. The stack map support described in this document can be used to; precisely determine the location of values at a specific position in; the code. LLVM does not maintain any mapping between those values and; any higher-level entity. The runtime must be able to interpret the; stack map record given only the ID, offset, and the order of the; locations, records, and functions, which LLVM preserves. Note that this is quite different from the goal of debug information,; which is a best-effort attempt to track the location of named; variables at every instruction. An important motivation for this design is to allow a runtime to; commandeer a stack frame when execution reaches an instruction address; associated with a stack map. The runtime must be able to rebuild a; stack frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:18551,Usability,simpl,simply,18551,"ivation for this design is to allow a runtime to; commandeer a stack frame when execution reaches an instruction address; associated with a stack map. The runtime must be able to rebuild a; stack frame and resume program execution using the information; provided by the stack map. For example, execution may resume in an; interpreter or a recompiled version of the same function. This usage restricts LLVM optimization. Clearly, LLVM must not move; stores across a stack map. However, loads must also be handled; conservatively. If the load may trigger an exception, hoisting it; above a stack map could be invalid. For example, the runtime may; determine that a load is safe to execute without a type check given; the current state of the type system. If the type system changes while; some activation of the load's function exists on the stack, the load; becomes unsafe. The runtime can prevent subsequent execution of that; load by immediately patching any stack map location that lies between; the current call site and the load (typically, the runtime would; simply patch all stack map locations to invalidate the function). If; the compiler had hoisted the load above the stack map, then the; program could crash before the runtime could take back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; records the address of frame index. This address is itself the value; that the runtime requested. This differs from Indirect locations,; which refer to a stack locations from which the requested ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst:20374,Usability,simpl,simply,20374,"back control. To enforce these semantics, stackmap and patchpoint intrinsics are; considered to potentially read and write all memory. This may limit; optimization more than some clients desire. This limitation may be; avoided by marking the call site as ""readonly"". In the future we may; also allow meta-data to be added to the intrinsic call to express; aliasing, thereby allowing optimizations to hoist certain loads above; stack maps. Direct Stack Map Entries; ^^^^^^^^^^^^^^^^^^^^^^^^. As shown in :ref:`stackmap-section`, a Direct stack map location; records the address of frame index. This address is itself the value; that the runtime requested. This differs from Indirect locations,; which refer to a stack locations from which the requested values must; be loaded. Direct locations can communicate the address if an alloca,; while Indirect locations handle register spills. For example:. .. code-block:: none. entry:; %a = alloca i64...; llvm.experimental.stackmap(i64 <ID>, i32 <shadowBytes>, ptr %a). The runtime can determine this alloca's relative location on the; stack immediately after compilation, or at any time thereafter. This; differs from Register and Indirect locations, because the runtime can; only read the values in those locations when execution reaches the; instruction address of the stack map. This functionality requires LLVM to treat entry-block allocas; specially when they are directly consumed by an intrinsics. (This is; the same requirement imposed by the llvm.gcroot intrinsic.) LLVM; transformations must not substitute the alloca with any intervening; value. This can be verified by the runtime simply by checking that the; stack map's location is a Direct location type. Supported Architectures; =======================. Support for StackMap generation and the related intrinsics requires; some code for each backend. Today, only a subset of LLVM's backends; are supported. The currently supported architectures are X86_64,; PowerPC, AArch64 and SystemZ.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackMaps.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackMaps.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:1644,Availability,toler,tolerate,1644,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:169,Energy Efficiency,allocate,allocated,169,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:179,Modifiability,variab,variables,179,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:352,Modifiability,variab,variables,352,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:412,Modifiability,variab,variables,412,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:440,Modifiability,variab,variables,440,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:561,Modifiability,extend,extended,561,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:585,Modifiability,variab,variable,585,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:622,Modifiability,extend,extend,622,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:676,Modifiability,variab,variable,676,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:1677,Modifiability,variab,variables,1677,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:2005,Modifiability,variab,variables,2005,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:2165,Modifiability,variab,variable,2165,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:729,Performance,optimiz,optimize,729,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:886,Performance,perform,performs,886,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:980,Performance,load,loads,980,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:1327,Performance,perform,performs,1327,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:1495,Performance,perform,performs,1495,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:209,Safety,safe,safe,209,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:307,Safety,avoid,avoid,307,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:346,Safety,safe,safe,346,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:406,Safety,safe,safe,406,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:1692,Safety,unsafe,unsafe,1692,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:1719,Safety,safe,safe,1719,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:1794,Safety,safe,safe,1794,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:1888,Safety,avoid,avoid,1888,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:2054,Safety,safe,safe,2054,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:2138,Safety,detect,detects,2138,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:2159,Safety,safe,safe,2159,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:227,Security,access,access,227,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:293,Security,sanitiz,sanitizers,293,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:512,Security,access,accessed,512,"==================================; Stack Safety Analysis; ==================================. Introduction; ============. The Stack Safety Analysis determines if stack allocated variables can be; considered 'safe' from memory access bugs. The primary purpose of the analysis is to be used by sanitizers to avoid; unnecessary instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:1831,Security,sanitiz,sanitizers,1831,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:1918,Security,validat,validation,1918,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:1971,Security,validat,validation,1971,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst:1612,Testability,test,tests,1612,"y instrumentation of 'safe' variables. SafeStack is going to be the; first user. 'safe' variables can be defined as variables that can not be used out-of-scope; (e.g. use-after-return) or accessed out of bounds. In the future it can be; extended to track other variable properties. E.g. we plan to extend; implementation with a check to make sure that variable is always initialized; before every read to optimize use-of-uninitialized-memory checks. How it works; ============. The analysis is implemented in two stages:. The intra-procedural, or 'local', stage performs a depth-first search inside; functions to collect all uses of each alloca, including loads/stores and uses as; arguments functions. After this stage we know which parts of the alloca are used; by functions itself but we don't know what happens after it is passed as; an argument to another function. The inter-procedural, or 'global', stage, resolves what happens to allocas after; they are passed as function arguments. This stage performs a depth-first search; on function calls inside a single module and propagates allocas usage through; functions calls. When used with ThinLTO, the global stage performs a whole program analysis over; the Module Summary Index. Testing; =======. The analysis is covered with lit tests. We expect that users can tolerate false classification of variables as; 'unsafe' when in-fact it's 'safe'. This may lead to inefficient code. However, we; can't accept false 'safe' classification which may cause sanitizers to miss actual; bugs in instrumented code. To avoid that we want additional validation tool. AddressSanitizer may help with this validation. We can instrument all variables; as usual but additionally store stack-safe information in the; ``ASanStackVariableDescription``. Then if AddressSanitizer detects a bug on; a 'safe' variable we can produce an additional report to let the user know that; probably Stack Safety Analysis failed and we should check for a bug in the; compiler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/StackSafetyAnalysis.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:10282,Availability,redundant,redundant,10282,"argument, N; return value function (where M is the number of values being; relocated + the original call arguments and N is the original return; value + each relocated value), but LLVM does not easily support such a; representation. Instead, the statepoint intrinsic marks the actual site of the; safepoint or statepoint. The statepoint returns a token value (which; exists only at compile time). To get back the original return value; of the call, we use the ``gc.result`` intrinsic. To get the relocation; of each pointer in turn, we use the ``gc.relocate`` intrinsic with the; appropriate index. Note that both the ``gc.relocate`` and ``gc.result`` are; tied to the statepoint. The combination forms a ""statepoint relocation; sequence"" and represents the entirety of a parseable call or 'statepoint'. When lowered, this example would generate the following x86 assembly:. .. code-block:: gas. 	 .globl	test1; 	 .align	16, 0x90; 	 pushq	%rax; 	 callq	foo; .Ltmp1:; 	 movq	(%rsp), %rax # This load is redundant (oops!); 	 popq	%rdx; 	 retq. Each of the potentially relocated values has been spilled to the; stack, and a record of that location has been recorded to the; :ref:`Stack Map section <stackmap-section>`. If the garbage collector; needs to update any of these pointers during the call, it knows; exactly what to change. The relevant parts of the StackMap section for our example are:. .. code-block:: gas. # This describes the call site; # Stack Maps: callsite 2882400000; 	 .quad	2882400000; 	 .long	.Ltmp1-test1; 	 .short	0; # .. 8 entries skipped ..; # This entry describes the spill slot which is directly addressable; # off RSP with offset 0. Given the value was spilled with a pushq,; # that makes sense.; # Stack Maps: Loc 8: Direct RSP [encoding: .byte 2, .byte 8, .short 7, .int 0]; 	 .byte	2; 	 .byte	8; 	 .short	7; 	 .long	0. This example was taken from the tests for the :ref:`RewriteStatepointsForGC`; utility pass. As such, its full StackMap can be easily examined with the; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:19141,Availability,redundant,redundant,19141,", i32 0, i8 addrspace(1)* %obj); %obj.relocated = call coldcc i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %0, i32 7, i32 7); ret i8 addrspace(1)* %obj.relocated; }. During lowering, this will result in an instruction selection DAG that looks; something like:. ::. CALLSEQ_START; ...; GC_TRANSITION_START (lowered i32 *@Flag), SRCVALUE i32* Flag; STATEPOINT; GC_TRANSITION_END (lowered i32 *@Flag), SRCVALUE i32 *Flag; ...; CALLSEQ_END. In order to generate the necessary transition code, the backend for each target; supported by ""hypothetical-gc"" must be modified to lower ``GC_TRANSITION_START``; and ``GC_TRANSITION_END`` nodes appropriately when the ""hypothetical-gc""; strategy is in use for a particular function. Assuming that such lowering has; been added for X86, the generated assembly would be:. .. code-block:: gas. 	 .globl	test1; 	 .align	16, 0x90; 	 pushq	%rax; 	 movl $1, %fs:Flag@TPOFF; 	 callq	foo; 	 movl $0, %fs:Flag@TPOFF; .Ltmp1:; 	 movq	(%rsp), %rax # This load is redundant (oops!); 	 popq	%rdx; 	 retq. Note that the design as presented above is not fully implemented: in particular,; strategy-specific lowering is not present, and all GC transitions are emitted as; as single no-op before and after the call instruction. These no-ops are often; removed by the backend during dead machine instruction elimination. Before the abstract machine model is lowered to the explicit statepoint model; of relocations by the :ref:`RewriteStatepointsForGC` pass it is possible for; any derived pointer to get its base pointer and offset from the base pointer; by using the ``gc.get.pointer.base`` and the ``gc.get.pointer.offset``; intrinsics respectively. These intrinsics are inlined by the; :ref:`RewriteStatepointsForGC` pass and must not be used after this pass. .. _statepoint-stackmap-format:. Stack Map Format; ================. Locations for each pointer value which may need read and/or updated by; the runtime or collector are provided in a separate section of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:31047,Availability,avail,available,31047,"ll is made GC parseable by wrapping the; call into a statepoint. This makes it possible to take a safepoint during; copy operation. Note that a GC parseable copy operation is not required to; take a safepoint. For example, a short copy operation may be performed without; taking a safepoint. GC parseable calls to '``llvm.memcpy.element.unordered.atomic.*``',; '``llvm.memmove.element.unordered.atomic.*``' intrinsics are lowered to calls; to '``__llvm_memcpy_element_unordered_atomic_safepoint_*``',; '``__llvm_memmove_element_unordered_atomic_safepoint_*``' symbols respectively.; This way the runtime can provide implementations of copy operations with and; without safepoints. GC parseable lowering also involves adjusting the arguments for the call.; Memcpy and memmove intrinsics take derived pointers as source and destination; arguments. If a copy operation takes a safepoint it might need to relocate the; underlying source and destination objects. This requires the corresponding base; pointers to be available in the copy operation. In order to make the base; pointers available RewriteStatepointsForGC replaces derived pointers with base; pointer and offset pairs. For example:. .. code-block:: llvm. declare void @__llvm_memcpy_element_unordered_atomic_safepoint_1(; i8 addrspace(1)* %dest_base, i64 %dest_offset,; i8 addrspace(1)* %src_base, i64 %src_offset,; i64 %length). .. _PlaceSafepoints:. PlaceSafepoints; ^^^^^^^^^^^^^^^^. The pass PlaceSafepoints inserts safepoint polls sufficient to ensure running; code checks for a safepoint request on a timely manner. This pass is expected; to be run before RewriteStatepointsForGC and thus does not produce full; relocation sequences. As an example, given input IR of the following:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @foo(); ret void; }. declare void @do_safepoint(); define void @gc.safepoint_poll() {; call void @do_safepoint(); ret void; }. This pass would produce the following IR:. .. c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:31116,Availability,avail,available,31116,"uring; copy operation. Note that a GC parseable copy operation is not required to; take a safepoint. For example, a short copy operation may be performed without; taking a safepoint. GC parseable calls to '``llvm.memcpy.element.unordered.atomic.*``',; '``llvm.memmove.element.unordered.atomic.*``' intrinsics are lowered to calls; to '``__llvm_memcpy_element_unordered_atomic_safepoint_*``',; '``__llvm_memmove_element_unordered_atomic_safepoint_*``' symbols respectively.; This way the runtime can provide implementations of copy operations with and; without safepoints. GC parseable lowering also involves adjusting the arguments for the call.; Memcpy and memmove intrinsics take derived pointers as source and destination; arguments. If a copy operation takes a safepoint it might need to relocate the; underlying source and destination objects. This requires the corresponding base; pointers to be available in the copy operation. In order to make the base; pointers available RewriteStatepointsForGC replaces derived pointers with base; pointer and offset pairs. For example:. .. code-block:: llvm. declare void @__llvm_memcpy_element_unordered_atomic_safepoint_1(; i8 addrspace(1)* %dest_base, i64 %dest_offset,; i8 addrspace(1)* %src_base, i64 %src_offset,; i64 %length). .. _PlaceSafepoints:. PlaceSafepoints; ^^^^^^^^^^^^^^^^. The pass PlaceSafepoints inserts safepoint polls sufficient to ensure running; code checks for a safepoint request on a timely manner. This pass is expected; to be run before RewriteStatepointsForGC and thus does not produce full; relocation sequences. As an example, given input IR of the following:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @foo(); ret void; }. declare void @do_safepoint(); define void @gc.safepoint_poll() {; call void @do_safepoint(); ret void; }. This pass would produce the following IR:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @do_safepoint(); call void @foo(); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:32292,Availability,redundant,redundant,32292,"__llvm_memcpy_element_unordered_atomic_safepoint_1(; i8 addrspace(1)* %dest_base, i64 %dest_offset,; i8 addrspace(1)* %src_base, i64 %src_offset,; i64 %length). .. _PlaceSafepoints:. PlaceSafepoints; ^^^^^^^^^^^^^^^^. The pass PlaceSafepoints inserts safepoint polls sufficient to ensure running; code checks for a safepoint request on a timely manner. This pass is expected; to be run before RewriteStatepointsForGC and thus does not produce full; relocation sequences. As an example, given input IR of the following:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @foo(); ret void; }. declare void @do_safepoint(); define void @gc.safepoint_poll() {; call void @do_safepoint(); ret void; }. This pass would produce the following IR:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @do_safepoint(); call void @foo(); ret void; }. In this case, we've added an (unconditional) entry safepoint poll. Note that; despite appearances, the entry poll is not necessarily redundant. We'd have to; know that ``foo`` and ``test`` were not mutually recursive for the poll to be; redundant. In practice, you'd probably want to your poll definition to contain; a conditional branch of some form. At the moment, PlaceSafepoints can insert safepoint polls at method entry and; loop backedges locations. Extending this to work with return polls would be; straight forward if desired. PlaceSafepoints includes a number of optimizations to avoid placing safepoint; polls at particular sites unless needed to ensure timely execution of a poll; under normal conditions. PlaceSafepoints does not attempt to ensure timely; execution of a poll under worst case conditions such as heavy system paging. The implementation of a safepoint poll action is specified by looking up a; function of the name ``gc.safepoint_poll`` in the containing Module. The body; of this function is inserted at each poll site desired. While calls or invokes; inside this method are ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:32396,Availability,redundant,redundant,32396,"_offset,; i8 addrspace(1)* %src_base, i64 %src_offset,; i64 %length). .. _PlaceSafepoints:. PlaceSafepoints; ^^^^^^^^^^^^^^^^. The pass PlaceSafepoints inserts safepoint polls sufficient to ensure running; code checks for a safepoint request on a timely manner. This pass is expected; to be run before RewriteStatepointsForGC and thus does not produce full; relocation sequences. As an example, given input IR of the following:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @foo(); ret void; }. declare void @do_safepoint(); define void @gc.safepoint_poll() {; call void @do_safepoint(); ret void; }. This pass would produce the following IR:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @do_safepoint(); call void @foo(); ret void; }. In this case, we've added an (unconditional) entry safepoint poll. Note that; despite appearances, the entry poll is not necessarily redundant. We'd have to; know that ``foo`` and ``test`` were not mutually recursive for the poll to be; redundant. In practice, you'd probably want to your poll definition to contain; a conditional branch of some form. At the moment, PlaceSafepoints can insert safepoint polls at method entry and; loop backedges locations. Extending this to work with return polls would be; straight forward if desired. PlaceSafepoints includes a number of optimizations to avoid placing safepoint; polls at particular sites unless needed to ensure timely execution of a poll; under normal conditions. PlaceSafepoints does not attempt to ensure timely; execution of a poll under worst case conditions such as heavy system paging. The implementation of a safepoint poll action is specified by looking up a; function of the name ``gc.safepoint_poll`` in the containing Module. The body; of this function is inserted at each poll site desired. While calls or invokes; inside this method are transformed to a ``gc.statepoints``, recursive poll; insertion is not performed. This pass",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:1318,Deployability,update,update,1318,"age; collection. By now, these mechanisms are well proven with commercial java; implementation with a fully relocating collector having shipped using them.; There are a couple places where bugs might still linger; these are called out; below. They are still listed as ""experimental"" to indicate that no forward or backward; compatibility guarantees are offered across versions. If your use case is such; that you need some form of forward compatibility guarantee, please raise the; issue on the llvm-dev mailing list. LLVM still supports an alternate mechanism for conservative garbage collection; support using the ``gcroot`` intrinsic. The ``gcroot`` mechanism is mostly of; historical interest at this point with one exception - its implementation of; shadow stacks has been used successfully by a number of language frontends and; is still supported. Overview & Core Concepts; ========================. To collect dead objects, garbage collectors must be able to identify; any references to objects contained within executing code, and,; depending on the collector, potentially update them. The collector; does not need this information at all points in code - that would make; the problem much harder - but only at well-defined points in the; execution known as 'safepoints' For most collectors, it is sufficient; to track at least one copy of each unique pointer value. However, for; a collector which wishes to relocate objects directly reachable from; running code, a higher standard is required. One additional challenge is that the compiler may compute intermediate; results (""derived pointers"") which point outside of the allocation or; even into the middle of another allocation. The eventual use of this; intermediate value must yield an address within the bounds of the; allocation, but such ""exterior derived pointers"" may be visible to the; collector. Given this, a garbage collector can not safely rely on the; runtime value of an address to indicate the object it is associated; wit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:3073,Deployability,update,update,3073,"sible to the; collector. Given this, a garbage collector can not safely rely on the; runtime value of an address to indicate the object it is associated; with. If the garbage collector wishes to move any object, the; compiler must provide a mapping, for each pointer, to an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage collectors are organized in terms of three abstractions:; load barriers, store barriers, and safepoints. #. A load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the collector can safely use that information. The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focuses on the last item - compiler support for; safepoints in generated code. We will assume that an outside; mechanism has decided where to place safepoints. From our; perspective, all safepoints will be function calls. To support; relocation of objects directly reachable from values in compiled",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:4298,Deployability,update,update,4298,"etes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the collector can safely use that information. The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focuses on the last item - compiler support for; safepoints in generated code. We will assume that an outside; mechanism has decided where to place safepoints. From our; perspective, all safepoints will be function calls. To support; relocation of objects directly reachable from values in compiled code,; the collector must be able to:. #. identify every copy of a pointer (including copies introduced by; the compiler itself) at the safepoint,; #. identify which object each pointer relates to, and; #. potentially update each of those copies. This document describes the mechanism by which an LLVM based compiler; can provide this information to a language runtime/collector, and; ensure that all pointers can be read and updated if desired. Abstract Machine Model; ^^^^^^^^^^^^^^^^^^^^^^^. At a high level, LLVM has been extended to support compiling to an abstract; machine which extends the actual target with a non-integral pointer type; suitable for representing a garbage collected reference to an object. In; particular, such non-integral pointer type have no defined mapping to an; integer representation. This semantic quirk allows the runtime to pick a; integer mapping for each point in the program allowing relocations of objects; without visible effects. This high level abstract machine model is used for most of the optimizer. As; a result, transform passes do not need to be extended to look through explicit; relocation sequence. Before starting code generation, we switch; representations to an explicit ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:4506,Deployability,update,updated,4506," that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the collector can safely use that information. The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focuses on the last item - compiler support for; safepoints in generated code. We will assume that an outside; mechanism has decided where to place safepoints. From our; perspective, all safepoints will be function calls. To support; relocation of objects directly reachable from values in compiled code,; the collector must be able to:. #. identify every copy of a pointer (including copies introduced by; the compiler itself) at the safepoint,; #. identify which object each pointer relates to, and; #. potentially update each of those copies. This document describes the mechanism by which an LLVM based compiler; can provide this information to a language runtime/collector, and; ensure that all pointers can be read and updated if desired. Abstract Machine Model; ^^^^^^^^^^^^^^^^^^^^^^^. At a high level, LLVM has been extended to support compiling to an abstract; machine which extends the actual target with a non-integral pointer type; suitable for representing a garbage collected reference to an object. In; particular, such non-integral pointer type have no defined mapping to an; integer representation. This semantic quirk allows the runtime to pick a; integer mapping for each point in the program allowing relocations of objects; without visible effects. This high level abstract machine model is used for most of the optimizer. As; a result, transform passes do not need to be extended to look through explicit; relocation sequence. Before starting code generation, we switch; representations to an explicit form. The exact location chosen for lowering; is an implementation detail. Note that most of the value of the abstract m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:6535,Deployability,update,updates,6535,"ompiler which; supports only a non-relocating collector, you may wish to consider starting; with the fully explicit form. Warning: There is one currently known semantic hole in the definition of; non-integral pointers which has not been addressed upstream. To work around; this, you need to disable speculation of loads unless the memory type; (non-integral pointer vs anything else) is known to unchanged. That is, it is; not safe to speculate a load if doing causes a non-integral pointer value to; be loaded as any other type or vice versa. In practice, this restriction is; well isolated to isSafeToSpeculate in ValueTracking.cpp. Explicit Representation; ^^^^^^^^^^^^^^^^^^^^^^^. A frontend could directly generate this low level explicit form, but; doing so may inhibit optimization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the optimizer; from performing unsound optimizations.; #. recording a mapping of live pointers (and the allocation they're; associated with) for each statepoint. At the most abstract level, inserting a safepoint can be thought of as; replacing a call instruction with a call to a multiple return value; function which both calls the original target of the call, returns; its result, and returns updated values for any live pointers to; garbage collected objects. Note that the task of identifying all live pointers to garbage; collec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:7384,Deployability,update,updated,7384,"imization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the optimizer; from performing unsound optimizations.; #. recording a mapping of live pointers (and the allocation they're; associated with) for each statepoint. At the most abstract level, inserting a safepoint can be thought of as; replacing a call instruction with a call to a multiple return value; function which both calls the original target of the call, returns; its result, and returns updated values for any live pointers to; garbage collected objects. Note that the task of identifying all live pointers to garbage; collected values, transforming the IR to expose a pointer giving the; base object for every such live pointer, and inserting all the; intrinsics correctly is explicitly out of scope for this document.; The recommended approach is to use the :ref:`utility passes; <statepoint-utilities>` described below. This abstract function call is concretely represented by a sequence of; intrinsic calls known collectively as a ""statepoint relocation sequence"". Let's consider a simple call in LLVM IR:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; call void ()* @foo(); ret i8 addrspace(1)* %obj; }. Depending on our language we may need to allow a safepoint during the execution; of ``foo``. If so, we need to let the collector update l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:8293,Deployability,update,update,8293,"ction which both calls the original target of the call, returns; its result, and returns updated values for any live pointers to; garbage collected objects. Note that the task of identifying all live pointers to garbage; collected values, transforming the IR to expose a pointer giving the; base object for every such live pointer, and inserting all the; intrinsics correctly is explicitly out of scope for this document.; The recommended approach is to use the :ref:`utility passes; <statepoint-utilities>` described below. This abstract function call is concretely represented by a sequence of; intrinsic calls known collectively as a ""statepoint relocation sequence"". Let's consider a simple call in LLVM IR:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; call void ()* @foo(); ret i8 addrspace(1)* %obj; }. Depending on our language we may need to allow a safepoint during the execution; of ``foo``. If so, we need to let the collector update local values in the; current frame. If we don't, we'll be accessing a potential invalid reference; once we eventually return from the call. In this example, we need to relocate the SSA value ``%obj``. Since we can't; actually change the value in the SSA value ``%obj``, we need to introduce a new; SSA value ``%obj.relocated`` which represents the potentially changed value of; ``%obj`` after the safepoint and update any following uses appropriately. The; resulting relocation sequence is:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; %0 = call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj); %obj.relocated = call coldcc i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %0, i32 7, i32 7); ret i8 addrspace(1)* %obj.relocated; }. Ideally, this sequence would have been represented as a M argument, N; ret",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:8711,Deployability,update,update,8711,"y out of scope for this document.; The recommended approach is to use the :ref:`utility passes; <statepoint-utilities>` described below. This abstract function call is concretely represented by a sequence of; intrinsic calls known collectively as a ""statepoint relocation sequence"". Let's consider a simple call in LLVM IR:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; call void ()* @foo(); ret i8 addrspace(1)* %obj; }. Depending on our language we may need to allow a safepoint during the execution; of ``foo``. If so, we need to let the collector update local values in the; current frame. If we don't, we'll be accessing a potential invalid reference; once we eventually return from the call. In this example, we need to relocate the SSA value ``%obj``. Since we can't; actually change the value in the SSA value ``%obj``, we need to introduce a new; SSA value ``%obj.relocated`` which represents the potentially changed value of; ``%obj`` after the safepoint and update any following uses appropriately. The; resulting relocation sequence is:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; %0 = call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj); %obj.relocated = call coldcc i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %0, i32 7, i32 7); ret i8 addrspace(1)* %obj.relocated; }. Ideally, this sequence would have been represented as a M argument, N; return value function (where M is the number of values being; relocated + the original call arguments and N is the original return; value + each relocated value), but LLVM does not easily support such a; representation. Instead, the statepoint intrinsic marks the actual site of the; safepoint or statepoint. The statepoint returns a token value (which; exists only at compile time). To get",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:10531,Deployability,update,update,10531," the actual site of the; safepoint or statepoint. The statepoint returns a token value (which; exists only at compile time). To get back the original return value; of the call, we use the ``gc.result`` intrinsic. To get the relocation; of each pointer in turn, we use the ``gc.relocate`` intrinsic with the; appropriate index. Note that both the ``gc.relocate`` and ``gc.result`` are; tied to the statepoint. The combination forms a ""statepoint relocation; sequence"" and represents the entirety of a parseable call or 'statepoint'. When lowered, this example would generate the following x86 assembly:. .. code-block:: gas. 	 .globl	test1; 	 .align	16, 0x90; 	 pushq	%rax; 	 callq	foo; .Ltmp1:; 	 movq	(%rsp), %rax # This load is redundant (oops!); 	 popq	%rdx; 	 retq. Each of the potentially relocated values has been spilled to the; stack, and a record of that location has been recorded to the; :ref:`Stack Map section <stackmap-section>`. If the garbage collector; needs to update any of these pointers during the call, it knows; exactly what to change. The relevant parts of the StackMap section for our example are:. .. code-block:: gas. # This describes the call site; # Stack Maps: callsite 2882400000; 	 .quad	2882400000; 	 .long	.Ltmp1-test1; 	 .short	0; # .. 8 entries skipped ..; # This entry describes the spill slot which is directly addressable; # off RSP with offset 0. Given the value was spilled with a pushq,; # that makes sense.; # Stack Maps: Loc 8: Direct RSP [encoding: .byte 2, .byte 8, .short 7, .int 0]; 	 .byte	2; 	 .byte	8; 	 .short	7; 	 .long	0. This example was taken from the tests for the :ref:`RewriteStatepointsForGC`; utility pass. As such, its full StackMap can be easily examined with the; following command. .. code-block:: bash. opt -rewrite-statepoints-for-gc test/Transforms/RewriteStatepointsForGC/basics.ll -S | llc -debug-only=stackmaps. Simplifications for Non-Relocating GCs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Some of the complexity in the previous",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:20064,Deployability,update,updated,20064," movq	(%rsp), %rax # This load is redundant (oops!); 	 popq	%rdx; 	 retq. Note that the design as presented above is not fully implemented: in particular,; strategy-specific lowering is not present, and all GC transitions are emitted as; as single no-op before and after the call instruction. These no-ops are often; removed by the backend during dead machine instruction elimination. Before the abstract machine model is lowered to the explicit statepoint model; of relocations by the :ref:`RewriteStatepointsForGC` pass it is possible for; any derived pointer to get its base pointer and offset from the base pointer; by using the ``gc.get.pointer.base`` and the ``gc.get.pointer.offset``; intrinsics respectively. These intrinsics are inlined by the; :ref:`RewriteStatepointsForGC` pass and must not be used after this pass. .. _statepoint-stackmap-format:. Stack Map Format; ================. Locations for each pointer value which may need read and/or updated by; the runtime or collector are provided in a separate section of the; generated object file as specified in the PatchPoint documentation.; This special section is encoded per the; :ref:`Stack Map format <stackmap-format>`. The general expectation is that a JIT compiler will parse and discard this; format; it is not particularly memory efficient. If you need an alternate; format (e.g. for an ahead of time compiler), see discussion under; :ref: `open work items <OpenWork>` below. Each statepoint generates the following Locations:. * Constant which describes the calling convention of the call target. This; constant is a valid :ref:`calling convention identifier <callingconv>` for; the version of LLVM used to generate the stackmap. No additional compatibility; guarantees are made for this constant over what LLVM provides elsewhere w.r.t.; these identifiers.; * Constant which describes the flags passed to the statepoint intrinsic; * Constant which describes number of following deopt *Locations* (not; operands). Will be 0 i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:21949,Deployability,update,updated,21949,"e w.r.t.; these identifiers.; * Constant which describes the flags passed to the statepoint intrinsic; * Constant which describes number of following deopt *Locations* (not; operands). Will be 0 if no ""deopt"" bundle is provided.; * Variable number of Locations, one for each deopt parameter listed in the; ""deopt"" operand bundle. At the moment, only deopt parameters with a bitwidth; of 64 bits or less are supported. Values of a type larger than 64 bits can be; specified and reported only if a) the value is constant at the call site, and; b) the constant can be represented with less than 64 bits (assuming zero; extension to the original bitwidth).; * Variable number of relocation records, each of which consists of; exactly two Locations. Relocation records are described in detail; below. Each relocation record provides sufficient information for a collector to; relocate one or more derived pointers. Each record consists of a pair of; Locations. The second element in the record represents the pointer (or; pointers) which need updated. The first element in the record provides a; pointer to the base of the object with which the pointer(s) being relocated is; associated. This information is required for handling generalized derived; pointers since a pointer may be outside the bounds of the original allocation,; but still needs to be relocated with the allocation. Additionally:. * It is guaranteed that the base pointer must also appear explicitly as a; relocation pair if used after the statepoint.; * There may be fewer relocation records then gc parameters in the IR; statepoint. Each *unique* pair will occur at least once; duplicates; are possible.; * The Locations within each record may either be of pointer size or a; multiple of pointer size. In the later case, the record must be; interpreted as describing a sequence of pointers and their corresponding; base pointers. If the Location is of size N x sizeof(pointer), then; there will be N records of one pointer each containe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:28175,Deployability,patch,patchable,28175,"ntend that doesn't; want to manually reason about liveness, base pointers, or relocation when; constructing IR. As currently implemented, RewriteStatepointsForGC must be; run after SSA construction (i.e. mem2ref). RewriteStatepointsForGC will ensure that appropriate base pointers are listed; for every relocation created. It will do so by duplicating code as needed to; propagate the base pointer associated with each pointer being relocated to; the appropriate safepoints. The implementation assumes that the following; IR constructs produce base pointers: loads from the heap, addresses of global; variables, function arguments, function return values. Constant pointers (such; as null) are also assumed to be base pointers. In practice, this constraint; can be relaxed to producing interior derived pointers provided the target; collector can find the associated allocation from an arbitrary interior; derived pointer. By default RewriteStatepointsForGC passes in ``0xABCDEF00`` as the statepoint; ID and ``0`` as the number of patchable bytes to the newly constructed; ``gc.statepoint``. These values can be configured on a per-callsite; basis using the attributes ``""statepoint-id""`` and; ``""statepoint-num-patch-bytes""``. If a call site is marked with a; ``""statepoint-id""`` function attribute and its value is a positive; integer (represented as a string), then that value is used as the ID; of the newly constructed ``gc.statepoint``. If a call site is marked; with a ``""statepoint-num-patch-bytes""`` function attribute and its; value is a positive integer, then that value is used as the 'num patch; bytes' parameter of the newly constructed ``gc.statepoint``. The; ``""statepoint-id""`` and ``""statepoint-num-patch-bytes""`` attributes; are not propagated to the ``gc.statepoint`` call or invoke if they; could be successfully parsed. In practice, RewriteStatepointsForGC should be run much later in the pass; pipeline, after most optimization is already done. This helps to improve; the quali",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:28356,Deployability,patch,patch-bytes,28356,"C must be; run after SSA construction (i.e. mem2ref). RewriteStatepointsForGC will ensure that appropriate base pointers are listed; for every relocation created. It will do so by duplicating code as needed to; propagate the base pointer associated with each pointer being relocated to; the appropriate safepoints. The implementation assumes that the following; IR constructs produce base pointers: loads from the heap, addresses of global; variables, function arguments, function return values. Constant pointers (such; as null) are also assumed to be base pointers. In practice, this constraint; can be relaxed to producing interior derived pointers provided the target; collector can find the associated allocation from an arbitrary interior; derived pointer. By default RewriteStatepointsForGC passes in ``0xABCDEF00`` as the statepoint; ID and ``0`` as the number of patchable bytes to the newly constructed; ``gc.statepoint``. These values can be configured on a per-callsite; basis using the attributes ``""statepoint-id""`` and; ``""statepoint-num-patch-bytes""``. If a call site is marked with a; ``""statepoint-id""`` function attribute and its value is a positive; integer (represented as a string), then that value is used as the ID; of the newly constructed ``gc.statepoint``. If a call site is marked; with a ``""statepoint-num-patch-bytes""`` function attribute and its; value is a positive integer, then that value is used as the 'num patch; bytes' parameter of the newly constructed ``gc.statepoint``. The; ``""statepoint-id""`` and ``""statepoint-num-patch-bytes""`` attributes; are not propagated to the ``gc.statepoint`` call or invoke if they; could be successfully parsed. In practice, RewriteStatepointsForGC should be run much later in the pass; pipeline, after most optimization is already done. This helps to improve; the quality of the generated code when compiled with garbage collection support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:28638,Deployability,patch,patch-bytes,28638,"ointers: loads from the heap, addresses of global; variables, function arguments, function return values. Constant pointers (such; as null) are also assumed to be base pointers. In practice, this constraint; can be relaxed to producing interior derived pointers provided the target; collector can find the associated allocation from an arbitrary interior; derived pointer. By default RewriteStatepointsForGC passes in ``0xABCDEF00`` as the statepoint; ID and ``0`` as the number of patchable bytes to the newly constructed; ``gc.statepoint``. These values can be configured on a per-callsite; basis using the attributes ``""statepoint-id""`` and; ``""statepoint-num-patch-bytes""``. If a call site is marked with a; ``""statepoint-id""`` function attribute and its value is a positive; integer (represented as a string), then that value is used as the ID; of the newly constructed ``gc.statepoint``. If a call site is marked; with a ``""statepoint-num-patch-bytes""`` function attribute and its; value is a positive integer, then that value is used as the 'num patch; bytes' parameter of the newly constructed ``gc.statepoint``. The; ``""statepoint-id""`` and ``""statepoint-num-patch-bytes""`` attributes; are not propagated to the ``gc.statepoint`` call or invoke if they; could be successfully parsed. In practice, RewriteStatepointsForGC should be run much later in the pass; pipeline, after most optimization is already done. This helps to improve; the quality of the generated code when compiled with garbage collection support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowering; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. As a part of lowering to the explicit model of relocations; RewriteStatepointsForGC performs GC specific lowering for the following; intrinsics:. * ``gc.get.pointer.base``; * ``gc.get.pointer.offset``; * ``llvm.memcpy.element.unordered.atomic.*``; * ``llvm.memmove.element.unordered.atomic.*``. There are two possible lowerings for the memc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:28746,Deployability,patch,patch,28746,"ointers: loads from the heap, addresses of global; variables, function arguments, function return values. Constant pointers (such; as null) are also assumed to be base pointers. In practice, this constraint; can be relaxed to producing interior derived pointers provided the target; collector can find the associated allocation from an arbitrary interior; derived pointer. By default RewriteStatepointsForGC passes in ``0xABCDEF00`` as the statepoint; ID and ``0`` as the number of patchable bytes to the newly constructed; ``gc.statepoint``. These values can be configured on a per-callsite; basis using the attributes ``""statepoint-id""`` and; ``""statepoint-num-patch-bytes""``. If a call site is marked with a; ``""statepoint-id""`` function attribute and its value is a positive; integer (represented as a string), then that value is used as the ID; of the newly constructed ``gc.statepoint``. If a call site is marked; with a ``""statepoint-num-patch-bytes""`` function attribute and its; value is a positive integer, then that value is used as the 'num patch; bytes' parameter of the newly constructed ``gc.statepoint``. The; ``""statepoint-id""`` and ``""statepoint-num-patch-bytes""`` attributes; are not propagated to the ``gc.statepoint`` call or invoke if they; could be successfully parsed. In practice, RewriteStatepointsForGC should be run much later in the pass; pipeline, after most optimization is already done. This helps to improve; the quality of the generated code when compiled with garbage collection support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowering; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. As a part of lowering to the explicit model of relocations; RewriteStatepointsForGC performs GC specific lowering for the following; intrinsics:. * ``gc.get.pointer.base``; * ``gc.get.pointer.offset``; * ``llvm.memcpy.element.unordered.atomic.*``; * ``llvm.memmove.element.unordered.atomic.*``. There are two possible lowerings for the memc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:28861,Deployability,patch,patch-bytes,28861,"ers. In practice, this constraint; can be relaxed to producing interior derived pointers provided the target; collector can find the associated allocation from an arbitrary interior; derived pointer. By default RewriteStatepointsForGC passes in ``0xABCDEF00`` as the statepoint; ID and ``0`` as the number of patchable bytes to the newly constructed; ``gc.statepoint``. These values can be configured on a per-callsite; basis using the attributes ``""statepoint-id""`` and; ``""statepoint-num-patch-bytes""``. If a call site is marked with a; ``""statepoint-id""`` function attribute and its value is a positive; integer (represented as a string), then that value is used as the ID; of the newly constructed ``gc.statepoint``. If a call site is marked; with a ``""statepoint-num-patch-bytes""`` function attribute and its; value is a positive integer, then that value is used as the 'num patch; bytes' parameter of the newly constructed ``gc.statepoint``. The; ``""statepoint-id""`` and ``""statepoint-num-patch-bytes""`` attributes; are not propagated to the ``gc.statepoint`` call or invoke if they; could be successfully parsed. In practice, RewriteStatepointsForGC should be run much later in the pass; pipeline, after most optimization is already done. This helps to improve; the quality of the generated code when compiled with garbage collection support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowering; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. As a part of lowering to the explicit model of relocations; RewriteStatepointsForGC performs GC specific lowering for the following; intrinsics:. * ``gc.get.pointer.base``; * ``gc.get.pointer.offset``; * ``llvm.memcpy.element.unordered.atomic.*``; * ``llvm.memmove.element.unordered.atomic.*``. There are two possible lowerings for the memcpy and memmove operations:; GC leaf lowering and GC parseable lowering. If a call is explicitly marked with; ""gc-leaf-function"" attribute the call is lowered to a GC leaf ca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:29061,Deployability,pipeline,pipeline,29061," derived pointer. By default RewriteStatepointsForGC passes in ``0xABCDEF00`` as the statepoint; ID and ``0`` as the number of patchable bytes to the newly constructed; ``gc.statepoint``. These values can be configured on a per-callsite; basis using the attributes ``""statepoint-id""`` and; ``""statepoint-num-patch-bytes""``. If a call site is marked with a; ``""statepoint-id""`` function attribute and its value is a positive; integer (represented as a string), then that value is used as the ID; of the newly constructed ``gc.statepoint``. If a call site is marked; with a ``""statepoint-num-patch-bytes""`` function attribute and its; value is a positive integer, then that value is used as the 'num patch; bytes' parameter of the newly constructed ``gc.statepoint``. The; ``""statepoint-id""`` and ``""statepoint-num-patch-bytes""`` attributes; are not propagated to the ``gc.statepoint`` call or invoke if they; could be successfully parsed. In practice, RewriteStatepointsForGC should be run much later in the pass; pipeline, after most optimization is already done. This helps to improve; the quality of the generated code when compiled with garbage collection support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowering; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. As a part of lowering to the explicit model of relocations; RewriteStatepointsForGC performs GC specific lowering for the following; intrinsics:. * ``gc.get.pointer.base``; * ``gc.get.pointer.offset``; * ``llvm.memcpy.element.unordered.atomic.*``; * ``llvm.memmove.element.unordered.atomic.*``. There are two possible lowerings for the memcpy and memmove operations:; GC leaf lowering and GC parseable lowering. If a call is explicitly marked with; ""gc-leaf-function"" attribute the call is lowered to a GC leaf call to; '``__llvm_memcpy_element_unordered_atomic_*``' or; '``__llvm_memmove_element_unordered_atomic_*``' symbol. Such a call can not; take a safepoint. Otherwise, the call is made G",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:35024,Deployability,integrat,integration,35024,"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Support for languages which allow unmanaged pointers to garbage collected; objects (i.e. pass a pointer to an object to a C routine) in the abstract; machine model. At the moment, the best idea on how to approach this; involves an intrinsic or opaque function which hides the connection between; the reference value and the raw pointer. The problem is that having a; ptrtoint or inttoptr cast (which is common for such use cases) breaks the; rules used for inferring base pointers for arbitrary references when; lowering out of the abstract model to the explicit physical model. Note; that a frontend which lowers directly to the physical model doesn't have; any problems here. Objects on the Stack; ^^^^^^^^^^^^^^^^^^^^. As noted above, the explicit lowering supports objects allocated on the; stack provided the collector can find a heap map given the stack address. The missing pieces are a) integration with rewriting (RS4GC) from the; abstract machine model and b) support for optionally decomposing on stack; objects so as not to require heap maps for them. The later is required; for ease of integration with some collectors. Lowering Quality and Representation Overhead; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The current statepoint lowering is known to be somewhat poor. In the very; long term, we'd like to integrate statepoints with the register allocator;; in the near term this is unlikely to happen. We've found the quality of; lowering to be relatively unimportant as hot-statepoints are almost always; inliner bugs. Concerns have been raised that the statepoint representation results in a; large amount of IR being produced for some examples and that this; contributes to higher than expected memory usage and compile times. There's; no immediate plans to make changes due to this, but alternate models may be; explored in the future. Relocations Along Exceptional Edges; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Relocations along exceptional pat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:35228,Deployability,integrat,integration,35228,"ointer to an object to a C routine) in the abstract; machine model. At the moment, the best idea on how to approach this; involves an intrinsic or opaque function which hides the connection between; the reference value and the raw pointer. The problem is that having a; ptrtoint or inttoptr cast (which is common for such use cases) breaks the; rules used for inferring base pointers for arbitrary references when; lowering out of the abstract model to the explicit physical model. Note; that a frontend which lowers directly to the physical model doesn't have; any problems here. Objects on the Stack; ^^^^^^^^^^^^^^^^^^^^. As noted above, the explicit lowering supports objects allocated on the; stack provided the collector can find a heap map given the stack address. The missing pieces are a) integration with rewriting (RS4GC) from the; abstract machine model and b) support for optionally decomposing on stack; objects so as not to require heap maps for them. The later is required; for ease of integration with some collectors. Lowering Quality and Representation Overhead; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The current statepoint lowering is known to be somewhat poor. In the very; long term, we'd like to integrate statepoints with the register allocator;; in the near term this is unlikely to happen. We've found the quality of; lowering to be relatively unimportant as hot-statepoints are almost always; inliner bugs. Concerns have been raised that the statepoint representation results in a; large amount of IR being produced for some examples and that this; contributes to higher than expected memory usage and compile times. There's; no immediate plans to make changes due to this, but alternate models may be; explored in the future. Relocations Along Exceptional Edges; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Relocations along exceptional paths are currently broken in ToT. In; particular, there is current no way to represent a rethrow on a path which; also has relocations",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:35453,Deployability,integrat,integrate,35453,"hat having a; ptrtoint or inttoptr cast (which is common for such use cases) breaks the; rules used for inferring base pointers for arbitrary references when; lowering out of the abstract model to the explicit physical model. Note; that a frontend which lowers directly to the physical model doesn't have; any problems here. Objects on the Stack; ^^^^^^^^^^^^^^^^^^^^. As noted above, the explicit lowering supports objects allocated on the; stack provided the collector can find a heap map given the stack address. The missing pieces are a) integration with rewriting (RS4GC) from the; abstract machine model and b) support for optionally decomposing on stack; objects so as not to require heap maps for them. The later is required; for ease of integration with some collectors. Lowering Quality and Representation Overhead; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The current statepoint lowering is known to be somewhat poor. In the very; long term, we'd like to integrate statepoints with the register allocator;; in the near term this is unlikely to happen. We've found the quality of; lowering to be relatively unimportant as hot-statepoints are almost always; inliner bugs. Concerns have been raised that the statepoint representation results in a; large amount of IR being produced for some examples and that this; contributes to higher than expected memory usage and compile times. There's; no immediate plans to make changes due to this, but alternate models may be; explored in the future. Relocations Along Exceptional Edges; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Relocations along exceptional paths are currently broken in ToT. In; particular, there is current no way to represent a rethrow on a path which; also has relocations. See `this llvm-dev discussion; <https://groups.google.com/forum/#!topic/llvm-dev/AE417XjgxvI>`_ for more; detail. Bugs and Enhancements; =====================. Currently known bugs and enhancements under consideration can be; tracked by performing a `bu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:36847,Deployability,patch,patches,36847,"ind a heap map given the stack address. The missing pieces are a) integration with rewriting (RS4GC) from the; abstract machine model and b) support for optionally decomposing on stack; objects so as not to require heap maps for them. The later is required; for ease of integration with some collectors. Lowering Quality and Representation Overhead; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The current statepoint lowering is known to be somewhat poor. In the very; long term, we'd like to integrate statepoints with the register allocator;; in the near term this is unlikely to happen. We've found the quality of; lowering to be relatively unimportant as hot-statepoints are almost always; inliner bugs. Concerns have been raised that the statepoint representation results in a; large amount of IR being produced for some examples and that this; contributes to higher than expected memory usage and compile times. There's; no immediate plans to make changes due to this, but alternate models may be; explored in the future. Relocations Along Exceptional Edges; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Relocations along exceptional paths are currently broken in ToT. In; particular, there is current no way to represent a rethrow on a path which; also has relocations. See `this llvm-dev discussion; <https://groups.google.com/forum/#!topic/llvm-dev/AE417XjgxvI>`_ for more; detail. Bugs and Enhancements; =====================. Currently known bugs and enhancements under consideration can be; tracked by performing a `bugzilla search; <https://bugs.llvm.org/buglist.cgi?cmdtype=runnamed&namedcmd=Statepoint%20Bugs&list_id=64342>`_; for [Statepoint] in the summary field. When filing new bugs, please; use this tag so that interested parties see the newly filed bug. As; with most LLVM features, design discussions take place on the `Discourse forums <https://discourse.llvm.org>`_ and patches; should be sent to `llvm-commits; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_ for review.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:20411,Energy Efficiency,efficient,efficient,20411,"op before and after the call instruction. These no-ops are often; removed by the backend during dead machine instruction elimination. Before the abstract machine model is lowered to the explicit statepoint model; of relocations by the :ref:`RewriteStatepointsForGC` pass it is possible for; any derived pointer to get its base pointer and offset from the base pointer; by using the ``gc.get.pointer.base`` and the ``gc.get.pointer.offset``; intrinsics respectively. These intrinsics are inlined by the; :ref:`RewriteStatepointsForGC` pass and must not be used after this pass. .. _statepoint-stackmap-format:. Stack Map Format; ================. Locations for each pointer value which may need read and/or updated by; the runtime or collector are provided in a separate section of the; generated object file as specified in the PatchPoint documentation.; This special section is encoded per the; :ref:`Stack Map format <stackmap-format>`. The general expectation is that a JIT compiler will parse and discard this; format; it is not particularly memory efficient. If you need an alternate; format (e.g. for an ahead of time compiler), see discussion under; :ref: `open work items <OpenWork>` below. Each statepoint generates the following Locations:. * Constant which describes the calling convention of the call target. This; constant is a valid :ref:`calling convention identifier <callingconv>` for; the version of LLVM used to generate the stackmap. No additional compatibility; guarantees are made for this constant over what LLVM provides elsewhere w.r.t.; these identifiers.; * Constant which describes the flags passed to the statepoint intrinsic; * Constant which describes number of following deopt *Locations* (not; operands). Will be 0 if no ""deopt"" bundle is provided.; * Variable number of Locations, one for each deopt parameter listed in the; ""deopt"" operand bundle. At the moment, only deopt parameters with a bitwidth; of 64 bits or less are supported. Values of a type larger than 6",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:24225,Energy Efficiency,schedul,scheduling,24225,"apRecord will be empty for a statepoint; record. Safepoint Semantics & Verification; ==================================. The fundamental correctness property for the compiled code's; correctness w.r.t. the garbage collector is a dynamic one. It must be; the case that there is no dynamic trace such that an operation; involving a potentially relocated pointer is observably-after a; safepoint which could relocate it. 'observably-after' is this usage; means that an outside observer could observe this sequence of events; in a way which precludes the operation being performed before the; safepoint. To understand why this 'observable-after' property is required,; consider a null comparison performed on the original copy of a; relocated pointer. Assuming that control flow follows the safepoint,; there is no way to observe externally whether the null comparison is; performed before or after the safepoint. (Remember, the original; Value is unmodified by the safepoint.) The compiler is free to make; either scheduling choice. The actual correctness property implemented is slightly stronger than; this. We require that there be no *static path* on which a; potentially relocated pointer is 'observably-after' it may have been; relocated. This is slightly stronger than is strictly necessary (and; thus may disallow some otherwise valid programs), but greatly; simplifies reasoning about correctness of the compiled code. By construction, this property will be upheld by the optimizer if; correctly established in the source IR. This is a key invariant of; the design. The existing IR Verifier pass has been extended to check most of the; local restrictions on the intrinsics mentioned in their respective; documentation. The current implementation in LLVM does not check the; key relocation invariant, but this is ongoing work on developing such; a verifier. Please ask on llvm-dev if you're interested in; experimenting with the current version. .. _statepoint-utilities:. Utility Passes for Safe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:34906,Energy Efficiency,allocate,allocated,34906,"nd.; Today, only Aarch64 and X86_64 are supported. .. _OpenWork:. Limitations and Half Baked Ideas; ================================. Mixing References and Raw Pointers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Support for languages which allow unmanaged pointers to garbage collected; objects (i.e. pass a pointer to an object to a C routine) in the abstract; machine model. At the moment, the best idea on how to approach this; involves an intrinsic or opaque function which hides the connection between; the reference value and the raw pointer. The problem is that having a; ptrtoint or inttoptr cast (which is common for such use cases) breaks the; rules used for inferring base pointers for arbitrary references when; lowering out of the abstract model to the explicit physical model. Note; that a frontend which lowers directly to the physical model doesn't have; any problems here. Objects on the Stack; ^^^^^^^^^^^^^^^^^^^^. As noted above, the explicit lowering supports objects allocated on the; stack provided the collector can find a heap map given the stack address. The missing pieces are a) integration with rewriting (RS4GC) from the; abstract machine model and b) support for optionally decomposing on stack; objects so as not to require heap maps for them. The later is required; for ease of integration with some collectors. Lowering Quality and Representation Overhead; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The current statepoint lowering is known to be somewhat poor. In the very; long term, we'd like to integrate statepoints with the register allocator;; in the near term this is unlikely to happen. We've found the quality of; lowering to be relatively unimportant as hot-statepoints are almost always; inliner bugs. Concerns have been raised that the statepoint representation results in a; large amount of IR being produced for some examples and that this; contributes to higher than expected memory usage and compile times. There's; no immediate plans to make changes du",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:1278,Integrability,depend,depending,1278,"age; collection. By now, these mechanisms are well proven with commercial java; implementation with a fully relocating collector having shipped using them.; There are a couple places where bugs might still linger; these are called out; below. They are still listed as ""experimental"" to indicate that no forward or backward; compatibility guarantees are offered across versions. If your use case is such; that you need some form of forward compatibility guarantee, please raise the; issue on the llvm-dev mailing list. LLVM still supports an alternate mechanism for conservative garbage collection; support using the ``gcroot`` intrinsic. The ``gcroot`` mechanism is mostly of; historical interest at this point with one exception - its implementation of; shadow stacks has been used successfully by a number of language frontends and; is still supported. Overview & Core Concepts; ========================. To collect dead objects, garbage collectors must be able to identify; any references to objects contained within executing code, and,; depending on the collector, potentially update them. The collector; does not need this information at all points in code - that would make; the problem much harder - but only at well-defined points in the; execution known as 'safepoints' For most collectors, it is sufficient; to track at least one copy of each unique pointer value. However, for; a collector which wishes to relocate objects directly reachable from; running code, a higher standard is required. One additional challenge is that the compiler may compute intermediate; results (""derived pointers"") which point outside of the allocation or; even into the middle of another allocation. The eventual use of this; intermediate value must yield an address within the bounds of the; allocation, but such ""exterior derived pointers"" may be visible to the; collector. Given this, a garbage collector can not safely rely on the; runtime value of an address to indicate the object it is associated; wit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:3569,Integrability,protocol,protocol,3569,"load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the collector can safely use that information. The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focuses on the last item - compiler support for; safepoints in generated code. We will assume that an outside; mechanism has decided where to place safepoints. From our; perspective, all safepoints will be function calls. To support; relocation of objects directly reachable from values in compiled code,; the collector must be able to:. #. identify every copy of a pointer (including copies introduced by; the compiler itself) at the safepoint,; #. identify which object each pointer relates to, and; #. potentially update each of those copies. This document describes the mechanism by which an LLVM based compiler; can provide this information to a language runtime/collector, and; ensure that all pointers can be read and updated if desired. Abstract Machine Model; ^^^^^^^^^^^^^^^^^^^^^^^. At a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:30063,Integrability,wrap,wrapping,30063,"; pipeline, after most optimization is already done. This helps to improve; the quality of the generated code when compiled with garbage collection support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowering; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. As a part of lowering to the explicit model of relocations; RewriteStatepointsForGC performs GC specific lowering for the following; intrinsics:. * ``gc.get.pointer.base``; * ``gc.get.pointer.offset``; * ``llvm.memcpy.element.unordered.atomic.*``; * ``llvm.memmove.element.unordered.atomic.*``. There are two possible lowerings for the memcpy and memmove operations:; GC leaf lowering and GC parseable lowering. If a call is explicitly marked with; ""gc-leaf-function"" attribute the call is lowered to a GC leaf call to; '``__llvm_memcpy_element_unordered_atomic_*``' or; '``__llvm_memmove_element_unordered_atomic_*``' symbol. Such a call can not; take a safepoint. Otherwise, the call is made GC parseable by wrapping the; call into a statepoint. This makes it possible to take a safepoint during; copy operation. Note that a GC parseable copy operation is not required to; take a safepoint. For example, a short copy operation may be performed without; taking a safepoint. GC parseable calls to '``llvm.memcpy.element.unordered.atomic.*``',; '``llvm.memmove.element.unordered.atomic.*``' intrinsics are lowered to calls; to '``__llvm_memcpy_element_unordered_atomic_safepoint_*``',; '``__llvm_memmove_element_unordered_atomic_safepoint_*``' symbols respectively.; This way the runtime can provide implementations of copy operations with and; without safepoints. GC parseable lowering also involves adjusting the arguments for the call.; Memcpy and memmove intrinsics take derived pointers as source and destination; arguments. If a copy operation takes a safepoint it might need to relocate the; underlying source and destination objects. This requires the corresponding base; pointers to be available in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:34253,Integrability,rout,routine,34253,"thod are transformed to a ``gc.statepoints``, recursive poll; insertion is not performed. This pass is useful for any language frontend which only has to support; garbage collection semantics at safepoints. If you need other abstract; frame information at safepoints (e.g. for deoptimization or introspection),; you can insert safepoint polls in the frontend. If you have the later case,; please ask on llvm-dev for suggestions. There's been a good amount of work; done on making such a scheme work well in practice which is not yet documented; here. Supported Architectures; =======================. Support for statepoint generation requires some code for each backend.; Today, only Aarch64 and X86_64 are supported. .. _OpenWork:. Limitations and Half Baked Ideas; ================================. Mixing References and Raw Pointers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Support for languages which allow unmanaged pointers to garbage collected; objects (i.e. pass a pointer to an object to a C routine) in the abstract; machine model. At the moment, the best idea on how to approach this; involves an intrinsic or opaque function which hides the connection between; the reference value and the raw pointer. The problem is that having a; ptrtoint or inttoptr cast (which is common for such use cases) breaks the; rules used for inferring base pointers for arbitrary references when; lowering out of the abstract model to the explicit physical model. Note; that a frontend which lowers directly to the physical model doesn't have; any problems here. Objects on the Stack; ^^^^^^^^^^^^^^^^^^^^. As noted above, the explicit lowering supports objects allocated on the; stack provided the collector can find a heap map given the stack address. The missing pieces are a) integration with rewriting (RS4GC) from the; abstract machine model and b) support for optionally decomposing on stack; objects so as not to require heap maps for them. The later is required; for ease of integration with some colle",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:35024,Integrability,integrat,integration,35024,"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Support for languages which allow unmanaged pointers to garbage collected; objects (i.e. pass a pointer to an object to a C routine) in the abstract; machine model. At the moment, the best idea on how to approach this; involves an intrinsic or opaque function which hides the connection between; the reference value and the raw pointer. The problem is that having a; ptrtoint or inttoptr cast (which is common for such use cases) breaks the; rules used for inferring base pointers for arbitrary references when; lowering out of the abstract model to the explicit physical model. Note; that a frontend which lowers directly to the physical model doesn't have; any problems here. Objects on the Stack; ^^^^^^^^^^^^^^^^^^^^. As noted above, the explicit lowering supports objects allocated on the; stack provided the collector can find a heap map given the stack address. The missing pieces are a) integration with rewriting (RS4GC) from the; abstract machine model and b) support for optionally decomposing on stack; objects so as not to require heap maps for them. The later is required; for ease of integration with some collectors. Lowering Quality and Representation Overhead; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The current statepoint lowering is known to be somewhat poor. In the very; long term, we'd like to integrate statepoints with the register allocator;; in the near term this is unlikely to happen. We've found the quality of; lowering to be relatively unimportant as hot-statepoints are almost always; inliner bugs. Concerns have been raised that the statepoint representation results in a; large amount of IR being produced for some examples and that this; contributes to higher than expected memory usage and compile times. There's; no immediate plans to make changes due to this, but alternate models may be; explored in the future. Relocations Along Exceptional Edges; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Relocations along exceptional pat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:35228,Integrability,integrat,integration,35228,"ointer to an object to a C routine) in the abstract; machine model. At the moment, the best idea on how to approach this; involves an intrinsic or opaque function which hides the connection between; the reference value and the raw pointer. The problem is that having a; ptrtoint or inttoptr cast (which is common for such use cases) breaks the; rules used for inferring base pointers for arbitrary references when; lowering out of the abstract model to the explicit physical model. Note; that a frontend which lowers directly to the physical model doesn't have; any problems here. Objects on the Stack; ^^^^^^^^^^^^^^^^^^^^. As noted above, the explicit lowering supports objects allocated on the; stack provided the collector can find a heap map given the stack address. The missing pieces are a) integration with rewriting (RS4GC) from the; abstract machine model and b) support for optionally decomposing on stack; objects so as not to require heap maps for them. The later is required; for ease of integration with some collectors. Lowering Quality and Representation Overhead; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The current statepoint lowering is known to be somewhat poor. In the very; long term, we'd like to integrate statepoints with the register allocator;; in the near term this is unlikely to happen. We've found the quality of; lowering to be relatively unimportant as hot-statepoints are almost always; inliner bugs. Concerns have been raised that the statepoint representation results in a; large amount of IR being produced for some examples and that this; contributes to higher than expected memory usage and compile times. There's; no immediate plans to make changes due to this, but alternate models may be; explored in the future. Relocations Along Exceptional Edges; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Relocations along exceptional paths are currently broken in ToT. In; particular, there is current no way to represent a rethrow on a path which; also has relocations",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:35453,Integrability,integrat,integrate,35453,"hat having a; ptrtoint or inttoptr cast (which is common for such use cases) breaks the; rules used for inferring base pointers for arbitrary references when; lowering out of the abstract model to the explicit physical model. Note; that a frontend which lowers directly to the physical model doesn't have; any problems here. Objects on the Stack; ^^^^^^^^^^^^^^^^^^^^. As noted above, the explicit lowering supports objects allocated on the; stack provided the collector can find a heap map given the stack address. The missing pieces are a) integration with rewriting (RS4GC) from the; abstract machine model and b) support for optionally decomposing on stack; objects so as not to require heap maps for them. The later is required; for ease of integration with some collectors. Lowering Quality and Representation Overhead; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The current statepoint lowering is known to be somewhat poor. In the very; long term, we'd like to integrate statepoints with the register allocator;; in the near term this is unlikely to happen. We've found the quality of; lowering to be relatively unimportant as hot-statepoints are almost always; inliner bugs. Concerns have been raised that the statepoint representation results in a; large amount of IR being produced for some examples and that this; contributes to higher than expected memory usage and compile times. There's; no immediate plans to make changes due to this, but alternate models may be; explored in the future. Relocations Along Exceptional Edges; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Relocations along exceptional paths are currently broken in ToT. In; particular, there is current no way to represent a rethrow on a path which; also has relocations. See `this llvm-dev discussion; <https://groups.google.com/forum/#!topic/llvm-dev/AE417XjgxvI>`_ for more; detail. Bugs and Enhancements; =====================. Currently known bugs and enhancements under consideration can be; tracked by performing a `bu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:4606,Modifiability,extend,extended,4606,"The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focuses on the last item - compiler support for; safepoints in generated code. We will assume that an outside; mechanism has decided where to place safepoints. From our; perspective, all safepoints will be function calls. To support; relocation of objects directly reachable from values in compiled code,; the collector must be able to:. #. identify every copy of a pointer (including copies introduced by; the compiler itself) at the safepoint,; #. identify which object each pointer relates to, and; #. potentially update each of those copies. This document describes the mechanism by which an LLVM based compiler; can provide this information to a language runtime/collector, and; ensure that all pointers can be read and updated if desired. Abstract Machine Model; ^^^^^^^^^^^^^^^^^^^^^^^. At a high level, LLVM has been extended to support compiling to an abstract; machine which extends the actual target with a non-integral pointer type; suitable for representing a garbage collected reference to an object. In; particular, such non-integral pointer type have no defined mapping to an; integer representation. This semantic quirk allows the runtime to pick a; integer mapping for each point in the program allowing relocations of objects; without visible effects. This high level abstract machine model is used for most of the optimizer. As; a result, transform passes do not need to be extended to look through explicit; relocation sequence. Before starting code generation, we switch; representations to an explicit form. The exact location chosen for lowering; is an implementation detail. Note that most of the value of the abstract machine model comes for collectors; which need to model potentially relocatable objects. For a compiler which; supports only a non-relocating collector, you may wish to consider starting; with the fully explicit form. Warning: There is one currently known sema",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:4666,Modifiability,extend,extends,4666,"The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focuses on the last item - compiler support for; safepoints in generated code. We will assume that an outside; mechanism has decided where to place safepoints. From our; perspective, all safepoints will be function calls. To support; relocation of objects directly reachable from values in compiled code,; the collector must be able to:. #. identify every copy of a pointer (including copies introduced by; the compiler itself) at the safepoint,; #. identify which object each pointer relates to, and; #. potentially update each of those copies. This document describes the mechanism by which an LLVM based compiler; can provide this information to a language runtime/collector, and; ensure that all pointers can be read and updated if desired. Abstract Machine Model; ^^^^^^^^^^^^^^^^^^^^^^^. At a high level, LLVM has been extended to support compiling to an abstract; machine which extends the actual target with a non-integral pointer type; suitable for representing a garbage collected reference to an object. In; particular, such non-integral pointer type have no defined mapping to an; integer representation. This semantic quirk allows the runtime to pick a; integer mapping for each point in the program allowing relocations of objects; without visible effects. This high level abstract machine model is used for most of the optimizer. As; a result, transform passes do not need to be extended to look through explicit; relocation sequence. Before starting code generation, we switch; representations to an explicit form. The exact location chosen for lowering; is an implementation detail. Note that most of the value of the abstract machine model comes for collectors; which need to model potentially relocatable objects. For a compiler which; supports only a non-relocating collector, you may wish to consider starting; with the fully explicit form. Warning: There is one currently known sema",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:5175,Modifiability,extend,extended,5175,"oduced by; the compiler itself) at the safepoint,; #. identify which object each pointer relates to, and; #. potentially update each of those copies. This document describes the mechanism by which an LLVM based compiler; can provide this information to a language runtime/collector, and; ensure that all pointers can be read and updated if desired. Abstract Machine Model; ^^^^^^^^^^^^^^^^^^^^^^^. At a high level, LLVM has been extended to support compiling to an abstract; machine which extends the actual target with a non-integral pointer type; suitable for representing a garbage collected reference to an object. In; particular, such non-integral pointer type have no defined mapping to an; integer representation. This semantic quirk allows the runtime to pick a; integer mapping for each point in the program allowing relocations of objects; without visible effects. This high level abstract machine model is used for most of the optimizer. As; a result, transform passes do not need to be extended to look through explicit; relocation sequence. Before starting code generation, we switch; representations to an explicit form. The exact location chosen for lowering; is an implementation detail. Note that most of the value of the abstract machine model comes for collectors; which need to model potentially relocatable objects. For a compiler which; supports only a non-relocating collector, you may wish to consider starting; with the fully explicit form. Warning: There is one currently known semantic hole in the definition of; non-integral pointers which has not been addressed upstream. To work around; this, you need to disable speculation of loads unless the memory type; (non-integral pointer vs anything else) is known to unchanged. That is, it is; not safe to speculate a load if doing causes a non-integral pointer value to; be loaded as any other type or vice versa. In practice, this restriction is; well isolated to isSafeToSpeculate in ValueTracking.cpp. Explicit Representatio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:6487,Modifiability,rewrite,rewrite,6487,"ompiler which; supports only a non-relocating collector, you may wish to consider starting; with the fully explicit form. Warning: There is one currently known semantic hole in the definition of; non-integral pointers which has not been addressed upstream. To work around; this, you need to disable speculation of loads unless the memory type; (non-integral pointer vs anything else) is known to unchanged. That is, it is; not safe to speculate a load if doing causes a non-integral pointer value to; be loaded as any other type or vice versa. In practice, this restriction is; well isolated to isSafeToSpeculate in ValueTracking.cpp. Explicit Representation; ^^^^^^^^^^^^^^^^^^^^^^^. A frontend could directly generate this low level explicit form, but; doing so may inhibit optimization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the optimizer; from performing unsound optimizations.; #. recording a mapping of live pointers (and the allocation they're; associated with) for each statepoint. At the most abstract level, inserting a safepoint can be thought of as; replacing a call instruction with a call to a multiple return value; function which both calls the original target of the call, returns; its result, and returns updated values for any live pointers to; garbage collected objects. Note that the task of identifying all live pointers to garbage; collec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:11326,Modifiability,rewrite,rewrite-statepoints-for-gc,11326,"es has been spilled to the; stack, and a record of that location has been recorded to the; :ref:`Stack Map section <stackmap-section>`. If the garbage collector; needs to update any of these pointers during the call, it knows; exactly what to change. The relevant parts of the StackMap section for our example are:. .. code-block:: gas. # This describes the call site; # Stack Maps: callsite 2882400000; 	 .quad	2882400000; 	 .long	.Ltmp1-test1; 	 .short	0; # .. 8 entries skipped ..; # This entry describes the spill slot which is directly addressable; # off RSP with offset 0. Given the value was spilled with a pushq,; # that makes sense.; # Stack Maps: Loc 8: Direct RSP [encoding: .byte 2, .byte 8, .short 7, .int 0]; 	 .byte	2; 	 .byte	8; 	 .short	7; 	 .long	0. This example was taken from the tests for the :ref:`RewriteStatepointsForGC`; utility pass. As such, its full StackMap can be easily examined with the; following command. .. code-block:: bash. opt -rewrite-statepoints-for-gc test/Transforms/RewriteStatepointsForGC/basics.ll -S | llc -debug-only=stackmaps. Simplifications for Non-Relocating GCs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Some of the complexity in the previous example is unnecessary for a; non-relocating collector. While a non-relocating collector still needs the; information about which location contain live references, it doesn't need to; represent explicit relocations. As such, the previously described explicit; lowering can be simplified to remove all of the ``gc.relocate`` intrinsic; calls and leave uses in terms of the original reference value. Here's the explicit lowering for the previous example for a non-relocating; collector:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj); ret i8 addrspace(1)* %obj; }. Recording On",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:15282,Modifiability,extend,extend,15282,"f allocations are known to the runtime system. ""Exterior derived pointers"" are outside the bounds of the associated object;; they may even fall within *another* allocations address range. As a result,; there is no way for a garbage collector to determine which allocation they; are associated with at runtime and compiler support is needed. The ``gc.relocate`` intrinsic supports an explicit operand for describing the; allocation associated with a derived pointer. This operand is frequently; referred to as the base operand, but does not strictly speaking have to be; a base pointer, but it does need to lie within the bounds of the associated; allocation. Some collectors may require that the operand be an actual base; pointer rather than merely an internal derived pointer. Note that during; lowering both the base and derived pointer operands are required to be live; over the associated call safepoint even if the base is otherwise unused; afterwards. If we extend our previous example to include a pointless derived pointer,; we get:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; %gep = getelementptr i8, i8 addrspace(1)* %obj, i64 20000; %token = call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj, i8 addrspace(1)* %gep); %obj.relocated = call i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %token, i32 7, i32 7); %gep.relocated = call i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %token, i32 7, i32 8); %p = getelementptr i8, i8 addrspace(1)* %gep, i64 -20000; ret i8 addrspace(1)* %p; }. Note that in this example %p and %obj.relocate are the same address and we; could replace one with the other, potentially removing the derived pointer; from the live set at the safepoint entirely. .. _gc_transition_args:. GC Transitions; ^^^^^^^^^^^^^^^^^^. As a practical consideration, many g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:17732,Modifiability,variab,variable,17732,"ode generation at the call site to; inform the collector of the transition. In order to support these needs, a; statepoint may be marked as a GC transition, and data that is necessary to; perform the transition (if any) may be provided as additional arguments to the; statepoint. Note that although in many cases statepoints may be inferred to be GC; transitions based on the function symbols involved (e.g. a call from a; function with GC strategy ""foo"" to a function with GC strategy ""bar""),; indirect calls that are also GC transitions must also be supported. This; requirement is the driving force behind the decision to require that GC; transitions are explicitly marked. Let's revisit the sample given above, this time treating the call to ``@foo``; as a GC transition. Depending on our target, the transition code may need to; access some extra state in order to inform the collector of the transition.; Let's assume a hypothetical GC--somewhat unimaginatively named ""hypothetical-gc""; --that requires that a TLS variable must be written to before and after a call; to unmanaged code. The resulting relocation sequence is:. .. code-block:: llvm. @flag = thread_local global i32 0, align 4. define i8 addrspace(1)* @test1(i8 addrspace(1) *%obj); gc ""hypothetical-gc"" {. %0 = call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 1, i32* @Flag, i32 0, i8 addrspace(1)* %obj); %obj.relocated = call coldcc i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %0, i32 7, i32 7); ret i8 addrspace(1)* %obj.relocated; }. During lowering, this will result in an instruction selection DAG that looks; something like:. ::. CALLSEQ_START; ...; GC_TRANSITION_START (lowered i32 *@Flag), SRCVALUE i32* Flag; STATEPOINT; GC_TRANSITION_END (lowered i32 *@Flag), SRCVALUE i32 *Flag; ...; CALLSEQ_END. In order to generate the necessary transition code, the backend for each target; supported by ""hypothetical-gc"" must be mo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:24825,Modifiability,extend,extended,24825,"rty is required,; consider a null comparison performed on the original copy of a; relocated pointer. Assuming that control flow follows the safepoint,; there is no way to observe externally whether the null comparison is; performed before or after the safepoint. (Remember, the original; Value is unmodified by the safepoint.) The compiler is free to make; either scheduling choice. The actual correctness property implemented is slightly stronger than; this. We require that there be no *static path* on which a; potentially relocated pointer is 'observably-after' it may have been; relocated. This is slightly stronger than is strictly necessary (and; thus may disallow some otherwise valid programs), but greatly; simplifies reasoning about correctness of the compiled code. By construction, this property will be upheld by the optimizer if; correctly established in the source IR. This is a key invariant of; the design. The existing IR Verifier pass has been extended to check most of the; local restrictions on the intrinsics mentioned in their respective; documentation. The current implementation in LLVM does not check the; key relocation invariant, but this is ongoing work on developing such; a verifier. Please ask on llvm-dev if you're interested in; experimenting with the current version. .. _statepoint-utilities:. Utility Passes for Safepoint Insertion; ======================================. .. _RewriteStatepointsForGC:. RewriteStatepointsForGC; ^^^^^^^^^^^^^^^^^^^^^^^^. The pass RewriteStatepointsForGC transforms a function's IR to lower from the; abstract machine model described above to the explicit statepoint model of; relocations. To do this, it replaces all calls or invokes of functions which; might contain a safepoint poll with a ``gc.statepoint`` and associated full; relocation sequence, including all required ``gc.relocates``. This pass only applies to GCStrategy instances where the ``UseRS4GC`` flag; is set. The two builtin GC strategies with this set are the; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:27744,Modifiability,variab,variables,27744,"example`` GC strategy uses to distinguish references from; non references. This is controlled via GCStrategy::isGCManagedPointer. The; ``statepoint-example`` and ``coreclr`` strategies (the only two default; strategies that support statepoints) both use addrspace(1) to determine which; pointers are references, however custom strategies don't have to follow this; convention. This pass can be used an utility function by a language frontend that doesn't; want to manually reason about liveness, base pointers, or relocation when; constructing IR. As currently implemented, RewriteStatepointsForGC must be; run after SSA construction (i.e. mem2ref). RewriteStatepointsForGC will ensure that appropriate base pointers are listed; for every relocation created. It will do so by duplicating code as needed to; propagate the base pointer associated with each pointer being relocated to; the appropriate safepoints. The implementation assumes that the following; IR constructs produce base pointers: loads from the heap, addresses of global; variables, function arguments, function return values. Constant pointers (such; as null) are also assumed to be base pointers. In practice, this constraint; can be relaxed to producing interior derived pointers provided the target; collector can find the associated allocation from an arbitrary interior; derived pointer. By default RewriteStatepointsForGC passes in ``0xABCDEF00`` as the statepoint; ID and ``0`` as the number of patchable bytes to the newly constructed; ``gc.statepoint``. These values can be configured on a per-callsite; basis using the attributes ``""statepoint-id""`` and; ``""statepoint-num-patch-bytes""``. If a call site is marked with a; ``""statepoint-id""`` function attribute and its value is a positive; integer (represented as a string), then that value is used as the ID; of the newly constructed ``gc.statepoint``. If a call site is marked; with a ``""statepoint-num-patch-bytes""`` function attribute and its; value is a positive integer",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:28256,Modifiability,config,configured,28256,"C must be; run after SSA construction (i.e. mem2ref). RewriteStatepointsForGC will ensure that appropriate base pointers are listed; for every relocation created. It will do so by duplicating code as needed to; propagate the base pointer associated with each pointer being relocated to; the appropriate safepoints. The implementation assumes that the following; IR constructs produce base pointers: loads from the heap, addresses of global; variables, function arguments, function return values. Constant pointers (such; as null) are also assumed to be base pointers. In practice, this constraint; can be relaxed to producing interior derived pointers provided the target; collector can find the associated allocation from an arbitrary interior; derived pointer. By default RewriteStatepointsForGC passes in ``0xABCDEF00`` as the statepoint; ID and ``0`` as the number of patchable bytes to the newly constructed; ``gc.statepoint``. These values can be configured on a per-callsite; basis using the attributes ``""statepoint-id""`` and; ``""statepoint-num-patch-bytes""``. If a call site is marked with a; ``""statepoint-id""`` function attribute and its value is a positive; integer (represented as a string), then that value is used as the ID; of the newly constructed ``gc.statepoint``. If a call site is marked; with a ``""statepoint-num-patch-bytes""`` function attribute and its; value is a positive integer, then that value is used as the 'num patch; bytes' parameter of the newly constructed ``gc.statepoint``. The; ``""statepoint-id""`` and ``""statepoint-num-patch-bytes""`` attributes; are not propagated to the ``gc.statepoint`` call or invoke if they; could be successfully parsed. In practice, RewriteStatepointsForGC should be run much later in the pass; pipeline, after most optimization is already done. This helps to improve; the quality of the generated code when compiled with garbage collection support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:36414,Modifiability,enhance,enhancements,36414,"ind a heap map given the stack address. The missing pieces are a) integration with rewriting (RS4GC) from the; abstract machine model and b) support for optionally decomposing on stack; objects so as not to require heap maps for them. The later is required; for ease of integration with some collectors. Lowering Quality and Representation Overhead; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The current statepoint lowering is known to be somewhat poor. In the very; long term, we'd like to integrate statepoints with the register allocator;; in the near term this is unlikely to happen. We've found the quality of; lowering to be relatively unimportant as hot-statepoints are almost always; inliner bugs. Concerns have been raised that the statepoint representation results in a; large amount of IR being produced for some examples and that this; contributes to higher than expected memory usage and compile times. There's; no immediate plans to make changes due to this, but alternate models may be; explored in the future. Relocations Along Exceptional Edges; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Relocations along exceptional paths are currently broken in ToT. In; particular, there is current no way to represent a rethrow on a path which; also has relocations. See `this llvm-dev discussion; <https://groups.google.com/forum/#!topic/llvm-dev/AE417XjgxvI>`_ for more; detail. Bugs and Enhancements; =====================. Currently known bugs and enhancements under consideration can be; tracked by performing a `bugzilla search; <https://bugs.llvm.org/buglist.cgi?cmdtype=runnamed&namedcmd=Statepoint%20Bugs&list_id=64342>`_; for [Statepoint] in the summary field. When filing new bugs, please; use this tag so that interested parties see the newly filed bug. As; with most LLVM features, design discussions take place on the `Discourse forums <https://discourse.llvm.org>`_ and patches; should be sent to `llvm-commits; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_ for review.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:2527,Performance,load,load,2527," the; execution known as 'safepoints' For most collectors, it is sufficient; to track at least one copy of each unique pointer value. However, for; a collector which wishes to relocate objects directly reachable from; running code, a higher standard is required. One additional challenge is that the compiler may compute intermediate; results (""derived pointers"") which point outside of the allocation or; even into the middle of another allocation. The eventual use of this; intermediate value must yield an address within the bounds of the; allocation, but such ""exterior derived pointers"" may be visible to the; collector. Given this, a garbage collector can not safely rely on the; runtime value of an address to indicate the object it is associated; with. If the garbage collector wishes to move any object, the; compiler must provide a mapping, for each pointer, to an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage collectors are organized in terms of three abstractions:; load barriers, store barriers, and safepoints. #. A load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:2579,Performance,load,load,2579,"ch wishes to relocate objects directly reachable from; running code, a higher standard is required. One additional challenge is that the compiler may compute intermediate; results (""derived pointers"") which point outside of the allocation or; even into the middle of another allocation. The eventual use of this; intermediate value must yield an address within the bounds of the; allocation, but such ""exterior derived pointers"" may be visible to the; collector. Given this, a garbage collector can not safely rely on the; runtime value of an address to indicate the object it is associated; with. If the garbage collector wishes to move any object, the; compiler must provide a mapping, for each pointer, to an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage collectors are organized in terms of three abstractions:; load barriers, store barriers, and safepoints. #. A load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:2649,Performance,load,load,2649,"ch wishes to relocate objects directly reachable from; running code, a higher standard is required. One additional challenge is that the compiler may compute intermediate; results (""derived pointers"") which point outside of the allocation or; even into the middle of another allocation. The eventual use of this; intermediate value must yield an address within the bounds of the; allocation, but such ""exterior derived pointers"" may be visible to the; collector. Given this, a garbage collector can not safely rely on the; runtime value of an address to indicate the object it is associated; with. If the garbage collector wishes to move any object, the; compiler must provide a mapping, for each pointer, to an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage collectors are organized in terms of three abstractions:; load barriers, store barriers, and safepoints. #. A load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:2699,Performance,load,loaded,2699,"ch wishes to relocate objects directly reachable from; running code, a higher standard is required. One additional challenge is that the compiler may compute intermediate; results (""derived pointers"") which point outside of the allocation or; even into the middle of another allocation. The eventual use of this; intermediate value must yield an address within the bounds of the; allocation, but such ""exterior derived pointers"" may be visible to the; collector. Given this, a garbage collector can not safely rely on the; runtime value of an address to indicate the object it is associated; with. If the garbage collector wishes to move any object, the; compiler must provide a mapping, for each pointer, to an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage collectors are organized in terms of three abstractions:; load barriers, store barriers, and safepoints. #. A load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:2774,Performance,load,loads,2774," may compute intermediate; results (""derived pointers"") which point outside of the allocation or; even into the middle of another allocation. The eventual use of this; intermediate value must yield an address within the bounds of the; allocation, but such ""exterior derived pointers"" may be visible to the; collector. Given this, a garbage collector can not safely rely on the; runtime value of an address to indicate the object it is associated; with. If the garbage collector wishes to move any object, the; compiler must provide a mapping, for each pointer, to an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage collectors are organized in terms of three abstractions:; load barriers, store barriers, and safepoints. #. A load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the collector can safely use that information. The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focus",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:2788,Performance,load,loads,2788," may compute intermediate; results (""derived pointers"") which point outside of the allocation or; even into the middle of another allocation. The eventual use of this; intermediate value must yield an address within the bounds of the; allocation, but such ""exterior derived pointers"" may be visible to the; collector. Given this, a garbage collector can not safely rely on the; runtime value of an address to indicate the object it is associated; with. If the garbage collector wishes to move any object, the; compiler must provide a mapping, for each pointer, to an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage collectors are organized in terms of three abstractions:; load barriers, store barriers, and safepoints. #. A load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the collector can safely use that information. The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focus",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:5115,Performance,optimiz,optimizer,5115,"he collector must be able to:. #. identify every copy of a pointer (including copies introduced by; the compiler itself) at the safepoint,; #. identify which object each pointer relates to, and; #. potentially update each of those copies. This document describes the mechanism by which an LLVM based compiler; can provide this information to a language runtime/collector, and; ensure that all pointers can be read and updated if desired. Abstract Machine Model; ^^^^^^^^^^^^^^^^^^^^^^^. At a high level, LLVM has been extended to support compiling to an abstract; machine which extends the actual target with a non-integral pointer type; suitable for representing a garbage collected reference to an object. In; particular, such non-integral pointer type have no defined mapping to an; integer representation. This semantic quirk allows the runtime to pick a; integer mapping for each point in the program allowing relocations of objects; without visible effects. This high level abstract machine model is used for most of the optimizer. As; a result, transform passes do not need to be extended to look through explicit; relocation sequence. Before starting code generation, we switch; representations to an explicit form. The exact location chosen for lowering; is an implementation detail. Note that most of the value of the abstract machine model comes for collectors; which need to model potentially relocatable objects. For a compiler which; supports only a non-relocating collector, you may wish to consider starting; with the fully explicit form. Warning: There is one currently known semantic hole in the definition of; non-integral pointers which has not been addressed upstream. To work around; this, you need to disable speculation of loads unless the memory type; (non-integral pointer vs anything else) is known to unchanged. That is, it is; not safe to speculate a load if doing causes a non-integral pointer value to; be loaded as any other type or vice versa. In practice, this restr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:5835,Performance,load,loads,5835,"efined mapping to an; integer representation. This semantic quirk allows the runtime to pick a; integer mapping for each point in the program allowing relocations of objects; without visible effects. This high level abstract machine model is used for most of the optimizer. As; a result, transform passes do not need to be extended to look through explicit; relocation sequence. Before starting code generation, we switch; representations to an explicit form. The exact location chosen for lowering; is an implementation detail. Note that most of the value of the abstract machine model comes for collectors; which need to model potentially relocatable objects. For a compiler which; supports only a non-relocating collector, you may wish to consider starting; with the fully explicit form. Warning: There is one currently known semantic hole in the definition of; non-integral pointers which has not been addressed upstream. To work around; this, you need to disable speculation of loads unless the memory type; (non-integral pointer vs anything else) is known to unchanged. That is, it is; not safe to speculate a load if doing causes a non-integral pointer value to; be loaded as any other type or vice versa. In practice, this restriction is; well isolated to isSafeToSpeculate in ValueTracking.cpp. Explicit Representation; ^^^^^^^^^^^^^^^^^^^^^^^. A frontend could directly generate this low level explicit form, but; doing so may inhibit optimization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is op",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:5968,Performance,load,load,5968,"llowing relocations of objects; without visible effects. This high level abstract machine model is used for most of the optimizer. As; a result, transform passes do not need to be extended to look through explicit; relocation sequence. Before starting code generation, we switch; representations to an explicit form. The exact location chosen for lowering; is an implementation detail. Note that most of the value of the abstract machine model comes for collectors; which need to model potentially relocatable objects. For a compiler which; supports only a non-relocating collector, you may wish to consider starting; with the fully explicit form. Warning: There is one currently known semantic hole in the definition of; non-integral pointers which has not been addressed upstream. To work around; this, you need to disable speculation of loads unless the memory type; (non-integral pointer vs anything else) is known to unchanged. That is, it is; not safe to speculate a load if doing causes a non-integral pointer value to; be loaded as any other type or vice versa. In practice, this restriction is; well isolated to isSafeToSpeculate in ValueTracking.cpp. Explicit Representation; ^^^^^^^^^^^^^^^^^^^^^^^. A frontend could directly generate this low level explicit form, but; doing so may inhibit optimization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the opt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:6025,Performance,load,loaded,6025,"llowing relocations of objects; without visible effects. This high level abstract machine model is used for most of the optimizer. As; a result, transform passes do not need to be extended to look through explicit; relocation sequence. Before starting code generation, we switch; representations to an explicit form. The exact location chosen for lowering; is an implementation detail. Note that most of the value of the abstract machine model comes for collectors; which need to model potentially relocatable objects. For a compiler which; supports only a non-relocating collector, you may wish to consider starting; with the fully explicit form. Warning: There is one currently known semantic hole in the definition of; non-integral pointers which has not been addressed upstream. To work around; this, you need to disable speculation of loads unless the memory type; (non-integral pointer vs anything else) is known to unchanged. That is, it is; not safe to speculate a load if doing causes a non-integral pointer value to; be loaded as any other type or vice versa. In practice, this restriction is; well isolated to isSafeToSpeculate in ValueTracking.cpp. Explicit Representation; ^^^^^^^^^^^^^^^^^^^^^^^. A frontend could directly generate this low level explicit form, but; doing so may inhibit optimization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the opt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:6297,Performance,optimiz,optimization,6297,"ation, we switch; representations to an explicit form. The exact location chosen for lowering; is an implementation detail. Note that most of the value of the abstract machine model comes for collectors; which need to model potentially relocatable objects. For a compiler which; supports only a non-relocating collector, you may wish to consider starting; with the fully explicit form. Warning: There is one currently known semantic hole in the definition of; non-integral pointers which has not been addressed upstream. To work around; this, you need to disable speculation of loads unless the memory type; (non-integral pointer vs anything else) is known to unchanged. That is, it is; not safe to speculate a load if doing causes a non-integral pointer value to; be loaded as any other type or vice versa. In practice, this restriction is; well isolated to isSafeToSpeculate in ValueTracking.cpp. Explicit Representation; ^^^^^^^^^^^^^^^^^^^^^^^. A frontend could directly generate this low level explicit form, but; doing so may inhibit optimization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the optimizer; from performing unsound optimizations.; #. recording a mapping of live pointers (and the allocation they're; associated with) for each statepoint. At the most abstract level, inserting a safepoint can be thought of as; replacing a call instruction with a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:6543,Performance,perform,performed,6543,"ompiler which; supports only a non-relocating collector, you may wish to consider starting; with the fully explicit form. Warning: There is one currently known semantic hole in the definition of; non-integral pointers which has not been addressed upstream. To work around; this, you need to disable speculation of loads unless the memory type; (non-integral pointer vs anything else) is known to unchanged. That is, it is; not safe to speculate a load if doing causes a non-integral pointer value to; be loaded as any other type or vice versa. In practice, this restriction is; well isolated to isSafeToSpeculate in ValueTracking.cpp. Explicit Representation; ^^^^^^^^^^^^^^^^^^^^^^^. A frontend could directly generate this low level explicit form, but; doing so may inhibit optimization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the optimizer; from performing unsound optimizations.; #. recording a mapping of live pointers (and the allocation they're; associated with) for each statepoint. At the most abstract level, inserting a safepoint can be thought of as; replacing a call instruction with a call to a multiple return value; function which both calls the original target of the call, returns; its result, and returns updated values for any live pointers to; garbage collected objects. Note that the task of identifying all live pointers to garbage; collec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:6893,Performance,optimiz,optimizer,6893,"nything else) is known to unchanged. That is, it is; not safe to speculate a load if doing causes a non-integral pointer value to; be loaded as any other type or vice versa. In practice, this restriction is; well isolated to isSafeToSpeculate in ValueTracking.cpp. Explicit Representation; ^^^^^^^^^^^^^^^^^^^^^^^. A frontend could directly generate this low level explicit form, but; doing so may inhibit optimization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the optimizer; from performing unsound optimizations.; #. recording a mapping of live pointers (and the allocation they're; associated with) for each statepoint. At the most abstract level, inserting a safepoint can be thought of as; replacing a call instruction with a call to a multiple return value; function which both calls the original target of the call, returns; its result, and returns updated values for any live pointers to; garbage collected objects. Note that the task of identifying all live pointers to garbage; collected values, transforming the IR to expose a pointer giving the; base object for every such live pointer, and inserting all the; intrinsics correctly is explicitly out of scope for this document.; The recommended approach is to use the :ref:`utility passes; <statepoint-utilities>` described below. This abstract function call is concretely represented by a sequence of;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:6993,Performance,optimiz,optimizer,6993,"ter value to; be loaded as any other type or vice versa. In practice, this restriction is; well isolated to isSafeToSpeculate in ValueTracking.cpp. Explicit Representation; ^^^^^^^^^^^^^^^^^^^^^^^. A frontend could directly generate this low level explicit form, but; doing so may inhibit optimization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the optimizer; from performing unsound optimizations.; #. recording a mapping of live pointers (and the allocation they're; associated with) for each statepoint. At the most abstract level, inserting a safepoint can be thought of as; replacing a call instruction with a call to a multiple return value; function which both calls the original target of the call, returns; its result, and returns updated values for any live pointers to; garbage collected objects. Note that the task of identifying all live pointers to garbage; collected values, transforming the IR to expose a pointer giving the; base object for every such live pointer, and inserting all the; intrinsics correctly is explicitly out of scope for this document.; The recommended approach is to use the :ref:`utility passes; <statepoint-utilities>` described below. This abstract function call is concretely represented by a sequence of; intrinsic calls known collectively as a ""statepoint relocation sequence"". Let's consider a simple call in LLVM IR:. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:7009,Performance,perform,performing,7009,"ter value to; be loaded as any other type or vice versa. In practice, this restriction is; well isolated to isSafeToSpeculate in ValueTracking.cpp. Explicit Representation; ^^^^^^^^^^^^^^^^^^^^^^^. A frontend could directly generate this low level explicit form, but; doing so may inhibit optimization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the optimizer; from performing unsound optimizations.; #. recording a mapping of live pointers (and the allocation they're; associated with) for each statepoint. At the most abstract level, inserting a safepoint can be thought of as; replacing a call instruction with a call to a multiple return value; function which both calls the original target of the call, returns; its result, and returns updated values for any live pointers to; garbage collected objects. Note that the task of identifying all live pointers to garbage; collected values, transforming the IR to expose a pointer giving the; base object for every such live pointer, and inserting all the; intrinsics correctly is explicitly out of scope for this document.; The recommended approach is to use the :ref:`utility passes; <statepoint-utilities>` described below. This abstract function call is concretely represented by a sequence of; intrinsic calls known collectively as a ""statepoint relocation sequence"". Let's consider a simple call in LLVM IR:. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:7028,Performance,optimiz,optimizations,7028,"ter value to; be loaded as any other type or vice versa. In practice, this restriction is; well isolated to isSafeToSpeculate in ValueTracking.cpp. Explicit Representation; ^^^^^^^^^^^^^^^^^^^^^^^. A frontend could directly generate this low level explicit form, but; doing so may inhibit optimization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the optimizer; from performing unsound optimizations.; #. recording a mapping of live pointers (and the allocation they're; associated with) for each statepoint. At the most abstract level, inserting a safepoint can be thought of as; replacing a call instruction with a call to a multiple return value; function which both calls the original target of the call, returns; its result, and returns updated values for any live pointers to; garbage collected objects. Note that the task of identifying all live pointers to garbage; collected values, transforming the IR to expose a pointer giving the; base object for every such live pointer, and inserting all the; intrinsics correctly is explicitly out of scope for this document.; The recommended approach is to use the :ref:`utility passes; <statepoint-utilities>` described below. This abstract function call is concretely represented by a sequence of; intrinsic calls known collectively as a ""statepoint relocation sequence"". Let's consider a simple call in LLVM IR:. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:10274,Performance,load,load,10274,"argument, N; return value function (where M is the number of values being; relocated + the original call arguments and N is the original return; value + each relocated value), but LLVM does not easily support such a; representation. Instead, the statepoint intrinsic marks the actual site of the; safepoint or statepoint. The statepoint returns a token value (which; exists only at compile time). To get back the original return value; of the call, we use the ``gc.result`` intrinsic. To get the relocation; of each pointer in turn, we use the ``gc.relocate`` intrinsic with the; appropriate index. Note that both the ``gc.relocate`` and ``gc.result`` are; tied to the statepoint. The combination forms a ""statepoint relocation; sequence"" and represents the entirety of a parseable call or 'statepoint'. When lowered, this example would generate the following x86 assembly:. .. code-block:: gas. 	 .globl	test1; 	 .align	16, 0x90; 	 pushq	%rax; 	 callq	foo; .Ltmp1:; 	 movq	(%rsp), %rax # This load is redundant (oops!); 	 popq	%rdx; 	 retq. Each of the potentially relocated values has been spilled to the; stack, and a record of that location has been recorded to the; :ref:`Stack Map section <stackmap-section>`. If the garbage collector; needs to update any of these pointers during the call, it knows; exactly what to change. The relevant parts of the StackMap section for our example are:. .. code-block:: gas. # This describes the call site; # Stack Maps: callsite 2882400000; 	 .quad	2882400000; 	 .long	.Ltmp1-test1; 	 .short	0; # .. 8 entries skipped ..; # This entry describes the spill slot which is directly addressable; # off RSP with offset 0. Given the value was spilled with a pushq,; # that makes sense.; # Stack Maps: Loc 8: Direct RSP [encoding: .byte 2, .byte 8, .short 7, .int 0]; 	 .byte	2; 	 .byte	8; 	 .short	7; 	 .long	0. This example was taken from the tests for the :ref:`RewriteStatepointsForGC`; utility pass. As such, its full StackMap can be easily examined with the; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:16900,Performance,perform,perform,16900,"l.gc.relocate.p1i8(token %token, i32 7, i32 8); %p = getelementptr i8, i8 addrspace(1)* %gep, i64 -20000; ret i8 addrspace(1)* %p; }. Note that in this example %p and %obj.relocate are the same address and we; could replace one with the other, potentially removing the derived pointer; from the live set at the safepoint entirely. .. _gc_transition_args:. GC Transitions; ^^^^^^^^^^^^^^^^^^. As a practical consideration, many garbage-collected systems allow code that is; collector-aware (""managed code"") to call code that is not collector-aware; (""unmanaged code""). It is common that such calls must also be safepoints, since; it is desirable to allow the collector to run during the execution of; unmanaged code. Furthermore, it is common that coordinating the transition from; managed to unmanaged code requires extra code generation at the call site to; inform the collector of the transition. In order to support these needs, a; statepoint may be marked as a GC transition, and data that is necessary to; perform the transition (if any) may be provided as additional arguments to the; statepoint. Note that although in many cases statepoints may be inferred to be GC; transitions based on the function symbols involved (e.g. a call from a; function with GC strategy ""foo"" to a function with GC strategy ""bar""),; indirect calls that are also GC transitions must also be supported. This; requirement is the driving force behind the decision to require that GC; transitions are explicitly marked. Let's revisit the sample given above, this time treating the call to ``@foo``; as a GC transition. Depending on our target, the transition code may need to; access some extra state in order to inform the collector of the transition.; Let's assume a hypothetical GC--somewhat unimaginatively named ""hypothetical-gc""; --that requires that a TLS variable must be written to before and after a call; to unmanaged code. The resulting relocation sequence is:. .. code-block:: llvm. @flag = thread_local glo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:19133,Performance,load,load,19133,", i32 0, i8 addrspace(1)* %obj); %obj.relocated = call coldcc i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %0, i32 7, i32 7); ret i8 addrspace(1)* %obj.relocated; }. During lowering, this will result in an instruction selection DAG that looks; something like:. ::. CALLSEQ_START; ...; GC_TRANSITION_START (lowered i32 *@Flag), SRCVALUE i32* Flag; STATEPOINT; GC_TRANSITION_END (lowered i32 *@Flag), SRCVALUE i32 *Flag; ...; CALLSEQ_END. In order to generate the necessary transition code, the backend for each target; supported by ""hypothetical-gc"" must be modified to lower ``GC_TRANSITION_START``; and ``GC_TRANSITION_END`` nodes appropriately when the ""hypothetical-gc""; strategy is in use for a particular function. Assuming that such lowering has; been added for X86, the generated assembly would be:. .. code-block:: gas. 	 .globl	test1; 	 .align	16, 0x90; 	 pushq	%rax; 	 movl $1, %fs:Flag@TPOFF; 	 callq	foo; 	 movl $0, %fs:Flag@TPOFF; .Ltmp1:; 	 movq	(%rsp), %rax # This load is redundant (oops!); 	 popq	%rdx; 	 retq. Note that the design as presented above is not fully implemented: in particular,; strategy-specific lowering is not present, and all GC transitions are emitted as; as single no-op before and after the call instruction. These no-ops are often; removed by the backend during dead machine instruction elimination. Before the abstract machine model is lowered to the explicit statepoint model; of relocations by the :ref:`RewriteStatepointsForGC` pass it is possible for; any derived pointer to get its base pointer and offset from the base pointer; by using the ``gc.get.pointer.base`` and the ``gc.get.pointer.offset``; intrinsics respectively. These intrinsics are inlined by the; :ref:`RewriteStatepointsForGC` pass and must not be used after this pass. .. _statepoint-stackmap-format:. Stack Map Format; ================. Locations for each pointer value which may need read and/or updated by; the runtime or collector are provided in a separate section of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:23781,Performance,perform,performed,23781,"preted as describing a sequence of pointers and their corresponding; base pointers. If the Location is of size N x sizeof(pointer), then; there will be N records of one pointer each contained within the Location.; Both Locations in a pair can be assumed to be of the same size. Note that the Locations used in each section may describe the same; physical location. e.g. A stack slot may appear as a deopt location,; a gc base pointer, and a gc derived pointer. The LiveOut section of the StkMapRecord will be empty for a statepoint; record. Safepoint Semantics & Verification; ==================================. The fundamental correctness property for the compiled code's; correctness w.r.t. the garbage collector is a dynamic one. It must be; the case that there is no dynamic trace such that an operation; involving a potentially relocated pointer is observably-after a; safepoint which could relocate it. 'observably-after' is this usage; means that an outside observer could observe this sequence of events; in a way which precludes the operation being performed before the; safepoint. To understand why this 'observable-after' property is required,; consider a null comparison performed on the original copy of a; relocated pointer. Assuming that control flow follows the safepoint,; there is no way to observe externally whether the null comparison is; performed before or after the safepoint. (Remember, the original; Value is unmodified by the safepoint.) The compiler is free to make; either scheduling choice. The actual correctness property implemented is slightly stronger than; this. We require that there be no *static path* on which a; potentially relocated pointer is 'observably-after' it may have been; relocated. This is slightly stronger than is strictly necessary (and; thus may disallow some otherwise valid programs), but greatly; simplifies reasoning about correctness of the compiled code. By construction, this property will be upheld by the optimizer if; correctly establ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:23906,Performance,perform,performed,23906,"one pointer each contained within the Location.; Both Locations in a pair can be assumed to be of the same size. Note that the Locations used in each section may describe the same; physical location. e.g. A stack slot may appear as a deopt location,; a gc base pointer, and a gc derived pointer. The LiveOut section of the StkMapRecord will be empty for a statepoint; record. Safepoint Semantics & Verification; ==================================. The fundamental correctness property for the compiled code's; correctness w.r.t. the garbage collector is a dynamic one. It must be; the case that there is no dynamic trace such that an operation; involving a potentially relocated pointer is observably-after a; safepoint which could relocate it. 'observably-after' is this usage; means that an outside observer could observe this sequence of events; in a way which precludes the operation being performed before the; safepoint. To understand why this 'observable-after' property is required,; consider a null comparison performed on the original copy of a; relocated pointer. Assuming that control flow follows the safepoint,; there is no way to observe externally whether the null comparison is; performed before or after the safepoint. (Remember, the original; Value is unmodified by the safepoint.) The compiler is free to make; either scheduling choice. The actual correctness property implemented is slightly stronger than; this. We require that there be no *static path* on which a; potentially relocated pointer is 'observably-after' it may have been; relocated. This is slightly stronger than is strictly necessary (and; thus may disallow some otherwise valid programs), but greatly; simplifies reasoning about correctness of the compiled code. By construction, this property will be upheld by the optimizer if; correctly established in the source IR. This is a key invariant of; the design. The existing IR Verifier pass has been extended to check most of the; local restrictions on the intri",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:24083,Performance,perform,performed,24083,"on may describe the same; physical location. e.g. A stack slot may appear as a deopt location,; a gc base pointer, and a gc derived pointer. The LiveOut section of the StkMapRecord will be empty for a statepoint; record. Safepoint Semantics & Verification; ==================================. The fundamental correctness property for the compiled code's; correctness w.r.t. the garbage collector is a dynamic one. It must be; the case that there is no dynamic trace such that an operation; involving a potentially relocated pointer is observably-after a; safepoint which could relocate it. 'observably-after' is this usage; means that an outside observer could observe this sequence of events; in a way which precludes the operation being performed before the; safepoint. To understand why this 'observable-after' property is required,; consider a null comparison performed on the original copy of a; relocated pointer. Assuming that control flow follows the safepoint,; there is no way to observe externally whether the null comparison is; performed before or after the safepoint. (Remember, the original; Value is unmodified by the safepoint.) The compiler is free to make; either scheduling choice. The actual correctness property implemented is slightly stronger than; this. We require that there be no *static path* on which a; potentially relocated pointer is 'observably-after' it may have been; relocated. This is slightly stronger than is strictly necessary (and; thus may disallow some otherwise valid programs), but greatly; simplifies reasoning about correctness of the compiled code. By construction, this property will be upheld by the optimizer if; correctly established in the source IR. This is a key invariant of; the design. The existing IR Verifier pass has been extended to check most of the; local restrictions on the intrinsics mentioned in their respective; documentation. The current implementation in LLVM does not check the; key relocation invariant, but this is ongoing wo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:24692,Performance,optimiz,optimizer,24692,"erver could observe this sequence of events; in a way which precludes the operation being performed before the; safepoint. To understand why this 'observable-after' property is required,; consider a null comparison performed on the original copy of a; relocated pointer. Assuming that control flow follows the safepoint,; there is no way to observe externally whether the null comparison is; performed before or after the safepoint. (Remember, the original; Value is unmodified by the safepoint.) The compiler is free to make; either scheduling choice. The actual correctness property implemented is slightly stronger than; this. We require that there be no *static path* on which a; potentially relocated pointer is 'observably-after' it may have been; relocated. This is slightly stronger than is strictly necessary (and; thus may disallow some otherwise valid programs), but greatly; simplifies reasoning about correctness of the compiled code. By construction, this property will be upheld by the optimizer if; correctly established in the source IR. This is a key invariant of; the design. The existing IR Verifier pass has been extended to check most of the; local restrictions on the intrinsics mentioned in their respective; documentation. The current implementation in LLVM does not check the; key relocation invariant, but this is ongoing work on developing such; a verifier. Please ask on llvm-dev if you're interested in; experimenting with the current version. .. _statepoint-utilities:. Utility Passes for Safepoint Insertion; ======================================. .. _RewriteStatepointsForGC:. RewriteStatepointsForGC; ^^^^^^^^^^^^^^^^^^^^^^^^. The pass RewriteStatepointsForGC transforms a function's IR to lower from the; abstract machine model described above to the explicit statepoint model of; relocations. To do this, it replaces all calls or invokes of functions which; might contain a safepoint poll with a ``gc.statepoint`` and associated full; relocation sequence, includin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:27702,Performance,load,loads,27702,"example`` GC strategy uses to distinguish references from; non references. This is controlled via GCStrategy::isGCManagedPointer. The; ``statepoint-example`` and ``coreclr`` strategies (the only two default; strategies that support statepoints) both use addrspace(1) to determine which; pointers are references, however custom strategies don't have to follow this; convention. This pass can be used an utility function by a language frontend that doesn't; want to manually reason about liveness, base pointers, or relocation when; constructing IR. As currently implemented, RewriteStatepointsForGC must be; run after SSA construction (i.e. mem2ref). RewriteStatepointsForGC will ensure that appropriate base pointers are listed; for every relocation created. It will do so by duplicating code as needed to; propagate the base pointer associated with each pointer being relocated to; the appropriate safepoints. The implementation assumes that the following; IR constructs produce base pointers: loads from the heap, addresses of global; variables, function arguments, function return values. Constant pointers (such; as null) are also assumed to be base pointers. In practice, this constraint; can be relaxed to producing interior derived pointers provided the target; collector can find the associated allocation from an arbitrary interior; derived pointer. By default RewriteStatepointsForGC passes in ``0xABCDEF00`` as the statepoint; ID and ``0`` as the number of patchable bytes to the newly constructed; ``gc.statepoint``. These values can be configured on a per-callsite; basis using the attributes ``""statepoint-id""`` and; ``""statepoint-num-patch-bytes""``. If a call site is marked with a; ``""statepoint-id""`` function attribute and its value is a positive; integer (represented as a string), then that value is used as the ID; of the newly constructed ``gc.statepoint``. If a call site is marked; with a ``""statepoint-num-patch-bytes""`` function attribute and its; value is a positive integer",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:29082,Performance,optimiz,optimization,29082," derived pointer. By default RewriteStatepointsForGC passes in ``0xABCDEF00`` as the statepoint; ID and ``0`` as the number of patchable bytes to the newly constructed; ``gc.statepoint``. These values can be configured on a per-callsite; basis using the attributes ``""statepoint-id""`` and; ``""statepoint-num-patch-bytes""``. If a call site is marked with a; ``""statepoint-id""`` function attribute and its value is a positive; integer (represented as a string), then that value is used as the ID; of the newly constructed ``gc.statepoint``. If a call site is marked; with a ``""statepoint-num-patch-bytes""`` function attribute and its; value is a positive integer, then that value is used as the 'num patch; bytes' parameter of the newly constructed ``gc.statepoint``. The; ``""statepoint-id""`` and ``""statepoint-num-patch-bytes""`` attributes; are not propagated to the ``gc.statepoint`` call or invoke if they; could be successfully parsed. In practice, RewriteStatepointsForGC should be run much later in the pass; pipeline, after most optimization is already done. This helps to improve; the quality of the generated code when compiled with garbage collection support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowering; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. As a part of lowering to the explicit model of relocations; RewriteStatepointsForGC performs GC specific lowering for the following; intrinsics:. * ``gc.get.pointer.base``; * ``gc.get.pointer.offset``; * ``llvm.memcpy.element.unordered.atomic.*``; * ``llvm.memmove.element.unordered.atomic.*``. There are two possible lowerings for the memcpy and memmove operations:; GC leaf lowering and GC parseable lowering. If a call is explicitly marked with; ""gc-leaf-function"" attribute the call is lowered to a GC leaf call to; '``__llvm_memcpy_element_unordered_atomic_*``' or; '``__llvm_memmove_element_unordered_atomic_*``' symbol. Such a call can not; take a safepoint. Otherwise, the call is made G",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:29437,Performance,perform,performs,29437,"function attribute and its value is a positive; integer (represented as a string), then that value is used as the ID; of the newly constructed ``gc.statepoint``. If a call site is marked; with a ``""statepoint-num-patch-bytes""`` function attribute and its; value is a positive integer, then that value is used as the 'num patch; bytes' parameter of the newly constructed ``gc.statepoint``. The; ``""statepoint-id""`` and ``""statepoint-num-patch-bytes""`` attributes; are not propagated to the ``gc.statepoint`` call or invoke if they; could be successfully parsed. In practice, RewriteStatepointsForGC should be run much later in the pass; pipeline, after most optimization is already done. This helps to improve; the quality of the generated code when compiled with garbage collection support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowering; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. As a part of lowering to the explicit model of relocations; RewriteStatepointsForGC performs GC specific lowering for the following; intrinsics:. * ``gc.get.pointer.base``; * ``gc.get.pointer.offset``; * ``llvm.memcpy.element.unordered.atomic.*``; * ``llvm.memmove.element.unordered.atomic.*``. There are two possible lowerings for the memcpy and memmove operations:; GC leaf lowering and GC parseable lowering. If a call is explicitly marked with; ""gc-leaf-function"" attribute the call is lowered to a GC leaf call to; '``__llvm_memcpy_element_unordered_atomic_*``' or; '``__llvm_memmove_element_unordered_atomic_*``' symbol. Such a call can not; take a safepoint. Otherwise, the call is made GC parseable by wrapping the; call into a statepoint. This makes it possible to take a safepoint during; copy operation. Note that a GC parseable copy operation is not required to; take a safepoint. For example, a short copy operation may be performed without; taking a safepoint. GC parseable calls to '``llvm.memcpy.element.unordered.atomic.*``',; '``llvm.memmove.element.unor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:30289,Performance,perform,performed,30289,"GC intrinsic lowering; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. As a part of lowering to the explicit model of relocations; RewriteStatepointsForGC performs GC specific lowering for the following; intrinsics:. * ``gc.get.pointer.base``; * ``gc.get.pointer.offset``; * ``llvm.memcpy.element.unordered.atomic.*``; * ``llvm.memmove.element.unordered.atomic.*``. There are two possible lowerings for the memcpy and memmove operations:; GC leaf lowering and GC parseable lowering. If a call is explicitly marked with; ""gc-leaf-function"" attribute the call is lowered to a GC leaf call to; '``__llvm_memcpy_element_unordered_atomic_*``' or; '``__llvm_memmove_element_unordered_atomic_*``' symbol. Such a call can not; take a safepoint. Otherwise, the call is made GC parseable by wrapping the; call into a statepoint. This makes it possible to take a safepoint during; copy operation. Note that a GC parseable copy operation is not required to; take a safepoint. For example, a short copy operation may be performed without; taking a safepoint. GC parseable calls to '``llvm.memcpy.element.unordered.atomic.*``',; '``llvm.memmove.element.unordered.atomic.*``' intrinsics are lowered to calls; to '``__llvm_memcpy_element_unordered_atomic_safepoint_*``',; '``__llvm_memmove_element_unordered_atomic_safepoint_*``' symbols respectively.; This way the runtime can provide implementations of copy operations with and; without safepoints. GC parseable lowering also involves adjusting the arguments for the call.; Memcpy and memmove intrinsics take derived pointers as source and destination; arguments. If a copy operation takes a safepoint it might need to relocate the; underlying source and destination objects. This requires the corresponding base; pointers to be available in the copy operation. In order to make the base; pointers available RewriteStatepointsForGC replaces derived pointers with base; pointer and offset pairs. For example:. .. code-block:: llvm. declare void @__llvm_memcpy_element_u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:32733,Performance,optimiz,optimizations,32733,"code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @foo(); ret void; }. declare void @do_safepoint(); define void @gc.safepoint_poll() {; call void @do_safepoint(); ret void; }. This pass would produce the following IR:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @do_safepoint(); call void @foo(); ret void; }. In this case, we've added an (unconditional) entry safepoint poll. Note that; despite appearances, the entry poll is not necessarily redundant. We'd have to; know that ``foo`` and ``test`` were not mutually recursive for the poll to be; redundant. In practice, you'd probably want to your poll definition to contain; a conditional branch of some form. At the moment, PlaceSafepoints can insert safepoint polls at method entry and; loop backedges locations. Extending this to work with return polls would be; straight forward if desired. PlaceSafepoints includes a number of optimizations to avoid placing safepoint; polls at particular sites unless needed to ensure timely execution of a poll; under normal conditions. PlaceSafepoints does not attempt to ensure timely; execution of a poll under worst case conditions such as heavy system paging. The implementation of a safepoint poll action is specified by looking up a; function of the name ``gc.safepoint_poll`` in the containing Module. The body; of this function is inserted at each poll site desired. While calls or invokes; inside this method are transformed to a ``gc.statepoints``, recursive poll; insertion is not performed. This pass is useful for any language frontend which only has to support; garbage collection semantics at safepoints. If you need other abstract; frame information at safepoints (e.g. for deoptimization or introspection),; you can insert safepoint polls in the frontend. If you have the later case,; please ask on llvm-dev for suggestions. There's been a good amount of work; done on making such a scheme work well in practice which is not ye",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:33334,Performance,perform,performed,33334,"; know that ``foo`` and ``test`` were not mutually recursive for the poll to be; redundant. In practice, you'd probably want to your poll definition to contain; a conditional branch of some form. At the moment, PlaceSafepoints can insert safepoint polls at method entry and; loop backedges locations. Extending this to work with return polls would be; straight forward if desired. PlaceSafepoints includes a number of optimizations to avoid placing safepoint; polls at particular sites unless needed to ensure timely execution of a poll; under normal conditions. PlaceSafepoints does not attempt to ensure timely; execution of a poll under worst case conditions such as heavy system paging. The implementation of a safepoint poll action is specified by looking up a; function of the name ``gc.safepoint_poll`` in the containing Module. The body; of this function is inserted at each poll site desired. While calls or invokes; inside this method are transformed to a ``gc.statepoints``, recursive poll; insertion is not performed. This pass is useful for any language frontend which only has to support; garbage collection semantics at safepoints. If you need other abstract; frame information at safepoints (e.g. for deoptimization or introspection),; you can insert safepoint polls in the frontend. If you have the later case,; please ask on llvm-dev for suggestions. There's been a good amount of work; done on making such a scheme work well in practice which is not yet documented; here. Supported Architectures; =======================. Support for statepoint generation requires some code for each backend.; Today, only Aarch64 and X86_64 are supported. .. _OpenWork:. Limitations and Half Baked Ideas; ================================. Mixing References and Raw Pointers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Support for languages which allow unmanaged pointers to garbage collected; objects (i.e. pass a pointer to an object to a C routine) in the abstract; machine model. At the moment, the be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:36466,Performance,perform,performing,36466,"ind a heap map given the stack address. The missing pieces are a) integration with rewriting (RS4GC) from the; abstract machine model and b) support for optionally decomposing on stack; objects so as not to require heap maps for them. The later is required; for ease of integration with some collectors. Lowering Quality and Representation Overhead; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The current statepoint lowering is known to be somewhat poor. In the very; long term, we'd like to integrate statepoints with the register allocator;; in the near term this is unlikely to happen. We've found the quality of; lowering to be relatively unimportant as hot-statepoints are almost always; inliner bugs. Concerns have been raised that the statepoint representation results in a; large amount of IR being produced for some examples and that this; contributes to higher than expected memory usage and compile times. There's; no immediate plans to make changes due to this, but alternate models may be; explored in the future. Relocations Along Exceptional Edges; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Relocations along exceptional paths are currently broken in ToT. In; particular, there is current no way to represent a rethrow on a path which; also has relocations. See `this llvm-dev discussion; <https://groups.google.com/forum/#!topic/llvm-dev/AE417XjgxvI>`_ for more; detail. Bugs and Enhancements; =====================. Currently known bugs and enhancements under consideration can be; tracked by performing a `bugzilla search; <https://bugs.llvm.org/buglist.cgi?cmdtype=runnamed&namedcmd=Statepoint%20Bugs&list_id=64342>`_; for [Statepoint] in the summary field. When filing new bugs, please; use this tag so that interested parties see the newly filed bug. As; with most LLVM features, design discussions take place on the `Discourse forums <https://discourse.llvm.org>`_ and patches; should be sent to `llvm-commits; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_ for review.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:1504,Safety,safe,safepoints,1504,"; below. They are still listed as ""experimental"" to indicate that no forward or backward; compatibility guarantees are offered across versions. If your use case is such; that you need some form of forward compatibility guarantee, please raise the; issue on the llvm-dev mailing list. LLVM still supports an alternate mechanism for conservative garbage collection; support using the ``gcroot`` intrinsic. The ``gcroot`` mechanism is mostly of; historical interest at this point with one exception - its implementation of; shadow stacks has been used successfully by a number of language frontends and; is still supported. Overview & Core Concepts; ========================. To collect dead objects, garbage collectors must be able to identify; any references to objects contained within executing code, and,; depending on the collector, potentially update them. The collector; does not need this information at all points in code - that would make; the problem much harder - but only at well-defined points in the; execution known as 'safepoints' For most collectors, it is sufficient; to track at least one copy of each unique pointer value. However, for; a collector which wishes to relocate objects directly reachable from; running code, a higher standard is required. One additional challenge is that the compiler may compute intermediate; results (""derived pointers"") which point outside of the allocation or; even into the middle of another allocation. The eventual use of this; intermediate value must yield an address within the bounds of the; allocation, but such ""exterior derived pointers"" may be visible to the; collector. Given this, a garbage collector can not safely rely on the; runtime value of an address to indicate the object it is associated; with. If the garbage collector wishes to move any object, the; compiler must provide a mapping, for each pointer, to an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:2144,Safety,safe,safely,2144,"rbage collectors must be able to identify; any references to objects contained within executing code, and,; depending on the collector, potentially update them. The collector; does not need this information at all points in code - that would make; the problem much harder - but only at well-defined points in the; execution known as 'safepoints' For most collectors, it is sufficient; to track at least one copy of each unique pointer value. However, for; a collector which wishes to relocate objects directly reachable from; running code, a higher standard is required. One additional challenge is that the compiler may compute intermediate; results (""derived pointers"") which point outside of the allocation or; even into the middle of another allocation. The eventual use of this; intermediate value must yield an address within the bounds of the; allocation, but such ""exterior derived pointers"" may be visible to the; collector. Given this, a garbage collector can not safely rely on the; runtime value of an address to indicate the object it is associated; with. If the garbage collector wishes to move any object, the; compiler must provide a mapping, for each pointer, to an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage collectors are organized in terms of three abstractions:; load barriers, store barriers, and safepoints. #. A load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:2562,Safety,safe,safepoints,2562," the; execution known as 'safepoints' For most collectors, it is sufficient; to track at least one copy of each unique pointer value. However, for; a collector which wishes to relocate objects directly reachable from; running code, a higher standard is required. One additional challenge is that the compiler may compute intermediate; results (""derived pointers"") which point outside of the allocation or; even into the middle of another allocation. The eventual use of this; intermediate value must yield an address within the bounds of the; allocation, but such ""exterior derived pointers"" may be visible to the; collector. Given this, a garbage collector can not safely rely on the; runtime value of an address to indicate the object it is associated; with. If the garbage collector wishes to move any object, the; compiler must provide a mapping, for each pointer, to an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage collectors are organized in terms of three abstractions:; load barriers, store barriers, and safepoints. #. A load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:3138,Safety,safe,safepoint,3138,"lue of an address to indicate the object it is associated; with. If the garbage collector wishes to move any object, the; compiler must provide a mapping, for each pointer, to an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage collectors are organized in terms of three abstractions:; load barriers, store barriers, and safepoints. #. A load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the collector can safely use that information. The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focuses on the last item - compiler support for; safepoints in generated code. We will assume that an outside; mechanism has decided where to place safepoints. From our; perspective, all safepoints will be function calls. To support; relocation of objects directly reachable from values in compiled code,; the collector must be able to:. #. identify every copy of a pointer (including copies i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:3290,Safety,safe,safepoint,3290," an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage collectors are organized in terms of three abstractions:; load barriers, store barriers, and safepoints. #. A load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the collector can safely use that information. The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focuses on the last item - compiler support for; safepoints in generated code. We will assume that an outside; mechanism has decided where to place safepoints. From our; perspective, all safepoints will be function calls. To support; relocation of objects directly reachable from values in compiled code,; the collector must be able to:. #. identify every copy of a pointer (including copies introduced by; the compiler itself) at the safepoint,; #. identify which object each pointer relates to, and; #. potentially update each of those copies. This document describes",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:3441,Safety,safe,safepoint,3441,"d code,; most garbage collectors are organized in terms of three abstractions:; load barriers, store barriers, and safepoints. #. A load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the collector can safely use that information. The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focuses on the last item - compiler support for; safepoints in generated code. We will assume that an outside; mechanism has decided where to place safepoints. From our; perspective, all safepoints will be function calls. To support; relocation of objects directly reachable from values in compiled code,; the collector must be able to:. #. identify every copy of a pointer (including copies introduced by; the compiler itself) at the safepoint,; #. identify which object each pointer relates to, and; #. potentially update each of those copies. This document describes the mechanism by which an LLVM based compiler; can provide this information to a language runtime",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:3655,Safety,safe,safely,3655,"load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the collector can safely use that information. The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focuses on the last item - compiler support for; safepoints in generated code. We will assume that an outside; mechanism has decided where to place safepoints. From our; perspective, all safepoints will be function calls. To support; relocation of objects directly reachable from values in compiled code,; the collector must be able to:. #. identify every copy of a pointer (including copies introduced by; the compiler itself) at the safepoint,; #. identify which object each pointer relates to, and; #. potentially update each of those copies. This document describes the mechanism by which an LLVM based compiler; can provide this information to a language runtime/collector, and; ensure that all pointers can be read and updated if desired. Abstract Machine Model; ^^^^^^^^^^^^^^^^^^^^^^^. At a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:3830,Safety,safe,safepoints,3830,"pe (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the collector can safely use that information. The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focuses on the last item - compiler support for; safepoints in generated code. We will assume that an outside; mechanism has decided where to place safepoints. From our; perspective, all safepoints will be function calls. To support; relocation of objects directly reachable from values in compiled code,; the collector must be able to:. #. identify every copy of a pointer (including copies introduced by; the compiler itself) at the safepoint,; #. identify which object each pointer relates to, and; #. potentially update each of those copies. This document describes the mechanism by which an LLVM based compiler; can provide this information to a language runtime/collector, and; ensure that all pointers can be read and updated if desired. Abstract Machine Model; ^^^^^^^^^^^^^^^^^^^^^^^. At a high level, LLVM has been extended to support compiling to an abstract; machine which extends the actual target with a non-integral pointer type; suitable for representing a garbage collected reference to an object. In; particular, s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:3929,Safety,safe,safepoints,3929,"is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the collector can safely use that information. The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focuses on the last item - compiler support for; safepoints in generated code. We will assume that an outside; mechanism has decided where to place safepoints. From our; perspective, all safepoints will be function calls. To support; relocation of objects directly reachable from values in compiled code,; the collector must be able to:. #. identify every copy of a pointer (including copies introduced by; the compiler itself) at the safepoint,; #. identify which object each pointer relates to, and; #. potentially update each of those copies. This document describes the mechanism by which an LLVM based compiler; can provide this information to a language runtime/collector, and; ensure that all pointers can be read and updated if desired. Abstract Machine Model; ^^^^^^^^^^^^^^^^^^^^^^^. At a high level, LLVM has been extended to support compiling to an abstract; machine which extends the actual target with a non-integral pointer type; suitable for representing a garbage collected reference to an object. In; particular, such non-integral pointer type have no defined mapping to an; integer representation. Th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:3968,Safety,safe,safepoints,3968,"uction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the collector can safely use that information. The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focuses on the last item - compiler support for; safepoints in generated code. We will assume that an outside; mechanism has decided where to place safepoints. From our; perspective, all safepoints will be function calls. To support; relocation of objects directly reachable from values in compiled code,; the collector must be able to:. #. identify every copy of a pointer (including copies introduced by; the compiler itself) at the safepoint,; #. identify which object each pointer relates to, and; #. potentially update each of those copies. This document describes the mechanism by which an LLVM based compiler; can provide this information to a language runtime/collector, and; ensure that all pointers can be read and updated if desired. Abstract Machine Model; ^^^^^^^^^^^^^^^^^^^^^^^. At a high level, LLVM has been extended to support compiling to an abstract; machine which extends the actual target with a non-integral pointer type; suitable for representing a garbage collected reference to an object. In; particular, such non-integral pointer type have no defined mapping to an; integer representation. This semantic quirk allows the runtime to pick a; integer mapping for eac",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:4216,Safety,safe,safepoint,4216,"ters visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It refers to; both the location at which the machine state is parsable and the; coordination protocol involved in bring application threads to a; point at which the collector can safely use that information. The; term ""statepoint"" as used in this document refers exclusively to the; former. This document focuses on the last item - compiler support for; safepoints in generated code. We will assume that an outside; mechanism has decided where to place safepoints. From our; perspective, all safepoints will be function calls. To support; relocation of objects directly reachable from values in compiled code,; the collector must be able to:. #. identify every copy of a pointer (including copies introduced by; the compiler itself) at the safepoint,; #. identify which object each pointer relates to, and; #. potentially update each of those copies. This document describes the mechanism by which an LLVM based compiler; can provide this information to a language runtime/collector, and; ensure that all pointers can be read and updated if desired. Abstract Machine Model; ^^^^^^^^^^^^^^^^^^^^^^^. At a high level, LLVM has been extended to support compiling to an abstract; machine which extends the actual target with a non-integral pointer type; suitable for representing a garbage collected reference to an object. In; particular, such non-integral pointer type have no defined mapping to an; integer representation. This semantic quirk allows the runtime to pick a; integer mapping for each point in the program allowing relocations of objects; without visible effects. This high level abstract machine model is used for most of the optimizer. As; a result, transform passes do not need to be e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:5948,Safety,safe,safe,5948,"llowing relocations of objects; without visible effects. This high level abstract machine model is used for most of the optimizer. As; a result, transform passes do not need to be extended to look through explicit; relocation sequence. Before starting code generation, we switch; representations to an explicit form. The exact location chosen for lowering; is an implementation detail. Note that most of the value of the abstract machine model comes for collectors; which need to model potentially relocatable objects. For a compiler which; supports only a non-relocating collector, you may wish to consider starting; with the fully explicit form. Warning: There is one currently known semantic hole in the definition of; non-integral pointers which has not been addressed upstream. To work around; this, you need to disable speculation of loads unless the memory type; (non-integral pointer vs anything else) is known to unchanged. That is, it is; not safe to speculate a load if doing causes a non-integral pointer value to; be loaded as any other type or vice versa. In practice, this restriction is; well isolated to isSafeToSpeculate in ValueTracking.cpp. Explicit Representation; ^^^^^^^^^^^^^^^^^^^^^^^. A frontend could directly generate this low level explicit form, but; doing so may inhibit optimization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the opt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:6794,Safety,safe,safepoint,6794,"gral pointers which has not been addressed upstream. To work around; this, you need to disable speculation of loads unless the memory type; (non-integral pointer vs anything else) is known to unchanged. That is, it is; not safe to speculate a load if doing causes a non-integral pointer value to; be loaded as any other type or vice versa. In practice, this restriction is; well isolated to isSafeToSpeculate in ValueTracking.cpp. Explicit Representation; ^^^^^^^^^^^^^^^^^^^^^^^. A frontend could directly generate this low level explicit form, but; doing so may inhibit optimization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the optimizer; from performing unsound optimizations.; #. recording a mapping of live pointers (and the allocation they're; associated with) for each statepoint. At the most abstract level, inserting a safepoint can be thought of as; replacing a call instruction with a call to a multiple return value; function which both calls the original target of the call, returns; its result, and returns updated values for any live pointers to; garbage collected objects. Note that the task of identifying all live pointers to garbage; collected values, transforming the IR to expose a pointer giving the; base object for every such live pointer, and inserting all the; intrinsics correctly is explicitly out of scope for this document.; The reco",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:7191,Safety,safe,safepoint,7191,"imization. Instead, it is recommended that; compilers with relocating collectors target the abstract machine model just; described. The heart of the explicit approach is to construct (or rewrite) the IR in a; manner where the possible updates performed by the garbage collector are; explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the optimizer; from performing unsound optimizations.; #. recording a mapping of live pointers (and the allocation they're; associated with) for each statepoint. At the most abstract level, inserting a safepoint can be thought of as; replacing a call instruction with a call to a multiple return value; function which both calls the original target of the call, returns; its result, and returns updated values for any live pointers to; garbage collected objects. Note that the task of identifying all live pointers to garbage; collected values, transforming the IR to expose a pointer giving the; base object for every such live pointer, and inserting all the; intrinsics correctly is explicitly out of scope for this document.; The recommended approach is to use the :ref:`utility passes; <statepoint-utilities>` described below. This abstract function call is concretely represented by a sequence of; intrinsic calls known collectively as a ""statepoint relocation sequence"". Let's consider a simple call in LLVM IR:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; call void ()* @foo(); ret i8 addrspace(1)* %obj; }. Depending on our language we may need to allow a safepoint during the execution; of ``foo``. If so, we need to let the collector update l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:8213,Safety,safe,safepoint,8213,"hought of as; replacing a call instruction with a call to a multiple return value; function which both calls the original target of the call, returns; its result, and returns updated values for any live pointers to; garbage collected objects. Note that the task of identifying all live pointers to garbage; collected values, transforming the IR to expose a pointer giving the; base object for every such live pointer, and inserting all the; intrinsics correctly is explicitly out of scope for this document.; The recommended approach is to use the :ref:`utility passes; <statepoint-utilities>` described below. This abstract function call is concretely represented by a sequence of; intrinsic calls known collectively as a ""statepoint relocation sequence"". Let's consider a simple call in LLVM IR:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; call void ()* @foo(); ret i8 addrspace(1)* %obj; }. Depending on our language we may need to allow a safepoint during the execution; of ``foo``. If so, we need to let the collector update local values in the; current frame. If we don't, we'll be accessing a potential invalid reference; once we eventually return from the call. In this example, we need to relocate the SSA value ``%obj``. Since we can't; actually change the value in the SSA value ``%obj``, we need to introduce a new; SSA value ``%obj.relocated`` which represents the potentially changed value of; ``%obj`` after the safepoint and update any following uses appropriately. The; resulting relocation sequence is:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; %0 = call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj); %obj.relocated = call coldcc i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %0, i32 7, i32 7); ret i8 addrspace(1)* %obj.re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:8697,Safety,safe,safepoint,8697,"y out of scope for this document.; The recommended approach is to use the :ref:`utility passes; <statepoint-utilities>` described below. This abstract function call is concretely represented by a sequence of; intrinsic calls known collectively as a ""statepoint relocation sequence"". Let's consider a simple call in LLVM IR:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; call void ()* @foo(); ret i8 addrspace(1)* %obj; }. Depending on our language we may need to allow a safepoint during the execution; of ``foo``. If so, we need to let the collector update local values in the; current frame. If we don't, we'll be accessing a potential invalid reference; once we eventually return from the call. In this example, we need to relocate the SSA value ``%obj``. Since we can't; actually change the value in the SSA value ``%obj``, we need to introduce a new; SSA value ``%obj.relocated`` which represents the potentially changed value of; ``%obj`` after the safepoint and update any following uses appropriately. The; resulting relocation sequence is:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; %0 = call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj); %obj.relocated = call coldcc i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %0, i32 7, i32 7); ret i8 addrspace(1)* %obj.relocated; }. Ideally, this sequence would have been represented as a M argument, N; return value function (where M is the number of values being; relocated + the original call arguments and N is the original return; value + each relocated value), but LLVM does not easily support such a; representation. Instead, the statepoint intrinsic marks the actual site of the; safepoint or statepoint. The statepoint returns a token value (which; exists only at compile time). To get",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:9577,Safety,safe,safepoint,9577,"lue ``%obj``, we need to introduce a new; SSA value ``%obj.relocated`` which represents the potentially changed value of; ``%obj`` after the safepoint and update any following uses appropriately. The; resulting relocation sequence is:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; %0 = call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj); %obj.relocated = call coldcc i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %0, i32 7, i32 7); ret i8 addrspace(1)* %obj.relocated; }. Ideally, this sequence would have been represented as a M argument, N; return value function (where M is the number of values being; relocated + the original call arguments and N is the original return; value + each relocated value), but LLVM does not easily support such a; representation. Instead, the statepoint intrinsic marks the actual site of the; safepoint or statepoint. The statepoint returns a token value (which; exists only at compile time). To get back the original return value; of the call, we use the ``gc.result`` intrinsic. To get the relocation; of each pointer in turn, we use the ``gc.relocate`` intrinsic with the; appropriate index. Note that both the ``gc.relocate`` and ``gc.result`` are; tied to the statepoint. The combination forms a ""statepoint relocation; sequence"" and represents the entirety of a parseable call or 'statepoint'. When lowered, this example would generate the following x86 assembly:. .. code-block:: gas. 	 .globl	test1; 	 .align	16, 0x90; 	 pushq	%rax; 	 callq	foo; .Ltmp1:; 	 movq	(%rsp), %rax # This load is redundant (oops!); 	 popq	%rdx; 	 retq. Each of the potentially relocated values has been spilled to the; stack, and a record of that location has been recorded to the; :ref:`Stack Map section <stackmap-section>`. If the garbage collector; needs to update any of these pointe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:10282,Safety,redund,redundant,10282,"argument, N; return value function (where M is the number of values being; relocated + the original call arguments and N is the original return; value + each relocated value), but LLVM does not easily support such a; representation. Instead, the statepoint intrinsic marks the actual site of the; safepoint or statepoint. The statepoint returns a token value (which; exists only at compile time). To get back the original return value; of the call, we use the ``gc.result`` intrinsic. To get the relocation; of each pointer in turn, we use the ``gc.relocate`` intrinsic with the; appropriate index. Note that both the ``gc.relocate`` and ``gc.result`` are; tied to the statepoint. The combination forms a ""statepoint relocation; sequence"" and represents the entirety of a parseable call or 'statepoint'. When lowered, this example would generate the following x86 assembly:. .. code-block:: gas. 	 .globl	test1; 	 .align	16, 0x90; 	 pushq	%rax; 	 callq	foo; .Ltmp1:; 	 movq	(%rsp), %rax # This load is redundant (oops!); 	 popq	%rdx; 	 retq. Each of the potentially relocated values has been spilled to the; stack, and a record of that location has been recorded to the; :ref:`Stack Map section <stackmap-section>`. If the garbage collector; needs to update any of these pointers during the call, it knows; exactly what to change. The relevant parts of the StackMap section for our example are:. .. code-block:: gas. # This describes the call site; # Stack Maps: callsite 2882400000; 	 .quad	2882400000; 	 .long	.Ltmp1-test1; 	 .short	0; # .. 8 entries skipped ..; # This entry describes the spill slot which is directly addressable; # off RSP with offset 0. Given the value was spilled with a pushq,; # that makes sense.; # Stack Maps: Loc 8: Direct RSP [encoding: .byte 2, .byte 8, .short 7, .int 0]; 	 .byte	2; 	 .byte	8; 	 .short	7; 	 .long	0. This example was taken from the tests for the :ref:`RewriteStatepointsForGC`; utility pass. As such, its full StackMap can be easily examined with the; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:13021,Safety,safe,safepoint,13021,"'s the explicit lowering for the previous example for a non-relocating; collector:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj); ret i8 addrspace(1)* %obj; }. Recording On Stack Regions; ^^^^^^^^^^^^^^^^^^^^^^^^^^. In addition to the explicit relocation form previously described, the; statepoint infrastructure also allows the listing of allocas within the gc; pointer list. Allocas can be listed with or without additional explicit gc; pointer values and relocations. An alloca in the gc region of the statepoint operand list will cause the; address of the stack region to be listed in the stackmap for the statepoint. This mechanism can be used to describe explicit spill slots if desired. It; then becomes the generator's responsibility to ensure that values are; spill/filled to/from the alloca as needed on either side of the safepoint.; Note that there is no way to indicate a corresponding base pointer for such; an explicitly specified spill slot, so usage is restricted to values for; which the associated collector can derive the object base from the pointer; itself. This mechanism can be used to describe on stack objects containing; references provided that the collector can map from the location on the; stack to a heap map describing the internal layout of the references the; collector needs to process. WARNING: At the moment, this alternate form is not well exercised. It is; recommended to use this with caution and expect to have to fix a few bugs.; In particular, the RewriteStatepointsForGC utility pass does not do; anything for allocas today. Base & Derived Pointers; ^^^^^^^^^^^^^^^^^^^^^^^. A ""base pointer"" is one which points to the starting address of an allocation; (object). A ""derived pointer"" is one which is offset from a base poin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:15216,Safety,safe,safepoint,15216,"n the bounds of the allocation; they're associated with. As a result, the base object can be found at; runtime provided the bounds of allocations are known to the runtime system. ""Exterior derived pointers"" are outside the bounds of the associated object;; they may even fall within *another* allocations address range. As a result,; there is no way for a garbage collector to determine which allocation they; are associated with at runtime and compiler support is needed. The ``gc.relocate`` intrinsic supports an explicit operand for describing the; allocation associated with a derived pointer. This operand is frequently; referred to as the base operand, but does not strictly speaking have to be; a base pointer, but it does need to lie within the bounds of the associated; allocation. Some collectors may require that the operand be an actual base; pointer rather than merely an internal derived pointer. Note that during; lowering both the base and derived pointer operands are required to be live; over the associated call safepoint even if the base is otherwise unused; afterwards. If we extend our previous example to include a pointless derived pointer,; we get:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; %gep = getelementptr i8, i8 addrspace(1)* %obj, i64 20000; %token = call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj, i8 addrspace(1)* %gep); %obj.relocated = call i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %token, i32 7, i32 7); %gep.relocated = call i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %token, i32 7, i32 8); %p = getelementptr i8, i8 addrspace(1)* %gep, i64 -20000; ret i8 addrspace(1)* %p; }. Note that in this example %p and %obj.relocate are the same address and we; could replace one with the other, potentially removing the derived pointer; from the l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:16200,Safety,safe,safepoint,16200," derived pointer operands are required to be live; over the associated call safepoint even if the base is otherwise unused; afterwards. If we extend our previous example to include a pointless derived pointer,; we get:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; %gep = getelementptr i8, i8 addrspace(1)* %obj, i64 20000; %token = call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj, i8 addrspace(1)* %gep); %obj.relocated = call i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %token, i32 7, i32 7); %gep.relocated = call i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %token, i32 7, i32 8); %p = getelementptr i8, i8 addrspace(1)* %gep, i64 -20000; ret i8 addrspace(1)* %p; }. Note that in this example %p and %obj.relocate are the same address and we; could replace one with the other, potentially removing the derived pointer; from the live set at the safepoint entirely. .. _gc_transition_args:. GC Transitions; ^^^^^^^^^^^^^^^^^^. As a practical consideration, many garbage-collected systems allow code that is; collector-aware (""managed code"") to call code that is not collector-aware; (""unmanaged code""). It is common that such calls must also be safepoints, since; it is desirable to allow the collector to run during the execution of; unmanaged code. Furthermore, it is common that coordinating the transition from; managed to unmanaged code requires extra code generation at the call site to; inform the collector of the transition. In order to support these needs, a; statepoint may be marked as a GC transition, and data that is necessary to; perform the transition (if any) may be provided as additional arguments to the; statepoint. Note that although in many cases statepoints may be inferred to be GC; transitions based on the function symbols involved (e.g. a call from a; funct",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:16499,Safety,safe,safepoints,16499,"= call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj, i8 addrspace(1)* %gep); %obj.relocated = call i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %token, i32 7, i32 7); %gep.relocated = call i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %token, i32 7, i32 8); %p = getelementptr i8, i8 addrspace(1)* %gep, i64 -20000; ret i8 addrspace(1)* %p; }. Note that in this example %p and %obj.relocate are the same address and we; could replace one with the other, potentially removing the derived pointer; from the live set at the safepoint entirely. .. _gc_transition_args:. GC Transitions; ^^^^^^^^^^^^^^^^^^. As a practical consideration, many garbage-collected systems allow code that is; collector-aware (""managed code"") to call code that is not collector-aware; (""unmanaged code""). It is common that such calls must also be safepoints, since; it is desirable to allow the collector to run during the execution of; unmanaged code. Furthermore, it is common that coordinating the transition from; managed to unmanaged code requires extra code generation at the call site to; inform the collector of the transition. In order to support these needs, a; statepoint may be marked as a GC transition, and data that is necessary to; perform the transition (if any) may be provided as additional arguments to the; statepoint. Note that although in many cases statepoints may be inferred to be GC; transitions based on the function symbols involved (e.g. a call from a; function with GC strategy ""foo"" to a function with GC strategy ""bar""),; indirect calls that are also GC transitions must also be supported. This; requirement is the driving force behind the decision to require that GC; transitions are explicitly marked. Let's revisit the sample given above, this time treating the call to ``@foo``; as a GC transition. Depending on our target, the transition co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:19141,Safety,redund,redundant,19141,", i32 0, i8 addrspace(1)* %obj); %obj.relocated = call coldcc i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %0, i32 7, i32 7); ret i8 addrspace(1)* %obj.relocated; }. During lowering, this will result in an instruction selection DAG that looks; something like:. ::. CALLSEQ_START; ...; GC_TRANSITION_START (lowered i32 *@Flag), SRCVALUE i32* Flag; STATEPOINT; GC_TRANSITION_END (lowered i32 *@Flag), SRCVALUE i32 *Flag; ...; CALLSEQ_END. In order to generate the necessary transition code, the backend for each target; supported by ""hypothetical-gc"" must be modified to lower ``GC_TRANSITION_START``; and ``GC_TRANSITION_END`` nodes appropriately when the ""hypothetical-gc""; strategy is in use for a particular function. Assuming that such lowering has; been added for X86, the generated assembly would be:. .. code-block:: gas. 	 .globl	test1; 	 .align	16, 0x90; 	 pushq	%rax; 	 movl $1, %fs:Flag@TPOFF; 	 callq	foo; 	 movl $0, %fs:Flag@TPOFF; .Ltmp1:; 	 movq	(%rsp), %rax # This load is redundant (oops!); 	 popq	%rdx; 	 retq. Note that the design as presented above is not fully implemented: in particular,; strategy-specific lowering is not present, and all GC transitions are emitted as; as single no-op before and after the call instruction. These no-ops are often; removed by the backend during dead machine instruction elimination. Before the abstract machine model is lowered to the explicit statepoint model; of relocations by the :ref:`RewriteStatepointsForGC` pass it is possible for; any derived pointer to get its base pointer and offset from the base pointer; by using the ``gc.get.pointer.base`` and the ``gc.get.pointer.offset``; intrinsics respectively. These intrinsics are inlined by the; :ref:`RewriteStatepointsForGC` pass and must not be used after this pass. .. _statepoint-stackmap-format:. Stack Map Format; ================. Locations for each pointer value which may need read and/or updated by; the runtime or collector are provided in a separate section of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:23597,Safety,safe,safepoint,23597,"east once; duplicates; are possible.; * The Locations within each record may either be of pointer size or a; multiple of pointer size. In the later case, the record must be; interpreted as describing a sequence of pointers and their corresponding; base pointers. If the Location is of size N x sizeof(pointer), then; there will be N records of one pointer each contained within the Location.; Both Locations in a pair can be assumed to be of the same size. Note that the Locations used in each section may describe the same; physical location. e.g. A stack slot may appear as a deopt location,; a gc base pointer, and a gc derived pointer. The LiveOut section of the StkMapRecord will be empty for a statepoint; record. Safepoint Semantics & Verification; ==================================. The fundamental correctness property for the compiled code's; correctness w.r.t. the garbage collector is a dynamic one. It must be; the case that there is no dynamic trace such that an operation; involving a potentially relocated pointer is observably-after a; safepoint which could relocate it. 'observably-after' is this usage; means that an outside observer could observe this sequence of events; in a way which precludes the operation being performed before the; safepoint. To understand why this 'observable-after' property is required,; consider a null comparison performed on the original copy of a; relocated pointer. Assuming that control flow follows the safepoint,; there is no way to observe externally whether the null comparison is; performed before or after the safepoint. (Remember, the original; Value is unmodified by the safepoint.) The compiler is free to make; either scheduling choice. The actual correctness property implemented is slightly stronger than; this. We require that there be no *static path* on which a; potentially relocated pointer is 'observably-after' it may have been; relocated. This is slightly stronger than is strictly necessary (and; thus may disallow some other",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:23803,Safety,safe,safepoint,23803,"preted as describing a sequence of pointers and their corresponding; base pointers. If the Location is of size N x sizeof(pointer), then; there will be N records of one pointer each contained within the Location.; Both Locations in a pair can be assumed to be of the same size. Note that the Locations used in each section may describe the same; physical location. e.g. A stack slot may appear as a deopt location,; a gc base pointer, and a gc derived pointer. The LiveOut section of the StkMapRecord will be empty for a statepoint; record. Safepoint Semantics & Verification; ==================================. The fundamental correctness property for the compiled code's; correctness w.r.t. the garbage collector is a dynamic one. It must be; the case that there is no dynamic trace such that an operation; involving a potentially relocated pointer is observably-after a; safepoint which could relocate it. 'observably-after' is this usage; means that an outside observer could observe this sequence of events; in a way which precludes the operation being performed before the; safepoint. To understand why this 'observable-after' property is required,; consider a null comparison performed on the original copy of a; relocated pointer. Assuming that control flow follows the safepoint,; there is no way to observe externally whether the null comparison is; performed before or after the safepoint. (Remember, the original; Value is unmodified by the safepoint.) The compiler is free to make; either scheduling choice. The actual correctness property implemented is slightly stronger than; this. We require that there be no *static path* on which a; potentially relocated pointer is 'observably-after' it may have been; relocated. This is slightly stronger than is strictly necessary (and; thus may disallow some otherwise valid programs), but greatly; simplifies reasoning about correctness of the compiled code. By construction, this property will be upheld by the optimizer if; correctly establ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:24001,Safety,safe,safepoint,24001,"on may describe the same; physical location. e.g. A stack slot may appear as a deopt location,; a gc base pointer, and a gc derived pointer. The LiveOut section of the StkMapRecord will be empty for a statepoint; record. Safepoint Semantics & Verification; ==================================. The fundamental correctness property for the compiled code's; correctness w.r.t. the garbage collector is a dynamic one. It must be; the case that there is no dynamic trace such that an operation; involving a potentially relocated pointer is observably-after a; safepoint which could relocate it. 'observably-after' is this usage; means that an outside observer could observe this sequence of events; in a way which precludes the operation being performed before the; safepoint. To understand why this 'observable-after' property is required,; consider a null comparison performed on the original copy of a; relocated pointer. Assuming that control flow follows the safepoint,; there is no way to observe externally whether the null comparison is; performed before or after the safepoint. (Remember, the original; Value is unmodified by the safepoint.) The compiler is free to make; either scheduling choice. The actual correctness property implemented is slightly stronger than; this. We require that there be no *static path* on which a; potentially relocated pointer is 'observably-after' it may have been; relocated. This is slightly stronger than is strictly necessary (and; thus may disallow some otherwise valid programs), but greatly; simplifies reasoning about correctness of the compiled code. By construction, this property will be upheld by the optimizer if; correctly established in the source IR. This is a key invariant of; the design. The existing IR Verifier pass has been extended to check most of the; local restrictions on the intrinsics mentioned in their respective; documentation. The current implementation in LLVM does not check the; key relocation invariant, but this is ongoing wo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:24113,Safety,safe,safepoint,24113,"on may describe the same; physical location. e.g. A stack slot may appear as a deopt location,; a gc base pointer, and a gc derived pointer. The LiveOut section of the StkMapRecord will be empty for a statepoint; record. Safepoint Semantics & Verification; ==================================. The fundamental correctness property for the compiled code's; correctness w.r.t. the garbage collector is a dynamic one. It must be; the case that there is no dynamic trace such that an operation; involving a potentially relocated pointer is observably-after a; safepoint which could relocate it. 'observably-after' is this usage; means that an outside observer could observe this sequence of events; in a way which precludes the operation being performed before the; safepoint. To understand why this 'observable-after' property is required,; consider a null comparison performed on the original copy of a; relocated pointer. Assuming that control flow follows the safepoint,; there is no way to observe externally whether the null comparison is; performed before or after the safepoint. (Remember, the original; Value is unmodified by the safepoint.) The compiler is free to make; either scheduling choice. The actual correctness property implemented is slightly stronger than; this. We require that there be no *static path* on which a; potentially relocated pointer is 'observably-after' it may have been; relocated. This is slightly stronger than is strictly necessary (and; thus may disallow some otherwise valid programs), but greatly; simplifies reasoning about correctness of the compiled code. By construction, this property will be upheld by the optimizer if; correctly established in the source IR. This is a key invariant of; the design. The existing IR Verifier pass has been extended to check most of the; local restrictions on the intrinsics mentioned in their respective; documentation. The current implementation in LLVM does not check the; key relocation invariant, but this is ongoing wo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:24176,Safety,safe,safepoint,24176,"r, and a gc derived pointer. The LiveOut section of the StkMapRecord will be empty for a statepoint; record. Safepoint Semantics & Verification; ==================================. The fundamental correctness property for the compiled code's; correctness w.r.t. the garbage collector is a dynamic one. It must be; the case that there is no dynamic trace such that an operation; involving a potentially relocated pointer is observably-after a; safepoint which could relocate it. 'observably-after' is this usage; means that an outside observer could observe this sequence of events; in a way which precludes the operation being performed before the; safepoint. To understand why this 'observable-after' property is required,; consider a null comparison performed on the original copy of a; relocated pointer. Assuming that control flow follows the safepoint,; there is no way to observe externally whether the null comparison is; performed before or after the safepoint. (Remember, the original; Value is unmodified by the safepoint.) The compiler is free to make; either scheduling choice. The actual correctness property implemented is slightly stronger than; this. We require that there be no *static path* on which a; potentially relocated pointer is 'observably-after' it may have been; relocated. This is slightly stronger than is strictly necessary (and; thus may disallow some otherwise valid programs), but greatly; simplifies reasoning about correctness of the compiled code. By construction, this property will be upheld by the optimizer if; correctly established in the source IR. This is a key invariant of; the design. The existing IR Verifier pass has been extended to check most of the; local restrictions on the intrinsics mentioned in their respective; documentation. The current implementation in LLVM does not check the; key relocation invariant, but this is ongoing work on developing such; a verifier. Please ask on llvm-dev if you're interested in; experimenting with the current",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:25602,Safety,safe,safepoint,25602,"ly; simplifies reasoning about correctness of the compiled code. By construction, this property will be upheld by the optimizer if; correctly established in the source IR. This is a key invariant of; the design. The existing IR Verifier pass has been extended to check most of the; local restrictions on the intrinsics mentioned in their respective; documentation. The current implementation in LLVM does not check the; key relocation invariant, but this is ongoing work on developing such; a verifier. Please ask on llvm-dev if you're interested in; experimenting with the current version. .. _statepoint-utilities:. Utility Passes for Safepoint Insertion; ======================================. .. _RewriteStatepointsForGC:. RewriteStatepointsForGC; ^^^^^^^^^^^^^^^^^^^^^^^^. The pass RewriteStatepointsForGC transforms a function's IR to lower from the; abstract machine model described above to the explicit statepoint model of; relocations. To do this, it replaces all calls or invokes of functions which; might contain a safepoint poll with a ``gc.statepoint`` and associated full; relocation sequence, including all required ``gc.relocates``. This pass only applies to GCStrategy instances where the ``UseRS4GC`` flag; is set. The two builtin GC strategies with this set are the; ""statepoint-example"" and ""coreclr"" strategies. As an example, given this code:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; call void @foo(); ret i8 addrspace(1)* %obj; }. The pass would produce this IR:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; %0 = call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 2882400000, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 5, i32 0, i32 -1, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj); %obj.relocated = call coldcc i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %0, i32 12, i32 12); ret i8 addr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:27606,Safety,safe,safepoints,27606,"n %0, i32 12, i32 12); ret i8 addrspace(1)* %obj.relocated; }. In the above examples, the addrspace(1) marker on the pointers is the mechanism; that the ``statepoint-example`` GC strategy uses to distinguish references from; non references. This is controlled via GCStrategy::isGCManagedPointer. The; ``statepoint-example`` and ``coreclr`` strategies (the only two default; strategies that support statepoints) both use addrspace(1) to determine which; pointers are references, however custom strategies don't have to follow this; convention. This pass can be used an utility function by a language frontend that doesn't; want to manually reason about liveness, base pointers, or relocation when; constructing IR. As currently implemented, RewriteStatepointsForGC must be; run after SSA construction (i.e. mem2ref). RewriteStatepointsForGC will ensure that appropriate base pointers are listed; for every relocation created. It will do so by duplicating code as needed to; propagate the base pointer associated with each pointer being relocated to; the appropriate safepoints. The implementation assumes that the following; IR constructs produce base pointers: loads from the heap, addresses of global; variables, function arguments, function return values. Constant pointers (such; as null) are also assumed to be base pointers. In practice, this constraint; can be relaxed to producing interior derived pointers provided the target; collector can find the associated allocation from an arbitrary interior; derived pointer. By default RewriteStatepointsForGC passes in ``0xABCDEF00`` as the statepoint; ID and ``0`` as the number of patchable bytes to the newly constructed; ``gc.statepoint``. These values can be configured on a per-callsite; basis using the attributes ``""statepoint-id""`` and; ``""statepoint-num-patch-bytes""``. If a call site is marked with a; ``""statepoint-id""`` function attribute and its value is a positive; integer (represented as a string), then that value is used as the ID",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:30008,Safety,safe,safepoint,30008," RewriteStatepointsForGC should be run much later in the pass; pipeline, after most optimization is already done. This helps to improve; the quality of the generated code when compiled with garbage collection support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowering; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. As a part of lowering to the explicit model of relocations; RewriteStatepointsForGC performs GC specific lowering for the following; intrinsics:. * ``gc.get.pointer.base``; * ``gc.get.pointer.offset``; * ``llvm.memcpy.element.unordered.atomic.*``; * ``llvm.memmove.element.unordered.atomic.*``. There are two possible lowerings for the memcpy and memmove operations:; GC leaf lowering and GC parseable lowering. If a call is explicitly marked with; ""gc-leaf-function"" attribute the call is lowered to a GC leaf call to; '``__llvm_memcpy_element_unordered_atomic_*``' or; '``__llvm_memmove_element_unordered_atomic_*``' symbol. Such a call can not; take a safepoint. Otherwise, the call is made GC parseable by wrapping the; call into a statepoint. This makes it possible to take a safepoint during; copy operation. Note that a GC parseable copy operation is not required to; take a safepoint. For example, a short copy operation may be performed without; taking a safepoint. GC parseable calls to '``llvm.memcpy.element.unordered.atomic.*``',; '``llvm.memmove.element.unordered.atomic.*``' intrinsics are lowered to calls; to '``__llvm_memcpy_element_unordered_atomic_safepoint_*``',; '``__llvm_memmove_element_unordered_atomic_safepoint_*``' symbols respectively.; This way the runtime can provide implementations of copy operations with and; without safepoints. GC parseable lowering also involves adjusting the arguments for the call.; Memcpy and memmove intrinsics take derived pointers as source and destination; arguments. If a copy operation takes a safepoint it might need to relocate the; underlying source and destination objects. This ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:30134,Safety,safe,safepoint,30134,"; the quality of the generated code when compiled with garbage collection support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowering; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. As a part of lowering to the explicit model of relocations; RewriteStatepointsForGC performs GC specific lowering for the following; intrinsics:. * ``gc.get.pointer.base``; * ``gc.get.pointer.offset``; * ``llvm.memcpy.element.unordered.atomic.*``; * ``llvm.memmove.element.unordered.atomic.*``. There are two possible lowerings for the memcpy and memmove operations:; GC leaf lowering and GC parseable lowering. If a call is explicitly marked with; ""gc-leaf-function"" attribute the call is lowered to a GC leaf call to; '``__llvm_memcpy_element_unordered_atomic_*``' or; '``__llvm_memmove_element_unordered_atomic_*``' symbol. Such a call can not; take a safepoint. Otherwise, the call is made GC parseable by wrapping the; call into a statepoint. This makes it possible to take a safepoint during; copy operation. Note that a GC parseable copy operation is not required to; take a safepoint. For example, a short copy operation may be performed without; taking a safepoint. GC parseable calls to '``llvm.memcpy.element.unordered.atomic.*``',; '``llvm.memmove.element.unordered.atomic.*``' intrinsics are lowered to calls; to '``__llvm_memcpy_element_unordered_atomic_safepoint_*``',; '``__llvm_memmove_element_unordered_atomic_safepoint_*``' symbols respectively.; This way the runtime can provide implementations of copy operations with and; without safepoints. GC parseable lowering also involves adjusting the arguments for the call.; Memcpy and memmove intrinsics take derived pointers as source and destination; arguments. If a copy operation takes a safepoint it might need to relocate the; underlying source and destination objects. This requires the corresponding base; pointers to be available in the copy operation. In order to make the base; pointers available RewriteS",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:30235,Safety,safe,safepoint,30235," support. .. _RewriteStatepointsForGC_intrinsic_lowering:. RewriteStatepointsForGC intrinsic lowering; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. As a part of lowering to the explicit model of relocations; RewriteStatepointsForGC performs GC specific lowering for the following; intrinsics:. * ``gc.get.pointer.base``; * ``gc.get.pointer.offset``; * ``llvm.memcpy.element.unordered.atomic.*``; * ``llvm.memmove.element.unordered.atomic.*``. There are two possible lowerings for the memcpy and memmove operations:; GC leaf lowering and GC parseable lowering. If a call is explicitly marked with; ""gc-leaf-function"" attribute the call is lowered to a GC leaf call to; '``__llvm_memcpy_element_unordered_atomic_*``' or; '``__llvm_memmove_element_unordered_atomic_*``' symbol. Such a call can not; take a safepoint. Otherwise, the call is made GC parseable by wrapping the; call into a statepoint. This makes it possible to take a safepoint during; copy operation. Note that a GC parseable copy operation is not required to; take a safepoint. For example, a short copy operation may be performed without; taking a safepoint. GC parseable calls to '``llvm.memcpy.element.unordered.atomic.*``',; '``llvm.memmove.element.unordered.atomic.*``' intrinsics are lowered to calls; to '``__llvm_memcpy_element_unordered_atomic_safepoint_*``',; '``__llvm_memmove_element_unordered_atomic_safepoint_*``' symbols respectively.; This way the runtime can provide implementations of copy operations with and; without safepoints. GC parseable lowering also involves adjusting the arguments for the call.; Memcpy and memmove intrinsics take derived pointers as source and destination; arguments. If a copy operation takes a safepoint it might need to relocate the; underlying source and destination objects. This requires the corresponding base; pointers to be available in the copy operation. In order to make the base; pointers available RewriteStatepointsForGC replaces derived pointers with base; pointer and offset ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:30317,Safety,safe,safepoint,30317,"GC intrinsic lowering; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. As a part of lowering to the explicit model of relocations; RewriteStatepointsForGC performs GC specific lowering for the following; intrinsics:. * ``gc.get.pointer.base``; * ``gc.get.pointer.offset``; * ``llvm.memcpy.element.unordered.atomic.*``; * ``llvm.memmove.element.unordered.atomic.*``. There are two possible lowerings for the memcpy and memmove operations:; GC leaf lowering and GC parseable lowering. If a call is explicitly marked with; ""gc-leaf-function"" attribute the call is lowered to a GC leaf call to; '``__llvm_memcpy_element_unordered_atomic_*``' or; '``__llvm_memmove_element_unordered_atomic_*``' symbol. Such a call can not; take a safepoint. Otherwise, the call is made GC parseable by wrapping the; call into a statepoint. This makes it possible to take a safepoint during; copy operation. Note that a GC parseable copy operation is not required to; take a safepoint. For example, a short copy operation may be performed without; taking a safepoint. GC parseable calls to '``llvm.memcpy.element.unordered.atomic.*``',; '``llvm.memmove.element.unordered.atomic.*``' intrinsics are lowered to calls; to '``__llvm_memcpy_element_unordered_atomic_safepoint_*``',; '``__llvm_memmove_element_unordered_atomic_safepoint_*``' symbols respectively.; This way the runtime can provide implementations of copy operations with and; without safepoints. GC parseable lowering also involves adjusting the arguments for the call.; Memcpy and memmove intrinsics take derived pointers as source and destination; arguments. If a copy operation takes a safepoint it might need to relocate the; underlying source and destination objects. This requires the corresponding base; pointers to be available in the copy operation. In order to make the base; pointers available RewriteStatepointsForGC replaces derived pointers with base; pointer and offset pairs. For example:. .. code-block:: llvm. declare void @__llvm_memcpy_element_u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:30705,Safety,safe,safepoints,30705,"ible lowerings for the memcpy and memmove operations:; GC leaf lowering and GC parseable lowering. If a call is explicitly marked with; ""gc-leaf-function"" attribute the call is lowered to a GC leaf call to; '``__llvm_memcpy_element_unordered_atomic_*``' or; '``__llvm_memmove_element_unordered_atomic_*``' symbol. Such a call can not; take a safepoint. Otherwise, the call is made GC parseable by wrapping the; call into a statepoint. This makes it possible to take a safepoint during; copy operation. Note that a GC parseable copy operation is not required to; take a safepoint. For example, a short copy operation may be performed without; taking a safepoint. GC parseable calls to '``llvm.memcpy.element.unordered.atomic.*``',; '``llvm.memmove.element.unordered.atomic.*``' intrinsics are lowered to calls; to '``__llvm_memcpy_element_unordered_atomic_safepoint_*``',; '``__llvm_memmove_element_unordered_atomic_safepoint_*``' symbols respectively.; This way the runtime can provide implementations of copy operations with and; without safepoints. GC parseable lowering also involves adjusting the arguments for the call.; Memcpy and memmove intrinsics take derived pointers as source and destination; arguments. If a copy operation takes a safepoint it might need to relocate the; underlying source and destination objects. This requires the corresponding base; pointers to be available in the copy operation. In order to make the base; pointers available RewriteStatepointsForGC replaces derived pointers with base; pointer and offset pairs. For example:. .. code-block:: llvm. declare void @__llvm_memcpy_element_unordered_atomic_safepoint_1(; i8 addrspace(1)* %dest_base, i64 %dest_offset,; i8 addrspace(1)* %src_base, i64 %src_offset,; i64 %length). .. _PlaceSafepoints:. PlaceSafepoints; ^^^^^^^^^^^^^^^^. The pass PlaceSafepoints inserts safepoint polls sufficient to ensure running; code checks for a safepoint request on a timely manner. This pass is expected; to be run before RewriteStat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:30910,Safety,safe,safepoint,30910,"move_element_unordered_atomic_*``' symbol. Such a call can not; take a safepoint. Otherwise, the call is made GC parseable by wrapping the; call into a statepoint. This makes it possible to take a safepoint during; copy operation. Note that a GC parseable copy operation is not required to; take a safepoint. For example, a short copy operation may be performed without; taking a safepoint. GC parseable calls to '``llvm.memcpy.element.unordered.atomic.*``',; '``llvm.memmove.element.unordered.atomic.*``' intrinsics are lowered to calls; to '``__llvm_memcpy_element_unordered_atomic_safepoint_*``',; '``__llvm_memmove_element_unordered_atomic_safepoint_*``' symbols respectively.; This way the runtime can provide implementations of copy operations with and; without safepoints. GC parseable lowering also involves adjusting the arguments for the call.; Memcpy and memmove intrinsics take derived pointers as source and destination; arguments. If a copy operation takes a safepoint it might need to relocate the; underlying source and destination objects. This requires the corresponding base; pointers to be available in the copy operation. In order to make the base; pointers available RewriteStatepointsForGC replaces derived pointers with base; pointer and offset pairs. For example:. .. code-block:: llvm. declare void @__llvm_memcpy_element_unordered_atomic_safepoint_1(; i8 addrspace(1)* %dest_base, i64 %dest_offset,; i8 addrspace(1)* %src_base, i64 %src_offset,; i64 %length). .. _PlaceSafepoints:. PlaceSafepoints; ^^^^^^^^^^^^^^^^. The pass PlaceSafepoints inserts safepoint polls sufficient to ensure running; code checks for a safepoint request on a timely manner. This pass is expected; to be run before RewriteStatepointsForGC and thus does not produce full; relocation sequences. As an example, given input IR of the following:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @foo(); ret void; }. declare void @do_safepoint(); define void @gc.safepoin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:31514,Safety,safe,safepoint,31514,"_memmove_element_unordered_atomic_safepoint_*``' symbols respectively.; This way the runtime can provide implementations of copy operations with and; without safepoints. GC parseable lowering also involves adjusting the arguments for the call.; Memcpy and memmove intrinsics take derived pointers as source and destination; arguments. If a copy operation takes a safepoint it might need to relocate the; underlying source and destination objects. This requires the corresponding base; pointers to be available in the copy operation. In order to make the base; pointers available RewriteStatepointsForGC replaces derived pointers with base; pointer and offset pairs. For example:. .. code-block:: llvm. declare void @__llvm_memcpy_element_unordered_atomic_safepoint_1(; i8 addrspace(1)* %dest_base, i64 %dest_offset,; i8 addrspace(1)* %src_base, i64 %src_offset,; i64 %length). .. _PlaceSafepoints:. PlaceSafepoints; ^^^^^^^^^^^^^^^^. The pass PlaceSafepoints inserts safepoint polls sufficient to ensure running; code checks for a safepoint request on a timely manner. This pass is expected; to be run before RewriteStatepointsForGC and thus does not produce full; relocation sequences. As an example, given input IR of the following:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @foo(); ret void; }. declare void @do_safepoint(); define void @gc.safepoint_poll() {; call void @do_safepoint(); ret void; }. This pass would produce the following IR:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @do_safepoint(); call void @foo(); ret void; }. In this case, we've added an (unconditional) entry safepoint poll. Note that; despite appearances, the entry poll is not necessarily redundant. We'd have to; know that ``foo`` and ``test`` were not mutually recursive for the poll to be; redundant. In practice, you'd probably want to your poll definition to contain; a conditional branch of some form. At the moment, PlaceSafepoints can in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:31578,Safety,safe,safepoint,31578,"_memmove_element_unordered_atomic_safepoint_*``' symbols respectively.; This way the runtime can provide implementations of copy operations with and; without safepoints. GC parseable lowering also involves adjusting the arguments for the call.; Memcpy and memmove intrinsics take derived pointers as source and destination; arguments. If a copy operation takes a safepoint it might need to relocate the; underlying source and destination objects. This requires the corresponding base; pointers to be available in the copy operation. In order to make the base; pointers available RewriteStatepointsForGC replaces derived pointers with base; pointer and offset pairs. For example:. .. code-block:: llvm. declare void @__llvm_memcpy_element_unordered_atomic_safepoint_1(; i8 addrspace(1)* %dest_base, i64 %dest_offset,; i8 addrspace(1)* %src_base, i64 %src_offset,; i64 %length). .. _PlaceSafepoints:. PlaceSafepoints; ^^^^^^^^^^^^^^^^. The pass PlaceSafepoints inserts safepoint polls sufficient to ensure running; code checks for a safepoint request on a timely manner. This pass is expected; to be run before RewriteStatepointsForGC and thus does not produce full; relocation sequences. As an example, given input IR of the following:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @foo(); ret void; }. declare void @do_safepoint(); define void @gc.safepoint_poll() {; call void @do_safepoint(); ret void; }. This pass would produce the following IR:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @do_safepoint(); call void @foo(); ret void; }. In this case, we've added an (unconditional) entry safepoint poll. Note that; despite appearances, the entry poll is not necessarily redundant. We'd have to; know that ``foo`` and ``test`` were not mutually recursive for the poll to be; redundant. In practice, you'd probably want to your poll definition to contain; a conditional branch of some form. At the moment, PlaceSafepoints can in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:32210,Safety,safe,safepoint,32210,"ter and offset pairs. For example:. .. code-block:: llvm. declare void @__llvm_memcpy_element_unordered_atomic_safepoint_1(; i8 addrspace(1)* %dest_base, i64 %dest_offset,; i8 addrspace(1)* %src_base, i64 %src_offset,; i64 %length). .. _PlaceSafepoints:. PlaceSafepoints; ^^^^^^^^^^^^^^^^. The pass PlaceSafepoints inserts safepoint polls sufficient to ensure running; code checks for a safepoint request on a timely manner. This pass is expected; to be run before RewriteStatepointsForGC and thus does not produce full; relocation sequences. As an example, given input IR of the following:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @foo(); ret void; }. declare void @do_safepoint(); define void @gc.safepoint_poll() {; call void @do_safepoint(); ret void; }. This pass would produce the following IR:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @do_safepoint(); call void @foo(); ret void; }. In this case, we've added an (unconditional) entry safepoint poll. Note that; despite appearances, the entry poll is not necessarily redundant. We'd have to; know that ``foo`` and ``test`` were not mutually recursive for the poll to be; redundant. In practice, you'd probably want to your poll definition to contain; a conditional branch of some form. At the moment, PlaceSafepoints can insert safepoint polls at method entry and; loop backedges locations. Extending this to work with return polls would be; straight forward if desired. PlaceSafepoints includes a number of optimizations to avoid placing safepoint; polls at particular sites unless needed to ensure timely execution of a poll; under normal conditions. PlaceSafepoints does not attempt to ensure timely; execution of a poll under worst case conditions such as heavy system paging. The implementation of a safepoint poll action is specified by looking up a; function of the name ``gc.safepoint_poll`` in the containing Module. The body; of this function is inserted at",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:32292,Safety,redund,redundant,32292,"__llvm_memcpy_element_unordered_atomic_safepoint_1(; i8 addrspace(1)* %dest_base, i64 %dest_offset,; i8 addrspace(1)* %src_base, i64 %src_offset,; i64 %length). .. _PlaceSafepoints:. PlaceSafepoints; ^^^^^^^^^^^^^^^^. The pass PlaceSafepoints inserts safepoint polls sufficient to ensure running; code checks for a safepoint request on a timely manner. This pass is expected; to be run before RewriteStatepointsForGC and thus does not produce full; relocation sequences. As an example, given input IR of the following:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @foo(); ret void; }. declare void @do_safepoint(); define void @gc.safepoint_poll() {; call void @do_safepoint(); ret void; }. This pass would produce the following IR:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @do_safepoint(); call void @foo(); ret void; }. In this case, we've added an (unconditional) entry safepoint poll. Note that; despite appearances, the entry poll is not necessarily redundant. We'd have to; know that ``foo`` and ``test`` were not mutually recursive for the poll to be; redundant. In practice, you'd probably want to your poll definition to contain; a conditional branch of some form. At the moment, PlaceSafepoints can insert safepoint polls at method entry and; loop backedges locations. Extending this to work with return polls would be; straight forward if desired. PlaceSafepoints includes a number of optimizations to avoid placing safepoint; polls at particular sites unless needed to ensure timely execution of a poll; under normal conditions. PlaceSafepoints does not attempt to ensure timely; execution of a poll under worst case conditions such as heavy system paging. The implementation of a safepoint poll action is specified by looking up a; function of the name ``gc.safepoint_poll`` in the containing Module. The body; of this function is inserted at each poll site desired. While calls or invokes; inside this method are ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:32396,Safety,redund,redundant,32396,"_offset,; i8 addrspace(1)* %src_base, i64 %src_offset,; i64 %length). .. _PlaceSafepoints:. PlaceSafepoints; ^^^^^^^^^^^^^^^^. The pass PlaceSafepoints inserts safepoint polls sufficient to ensure running; code checks for a safepoint request on a timely manner. This pass is expected; to be run before RewriteStatepointsForGC and thus does not produce full; relocation sequences. As an example, given input IR of the following:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @foo(); ret void; }. declare void @do_safepoint(); define void @gc.safepoint_poll() {; call void @do_safepoint(); ret void; }. This pass would produce the following IR:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @do_safepoint(); call void @foo(); ret void; }. In this case, we've added an (unconditional) entry safepoint poll. Note that; despite appearances, the entry poll is not necessarily redundant. We'd have to; know that ``foo`` and ``test`` were not mutually recursive for the poll to be; redundant. In practice, you'd probably want to your poll definition to contain; a conditional branch of some form. At the moment, PlaceSafepoints can insert safepoint polls at method entry and; loop backedges locations. Extending this to work with return polls would be; straight forward if desired. PlaceSafepoints includes a number of optimizations to avoid placing safepoint; polls at particular sites unless needed to ensure timely execution of a poll; under normal conditions. PlaceSafepoints does not attempt to ensure timely; execution of a poll under worst case conditions such as heavy system paging. The implementation of a safepoint poll action is specified by looking up a; function of the name ``gc.safepoint_poll`` in the containing Module. The body; of this function is inserted at each poll site desired. While calls or invokes; inside this method are transformed to a ``gc.statepoints``, recursive poll; insertion is not performed. This pass",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:32553,Safety,safe,safepoint,32553,"de checks for a safepoint request on a timely manner. This pass is expected; to be run before RewriteStatepointsForGC and thus does not produce full; relocation sequences. As an example, given input IR of the following:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @foo(); ret void; }. declare void @do_safepoint(); define void @gc.safepoint_poll() {; call void @do_safepoint(); ret void; }. This pass would produce the following IR:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @do_safepoint(); call void @foo(); ret void; }. In this case, we've added an (unconditional) entry safepoint poll. Note that; despite appearances, the entry poll is not necessarily redundant. We'd have to; know that ``foo`` and ``test`` were not mutually recursive for the poll to be; redundant. In practice, you'd probably want to your poll definition to contain; a conditional branch of some form. At the moment, PlaceSafepoints can insert safepoint polls at method entry and; loop backedges locations. Extending this to work with return polls would be; straight forward if desired. PlaceSafepoints includes a number of optimizations to avoid placing safepoint; polls at particular sites unless needed to ensure timely execution of a poll; under normal conditions. PlaceSafepoints does not attempt to ensure timely; execution of a poll under worst case conditions such as heavy system paging. The implementation of a safepoint poll action is specified by looking up a; function of the name ``gc.safepoint_poll`` in the containing Module. The body; of this function is inserted at each poll site desired. While calls or invokes; inside this method are transformed to a ``gc.statepoints``, recursive poll; insertion is not performed. This pass is useful for any language frontend which only has to support; garbage collection semantics at safepoints. If you need other abstract; frame information at safepoints (e.g. for deoptimization or introspection",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:32750,Safety,avoid,avoid,32750,"code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @foo(); ret void; }. declare void @do_safepoint(); define void @gc.safepoint_poll() {; call void @do_safepoint(); ret void; }. This pass would produce the following IR:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @do_safepoint(); call void @foo(); ret void; }. In this case, we've added an (unconditional) entry safepoint poll. Note that; despite appearances, the entry poll is not necessarily redundant. We'd have to; know that ``foo`` and ``test`` were not mutually recursive for the poll to be; redundant. In practice, you'd probably want to your poll definition to contain; a conditional branch of some form. At the moment, PlaceSafepoints can insert safepoint polls at method entry and; loop backedges locations. Extending this to work with return polls would be; straight forward if desired. PlaceSafepoints includes a number of optimizations to avoid placing safepoint; polls at particular sites unless needed to ensure timely execution of a poll; under normal conditions. PlaceSafepoints does not attempt to ensure timely; execution of a poll under worst case conditions such as heavy system paging. The implementation of a safepoint poll action is specified by looking up a; function of the name ``gc.safepoint_poll`` in the containing Module. The body; of this function is inserted at each poll site desired. While calls or invokes; inside this method are transformed to a ``gc.statepoints``, recursive poll; insertion is not performed. This pass is useful for any language frontend which only has to support; garbage collection semantics at safepoints. If you need other abstract; frame information at safepoints (e.g. for deoptimization or introspection),; you can insert safepoint polls in the frontend. If you have the later case,; please ask on llvm-dev for suggestions. There's been a good amount of work; done on making such a scheme work well in practice which is not ye",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:32764,Safety,safe,safepoint,32764,"code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @foo(); ret void; }. declare void @do_safepoint(); define void @gc.safepoint_poll() {; call void @do_safepoint(); ret void; }. This pass would produce the following IR:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @do_safepoint(); call void @foo(); ret void; }. In this case, we've added an (unconditional) entry safepoint poll. Note that; despite appearances, the entry poll is not necessarily redundant. We'd have to; know that ``foo`` and ``test`` were not mutually recursive for the poll to be; redundant. In practice, you'd probably want to your poll definition to contain; a conditional branch of some form. At the moment, PlaceSafepoints can insert safepoint polls at method entry and; loop backedges locations. Extending this to work with return polls would be; straight forward if desired. PlaceSafepoints includes a number of optimizations to avoid placing safepoint; polls at particular sites unless needed to ensure timely execution of a poll; under normal conditions. PlaceSafepoints does not attempt to ensure timely; execution of a poll under worst case conditions such as heavy system paging. The implementation of a safepoint poll action is specified by looking up a; function of the name ``gc.safepoint_poll`` in the containing Module. The body; of this function is inserted at each poll site desired. While calls or invokes; inside this method are transformed to a ``gc.statepoints``, recursive poll; insertion is not performed. This pass is useful for any language frontend which only has to support; garbage collection semantics at safepoints. If you need other abstract; frame information at safepoints (e.g. for deoptimization or introspection),; you can insert safepoint polls in the frontend. If you have the later case,; please ask on llvm-dev for suggestions. There's been a good amount of work; done on making such a scheme work well in practice which is not ye",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:33030,Safety,safe,safepoint,33030,"fine void @test() gc ""statepoint-example"" {; call void @do_safepoint(); call void @foo(); ret void; }. In this case, we've added an (unconditional) entry safepoint poll. Note that; despite appearances, the entry poll is not necessarily redundant. We'd have to; know that ``foo`` and ``test`` were not mutually recursive for the poll to be; redundant. In practice, you'd probably want to your poll definition to contain; a conditional branch of some form. At the moment, PlaceSafepoints can insert safepoint polls at method entry and; loop backedges locations. Extending this to work with return polls would be; straight forward if desired. PlaceSafepoints includes a number of optimizations to avoid placing safepoint; polls at particular sites unless needed to ensure timely execution of a poll; under normal conditions. PlaceSafepoints does not attempt to ensure timely; execution of a poll under worst case conditions such as heavy system paging. The implementation of a safepoint poll action is specified by looking up a; function of the name ``gc.safepoint_poll`` in the containing Module. The body; of this function is inserted at each poll site desired. While calls or invokes; inside this method are transformed to a ``gc.statepoints``, recursive poll; insertion is not performed. This pass is useful for any language frontend which only has to support; garbage collection semantics at safepoints. If you need other abstract; frame information at safepoints (e.g. for deoptimization or introspection),; you can insert safepoint polls in the frontend. If you have the later case,; please ask on llvm-dev for suggestions. There's been a good amount of work; done on making such a scheme work well in practice which is not yet documented; here. Supported Architectures; =======================. Support for statepoint generation requires some code for each backend.; Today, only Aarch64 and X86_64 are supported. .. _OpenWork:. Limitations and Half Baked Ideas; ================================. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:33450,Safety,safe,safepoints,33450,"ant. In practice, you'd probably want to your poll definition to contain; a conditional branch of some form. At the moment, PlaceSafepoints can insert safepoint polls at method entry and; loop backedges locations. Extending this to work with return polls would be; straight forward if desired. PlaceSafepoints includes a number of optimizations to avoid placing safepoint; polls at particular sites unless needed to ensure timely execution of a poll; under normal conditions. PlaceSafepoints does not attempt to ensure timely; execution of a poll under worst case conditions such as heavy system paging. The implementation of a safepoint poll action is specified by looking up a; function of the name ``gc.safepoint_poll`` in the containing Module. The body; of this function is inserted at each poll site desired. While calls or invokes; inside this method are transformed to a ``gc.statepoints``, recursive poll; insertion is not performed. This pass is useful for any language frontend which only has to support; garbage collection semantics at safepoints. If you need other abstract; frame information at safepoints (e.g. for deoptimization or introspection),; you can insert safepoint polls in the frontend. If you have the later case,; please ask on llvm-dev for suggestions. There's been a good amount of work; done on making such a scheme work well in practice which is not yet documented; here. Supported Architectures; =======================. Support for statepoint generation requires some code for each backend.; Today, only Aarch64 and X86_64 are supported. .. _OpenWork:. Limitations and Half Baked Ideas; ================================. Mixing References and Raw Pointers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Support for languages which allow unmanaged pointers to garbage collected; objects (i.e. pass a pointer to an object to a C routine) in the abstract; machine model. At the moment, the best idea on how to approach this; involves an intrinsic or opaque function which hides th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:33511,Safety,safe,safepoints,33511,"nch of some form. At the moment, PlaceSafepoints can insert safepoint polls at method entry and; loop backedges locations. Extending this to work with return polls would be; straight forward if desired. PlaceSafepoints includes a number of optimizations to avoid placing safepoint; polls at particular sites unless needed to ensure timely execution of a poll; under normal conditions. PlaceSafepoints does not attempt to ensure timely; execution of a poll under worst case conditions such as heavy system paging. The implementation of a safepoint poll action is specified by looking up a; function of the name ``gc.safepoint_poll`` in the containing Module. The body; of this function is inserted at each poll site desired. While calls or invokes; inside this method are transformed to a ``gc.statepoints``, recursive poll; insertion is not performed. This pass is useful for any language frontend which only has to support; garbage collection semantics at safepoints. If you need other abstract; frame information at safepoints (e.g. for deoptimization or introspection),; you can insert safepoint polls in the frontend. If you have the later case,; please ask on llvm-dev for suggestions. There's been a good amount of work; done on making such a scheme work well in practice which is not yet documented; here. Supported Architectures; =======================. Support for statepoint generation requires some code for each backend.; Today, only Aarch64 and X86_64 are supported. .. _OpenWork:. Limitations and Half Baked Ideas; ================================. Mixing References and Raw Pointers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Support for languages which allow unmanaged pointers to garbage collected; objects (i.e. pass a pointer to an object to a C routine) in the abstract; machine model. At the moment, the best idea on how to approach this; involves an intrinsic or opaque function which hides the connection between; the reference value and the raw pointer. The problem is that having ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:33582,Safety,safe,safepoint,33582,"t method entry and; loop backedges locations. Extending this to work with return polls would be; straight forward if desired. PlaceSafepoints includes a number of optimizations to avoid placing safepoint; polls at particular sites unless needed to ensure timely execution of a poll; under normal conditions. PlaceSafepoints does not attempt to ensure timely; execution of a poll under worst case conditions such as heavy system paging. The implementation of a safepoint poll action is specified by looking up a; function of the name ``gc.safepoint_poll`` in the containing Module. The body; of this function is inserted at each poll site desired. While calls or invokes; inside this method are transformed to a ``gc.statepoints``, recursive poll; insertion is not performed. This pass is useful for any language frontend which only has to support; garbage collection semantics at safepoints. If you need other abstract; frame information at safepoints (e.g. for deoptimization or introspection),; you can insert safepoint polls in the frontend. If you have the later case,; please ask on llvm-dev for suggestions. There's been a good amount of work; done on making such a scheme work well in practice which is not yet documented; here. Supported Architectures; =======================. Support for statepoint generation requires some code for each backend.; Today, only Aarch64 and X86_64 are supported. .. _OpenWork:. Limitations and Half Baked Ideas; ================================. Mixing References and Raw Pointers; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Support for languages which allow unmanaged pointers to garbage collected; objects (i.e. pass a pointer to an object to a C routine) in the abstract; machine model. At the moment, the best idea on how to approach this; involves an intrinsic or opaque function which hides the connection between; the reference value and the raw pointer. The problem is that having a; ptrtoint or inttoptr cast (which is common for such use cases) breaks the; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:7557,Security,expose,expose,7557,"explicitly visible in the IR. Doing so requires that we:. #. create a new SSA value for each potentially relocated pointer, and; ensure that no uses of the original (non relocated) value is; reachable after the safepoint,; #. specify the relocation in a way which is opaque to the compiler to; ensure that the optimizer can not introduce new uses of an; unrelocated value after a statepoint. This prevents the optimizer; from performing unsound optimizations.; #. recording a mapping of live pointers (and the allocation they're; associated with) for each statepoint. At the most abstract level, inserting a safepoint can be thought of as; replacing a call instruction with a call to a multiple return value; function which both calls the original target of the call, returns; its result, and returns updated values for any live pointers to; garbage collected objects. Note that the task of identifying all live pointers to garbage; collected values, transforming the IR to expose a pointer giving the; base object for every such live pointer, and inserting all the; intrinsics correctly is explicitly out of scope for this document.; The recommended approach is to use the :ref:`utility passes; <statepoint-utilities>` described below. This abstract function call is concretely represented by a sequence of; intrinsic calls known collectively as a ""statepoint relocation sequence"". Let's consider a simple call in LLVM IR:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; call void ()* @foo(); ret i8 addrspace(1)* %obj; }. Depending on our language we may need to allow a safepoint during the execution; of ``foo``. If so, we need to let the collector update local values in the; current frame. If we don't, we'll be accessing a potential invalid reference; once we eventually return from the call. In this example, we need to relocate the SSA value ``%obj``. Since we can't; actually change the value in the SSA value ``%obj``, we need to int",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:8358,Security,access,accessing,8358,"ated values for any live pointers to; garbage collected objects. Note that the task of identifying all live pointers to garbage; collected values, transforming the IR to expose a pointer giving the; base object for every such live pointer, and inserting all the; intrinsics correctly is explicitly out of scope for this document.; The recommended approach is to use the :ref:`utility passes; <statepoint-utilities>` described below. This abstract function call is concretely represented by a sequence of; intrinsic calls known collectively as a ""statepoint relocation sequence"". Let's consider a simple call in LLVM IR:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; call void ()* @foo(); ret i8 addrspace(1)* %obj; }. Depending on our language we may need to allow a safepoint during the execution; of ``foo``. If so, we need to let the collector update local values in the; current frame. If we don't, we'll be accessing a potential invalid reference; once we eventually return from the call. In this example, we need to relocate the SSA value ``%obj``. Since we can't; actually change the value in the SSA value ``%obj``, we need to introduce a new; SSA value ``%obj.relocated`` which represents the potentially changed value of; ``%obj`` after the safepoint and update any following uses appropriately. The; resulting relocation sequence is:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; %0 = call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj); %obj.relocated = call coldcc i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %0, i32 7, i32 7); ret i8 addrspace(1)* %obj.relocated; }. Ideally, this sequence would have been represented as a M argument, N; return value function (where M is the number of values being; relocated + the original call ar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:17546,Security,access,access,17546,"or to run during the execution of; unmanaged code. Furthermore, it is common that coordinating the transition from; managed to unmanaged code requires extra code generation at the call site to; inform the collector of the transition. In order to support these needs, a; statepoint may be marked as a GC transition, and data that is necessary to; perform the transition (if any) may be provided as additional arguments to the; statepoint. Note that although in many cases statepoints may be inferred to be GC; transitions based on the function symbols involved (e.g. a call from a; function with GC strategy ""foo"" to a function with GC strategy ""bar""),; indirect calls that are also GC transitions must also be supported. This; requirement is the driving force behind the decision to require that GC; transitions are explicitly marked. Let's revisit the sample given above, this time treating the call to ``@foo``; as a GC transition. Depending on our target, the transition code may need to; access some extra state in order to inform the collector of the transition.; Let's assume a hypothetical GC--somewhat unimaginatively named ""hypothetical-gc""; --that requires that a TLS variable must be written to before and after a call; to unmanaged code. The resulting relocation sequence is:. .. code-block:: llvm. @flag = thread_local global i32 0, align 4. define i8 addrspace(1)* @test1(i8 addrspace(1) *%obj); gc ""hypothetical-gc"" {. %0 = call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 1, i32* @Flag, i32 0, i8 addrspace(1)* %obj); %obj.relocated = call coldcc i8 addrspace(1)* @llvm.experimental.gc.relocate.p1i8(token %0, i32 7, i32 7); ret i8 addrspace(1)* %obj.relocated; }. During lowering, this will result in an instruction selection DAG that looks; something like:. ::. CALLSEQ_START; ...; GC_TRANSITION_START (lowered i32 *@Flag), SRCVALUE i32* Flag; STATEPOINT; GC_TRANSITION_END (lowered i32 *@Flag), SR",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:11160,Testability,test,tests,11160,"s. 	 .globl	test1; 	 .align	16, 0x90; 	 pushq	%rax; 	 callq	foo; .Ltmp1:; 	 movq	(%rsp), %rax # This load is redundant (oops!); 	 popq	%rdx; 	 retq. Each of the potentially relocated values has been spilled to the; stack, and a record of that location has been recorded to the; :ref:`Stack Map section <stackmap-section>`. If the garbage collector; needs to update any of these pointers during the call, it knows; exactly what to change. The relevant parts of the StackMap section for our example are:. .. code-block:: gas. # This describes the call site; # Stack Maps: callsite 2882400000; 	 .quad	2882400000; 	 .long	.Ltmp1-test1; 	 .short	0; # .. 8 entries skipped ..; # This entry describes the spill slot which is directly addressable; # off RSP with offset 0. Given the value was spilled with a pushq,; # that makes sense.; # Stack Maps: Loc 8: Direct RSP [encoding: .byte 2, .byte 8, .short 7, .int 0]; 	 .byte	2; 	 .byte	8; 	 .short	7; 	 .long	0. This example was taken from the tests for the :ref:`RewriteStatepointsForGC`; utility pass. As such, its full StackMap can be easily examined with the; following command. .. code-block:: bash. opt -rewrite-statepoints-for-gc test/Transforms/RewriteStatepointsForGC/basics.ll -S | llc -debug-only=stackmaps. Simplifications for Non-Relocating GCs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Some of the complexity in the previous example is unnecessary for a; non-relocating collector. While a non-relocating collector still needs the; information about which location contain live references, it doesn't need to; represent explicit relocations. As such, the previously described explicit; lowering can be simplified to remove all of the ``gc.relocate`` intrinsic; calls and leave uses in terms of the original reference value. Here's the explicit lowering for the previous example for a non-relocating; collector:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; call token (i64, i32, void ()",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:11353,Testability,test,test,11353,"es has been spilled to the; stack, and a record of that location has been recorded to the; :ref:`Stack Map section <stackmap-section>`. If the garbage collector; needs to update any of these pointers during the call, it knows; exactly what to change. The relevant parts of the StackMap section for our example are:. .. code-block:: gas. # This describes the call site; # Stack Maps: callsite 2882400000; 	 .quad	2882400000; 	 .long	.Ltmp1-test1; 	 .short	0; # .. 8 entries skipped ..; # This entry describes the spill slot which is directly addressable; # off RSP with offset 0. Given the value was spilled with a pushq,; # that makes sense.; # Stack Maps: Loc 8: Direct RSP [encoding: .byte 2, .byte 8, .short 7, .int 0]; 	 .byte	2; 	 .byte	8; 	 .short	7; 	 .long	0. This example was taken from the tests for the :ref:`RewriteStatepointsForGC`; utility pass. As such, its full StackMap can be easily examined with the; following command. .. code-block:: bash. opt -rewrite-statepoints-for-gc test/Transforms/RewriteStatepointsForGC/basics.ll -S | llc -debug-only=stackmaps. Simplifications for Non-Relocating GCs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Some of the complexity in the previous example is unnecessary for a; non-relocating collector. While a non-relocating collector still needs the; information about which location contain live references, it doesn't need to; represent explicit relocations. As such, the previously described explicit; lowering can be simplified to remove all of the ``gc.relocate`` intrinsic; calls and leave uses in terms of the original reference value. Here's the explicit lowering for the previous example for a non-relocating; collector:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj); ret i8 addrspace(1)* %obj; }. Recording On",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:31818,Testability,test,test,31818," as source and destination; arguments. If a copy operation takes a safepoint it might need to relocate the; underlying source and destination objects. This requires the corresponding base; pointers to be available in the copy operation. In order to make the base; pointers available RewriteStatepointsForGC replaces derived pointers with base; pointer and offset pairs. For example:. .. code-block:: llvm. declare void @__llvm_memcpy_element_unordered_atomic_safepoint_1(; i8 addrspace(1)* %dest_base, i64 %dest_offset,; i8 addrspace(1)* %src_base, i64 %src_offset,; i64 %length). .. _PlaceSafepoints:. PlaceSafepoints; ^^^^^^^^^^^^^^^^. The pass PlaceSafepoints inserts safepoint polls sufficient to ensure running; code checks for a safepoint request on a timely manner. This pass is expected; to be run before RewriteStatepointsForGC and thus does not produce full; relocation sequences. As an example, given input IR of the following:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @foo(); ret void; }. declare void @do_safepoint(); define void @gc.safepoint_poll() {; call void @do_safepoint(); ret void; }. This pass would produce the following IR:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @do_safepoint(); call void @foo(); ret void; }. In this case, we've added an (unconditional) entry safepoint poll. Note that; despite appearances, the entry poll is not necessarily redundant. We'd have to; know that ``foo`` and ``test`` were not mutually recursive for the poll to be; redundant. In practice, you'd probably want to your poll definition to contain; a conditional branch of some form. At the moment, PlaceSafepoints can insert safepoint polls at method entry and; loop backedges locations. Extending this to work with return polls would be; straight forward if desired. PlaceSafepoints includes a number of optimizations to avoid placing safepoint; polls at particular sites unless needed to ensure timely execution o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:32067,Testability,test,test,32067,"; pointers available RewriteStatepointsForGC replaces derived pointers with base; pointer and offset pairs. For example:. .. code-block:: llvm. declare void @__llvm_memcpy_element_unordered_atomic_safepoint_1(; i8 addrspace(1)* %dest_base, i64 %dest_offset,; i8 addrspace(1)* %src_base, i64 %src_offset,; i64 %length). .. _PlaceSafepoints:. PlaceSafepoints; ^^^^^^^^^^^^^^^^. The pass PlaceSafepoints inserts safepoint polls sufficient to ensure running; code checks for a safepoint request on a timely manner. This pass is expected; to be run before RewriteStatepointsForGC and thus does not produce full; relocation sequences. As an example, given input IR of the following:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @foo(); ret void; }. declare void @do_safepoint(); define void @gc.safepoint_poll() {; call void @do_safepoint(); ret void; }. This pass would produce the following IR:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @do_safepoint(); call void @foo(); ret void; }. In this case, we've added an (unconditional) entry safepoint poll. Note that; despite appearances, the entry poll is not necessarily redundant. We'd have to; know that ``foo`` and ``test`` were not mutually recursive for the poll to be; redundant. In practice, you'd probably want to your poll definition to contain; a conditional branch of some form. At the moment, PlaceSafepoints can insert safepoint polls at method entry and; loop backedges locations. Extending this to work with return polls would be; straight forward if desired. PlaceSafepoints includes a number of optimizations to avoid placing safepoint; polls at particular sites unless needed to ensure timely execution of a poll; under normal conditions. PlaceSafepoints does not attempt to ensure timely; execution of a poll under worst case conditions such as heavy system paging. The implementation of a safepoint poll action is specified by looking up a; function of the name ``g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:32341,Testability,test,test,32341,"_offset,; i8 addrspace(1)* %src_base, i64 %src_offset,; i64 %length). .. _PlaceSafepoints:. PlaceSafepoints; ^^^^^^^^^^^^^^^^. The pass PlaceSafepoints inserts safepoint polls sufficient to ensure running; code checks for a safepoint request on a timely manner. This pass is expected; to be run before RewriteStatepointsForGC and thus does not produce full; relocation sequences. As an example, given input IR of the following:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @foo(); ret void; }. declare void @do_safepoint(); define void @gc.safepoint_poll() {; call void @do_safepoint(); ret void; }. This pass would produce the following IR:. .. code-block:: llvm. define void @test() gc ""statepoint-example"" {; call void @do_safepoint(); call void @foo(); ret void; }. In this case, we've added an (unconditional) entry safepoint poll. Note that; despite appearances, the entry poll is not necessarily redundant. We'd have to; know that ``foo`` and ``test`` were not mutually recursive for the poll to be; redundant. In practice, you'd probably want to your poll definition to contain; a conditional branch of some form. At the moment, PlaceSafepoints can insert safepoint polls at method entry and; loop backedges locations. Extending this to work with return polls would be; straight forward if desired. PlaceSafepoints includes a number of optimizations to avoid placing safepoint; polls at particular sites unless needed to ensure timely execution of a poll; under normal conditions. PlaceSafepoints does not attempt to ensure timely; execution of a poll under worst case conditions such as heavy system paging. The implementation of a safepoint poll action is specified by looking up a; function of the name ``gc.safepoint_poll`` in the containing Module. The body; of this function is inserted at each poll site desired. While calls or invokes; inside this method are transformed to a ``gc.statepoints``, recursive poll; insertion is not performed. This pass",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:2387,Usability,simpl,simplify,2387," the; execution known as 'safepoints' For most collectors, it is sufficient; to track at least one copy of each unique pointer value. However, for; a collector which wishes to relocate objects directly reachable from; running code, a higher standard is required. One additional challenge is that the compiler may compute intermediate; results (""derived pointers"") which point outside of the allocation or; even into the middle of another allocation. The eventual use of this; intermediate value must yield an address within the bounds of the; allocation, but such ""exterior derived pointers"" may be visible to the; collector. Given this, a garbage collector can not safely rely on the; runtime value of an address to indicate the object it is associated; with. If the garbage collector wishes to move any object, the; compiler must provide a mapping, for each pointer, to an indication of; its allocation. To simplify the interaction between a collector and the compiled code,; most garbage collectors are organized in terms of three abstractions:; load barriers, store barriers, and safepoints. #. A load barrier is a bit of code executed immediately after the; machine load instruction, but before any use of the value loaded.; Depending on the collector, such a barrier may be needed for all; loads, merely loads of a particular type (in the original source; language), or none at all. #. Analogously, a store barrier is a code fragment that runs; immediately before the machine store instruction, but after the; computation of the value stored. The most common use of a store; barrier is to update a 'card table' in a generational garbage; collector. #. A safepoint is a location at which pointers visible to the compiled; code (i.e. currently in registers or on the stack) are allowed to; change. After the safepoint completes, the actual pointer value; may differ, but the 'object' (as seen by the source language); pointed to will not. Note that the term 'safepoint' is somewhat overloaded. It",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:7983,Usability,simpl,simple,7983,"ts the optimizer; from performing unsound optimizations.; #. recording a mapping of live pointers (and the allocation they're; associated with) for each statepoint. At the most abstract level, inserting a safepoint can be thought of as; replacing a call instruction with a call to a multiple return value; function which both calls the original target of the call, returns; its result, and returns updated values for any live pointers to; garbage collected objects. Note that the task of identifying all live pointers to garbage; collected values, transforming the IR to expose a pointer giving the; base object for every such live pointer, and inserting all the; intrinsics correctly is explicitly out of scope for this document.; The recommended approach is to use the :ref:`utility passes; <statepoint-utilities>` described below. This abstract function call is concretely represented by a sequence of; intrinsic calls known collectively as a ""statepoint relocation sequence"". Let's consider a simple call in LLVM IR:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; call void ()* @foo(); ret i8 addrspace(1)* %obj; }. Depending on our language we may need to allow a safepoint during the execution; of ``foo``. If so, we need to let the collector update local values in the; current frame. If we don't, we'll be accessing a potential invalid reference; once we eventually return from the call. In this example, we need to relocate the SSA value ``%obj``. Since we can't; actually change the value in the SSA value ``%obj``, we need to introduce a new; SSA value ``%obj.relocated`` which represents the potentially changed value of; ``%obj`` after the safepoint and update any following uses appropriately. The; resulting relocation sequence is:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; %0 = call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:11830,Usability,simpl,simplified,11830,"# .. 8 entries skipped ..; # This entry describes the spill slot which is directly addressable; # off RSP with offset 0. Given the value was spilled with a pushq,; # that makes sense.; # Stack Maps: Loc 8: Direct RSP [encoding: .byte 2, .byte 8, .short 7, .int 0]; 	 .byte	2; 	 .byte	8; 	 .short	7; 	 .long	0. This example was taken from the tests for the :ref:`RewriteStatepointsForGC`; utility pass. As such, its full StackMap can be easily examined with the; following command. .. code-block:: bash. opt -rewrite-statepoints-for-gc test/Transforms/RewriteStatepointsForGC/basics.ll -S | llc -debug-only=stackmaps. Simplifications for Non-Relocating GCs; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Some of the complexity in the previous example is unnecessary for a; non-relocating collector. While a non-relocating collector still needs the; information about which location contain live references, it doesn't need to; represent explicit relocations. As such, the previously described explicit; lowering can be simplified to remove all of the ``gc.relocate`` intrinsic; calls and leave uses in terms of the original reference value. Here's the explicit lowering for the previous example for a non-relocating; collector:. .. code-block:: llvm. define i8 addrspace(1)* @test1(i8 addrspace(1)* %obj); gc ""statepoint-example"" {; call token (i64, i32, void ()*, i32, i32, ...)* @llvm.experimental.gc.statepoint.p0f_isVoidf(i64 0, i32 0, void ()* @foo, i32 0, i32 0, i32 0, i32 0, i8 addrspace(1)* %obj); ret i8 addrspace(1)* %obj; }. Recording On Stack Regions; ^^^^^^^^^^^^^^^^^^^^^^^^^^. In addition to the explicit relocation form previously described, the; statepoint infrastructure also allows the listing of allocas within the gc; pointer list. Allocas can be listed with or without additional explicit gc; pointer values and relocations. An alloca in the gc region of the statepoint operand list will cause the; address of the stack region to be listed in the stackmap for the statepoint. This mec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst:24578,Usability,simpl,simplifies,24578,"tentially relocated pointer is observably-after a; safepoint which could relocate it. 'observably-after' is this usage; means that an outside observer could observe this sequence of events; in a way which precludes the operation being performed before the; safepoint. To understand why this 'observable-after' property is required,; consider a null comparison performed on the original copy of a; relocated pointer. Assuming that control flow follows the safepoint,; there is no way to observe externally whether the null comparison is; performed before or after the safepoint. (Remember, the original; Value is unmodified by the safepoint.) The compiler is free to make; either scheduling choice. The actual correctness property implemented is slightly stronger than; this. We require that there be no *static path* on which a; potentially relocated pointer is 'observably-after' it may have been; relocated. This is slightly stronger than is strictly necessary (and; thus may disallow some otherwise valid programs), but greatly; simplifies reasoning about correctness of the compiled code. By construction, this property will be upheld by the optimizer if; correctly established in the source IR. This is a key invariant of; the design. The existing IR Verifier pass has been extended to check most of the; local restrictions on the intrinsics mentioned in their respective; documentation. The current implementation in LLVM does not check the; key relocation invariant, but this is ongoing work on developing such; a verifier. Please ask on llvm-dev if you're interested in; experimenting with the current version. .. _statepoint-utilities:. Utility Passes for Safepoint Insertion; ======================================. .. _RewriteStatepointsForGC:. RewriteStatepointsForGC; ^^^^^^^^^^^^^^^^^^^^^^^^. The pass RewriteStatepointsForGC transforms a function's IR to lower from the; abstract machine model described above to the explicit statepoint model of; relocations. To do this, it replaces al",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Statepoints.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Statepoints.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:2602,Availability,avail,available,2602,"adhere to a set of; portability rules associated with the Support Library. Adherence to these rules; should help the Support Library achieve its goal of shielding LLVM from the; variations in operating system interfaces and doing so efficiently. The; following sections define the rules needed to fulfill this objective. Don't Include System Headers; ----------------------------. Except in ``lib/Support``, no LLVM source code should directly ``#include`` a; system header. Care has been taken to remove all such ``#includes`` from LLVM; while ``lib/Support`` was being developed. Specifically this means that header; files like ""``unistd.h``"", ""``windows.h``"", ""``stdio.h``"", and ""``string.h``""; are forbidden to be included by LLVM source code outside the implementation of; ``lib/Support``. To obtain system-dependent functionality, existing interfaces to the system; found in ``include/llvm/Support`` should be used. If an appropriate interface is; not available, it should be added to ``include/llvm/Support`` and implemented in; ``lib/Support`` for all supported platforms. Don't Expose System Headers; ---------------------------. The Support Library must shield LLVM from **all** system headers. To obtain; system level functionality, LLVM source must; ``#include ""llvm/Support/Thing.h""`` and nothing else. This means that; ``Thing.h`` cannot expose any system header files. This protects LLVM from; accidentally using system specific functionality and only allows it via; the ``lib/Support`` interface. Use Standard C Headers; ----------------------. The **standard** C headers (the ones beginning with ""c"") are allowed to be; exposed through the ``lib/Support`` interface. These headers and the things they; declare are considered to be platform agnostic. LLVM source files may include; them directly or obtain their inclusion through ``lib/Support`` interfaces. Use Standard C++ Headers; ------------------------. The **standard** C++ headers from the standard C++ library and standard; te",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:7304,Availability,error,error,7304,"on is not exposed. This prevents inadvertent use of system; specific functionality. For example, the ``stat`` system call is notorious for having variations in the; data it provides. ``lib/Support`` must not declare ``stat`` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:7406,Availability,error,error,7406,"stem call is notorious for having variations in the; data it provides. ``lib/Support`` must not declare ``stat`` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, att",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:7499,Availability,error,errors,7499,"` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:7597,Availability,error,errors,7597,"ut files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:7728,Availability,error,errors,7728,"s strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn'",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:7765,Availability,error,errors,7765,"s strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn'",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:7826,Availability,error,errors,7826,"port Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:7897,Availability,error,errors,7897,"a; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:8024,Availability,error,errors,8024,"e header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:8266,Availability,error,errors,8266," Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:8461,Availability,error,error,8461,"esults into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:8523,Availability,error,error,8523,"information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; com",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:8561,Availability,error,error,8561,"information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; com",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:8740,Availability,error,error,8740," ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; compiler does not insert additional exception handling code into the interface; functions. This is a performance consideration: ``lib/Support`` functions are; at the bottom of many call chains and as such can be frequently called. We; need th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:8920,Availability,error,error,8920,"n of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; compiler does not insert additional exception handling code into the interface; functions. This is a performance consideration: ``lib/Support`` functions are; at the bottom of many call chains and as such can be frequently called. We; need them to be as efficient as possible. However, no routines in the system; library should actually throw exceptions. Code Organization; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:8970,Availability,error,errors,8970,"soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; compiler does not insert additional exception handling code into the interface; functions. This is a performance consideration: ``lib/Support`` functions are; at the bottom of many call chains and as such can be frequently called. We; need them to be as efficient as possible. However, no routines in the system; library should actually throw exceptions. Code Organization; -----------------. Implementations of the Support Library interface are separated by their general; class of operating system. Curr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:9113,Availability,error,errors,9113," to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; compiler does not insert additional exception handling code into the interface; functions. This is a performance consideration: ``lib/Support`` functions are; at the bottom of many call chains and as such can be frequently called. We; need them to be as efficient as possible. However, no routines in the system; library should actually throw exceptions. Code Organization; -----------------. Implementations of the Support Library interface are separated by their general; class of operating system. Currently only Unix and Win32 classes are defined; but more could be added for other operating system ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:9131,Availability,error,errors,9131," to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; compiler does not insert additional exception handling code into the interface; functions. This is a performance consideration: ``lib/Support`` functions are; at the bottom of many call chains and as such can be frequently called. We; need them to be as efficient as possible. However, no routines in the system; library should actually throw exceptions. Code Organization; -----------------. Implementations of the Support Library interface are separated by their general; class of operating system. Currently only Unix and Win32 classes are defined; but more could be added for other operating system ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:9176,Availability,error,error,9176,"of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; compiler does not insert additional exception handling code into the interface; functions. This is a performance consideration: ``lib/Support`` functions are; at the bottom of many call chains and as such can be frequently called. We; need them to be as efficient as possible. However, no routines in the system; library should actually throw exceptions. Code Organization; -----------------. Implementations of the Support Library interface are separated by their general; class of operating system. Currently only Unix and Win32 classes are defined; but more could be added for other operating system classifications. To; distinguish which implementation to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:9261,Availability,error,error,9261,"ard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; compiler does not insert additional exception handling code into the interface; functions. This is a performance consideration: ``lib/Support`` functions are; at the bottom of many call chains and as such can be frequently called. We; need them to be as efficient as possible. However, no routines in the system; library should actually throw exceptions. Code Organization; -----------------. Implementations of the Support Library interface are separated by their general; class of operating system. Currently only Unix and Win32 classes are defined; but more could be added for other operating system classifications. To; distinguish which implementation to compile, the code in ``lib/Support`` uses; the ``LLVM_ON_UNIX`` and ``_WIN32`` ``#define",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:11666,Availability,avail,available,11666,"throw exceptions. Code Organization; -----------------. Implementations of the Support Library interface are separated by their general; class of operating system. Currently only Unix and Win32 classes are defined; but more could be added for other operating system classifications. To; distinguish which implementation to compile, the code in ``lib/Support`` uses; the ``LLVM_ON_UNIX`` and ``_WIN32`` ``#defines``. Each source file in; ``lib/Support``, after implementing the generic (operating system independent); functionality needs to include the correct implementation using a set of; ``#if defined(LLVM_ON_XYZ)`` directives. For example, if we had; ``lib/Support/Path.cpp``, we'd expect to see in that file:. .. code-block:: c++. #if defined(LLVM_ON_UNIX); #include ""Unix/Path.inc""; #endif; #if defined(_WIN32); #include ""Windows/Path.inc""; #endif. The implementation in ``lib/Support/Unix/Path.inc`` should handle all Unix; variants. The implementation in ``lib/Support/Windows/Path.inc`` should handle; all Windows variants. What this does is quickly inc the basic class; of operating system that will provide the implementation. The specific details; for a given platform must still be determined through the use of ``#ifdef``. Consistent Semantics; --------------------. The implementation of a ``lib/Support`` interface can vary drastically between; platforms. That's okay as long as the end result of the interface function is; the same. For example, a function to create a directory is pretty straight; forward on all operating system. System V IPC on the other hand isn't even; supported on all platforms. Instead of ""supporting"" System V IPC,; ``lib/Support`` should provide an interface to the basic concept of; inter-process communications. The implementations might use System V IPC if; that was available or named pipes, or whatever gets the job done effectively; for a given operating system. In all cases, the interface and the; implementation must be semantically consistent.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:1877,Energy Efficiency,efficient,efficiently,1877,"so unclutters the rest of LLVM from #ifdef use and special cases for; specific operating systems. Such uses are replaced with simple calls to the; interfaces provided in ``include/llvm/Support``. Note that the Support Library is not intended to be a complete operating system; wrapper (such as the Adaptive Communications Environment (ACE) or Apache; Portable Runtime (APR)), but only provides the functionality necessary to; support LLVM. The Support Library was originally referred to as the System Library, written; by Reid Spencer who formulated the design based on similar work originating; from the eXtensible Programming System (XPS). Several people helped with the; effort; especially, Jeff Cohen and Henrik Bach on the Win32 port. Keeping LLVM Portable; =====================. In order to keep LLVM portable, LLVM developers should adhere to a set of; portability rules associated with the Support Library. Adherence to these rules; should help the Support Library achieve its goal of shielding LLVM from the; variations in operating system interfaces and doing so efficiently. The; following sections define the rules needed to fulfill this objective. Don't Include System Headers; ----------------------------. Except in ``lib/Support``, no LLVM source code should directly ``#include`` a; system header. Care has been taken to remove all such ``#includes`` from LLVM; while ``lib/Support`` was being developed. Specifically this means that header; files like ""``unistd.h``"", ""``windows.h``"", ""``stdio.h``"", and ""``string.h``""; are forbidden to be included by LLVM source code outside the implementation of; ``lib/Support``. To obtain system-dependent functionality, existing interfaces to the system; found in ``include/llvm/Support`` should be used. If an appropriate interface is; not available, it should be added to ``include/llvm/Support`` and implemented in; ``lib/Support`` for all supported platforms. Don't Expose System Headers; ---------------------------. The Support Library m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:5879,Energy Efficiency,efficient,efficient,5879," -----------------------. There must be no functionality specified in the interface of ``lib/Support``; that isn't actually used by LLVM. We're not writing a general purpose operating; system wrapper here, just enough to satisfy LLVM's needs. And, LLVM doesn't; need much. This design goal aims to keep the ``lib/Support`` interface small and; understandable which should foster its actual use and adoption. No Duplicate Implementations; ----------------------------. The implementation of a function for a given platform must be written exactly; once. This implies that it must be possible to apply a function's; implementation to multiple operating systems if those operating systems can; share the same implementation. This rule applies to the set of operating; systems supported for a given class of operating system (e.g. Unix, Win32). No Virtual Methods; ------------------. The Support Library interfaces can be called quite frequently by LLVM. In order; to make those calls as efficient as possible, we discourage the use of virtual; methods. There is no need to use inheritance for implementation differences, it; just adds complexity. The ``#include`` mechanism works just fine. No Exposed Functions; --------------------. Any functions defined by system libraries (i.e. not defined by ``lib/Support``); must not be exposed through the ``lib/Support`` interface, even if the header; file for that function is not exposed. This prevents inadvertent use of system; specific functionality. For example, the ``stat`` system call is notorious for having variations in the; data it provides. ``lib/Support`` must not declare ``stat`` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:9768,Energy Efficiency,efficient,efficient,9768," just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; compiler does not insert additional exception handling code into the interface; functions. This is a performance consideration: ``lib/Support`` functions are; at the bottom of many call chains and as such can be frequently called. We; need them to be as efficient as possible. However, no routines in the system; library should actually throw exceptions. Code Organization; -----------------. Implementations of the Support Library interface are separated by their general; class of operating system. Currently only Unix and Win32 classes are defined; but more could be added for other operating system classifications. To; distinguish which implementation to compile, the code in ``lib/Support`` uses; the ``LLVM_ON_UNIX`` and ``_WIN32`` ``#defines``. Each source file in; ``lib/Support``, after implementing the generic (operating system independent); functionality needs to include the correct implementation using a set of; ``#if defined(LLVM_ON_XYZ)`` directives. For example, if we had; ``lib/Support/Path.cpp``, we'd expect to see in that file:. .. code-block:: c++. #if defined(LLVM_ON_UNIX); #include ""Unix/Path.inc""; #endif; #if defined(_WIN32); #include ""Windows/Path.inc""; #endif. The implementation in ``lib/Support/Unix/Path.inc`` should h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:455,Integrability,depend,dependent,455,"===============; Support Library; ===============. Abstract; ========. This document provides some details on LLVM's Support Library, located in the; source at ``lib/Support`` and ``include/llvm/Support``. The library's purpose; is to shield LLVM from the differences between operating systems for the few; services LLVM needs from the operating system. Much of LLVM is written using; portability features of standard C++. However, in a few areas, system dependent; facilities are needed and the Support Library is the wrapper around those; system calls. By centralizing LLVM's use of operating system interfaces, we make it possible; for the LLVM tool chain and runtime libraries to be more easily ported to new; platforms since (theoretically) only ``lib/Support`` needs to be ported. This; library also unclutters the rest of LLVM from #ifdef use and special cases for; specific operating systems. Such uses are replaced with simple calls to the; interfaces provided in ``include/llvm/Support``. Note that the Support Library is not intended to be a complete operating system; wrapper (such as the Adaptive Communications Environment (ACE) or Apache; Portable Runtime (APR)), but only provides the functionality necessary to; support LLVM. The Support Library was originally referred to as the System Library, written; by Reid Spencer who formulated the design based on similar work originating; from the eXtensible Programming System (XPS). Several people helped with the; effort; especially, Jeff Cohen and Henrik Bach on the Win32 port. Keeping LLVM Portable; =====================. In order to keep LLVM portable, LLVM developers should adhere to a set of; portability rules associated with the Support Library. Adherence to these rules; should help the Support Library achieve its goal of shielding LLVM from the; variations in operating system interfaces and doing so efficiently. The; following sections define the rules needed to fulfill this objective. Don't Include System Headers; ------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:519,Integrability,wrap,wrapper,519,"===============; Support Library; ===============. Abstract; ========. This document provides some details on LLVM's Support Library, located in the; source at ``lib/Support`` and ``include/llvm/Support``. The library's purpose; is to shield LLVM from the differences between operating systems for the few; services LLVM needs from the operating system. Much of LLVM is written using; portability features of standard C++. However, in a few areas, system dependent; facilities are needed and the Support Library is the wrapper around those; system calls. By centralizing LLVM's use of operating system interfaces, we make it possible; for the LLVM tool chain and runtime libraries to be more easily ported to new; platforms since (theoretically) only ``lib/Support`` needs to be ported. This; library also unclutters the rest of LLVM from #ifdef use and special cases for; specific operating systems. Such uses are replaced with simple calls to the; interfaces provided in ``include/llvm/Support``. Note that the Support Library is not intended to be a complete operating system; wrapper (such as the Adaptive Communications Environment (ACE) or Apache; Portable Runtime (APR)), but only provides the functionality necessary to; support LLVM. The Support Library was originally referred to as the System Library, written; by Reid Spencer who formulated the design based on similar work originating; from the eXtensible Programming System (XPS). Several people helped with the; effort; especially, Jeff Cohen and Henrik Bach on the Win32 port. Keeping LLVM Portable; =====================. In order to keep LLVM portable, LLVM developers should adhere to a set of; portability rules associated with the Support Library. Adherence to these rules; should help the Support Library achieve its goal of shielding LLVM from the; variations in operating system interfaces and doing so efficiently. The; following sections define the rules needed to fulfill this objective. Don't Include System Headers; ------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:602,Integrability,interface,interfaces,602,"===============; Support Library; ===============. Abstract; ========. This document provides some details on LLVM's Support Library, located in the; source at ``lib/Support`` and ``include/llvm/Support``. The library's purpose; is to shield LLVM from the differences between operating systems for the few; services LLVM needs from the operating system. Much of LLVM is written using; portability features of standard C++. However, in a few areas, system dependent; facilities are needed and the Support Library is the wrapper around those; system calls. By centralizing LLVM's use of operating system interfaces, we make it possible; for the LLVM tool chain and runtime libraries to be more easily ported to new; platforms since (theoretically) only ``lib/Support`` needs to be ported. This; library also unclutters the rest of LLVM from #ifdef use and special cases for; specific operating systems. Such uses are replaced with simple calls to the; interfaces provided in ``include/llvm/Support``. Note that the Support Library is not intended to be a complete operating system; wrapper (such as the Adaptive Communications Environment (ACE) or Apache; Portable Runtime (APR)), but only provides the functionality necessary to; support LLVM. The Support Library was originally referred to as the System Library, written; by Reid Spencer who formulated the design based on similar work originating; from the eXtensible Programming System (XPS). Several people helped with the; effort; especially, Jeff Cohen and Henrik Bach on the Win32 port. Keeping LLVM Portable; =====================. In order to keep LLVM portable, LLVM developers should adhere to a set of; portability rules associated with the Support Library. Adherence to these rules; should help the Support Library achieve its goal of shielding LLVM from the; variations in operating system interfaces and doing so efficiently. The; following sections define the rules needed to fulfill this objective. Don't Include System Headers; ------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:950,Integrability,interface,interfaces,950,"===============; Support Library; ===============. Abstract; ========. This document provides some details on LLVM's Support Library, located in the; source at ``lib/Support`` and ``include/llvm/Support``. The library's purpose; is to shield LLVM from the differences between operating systems for the few; services LLVM needs from the operating system. Much of LLVM is written using; portability features of standard C++. However, in a few areas, system dependent; facilities are needed and the Support Library is the wrapper around those; system calls. By centralizing LLVM's use of operating system interfaces, we make it possible; for the LLVM tool chain and runtime libraries to be more easily ported to new; platforms since (theoretically) only ``lib/Support`` needs to be ported. This; library also unclutters the rest of LLVM from #ifdef use and special cases for; specific operating systems. Such uses are replaced with simple calls to the; interfaces provided in ``include/llvm/Support``. Note that the Support Library is not intended to be a complete operating system; wrapper (such as the Adaptive Communications Environment (ACE) or Apache; Portable Runtime (APR)), but only provides the functionality necessary to; support LLVM. The Support Library was originally referred to as the System Library, written; by Reid Spencer who formulated the design based on similar work originating; from the eXtensible Programming System (XPS). Several people helped with the; effort; especially, Jeff Cohen and Henrik Bach on the Win32 port. Keeping LLVM Portable; =====================. In order to keep LLVM portable, LLVM developers should adhere to a set of; portability rules associated with the Support Library. Adherence to these rules; should help the Support Library achieve its goal of shielding LLVM from the; variations in operating system interfaces and doing so efficiently. The; following sections define the rules needed to fulfill this objective. Don't Include System Headers; ------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:1080,Integrability,wrap,wrapper,1080,"port Library, located in the; source at ``lib/Support`` and ``include/llvm/Support``. The library's purpose; is to shield LLVM from the differences between operating systems for the few; services LLVM needs from the operating system. Much of LLVM is written using; portability features of standard C++. However, in a few areas, system dependent; facilities are needed and the Support Library is the wrapper around those; system calls. By centralizing LLVM's use of operating system interfaces, we make it possible; for the LLVM tool chain and runtime libraries to be more easily ported to new; platforms since (theoretically) only ``lib/Support`` needs to be ported. This; library also unclutters the rest of LLVM from #ifdef use and special cases for; specific operating systems. Such uses are replaced with simple calls to the; interfaces provided in ``include/llvm/Support``. Note that the Support Library is not intended to be a complete operating system; wrapper (such as the Adaptive Communications Environment (ACE) or Apache; Portable Runtime (APR)), but only provides the functionality necessary to; support LLVM. The Support Library was originally referred to as the System Library, written; by Reid Spencer who formulated the design based on similar work originating; from the eXtensible Programming System (XPS). Several people helped with the; effort; especially, Jeff Cohen and Henrik Bach on the Win32 port. Keeping LLVM Portable; =====================. In order to keep LLVM portable, LLVM developers should adhere to a set of; portability rules associated with the Support Library. Adherence to these rules; should help the Support Library achieve its goal of shielding LLVM from the; variations in operating system interfaces and doing so efficiently. The; following sections define the rules needed to fulfill this objective. Don't Include System Headers; ----------------------------. Except in ``lib/Support``, no LLVM source code should directly ``#include`` a; system header. C",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:1853,Integrability,interface,interfaces,1853,"so unclutters the rest of LLVM from #ifdef use and special cases for; specific operating systems. Such uses are replaced with simple calls to the; interfaces provided in ``include/llvm/Support``. Note that the Support Library is not intended to be a complete operating system; wrapper (such as the Adaptive Communications Environment (ACE) or Apache; Portable Runtime (APR)), but only provides the functionality necessary to; support LLVM. The Support Library was originally referred to as the System Library, written; by Reid Spencer who formulated the design based on similar work originating; from the eXtensible Programming System (XPS). Several people helped with the; effort; especially, Jeff Cohen and Henrik Bach on the Win32 port. Keeping LLVM Portable; =====================. In order to keep LLVM portable, LLVM developers should adhere to a set of; portability rules associated with the Support Library. Adherence to these rules; should help the Support Library achieve its goal of shielding LLVM from the; variations in operating system interfaces and doing so efficiently. The; following sections define the rules needed to fulfill this objective. Don't Include System Headers; ----------------------------. Except in ``lib/Support``, no LLVM source code should directly ``#include`` a; system header. Care has been taken to remove all such ``#includes`` from LLVM; while ``lib/Support`` was being developed. Specifically this means that header; files like ""``unistd.h``"", ""``windows.h``"", ""``stdio.h``"", and ""``string.h``""; are forbidden to be included by LLVM source code outside the implementation of; ``lib/Support``. To obtain system-dependent functionality, existing interfaces to the system; found in ``include/llvm/Support`` should be used. If an appropriate interface is; not available, it should be added to ``include/llvm/Support`` and implemented in; ``lib/Support`` for all supported platforms. Don't Expose System Headers; ---------------------------. The Support Library m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:2456,Integrability,depend,dependent,2456," Cohen and Henrik Bach on the Win32 port. Keeping LLVM Portable; =====================. In order to keep LLVM portable, LLVM developers should adhere to a set of; portability rules associated with the Support Library. Adherence to these rules; should help the Support Library achieve its goal of shielding LLVM from the; variations in operating system interfaces and doing so efficiently. The; following sections define the rules needed to fulfill this objective. Don't Include System Headers; ----------------------------. Except in ``lib/Support``, no LLVM source code should directly ``#include`` a; system header. Care has been taken to remove all such ``#includes`` from LLVM; while ``lib/Support`` was being developed. Specifically this means that header; files like ""``unistd.h``"", ""``windows.h``"", ""``stdio.h``"", and ""``string.h``""; are forbidden to be included by LLVM source code outside the implementation of; ``lib/Support``. To obtain system-dependent functionality, existing interfaces to the system; found in ``include/llvm/Support`` should be used. If an appropriate interface is; not available, it should be added to ``include/llvm/Support`` and implemented in; ``lib/Support`` for all supported platforms. Don't Expose System Headers; ---------------------------. The Support Library must shield LLVM from **all** system headers. To obtain; system level functionality, LLVM source must; ``#include ""llvm/Support/Thing.h""`` and nothing else. This means that; ``Thing.h`` cannot expose any system header files. This protects LLVM from; accidentally using system specific functionality and only allows it via; the ``lib/Support`` interface. Use Standard C Headers; ----------------------. The **standard** C headers (the ones beginning with ""c"") are allowed to be; exposed through the ``lib/Support`` interface. These headers and the things they; declare are considered to be platform agnostic. LLVM source files may include; them directly or obtain their inclusion through ``lib/Suppor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:2490,Integrability,interface,interfaces,2490," Cohen and Henrik Bach on the Win32 port. Keeping LLVM Portable; =====================. In order to keep LLVM portable, LLVM developers should adhere to a set of; portability rules associated with the Support Library. Adherence to these rules; should help the Support Library achieve its goal of shielding LLVM from the; variations in operating system interfaces and doing so efficiently. The; following sections define the rules needed to fulfill this objective. Don't Include System Headers; ----------------------------. Except in ``lib/Support``, no LLVM source code should directly ``#include`` a; system header. Care has been taken to remove all such ``#includes`` from LLVM; while ``lib/Support`` was being developed. Specifically this means that header; files like ""``unistd.h``"", ""``windows.h``"", ""``stdio.h``"", and ""``string.h``""; are forbidden to be included by LLVM source code outside the implementation of; ``lib/Support``. To obtain system-dependent functionality, existing interfaces to the system; found in ``include/llvm/Support`` should be used. If an appropriate interface is; not available, it should be added to ``include/llvm/Support`` and implemented in; ``lib/Support`` for all supported platforms. Don't Expose System Headers; ---------------------------. The Support Library must shield LLVM from **all** system headers. To obtain; system level functionality, LLVM source must; ``#include ""llvm/Support/Thing.h""`` and nothing else. This means that; ``Thing.h`` cannot expose any system header files. This protects LLVM from; accidentally using system specific functionality and only allows it via; the ``lib/Support`` interface. Use Standard C Headers; ----------------------. The **standard** C headers (the ones beginning with ""c"") are allowed to be; exposed through the ``lib/Support`` interface. These headers and the things they; declare are considered to be platform agnostic. LLVM source files may include; them directly or obtain their inclusion through ``lib/Suppor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:2584,Integrability,interface,interface,2584,"adhere to a set of; portability rules associated with the Support Library. Adherence to these rules; should help the Support Library achieve its goal of shielding LLVM from the; variations in operating system interfaces and doing so efficiently. The; following sections define the rules needed to fulfill this objective. Don't Include System Headers; ----------------------------. Except in ``lib/Support``, no LLVM source code should directly ``#include`` a; system header. Care has been taken to remove all such ``#includes`` from LLVM; while ``lib/Support`` was being developed. Specifically this means that header; files like ""``unistd.h``"", ""``windows.h``"", ""``stdio.h``"", and ""``string.h``""; are forbidden to be included by LLVM source code outside the implementation of; ``lib/Support``. To obtain system-dependent functionality, existing interfaces to the system; found in ``include/llvm/Support`` should be used. If an appropriate interface is; not available, it should be added to ``include/llvm/Support`` and implemented in; ``lib/Support`` for all supported platforms. Don't Expose System Headers; ---------------------------. The Support Library must shield LLVM from **all** system headers. To obtain; system level functionality, LLVM source must; ``#include ""llvm/Support/Thing.h""`` and nothing else. This means that; ``Thing.h`` cannot expose any system header files. This protects LLVM from; accidentally using system specific functionality and only allows it via; the ``lib/Support`` interface. Use Standard C Headers; ----------------------. The **standard** C headers (the ones beginning with ""c"") are allowed to be; exposed through the ``lib/Support`` interface. These headers and the things they; declare are considered to be platform agnostic. LLVM source files may include; them directly or obtain their inclusion through ``lib/Support`` interfaces. Use Standard C++ Headers; ------------------------. The **standard** C++ headers from the standard C++ library and standard; te",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:3146,Integrability,interface,interface,3146,"include`` a; system header. Care has been taken to remove all such ``#includes`` from LLVM; while ``lib/Support`` was being developed. Specifically this means that header; files like ""``unistd.h``"", ""``windows.h``"", ""``stdio.h``"", and ""``string.h``""; are forbidden to be included by LLVM source code outside the implementation of; ``lib/Support``. To obtain system-dependent functionality, existing interfaces to the system; found in ``include/llvm/Support`` should be used. If an appropriate interface is; not available, it should be added to ``include/llvm/Support`` and implemented in; ``lib/Support`` for all supported platforms. Don't Expose System Headers; ---------------------------. The Support Library must shield LLVM from **all** system headers. To obtain; system level functionality, LLVM source must; ``#include ""llvm/Support/Thing.h""`` and nothing else. This means that; ``Thing.h`` cannot expose any system header files. This protects LLVM from; accidentally using system specific functionality and only allows it via; the ``lib/Support`` interface. Use Standard C Headers; ----------------------. The **standard** C headers (the ones beginning with ""c"") are allowed to be; exposed through the ``lib/Support`` interface. These headers and the things they; declare are considered to be platform agnostic. LLVM source files may include; them directly or obtain their inclusion through ``lib/Support`` interfaces. Use Standard C++ Headers; ------------------------. The **standard** C++ headers from the standard C++ library and standard; template library may be exposed through the ``lib/Support`` interface. These; headers and the things they declare are considered to be platform agnostic.; LLVM source files may include them or obtain their inclusion through; ``lib/Support`` interfaces. High Level Interface; --------------------. The entry points specified in the interface of ``lib/Support`` must be aimed at; completing some reasonably high level task needed by LLVM. We do not wa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:3317,Integrability,interface,interface,3317,"les like ""``unistd.h``"", ""``windows.h``"", ""``stdio.h``"", and ""``string.h``""; are forbidden to be included by LLVM source code outside the implementation of; ``lib/Support``. To obtain system-dependent functionality, existing interfaces to the system; found in ``include/llvm/Support`` should be used. If an appropriate interface is; not available, it should be added to ``include/llvm/Support`` and implemented in; ``lib/Support`` for all supported platforms. Don't Expose System Headers; ---------------------------. The Support Library must shield LLVM from **all** system headers. To obtain; system level functionality, LLVM source must; ``#include ""llvm/Support/Thing.h""`` and nothing else. This means that; ``Thing.h`` cannot expose any system header files. This protects LLVM from; accidentally using system specific functionality and only allows it via; the ``lib/Support`` interface. Use Standard C Headers; ----------------------. The **standard** C headers (the ones beginning with ""c"") are allowed to be; exposed through the ``lib/Support`` interface. These headers and the things they; declare are considered to be platform agnostic. LLVM source files may include; them directly or obtain their inclusion through ``lib/Support`` interfaces. Use Standard C++ Headers; ------------------------. The **standard** C++ headers from the standard C++ library and standard; template library may be exposed through the ``lib/Support`` interface. These; headers and the things they declare are considered to be platform agnostic.; LLVM source files may include them or obtain their inclusion through; ``lib/Support`` interfaces. High Level Interface; --------------------. The entry points specified in the interface of ``lib/Support`` must be aimed at; completing some reasonably high level task needed by LLVM. We do not want to; simply wrap each operating system call. It would be preferable to wrap several; operating system calls that are always used in conjunction with one another by; LLVM. F",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:3506,Integrability,interface,interfaces,3506,"nt functionality, existing interfaces to the system; found in ``include/llvm/Support`` should be used. If an appropriate interface is; not available, it should be added to ``include/llvm/Support`` and implemented in; ``lib/Support`` for all supported platforms. Don't Expose System Headers; ---------------------------. The Support Library must shield LLVM from **all** system headers. To obtain; system level functionality, LLVM source must; ``#include ""llvm/Support/Thing.h""`` and nothing else. This means that; ``Thing.h`` cannot expose any system header files. This protects LLVM from; accidentally using system specific functionality and only allows it via; the ``lib/Support`` interface. Use Standard C Headers; ----------------------. The **standard** C headers (the ones beginning with ""c"") are allowed to be; exposed through the ``lib/Support`` interface. These headers and the things they; declare are considered to be platform agnostic. LLVM source files may include; them directly or obtain their inclusion through ``lib/Support`` interfaces. Use Standard C++ Headers; ------------------------. The **standard** C++ headers from the standard C++ library and standard; template library may be exposed through the ``lib/Support`` interface. These; headers and the things they declare are considered to be platform agnostic.; LLVM source files may include them or obtain their inclusion through; ``lib/Support`` interfaces. High Level Interface; --------------------. The entry points specified in the interface of ``lib/Support`` must be aimed at; completing some reasonably high level task needed by LLVM. We do not want to; simply wrap each operating system call. It would be preferable to wrap several; operating system calls that are always used in conjunction with one another by; LLVM. For example, consider what is needed to execute a program, wait for it to; complete, and return its result code. On Unix, this involves the following; operating system calls: ``getenv``, ``fork``, ``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:3703,Integrability,interface,interface,3703,"ude/llvm/Support`` and implemented in; ``lib/Support`` for all supported platforms. Don't Expose System Headers; ---------------------------. The Support Library must shield LLVM from **all** system headers. To obtain; system level functionality, LLVM source must; ``#include ""llvm/Support/Thing.h""`` and nothing else. This means that; ``Thing.h`` cannot expose any system header files. This protects LLVM from; accidentally using system specific functionality and only allows it via; the ``lib/Support`` interface. Use Standard C Headers; ----------------------. The **standard** C headers (the ones beginning with ""c"") are allowed to be; exposed through the ``lib/Support`` interface. These headers and the things they; declare are considered to be platform agnostic. LLVM source files may include; them directly or obtain their inclusion through ``lib/Support`` interfaces. Use Standard C++ Headers; ------------------------. The **standard** C++ headers from the standard C++ library and standard; template library may be exposed through the ``lib/Support`` interface. These; headers and the things they declare are considered to be platform agnostic.; LLVM source files may include them or obtain their inclusion through; ``lib/Support`` interfaces. High Level Interface; --------------------. The entry points specified in the interface of ``lib/Support`` must be aimed at; completing some reasonably high level task needed by LLVM. We do not want to; simply wrap each operating system call. It would be preferable to wrap several; operating system calls that are always used in conjunction with one another by; LLVM. For example, consider what is needed to execute a program, wait for it to; complete, and return its result code. On Unix, this involves the following; operating system calls: ``getenv``, ``fork``, ``execve``, and ``wait``. The; correct thing for ``lib/Support`` to provide is a function, say; ``ExecuteProgramAndWait``, that implements the functionality completely. what; we d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:3884,Integrability,interface,interfaces,3884,"rs. To obtain; system level functionality, LLVM source must; ``#include ""llvm/Support/Thing.h""`` and nothing else. This means that; ``Thing.h`` cannot expose any system header files. This protects LLVM from; accidentally using system specific functionality and only allows it via; the ``lib/Support`` interface. Use Standard C Headers; ----------------------. The **standard** C headers (the ones beginning with ""c"") are allowed to be; exposed through the ``lib/Support`` interface. These headers and the things they; declare are considered to be platform agnostic. LLVM source files may include; them directly or obtain their inclusion through ``lib/Support`` interfaces. Use Standard C++ Headers; ------------------------. The **standard** C++ headers from the standard C++ library and standard; template library may be exposed through the ``lib/Support`` interface. These; headers and the things they declare are considered to be platform agnostic.; LLVM source files may include them or obtain their inclusion through; ``lib/Support`` interfaces. High Level Interface; --------------------. The entry points specified in the interface of ``lib/Support`` must be aimed at; completing some reasonably high level task needed by LLVM. We do not want to; simply wrap each operating system call. It would be preferable to wrap several; operating system calls that are always used in conjunction with one another by; LLVM. For example, consider what is needed to execute a program, wait for it to; complete, and return its result code. On Unix, this involves the following; operating system calls: ``getenv``, ``fork``, ``execve``, and ``wait``. The; correct thing for ``lib/Support`` to provide is a function, say; ``ExecuteProgramAndWait``, that implements the functionality completely. what; we don't want is wrappers for the operating system calls involved. There must **not** be a one-to-one relationship between operating system; calls and the Support library's interface. Any such interface functi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:3974,Integrability,interface,interface,3974,"stem header files. This protects LLVM from; accidentally using system specific functionality and only allows it via; the ``lib/Support`` interface. Use Standard C Headers; ----------------------. The **standard** C headers (the ones beginning with ""c"") are allowed to be; exposed through the ``lib/Support`` interface. These headers and the things they; declare are considered to be platform agnostic. LLVM source files may include; them directly or obtain their inclusion through ``lib/Support`` interfaces. Use Standard C++ Headers; ------------------------. The **standard** C++ headers from the standard C++ library and standard; template library may be exposed through the ``lib/Support`` interface. These; headers and the things they declare are considered to be platform agnostic.; LLVM source files may include them or obtain their inclusion through; ``lib/Support`` interfaces. High Level Interface; --------------------. The entry points specified in the interface of ``lib/Support`` must be aimed at; completing some reasonably high level task needed by LLVM. We do not want to; simply wrap each operating system call. It would be preferable to wrap several; operating system calls that are always used in conjunction with one another by; LLVM. For example, consider what is needed to execute a program, wait for it to; complete, and return its result code. On Unix, this involves the following; operating system calls: ``getenv``, ``fork``, ``execve``, and ``wait``. The; correct thing for ``lib/Support`` to provide is a function, say; ``ExecuteProgramAndWait``, that implements the functionality completely. what; we don't want is wrappers for the operating system calls involved. There must **not** be a one-to-one relationship between operating system; calls and the Support library's interface. Any such interface function will be; suspicious. No Unused Functionality; -----------------------. There must be no functionality specified in the interface of ``lib/Support``; that isn't ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:4106,Integrability,wrap,wrap,4106,"ly allows it via; the ``lib/Support`` interface. Use Standard C Headers; ----------------------. The **standard** C headers (the ones beginning with ""c"") are allowed to be; exposed through the ``lib/Support`` interface. These headers and the things they; declare are considered to be platform agnostic. LLVM source files may include; them directly or obtain their inclusion through ``lib/Support`` interfaces. Use Standard C++ Headers; ------------------------. The **standard** C++ headers from the standard C++ library and standard; template library may be exposed through the ``lib/Support`` interface. These; headers and the things they declare are considered to be platform agnostic.; LLVM source files may include them or obtain their inclusion through; ``lib/Support`` interfaces. High Level Interface; --------------------. The entry points specified in the interface of ``lib/Support`` must be aimed at; completing some reasonably high level task needed by LLVM. We do not want to; simply wrap each operating system call. It would be preferable to wrap several; operating system calls that are always used in conjunction with one another by; LLVM. For example, consider what is needed to execute a program, wait for it to; complete, and return its result code. On Unix, this involves the following; operating system calls: ``getenv``, ``fork``, ``execve``, and ``wait``. The; correct thing for ``lib/Support`` to provide is a function, say; ``ExecuteProgramAndWait``, that implements the functionality completely. what; we don't want is wrappers for the operating system calls involved. There must **not** be a one-to-one relationship between operating system; calls and the Support library's interface. Any such interface function will be; suspicious. No Unused Functionality; -----------------------. There must be no functionality specified in the interface of ``lib/Support``; that isn't actually used by LLVM. We're not writing a general purpose operating; system wrapper here, just enou",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:4165,Integrability,wrap,wrap,4165,"--. The **standard** C headers (the ones beginning with ""c"") are allowed to be; exposed through the ``lib/Support`` interface. These headers and the things they; declare are considered to be platform agnostic. LLVM source files may include; them directly or obtain their inclusion through ``lib/Support`` interfaces. Use Standard C++ Headers; ------------------------. The **standard** C++ headers from the standard C++ library and standard; template library may be exposed through the ``lib/Support`` interface. These; headers and the things they declare are considered to be platform agnostic.; LLVM source files may include them or obtain their inclusion through; ``lib/Support`` interfaces. High Level Interface; --------------------. The entry points specified in the interface of ``lib/Support`` must be aimed at; completing some reasonably high level task needed by LLVM. We do not want to; simply wrap each operating system call. It would be preferable to wrap several; operating system calls that are always used in conjunction with one another by; LLVM. For example, consider what is needed to execute a program, wait for it to; complete, and return its result code. On Unix, this involves the following; operating system calls: ``getenv``, ``fork``, ``execve``, and ``wait``. The; correct thing for ``lib/Support`` to provide is a function, say; ``ExecuteProgramAndWait``, that implements the functionality completely. what; we don't want is wrappers for the operating system calls involved. There must **not** be a one-to-one relationship between operating system; calls and the Support library's interface. Any such interface function will be; suspicious. No Unused Functionality; -----------------------. There must be no functionality specified in the interface of ``lib/Support``; that isn't actually used by LLVM. We're not writing a general purpose operating; system wrapper here, just enough to satisfy LLVM's needs. And, LLVM doesn't; need much. This design goal aims to keep the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:4654,Integrability,wrap,wrappers,4654," exposed through the ``lib/Support`` interface. These; headers and the things they declare are considered to be platform agnostic.; LLVM source files may include them or obtain their inclusion through; ``lib/Support`` interfaces. High Level Interface; --------------------. The entry points specified in the interface of ``lib/Support`` must be aimed at; completing some reasonably high level task needed by LLVM. We do not want to; simply wrap each operating system call. It would be preferable to wrap several; operating system calls that are always used in conjunction with one another by; LLVM. For example, consider what is needed to execute a program, wait for it to; complete, and return its result code. On Unix, this involves the following; operating system calls: ``getenv``, ``fork``, ``execve``, and ``wait``. The; correct thing for ``lib/Support`` to provide is a function, say; ``ExecuteProgramAndWait``, that implements the functionality completely. what; we don't want is wrappers for the operating system calls involved. There must **not** be a one-to-one relationship between operating system; calls and the Support library's interface. Any such interface function will be; suspicious. No Unused Functionality; -----------------------. There must be no functionality specified in the interface of ``lib/Support``; that isn't actually used by LLVM. We're not writing a general purpose operating; system wrapper here, just enough to satisfy LLVM's needs. And, LLVM doesn't; need much. This design goal aims to keep the ``lib/Support`` interface small and; understandable which should foster its actual use and adoption. No Duplicate Implementations; ----------------------------. The implementation of a function for a given platform must be written exactly; once. This implies that it must be possible to apply a function's; implementation to multiple operating systems if those operating systems can; share the same implementation. This rule applies to the set of operating; systems ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:4810,Integrability,interface,interface,4810,"considered to be platform agnostic.; LLVM source files may include them or obtain their inclusion through; ``lib/Support`` interfaces. High Level Interface; --------------------. The entry points specified in the interface of ``lib/Support`` must be aimed at; completing some reasonably high level task needed by LLVM. We do not want to; simply wrap each operating system call. It would be preferable to wrap several; operating system calls that are always used in conjunction with one another by; LLVM. For example, consider what is needed to execute a program, wait for it to; complete, and return its result code. On Unix, this involves the following; operating system calls: ``getenv``, ``fork``, ``execve``, and ``wait``. The; correct thing for ``lib/Support`` to provide is a function, say; ``ExecuteProgramAndWait``, that implements the functionality completely. what; we don't want is wrappers for the operating system calls involved. There must **not** be a one-to-one relationship between operating system; calls and the Support library's interface. Any such interface function will be; suspicious. No Unused Functionality; -----------------------. There must be no functionality specified in the interface of ``lib/Support``; that isn't actually used by LLVM. We're not writing a general purpose operating; system wrapper here, just enough to satisfy LLVM's needs. And, LLVM doesn't; need much. This design goal aims to keep the ``lib/Support`` interface small and; understandable which should foster its actual use and adoption. No Duplicate Implementations; ----------------------------. The implementation of a function for a given platform must be written exactly; once. This implies that it must be possible to apply a function's; implementation to multiple operating systems if those operating systems can; share the same implementation. This rule applies to the set of operating; systems supported for a given class of operating system (e.g. Unix, Win32). No Virtual Methods; -------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:4830,Integrability,interface,interface,4830,"heir inclusion through; ``lib/Support`` interfaces. High Level Interface; --------------------. The entry points specified in the interface of ``lib/Support`` must be aimed at; completing some reasonably high level task needed by LLVM. We do not want to; simply wrap each operating system call. It would be preferable to wrap several; operating system calls that are always used in conjunction with one another by; LLVM. For example, consider what is needed to execute a program, wait for it to; complete, and return its result code. On Unix, this involves the following; operating system calls: ``getenv``, ``fork``, ``execve``, and ``wait``. The; correct thing for ``lib/Support`` to provide is a function, say; ``ExecuteProgramAndWait``, that implements the functionality completely. what; we don't want is wrappers for the operating system calls involved. There must **not** be a one-to-one relationship between operating system; calls and the Support library's interface. Any such interface function will be; suspicious. No Unused Functionality; -----------------------. There must be no functionality specified in the interface of ``lib/Support``; that isn't actually used by LLVM. We're not writing a general purpose operating; system wrapper here, just enough to satisfy LLVM's needs. And, LLVM doesn't; need much. This design goal aims to keep the ``lib/Support`` interface small and; understandable which should foster its actual use and adoption. No Duplicate Implementations; ----------------------------. The implementation of a function for a given platform must be written exactly; once. This implies that it must be possible to apply a function's; implementation to multiple operating systems if those operating systems can; share the same implementation. This rule applies to the set of operating; systems supported for a given class of operating system (e.g. Unix, Win32). No Virtual Methods; ------------------. The Support Library interfaces can be called quite frequently by LLVM.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:4968,Integrability,interface,interface,4968,"nterface of ``lib/Support`` must be aimed at; completing some reasonably high level task needed by LLVM. We do not want to; simply wrap each operating system call. It would be preferable to wrap several; operating system calls that are always used in conjunction with one another by; LLVM. For example, consider what is needed to execute a program, wait for it to; complete, and return its result code. On Unix, this involves the following; operating system calls: ``getenv``, ``fork``, ``execve``, and ``wait``. The; correct thing for ``lib/Support`` to provide is a function, say; ``ExecuteProgramAndWait``, that implements the functionality completely. what; we don't want is wrappers for the operating system calls involved. There must **not** be a one-to-one relationship between operating system; calls and the Support library's interface. Any such interface function will be; suspicious. No Unused Functionality; -----------------------. There must be no functionality specified in the interface of ``lib/Support``; that isn't actually used by LLVM. We're not writing a general purpose operating; system wrapper here, just enough to satisfy LLVM's needs. And, LLVM doesn't; need much. This design goal aims to keep the ``lib/Support`` interface small and; understandable which should foster its actual use and adoption. No Duplicate Implementations; ----------------------------. The implementation of a function for a given platform must be written exactly; once. This implies that it must be possible to apply a function's; implementation to multiple operating systems if those operating systems can; share the same implementation. This rule applies to the set of operating; systems supported for a given class of operating system (e.g. Unix, Win32). No Virtual Methods; ------------------. The Support Library interfaces can be called quite frequently by LLVM. In order; to make those calls as efficient as possible, we discourage the use of virtual; methods. There is no need to use inheri",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:5086,Integrability,wrap,wrapper,5086,"do not want to; simply wrap each operating system call. It would be preferable to wrap several; operating system calls that are always used in conjunction with one another by; LLVM. For example, consider what is needed to execute a program, wait for it to; complete, and return its result code. On Unix, this involves the following; operating system calls: ``getenv``, ``fork``, ``execve``, and ``wait``. The; correct thing for ``lib/Support`` to provide is a function, say; ``ExecuteProgramAndWait``, that implements the functionality completely. what; we don't want is wrappers for the operating system calls involved. There must **not** be a one-to-one relationship between operating system; calls and the Support library's interface. Any such interface function will be; suspicious. No Unused Functionality; -----------------------. There must be no functionality specified in the interface of ``lib/Support``; that isn't actually used by LLVM. We're not writing a general purpose operating; system wrapper here, just enough to satisfy LLVM's needs. And, LLVM doesn't; need much. This design goal aims to keep the ``lib/Support`` interface small and; understandable which should foster its actual use and adoption. No Duplicate Implementations; ----------------------------. The implementation of a function for a given platform must be written exactly; once. This implies that it must be possible to apply a function's; implementation to multiple operating systems if those operating systems can; share the same implementation. This rule applies to the set of operating; systems supported for a given class of operating system (e.g. Unix, Win32). No Virtual Methods; ------------------. The Support Library interfaces can be called quite frequently by LLVM. In order; to make those calls as efficient as possible, we discourage the use of virtual; methods. There is no need to use inheritance for implementation differences, it; just adds complexity. The ``#include`` mechanism works just fine. N",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:5217,Integrability,interface,interface,5217,"tion with one another by; LLVM. For example, consider what is needed to execute a program, wait for it to; complete, and return its result code. On Unix, this involves the following; operating system calls: ``getenv``, ``fork``, ``execve``, and ``wait``. The; correct thing for ``lib/Support`` to provide is a function, say; ``ExecuteProgramAndWait``, that implements the functionality completely. what; we don't want is wrappers for the operating system calls involved. There must **not** be a one-to-one relationship between operating system; calls and the Support library's interface. Any such interface function will be; suspicious. No Unused Functionality; -----------------------. There must be no functionality specified in the interface of ``lib/Support``; that isn't actually used by LLVM. We're not writing a general purpose operating; system wrapper here, just enough to satisfy LLVM's needs. And, LLVM doesn't; need much. This design goal aims to keep the ``lib/Support`` interface small and; understandable which should foster its actual use and adoption. No Duplicate Implementations; ----------------------------. The implementation of a function for a given platform must be written exactly; once. This implies that it must be possible to apply a function's; implementation to multiple operating systems if those operating systems can; share the same implementation. This rule applies to the set of operating; systems supported for a given class of operating system (e.g. Unix, Win32). No Virtual Methods; ------------------. The Support Library interfaces can be called quite frequently by LLVM. In order; to make those calls as efficient as possible, we discourage the use of virtual; methods. There is no need to use inheritance for implementation differences, it; just adds complexity. The ``#include`` mechanism works just fine. No Exposed Functions; --------------------. Any functions defined by system libraries (i.e. not defined by ``lib/Support``); must not be exposed throug",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:5795,Integrability,interface,interfaces,5795," interface. Any such interface function will be; suspicious. No Unused Functionality; -----------------------. There must be no functionality specified in the interface of ``lib/Support``; that isn't actually used by LLVM. We're not writing a general purpose operating; system wrapper here, just enough to satisfy LLVM's needs. And, LLVM doesn't; need much. This design goal aims to keep the ``lib/Support`` interface small and; understandable which should foster its actual use and adoption. No Duplicate Implementations; ----------------------------. The implementation of a function for a given platform must be written exactly; once. This implies that it must be possible to apply a function's; implementation to multiple operating systems if those operating systems can; share the same implementation. This rule applies to the set of operating; systems supported for a given class of operating system (e.g. Unix, Win32). No Virtual Methods; ------------------. The Support Library interfaces can be called quite frequently by LLVM. In order; to make those calls as efficient as possible, we discourage the use of virtual; methods. There is no need to use inheritance for implementation differences, it; just adds complexity. The ``#include`` mechanism works just fine. No Exposed Functions; --------------------. Any functions defined by system libraries (i.e. not defined by ``lib/Support``); must not be exposed through the ``lib/Support`` interface, even if the header; file for that function is not exposed. This prevents inadvertent use of system; specific functionality. For example, the ``stat`` system call is notorious for having variations in the; data it provides. ``lib/Support`` must not declare ``stat`` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Lib",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:6256,Integrability,interface,interface,6256,"ble which should foster its actual use and adoption. No Duplicate Implementations; ----------------------------. The implementation of a function for a given platform must be written exactly; once. This implies that it must be possible to apply a function's; implementation to multiple operating systems if those operating systems can; share the same implementation. This rule applies to the set of operating; systems supported for a given class of operating system (e.g. Unix, Win32). No Virtual Methods; ------------------. The Support Library interfaces can be called quite frequently by LLVM. In order; to make those calls as efficient as possible, we discourage the use of virtual; methods. There is no need to use inheritance for implementation differences, it; just adds complexity. The ``#include`` mechanism works just fine. No Exposed Functions; --------------------. Any functions defined by system libraries (i.e. not defined by ``lib/Support``); must not be exposed through the ``lib/Support`` interface, even if the header; file for that function is not exposed. This prevents inadvertent use of system; specific functionality. For example, the ``stat`` system call is notorious for having variations in the; data it provides. ``lib/Support`` must not declare ``stat`` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; -------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:6596,Integrability,interface,interface,6596,"ion. This rule applies to the set of operating; systems supported for a given class of operating system (e.g. Unix, Win32). No Virtual Methods; ------------------. The Support Library interfaces can be called quite frequently by LLVM. In order; to make those calls as efficient as possible, we discourage the use of virtual; methods. There is no need to use inheritance for implementation differences, it; just adds complexity. The ``#include`` mechanism works just fine. No Exposed Functions; --------------------. Any functions defined by system libraries (i.e. not defined by ``lib/Support``); must not be exposed through the ``lib/Support`` interface, even if the header; file for that function is not exposed. This prevents inadvertent use of system; specific functionality. For example, the ``stat`` system call is notorious for having variations in the; data it provides. ``lib/Support`` must not declare ``stat`` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:6669,Integrability,interface,interfaces,6669," (e.g. Unix, Win32). No Virtual Methods; ------------------. The Support Library interfaces can be called quite frequently by LLVM. In order; to make those calls as efficient as possible, we discourage the use of virtual; methods. There is no need to use inheritance for implementation differences, it; just adds complexity. The ``#include`` mechanism works just fine. No Exposed Functions; --------------------. Any functions defined by system libraries (i.e. not defined by ``lib/Support``); must not be exposed through the ``lib/Support`` interface, even if the header; file for that function is not exposed. This prevents inadvertent use of system; specific functionality. For example, the ``stat`` system call is notorious for having variations in the; data it provides. ``lib/Support`` must not declare ``stat`` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first gro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:6772,Integrability,interface,interface,6772," frequently by LLVM. In order; to make those calls as efficient as possible, we discourage the use of virtual; methods. There is no need to use inheritance for implementation differences, it; just adds complexity. The ``#include`` mechanism works just fine. No Exposed Functions; --------------------. Any functions defined by system libraries (i.e. not defined by ``lib/Support``); must not be exposed through the ``lib/Support`` interface, even if the header; file for that function is not exposed. This prevents inadvertent use of system; specific functionality. For example, the ``stat`` system call is notorious for having variations in the; data it provides. ``lib/Support`` must not declare ``stat`` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:7042,Integrability,interface,interface,7042,"ty. The ``#include`` mechanism works just fine. No Exposed Functions; --------------------. Any functions defined by system libraries (i.e. not defined by ``lib/Support``); must not be exposed through the ``lib/Support`` interface, even if the header; file for that function is not exposed. This prevents inadvertent use of system; specific functionality. For example, the ``stat`` system call is notorious for having variations in the; data it provides. ``lib/Support`` must not declare ``stat`` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:7270,Integrability,interface,interfaces,7270,"on is not exposed. This prevents inadvertent use of system; specific functionality. For example, the ``stat`` system call is notorious for having variations in the; data it provides. ``lib/Support`` must not declare ``stat`` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:7954,Integrability,interface,interface,7954,"a; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:8071,Integrability,interface,interface,8071,"e header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:8196,Integrability,interface,interface,8196," Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:8593,Integrability,interface,interface,8593,"ch harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; compiler does not insert additional exception handling code into the interface; functions. This ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:9196,Integrability,interface,interface,9196,"of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; compiler does not insert additional exception handling code into the interface; functions. This is a performance consideration: ``lib/Support`` functions are; at the bottom of many call chains and as such can be frequently called. We; need them to be as efficient as possible. However, no routines in the system; library should actually throw exceptions. Code Organization; -----------------. Implementations of the Support Library interface are separated by their general; class of operating system. Currently only Unix and Win32 classes are defined; but more could be added for other operating system classifications. To; distinguish which implementation to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:9394,Integrability,interface,interface,9394,"mpting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; compiler does not insert additional exception handling code into the interface; functions. This is a performance consideration: ``lib/Support`` functions are; at the bottom of many call chains and as such can be frequently called. We; need them to be as efficient as possible. However, no routines in the system; library should actually throw exceptions. Code Organization; -----------------. Implementations of the Support Library interface are separated by their general; class of operating system. Currently only Unix and Win32 classes are defined; but more could be added for other operating system classifications. To; distinguish which implementation to compile, the code in ``lib/Support`` uses; the ``LLVM_ON_UNIX`` and ``_WIN32`` ``#defines``. Each source file in; ``lib/Support``, after implementing the generic (operating system independent); functionality needs to include the correct implement",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:9583,Integrability,interface,interface,9583,"rs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; compiler does not insert additional exception handling code into the interface; functions. This is a performance consideration: ``lib/Support`` functions are; at the bottom of many call chains and as such can be frequently called. We; need them to be as efficient as possible. However, no routines in the system; library should actually throw exceptions. Code Organization; -----------------. Implementations of the Support Library interface are separated by their general; class of operating system. Currently only Unix and Win32 classes are defined; but more could be added for other operating system classifications. To; distinguish which implementation to compile, the code in ``lib/Support`` uses; the ``LLVM_ON_UNIX`` and ``_WIN32`` ``#defines``. Each source file in; ``lib/Support``, after implementing the generic (operating system independent); functionality needs to include the correct implementation using a set of; ``#if defined(LLVM_ON_XYZ)`` directives. For example, if we had; ``lib/Support/Path.cpp``, we'd ex",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:9803,Integrability,rout,routines,9803,"ciple needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; compiler does not insert additional exception handling code into the interface; functions. This is a performance consideration: ``lib/Support`` functions are; at the bottom of many call chains and as such can be frequently called. We; need them to be as efficient as possible. However, no routines in the system; library should actually throw exceptions. Code Organization; -----------------. Implementations of the Support Library interface are separated by their general; class of operating system. Currently only Unix and Win32 classes are defined; but more could be added for other operating system classifications. To; distinguish which implementation to compile, the code in ``lib/Support`` uses; the ``LLVM_ON_UNIX`` and ``_WIN32`` ``#defines``. Each source file in; ``lib/Support``, after implementing the generic (operating system independent); functionality needs to include the correct implementation using a set of; ``#if defined(LLVM_ON_XYZ)`` directives. For example, if we had; ``lib/Support/Path.cpp``, we'd expect to see in that file:. .. code-block:: c++. #if defined(LLVM_ON_UNIX); #include ""Unix/Path.inc""; #endif; #if defined(_WIN32); #include ""Windows/Path.inc""; #endif. The implementation in ``lib/Support/Unix/Path.inc`` should handle all Unix; variants. The implementation in ``lib/Support/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:9946,Integrability,interface,interface,9946,"VM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; compiler does not insert additional exception handling code into the interface; functions. This is a performance consideration: ``lib/Support`` functions are; at the bottom of many call chains and as such can be frequently called. We; need them to be as efficient as possible. However, no routines in the system; library should actually throw exceptions. Code Organization; -----------------. Implementations of the Support Library interface are separated by their general; class of operating system. Currently only Unix and Win32 classes are defined; but more could be added for other operating system classifications. To; distinguish which implementation to compile, the code in ``lib/Support`` uses; the ``LLVM_ON_UNIX`` and ``_WIN32`` ``#defines``. Each source file in; ``lib/Support``, after implementing the generic (operating system independent); functionality needs to include the correct implementation using a set of; ``#if defined(LLVM_ON_XYZ)`` directives. For example, if we had; ``lib/Support/Path.cpp``, we'd expect to see in that file:. .. code-block:: c++. #if defined(LLVM_ON_UNIX); #include ""Unix/Path.inc""; #endif; #if defined(_WIN32); #include ""Windows/Path.inc""; #endif. The implementation in ``lib/Support/Unix/Path.inc`` should handle all Unix; variants. The implementation in ``lib/Support/Windows/Path.inc`` should handle; all Windows variants. What this does is quickly inc the basic class; of operating system that wil",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:11173,Integrability,interface,interface,11173,"throw exceptions. Code Organization; -----------------. Implementations of the Support Library interface are separated by their general; class of operating system. Currently only Unix and Win32 classes are defined; but more could be added for other operating system classifications. To; distinguish which implementation to compile, the code in ``lib/Support`` uses; the ``LLVM_ON_UNIX`` and ``_WIN32`` ``#defines``. Each source file in; ``lib/Support``, after implementing the generic (operating system independent); functionality needs to include the correct implementation using a set of; ``#if defined(LLVM_ON_XYZ)`` directives. For example, if we had; ``lib/Support/Path.cpp``, we'd expect to see in that file:. .. code-block:: c++. #if defined(LLVM_ON_UNIX); #include ""Unix/Path.inc""; #endif; #if defined(_WIN32); #include ""Windows/Path.inc""; #endif. The implementation in ``lib/Support/Unix/Path.inc`` should handle all Unix; variants. The implementation in ``lib/Support/Windows/Path.inc`` should handle; all Windows variants. What this does is quickly inc the basic class; of operating system that will provide the implementation. The specific details; for a given platform must still be determined through the use of ``#ifdef``. Consistent Semantics; --------------------. The implementation of a ``lib/Support`` interface can vary drastically between; platforms. That's okay as long as the end result of the interface function is; the same. For example, a function to create a directory is pretty straight; forward on all operating system. System V IPC on the other hand isn't even; supported on all platforms. Instead of ""supporting"" System V IPC,; ``lib/Support`` should provide an interface to the basic concept of; inter-process communications. The implementations might use System V IPC if; that was available or named pipes, or whatever gets the job done effectively; for a given operating system. In all cases, the interface and the; implementation must be semantically consistent.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:11269,Integrability,interface,interface,11269,"throw exceptions. Code Organization; -----------------. Implementations of the Support Library interface are separated by their general; class of operating system. Currently only Unix and Win32 classes are defined; but more could be added for other operating system classifications. To; distinguish which implementation to compile, the code in ``lib/Support`` uses; the ``LLVM_ON_UNIX`` and ``_WIN32`` ``#defines``. Each source file in; ``lib/Support``, after implementing the generic (operating system independent); functionality needs to include the correct implementation using a set of; ``#if defined(LLVM_ON_XYZ)`` directives. For example, if we had; ``lib/Support/Path.cpp``, we'd expect to see in that file:. .. code-block:: c++. #if defined(LLVM_ON_UNIX); #include ""Unix/Path.inc""; #endif; #if defined(_WIN32); #include ""Windows/Path.inc""; #endif. The implementation in ``lib/Support/Unix/Path.inc`` should handle all Unix; variants. The implementation in ``lib/Support/Windows/Path.inc`` should handle; all Windows variants. What this does is quickly inc the basic class; of operating system that will provide the implementation. The specific details; for a given platform must still be determined through the use of ``#ifdef``. Consistent Semantics; --------------------. The implementation of a ``lib/Support`` interface can vary drastically between; platforms. That's okay as long as the end result of the interface function is; the same. For example, a function to create a directory is pretty straight; forward on all operating system. System V IPC on the other hand isn't even; supported on all platforms. Instead of ""supporting"" System V IPC,; ``lib/Support`` should provide an interface to the basic concept of; inter-process communications. The implementations might use System V IPC if; that was available or named pipes, or whatever gets the job done effectively; for a given operating system. In all cases, the interface and the; implementation must be semantically consistent.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:11545,Integrability,interface,interface,11545,"throw exceptions. Code Organization; -----------------. Implementations of the Support Library interface are separated by their general; class of operating system. Currently only Unix and Win32 classes are defined; but more could be added for other operating system classifications. To; distinguish which implementation to compile, the code in ``lib/Support`` uses; the ``LLVM_ON_UNIX`` and ``_WIN32`` ``#defines``. Each source file in; ``lib/Support``, after implementing the generic (operating system independent); functionality needs to include the correct implementation using a set of; ``#if defined(LLVM_ON_XYZ)`` directives. For example, if we had; ``lib/Support/Path.cpp``, we'd expect to see in that file:. .. code-block:: c++. #if defined(LLVM_ON_UNIX); #include ""Unix/Path.inc""; #endif; #if defined(_WIN32); #include ""Windows/Path.inc""; #endif. The implementation in ``lib/Support/Unix/Path.inc`` should handle all Unix; variants. The implementation in ``lib/Support/Windows/Path.inc`` should handle; all Windows variants. What this does is quickly inc the basic class; of operating system that will provide the implementation. The specific details; for a given platform must still be determined through the use of ``#ifdef``. Consistent Semantics; --------------------. The implementation of a ``lib/Support`` interface can vary drastically between; platforms. That's okay as long as the end result of the interface function is; the same. For example, a function to create a directory is pretty straight; forward on all operating system. System V IPC on the other hand isn't even; supported on all platforms. Instead of ""supporting"" System V IPC,; ``lib/Support`` should provide an interface to the basic concept of; inter-process communications. The implementations might use System V IPC if; that was available or named pipes, or whatever gets the job done effectively; for a given operating system. In all cases, the interface and the; implementation must be semantically consistent.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:11783,Integrability,interface,interface,11783,"throw exceptions. Code Organization; -----------------. Implementations of the Support Library interface are separated by their general; class of operating system. Currently only Unix and Win32 classes are defined; but more could be added for other operating system classifications. To; distinguish which implementation to compile, the code in ``lib/Support`` uses; the ``LLVM_ON_UNIX`` and ``_WIN32`` ``#defines``. Each source file in; ``lib/Support``, after implementing the generic (operating system independent); functionality needs to include the correct implementation using a set of; ``#if defined(LLVM_ON_XYZ)`` directives. For example, if we had; ``lib/Support/Path.cpp``, we'd expect to see in that file:. .. code-block:: c++. #if defined(LLVM_ON_UNIX); #include ""Unix/Path.inc""; #endif; #if defined(_WIN32); #include ""Windows/Path.inc""; #endif. The implementation in ``lib/Support/Unix/Path.inc`` should handle all Unix; variants. The implementation in ``lib/Support/Windows/Path.inc`` should handle; all Windows variants. What this does is quickly inc the basic class; of operating system that will provide the implementation. The specific details; for a given platform must still be determined through the use of ``#ifdef``. Consistent Semantics; --------------------. The implementation of a ``lib/Support`` interface can vary drastically between; platforms. That's okay as long as the end result of the interface function is; the same. For example, a function to create a directory is pretty straight; forward on all operating system. System V IPC on the other hand isn't even; supported on all platforms. Instead of ""supporting"" System V IPC,; ``lib/Support`` should provide an interface to the basic concept of; inter-process communications. The implementations might use System V IPC if; that was available or named pipes, or whatever gets the job done effectively; for a given operating system. In all cases, the interface and the; implementation must be semantically consistent.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:385,Modifiability,portab,portability,385,"===============; Support Library; ===============. Abstract; ========. This document provides some details on LLVM's Support Library, located in the; source at ``lib/Support`` and ``include/llvm/Support``. The library's purpose; is to shield LLVM from the differences between operating systems for the few; services LLVM needs from the operating system. Much of LLVM is written using; portability features of standard C++. However, in a few areas, system dependent; facilities are needed and the Support Library is the wrapper around those; system calls. By centralizing LLVM's use of operating system interfaces, we make it possible; for the LLVM tool chain and runtime libraries to be more easily ported to new; platforms since (theoretically) only ``lib/Support`` needs to be ported. This; library also unclutters the rest of LLVM from #ifdef use and special cases for; specific operating systems. Such uses are replaced with simple calls to the; interfaces provided in ``include/llvm/Support``. Note that the Support Library is not intended to be a complete operating system; wrapper (such as the Adaptive Communications Environment (ACE) or Apache; Portable Runtime (APR)), but only provides the functionality necessary to; support LLVM. The Support Library was originally referred to as the System Library, written; by Reid Spencer who formulated the design based on similar work originating; from the eXtensible Programming System (XPS). Several people helped with the; effort; especially, Jeff Cohen and Henrik Bach on the Win32 port. Keeping LLVM Portable; =====================. In order to keep LLVM portable, LLVM developers should adhere to a set of; portability rules associated with the Support Library. Adherence to these rules; should help the Support Library achieve its goal of shielding LLVM from the; variations in operating system interfaces and doing so efficiently. The; following sections define the rules needed to fulfill this objective. Don't Include System Headers; ------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:1611,Modifiability,portab,portable,1611,"chain and runtime libraries to be more easily ported to new; platforms since (theoretically) only ``lib/Support`` needs to be ported. This; library also unclutters the rest of LLVM from #ifdef use and special cases for; specific operating systems. Such uses are replaced with simple calls to the; interfaces provided in ``include/llvm/Support``. Note that the Support Library is not intended to be a complete operating system; wrapper (such as the Adaptive Communications Environment (ACE) or Apache; Portable Runtime (APR)), but only provides the functionality necessary to; support LLVM. The Support Library was originally referred to as the System Library, written; by Reid Spencer who formulated the design based on similar work originating; from the eXtensible Programming System (XPS). Several people helped with the; effort; especially, Jeff Cohen and Henrik Bach on the Win32 port. Keeping LLVM Portable; =====================. In order to keep LLVM portable, LLVM developers should adhere to a set of; portability rules associated with the Support Library. Adherence to these rules; should help the Support Library achieve its goal of shielding LLVM from the; variations in operating system interfaces and doing so efficiently. The; following sections define the rules needed to fulfill this objective. Don't Include System Headers; ----------------------------. Except in ``lib/Support``, no LLVM source code should directly ``#include`` a; system header. Care has been taken to remove all such ``#includes`` from LLVM; while ``lib/Support`` was being developed. Specifically this means that header; files like ""``unistd.h``"", ""``windows.h``"", ""``stdio.h``"", and ""``string.h``""; are forbidden to be included by LLVM source code outside the implementation of; ``lib/Support``. To obtain system-dependent functionality, existing interfaces to the system; found in ``include/llvm/Support`` should be used. If an appropriate interface is; not available, it should be added to ``include/llvm/Sup",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:1664,Modifiability,portab,portability,1664,"chain and runtime libraries to be more easily ported to new; platforms since (theoretically) only ``lib/Support`` needs to be ported. This; library also unclutters the rest of LLVM from #ifdef use and special cases for; specific operating systems. Such uses are replaced with simple calls to the; interfaces provided in ``include/llvm/Support``. Note that the Support Library is not intended to be a complete operating system; wrapper (such as the Adaptive Communications Environment (ACE) or Apache; Portable Runtime (APR)), but only provides the functionality necessary to; support LLVM. The Support Library was originally referred to as the System Library, written; by Reid Spencer who formulated the design based on similar work originating; from the eXtensible Programming System (XPS). Several people helped with the; effort; especially, Jeff Cohen and Henrik Bach on the Win32 port. Keeping LLVM Portable; =====================. In order to keep LLVM portable, LLVM developers should adhere to a set of; portability rules associated with the Support Library. Adherence to these rules; should help the Support Library achieve its goal of shielding LLVM from the; variations in operating system interfaces and doing so efficiently. The; following sections define the rules needed to fulfill this objective. Don't Include System Headers; ----------------------------. Except in ``lib/Support``, no LLVM source code should directly ``#include`` a; system header. Care has been taken to remove all such ``#includes`` from LLVM; while ``lib/Support`` was being developed. Specifically this means that header; files like ""``unistd.h``"", ""``windows.h``"", ""``stdio.h``"", and ""``string.h``""; are forbidden to be included by LLVM source code outside the implementation of; ``lib/Support``. To obtain system-dependent functionality, existing interfaces to the system; found in ``include/llvm/Support`` should be used. If an appropriate interface is; not available, it should be added to ``include/llvm/Sup",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:5969,Modifiability,inherit,inheritance,5969,"ort``; that isn't actually used by LLVM. We're not writing a general purpose operating; system wrapper here, just enough to satisfy LLVM's needs. And, LLVM doesn't; need much. This design goal aims to keep the ``lib/Support`` interface small and; understandable which should foster its actual use and adoption. No Duplicate Implementations; ----------------------------. The implementation of a function for a given platform must be written exactly; once. This implies that it must be possible to apply a function's; implementation to multiple operating systems if those operating systems can; share the same implementation. This rule applies to the set of operating; systems supported for a given class of operating system (e.g. Unix, Win32). No Virtual Methods; ------------------. The Support Library interfaces can be called quite frequently by LLVM. In order; to make those calls as efficient as possible, we discourage the use of virtual; methods. There is no need to use inheritance for implementation differences, it; just adds complexity. The ``#include`` mechanism works just fine. No Exposed Functions; --------------------. Any functions defined by system libraries (i.e. not defined by ``lib/Support``); must not be exposed through the ``lib/Support`` interface, even if the header; file for that function is not exposed. This prevents inadvertent use of system; specific functionality. For example, the ``stat`` system call is notorious for having variations in the; data it provides. ``lib/Support`` must not declare ``stat`` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:9615,Performance,perform,performance,9615,"OrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; compiler does not insert additional exception handling code into the interface; functions. This is a performance consideration: ``lib/Support`` functions are; at the bottom of many call chains and as such can be frequently called. We; need them to be as efficient as possible. However, no routines in the system; library should actually throw exceptions. Code Organization; -----------------. Implementations of the Support Library interface are separated by their general; class of operating system. Currently only Unix and Win32 classes are defined; but more could be added for other operating system classifications. To; distinguish which implementation to compile, the code in ``lib/Support`` uses; the ``LLVM_ON_UNIX`` and ``_WIN32`` ``#defines``. Each source file in; ``lib/Support``, after implementing the generic (operating system independent); functionality needs to include the correct implementation using a set of; ``#if defined(LLVM_ON_XYZ)`` directives. For example, if we had; ``lib/Support/Path.cpp``, we'd expect to see in that file:. .. code-block:: c++. #if defined(LLVM_ON_UNIX); #include ""Unix/Path.inc""; #endif; #if defined(_WIN32); #inc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:8889,Safety,avoid,avoids,8889,"n of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; compiler does not insert additional exception handling code into the interface; functions. This is a performance consideration: ``lib/Support`` functions are; at the bottom of many call chains and as such can be frequently called. We; need them to be as efficient as possible. However, no routines in the system; library should actually throw exceptions. Code Organization; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:2996,Security,expose,expose,2996,"-----------------. Except in ``lib/Support``, no LLVM source code should directly ``#include`` a; system header. Care has been taken to remove all such ``#includes`` from LLVM; while ``lib/Support`` was being developed. Specifically this means that header; files like ""``unistd.h``"", ""``windows.h``"", ""``stdio.h``"", and ""``string.h``""; are forbidden to be included by LLVM source code outside the implementation of; ``lib/Support``. To obtain system-dependent functionality, existing interfaces to the system; found in ``include/llvm/Support`` should be used. If an appropriate interface is; not available, it should be added to ``include/llvm/Support`` and implemented in; ``lib/Support`` for all supported platforms. Don't Expose System Headers; ---------------------------. The Support Library must shield LLVM from **all** system headers. To obtain; system level functionality, LLVM source must; ``#include ""llvm/Support/Thing.h""`` and nothing else. This means that; ``Thing.h`` cannot expose any system header files. This protects LLVM from; accidentally using system specific functionality and only allows it via; the ``lib/Support`` interface. Use Standard C Headers; ----------------------. The **standard** C headers (the ones beginning with ""c"") are allowed to be; exposed through the ``lib/Support`` interface. These headers and the things they; declare are considered to be platform agnostic. LLVM source files may include; them directly or obtain their inclusion through ``lib/Support`` interfaces. Use Standard C++ Headers; ------------------------. The **standard** C++ headers from the standard C++ library and standard; template library may be exposed through the ``lib/Support`` interface. These; headers and the things they declare are considered to be platform agnostic.; LLVM source files may include them or obtain their inclusion through; ``lib/Support`` interfaces. High Level Interface; --------------------. The entry points specified in the interface of ``lib/Support`` mus",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:3281,Security,expose,exposed,3281,"les like ""``unistd.h``"", ""``windows.h``"", ""``stdio.h``"", and ""``string.h``""; are forbidden to be included by LLVM source code outside the implementation of; ``lib/Support``. To obtain system-dependent functionality, existing interfaces to the system; found in ``include/llvm/Support`` should be used. If an appropriate interface is; not available, it should be added to ``include/llvm/Support`` and implemented in; ``lib/Support`` for all supported platforms. Don't Expose System Headers; ---------------------------. The Support Library must shield LLVM from **all** system headers. To obtain; system level functionality, LLVM source must; ``#include ""llvm/Support/Thing.h""`` and nothing else. This means that; ``Thing.h`` cannot expose any system header files. This protects LLVM from; accidentally using system specific functionality and only allows it via; the ``lib/Support`` interface. Use Standard C Headers; ----------------------. The **standard** C headers (the ones beginning with ""c"") are allowed to be; exposed through the ``lib/Support`` interface. These headers and the things they; declare are considered to be platform agnostic. LLVM source files may include; them directly or obtain their inclusion through ``lib/Support`` interfaces. Use Standard C++ Headers; ------------------------. The **standard** C++ headers from the standard C++ library and standard; template library may be exposed through the ``lib/Support`` interface. These; headers and the things they declare are considered to be platform agnostic.; LLVM source files may include them or obtain their inclusion through; ``lib/Support`` interfaces. High Level Interface; --------------------. The entry points specified in the interface of ``lib/Support`` must be aimed at; completing some reasonably high level task needed by LLVM. We do not want to; simply wrap each operating system call. It would be preferable to wrap several; operating system calls that are always used in conjunction with one another by; LLVM. F",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:3667,Security,expose,exposed,3667,"ude/llvm/Support`` and implemented in; ``lib/Support`` for all supported platforms. Don't Expose System Headers; ---------------------------. The Support Library must shield LLVM from **all** system headers. To obtain; system level functionality, LLVM source must; ``#include ""llvm/Support/Thing.h""`` and nothing else. This means that; ``Thing.h`` cannot expose any system header files. This protects LLVM from; accidentally using system specific functionality and only allows it via; the ``lib/Support`` interface. Use Standard C Headers; ----------------------. The **standard** C headers (the ones beginning with ""c"") are allowed to be; exposed through the ``lib/Support`` interface. These headers and the things they; declare are considered to be platform agnostic. LLVM source files may include; them directly or obtain their inclusion through ``lib/Support`` interfaces. Use Standard C++ Headers; ------------------------. The **standard** C++ headers from the standard C++ library and standard; template library may be exposed through the ``lib/Support`` interface. These; headers and the things they declare are considered to be platform agnostic.; LLVM source files may include them or obtain their inclusion through; ``lib/Support`` interfaces. High Level Interface; --------------------. The entry points specified in the interface of ``lib/Support`` must be aimed at; completing some reasonably high level task needed by LLVM. We do not want to; simply wrap each operating system call. It would be preferable to wrap several; operating system calls that are always used in conjunction with one another by; LLVM. For example, consider what is needed to execute a program, wait for it to; complete, and return its result code. On Unix, this involves the following; operating system calls: ``getenv``, ``fork``, ``execve``, and ``wait``. The; correct thing for ``lib/Support`` to provide is a function, say; ``ExecuteProgramAndWait``, that implements the functionality completely. what; we d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:6220,Security,expose,exposed,6220,"ble which should foster its actual use and adoption. No Duplicate Implementations; ----------------------------. The implementation of a function for a given platform must be written exactly; once. This implies that it must be possible to apply a function's; implementation to multiple operating systems if those operating systems can; share the same implementation. This rule applies to the set of operating; systems supported for a given class of operating system (e.g. Unix, Win32). No Virtual Methods; ------------------. The Support Library interfaces can be called quite frequently by LLVM. In order; to make those calls as efficient as possible, we discourage the use of virtual; methods. There is no need to use inheritance for implementation differences, it; just adds complexity. The ``#include`` mechanism works just fine. No Exposed Functions; --------------------. Any functions defined by system libraries (i.e. not defined by ``lib/Support``); must not be exposed through the ``lib/Support`` interface, even if the header; file for that function is not exposed. This prevents inadvertent use of system; specific functionality. For example, the ``stat`` system call is notorious for having variations in the; data it provides. ``lib/Support`` must not declare ``stat`` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; -------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:6317,Security,expose,exposed,6317,"ble which should foster its actual use and adoption. No Duplicate Implementations; ----------------------------. The implementation of a function for a given platform must be written exactly; once. This implies that it must be possible to apply a function's; implementation to multiple operating systems if those operating systems can; share the same implementation. This rule applies to the set of operating; systems supported for a given class of operating system (e.g. Unix, Win32). No Virtual Methods; ------------------. The Support Library interfaces can be called quite frequently by LLVM. In order; to make those calls as efficient as possible, we discourage the use of virtual; methods. There is no need to use inheritance for implementation differences, it; just adds complexity. The ``#include`` mechanism works just fine. No Exposed Functions; --------------------. Any functions defined by system libraries (i.e. not defined by ``lib/Support``); must not be exposed through the ``lib/Support`` interface, even if the header; file for that function is not exposed. This prevents inadvertent use of system; specific functionality. For example, the ``stat`` system call is notorious for having variations in the; data it provides. ``lib/Support`` must not declare ``stat`` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; -------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:7006,Security,expose,exposed,7006,"ty. The ``#include`` mechanism works just fine. No Exposed Functions; --------------------. Any functions defined by system libraries (i.e. not defined by ``lib/Support``); must not be exposed through the ``lib/Support`` interface, even if the header; file for that function is not exposed. This prevents inadvertent use of system; specific functionality. For example, the ``stat`` system call is notorious for having variations in the; data it provides. ``lib/Support`` must not declare ``stat`` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:7103,Security,expose,exposed,7103,"ty. The ``#include`` mechanism works just fine. No Exposed Functions; --------------------. Any functions defined by system libraries (i.e. not defined by ``lib/Support``); must not be exposed through the ``lib/Support`` interface, even if the header; file for that function is not exposed. This prevents inadvertent use of system; specific functionality. For example, the ``stat`` system call is notorious for having variations in the; data it provides. ``lib/Support`` must not declare ``stat`` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:929,Usability,simpl,simple,929,"===============; Support Library; ===============. Abstract; ========. This document provides some details on LLVM's Support Library, located in the; source at ``lib/Support`` and ``include/llvm/Support``. The library's purpose; is to shield LLVM from the differences between operating systems for the few; services LLVM needs from the operating system. Much of LLVM is written using; portability features of standard C++. However, in a few areas, system dependent; facilities are needed and the Support Library is the wrapper around those; system calls. By centralizing LLVM's use of operating system interfaces, we make it possible; for the LLVM tool chain and runtime libraries to be more easily ported to new; platforms since (theoretically) only ``lib/Support`` needs to be ported. This; library also unclutters the rest of LLVM from #ifdef use and special cases for; specific operating systems. Such uses are replaced with simple calls to the; interfaces provided in ``include/llvm/Support``. Note that the Support Library is not intended to be a complete operating system; wrapper (such as the Adaptive Communications Environment (ACE) or Apache; Portable Runtime (APR)), but only provides the functionality necessary to; support LLVM. The Support Library was originally referred to as the System Library, written; by Reid Spencer who formulated the design based on similar work originating; from the eXtensible Programming System (XPS). Several people helped with the; effort; especially, Jeff Cohen and Henrik Bach on the Win32 port. Keeping LLVM Portable; =====================. In order to keep LLVM portable, LLVM developers should adhere to a set of; portability rules associated with the Support Library. Adherence to these rules; should help the Support Library achieve its goal of shielding LLVM from the; variations in operating system interfaces and doing so efficiently. The; following sections define the rules needed to fulfill this objective. Don't Include System Headers; ------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:4099,Usability,simpl,simply,4099,"ly allows it via; the ``lib/Support`` interface. Use Standard C Headers; ----------------------. The **standard** C headers (the ones beginning with ""c"") are allowed to be; exposed through the ``lib/Support`` interface. These headers and the things they; declare are considered to be platform agnostic. LLVM source files may include; them directly or obtain their inclusion through ``lib/Support`` interfaces. Use Standard C++ Headers; ------------------------. The **standard** C++ headers from the standard C++ library and standard; template library may be exposed through the ``lib/Support`` interface. These; headers and the things they declare are considered to be platform agnostic.; LLVM source files may include them or obtain their inclusion through; ``lib/Support`` interfaces. High Level Interface; --------------------. The entry points specified in the interface of ``lib/Support`` must be aimed at; completing some reasonably high level task needed by LLVM. We do not want to; simply wrap each operating system call. It would be preferable to wrap several; operating system calls that are always used in conjunction with one another by; LLVM. For example, consider what is needed to execute a program, wait for it to; complete, and return its result code. On Unix, this involves the following; operating system calls: ``getenv``, ``fork``, ``execve``, and ``wait``. The; correct thing for ``lib/Support`` to provide is a function, say; ``ExecuteProgramAndWait``, that implements the functionality completely. what; we don't want is wrappers for the operating system calls involved. There must **not** be a one-to-one relationship between operating system; calls and the Support library's interface. Any such interface function will be; suspicious. No Unused Functionality; -----------------------. There must be no functionality specified in the interface of ``lib/Support``; that isn't actually used by LLVM. We're not writing a general purpose operating; system wrapper here, just enou",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:7510,Usability,simpl,simply,7510,"` nor allow it to be; declared. Instead it should provide its own interface to discovering; information about files and directories. Those interfaces may be implemented in; terms of ``stat`` but that is strictly an implementation detail. The interface; provided by the Support Library must be implemented on all platforms (even; those without ``stat``). No Exposed Data; ---------------. Any data defined by system libraries (i.e. not defined by ``lib/Support``) must; not be exposed through the ``lib/Support`` interface, even if the header file; for that function is not exposed. As with functions, this prevents inadvertent; use of data that might not exist on all platforms. Minimize Soft Errors; --------------------. Operating system interfaces will generally provide error results for every; little thing that could go wrong. In almost all cases, you can divide these; error results into two groups: normal/good/soft and abnormal/bad/hard. That is,; some of the errors are simply information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst:8504,Usability,simpl,simply,8504,"information like ""file not found"", ""insufficient; privileges"", etc. while other errors are much harder like ""out of space"", ""bad; disk sector"", or ""system call interrupted"". We'll call the first group ""*soft*""; errors and the second group ""*hard*"" errors. ``lib/Support`` must always attempt to minimize soft errors. This is a design; requirement because the minimization of soft errors can affect the granularity; and the nature of the interface. In general, if you find that you're wanting to; throw soft errors, you must review the granularity of the interface because it; is likely you're trying to implement something that is too low level. The rule; of thumb is to provide interface functions that **can't** fail, except when; faced with hard errors. For a trivial example, suppose we wanted to add an ""``OpenFileForWriting``""; function. For many operating systems, if the file doesn't exist, attempting to; open the file will produce an error. However, ``lib/Support`` should not simply; throw that error if it occurs because its a soft error. The problem is that the; interface function, ``OpenFileForWriting`` is too low level. It should be; ``OpenOrCreateFileForWriting``. In the case of the soft ""doesn't exist"" error,; this function would just create it and then open it for writing. This design principle needs to be maintained in ``lib/Support`` because it; avoids the propagation of soft error handling throughout the rest of LLVM.; Hard errors will generally just cause a termination for an LLVM tool so don't; be bashful about throwing them. Rules of thumb:. #. Don't throw soft errors, only hard errors. #. If you're tempted to throw a soft error, re-think the interface. #. Handle internally the most common normal/good/soft error conditions; so the rest of LLVM doesn't have to. No throw Specifications; -----------------------. None of the ``lib/Support`` interface functions may be declared with C++; ``throw()`` specifications on them. This requirement makes sure that the; com",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:166,Availability,down,downstream,166,"=============================; LLVM Community Support Policy; =============================. As a compilation infrastructure, LLVM has multiple types of users, both; downstream and upstream, of many combinations of its projects, tools and; libraries. There is a core part of it that encompass the implementation of the compiler; (front/middle/back ends), run-time libraries (RT, C++, OpenMP, etc) and; associated tools (debugger, linker, object file manipulation, etc). These; components are present in the public release on our supported architectures; and operating systems and the whole community must maintain and care about. There are, however, other components within the main repository that either; cater to a specific sub-community of LLVM (upstream or downstream) or; help parts of the community to integrate LLVM into their own development tools; or external projects. Those parts of the main repository don't always have; rigorous testing like the core parts, nor are they validated and shipped with; our public upstream releases. Even not being a core part of the project, we have enough sub-communities; needing those changes with enough overlap that having them in the main; repository is beneficial to minimise the repetition of those changes in all; the external repositories that need them. But the maintenance costs of such diverse ecosystem is non trivial, so we divide; the level of support in two tiers: core and peripheral, with two; different levels of impact and responsibilities. Those tiers refer only to the; main repository (``llvm-project``) and not the other repositories in our git; project, unless explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libra",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:762,Availability,down,downstream,762,"=============================; LLVM Community Support Policy; =============================. As a compilation infrastructure, LLVM has multiple types of users, both; downstream and upstream, of many combinations of its projects, tools and; libraries. There is a core part of it that encompass the implementation of the compiler; (front/middle/back ends), run-time libraries (RT, C++, OpenMP, etc) and; associated tools (debugger, linker, object file manipulation, etc). These; components are present in the public release on our supported architectures; and operating systems and the whole community must maintain and care about. There are, however, other components within the main repository that either; cater to a specific sub-community of LLVM (upstream or downstream) or; help parts of the community to integrate LLVM into their own development tools; or external projects. Those parts of the main repository don't always have; rigorous testing like the core parts, nor are they validated and shipped with; our public upstream releases. Even not being a core part of the project, we have enough sub-communities; needing those changes with enough overlap that having them in the main; repository is beneficial to minimise the repetition of those changes in all; the external repositories that need them. But the maintenance costs of such diverse ecosystem is non trivial, so we divide; the level of support in two tiers: core and peripheral, with two; different levels of impact and responsibilities. Those tiers refer only to the; main repository (``llvm-project``) and not the other repositories in our git; project, unless explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libra",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:1317,Availability,mainten,maintenance,1317,"ciated tools (debugger, linker, object file manipulation, etc). These; components are present in the public release on our supported architectures; and operating systems and the whole community must maintain and care about. There are, however, other components within the main repository that either; cater to a specific sub-community of LLVM (upstream or downstream) or; help parts of the community to integrate LLVM into their own development tools; or external projects. Those parts of the main repository don't always have; rigorous testing like the core parts, nor are they validated and shipped with; our public upstream releases. Even not being a core part of the project, we have enough sub-communities; needing those changes with enough overlap that having them in the main; repository is beneficial to minimise the repetition of those changes in all; the external repositories that need them. But the maintenance costs of such diverse ecosystem is non trivial, so we divide; the level of support in two tiers: core and peripheral, with two; different levels of impact and responsibilities. Those tiers refer only to the; main repository (``llvm-project``) and not the other repositories in our git; project, unless explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libraries,; tools, etc. It is the responsibility of **every** LLVM developer to care for the core tier; regardless of where their work is applied to. What is covered; ---------------. The core tier is composed of:; * Core code (``llvm-project``) present in official releases and buildbots:; compiler, debugger, linker, libraries, etc, including infrastructure code; (table-gen, lit, file-check, unit-tests, etc)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:3004,Availability,down,downgraded,3004,"n-time libraries,; tools, etc. It is the responsibility of **every** LLVM developer to care for the core tier; regardless of where their work is applied to. What is covered; ---------------. The core tier is composed of:; * Core code (``llvm-project``) present in official releases and buildbots:; compiler, debugger, linker, libraries, etc, including infrastructure code; (table-gen, lit, file-check, unit-tests, etc).; * Build infrastructure that creates releases and buildbots (CMake, scripts).; * `Phabricator <https://github.com/llvm/phabricator>`_ and; `buildbot <https://github.com/llvm/llvm-zorg>`_ infrastructure.; * The `test-suite <https://github.com/llvm/llvm-test-suite>`_. Requirements; ------------. Code in this tier must:; * Keep official buildbots green, with warnings on breakages being emailed to; all affected developers. Those must be fixed as soon as possible or patches; must be reverted, as per review policy.; * Bit-rot of a component in the core tier will result in that component being; downgraded to the peripheral tier or being removed. Sub-communities can; avoid this by fixing all raised issues in a timely manner. Peripheral Tier; ===============. The peripheral tier encompass the parts of LLVM that cater to a specific; sub-community and which don't usually affect the core components directly. This includes experimental back-ends, disabled-by-default options and; alternative paths (work-in-progress replacements) in the same repository, as; well as separate efforts to integrate LLVM development with local practices. It is the responsibility of each sub-community to care about their own parts; and the intersection of that with the core tier and other peripheral parts. There are three main groups of code that fit in this category:; * Code that is making its way into LLVM, via the `experimental <https://llvm.org/docs/DeveloperPolicy.html#introducing-new-components-into-llvm>`_; roadmap or similar efforts.; * Code that is making its way out of LLVM, via de",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:4889,Availability,down,downstream,4889,"https://llvm.org/docs/DeveloperPolicy.html#introducing-new-components-into-llvm>`_; roadmap or similar efforts.; * Code that is making its way out of LLVM, via deprecation, replacement or; bit-rot, and will be removed if the sub-community that cares about it; cannot maintain it.; * Code that isn't meant to be in LLVM core and can coexist with the code in; the core tier (and others in the peripheral tier) long term, without causing; breakages or disturbances. What is covered; ---------------. The peripheral tier is composed of:; * Experimental targets and options that haven't been enable by default yet.; * Main repository projects that don't get released or regularly tested.; * Legacy tools and scripts that aren't used in upstream validation.; * Alternative build systems (ex. GN, Bazel) and related infrastructure.; * Tools support (ex. gdb scripts, editor configuration, helper scripts). Requirements; ------------. Code in this tier must:; * Have a clear benefit for residing in the main repository, catering to an; active sub-community (upstream or downstream).; * Be actively maintained by such sub-community and have its problems addressed; in a timely manner. Code in this tier must **not**:; * Break or invalidate core tier code or infrastructure. If that happens; accidentally, reverting functionality and working on the issues offline; is the only acceptable course of action.; * Negatively affect development of core tier code, with the sub-community; involved responsible for making changes to address specific concerns.; * Negatively affect other peripheral tier code, with the sub-communities; involved tasked to resolve the issues, still making sure the solution doesn't; break or invalidate the core tier.; * Impose sub-optimal implementation strategies on core tier components as a; result of idiosyncrasies in the peripheral component.; * Have build infrastructure that spams all developers about their breakages.; * Fall into disrepair. This is a reflection of lack of an ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:6097,Availability,resilien,resilience,6097,"ly acceptable course of action.; * Negatively affect development of core tier code, with the sub-community; involved responsible for making changes to address specific concerns.; * Negatively affect other peripheral tier code, with the sub-communities; involved tasked to resolve the issues, still making sure the solution doesn't; break or invalidate the core tier.; * Impose sub-optimal implementation strategies on core tier components as a; result of idiosyncrasies in the peripheral component.; * Have build infrastructure that spams all developers about their breakages.; * Fall into disrepair. This is a reflection of lack of an active sub-community; and will result in removal. Code in this tier should:; * Have infrastructure to test, whenever meaningful, with either no warnings or; notification contained within the sub-community.; * Have support and testing that scales with the complexity and resilience of; the component, with the bar for simple and gracefully-degrading components; (such as editor bindings) much lower than for complex components that must; remain fresh with HEAD (such as experimental back-ends or alternative build; systems).; * Have a document making clear the status of implementation, level of support; available, who the sub-community is and, if applicable, roadmap for inclusion; into the core tier.; * Be restricted to a specific directory or have a consistent pattern (ex.; unique file suffix), making it easy to remove when necessary. Inclusion Policy; ================. To add a new peripheral component, send an RFC to the appropriate dev list; proposing its addition and explaining how it will meet the support requirements; listed above. Different types of components could require different levels of; detail. when in doubt, ask the community what's the best approach. Inclusion must reach consensus in the RFC by the community and the approval of; the corresponding review (by multiple members of the community) is the official; note of acceptance. Aft",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:6431,Availability,avail,available,6431,"ies; involved tasked to resolve the issues, still making sure the solution doesn't; break or invalidate the core tier.; * Impose sub-optimal implementation strategies on core tier components as a; result of idiosyncrasies in the peripheral component.; * Have build infrastructure that spams all developers about their breakages.; * Fall into disrepair. This is a reflection of lack of an active sub-community; and will result in removal. Code in this tier should:; * Have infrastructure to test, whenever meaningful, with either no warnings or; notification contained within the sub-community.; * Have support and testing that scales with the complexity and resilience of; the component, with the bar for simple and gracefully-degrading components; (such as editor bindings) much lower than for complex components that must; remain fresh with HEAD (such as experimental back-ends or alternative build; systems).; * Have a document making clear the status of implementation, level of support; available, who the sub-community is and, if applicable, roadmap for inclusion; into the core tier.; * Be restricted to a specific directory or have a consistent pattern (ex.; unique file suffix), making it easy to remove when necessary. Inclusion Policy; ================. To add a new peripheral component, send an RFC to the appropriate dev list; proposing its addition and explaining how it will meet the support requirements; listed above. Different types of components could require different levels of; detail. when in doubt, ask the community what's the best approach. Inclusion must reach consensus in the RFC by the community and the approval of; the corresponding review (by multiple members of the community) is the official; note of acceptance. After merge, there often is a period of transition, where teething issues on; existing buildbots are discovered and fixed. If those cannot be fixed straight; away, the sub-community is responsible for tracking and reverting all the; pertinent patches a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:8141,Availability,down,downstream,8141," and the approval of; the corresponding review (by multiple members of the community) is the official; note of acceptance. After merge, there often is a period of transition, where teething issues on; existing buildbots are discovered and fixed. If those cannot be fixed straight; away, the sub-community is responsible for tracking and reverting all the; pertinent patches and retrying the inclusion review. Once the component is stable in tree, it must follow this policy and the; deprecation rules below apply. Due to the uncertain nature of inclusion, it's advisable that new components; are not added too close to a release branch. The time will depend on the size; and complexity of the component, so adding release and testing managers on the; RFC and review is strongly advisable. Deprecation Policy; ==================. The LLVM code base has a number of files that aren't being actively maintained.; But not all of those files are obstructing the development of the project and; so it remains in the repository with the assumption that it could still be; useful for downstream users. For code to remain in the repository, its presence must not impose an undue; burden on maintaining other components (core or peripheral). Warnings; --------. There are multiple types of issues that might trigger a request for deprecation,; including (but not limited to):. * Changes in a component consistently break other areas of the project.; * Components go broken for long periods of time (weeks or more).; * Clearly superior alternatives are in use and maintenance is painful.; * Builds and tests are harder / take longer, increasing the cost of; maintenance, overtaking the perceived benefits. If the maintenance cost is higher than it is acceptable by the majority of; developers, it means that either the sub-community is too small (and the extra; cost should be paid locally), or not active enough (and the problems won't be; fixed any time soon). In either case, removal of such problematic compo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:8618,Availability,mainten,maintenance,8618,"e of inclusion, it's advisable that new components; are not added too close to a release branch. The time will depend on the size; and complexity of the component, so adding release and testing managers on the; RFC and review is strongly advisable. Deprecation Policy; ==================. The LLVM code base has a number of files that aren't being actively maintained.; But not all of those files are obstructing the development of the project and; so it remains in the repository with the assumption that it could still be; useful for downstream users. For code to remain in the repository, its presence must not impose an undue; burden on maintaining other components (core or peripheral). Warnings; --------. There are multiple types of issues that might trigger a request for deprecation,; including (but not limited to):. * Changes in a component consistently break other areas of the project.; * Components go broken for long periods of time (weeks or more).; * Clearly superior alternatives are in use and maintenance is painful.; * Builds and tests are harder / take longer, increasing the cost of; maintenance, overtaking the perceived benefits. If the maintenance cost is higher than it is acceptable by the majority of; developers, it means that either the sub-community is too small (and the extra; cost should be paid locally), or not active enough (and the problems won't be; fixed any time soon). In either case, removal of such problematic component is; justified. Steps for removal; -----------------. However clear the needs for removal are, we should take an incremental approach; to deprecating code, especially when there's still a sub-community that cares; about it. In that sense, code will never be removed outright without a series; of steps are taken. A minimum set of steps should be:; #. A proposal for removal / deactivation should be made to the Discourse forums ; (under the appropriate category), with a clear; statement of the maintenance costs imposed and the altern",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:8712,Availability,mainten,maintenance,8712,". The time will depend on the size; and complexity of the component, so adding release and testing managers on the; RFC and review is strongly advisable. Deprecation Policy; ==================. The LLVM code base has a number of files that aren't being actively maintained.; But not all of those files are obstructing the development of the project and; so it remains in the repository with the assumption that it could still be; useful for downstream users. For code to remain in the repository, its presence must not impose an undue; burden on maintaining other components (core or peripheral). Warnings; --------. There are multiple types of issues that might trigger a request for deprecation,; including (but not limited to):. * Changes in a component consistently break other areas of the project.; * Components go broken for long periods of time (weeks or more).; * Clearly superior alternatives are in use and maintenance is painful.; * Builds and tests are harder / take longer, increasing the cost of; maintenance, overtaking the perceived benefits. If the maintenance cost is higher than it is acceptable by the majority of; developers, it means that either the sub-community is too small (and the extra; cost should be paid locally), or not active enough (and the problems won't be; fixed any time soon). In either case, removal of such problematic component is; justified. Steps for removal; -----------------. However clear the needs for removal are, we should take an incremental approach; to deprecating code, especially when there's still a sub-community that cares; about it. In that sense, code will never be removed outright without a series; of steps are taken. A minimum set of steps should be:; #. A proposal for removal / deactivation should be made to the Discourse forums ; (under the appropriate category), with a clear; statement of the maintenance costs imposed and the alternatives, if; applicable.; #. There must be enough consensus on the list that removal is warrante",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:8767,Availability,mainten,maintenance,8767,"=====. The LLVM code base has a number of files that aren't being actively maintained.; But not all of those files are obstructing the development of the project and; so it remains in the repository with the assumption that it could still be; useful for downstream users. For code to remain in the repository, its presence must not impose an undue; burden on maintaining other components (core or peripheral). Warnings; --------. There are multiple types of issues that might trigger a request for deprecation,; including (but not limited to):. * Changes in a component consistently break other areas of the project.; * Components go broken for long periods of time (weeks or more).; * Clearly superior alternatives are in use and maintenance is painful.; * Builds and tests are harder / take longer, increasing the cost of; maintenance, overtaking the perceived benefits. If the maintenance cost is higher than it is acceptable by the majority of; developers, it means that either the sub-community is too small (and the extra; cost should be paid locally), or not active enough (and the problems won't be; fixed any time soon). In either case, removal of such problematic component is; justified. Steps for removal; -----------------. However clear the needs for removal are, we should take an incremental approach; to deprecating code, especially when there's still a sub-community that cares; about it. In that sense, code will never be removed outright without a series; of steps are taken. A minimum set of steps should be:; #. A proposal for removal / deactivation should be made to the Discourse forums ; (under the appropriate category), with a clear; statement of the maintenance costs imposed and the alternatives, if; applicable.; #. There must be enough consensus on the list that removal is warranted, and no; pending proposals to fix the situation from a sub-community.; #. An announcement for removal must be made on the same lists, with ample time; for downstream users to take action",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:9565,Availability,mainten,maintenance,9565,"ken for long periods of time (weeks or more).; * Clearly superior alternatives are in use and maintenance is painful.; * Builds and tests are harder / take longer, increasing the cost of; maintenance, overtaking the perceived benefits. If the maintenance cost is higher than it is acceptable by the majority of; developers, it means that either the sub-community is too small (and the extra; cost should be paid locally), or not active enough (and the problems won't be; fixed any time soon). In either case, removal of such problematic component is; justified. Steps for removal; -----------------. However clear the needs for removal are, we should take an incremental approach; to deprecating code, especially when there's still a sub-community that cares; about it. In that sense, code will never be removed outright without a series; of steps are taken. A minimum set of steps should be:; #. A proposal for removal / deactivation should be made to the Discourse forums ; (under the appropriate category), with a clear; statement of the maintenance costs imposed and the alternatives, if; applicable.; #. There must be enough consensus on the list that removal is warranted, and no; pending proposals to fix the situation from a sub-community.; #. An announcement for removal must be made on the same lists, with ample time; for downstream users to take action on their local infrastructure. The time; will depend on what is being removed. #. If a script or documents are to be removed, they can always be pulled; from previous revision, and can be removed within days.; #. if a whole target is removed, we need to first announce publicly, and; potentially mark as deprecated in one release, only to remove on the; next release.; #. Everything else will fall in between those two extremes.; #. The removal is made by either the proposer or the sub-community that used to; maintain it, with replacements and arrangements made atomically on the same; commit. If a proposal for removal is delayed by",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:9857,Availability,down,downstream,9857," it means that either the sub-community is too small (and the extra; cost should be paid locally), or not active enough (and the problems won't be; fixed any time soon). In either case, removal of such problematic component is; justified. Steps for removal; -----------------. However clear the needs for removal are, we should take an incremental approach; to deprecating code, especially when there's still a sub-community that cares; about it. In that sense, code will never be removed outright without a series; of steps are taken. A minimum set of steps should be:; #. A proposal for removal / deactivation should be made to the Discourse forums ; (under the appropriate category), with a clear; statement of the maintenance costs imposed and the alternatives, if; applicable.; #. There must be enough consensus on the list that removal is warranted, and no; pending proposals to fix the situation from a sub-community.; #. An announcement for removal must be made on the same lists, with ample time; for downstream users to take action on their local infrastructure. The time; will depend on what is being removed. #. If a script or documents are to be removed, they can always be pulled; from previous revision, and can be removed within days.; #. if a whole target is removed, we need to first announce publicly, and; potentially mark as deprecated in one release, only to remove on the; next release.; #. Everything else will fall in between those two extremes.; #. The removal is made by either the proposer or the sub-community that used to; maintain it, with replacements and arrangements made atomically on the same; commit. If a proposal for removal is delayed by the promise a sub-community will take; care of the code affected, the sub-community will have a time to fix all the; issues (depending on each case, as above), and if those are not fixed in time, a; subsequent request for removal should be made and the community may elect to; eject the component without further attempts ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:11184,Availability,mainten,maintenance,11184,"hould be:; #. A proposal for removal / deactivation should be made to the Discourse forums ; (under the appropriate category), with a clear; statement of the maintenance costs imposed and the alternatives, if; applicable.; #. There must be enough consensus on the list that removal is warranted, and no; pending proposals to fix the situation from a sub-community.; #. An announcement for removal must be made on the same lists, with ample time; for downstream users to take action on their local infrastructure. The time; will depend on what is being removed. #. If a script or documents are to be removed, they can always be pulled; from previous revision, and can be removed within days.; #. if a whole target is removed, we need to first announce publicly, and; potentially mark as deprecated in one release, only to remove on the; next release.; #. Everything else will fall in between those two extremes.; #. The removal is made by either the proposer or the sub-community that used to; maintain it, with replacements and arrangements made atomically on the same; commit. If a proposal for removal is delayed by the promise a sub-community will take; care of the code affected, the sub-community will have a time to fix all the; issues (depending on each case, as above), and if those are not fixed in time, a; subsequent request for removal should be made and the community may elect to; eject the component without further attempts to fix. Reinstatement; -------------. If a component is removed from LLVM, it may, at a later date, request inclusion; of a modified version, with evidence that all of the issues were fixed and that; there is a clear sub-community that will maintain it. By consequence, the pressure on such sub-community will be higher to keep; overall maintenance costs to a minimum and will need to show steps to mitigate; all of the issues that were listed as reasons for its original removal. Failing on those again, will lead to become a candidate for removal yet again. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:514,Deployability,release,release,514,"=============================; LLVM Community Support Policy; =============================. As a compilation infrastructure, LLVM has multiple types of users, both; downstream and upstream, of many combinations of its projects, tools and; libraries. There is a core part of it that encompass the implementation of the compiler; (front/middle/back ends), run-time libraries (RT, C++, OpenMP, etc) and; associated tools (debugger, linker, object file manipulation, etc). These; components are present in the public release on our supported architectures; and operating systems and the whole community must maintain and care about. There are, however, other components within the main repository that either; cater to a specific sub-community of LLVM (upstream or downstream) or; help parts of the community to integrate LLVM into their own development tools; or external projects. Those parts of the main repository don't always have; rigorous testing like the core parts, nor are they validated and shipped with; our public upstream releases. Even not being a core part of the project, we have enough sub-communities; needing those changes with enough overlap that having them in the main; repository is beneficial to minimise the repetition of those changes in all; the external repositories that need them. But the maintenance costs of such diverse ecosystem is non trivial, so we divide; the level of support in two tiers: core and peripheral, with two; different levels of impact and responsibilities. Those tiers refer only to the; main repository (``llvm-project``) and not the other repositories in our git; project, unless explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libra",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:809,Deployability,integrat,integrate,809,"=============================; LLVM Community Support Policy; =============================. As a compilation infrastructure, LLVM has multiple types of users, both; downstream and upstream, of many combinations of its projects, tools and; libraries. There is a core part of it that encompass the implementation of the compiler; (front/middle/back ends), run-time libraries (RT, C++, OpenMP, etc) and; associated tools (debugger, linker, object file manipulation, etc). These; components are present in the public release on our supported architectures; and operating systems and the whole community must maintain and care about. There are, however, other components within the main repository that either; cater to a specific sub-community of LLVM (upstream or downstream) or; help parts of the community to integrate LLVM into their own development tools; or external projects. Those parts of the main repository don't always have; rigorous testing like the core parts, nor are they validated and shipped with; our public upstream releases. Even not being a core part of the project, we have enough sub-communities; needing those changes with enough overlap that having them in the main; repository is beneficial to minimise the repetition of those changes in all; the external repositories that need them. But the maintenance costs of such diverse ecosystem is non trivial, so we divide; the level of support in two tiers: core and peripheral, with two; different levels of impact and responsibilities. Those tiers refer only to the; main repository (``llvm-project``) and not the other repositories in our git; project, unless explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libra",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:1033,Deployability,release,releases,1033,"=============================; LLVM Community Support Policy; =============================. As a compilation infrastructure, LLVM has multiple types of users, both; downstream and upstream, of many combinations of its projects, tools and; libraries. There is a core part of it that encompass the implementation of the compiler; (front/middle/back ends), run-time libraries (RT, C++, OpenMP, etc) and; associated tools (debugger, linker, object file manipulation, etc). These; components are present in the public release on our supported architectures; and operating systems and the whole community must maintain and care about. There are, however, other components within the main repository that either; cater to a specific sub-community of LLVM (upstream or downstream) or; help parts of the community to integrate LLVM into their own development tools; or external projects. Those parts of the main repository don't always have; rigorous testing like the core parts, nor are they validated and shipped with; our public upstream releases. Even not being a core part of the project, we have enough sub-communities; needing those changes with enough overlap that having them in the main; repository is beneficial to minimise the repetition of those changes in all; the external repositories that need them. But the maintenance costs of such diverse ecosystem is non trivial, so we divide; the level of support in two tiers: core and peripheral, with two; different levels of impact and responsibilities. Those tiers refer only to the; main repository (``llvm-project``) and not the other repositories in our git; project, unless explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libra",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:1885,Deployability,release,released,1885,"the main repository don't always have; rigorous testing like the core parts, nor are they validated and shipped with; our public upstream releases. Even not being a core part of the project, we have enough sub-communities; needing those changes with enough overlap that having them in the main; repository is beneficial to minimise the repetition of those changes in all; the external repositories that need them. But the maintenance costs of such diverse ecosystem is non trivial, so we divide; the level of support in two tiers: core and peripheral, with two; different levels of impact and responsibilities. Those tiers refer only to the; main repository (``llvm-project``) and not the other repositories in our git; project, unless explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libraries,; tools, etc. It is the responsibility of **every** LLVM developer to care for the core tier; regardless of where their work is applied to. What is covered; ---------------. The core tier is composed of:; * Core code (``llvm-project``) present in official releases and buildbots:; compiler, debugger, linker, libraries, etc, including infrastructure code; (table-gen, lit, file-check, unit-tests, etc).; * Build infrastructure that creates releases and buildbots (CMake, scripts).; * `Phabricator <https://github.com/llvm/phabricator>`_ and; `buildbot <https://github.com/llvm/llvm-zorg>`_ infrastructure.; * The `test-suite <https://github.com/llvm/llvm-test-suite>`_. Requirements; ------------. Code in this tier must:; * Keep official buildbots green, with warnings on breakages being emailed to; all affected developers. Those must be fixed as soon as possible or patches; must be reve",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:2262,Deployability,release,releases,2262,"that need them. But the maintenance costs of such diverse ecosystem is non trivial, so we divide; the level of support in two tiers: core and peripheral, with two; different levels of impact and responsibilities. Those tiers refer only to the; main repository (``llvm-project``) and not the other repositories in our git; project, unless explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libraries,; tools, etc. It is the responsibility of **every** LLVM developer to care for the core tier; regardless of where their work is applied to. What is covered; ---------------. The core tier is composed of:; * Core code (``llvm-project``) present in official releases and buildbots:; compiler, debugger, linker, libraries, etc, including infrastructure code; (table-gen, lit, file-check, unit-tests, etc).; * Build infrastructure that creates releases and buildbots (CMake, scripts).; * `Phabricator <https://github.com/llvm/phabricator>`_ and; `buildbot <https://github.com/llvm/llvm-zorg>`_ infrastructure.; * The `test-suite <https://github.com/llvm/llvm-test-suite>`_. Requirements; ------------. Code in this tier must:; * Keep official buildbots green, with warnings on breakages being emailed to; all affected developers. Those must be fixed as soon as possible or patches; must be reverted, as per review policy.; * Bit-rot of a component in the core tier will result in that component being; downgraded to the peripheral tier or being removed. Sub-communities can; avoid this by fixing all raised issues in a timely manner. Peripheral Tier; ===============. The peripheral tier encompass the parts of LLVM that cater to a specific; sub-community and which don't usually affect the c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:2446,Deployability,release,releases,2446,"with two; different levels of impact and responsibilities. Those tiers refer only to the; main repository (``llvm-project``) and not the other repositories in our git; project, unless explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libraries,; tools, etc. It is the responsibility of **every** LLVM developer to care for the core tier; regardless of where their work is applied to. What is covered; ---------------. The core tier is composed of:; * Core code (``llvm-project``) present in official releases and buildbots:; compiler, debugger, linker, libraries, etc, including infrastructure code; (table-gen, lit, file-check, unit-tests, etc).; * Build infrastructure that creates releases and buildbots (CMake, scripts).; * `Phabricator <https://github.com/llvm/phabricator>`_ and; `buildbot <https://github.com/llvm/llvm-zorg>`_ infrastructure.; * The `test-suite <https://github.com/llvm/llvm-test-suite>`_. Requirements; ------------. Code in this tier must:; * Keep official buildbots green, with warnings on breakages being emailed to; all affected developers. Those must be fixed as soon as possible or patches; must be reverted, as per review policy.; * Bit-rot of a component in the core tier will result in that component being; downgraded to the peripheral tier or being removed. Sub-communities can; avoid this by fixing all raised issues in a timely manner. Peripheral Tier; ===============. The peripheral tier encompass the parts of LLVM that cater to a specific; sub-community and which don't usually affect the core components directly. This includes experimental back-ends, disabled-by-default options and; alternative paths (work-in-progress replacements) in the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:2875,Deployability,patch,patches,2875,"ted and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libraries,; tools, etc. It is the responsibility of **every** LLVM developer to care for the core tier; regardless of where their work is applied to. What is covered; ---------------. The core tier is composed of:; * Core code (``llvm-project``) present in official releases and buildbots:; compiler, debugger, linker, libraries, etc, including infrastructure code; (table-gen, lit, file-check, unit-tests, etc).; * Build infrastructure that creates releases and buildbots (CMake, scripts).; * `Phabricator <https://github.com/llvm/phabricator>`_ and; `buildbot <https://github.com/llvm/llvm-zorg>`_ infrastructure.; * The `test-suite <https://github.com/llvm/llvm-test-suite>`_. Requirements; ------------. Code in this tier must:; * Keep official buildbots green, with warnings on breakages being emailed to; all affected developers. Those must be fixed as soon as possible or patches; must be reverted, as per review policy.; * Bit-rot of a component in the core tier will result in that component being; downgraded to the peripheral tier or being removed. Sub-communities can; avoid this by fixing all raised issues in a timely manner. Peripheral Tier; ===============. The peripheral tier encompass the parts of LLVM that cater to a specific; sub-community and which don't usually affect the core components directly. This includes experimental back-ends, disabled-by-default options and; alternative paths (work-in-progress replacements) in the same repository, as; well as separate efforts to integrate LLVM development with local practices. It is the responsibility of each sub-community to care about their own parts; and the intersection of that with the core tier and other peripheral parts. There are three main groups of code that fit in this category:; * Code that is making its way into LLVM, via the `experimental <https://llvm.org/docs/DeveloperPolicy.html#introdu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:3496,Deployability,integrat,integrate,3496,"e that creates releases and buildbots (CMake, scripts).; * `Phabricator <https://github.com/llvm/phabricator>`_ and; `buildbot <https://github.com/llvm/llvm-zorg>`_ infrastructure.; * The `test-suite <https://github.com/llvm/llvm-test-suite>`_. Requirements; ------------. Code in this tier must:; * Keep official buildbots green, with warnings on breakages being emailed to; all affected developers. Those must be fixed as soon as possible or patches; must be reverted, as per review policy.; * Bit-rot of a component in the core tier will result in that component being; downgraded to the peripheral tier or being removed. Sub-communities can; avoid this by fixing all raised issues in a timely manner. Peripheral Tier; ===============. The peripheral tier encompass the parts of LLVM that cater to a specific; sub-community and which don't usually affect the core components directly. This includes experimental back-ends, disabled-by-default options and; alternative paths (work-in-progress replacements) in the same repository, as; well as separate efforts to integrate LLVM development with local practices. It is the responsibility of each sub-community to care about their own parts; and the intersection of that with the core tier and other peripheral parts. There are three main groups of code that fit in this category:; * Code that is making its way into LLVM, via the `experimental <https://llvm.org/docs/DeveloperPolicy.html#introducing-new-components-into-llvm>`_; roadmap or similar efforts.; * Code that is making its way out of LLVM, via deprecation, replacement or; bit-rot, and will be removed if the sub-community that cares about it; cannot maintain it.; * Code that isn't meant to be in LLVM core and can coexist with the code in; the core tier (and others in the peripheral tier) long term, without causing; breakages or disturbances. What is covered; ---------------. The peripheral tier is composed of:; * Experimental targets and options that haven't been enable by default",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:4480,Deployability,release,released,4480," as separate efforts to integrate LLVM development with local practices. It is the responsibility of each sub-community to care about their own parts; and the intersection of that with the core tier and other peripheral parts. There are three main groups of code that fit in this category:; * Code that is making its way into LLVM, via the `experimental <https://llvm.org/docs/DeveloperPolicy.html#introducing-new-components-into-llvm>`_; roadmap or similar efforts.; * Code that is making its way out of LLVM, via deprecation, replacement or; bit-rot, and will be removed if the sub-community that cares about it; cannot maintain it.; * Code that isn't meant to be in LLVM core and can coexist with the code in; the core tier (and others in the peripheral tier) long term, without causing; breakages or disturbances. What is covered; ---------------. The peripheral tier is composed of:; * Experimental targets and options that haven't been enable by default yet.; * Main repository projects that don't get released or regularly tested.; * Legacy tools and scripts that aren't used in upstream validation.; * Alternative build systems (ex. GN, Bazel) and related infrastructure.; * Tools support (ex. gdb scripts, editor configuration, helper scripts). Requirements; ------------. Code in this tier must:; * Have a clear benefit for residing in the main repository, catering to an; active sub-community (upstream or downstream).; * Be actively maintained by such sub-community and have its problems addressed; in a timely manner. Code in this tier must **not**:; * Break or invalidate core tier code or infrastructure. If that happens; accidentally, reverting functionality and working on the issues offline; is the only acceptable course of action.; * Negatively affect development of core tier code, with the sub-community; involved responsible for making changes to address specific concerns.; * Negatively affect other peripheral tier code, with the sub-communities; involved tasked to resolve th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:4694,Deployability,configurat,configuration,4694,"There are three main groups of code that fit in this category:; * Code that is making its way into LLVM, via the `experimental <https://llvm.org/docs/DeveloperPolicy.html#introducing-new-components-into-llvm>`_; roadmap or similar efforts.; * Code that is making its way out of LLVM, via deprecation, replacement or; bit-rot, and will be removed if the sub-community that cares about it; cannot maintain it.; * Code that isn't meant to be in LLVM core and can coexist with the code in; the core tier (and others in the peripheral tier) long term, without causing; breakages or disturbances. What is covered; ---------------. The peripheral tier is composed of:; * Experimental targets and options that haven't been enable by default yet.; * Main repository projects that don't get released or regularly tested.; * Legacy tools and scripts that aren't used in upstream validation.; * Alternative build systems (ex. GN, Bazel) and related infrastructure.; * Tools support (ex. gdb scripts, editor configuration, helper scripts). Requirements; ------------. Code in this tier must:; * Have a clear benefit for residing in the main repository, catering to an; active sub-community (upstream or downstream).; * Be actively maintained by such sub-community and have its problems addressed; in a timely manner. Code in this tier must **not**:; * Break or invalidate core tier code or infrastructure. If that happens; accidentally, reverting functionality and working on the issues offline; is the only acceptable course of action.; * Negatively affect development of core tier code, with the sub-community; involved responsible for making changes to address specific concerns.; * Negatively affect other peripheral tier code, with the sub-communities; involved tasked to resolve the issues, still making sure the solution doesn't; break or invalidate the core tier.; * Impose sub-optimal implementation strategies on core tier components as a; result of idiosyncrasies in the peripheral component.; * Have b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:7431,Deployability,patch,patches,7431,"us of implementation, level of support; available, who the sub-community is and, if applicable, roadmap for inclusion; into the core tier.; * Be restricted to a specific directory or have a consistent pattern (ex.; unique file suffix), making it easy to remove when necessary. Inclusion Policy; ================. To add a new peripheral component, send an RFC to the appropriate dev list; proposing its addition and explaining how it will meet the support requirements; listed above. Different types of components could require different levels of; detail. when in doubt, ask the community what's the best approach. Inclusion must reach consensus in the RFC by the community and the approval of; the corresponding review (by multiple members of the community) is the official; note of acceptance. After merge, there often is a period of transition, where teething issues on; existing buildbots are discovered and fixed. If those cannot be fixed straight; away, the sub-community is responsible for tracking and reverting all the; pertinent patches and retrying the inclusion review. Once the component is stable in tree, it must follow this policy and the; deprecation rules below apply. Due to the uncertain nature of inclusion, it's advisable that new components; are not added too close to a release branch. The time will depend on the size; and complexity of the component, so adding release and testing managers on the; RFC and review is strongly advisable. Deprecation Policy; ==================. The LLVM code base has a number of files that aren't being actively maintained.; But not all of those files are obstructing the development of the project and; so it remains in the repository with the assumption that it could still be; useful for downstream users. For code to remain in the repository, its presence must not impose an undue; burden on maintaining other components (core or peripheral). Warnings; --------. There are multiple types of issues that might trigger a request for depreca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:7686,Deployability,release,release,7686,"sy to remove when necessary. Inclusion Policy; ================. To add a new peripheral component, send an RFC to the appropriate dev list; proposing its addition and explaining how it will meet the support requirements; listed above. Different types of components could require different levels of; detail. when in doubt, ask the community what's the best approach. Inclusion must reach consensus in the RFC by the community and the approval of; the corresponding review (by multiple members of the community) is the official; note of acceptance. After merge, there often is a period of transition, where teething issues on; existing buildbots are discovered and fixed. If those cannot be fixed straight; away, the sub-community is responsible for tracking and reverting all the; pertinent patches and retrying the inclusion review. Once the component is stable in tree, it must follow this policy and the; deprecation rules below apply. Due to the uncertain nature of inclusion, it's advisable that new components; are not added too close to a release branch. The time will depend on the size; and complexity of the component, so adding release and testing managers on the; RFC and review is strongly advisable. Deprecation Policy; ==================. The LLVM code base has a number of files that aren't being actively maintained.; But not all of those files are obstructing the development of the project and; so it remains in the repository with the assumption that it could still be; useful for downstream users. For code to remain in the repository, its presence must not impose an undue; burden on maintaining other components (core or peripheral). Warnings; --------. There are multiple types of issues that might trigger a request for deprecation,; including (but not limited to):. * Changes in a component consistently break other areas of the project.; * Components go broken for long periods of time (weeks or more).; * Clearly superior alternatives are in use and maintenance is painful",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:7779,Deployability,release,release,7779,"t; proposing its addition and explaining how it will meet the support requirements; listed above. Different types of components could require different levels of; detail. when in doubt, ask the community what's the best approach. Inclusion must reach consensus in the RFC by the community and the approval of; the corresponding review (by multiple members of the community) is the official; note of acceptance. After merge, there often is a period of transition, where teething issues on; existing buildbots are discovered and fixed. If those cannot be fixed straight; away, the sub-community is responsible for tracking and reverting all the; pertinent patches and retrying the inclusion review. Once the component is stable in tree, it must follow this policy and the; deprecation rules below apply. Due to the uncertain nature of inclusion, it's advisable that new components; are not added too close to a release branch. The time will depend on the size; and complexity of the component, so adding release and testing managers on the; RFC and review is strongly advisable. Deprecation Policy; ==================. The LLVM code base has a number of files that aren't being actively maintained.; But not all of those files are obstructing the development of the project and; so it remains in the repository with the assumption that it could still be; useful for downstream users. For code to remain in the repository, its presence must not impose an undue; burden on maintaining other components (core or peripheral). Warnings; --------. There are multiple types of issues that might trigger a request for deprecation,; including (but not limited to):. * Changes in a component consistently break other areas of the project.; * Components go broken for long periods of time (weeks or more).; * Clearly superior alternatives are in use and maintenance is painful.; * Builds and tests are harder / take longer, increasing the cost of; maintenance, overtaking the perceived benefits. If the maintenanc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:10211,Deployability,release,release,10211,"e an incremental approach; to deprecating code, especially when there's still a sub-community that cares; about it. In that sense, code will never be removed outright without a series; of steps are taken. A minimum set of steps should be:; #. A proposal for removal / deactivation should be made to the Discourse forums ; (under the appropriate category), with a clear; statement of the maintenance costs imposed and the alternatives, if; applicable.; #. There must be enough consensus on the list that removal is warranted, and no; pending proposals to fix the situation from a sub-community.; #. An announcement for removal must be made on the same lists, with ample time; for downstream users to take action on their local infrastructure. The time; will depend on what is being removed. #. If a script or documents are to be removed, they can always be pulled; from previous revision, and can be removed within days.; #. if a whole target is removed, we need to first announce publicly, and; potentially mark as deprecated in one release, only to remove on the; next release.; #. Everything else will fall in between those two extremes.; #. The removal is made by either the proposer or the sub-community that used to; maintain it, with replacements and arrangements made atomically on the same; commit. If a proposal for removal is delayed by the promise a sub-community will take; care of the code affected, the sub-community will have a time to fix all the; issues (depending on each case, as above), and if those are not fixed in time, a; subsequent request for removal should be made and the community may elect to; eject the component without further attempts to fix. Reinstatement; -------------. If a component is removed from LLVM, it may, at a later date, request inclusion; of a modified version, with evidence that all of the issues were fixed and that; there is a clear sub-community that will maintain it. By consequence, the pressure on such sub-community will be higher to keep; ove",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:10248,Deployability,release,release,10248,"e an incremental approach; to deprecating code, especially when there's still a sub-community that cares; about it. In that sense, code will never be removed outright without a series; of steps are taken. A minimum set of steps should be:; #. A proposal for removal / deactivation should be made to the Discourse forums ; (under the appropriate category), with a clear; statement of the maintenance costs imposed and the alternatives, if; applicable.; #. There must be enough consensus on the list that removal is warranted, and no; pending proposals to fix the situation from a sub-community.; #. An announcement for removal must be made on the same lists, with ample time; for downstream users to take action on their local infrastructure. The time; will depend on what is being removed. #. If a script or documents are to be removed, they can always be pulled; from previous revision, and can be removed within days.; #. if a whole target is removed, we need to first announce publicly, and; potentially mark as deprecated in one release, only to remove on the; next release.; #. Everything else will fall in between those two extremes.; #. The removal is made by either the proposer or the sub-community that used to; maintain it, with replacements and arrangements made atomically on the same; commit. If a proposal for removal is delayed by the promise a sub-community will take; care of the code affected, the sub-community will have a time to fix all the; issues (depending on each case, as above), and if those are not fixed in time, a; subsequent request for removal should be made and the community may elect to; eject the component without further attempts to fix. Reinstatement; -------------. If a component is removed from LLVM, it may, at a later date, request inclusion; of a modified version, with evidence that all of the issues were fixed and that; there is a clear sub-community that will maintain it. By consequence, the pressure on such sub-community will be higher to keep; ove",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:1907,Energy Efficiency,schedul,schedule,1907,"the main repository don't always have; rigorous testing like the core parts, nor are they validated and shipped with; our public upstream releases. Even not being a core part of the project, we have enough sub-communities; needing those changes with enough overlap that having them in the main; repository is beneficial to minimise the repetition of those changes in all; the external repositories that need them. But the maintenance costs of such diverse ecosystem is non trivial, so we divide; the level of support in two tiers: core and peripheral, with two; different levels of impact and responsibilities. Those tiers refer only to the; main repository (``llvm-project``) and not the other repositories in our git; project, unless explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libraries,; tools, etc. It is the responsibility of **every** LLVM developer to care for the core tier; regardless of where their work is applied to. What is covered; ---------------. The core tier is composed of:; * Core code (``llvm-project``) present in official releases and buildbots:; compiler, debugger, linker, libraries, etc, including infrastructure code; (table-gen, lit, file-check, unit-tests, etc).; * Build infrastructure that creates releases and buildbots (CMake, scripts).; * `Phabricator <https://github.com/llvm/phabricator>`_ and; `buildbot <https://github.com/llvm/llvm-zorg>`_ infrastructure.; * The `test-suite <https://github.com/llvm/llvm-test-suite>`_. Requirements; ------------. Code in this tier must:; * Keep official buildbots green, with warnings on breakages being emailed to; all affected developers. Those must be fixed as soon as possible or patches; must be reve",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:2755,Energy Efficiency,green,green,2755,"====. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libraries,; tools, etc. It is the responsibility of **every** LLVM developer to care for the core tier; regardless of where their work is applied to. What is covered; ---------------. The core tier is composed of:; * Core code (``llvm-project``) present in official releases and buildbots:; compiler, debugger, linker, libraries, etc, including infrastructure code; (table-gen, lit, file-check, unit-tests, etc).; * Build infrastructure that creates releases and buildbots (CMake, scripts).; * `Phabricator <https://github.com/llvm/phabricator>`_ and; `buildbot <https://github.com/llvm/llvm-zorg>`_ infrastructure.; * The `test-suite <https://github.com/llvm/llvm-test-suite>`_. Requirements; ------------. Code in this tier must:; * Keep official buildbots green, with warnings on breakages being emailed to; all affected developers. Those must be fixed as soon as possible or patches; must be reverted, as per review policy.; * Bit-rot of a component in the core tier will result in that component being; downgraded to the peripheral tier or being removed. Sub-communities can; avoid this by fixing all raised issues in a timely manner. Peripheral Tier; ===============. The peripheral tier encompass the parts of LLVM that cater to a specific; sub-community and which don't usually affect the core components directly. This includes experimental back-ends, disabled-by-default options and; alternative paths (work-in-progress replacements) in the same repository, as; well as separate efforts to integrate LLVM development with local practices. It is the responsibility of each sub-community to care about their own parts; and the intersection of that with the core tier and other peripheral parts. There are three main groups of code that fit in this category:; * Co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:809,Integrability,integrat,integrate,809,"=============================; LLVM Community Support Policy; =============================. As a compilation infrastructure, LLVM has multiple types of users, both; downstream and upstream, of many combinations of its projects, tools and; libraries. There is a core part of it that encompass the implementation of the compiler; (front/middle/back ends), run-time libraries (RT, C++, OpenMP, etc) and; associated tools (debugger, linker, object file manipulation, etc). These; components are present in the public release on our supported architectures; and operating systems and the whole community must maintain and care about. There are, however, other components within the main repository that either; cater to a specific sub-community of LLVM (upstream or downstream) or; help parts of the community to integrate LLVM into their own development tools; or external projects. Those parts of the main repository don't always have; rigorous testing like the core parts, nor are they validated and shipped with; our public upstream releases. Even not being a core part of the project, we have enough sub-communities; needing those changes with enough overlap that having them in the main; repository is beneficial to minimise the repetition of those changes in all; the external repositories that need them. But the maintenance costs of such diverse ecosystem is non trivial, so we divide; the level of support in two tiers: core and peripheral, with two; different levels of impact and responsibilities. Those tiers refer only to the; main repository (``llvm-project``) and not the other repositories in our git; project, unless explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libra",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:3496,Integrability,integrat,integrate,3496,"e that creates releases and buildbots (CMake, scripts).; * `Phabricator <https://github.com/llvm/phabricator>`_ and; `buildbot <https://github.com/llvm/llvm-zorg>`_ infrastructure.; * The `test-suite <https://github.com/llvm/llvm-test-suite>`_. Requirements; ------------. Code in this tier must:; * Keep official buildbots green, with warnings on breakages being emailed to; all affected developers. Those must be fixed as soon as possible or patches; must be reverted, as per review policy.; * Bit-rot of a component in the core tier will result in that component being; downgraded to the peripheral tier or being removed. Sub-communities can; avoid this by fixing all raised issues in a timely manner. Peripheral Tier; ===============. The peripheral tier encompass the parts of LLVM that cater to a specific; sub-community and which don't usually affect the core components directly. This includes experimental back-ends, disabled-by-default options and; alternative paths (work-in-progress replacements) in the same repository, as; well as separate efforts to integrate LLVM development with local practices. It is the responsibility of each sub-community to care about their own parts; and the intersection of that with the core tier and other peripheral parts. There are three main groups of code that fit in this category:; * Code that is making its way into LLVM, via the `experimental <https://llvm.org/docs/DeveloperPolicy.html#introducing-new-components-into-llvm>`_; roadmap or similar efforts.; * Code that is making its way out of LLVM, via deprecation, replacement or; bit-rot, and will be removed if the sub-community that cares about it; cannot maintain it.; * Code that isn't meant to be in LLVM core and can coexist with the code in; the core tier (and others in the peripheral tier) long term, without causing; breakages or disturbances. What is covered; ---------------. The peripheral tier is composed of:; * Experimental targets and options that haven't been enable by default",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:7716,Integrability,depend,depend,7716,"t; proposing its addition and explaining how it will meet the support requirements; listed above. Different types of components could require different levels of; detail. when in doubt, ask the community what's the best approach. Inclusion must reach consensus in the RFC by the community and the approval of; the corresponding review (by multiple members of the community) is the official; note of acceptance. After merge, there often is a period of transition, where teething issues on; existing buildbots are discovered and fixed. If those cannot be fixed straight; away, the sub-community is responsible for tracking and reverting all the; pertinent patches and retrying the inclusion review. Once the component is stable in tree, it must follow this policy and the; deprecation rules below apply. Due to the uncertain nature of inclusion, it's advisable that new components; are not added too close to a release branch. The time will depend on the size; and complexity of the component, so adding release and testing managers on the; RFC and review is strongly advisable. Deprecation Policy; ==================. The LLVM code base has a number of files that aren't being actively maintained.; But not all of those files are obstructing the development of the project and; so it remains in the repository with the assumption that it could still be; useful for downstream users. For code to remain in the repository, its presence must not impose an undue; burden on maintaining other components (core or peripheral). Warnings; --------. There are multiple types of issues that might trigger a request for deprecation,; including (but not limited to):. * Changes in a component consistently break other areas of the project.; * Components go broken for long periods of time (weeks or more).; * Clearly superior alternatives are in use and maintenance is painful.; * Builds and tests are harder / take longer, increasing the cost of; maintenance, overtaking the perceived benefits. If the maintenanc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:9935,Integrability,depend,depend,9935,"), or not active enough (and the problems won't be; fixed any time soon). In either case, removal of such problematic component is; justified. Steps for removal; -----------------. However clear the needs for removal are, we should take an incremental approach; to deprecating code, especially when there's still a sub-community that cares; about it. In that sense, code will never be removed outright without a series; of steps are taken. A minimum set of steps should be:; #. A proposal for removal / deactivation should be made to the Discourse forums ; (under the appropriate category), with a clear; statement of the maintenance costs imposed and the alternatives, if; applicable.; #. There must be enough consensus on the list that removal is warranted, and no; pending proposals to fix the situation from a sub-community.; #. An announcement for removal must be made on the same lists, with ample time; for downstream users to take action on their local infrastructure. The time; will depend on what is being removed. #. If a script or documents are to be removed, they can always be pulled; from previous revision, and can be removed within days.; #. if a whole target is removed, we need to first announce publicly, and; potentially mark as deprecated in one release, only to remove on the; next release.; #. Everything else will fall in between those two extremes.; #. The removal is made by either the proposer or the sub-community that used to; maintain it, with replacements and arrangements made atomically on the same; commit. If a proposal for removal is delayed by the promise a sub-community will take; care of the code affected, the sub-community will have a time to fix all the; issues (depending on each case, as above), and if those are not fixed in time, a; subsequent request for removal should be made and the community may elect to; eject the component without further attempts to fix. Reinstatement; -------------. If a component is removed from LLVM, it may, at a later da",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:10650,Integrability,depend,depending,10650,"hould be:; #. A proposal for removal / deactivation should be made to the Discourse forums ; (under the appropriate category), with a clear; statement of the maintenance costs imposed and the alternatives, if; applicable.; #. There must be enough consensus on the list that removal is warranted, and no; pending proposals to fix the situation from a sub-community.; #. An announcement for removal must be made on the same lists, with ample time; for downstream users to take action on their local infrastructure. The time; will depend on what is being removed. #. If a script or documents are to be removed, they can always be pulled; from previous revision, and can be removed within days.; #. if a whole target is removed, we need to first announce publicly, and; potentially mark as deprecated in one release, only to remove on the; next release.; #. Everything else will fall in between those two extremes.; #. The removal is made by either the proposer or the sub-community that used to; maintain it, with replacements and arrangements made atomically on the same; commit. If a proposal for removal is delayed by the promise a sub-community will take; care of the code affected, the sub-community will have a time to fix all the; issues (depending on each case, as above), and if those are not fixed in time, a; subsequent request for removal should be made and the community may elect to; eject the component without further attempts to fix. Reinstatement; -------------. If a component is removed from LLVM, it may, at a later date, request inclusion; of a modified version, with evidence that all of the issues were fixed and that; there is a clear sub-community that will maintain it. By consequence, the pressure on such sub-community will be higher to keep; overall maintenance costs to a minimum and will need to show steps to mitigate; all of the issues that were listed as reasons for its original removal. Failing on those again, will lead to become a candidate for removal yet again. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:4694,Modifiability,config,configuration,4694,"There are three main groups of code that fit in this category:; * Code that is making its way into LLVM, via the `experimental <https://llvm.org/docs/DeveloperPolicy.html#introducing-new-components-into-llvm>`_; roadmap or similar efforts.; * Code that is making its way out of LLVM, via deprecation, replacement or; bit-rot, and will be removed if the sub-community that cares about it; cannot maintain it.; * Code that isn't meant to be in LLVM core and can coexist with the code in; the core tier (and others in the peripheral tier) long term, without causing; breakages or disturbances. What is covered; ---------------. The peripheral tier is composed of:; * Experimental targets and options that haven't been enable by default yet.; * Main repository projects that don't get released or regularly tested.; * Legacy tools and scripts that aren't used in upstream validation.; * Alternative build systems (ex. GN, Bazel) and related infrastructure.; * Tools support (ex. gdb scripts, editor configuration, helper scripts). Requirements; ------------. Code in this tier must:; * Have a clear benefit for residing in the main repository, catering to an; active sub-community (upstream or downstream).; * Be actively maintained by such sub-community and have its problems addressed; in a timely manner. Code in this tier must **not**:; * Break or invalidate core tier code or infrastructure. If that happens; accidentally, reverting functionality and working on the issues offline; is the only acceptable course of action.; * Negatively affect development of core tier code, with the sub-community; involved responsible for making changes to address specific concerns.; * Negatively affect other peripheral tier code, with the sub-communities; involved tasked to resolve the issues, still making sure the solution doesn't; break or invalidate the core tier.; * Impose sub-optimal implementation strategies on core tier components as a; result of idiosyncrasies in the peripheral component.; * Have b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:3077,Safety,avoid,avoid,3077,"ier; regardless of where their work is applied to. What is covered; ---------------. The core tier is composed of:; * Core code (``llvm-project``) present in official releases and buildbots:; compiler, debugger, linker, libraries, etc, including infrastructure code; (table-gen, lit, file-check, unit-tests, etc).; * Build infrastructure that creates releases and buildbots (CMake, scripts).; * `Phabricator <https://github.com/llvm/phabricator>`_ and; `buildbot <https://github.com/llvm/llvm-zorg>`_ infrastructure.; * The `test-suite <https://github.com/llvm/llvm-test-suite>`_. Requirements; ------------. Code in this tier must:; * Keep official buildbots green, with warnings on breakages being emailed to; all affected developers. Those must be fixed as soon as possible or patches; must be reverted, as per review policy.; * Bit-rot of a component in the core tier will result in that component being; downgraded to the peripheral tier or being removed. Sub-communities can; avoid this by fixing all raised issues in a timely manner. Peripheral Tier; ===============. The peripheral tier encompass the parts of LLVM that cater to a specific; sub-community and which don't usually affect the core components directly. This includes experimental back-ends, disabled-by-default options and; alternative paths (work-in-progress replacements) in the same repository, as; well as separate efforts to integrate LLVM development with local practices. It is the responsibility of each sub-community to care about their own parts; and the intersection of that with the core tier and other peripheral parts. There are three main groups of code that fit in this category:; * Code that is making its way into LLVM, via the `experimental <https://llvm.org/docs/DeveloperPolicy.html#introducing-new-components-into-llvm>`_; roadmap or similar efforts.; * Code that is making its way out of LLVM, via deprecation, replacement or; bit-rot, and will be removed if the sub-community that cares about it; cannot m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:985,Security,validat,validated,985,"=============================; LLVM Community Support Policy; =============================. As a compilation infrastructure, LLVM has multiple types of users, both; downstream and upstream, of many combinations of its projects, tools and; libraries. There is a core part of it that encompass the implementation of the compiler; (front/middle/back ends), run-time libraries (RT, C++, OpenMP, etc) and; associated tools (debugger, linker, object file manipulation, etc). These; components are present in the public release on our supported architectures; and operating systems and the whole community must maintain and care about. There are, however, other components within the main repository that either; cater to a specific sub-community of LLVM (upstream or downstream) or; help parts of the community to integrate LLVM into their own development tools; or external projects. Those parts of the main repository don't always have; rigorous testing like the core parts, nor are they validated and shipped with; our public upstream releases. Even not being a core part of the project, we have enough sub-communities; needing those changes with enough overlap that having them in the main; repository is beneficial to minimise the repetition of those changes in all; the external repositories that need them. But the maintenance costs of such diverse ecosystem is non trivial, so we divide; the level of support in two tiers: core and peripheral, with two; different levels of impact and responsibilities. Those tiers refer only to the; main repository (``llvm-project``) and not the other repositories in our git; project, unless explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libra",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:4567,Security,validat,validation,4567,". It is the responsibility of each sub-community to care about their own parts; and the intersection of that with the core tier and other peripheral parts. There are three main groups of code that fit in this category:; * Code that is making its way into LLVM, via the `experimental <https://llvm.org/docs/DeveloperPolicy.html#introducing-new-components-into-llvm>`_; roadmap or similar efforts.; * Code that is making its way out of LLVM, via deprecation, replacement or; bit-rot, and will be removed if the sub-community that cares about it; cannot maintain it.; * Code that isn't meant to be in LLVM core and can coexist with the code in; the core tier (and others in the peripheral tier) long term, without causing; breakages or disturbances. What is covered; ---------------. The peripheral tier is composed of:; * Experimental targets and options that haven't been enable by default yet.; * Main repository projects that don't get released or regularly tested.; * Legacy tools and scripts that aren't used in upstream validation.; * Alternative build systems (ex. GN, Bazel) and related infrastructure.; * Tools support (ex. gdb scripts, editor configuration, helper scripts). Requirements; ------------. Code in this tier must:; * Have a clear benefit for residing in the main repository, catering to an; active sub-community (upstream or downstream).; * Be actively maintained by such sub-community and have its problems addressed; in a timely manner. Code in this tier must **not**:; * Break or invalidate core tier code or infrastructure. If that happens; accidentally, reverting functionality and working on the issues offline; is the only acceptable course of action.; * Negatively affect development of core tier code, with the sub-community; involved responsible for making changes to address specific concerns.; * Negatively affect other peripheral tier code, with the sub-communities; involved tasked to resolve the issues, still making sure the solution doesn't; break or invalidate t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:943,Testability,test,testing,943,"=============================; LLVM Community Support Policy; =============================. As a compilation infrastructure, LLVM has multiple types of users, both; downstream and upstream, of many combinations of its projects, tools and; libraries. There is a core part of it that encompass the implementation of the compiler; (front/middle/back ends), run-time libraries (RT, C++, OpenMP, etc) and; associated tools (debugger, linker, object file manipulation, etc). These; components are present in the public release on our supported architectures; and operating systems and the whole community must maintain and care about. There are, however, other components within the main repository that either; cater to a specific sub-community of LLVM (upstream or downstream) or; help parts of the community to integrate LLVM into their own development tools; or external projects. Those parts of the main repository don't always have; rigorous testing like the core parts, nor are they validated and shipped with; our public upstream releases. Even not being a core part of the project, we have enough sub-communities; needing those changes with enough overlap that having them in the main; repository is beneficial to minimise the repetition of those changes in all; the external repositories that need them. But the maintenance costs of such diverse ecosystem is non trivial, so we divide; the level of support in two tiers: core and peripheral, with two; different levels of impact and responsibilities. Those tiers refer only to the; main repository (``llvm-project``) and not the other repositories in our git; project, unless explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libra",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:1874,Testability,test,tested,1874,"the main repository don't always have; rigorous testing like the core parts, nor are they validated and shipped with; our public upstream releases. Even not being a core part of the project, we have enough sub-communities; needing those changes with enough overlap that having them in the main; repository is beneficial to minimise the repetition of those changes in all; the external repositories that need them. But the maintenance costs of such diverse ecosystem is non trivial, so we divide; the level of support in two tiers: core and peripheral, with two; different levels of impact and responsibilities. Those tiers refer only to the; main repository (``llvm-project``) and not the other repositories in our git; project, unless explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libraries,; tools, etc. It is the responsibility of **every** LLVM developer to care for the core tier; regardless of where their work is applied to. What is covered; ---------------. The core tier is composed of:; * Core code (``llvm-project``) present in official releases and buildbots:; compiler, debugger, linker, libraries, etc, including infrastructure code; (table-gen, lit, file-check, unit-tests, etc).; * Build infrastructure that creates releases and buildbots (CMake, scripts).; * `Phabricator <https://github.com/llvm/phabricator>`_ and; `buildbot <https://github.com/llvm/llvm-zorg>`_ infrastructure.; * The `test-suite <https://github.com/llvm/llvm-test-suite>`_. Requirements; ------------. Code in this tier must:; * Keep official buildbots green, with warnings on breakages being emailed to; all affected developers. Those must be fixed as soon as possible or patches; must be reve",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:2396,Testability,test,tests,2396,"that need them. But the maintenance costs of such diverse ecosystem is non trivial, so we divide; the level of support in two tiers: core and peripheral, with two; different levels of impact and responsibilities. Those tiers refer only to the; main repository (``llvm-project``) and not the other repositories in our git; project, unless explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libraries,; tools, etc. It is the responsibility of **every** LLVM developer to care for the core tier; regardless of where their work is applied to. What is covered; ---------------. The core tier is composed of:; * Core code (``llvm-project``) present in official releases and buildbots:; compiler, debugger, linker, libraries, etc, including infrastructure code; (table-gen, lit, file-check, unit-tests, etc).; * Build infrastructure that creates releases and buildbots (CMake, scripts).; * `Phabricator <https://github.com/llvm/phabricator>`_ and; `buildbot <https://github.com/llvm/llvm-zorg>`_ infrastructure.; * The `test-suite <https://github.com/llvm/llvm-test-suite>`_. Requirements; ------------. Code in this tier must:; * Keep official buildbots green, with warnings on breakages being emailed to; all affected developers. Those must be fixed as soon as possible or patches; must be reverted, as per review policy.; * Bit-rot of a component in the core tier will result in that component being; downgraded to the peripheral tier or being removed. Sub-communities can; avoid this by fixing all raised issues in a timely manner. Peripheral Tier; ===============. The peripheral tier encompass the parts of LLVM that cater to a specific; sub-community and which don't usually affect the c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:2620,Testability,test,test-suite,2620,"s explicitly stated. Regardless of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libraries,; tools, etc. It is the responsibility of **every** LLVM developer to care for the core tier; regardless of where their work is applied to. What is covered; ---------------. The core tier is composed of:; * Core code (``llvm-project``) present in official releases and buildbots:; compiler, debugger, linker, libraries, etc, including infrastructure code; (table-gen, lit, file-check, unit-tests, etc).; * Build infrastructure that creates releases and buildbots (CMake, scripts).; * `Phabricator <https://github.com/llvm/phabricator>`_ and; `buildbot <https://github.com/llvm/llvm-zorg>`_ infrastructure.; * The `test-suite <https://github.com/llvm/llvm-test-suite>`_. Requirements; ------------. Code in this tier must:; * Keep official buildbots green, with warnings on breakages being emailed to; all affected developers. Those must be fixed as soon as possible or patches; must be reverted, as per review policy.; * Bit-rot of a component in the core tier will result in that component being; downgraded to the peripheral tier or being removed. Sub-communities can; avoid this by fixing all raised issues in a timely manner. Peripheral Tier; ===============. The peripheral tier encompass the parts of LLVM that cater to a specific; sub-community and which don't usually affect the core components directly. This includes experimental back-ends, disabled-by-default options and; alternative paths (work-in-progress replacements) in the same repository, as; well as separate efforts to integrate LLVM development with local practices. It is the responsibility of each sub-community to care about their own parts; and th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:2661,Testability,test,test-suite,2661,"of the tier, all code must follow the existing policies on quality,; reviews, style, etc. Core Tier; =========. The core tier encompasses all of the code in the main repository that is; in production, is actively tested and released in a regular schedule, including; core LLVM APIs and infrastructure, front/middle/back-ends, run-time libraries,; tools, etc. It is the responsibility of **every** LLVM developer to care for the core tier; regardless of where their work is applied to. What is covered; ---------------. The core tier is composed of:; * Core code (``llvm-project``) present in official releases and buildbots:; compiler, debugger, linker, libraries, etc, including infrastructure code; (table-gen, lit, file-check, unit-tests, etc).; * Build infrastructure that creates releases and buildbots (CMake, scripts).; * `Phabricator <https://github.com/llvm/phabricator>`_ and; `buildbot <https://github.com/llvm/llvm-zorg>`_ infrastructure.; * The `test-suite <https://github.com/llvm/llvm-test-suite>`_. Requirements; ------------. Code in this tier must:; * Keep official buildbots green, with warnings on breakages being emailed to; all affected developers. Those must be fixed as soon as possible or patches; must be reverted, as per review policy.; * Bit-rot of a component in the core tier will result in that component being; downgraded to the peripheral tier or being removed. Sub-communities can; avoid this by fixing all raised issues in a timely manner. Peripheral Tier; ===============. The peripheral tier encompass the parts of LLVM that cater to a specific; sub-community and which don't usually affect the core components directly. This includes experimental back-ends, disabled-by-default options and; alternative paths (work-in-progress replacements) in the same repository, as; well as separate efforts to integrate LLVM development with local practices. It is the responsibility of each sub-community to care about their own parts; and the intersection of that with the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:4502,Testability,test,tested,4502," as separate efforts to integrate LLVM development with local practices. It is the responsibility of each sub-community to care about their own parts; and the intersection of that with the core tier and other peripheral parts. There are three main groups of code that fit in this category:; * Code that is making its way into LLVM, via the `experimental <https://llvm.org/docs/DeveloperPolicy.html#introducing-new-components-into-llvm>`_; roadmap or similar efforts.; * Code that is making its way out of LLVM, via deprecation, replacement or; bit-rot, and will be removed if the sub-community that cares about it; cannot maintain it.; * Code that isn't meant to be in LLVM core and can coexist with the code in; the core tier (and others in the peripheral tier) long term, without causing; breakages or disturbances. What is covered; ---------------. The peripheral tier is composed of:; * Experimental targets and options that haven't been enable by default yet.; * Main repository projects that don't get released or regularly tested.; * Legacy tools and scripts that aren't used in upstream validation.; * Alternative build systems (ex. GN, Bazel) and related infrastructure.; * Tools support (ex. gdb scripts, editor configuration, helper scripts). Requirements; ------------. Code in this tier must:; * Have a clear benefit for residing in the main repository, catering to an; active sub-community (upstream or downstream).; * Be actively maintained by such sub-community and have its problems addressed; in a timely manner. Code in this tier must **not**:; * Break or invalidate core tier code or infrastructure. If that happens; accidentally, reverting functionality and working on the issues offline; is the only acceptable course of action.; * Negatively affect development of core tier code, with the sub-community; involved responsible for making changes to address specific concerns.; * Negatively affect other peripheral tier code, with the sub-communities; involved tasked to resolve th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:5929,Testability,test,test,5929,"have its problems addressed; in a timely manner. Code in this tier must **not**:; * Break or invalidate core tier code or infrastructure. If that happens; accidentally, reverting functionality and working on the issues offline; is the only acceptable course of action.; * Negatively affect development of core tier code, with the sub-community; involved responsible for making changes to address specific concerns.; * Negatively affect other peripheral tier code, with the sub-communities; involved tasked to resolve the issues, still making sure the solution doesn't; break or invalidate the core tier.; * Impose sub-optimal implementation strategies on core tier components as a; result of idiosyncrasies in the peripheral component.; * Have build infrastructure that spams all developers about their breakages.; * Fall into disrepair. This is a reflection of lack of an active sub-community; and will result in removal. Code in this tier should:; * Have infrastructure to test, whenever meaningful, with either no warnings or; notification contained within the sub-community.; * Have support and testing that scales with the complexity and resilience of; the component, with the bar for simple and gracefully-degrading components; (such as editor bindings) much lower than for complex components that must; remain fresh with HEAD (such as experimental back-ends or alternative build; systems).; * Have a document making clear the status of implementation, level of support; available, who the sub-community is and, if applicable, roadmap for inclusion; into the core tier.; * Be restricted to a specific directory or have a consistent pattern (ex.; unique file suffix), making it easy to remove when necessary. Inclusion Policy; ================. To add a new peripheral component, send an RFC to the appropriate dev list; proposing its addition and explaining how it will meet the support requirements; listed above. Different types of components could require different levels of; detail. when i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:6053,Testability,test,testing,6053,"ly acceptable course of action.; * Negatively affect development of core tier code, with the sub-community; involved responsible for making changes to address specific concerns.; * Negatively affect other peripheral tier code, with the sub-communities; involved tasked to resolve the issues, still making sure the solution doesn't; break or invalidate the core tier.; * Impose sub-optimal implementation strategies on core tier components as a; result of idiosyncrasies in the peripheral component.; * Have build infrastructure that spams all developers about their breakages.; * Fall into disrepair. This is a reflection of lack of an active sub-community; and will result in removal. Code in this tier should:; * Have infrastructure to test, whenever meaningful, with either no warnings or; notification contained within the sub-community.; * Have support and testing that scales with the complexity and resilience of; the component, with the bar for simple and gracefully-degrading components; (such as editor bindings) much lower than for complex components that must; remain fresh with HEAD (such as experimental back-ends or alternative build; systems).; * Have a document making clear the status of implementation, level of support; available, who the sub-community is and, if applicable, roadmap for inclusion; into the core tier.; * Be restricted to a specific directory or have a consistent pattern (ex.; unique file suffix), making it easy to remove when necessary. Inclusion Policy; ================. To add a new peripheral component, send an RFC to the appropriate dev list; proposing its addition and explaining how it will meet the support requirements; listed above. Different types of components could require different levels of; detail. when in doubt, ask the community what's the best approach. Inclusion must reach consensus in the RFC by the community and the approval of; the corresponding review (by multiple members of the community) is the official; note of acceptance. Aft",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:7791,Testability,test,testing,7791,"t; proposing its addition and explaining how it will meet the support requirements; listed above. Different types of components could require different levels of; detail. when in doubt, ask the community what's the best approach. Inclusion must reach consensus in the RFC by the community and the approval of; the corresponding review (by multiple members of the community) is the official; note of acceptance. After merge, there often is a period of transition, where teething issues on; existing buildbots are discovered and fixed. If those cannot be fixed straight; away, the sub-community is responsible for tracking and reverting all the; pertinent patches and retrying the inclusion review. Once the component is stable in tree, it must follow this policy and the; deprecation rules below apply. Due to the uncertain nature of inclusion, it's advisable that new components; are not added too close to a release branch. The time will depend on the size; and complexity of the component, so adding release and testing managers on the; RFC and review is strongly advisable. Deprecation Policy; ==================. The LLVM code base has a number of files that aren't being actively maintained.; But not all of those files are obstructing the development of the project and; so it remains in the repository with the assumption that it could still be; useful for downstream users. For code to remain in the repository, its presence must not impose an undue; burden on maintaining other components (core or peripheral). Warnings; --------. There are multiple types of issues that might trigger a request for deprecation,; including (but not limited to):. * Changes in a component consistently break other areas of the project.; * Components go broken for long periods of time (weeks or more).; * Clearly superior alternatives are in use and maintenance is painful.; * Builds and tests are harder / take longer, increasing the cost of; maintenance, overtaking the perceived benefits. If the maintenanc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:8656,Testability,test,tests,8656,". The time will depend on the size; and complexity of the component, so adding release and testing managers on the; RFC and review is strongly advisable. Deprecation Policy; ==================. The LLVM code base has a number of files that aren't being actively maintained.; But not all of those files are obstructing the development of the project and; so it remains in the repository with the assumption that it could still be; useful for downstream users. For code to remain in the repository, its presence must not impose an undue; burden on maintaining other components (core or peripheral). Warnings; --------. There are multiple types of issues that might trigger a request for deprecation,; including (but not limited to):. * Changes in a component consistently break other areas of the project.; * Components go broken for long periods of time (weeks or more).; * Clearly superior alternatives are in use and maintenance is painful.; * Builds and tests are harder / take longer, increasing the cost of; maintenance, overtaking the perceived benefits. If the maintenance cost is higher than it is acceptable by the majority of; developers, it means that either the sub-community is too small (and the extra; cost should be paid locally), or not active enough (and the problems won't be; fixed any time soon). In either case, removal of such problematic component is; justified. Steps for removal; -----------------. However clear the needs for removal are, we should take an incremental approach; to deprecating code, especially when there's still a sub-community that cares; about it. In that sense, code will never be removed outright without a series; of steps are taken. A minimum set of steps should be:; #. A proposal for removal / deactivation should be made to the Discourse forums ; (under the appropriate category), with a clear; statement of the maintenance costs imposed and the alternatives, if; applicable.; #. There must be enough consensus on the list that removal is warrante",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:4788,Usability,clear,clear,4788,"https://llvm.org/docs/DeveloperPolicy.html#introducing-new-components-into-llvm>`_; roadmap or similar efforts.; * Code that is making its way out of LLVM, via deprecation, replacement or; bit-rot, and will be removed if the sub-community that cares about it; cannot maintain it.; * Code that isn't meant to be in LLVM core and can coexist with the code in; the core tier (and others in the peripheral tier) long term, without causing; breakages or disturbances. What is covered; ---------------. The peripheral tier is composed of:; * Experimental targets and options that haven't been enable by default yet.; * Main repository projects that don't get released or regularly tested.; * Legacy tools and scripts that aren't used in upstream validation.; * Alternative build systems (ex. GN, Bazel) and related infrastructure.; * Tools support (ex. gdb scripts, editor configuration, helper scripts). Requirements; ------------. Code in this tier must:; * Have a clear benefit for residing in the main repository, catering to an; active sub-community (upstream or downstream).; * Be actively maintained by such sub-community and have its problems addressed; in a timely manner. Code in this tier must **not**:; * Break or invalidate core tier code or infrastructure. If that happens; accidentally, reverting functionality and working on the issues offline; is the only acceptable course of action.; * Negatively affect development of core tier code, with the sub-community; involved responsible for making changes to address specific concerns.; * Negatively affect other peripheral tier code, with the sub-communities; involved tasked to resolve the issues, still making sure the solution doesn't; break or invalidate the core tier.; * Impose sub-optimal implementation strategies on core tier components as a; result of idiosyncrasies in the peripheral component.; * Have build infrastructure that spams all developers about their breakages.; * Fall into disrepair. This is a reflection of lack of an ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:6144,Usability,simpl,simple,6144,"ly acceptable course of action.; * Negatively affect development of core tier code, with the sub-community; involved responsible for making changes to address specific concerns.; * Negatively affect other peripheral tier code, with the sub-communities; involved tasked to resolve the issues, still making sure the solution doesn't; break or invalidate the core tier.; * Impose sub-optimal implementation strategies on core tier components as a; result of idiosyncrasies in the peripheral component.; * Have build infrastructure that spams all developers about their breakages.; * Fall into disrepair. This is a reflection of lack of an active sub-community; and will result in removal. Code in this tier should:; * Have infrastructure to test, whenever meaningful, with either no warnings or; notification contained within the sub-community.; * Have support and testing that scales with the complexity and resilience of; the component, with the bar for simple and gracefully-degrading components; (such as editor bindings) much lower than for complex components that must; remain fresh with HEAD (such as experimental back-ends or alternative build; systems).; * Have a document making clear the status of implementation, level of support; available, who the sub-community is and, if applicable, roadmap for inclusion; into the core tier.; * Be restricted to a specific directory or have a consistent pattern (ex.; unique file suffix), making it easy to remove when necessary. Inclusion Policy; ================. To add a new peripheral component, send an RFC to the appropriate dev list; proposing its addition and explaining how it will meet the support requirements; listed above. Different types of components could require different levels of; detail. when in doubt, ask the community what's the best approach. Inclusion must reach consensus in the RFC by the community and the approval of; the corresponding review (by multiple members of the community) is the official; note of acceptance. Aft",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:6377,Usability,clear,clear,6377,"ies; involved tasked to resolve the issues, still making sure the solution doesn't; break or invalidate the core tier.; * Impose sub-optimal implementation strategies on core tier components as a; result of idiosyncrasies in the peripheral component.; * Have build infrastructure that spams all developers about their breakages.; * Fall into disrepair. This is a reflection of lack of an active sub-community; and will result in removal. Code in this tier should:; * Have infrastructure to test, whenever meaningful, with either no warnings or; notification contained within the sub-community.; * Have support and testing that scales with the complexity and resilience of; the component, with the bar for simple and gracefully-degrading components; (such as editor bindings) much lower than for complex components that must; remain fresh with HEAD (such as experimental back-ends or alternative build; systems).; * Have a document making clear the status of implementation, level of support; available, who the sub-community is and, if applicable, roadmap for inclusion; into the core tier.; * Be restricted to a specific directory or have a consistent pattern (ex.; unique file suffix), making it easy to remove when necessary. Inclusion Policy; ================. To add a new peripheral component, send an RFC to the appropriate dev list; proposing its addition and explaining how it will meet the support requirements; listed above. Different types of components could require different levels of; detail. when in doubt, ask the community what's the best approach. Inclusion must reach consensus in the RFC by the community and the approval of; the corresponding review (by multiple members of the community) is the official; note of acceptance. After merge, there often is a period of transition, where teething issues on; existing buildbots are discovered and fixed. If those cannot be fixed straight; away, the sub-community is responsible for tracking and reverting all the; pertinent patches a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:9132,Usability,clear,clear,9132,"e must not impose an undue; burden on maintaining other components (core or peripheral). Warnings; --------. There are multiple types of issues that might trigger a request for deprecation,; including (but not limited to):. * Changes in a component consistently break other areas of the project.; * Components go broken for long periods of time (weeks or more).; * Clearly superior alternatives are in use and maintenance is painful.; * Builds and tests are harder / take longer, increasing the cost of; maintenance, overtaking the perceived benefits. If the maintenance cost is higher than it is acceptable by the majority of; developers, it means that either the sub-community is too small (and the extra; cost should be paid locally), or not active enough (and the problems won't be; fixed any time soon). In either case, removal of such problematic component is; justified. Steps for removal; -----------------. However clear the needs for removal are, we should take an incremental approach; to deprecating code, especially when there's still a sub-community that cares; about it. In that sense, code will never be removed outright without a series; of steps are taken. A minimum set of steps should be:; #. A proposal for removal / deactivation should be made to the Discourse forums ; (under the appropriate category), with a clear; statement of the maintenance costs imposed and the alternatives, if; applicable.; #. There must be enough consensus on the list that removal is warranted, and no; pending proposals to fix the situation from a sub-community.; #. An announcement for removal must be made on the same lists, with ample time; for downstream users to take action on their local infrastructure. The time; will depend on what is being removed. #. If a script or documents are to be removed, they can always be pulled; from previous revision, and can be removed within days.; #. if a whole target is removed, we need to first announce publicly, and; potentially mark as deprecated in o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:9541,Usability,clear,clear,9541,"ken for long periods of time (weeks or more).; * Clearly superior alternatives are in use and maintenance is painful.; * Builds and tests are harder / take longer, increasing the cost of; maintenance, overtaking the perceived benefits. If the maintenance cost is higher than it is acceptable by the majority of; developers, it means that either the sub-community is too small (and the extra; cost should be paid locally), or not active enough (and the problems won't be; fixed any time soon). In either case, removal of such problematic component is; justified. Steps for removal; -----------------. However clear the needs for removal are, we should take an incremental approach; to deprecating code, especially when there's still a sub-community that cares; about it. In that sense, code will never be removed outright without a series; of steps are taken. A minimum set of steps should be:; #. A proposal for removal / deactivation should be made to the Discourse forums ; (under the appropriate category), with a clear; statement of the maintenance costs imposed and the alternatives, if; applicable.; #. There must be enough consensus on the list that removal is warranted, and no; pending proposals to fix the situation from a sub-community.; #. An announcement for removal must be made on the same lists, with ample time; for downstream users to take action on their local infrastructure. The time; will depend on what is being removed. #. If a script or documents are to be removed, they can always be pulled; from previous revision, and can be removed within days.; #. if a whole target is removed, we need to first announce publicly, and; potentially mark as deprecated in one release, only to remove on the; next release.; #. Everything else will fall in between those two extremes.; #. The removal is made by either the proposer or the sub-community that used to; maintain it, with replacements and arrangements made atomically on the same; commit. If a proposal for removal is delayed by",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst:11058,Usability,clear,clear,11058,"hould be:; #. A proposal for removal / deactivation should be made to the Discourse forums ; (under the appropriate category), with a clear; statement of the maintenance costs imposed and the alternatives, if; applicable.; #. There must be enough consensus on the list that removal is warranted, and no; pending proposals to fix the situation from a sub-community.; #. An announcement for removal must be made on the same lists, with ample time; for downstream users to take action on their local infrastructure. The time; will depend on what is being removed. #. If a script or documents are to be removed, they can always be pulled; from previous revision, and can be removed within days.; #. if a whole target is removed, we need to first announce publicly, and; potentially mark as deprecated in one release, only to remove on the; next release.; #. Everything else will fall in between those two extremes.; #. The removal is made by either the proposer or the sub-community that used to; maintain it, with replacements and arrangements made atomically on the same; commit. If a proposal for removal is delayed by the promise a sub-community will take; care of the code affected, the sub-community will have a time to fix all the; issues (depending on each case, as above), and if those are not fixed in time, a; subsequent request for removal should be made and the community may elect to; eject the component without further attempts to fix. Reinstatement; -------------. If a component is removed from LLVM, it may, at a later date, request inclusion; of a modified version, with evidence that all of the issues were fixed and that; there is a clear sub-community that will maintain it. By consequence, the pressure on such sub-community will be higher to keep; overall maintenance costs to a minimum and will need to show steps to mitigate; all of the issues that were listed as reasons for its original removal. Failing on those again, will lead to become a candidate for removal yet again. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SupportPolicy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SupportPolicy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:4884,Availability,error,errors,4884,"s a particular binary; (executable, shared library, loadable module, or driver module). The linker; generates this automatically based on a hash that includes the complete symbol; table and debugging information, even if this is later stripped from the binary. This specification uses the ELF Build ID as the sole means of identifying; binaries. Each binary relevant to the log must have been linked with a unique; Build ID. The symbolizing filter must have some means of mapping a Build ID back; to the original ELF binary (either the whole unstripped binary, or a stripped; binary paired with a separate debug file). Colorization; ============. The markup format supports a restricted subset of ANSI X3.64 SGR (Select Graphic; Rendition) control sequences. These are unlike other markup elements:. * They specify presentation details (bold or colors) rather than semantic; information. The association of semantic meaning with color (e.g. red for; errors) is chosen by the code doing the logging, rather than by the UI; presentation of the symbolizing filter. This is a concession to existing code; (e.g. LLVM sanitizer runtimes) that use specific colors and would require; substantial changes to generate semantic markup instead. * A single control sequence changes ""the state"", rather than being an; hierarchical structure that surrounds affected text. The filter processes ANSI SGR control sequences only within a single line. If a; control sequence to enter a bold or color state is encountered, it's expected; that the control sequence to reset to default state will be encountered before; the end of that line. If a ""dangling"" state is left at the end of a line, the; filter may reset to default state for the next line. An SGR control sequence is not interpreted inside any other markup element.; However, other markup elements may appear between SGR control sequences and the; color/bold state is expected to apply to the symbolic output that replaces the; markup element in the filter's out",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:10080,Availability,fault,fault,10080,"orms distinguish the kind of; code location, as described in detail for bt elements below. Examples::. {{{pc:0x12345678}}}; {{{pc:0xffffffff9abcdef0}}}. ``{{{data:%p}}}``. Here ``%p`` is the memory address of a data location. It might be presented as; the name of a global variable at that location. Examples::. {{{data:0x12345678}}}; {{{data:0xffffffff9abcdef0}}}. ``{{{bt:%u:%p}}}``, ``{{{bt:%u:%p:ra}}}``, ``{{{bt:%u:%p:pc}}}``. This represents one frame in a backtrace. It usually appears on a line by; itself (surrounded only by whitespace), in a sequence of such lines with; ascending frame numbers. So the human-readable output might be formatted; assuming that, such that it looks good for a sequence of bt elements each; alone on its line with uniform indentation of each line. But it can appear; anywhere, so the filter should not remove any non-whitespace text surrounding; the element. Here ``%u`` is the frame number, which starts at zero for the location of the; fault being identified, increments to one for the caller of frame zero's call; frame, to two for the caller of frame one, etc. ``%p`` is the memory address; of a code location. Code locations in a backtrace come from two distinct sources. Most backtrace; frames describe a return address code location, i.e. the instruction; immediately after a call instruction. This is the location of code that has; yet to run, since the function called there has not yet returned. Hence the; code location of actual interest is usually the call site itself rather than; the return address, i.e. one instruction earlier. When presenting the source; location for a return address frame, the symbolizing filter will subtract one; byte or one instruction length from the actual return address for the call; site, with the intent that the address logged can be translated directly to a; source location for the call site and not for the apparent return site; thereafter (which can be confusing). When inlined functions are involved, the; cal",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:11419,Availability,fault,fault,11419,"immediately after a call instruction. This is the location of code that has; yet to run, since the function called there has not yet returned. Hence the; code location of actual interest is usually the call site itself rather than; the return address, i.e. one instruction earlier. When presenting the source; location for a return address frame, the symbolizing filter will subtract one; byte or one instruction length from the actual return address for the call; site, with the intent that the address logged can be translated directly to a; source location for the call site and not for the apparent return site; thereafter (which can be confusing). When inlined functions are involved, the; call site and the return site can appear to be in different functions at; entirely unrelated source locations rather than just a line away, making the; confusion of showing the return site rather the call site quite severe. Often the first frame in a backtrace (""frame zero"") identifies the precise; code location of a fault, trap, or asynchronous interrupt rather than a return; address. At other times, even the first frame is actually a return address; (for example, backtraces collected at the time of an object allocation and; reported later when the allocated object is used or misused). When a system; supports in-thread trap handling, there may also be frames after the first; that represent a precise interrupted code location rather than a return; address, presented as the ""caller"" of a trap handler function (for example,; signal handlers in POSIX systems). Return address frames are identified by the ``:ra`` suffix. Precise code; location frames are identified by the ``:pc`` suffix. Traditional practice has often been to collect backtraces as simple address; lists, losing the distinction between return address code locations and; precise code locations. Some such code applies the ""subtract one"" adjustment; described above to the address values before reporting them, and it's not; alway",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:14448,Availability,avail,available,14448,"::. {{{bt:0:0x12345678:pc}}}; {{{bt:1:0xffffffff9abcdef0:ra}}}. ``{{{hexdict:...}}}`` [#not_yet_implemented]_. This element can span multiple lines. Here ``...`` is a sequence of key-value; pairs where a single ``:`` separates each key from its value, and arbitrary; whitespace separates the pairs. The value (right-hand side) of each pair; either is one or more ``0`` digits, or is ``0x`` followed by hexadecimal; digits. Each value might be a memory address or might be some other integer; (including an integer that looks like a likely memory address but actually has; an unrelated purpose). When the contextual information about the memory layout; suggests that a given value could be a code location or a global variable data; address, it might be presented as a source location or variable name or with; active UI that makes such interpretation optionally visible. The intended use is for things like register dumps, where the emitter doesn't; know which values might have a symbolic interpretation but a presentation that; makes plausible symbolic interpretations available might be very useful to; someone reading the log. At the same time, a flat text presentation should; usually avoid interfering too much with the original contents and formatting; of the dump. For example, it might use footnotes with source locations for; values that appear to be code locations. An active UI presentation might show; the dump text as is, but highlight values with symbolic information available; and pop up a presentation of symbolic details when a value is selected. Example::. {{{hexdict:; CS: 0 RIP: 0x6ee17076fb80 EFL: 0x10246 CR2: 0; RAX: 0xc53d0acbcf0 RBX: 0x1e659ea7e0d0 RCX: 0 RDX: 0x6ee1708300cc; RSI: 0 RDI: 0x6ee170830040 RBP: 0x3b13734898e0 RSP: 0x3b13734898d8; R8: 0x3b1373489860 R9: 0x2776ff4f R10: 0x2749d3e9a940 R11: 0x246; R12: 0x1e659ea7e0f0 R13: 0xd7231230fd6ff2e7 R14: 0x1e659ea7e108 R15: 0xc53d0acbcf0; }}}. Trigger elements; ================. These elements cause an external acti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:14860,Availability,avail,available,14860,"e some other integer; (including an integer that looks like a likely memory address but actually has; an unrelated purpose). When the contextual information about the memory layout; suggests that a given value could be a code location or a global variable data; address, it might be presented as a source location or variable name or with; active UI that makes such interpretation optionally visible. The intended use is for things like register dumps, where the emitter doesn't; know which values might have a symbolic interpretation but a presentation that; makes plausible symbolic interpretations available might be very useful to; someone reading the log. At the same time, a flat text presentation should; usually avoid interfering too much with the original contents and formatting; of the dump. For example, it might use footnotes with source locations for; values that appear to be code locations. An active UI presentation might show; the dump text as is, but highlight values with symbolic information available; and pop up a presentation of symbolic details when a value is selected. Example::. {{{hexdict:; CS: 0 RIP: 0x6ee17076fb80 EFL: 0x10246 CR2: 0; RAX: 0xc53d0acbcf0 RBX: 0x1e659ea7e0d0 RCX: 0 RDX: 0x6ee1708300cc; RSI: 0 RDI: 0x6ee170830040 RBP: 0x3b13734898e0 RSP: 0x3b13734898d8; R8: 0x3b1373489860 R9: 0x2776ff4f R10: 0x2749d3e9a940 R11: 0x246; R12: 0x1e659ea7e0f0 R13: 0xd7231230fd6ff2e7 R14: 0x1e659ea7e108 R15: 0xc53d0acbcf0; }}}. Trigger elements; ================. These elements cause an external action and will be presented to the user in a; human readable form. Generally they trigger an external action to occur that; results in a linkable page. The link or some other informative information about; the external action can then be presented to the user. ``{{{dumpfile:%s:%s}}}`` [#not_yet_implemented]_. Here the first ``%s`` is an identifier for a type of dump and the second; ``%s`` is an identifier for a particular dump that's just been published. The; types of d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:21425,Availability,down,down,21425,"erences. The second ``%s`` is the module type and it; determines what the remaining fields are. The following module types are; supported:. * ``elf:%x``. Here ``%x`` encodes an ELF Build ID. The Build ID should refer to a single; linked binary. The Build ID string is the sole way to identify the binary from; which this module was loaded. Example::. {{{module:1:libc.so:elf:83238ab56ba10497}}}. ``{{{mmap:%p:%i:...}}}``. This contextual element is used to give information about a particular region; in memory. ``%p`` is the starting address and ``%i`` gives the size in hex of the; region of memory. The ``...`` part can take different forms to give different; information about the specified region of memory. The allowed forms are the; following:. * ``load:%i:%s:%p``. This subelement informs the filter that a segment was loaded from a module.; The module is identified by its module ID ``%i``. The ``%s`` is one or more of; the letters 'r', 'w', and 'x' (in that order and in either upper or lower; case) to indicate this segment of memory is readable, writable, and/or; executable. The symbolizing filter can use this information to guess whether; an address is a likely code address or a likely data address in the given; module. The remaining ``%p`` gives the module relative address. For ELF files; the module relative address will be the ``p_vaddr`` of the associated program; header. For example if your module's executable segment has; ``p_vaddr=0x1000``, ``p_memsz=0x1234``, and was loaded at ``0x7acba69d5000``; then you need to subtract ``0x7acba69d4000`` from any address between; ``0x7acba69d5000`` and ``0x7acba69d6234`` to get the module relative address.; The starting address will usually have been rounded down to the active page; size, and the size rounded up. Example::. {{{mmap:0x7acba69d5000:0x5a000:load:1:rx:0x1000}}}. .. rubric:: Footnotes. .. [#not_yet_implemented] This markup element is not yet implemented in; :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:2380,Deployability,pipeline,pipeline,2380," code. It's distinctive enough that character sequences that look like the start; or end of a markup element should rarely if ever appear incidentally in logging; text. It's specifically intended not to require sanitizing plain text, such as; the HTML/XML requirement to replace ``<`` with ``&lt;`` and the like. :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` includes a symbolizing; filter via its ``--filter-markup`` option. Also, LLVM utilites emit stack; traces as markup when the ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` environment; variable is set. Scope and assumptions; =====================. A symbolizing filter implementation will be independent both of the target; operating system and machine architecture where the logs are generated and of; the host operating system and machine architecture where the filter runs. This format assumes that the symbolizing filter processes intact whole lines. If; long lines might be split during some stage of a logging pipeline, they must be; reassembled to restore the original line breaks before feeding lines into the; symbolizing filter. Most markup elements must appear entirely on a single line; (often with other text before and/or after the markup element). There are some; markup elements that are specified to span lines, with line breaks in the middle; of the element. Even in those cases, the filter is not expected to handle line; breaks in arbitrary places inside a markup element, but only inside certain; fields. This format assumes that the symbolizing filter processes a coherent stream of; log lines from a single process address space context. If a logging stream; interleaves log lines from more than one process, these must be collated into; separate per-process log streams and each stream processed by a separate; instance of the symbolizing filter. Because the kernel and user processes use; disjoint address regions in most operating systems, a single user process; address space plus the kernel address space can be treate",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:11656,Energy Efficiency,allocate,allocated,11656,"t is usually the call site itself rather than; the return address, i.e. one instruction earlier. When presenting the source; location for a return address frame, the symbolizing filter will subtract one; byte or one instruction length from the actual return address for the call; site, with the intent that the address logged can be translated directly to a; source location for the call site and not for the apparent return site; thereafter (which can be confusing). When inlined functions are involved, the; call site and the return site can appear to be in different functions at; entirely unrelated source locations rather than just a line away, making the; confusion of showing the return site rather the call site quite severe. Often the first frame in a backtrace (""frame zero"") identifies the precise; code location of a fault, trap, or asynchronous interrupt rather than a return; address. At other times, even the first frame is actually a return address; (for example, backtraces collected at the time of an object allocation and; reported later when the allocated object is used or misused). When a system; supports in-thread trap handling, there may also be frames after the first; that represent a precise interrupted code location rather than a return; address, presented as the ""caller"" of a trap handler function (for example,; signal handlers in POSIX systems). Return address frames are identified by the ``:ra`` suffix. Precise code; location frames are identified by the ``:pc`` suffix. Traditional practice has often been to collect backtraces as simple address; lists, losing the distinction between return address code locations and; precise code locations. Some such code applies the ""subtract one"" adjustment; described above to the address values before reporting them, and it's not; always clear or consistent whether this adjustment has been applied or not.; These ambiguous cases are supported by the ``bt`` and ``pc`` forms with no; ``:ra`` or ``:pc`` suffix, which indi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:170,Integrability,message,messages,170,"==========================; Symbolizer Markup Format; ==========================. .. contents::; :local:. Overview; ========. This document defines a text format for log messages that can be processed by a; symbolizing filter. The basic idea is that logging code emits text that contains; raw address values and so forth, without the logging code doing any real work to; convert those values to human-readable form. Instead, logging text uses the; markup format defined here to identify pieces of information that should be; converted to human-readable form after the fact. As with other markup formats,; the expectation is that most of the text will be displayed as is, while the; markup elements will be replaced with expanded text, or converted into active UI; elements, that present more details in symbolic form. This means there is no need for symbol tables, DWARF debugging sections, or; similar information to be directly accessible at runtime. There is also no need; at runtime for any logic intended to compute human-readable presentation of; information, such as C++ symbol demangling. Instead, logging must include markup; elements that give the contextual information necessary to make sense of the raw; data, such as memory layout details. This format identifies markup elements with a syntax that is both simple and; distinctive. It's simple enough to be matched and parsed with straightforward; code. It's distinctive enough that character sequences that look like the start; or end of a markup element should rarely if ever appear incidentally in logging; text. It's specifically intended not to require sanitizing plain text, such as; the HTML/XML requirement to replace ``<`` with ``&lt;`` and the like. :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` includes a symbolizing; filter via its ``--filter-markup`` option. Also, LLVM utilites emit stack; traces as markup when the ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` environment; variable is set. Scope and assumptions; ============",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:1949,Modifiability,variab,variable,1949,"nformation to be directly accessible at runtime. There is also no need; at runtime for any logic intended to compute human-readable presentation of; information, such as C++ symbol demangling. Instead, logging must include markup; elements that give the contextual information necessary to make sense of the raw; data, such as memory layout details. This format identifies markup elements with a syntax that is both simple and; distinctive. It's simple enough to be matched and parsed with straightforward; code. It's distinctive enough that character sequences that look like the start; or end of a markup element should rarely if ever appear incidentally in logging; text. It's specifically intended not to require sanitizing plain text, such as; the HTML/XML requirement to replace ``<`` with ``&lt;`` and the like. :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` includes a symbolizing; filter via its ``--filter-markup`` option. Also, LLVM utilites emit stack; traces as markup when the ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` environment; variable is set. Scope and assumptions; =====================. A symbolizing filter implementation will be independent both of the target; operating system and machine architecture where the logs are generated and of; the host operating system and machine architecture where the filter runs. This format assumes that the symbolizing filter processes intact whole lines. If; long lines might be split during some stage of a logging pipeline, they must be; reassembled to restore the original line breaks before feeding lines into the; symbolizing filter. Most markup elements must appear entirely on a single line; (often with other text before and/or after the markup element). There are some; markup elements that are specified to span lines, with line breaks in the middle; of the element. Even in those cases, the filter is not expected to handle line; breaks in arbitrary places inside a markup element, but only inside certain; fields. This format as",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:7409,Modifiability,extend,extend,7409," 30 Black foreground; 31 Red foreground; 32 Green foreground; 33 Yellow foreground; 34 Blue foreground; 35 Magenta foreground; 36 Cyan foreground; 37 White foreground; ==== ============================ ===============================================. Common markup element syntax; ============================. All the markup elements share a common syntactic structure to facilitate simple; matching and parsing code. Each element has the form::. {{{tag:fields}}}. ``tag`` identifies one of the element types described below, and is always a; short alphabetic string that must be in lower case. The rest of the element; consists of one or more fields. Fields are separated by ``:`` and cannot contain; any ``:`` or ``}`` characters. How many fields must be or may be present and; what they contain is specified for each element type. No markup elements or ANSI SGR control sequences are interpreted inside the; contents of a field. Implementations must ignore markup fields after those expected; this allows; adding new fields to backwards-compatibly extend elements. Implementations need; not ignore them silently, but the element should behave otherwise as if the; fields were removed. In the descriptions of each element type, ``printf``-style placeholders indicate; field contents:. ``%s``; A string of printable characters, not including ``:`` or ``}``. ``%p``; An address value represented by ``0x`` followed by an even number of; hexadecimal digits (using either lower-case or upper-case for ``A``–``F``).; If the digits are all ``0`` then the ``0x`` prefix may be omitted. No more; than 16 hexadecimal digits are expected to appear in a single value (64 bits). ``%u``; A nonnegative decimal integer. ``%i``; A nonnegative integer. The digits are hexadecimal if prefixed by ``0x``, octal; if prefixed by ``0``, or decimal otherwise. ``%x``; A sequence of an even number of hexadecimal digits (using either lower-case or; upper-case for ``A``–``F``), with no ``0x`` prefix. This represents an;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:9376,Modifiability,variab,variable,9376,"ry sequence of bytes, such as an ELF Build ID. Presentation elements; =====================. These are elements that convey a specific program entity to be displayed in; human-readable symbolic form. ``{{{symbol:%s}}}``; Here ``%s`` is the linkage name for a symbol or type. It may require; demangling according to language ABI rules. Even for unmangled names, it's; recommended that this markup element be used to identify a symbol name so that; it can be presented distinctively. Examples::. {{{symbol:_ZN7Mangled4NameEv}}}; {{{symbol:foobar}}}. ``{{{pc:%p}}}``, ``{{{pc:%p:ra}}}``, ``{{{pc:%p:pc}}}``. Here ``%p`` is the memory address of a code location. It might be presented as a; function name and source location. The second two forms distinguish the kind of; code location, as described in detail for bt elements below. Examples::. {{{pc:0x12345678}}}; {{{pc:0xffffffff9abcdef0}}}. ``{{{data:%p}}}``. Here ``%p`` is the memory address of a data location. It might be presented as; the name of a global variable at that location. Examples::. {{{data:0x12345678}}}; {{{data:0xffffffff9abcdef0}}}. ``{{{bt:%u:%p}}}``, ``{{{bt:%u:%p:ra}}}``, ``{{{bt:%u:%p:pc}}}``. This represents one frame in a backtrace. It usually appears on a line by; itself (surrounded only by whitespace), in a sequence of such lines with; ascending frame numbers. So the human-readable output might be formatted; assuming that, such that it looks good for a sequence of bt elements each; alone on its line with uniform indentation of each line. But it can appear; anywhere, so the filter should not remove any non-whitespace text surrounding; the element. Here ``%u`` is the frame number, which starts at zero for the location of the; fault being identified, increments to one for the caller of frame zero's call; frame, to two for the caller of frame one, etc. ``%p`` is the memory address; of a code location. Code locations in a backtrace come from two distinct sources. Most backtrace; frames describe a return addre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:14094,Modifiability,variab,variable,14094,"ng that a call instruction is longer than one byte on all; supported machines, applying the ""subtract one byte"" adjustment a second time; still results in an address somewhere in the call instruction, so a little; sloppiness here often does little or no harm. Examples::. {{{bt:0:0x12345678:pc}}}; {{{bt:1:0xffffffff9abcdef0:ra}}}. ``{{{hexdict:...}}}`` [#not_yet_implemented]_. This element can span multiple lines. Here ``...`` is a sequence of key-value; pairs where a single ``:`` separates each key from its value, and arbitrary; whitespace separates the pairs. The value (right-hand side) of each pair; either is one or more ``0`` digits, or is ``0x`` followed by hexadecimal; digits. Each value might be a memory address or might be some other integer; (including an integer that looks like a likely memory address but actually has; an unrelated purpose). When the contextual information about the memory layout; suggests that a given value could be a code location or a global variable data; address, it might be presented as a source location or variable name or with; active UI that makes such interpretation optionally visible. The intended use is for things like register dumps, where the emitter doesn't; know which values might have a symbolic interpretation but a presentation that; makes plausible symbolic interpretations available might be very useful to; someone reading the log. At the same time, a flat text presentation should; usually avoid interfering too much with the original contents and formatting; of the dump. For example, it might use footnotes with source locations for; values that appear to be code locations. An active UI presentation might show; the dump text as is, but highlight values with symbolic information available; and pop up a presentation of symbolic details when a value is selected. Example::. {{{hexdict:; CS: 0 RIP: 0x6ee17076fb80 EFL: 0x10246 CR2: 0; RAX: 0xc53d0acbcf0 RBX: 0x1e659ea7e0d0 RCX: 0 RDX: 0x6ee1708300cc; RSI: 0 RDI: 0x6ee170830040 R",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:14164,Modifiability,variab,variable,14164,"ng that a call instruction is longer than one byte on all; supported machines, applying the ""subtract one byte"" adjustment a second time; still results in an address somewhere in the call instruction, so a little; sloppiness here often does little or no harm. Examples::. {{{bt:0:0x12345678:pc}}}; {{{bt:1:0xffffffff9abcdef0:ra}}}. ``{{{hexdict:...}}}`` [#not_yet_implemented]_. This element can span multiple lines. Here ``...`` is a sequence of key-value; pairs where a single ``:`` separates each key from its value, and arbitrary; whitespace separates the pairs. The value (right-hand side) of each pair; either is one or more ``0`` digits, or is ``0x`` followed by hexadecimal; digits. Each value might be a memory address or might be some other integer; (including an integer that looks like a likely memory address but actually has; an unrelated purpose). When the contextual information about the memory layout; suggests that a given value could be a code location or a global variable data; address, it might be presented as a source location or variable name or with; active UI that makes such interpretation optionally visible. The intended use is for things like register dumps, where the emitter doesn't; know which values might have a symbolic interpretation but a presentation that; makes plausible symbolic interpretations available might be very useful to; someone reading the log. At the same time, a flat text presentation should; usually avoid interfering too much with the original contents and formatting; of the dump. For example, it might use footnotes with source locations for; values that appear to be code locations. An active UI presentation might show; the dump text as is, but highlight values with symbolic information available; and pop up a presentation of symbolic details when a value is selected. Example::. {{{hexdict:; CS: 0 RIP: 0x6ee17076fb80 EFL: 0x10246 CR2: 0; RAX: 0xc53d0acbcf0 RBX: 0x1e659ea7e0d0 RCX: 0 RDX: 0x6ee1708300cc; RSI: 0 RDI: 0x6ee170830040 R",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:3776,Performance,load,loaded,3776,"hose cases, the filter is not expected to handle line; breaks in arbitrary places inside a markup element, but only inside certain; fields. This format assumes that the symbolizing filter processes a coherent stream of; log lines from a single process address space context. If a logging stream; interleaves log lines from more than one process, these must be collated into; separate per-process log streams and each stream processed by a separate; instance of the symbolizing filter. Because the kernel and user processes use; disjoint address regions in most operating systems, a single user process; address space plus the kernel address space can be treated as a single address; space for symbolization purposes if desired. Dependence on Build IDs; =======================. The symbolizer markup scheme relies on contextual information about runtime; memory address layout to make it possible to convert markup elements into useful; symbolic form. This relies on having an unmistakable identification of which; binary was loaded at each address. An ELF Build ID is the payload of an ELF note with name ``""GNU""`` and type; ``NT_GNU_BUILD_ID``, a unique byte sequence that identifies a particular binary; (executable, shared library, loadable module, or driver module). The linker; generates this automatically based on a hash that includes the complete symbol; table and debugging information, even if this is later stripped from the binary. This specification uses the ELF Build ID as the sole means of identifying; binaries. Each binary relevant to the log must have been linked with a unique; Build ID. The symbolizing filter must have some means of mapping a Build ID back; to the original ELF binary (either the whole unstripped binary, or a stripped; binary paired with a separate debug file). Colorization; ============. The markup format supports a restricted subset of ANSI X3.64 SGR (Select Graphic; Rendition) control sequences. These are unlike other markup elements:. * They specify p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:3986,Performance,load,loadable,3986,"that the symbolizing filter processes a coherent stream of; log lines from a single process address space context. If a logging stream; interleaves log lines from more than one process, these must be collated into; separate per-process log streams and each stream processed by a separate; instance of the symbolizing filter. Because the kernel and user processes use; disjoint address regions in most operating systems, a single user process; address space plus the kernel address space can be treated as a single address; space for symbolization purposes if desired. Dependence on Build IDs; =======================. The symbolizer markup scheme relies on contextual information about runtime; memory address layout to make it possible to convert markup elements into useful; symbolic form. This relies on having an unmistakable identification of which; binary was loaded at each address. An ELF Build ID is the payload of an ELF note with name ``""GNU""`` and type; ``NT_GNU_BUILD_ID``, a unique byte sequence that identifies a particular binary; (executable, shared library, loadable module, or driver module). The linker; generates this automatically based on a hash that includes the complete symbol; table and debugging information, even if this is later stripped from the binary. This specification uses the ELF Build ID as the sole means of identifying; binaries. Each binary relevant to the log must have been linked with a unique; Build ID. The symbolizing filter must have some means of mapping a Build ID back; to the original ELF binary (either the whole unstripped binary, or a stripped; binary paired with a separate debug file). Colorization; ============. The markup format supports a restricted subset of ANSI X3.64 SGR (Select Graphic; Rendition) control sequences. These are unlike other markup elements:. * They specify presentation details (bold or colors) rather than semantic; information. The association of semantic meaning with color (e.g. red for; errors) is chosen by the c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:19055,Performance,load,loaded,19055," in the logging stream. It should; always be possible for the symbolizing filter to be implemented as a single pass; over the raw logging stream, accumulating context and massaging text as it goes. ``{{{reset}}}``. This should be output before any other contextual element. The need for this; contextual element is to support implementations that handle logs coming from; multiple processes. Such implementations might not know when a new process; starts or ends. Because some identifying information (like process IDs) might; be the same between old and new processes, a way is needed to distinguish two; processes with such identical identifying information. This element informs; such implementations to reset the state of a filter so that information from a; previous process's contextual elements is not assumed for new process that; just happens have the same identifying information. ``{{{module:%i:%s:%s:...}}}``. This element represents a so-called ""module"". A ""module"" is a single linked; binary, such as a loaded ELF file. Usually each module occupies a contiguous; range of memory. Here ``%i`` is the module ID which is used by other contextual elements to; refer to this module. The first ``%s`` is a human-readable identifier for the; module, such as an ELF ``DT_SONAME`` string or a file name; but it might be; empty. It's only for casual information. Only the module ID is used to refer; to this module in other contextual elements, never the ``%s`` string. The; ``module`` element defining a module ID must always be emitted before any; other elements that refer to that module ID, so that a filter never needs to; keep track of dangling references. The second ``%s`` is the module type and it; determines what the remaining fields are. The following module types are; supported:. * ``elf:%x``. Here ``%x`` encodes an ELF Build ID. The Build ID should refer to a single; linked binary. The Build ID string is the sole way to identify the binary from; which this module was loaded. Ex",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:20028,Performance,load,loaded,20028,"o-called ""module"". A ""module"" is a single linked; binary, such as a loaded ELF file. Usually each module occupies a contiguous; range of memory. Here ``%i`` is the module ID which is used by other contextual elements to; refer to this module. The first ``%s`` is a human-readable identifier for the; module, such as an ELF ``DT_SONAME`` string or a file name; but it might be; empty. It's only for casual information. Only the module ID is used to refer; to this module in other contextual elements, never the ``%s`` string. The; ``module`` element defining a module ID must always be emitted before any; other elements that refer to that module ID, so that a filter never needs to; keep track of dangling references. The second ``%s`` is the module type and it; determines what the remaining fields are. The following module types are; supported:. * ``elf:%x``. Here ``%x`` encodes an ELF Build ID. The Build ID should refer to a single; linked binary. The Build ID string is the sole way to identify the binary from; which this module was loaded. Example::. {{{module:1:libc.so:elf:83238ab56ba10497}}}. ``{{{mmap:%p:%i:...}}}``. This contextual element is used to give information about a particular region; in memory. ``%p`` is the starting address and ``%i`` gives the size in hex of the; region of memory. The ``...`` part can take different forms to give different; information about the specified region of memory. The allowed forms are the; following:. * ``load:%i:%s:%p``. This subelement informs the filter that a segment was loaded from a module.; The module is identified by its module ID ``%i``. The ``%s`` is one or more of; the letters 'r', 'w', and 'x' (in that order and in either upper or lower; case) to indicate this segment of memory is readable, writable, and/or; executable. The symbolizing filter can use this information to guess whether; an address is a likely code address or a likely data address in the given; module. The remaining ``%p`` gives the module relative address",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:20452,Performance,load,load,20452,"in other contextual elements, never the ``%s`` string. The; ``module`` element defining a module ID must always be emitted before any; other elements that refer to that module ID, so that a filter never needs to; keep track of dangling references. The second ``%s`` is the module type and it; determines what the remaining fields are. The following module types are; supported:. * ``elf:%x``. Here ``%x`` encodes an ELF Build ID. The Build ID should refer to a single; linked binary. The Build ID string is the sole way to identify the binary from; which this module was loaded. Example::. {{{module:1:libc.so:elf:83238ab56ba10497}}}. ``{{{mmap:%p:%i:...}}}``. This contextual element is used to give information about a particular region; in memory. ``%p`` is the starting address and ``%i`` gives the size in hex of the; region of memory. The ``...`` part can take different forms to give different; information about the specified region of memory. The allowed forms are the; following:. * ``load:%i:%s:%p``. This subelement informs the filter that a segment was loaded from a module.; The module is identified by its module ID ``%i``. The ``%s`` is one or more of; the letters 'r', 'w', and 'x' (in that order and in either upper or lower; case) to indicate this segment of memory is readable, writable, and/or; executable. The symbolizing filter can use this information to guess whether; an address is a likely code address or a likely data address in the given; module. The remaining ``%p`` gives the module relative address. For ELF files; the module relative address will be the ``p_vaddr`` of the associated program; header. For example if your module's executable segment has; ``p_vaddr=0x1000``, ``p_memsz=0x1234``, and was loaded at ``0x7acba69d5000``; then you need to subtract ``0x7acba69d4000`` from any address between; ``0x7acba69d5000`` and ``0x7acba69d6234`` to get the module relative address.; The starting address will usually have been rounded down to the active page; size, an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:20523,Performance,load,loaded,20523,"ring. The; ``module`` element defining a module ID must always be emitted before any; other elements that refer to that module ID, so that a filter never needs to; keep track of dangling references. The second ``%s`` is the module type and it; determines what the remaining fields are. The following module types are; supported:. * ``elf:%x``. Here ``%x`` encodes an ELF Build ID. The Build ID should refer to a single; linked binary. The Build ID string is the sole way to identify the binary from; which this module was loaded. Example::. {{{module:1:libc.so:elf:83238ab56ba10497}}}. ``{{{mmap:%p:%i:...}}}``. This contextual element is used to give information about a particular region; in memory. ``%p`` is the starting address and ``%i`` gives the size in hex of the; region of memory. The ``...`` part can take different forms to give different; information about the specified region of memory. The allowed forms are the; following:. * ``load:%i:%s:%p``. This subelement informs the filter that a segment was loaded from a module.; The module is identified by its module ID ``%i``. The ``%s`` is one or more of; the letters 'r', 'w', and 'x' (in that order and in either upper or lower; case) to indicate this segment of memory is readable, writable, and/or; executable. The symbolizing filter can use this information to guess whether; an address is a likely code address or a likely data address in the given; module. The remaining ``%p`` gives the module relative address. For ELF files; the module relative address will be the ``p_vaddr`` of the associated program; header. For example if your module's executable segment has; ``p_vaddr=0x1000``, ``p_memsz=0x1234``, and was loaded at ``0x7acba69d5000``; then you need to subtract ``0x7acba69d4000`` from any address between; ``0x7acba69d5000`` and ``0x7acba69d6234`` to get the module relative address.; The starting address will usually have been rounded down to the active page; size, and the size rounded up. Example::. {{{mmap:0x7acb",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:21193,Performance,load,loaded,21193,"erences. The second ``%s`` is the module type and it; determines what the remaining fields are. The following module types are; supported:. * ``elf:%x``. Here ``%x`` encodes an ELF Build ID. The Build ID should refer to a single; linked binary. The Build ID string is the sole way to identify the binary from; which this module was loaded. Example::. {{{module:1:libc.so:elf:83238ab56ba10497}}}. ``{{{mmap:%p:%i:...}}}``. This contextual element is used to give information about a particular region; in memory. ``%p`` is the starting address and ``%i`` gives the size in hex of the; region of memory. The ``...`` part can take different forms to give different; information about the specified region of memory. The allowed forms are the; following:. * ``load:%i:%s:%p``. This subelement informs the filter that a segment was loaded from a module.; The module is identified by its module ID ``%i``. The ``%s`` is one or more of; the letters 'r', 'w', and 'x' (in that order and in either upper or lower; case) to indicate this segment of memory is readable, writable, and/or; executable. The symbolizing filter can use this information to guess whether; an address is a likely code address or a likely data address in the given; module. The remaining ``%p`` gives the module relative address. For ELF files; the module relative address will be the ``p_vaddr`` of the associated program; header. For example if your module's executable segment has; ``p_vaddr=0x1000``, ``p_memsz=0x1234``, and was loaded at ``0x7acba69d5000``; then you need to subtract ``0x7acba69d4000`` from any address between; ``0x7acba69d5000`` and ``0x7acba69d6234`` to get the module relative address.; The starting address will usually have been rounded down to the active page; size, and the size rounded up. Example::. {{{mmap:0x7acba69d5000:0x5a000:load:1:rx:0x1000}}}. .. rubric:: Footnotes. .. [#not_yet_implemented] This markup element is not yet implemented in; :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:21523,Performance,load,load,21523,"erences. The second ``%s`` is the module type and it; determines what the remaining fields are. The following module types are; supported:. * ``elf:%x``. Here ``%x`` encodes an ELF Build ID. The Build ID should refer to a single; linked binary. The Build ID string is the sole way to identify the binary from; which this module was loaded. Example::. {{{module:1:libc.so:elf:83238ab56ba10497}}}. ``{{{mmap:%p:%i:...}}}``. This contextual element is used to give information about a particular region; in memory. ``%p`` is the starting address and ``%i`` gives the size in hex of the; region of memory. The ``...`` part can take different forms to give different; information about the specified region of memory. The allowed forms are the; following:. * ``load:%i:%s:%p``. This subelement informs the filter that a segment was loaded from a module.; The module is identified by its module ID ``%i``. The ``%s`` is one or more of; the letters 'r', 'w', and 'x' (in that order and in either upper or lower; case) to indicate this segment of memory is readable, writable, and/or; executable. The symbolizing filter can use this information to guess whether; an address is a likely code address or a likely data address in the given; module. The remaining ``%p`` gives the module relative address. For ELF files; the module relative address will be the ``p_vaddr`` of the associated program; header. For example if your module's executable segment has; ``p_vaddr=0x1000``, ``p_memsz=0x1234``, and was loaded at ``0x7acba69d5000``; then you need to subtract ``0x7acba69d4000`` from any address between; ``0x7acba69d5000`` and ``0x7acba69d6234`` to get the module relative address.; The starting address will usually have been rounded down to the active page; size, and the size rounded up. Example::. {{{mmap:0x7acba69d5000:0x5a000:load:1:rx:0x1000}}}. .. rubric:: Footnotes. .. [#not_yet_implemented] This markup element is not yet implemented in; :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:14567,Safety,avoid,avoid,14567," a single ``:`` separates each key from its value, and arbitrary; whitespace separates the pairs. The value (right-hand side) of each pair; either is one or more ``0`` digits, or is ``0x`` followed by hexadecimal; digits. Each value might be a memory address or might be some other integer; (including an integer that looks like a likely memory address but actually has; an unrelated purpose). When the contextual information about the memory layout; suggests that a given value could be a code location or a global variable data; address, it might be presented as a source location or variable name or with; active UI that makes such interpretation optionally visible. The intended use is for things like register dumps, where the emitter doesn't; know which values might have a symbolic interpretation but a presentation that; makes plausible symbolic interpretations available might be very useful to; someone reading the log. At the same time, a flat text presentation should; usually avoid interfering too much with the original contents and formatting; of the dump. For example, it might use footnotes with source locations for; values that appear to be code locations. An active UI presentation might show; the dump text as is, but highlight values with symbolic information available; and pop up a presentation of symbolic details when a value is selected. Example::. {{{hexdict:; CS: 0 RIP: 0x6ee17076fb80 EFL: 0x10246 CR2: 0; RAX: 0xc53d0acbcf0 RBX: 0x1e659ea7e0d0 RCX: 0 RDX: 0x6ee1708300cc; RSI: 0 RDI: 0x6ee170830040 RBP: 0x3b13734898e0 RSP: 0x3b13734898d8; R8: 0x3b1373489860 R9: 0x2776ff4f R10: 0x2749d3e9a940 R11: 0x246; R12: 0x1e659ea7e0f0 R13: 0xd7231230fd6ff2e7 R14: 0x1e659ea7e108 R15: 0xc53d0acbcf0; }}}. Trigger elements; ================. These elements cause an external action and will be presented to the user in a; human readable form. Generally they trigger an external action to occur that; results in a linkable page. The link or some other informative information about",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:930,Security,access,accessible,930,"==========================; Symbolizer Markup Format; ==========================. .. contents::; :local:. Overview; ========. This document defines a text format for log messages that can be processed by a; symbolizing filter. The basic idea is that logging code emits text that contains; raw address values and so forth, without the logging code doing any real work to; convert those values to human-readable form. Instead, logging text uses the; markup format defined here to identify pieces of information that should be; converted to human-readable form after the fact. As with other markup formats,; the expectation is that most of the text will be displayed as is, while the; markup elements will be replaced with expanded text, or converted into active UI; elements, that present more details in symbolic form. This means there is no need for symbol tables, DWARF debugging sections, or; similar information to be directly accessible at runtime. There is also no need; at runtime for any logic intended to compute human-readable presentation of; information, such as C++ symbol demangling. Instead, logging must include markup; elements that give the contextual information necessary to make sense of the raw; data, such as memory layout details. This format identifies markup elements with a syntax that is both simple and; distinctive. It's simple enough to be matched and parsed with straightforward; code. It's distinctive enough that character sequences that look like the start; or end of a markup element should rarely if ever appear incidentally in logging; text. It's specifically intended not to require sanitizing plain text, such as; the HTML/XML requirement to replace ``<`` with ``&lt;`` and the like. :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` includes a symbolizing; filter via its ``--filter-markup`` option. Also, LLVM utilites emit stack; traces as markup when the ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` environment; variable is set. Scope and assumptions; ============",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:1621,Security,sanitiz,sanitizing,1621," be displayed as is, while the; markup elements will be replaced with expanded text, or converted into active UI; elements, that present more details in symbolic form. This means there is no need for symbol tables, DWARF debugging sections, or; similar information to be directly accessible at runtime. There is also no need; at runtime for any logic intended to compute human-readable presentation of; information, such as C++ symbol demangling. Instead, logging must include markup; elements that give the contextual information necessary to make sense of the raw; data, such as memory layout details. This format identifies markup elements with a syntax that is both simple and; distinctive. It's simple enough to be matched and parsed with straightforward; code. It's distinctive enough that character sequences that look like the start; or end of a markup element should rarely if ever appear incidentally in logging; text. It's specifically intended not to require sanitizing plain text, such as; the HTML/XML requirement to replace ``<`` with ``&lt;`` and the like. :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` includes a symbolizing; filter via its ``--filter-markup`` option. Also, LLVM utilites emit stack; traces as markup when the ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` environment; variable is set. Scope and assumptions; =====================. A symbolizing filter implementation will be independent both of the target; operating system and machine architecture where the logs are generated and of; the host operating system and machine architecture where the filter runs. This format assumes that the symbolizing filter processes intact whole lines. If; long lines might be split during some stage of a logging pipeline, they must be; reassembled to restore the original line breaks before feeding lines into the; symbolizing filter. Most markup elements must appear entirely on a single line; (often with other text before and/or after the markup element). There are some; markup ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:4074,Security,hash,hash,4074,"be collated into; separate per-process log streams and each stream processed by a separate; instance of the symbolizing filter. Because the kernel and user processes use; disjoint address regions in most operating systems, a single user process; address space plus the kernel address space can be treated as a single address; space for symbolization purposes if desired. Dependence on Build IDs; =======================. The symbolizer markup scheme relies on contextual information about runtime; memory address layout to make it possible to convert markup elements into useful; symbolic form. This relies on having an unmistakable identification of which; binary was loaded at each address. An ELF Build ID is the payload of an ELF note with name ``""GNU""`` and type; ``NT_GNU_BUILD_ID``, a unique byte sequence that identifies a particular binary; (executable, shared library, loadable module, or driver module). The linker; generates this automatically based on a hash that includes the complete symbol; table and debugging information, even if this is later stripped from the binary. This specification uses the ELF Build ID as the sole means of identifying; binaries. Each binary relevant to the log must have been linked with a unique; Build ID. The symbolizing filter must have some means of mapping a Build ID back; to the original ELF binary (either the whole unstripped binary, or a stripped; binary paired with a separate debug file). Colorization; ============. The markup format supports a restricted subset of ANSI X3.64 SGR (Select Graphic; Rendition) control sequences. These are unlike other markup elements:. * They specify presentation details (bold or colors) rather than semantic; information. The association of semantic meaning with color (e.g. red for; errors) is chosen by the code doing the logging, rather than by the UI; presentation of the symbolizing filter. This is a concession to existing code; (e.g. LLVM sanitizer runtimes) that use specific colors and would require",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:5046,Security,sanitiz,sanitizer,5046,"te symbol; table and debugging information, even if this is later stripped from the binary. This specification uses the ELF Build ID as the sole means of identifying; binaries. Each binary relevant to the log must have been linked with a unique; Build ID. The symbolizing filter must have some means of mapping a Build ID back; to the original ELF binary (either the whole unstripped binary, or a stripped; binary paired with a separate debug file). Colorization; ============. The markup format supports a restricted subset of ANSI X3.64 SGR (Select Graphic; Rendition) control sequences. These are unlike other markup elements:. * They specify presentation details (bold or colors) rather than semantic; information. The association of semantic meaning with color (e.g. red for; errors) is chosen by the code doing the logging, rather than by the UI; presentation of the symbolizing filter. This is a concession to existing code; (e.g. LLVM sanitizer runtimes) that use specific colors and would require; substantial changes to generate semantic markup instead. * A single control sequence changes ""the state"", rather than being an; hierarchical structure that surrounds affected text. The filter processes ANSI SGR control sequences only within a single line. If a; control sequence to enter a bold or color state is encountered, it's expected; that the control sequence to reset to default state will be encountered before; the end of that line. If a ""dangling"" state is left at the end of a line, the; filter may reset to default state for the next line. An SGR control sequence is not interpreted inside any other markup element.; However, other markup elements may appear between SGR control sequences and the; color/bold state is expected to apply to the symbolic output that replaces the; markup element in the filter's output. The accepted SGR control sequences all have the form ``""\033[%um""`` (expressed here; using C string syntax), where ``%u`` is one of these:. ==== ==================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:17722,Security,access,accessible,17722," need to feed some distilled form of the contextual information to those; processes. An example of a type identifier is ``sancov``, for dumps from LLVM; `SanitizerCoverage <https://clang.llvm.org/docs/SanitizerCoverage.html>`_. Example::. {{{dumpfile:sancov:sancov.8675}}}. Contextual elements; ===================. These are elements that supply information necessary to convert presentation; elements to symbolic form. Unlike presentation elements, they are not directly; related to the surrounding text. Contextual elements should appear alone on; lines with no other non-whitespace text, so that the symbolizing filter might; elide the whole line from its output without hiding any other log text. The contextual elements themselves do not necessarily need to be presented in; human-readable output. However, the information they impart may be essential to; understanding the logging text even after symbolization. So it's recommended; that this information be preserved in some form when the original raw log with; markup may no longer be readily accessible for whatever reason. Contextual elements should appear in the logging stream before they are needed.; That is, if some piece of context may affect how the symbolizing filter would; interpret or present a later presentation element, the necessary contextual; elements should have appeared somewhere earlier in the logging stream. It should; always be possible for the symbolizing filter to be implemented as a single pass; over the raw logging stream, accumulating context and massaging text as it goes. ``{{{reset}}}``. This should be output before any other contextual element. The need for this; contextual element is to support implementations that handle logs coming from; multiple processes. Such implementations might not know when a new process; starts or ends. Because some identifying information (like process IDs) might; be the same between old and new processes, a way is needed to distinguish two; processes with such identic",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:166,Testability,log,log,166,"==========================; Symbolizer Markup Format; ==========================. .. contents::; :local:. Overview; ========. This document defines a text format for log messages that can be processed by a; symbolizing filter. The basic idea is that logging code emits text that contains; raw address values and so forth, without the logging code doing any real work to; convert those values to human-readable form. Instead, logging text uses the; markup format defined here to identify pieces of information that should be; converted to human-readable form after the fact. As with other markup formats,; the expectation is that most of the text will be displayed as is, while the; markup elements will be replaced with expanded text, or converted into active UI; elements, that present more details in symbolic form. This means there is no need for symbol tables, DWARF debugging sections, or; similar information to be directly accessible at runtime. There is also no need; at runtime for any logic intended to compute human-readable presentation of; information, such as C++ symbol demangling. Instead, logging must include markup; elements that give the contextual information necessary to make sense of the raw; data, such as memory layout details. This format identifies markup elements with a syntax that is both simple and; distinctive. It's simple enough to be matched and parsed with straightforward; code. It's distinctive enough that character sequences that look like the start; or end of a markup element should rarely if ever appear incidentally in logging; text. It's specifically intended not to require sanitizing plain text, such as; the HTML/XML requirement to replace ``<`` with ``&lt;`` and the like. :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` includes a symbolizing; filter via its ``--filter-markup`` option. Also, LLVM utilites emit stack; traces as markup when the ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` environment; variable is set. Scope and assumptions; ============",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:250,Testability,log,logging,250,"==========================; Symbolizer Markup Format; ==========================. .. contents::; :local:. Overview; ========. This document defines a text format for log messages that can be processed by a; symbolizing filter. The basic idea is that logging code emits text that contains; raw address values and so forth, without the logging code doing any real work to; convert those values to human-readable form. Instead, logging text uses the; markup format defined here to identify pieces of information that should be; converted to human-readable form after the fact. As with other markup formats,; the expectation is that most of the text will be displayed as is, while the; markup elements will be replaced with expanded text, or converted into active UI; elements, that present more details in symbolic form. This means there is no need for symbol tables, DWARF debugging sections, or; similar information to be directly accessible at runtime. There is also no need; at runtime for any logic intended to compute human-readable presentation of; information, such as C++ symbol demangling. Instead, logging must include markup; elements that give the contextual information necessary to make sense of the raw; data, such as memory layout details. This format identifies markup elements with a syntax that is both simple and; distinctive. It's simple enough to be matched and parsed with straightforward; code. It's distinctive enough that character sequences that look like the start; or end of a markup element should rarely if ever appear incidentally in logging; text. It's specifically intended not to require sanitizing plain text, such as; the HTML/XML requirement to replace ``<`` with ``&lt;`` and the like. :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` includes a symbolizing; filter via its ``--filter-markup`` option. Also, LLVM utilites emit stack; traces as markup when the ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` environment; variable is set. Scope and assumptions; ============",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:334,Testability,log,logging,334,"==========================; Symbolizer Markup Format; ==========================. .. contents::; :local:. Overview; ========. This document defines a text format for log messages that can be processed by a; symbolizing filter. The basic idea is that logging code emits text that contains; raw address values and so forth, without the logging code doing any real work to; convert those values to human-readable form. Instead, logging text uses the; markup format defined here to identify pieces of information that should be; converted to human-readable form after the fact. As with other markup formats,; the expectation is that most of the text will be displayed as is, while the; markup elements will be replaced with expanded text, or converted into active UI; elements, that present more details in symbolic form. This means there is no need for symbol tables, DWARF debugging sections, or; similar information to be directly accessible at runtime. There is also no need; at runtime for any logic intended to compute human-readable presentation of; information, such as C++ symbol demangling. Instead, logging must include markup; elements that give the contextual information necessary to make sense of the raw; data, such as memory layout details. This format identifies markup elements with a syntax that is both simple and; distinctive. It's simple enough to be matched and parsed with straightforward; code. It's distinctive enough that character sequences that look like the start; or end of a markup element should rarely if ever appear incidentally in logging; text. It's specifically intended not to require sanitizing plain text, such as; the HTML/XML requirement to replace ``<`` with ``&lt;`` and the like. :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` includes a symbolizing; filter via its ``--filter-markup`` option. Also, LLVM utilites emit stack; traces as markup when the ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` environment; variable is set. Scope and assumptions; ============",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:425,Testability,log,logging,425,"==========================; Symbolizer Markup Format; ==========================. .. contents::; :local:. Overview; ========. This document defines a text format for log messages that can be processed by a; symbolizing filter. The basic idea is that logging code emits text that contains; raw address values and so forth, without the logging code doing any real work to; convert those values to human-readable form. Instead, logging text uses the; markup format defined here to identify pieces of information that should be; converted to human-readable form after the fact. As with other markup formats,; the expectation is that most of the text will be displayed as is, while the; markup elements will be replaced with expanded text, or converted into active UI; elements, that present more details in symbolic form. This means there is no need for symbol tables, DWARF debugging sections, or; similar information to be directly accessible at runtime. There is also no need; at runtime for any logic intended to compute human-readable presentation of; information, such as C++ symbol demangling. Instead, logging must include markup; elements that give the contextual information necessary to make sense of the raw; data, such as memory layout details. This format identifies markup elements with a syntax that is both simple and; distinctive. It's simple enough to be matched and parsed with straightforward; code. It's distinctive enough that character sequences that look like the start; or end of a markup element should rarely if ever appear incidentally in logging; text. It's specifically intended not to require sanitizing plain text, such as; the HTML/XML requirement to replace ``<`` with ``&lt;`` and the like. :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` includes a symbolizing; filter via its ``--filter-markup`` option. Also, LLVM utilites emit stack; traces as markup when the ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` environment; variable is set. Scope and assumptions; ============",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:995,Testability,log,logic,995,"==; Symbolizer Markup Format; ==========================. .. contents::; :local:. Overview; ========. This document defines a text format for log messages that can be processed by a; symbolizing filter. The basic idea is that logging code emits text that contains; raw address values and so forth, without the logging code doing any real work to; convert those values to human-readable form. Instead, logging text uses the; markup format defined here to identify pieces of information that should be; converted to human-readable form after the fact. As with other markup formats,; the expectation is that most of the text will be displayed as is, while the; markup elements will be replaced with expanded text, or converted into active UI; elements, that present more details in symbolic form. This means there is no need for symbol tables, DWARF debugging sections, or; similar information to be directly accessible at runtime. There is also no need; at runtime for any logic intended to compute human-readable presentation of; information, such as C++ symbol demangling. Instead, logging must include markup; elements that give the contextual information necessary to make sense of the raw; data, such as memory layout details. This format identifies markup elements with a syntax that is both simple and; distinctive. It's simple enough to be matched and parsed with straightforward; code. It's distinctive enough that character sequences that look like the start; or end of a markup element should rarely if ever appear incidentally in logging; text. It's specifically intended not to require sanitizing plain text, such as; the HTML/XML requirement to replace ``<`` with ``&lt;`` and the like. :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` includes a symbolizing; filter via its ``--filter-markup`` option. Also, LLVM utilites emit stack; traces as markup when the ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` environment; variable is set. Scope and assumptions; =====================. A symbolizin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:1106,Testability,log,logging,1106,"ages that can be processed by a; symbolizing filter. The basic idea is that logging code emits text that contains; raw address values and so forth, without the logging code doing any real work to; convert those values to human-readable form. Instead, logging text uses the; markup format defined here to identify pieces of information that should be; converted to human-readable form after the fact. As with other markup formats,; the expectation is that most of the text will be displayed as is, while the; markup elements will be replaced with expanded text, or converted into active UI; elements, that present more details in symbolic form. This means there is no need for symbol tables, DWARF debugging sections, or; similar information to be directly accessible at runtime. There is also no need; at runtime for any logic intended to compute human-readable presentation of; information, such as C++ symbol demangling. Instead, logging must include markup; elements that give the contextual information necessary to make sense of the raw; data, such as memory layout details. This format identifies markup elements with a syntax that is both simple and; distinctive. It's simple enough to be matched and parsed with straightforward; code. It's distinctive enough that character sequences that look like the start; or end of a markup element should rarely if ever appear incidentally in logging; text. It's specifically intended not to require sanitizing plain text, such as; the HTML/XML requirement to replace ``<`` with ``&lt;`` and the like. :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` includes a symbolizing; filter via its ``--filter-markup`` option. Also, LLVM utilites emit stack; traces as markup when the ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` environment; variable is set. Scope and assumptions; =====================. A symbolizing filter implementation will be independent both of the target; operating system and machine architecture where the logs are generated and of; the host",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:1564,Testability,log,logging,1564,"information that should be; converted to human-readable form after the fact. As with other markup formats,; the expectation is that most of the text will be displayed as is, while the; markup elements will be replaced with expanded text, or converted into active UI; elements, that present more details in symbolic form. This means there is no need for symbol tables, DWARF debugging sections, or; similar information to be directly accessible at runtime. There is also no need; at runtime for any logic intended to compute human-readable presentation of; information, such as C++ symbol demangling. Instead, logging must include markup; elements that give the contextual information necessary to make sense of the raw; data, such as memory layout details. This format identifies markup elements with a syntax that is both simple and; distinctive. It's simple enough to be matched and parsed with straightforward; code. It's distinctive enough that character sequences that look like the start; or end of a markup element should rarely if ever appear incidentally in logging; text. It's specifically intended not to require sanitizing plain text, such as; the HTML/XML requirement to replace ``<`` with ``&lt;`` and the like. :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` includes a symbolizing; filter via its ``--filter-markup`` option. Also, LLVM utilites emit stack; traces as markup when the ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` environment; variable is set. Scope and assumptions; =====================. A symbolizing filter implementation will be independent both of the target; operating system and machine architecture where the logs are generated and of; the host operating system and machine architecture where the filter runs. This format assumes that the symbolizing filter processes intact whole lines. If; long lines might be split during some stage of a logging pipeline, they must be; reassembled to restore the original line breaks before feeding lines into the; symbolizing fi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:2140,Testability,log,logs,2140,"e markup; elements that give the contextual information necessary to make sense of the raw; data, such as memory layout details. This format identifies markup elements with a syntax that is both simple and; distinctive. It's simple enough to be matched and parsed with straightforward; code. It's distinctive enough that character sequences that look like the start; or end of a markup element should rarely if ever appear incidentally in logging; text. It's specifically intended not to require sanitizing plain text, such as; the HTML/XML requirement to replace ``<`` with ``&lt;`` and the like. :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` includes a symbolizing; filter via its ``--filter-markup`` option. Also, LLVM utilites emit stack; traces as markup when the ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` environment; variable is set. Scope and assumptions; =====================. A symbolizing filter implementation will be independent both of the target; operating system and machine architecture where the logs are generated and of; the host operating system and machine architecture where the filter runs. This format assumes that the symbolizing filter processes intact whole lines. If; long lines might be split during some stage of a logging pipeline, they must be; reassembled to restore the original line breaks before feeding lines into the; symbolizing filter. Most markup elements must appear entirely on a single line; (often with other text before and/or after the markup element). There are some; markup elements that are specified to span lines, with line breaks in the middle; of the element. Even in those cases, the filter is not expected to handle line; breaks in arbitrary places inside a markup element, but only inside certain; fields. This format assumes that the symbolizing filter processes a coherent stream of; log lines from a single process address space context. If a logging stream; interleaves log lines from more than one process, these must be collated into; s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:2372,Testability,log,logging,2372," code. It's distinctive enough that character sequences that look like the start; or end of a markup element should rarely if ever appear incidentally in logging; text. It's specifically intended not to require sanitizing plain text, such as; the HTML/XML requirement to replace ``<`` with ``&lt;`` and the like. :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` includes a symbolizing; filter via its ``--filter-markup`` option. Also, LLVM utilites emit stack; traces as markup when the ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` environment; variable is set. Scope and assumptions; =====================. A symbolizing filter implementation will be independent both of the target; operating system and machine architecture where the logs are generated and of; the host operating system and machine architecture where the filter runs. This format assumes that the symbolizing filter processes intact whole lines. If; long lines might be split during some stage of a logging pipeline, they must be; reassembled to restore the original line breaks before feeding lines into the; symbolizing filter. Most markup elements must appear entirely on a single line; (often with other text before and/or after the markup element). There are some; markup elements that are specified to span lines, with line breaks in the middle; of the element. Even in those cases, the filter is not expected to handle line; breaks in arbitrary places inside a markup element, but only inside certain; fields. This format assumes that the symbolizing filter processes a coherent stream of; log lines from a single process address space context. If a logging stream; interleaves log lines from more than one process, these must be collated into; separate per-process log streams and each stream processed by a separate; instance of the symbolizing filter. Because the kernel and user processes use; disjoint address regions in most operating systems, a single user process; address space plus the kernel address space can be treate",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:2970,Testability,log,log,2970,"e is set. Scope and assumptions; =====================. A symbolizing filter implementation will be independent both of the target; operating system and machine architecture where the logs are generated and of; the host operating system and machine architecture where the filter runs. This format assumes that the symbolizing filter processes intact whole lines. If; long lines might be split during some stage of a logging pipeline, they must be; reassembled to restore the original line breaks before feeding lines into the; symbolizing filter. Most markup elements must appear entirely on a single line; (often with other text before and/or after the markup element). There are some; markup elements that are specified to span lines, with line breaks in the middle; of the element. Even in those cases, the filter is not expected to handle line; breaks in arbitrary places inside a markup element, but only inside certain; fields. This format assumes that the symbolizing filter processes a coherent stream of; log lines from a single process address space context. If a logging stream; interleaves log lines from more than one process, these must be collated into; separate per-process log streams and each stream processed by a separate; instance of the symbolizing filter. Because the kernel and user processes use; disjoint address regions in most operating systems, a single user process; address space plus the kernel address space can be treated as a single address; space for symbolization purposes if desired. Dependence on Build IDs; =======================. The symbolizer markup scheme relies on contextual information about runtime; memory address layout to make it possible to convert markup elements into useful; symbolic form. This relies on having an unmistakable identification of which; binary was loaded at each address. An ELF Build ID is the payload of an ELF note with name ``""GNU""`` and type; ``NT_GNU_BUILD_ID``, a unique byte sequence that identifies a particular binary; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:3030,Testability,log,logging,3030," where the logs are generated and of; the host operating system and machine architecture where the filter runs. This format assumes that the symbolizing filter processes intact whole lines. If; long lines might be split during some stage of a logging pipeline, they must be; reassembled to restore the original line breaks before feeding lines into the; symbolizing filter. Most markup elements must appear entirely on a single line; (often with other text before and/or after the markup element). There are some; markup elements that are specified to span lines, with line breaks in the middle; of the element. Even in those cases, the filter is not expected to handle line; breaks in arbitrary places inside a markup element, but only inside certain; fields. This format assumes that the symbolizing filter processes a coherent stream of; log lines from a single process address space context. If a logging stream; interleaves log lines from more than one process, these must be collated into; separate per-process log streams and each stream processed by a separate; instance of the symbolizing filter. Because the kernel and user processes use; disjoint address regions in most operating systems, a single user process; address space plus the kernel address space can be treated as a single address; space for symbolization purposes if desired. Dependence on Build IDs; =======================. The symbolizer markup scheme relies on contextual information about runtime; memory address layout to make it possible to convert markup elements into useful; symbolic form. This relies on having an unmistakable identification of which; binary was loaded at each address. An ELF Build ID is the payload of an ELF note with name ``""GNU""`` and type; ``NT_GNU_BUILD_ID``, a unique byte sequence that identifies a particular binary; (executable, shared library, loadable module, or driver module). The linker; generates this automatically based on a hash that includes the complete symbol; table and debug",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:3058,Testability,log,log,3058," where the logs are generated and of; the host operating system and machine architecture where the filter runs. This format assumes that the symbolizing filter processes intact whole lines. If; long lines might be split during some stage of a logging pipeline, they must be; reassembled to restore the original line breaks before feeding lines into the; symbolizing filter. Most markup elements must appear entirely on a single line; (often with other text before and/or after the markup element). There are some; markup elements that are specified to span lines, with line breaks in the middle; of the element. Even in those cases, the filter is not expected to handle line; breaks in arbitrary places inside a markup element, but only inside certain; fields. This format assumes that the symbolizing filter processes a coherent stream of; log lines from a single process address space context. If a logging stream; interleaves log lines from more than one process, these must be collated into; separate per-process log streams and each stream processed by a separate; instance of the symbolizing filter. Because the kernel and user processes use; disjoint address regions in most operating systems, a single user process; address space plus the kernel address space can be treated as a single address; space for symbolization purposes if desired. Dependence on Build IDs; =======================. The symbolizer markup scheme relies on contextual information about runtime; memory address layout to make it possible to convert markup elements into useful; symbolic form. This relies on having an unmistakable identification of which; binary was loaded at each address. An ELF Build ID is the payload of an ELF note with name ``""GNU""`` and type; ``NT_GNU_BUILD_ID``, a unique byte sequence that identifies a particular binary; (executable, shared library, loadable module, or driver module). The linker; generates this automatically based on a hash that includes the complete symbol; table and debug",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:3146,Testability,log,log,3146," where the logs are generated and of; the host operating system and machine architecture where the filter runs. This format assumes that the symbolizing filter processes intact whole lines. If; long lines might be split during some stage of a logging pipeline, they must be; reassembled to restore the original line breaks before feeding lines into the; symbolizing filter. Most markup elements must appear entirely on a single line; (often with other text before and/or after the markup element). There are some; markup elements that are specified to span lines, with line breaks in the middle; of the element. Even in those cases, the filter is not expected to handle line; breaks in arbitrary places inside a markup element, but only inside certain; fields. This format assumes that the symbolizing filter processes a coherent stream of; log lines from a single process address space context. If a logging stream; interleaves log lines from more than one process, these must be collated into; separate per-process log streams and each stream processed by a separate; instance of the symbolizing filter. Because the kernel and user processes use; disjoint address regions in most operating systems, a single user process; address space plus the kernel address space can be treated as a single address; space for symbolization purposes if desired. Dependence on Build IDs; =======================. The symbolizer markup scheme relies on contextual information about runtime; memory address layout to make it possible to convert markup elements into useful; symbolic form. This relies on having an unmistakable identification of which; binary was loaded at each address. An ELF Build ID is the payload of an ELF note with name ``""GNU""`` and type; ``NT_GNU_BUILD_ID``, a unique byte sequence that identifies a particular binary; (executable, shared library, loadable module, or driver module). The linker; generates this automatically based on a hash that includes the complete symbol; table and debug",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:4308,Testability,log,log,4308,"ng systems, a single user process; address space plus the kernel address space can be treated as a single address; space for symbolization purposes if desired. Dependence on Build IDs; =======================. The symbolizer markup scheme relies on contextual information about runtime; memory address layout to make it possible to convert markup elements into useful; symbolic form. This relies on having an unmistakable identification of which; binary was loaded at each address. An ELF Build ID is the payload of an ELF note with name ``""GNU""`` and type; ``NT_GNU_BUILD_ID``, a unique byte sequence that identifies a particular binary; (executable, shared library, loadable module, or driver module). The linker; generates this automatically based on a hash that includes the complete symbol; table and debugging information, even if this is later stripped from the binary. This specification uses the ELF Build ID as the sole means of identifying; binaries. Each binary relevant to the log must have been linked with a unique; Build ID. The symbolizing filter must have some means of mapping a Build ID back; to the original ELF binary (either the whole unstripped binary, or a stripped; binary paired with a separate debug file). Colorization; ============. The markup format supports a restricted subset of ANSI X3.64 SGR (Select Graphic; Rendition) control sequences. These are unlike other markup elements:. * They specify presentation details (bold or colors) rather than semantic; information. The association of semantic meaning with color (e.g. red for; errors) is chosen by the code doing the logging, rather than by the UI; presentation of the symbolizing filter. This is a concession to existing code; (e.g. LLVM sanitizer runtimes) that use specific colors and would require; substantial changes to generate semantic markup instead. * A single control sequence changes ""the state"", rather than being an; hierarchical structure that surrounds affected text. The filter processes ANSI SG",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:4924,Testability,log,logging,4924,"s a particular binary; (executable, shared library, loadable module, or driver module). The linker; generates this automatically based on a hash that includes the complete symbol; table and debugging information, even if this is later stripped from the binary. This specification uses the ELF Build ID as the sole means of identifying; binaries. Each binary relevant to the log must have been linked with a unique; Build ID. The symbolizing filter must have some means of mapping a Build ID back; to the original ELF binary (either the whole unstripped binary, or a stripped; binary paired with a separate debug file). Colorization; ============. The markup format supports a restricted subset of ANSI X3.64 SGR (Select Graphic; Rendition) control sequences. These are unlike other markup elements:. * They specify presentation details (bold or colors) rather than semantic; information. The association of semantic meaning with color (e.g. red for; errors) is chosen by the code doing the logging, rather than by the UI; presentation of the symbolizing filter. This is a concession to existing code; (e.g. LLVM sanitizer runtimes) that use specific colors and would require; substantial changes to generate semantic markup instead. * A single control sequence changes ""the state"", rather than being an; hierarchical structure that surrounds affected text. The filter processes ANSI SGR control sequences only within a single line. If a; control sequence to enter a bold or color state is encountered, it's expected; that the control sequence to reset to default state will be encountered before; the end of that line. If a ""dangling"" state is left at the end of a line, the; filter may reset to default state for the next line. An SGR control sequence is not interpreted inside any other markup element.; However, other markup elements may appear between SGR control sequences and the; color/bold state is expected to apply to the symbolic output that replaces the; markup element in the filter's out",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:10909,Testability,log,logged,10909,"tion of each line. But it can appear; anywhere, so the filter should not remove any non-whitespace text surrounding; the element. Here ``%u`` is the frame number, which starts at zero for the location of the; fault being identified, increments to one for the caller of frame zero's call; frame, to two for the caller of frame one, etc. ``%p`` is the memory address; of a code location. Code locations in a backtrace come from two distinct sources. Most backtrace; frames describe a return address code location, i.e. the instruction; immediately after a call instruction. This is the location of code that has; yet to run, since the function called there has not yet returned. Hence the; code location of actual interest is usually the call site itself rather than; the return address, i.e. one instruction earlier. When presenting the source; location for a return address frame, the symbolizing filter will subtract one; byte or one instruction length from the actual return address for the call; site, with the intent that the address logged can be translated directly to a; source location for the call site and not for the apparent return site; thereafter (which can be confusing). When inlined functions are involved, the; call site and the return site can appear to be in different functions at; entirely unrelated source locations rather than just a line away, making the; confusion of showing the return site rather the call site quite severe. Often the first frame in a backtrace (""frame zero"") identifies the precise; code location of a fault, trap, or asynchronous interrupt rather than a return; address. At other times, even the first frame is actually a return address; (for example, backtraces collected at the time of an object allocation and; reported later when the allocated object is used or misused). When a system; supports in-thread trap handling, there may also be frames after the first; that represent a precise interrupted code location rather than a return; address, prese",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:14503,Testability,log,log,14503,"::. {{{bt:0:0x12345678:pc}}}; {{{bt:1:0xffffffff9abcdef0:ra}}}. ``{{{hexdict:...}}}`` [#not_yet_implemented]_. This element can span multiple lines. Here ``...`` is a sequence of key-value; pairs where a single ``:`` separates each key from its value, and arbitrary; whitespace separates the pairs. The value (right-hand side) of each pair; either is one or more ``0`` digits, or is ``0x`` followed by hexadecimal; digits. Each value might be a memory address or might be some other integer; (including an integer that looks like a likely memory address but actually has; an unrelated purpose). When the contextual information about the memory layout; suggests that a given value could be a code location or a global variable data; address, it might be presented as a source location or variable name or with; active UI that makes such interpretation optionally visible. The intended use is for things like register dumps, where the emitter doesn't; know which values might have a symbolic interpretation but a presentation that; makes plausible symbolic interpretations available might be very useful to; someone reading the log. At the same time, a flat text presentation should; usually avoid interfering too much with the original contents and formatting; of the dump. For example, it might use footnotes with source locations for; values that appear to be code locations. An active UI presentation might show; the dump text as is, but highlight values with symbolic information available; and pop up a presentation of symbolic details when a value is selected. Example::. {{{hexdict:; CS: 0 RIP: 0x6ee17076fb80 EFL: 0x10246 CR2: 0; RAX: 0xc53d0acbcf0 RBX: 0x1e659ea7e0d0 RCX: 0 RDX: 0x6ee1708300cc; RSI: 0 RDI: 0x6ee170830040 RBP: 0x3b13734898e0 RSP: 0x3b13734898d8; R8: 0x3b1373489860 R9: 0x2776ff4f R10: 0x2749d3e9a940 R11: 0x246; R12: 0x1e659ea7e0f0 R13: 0xd7231230fd6ff2e7 R14: 0x1e659ea7e108 R15: 0xc53d0acbcf0; }}}. Trigger elements; ================. These elements cause an external acti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:16216,Testability,log,logic,16216,"}}. Trigger elements; ================. These elements cause an external action and will be presented to the user in a; human readable form. Generally they trigger an external action to occur that; results in a linkable page. The link or some other informative information about; the external action can then be presented to the user. ``{{{dumpfile:%s:%s}}}`` [#not_yet_implemented]_. Here the first ``%s`` is an identifier for a type of dump and the second; ``%s`` is an identifier for a particular dump that's just been published. The; types of dumps, the exact meaning of ""published"", and the nature of the; identifier are outside the scope of the markup format per se. In general it; might correspond to writing a file by that name or something similar. This element may trigger additional post-processing work beyond symbolizing; the markup. It indicates that a dump file of some sort has been published.; Some logic attached to the symbolizing filter may understand certain types of; dump file and trigger additional post-processing of the dump file upon; encountering this element (e.g. generating visualizations, symbolization). The; expectation is that the information collected from contextual elements; (described below) in the logging stream may be necessary to decode the content; of the dump. So if the symbolizing filter triggers other processing, it may; need to feed some distilled form of the contextual information to those; processes. An example of a type identifier is ``sancov``, for dumps from LLVM; `SanitizerCoverage <https://clang.llvm.org/docs/SanitizerCoverage.html>`_. Example::. {{{dumpfile:sancov:sancov.8675}}}. Contextual elements; ===================. These are elements that supply information necessary to convert presentation; elements to symbolic form. Unlike presentation elements, they are not directly; related to the surrounding text. Contextual elements should appear alone on; lines with no other non-whitespace text, so that the symbolizing filter might; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:16539,Testability,log,logging,16539,"age. The link or some other informative information about; the external action can then be presented to the user. ``{{{dumpfile:%s:%s}}}`` [#not_yet_implemented]_. Here the first ``%s`` is an identifier for a type of dump and the second; ``%s`` is an identifier for a particular dump that's just been published. The; types of dumps, the exact meaning of ""published"", and the nature of the; identifier are outside the scope of the markup format per se. In general it; might correspond to writing a file by that name or something similar. This element may trigger additional post-processing work beyond symbolizing; the markup. It indicates that a dump file of some sort has been published.; Some logic attached to the symbolizing filter may understand certain types of; dump file and trigger additional post-processing of the dump file upon; encountering this element (e.g. generating visualizations, symbolization). The; expectation is that the information collected from contextual elements; (described below) in the logging stream may be necessary to decode the content; of the dump. So if the symbolizing filter triggers other processing, it may; need to feed some distilled form of the contextual information to those; processes. An example of a type identifier is ``sancov``, for dumps from LLVM; `SanitizerCoverage <https://clang.llvm.org/docs/SanitizerCoverage.html>`_. Example::. {{{dumpfile:sancov:sancov.8675}}}. Contextual elements; ===================. These are elements that supply information necessary to convert presentation; elements to symbolic form. Unlike presentation elements, they are not directly; related to the surrounding text. Contextual elements should appear alone on; lines with no other non-whitespace text, so that the symbolizing filter might; elide the whole line from its output without hiding any other log text. The contextual elements themselves do not necessarily need to be presented in; human-readable output. However, the information they impart may be ess",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:17362,Testability,log,log,17362,"ertain types of; dump file and trigger additional post-processing of the dump file upon; encountering this element (e.g. generating visualizations, symbolization). The; expectation is that the information collected from contextual elements; (described below) in the logging stream may be necessary to decode the content; of the dump. So if the symbolizing filter triggers other processing, it may; need to feed some distilled form of the contextual information to those; processes. An example of a type identifier is ``sancov``, for dumps from LLVM; `SanitizerCoverage <https://clang.llvm.org/docs/SanitizerCoverage.html>`_. Example::. {{{dumpfile:sancov:sancov.8675}}}. Contextual elements; ===================. These are elements that supply information necessary to convert presentation; elements to symbolic form. Unlike presentation elements, they are not directly; related to the surrounding text. Contextual elements should appear alone on; lines with no other non-whitespace text, so that the symbolizing filter might; elide the whole line from its output without hiding any other log text. The contextual elements themselves do not necessarily need to be presented in; human-readable output. However, the information they impart may be essential to; understanding the logging text even after symbolization. So it's recommended; that this information be preserved in some form when the original raw log with; markup may no longer be readily accessible for whatever reason. Contextual elements should appear in the logging stream before they are needed.; That is, if some piece of context may affect how the symbolizing filter would; interpret or present a later presentation element, the necessary contextual; elements should have appeared somewhere earlier in the logging stream. It should; always be possible for the symbolizing filter to be implemented as a single pass; over the raw logging stream, accumulating context and massaging text as it goes. ``{{{reset}}}``. This should be output",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:17550,Testability,log,logging,17550,") in the logging stream may be necessary to decode the content; of the dump. So if the symbolizing filter triggers other processing, it may; need to feed some distilled form of the contextual information to those; processes. An example of a type identifier is ``sancov``, for dumps from LLVM; `SanitizerCoverage <https://clang.llvm.org/docs/SanitizerCoverage.html>`_. Example::. {{{dumpfile:sancov:sancov.8675}}}. Contextual elements; ===================. These are elements that supply information necessary to convert presentation; elements to symbolic form. Unlike presentation elements, they are not directly; related to the surrounding text. Contextual elements should appear alone on; lines with no other non-whitespace text, so that the symbolizing filter might; elide the whole line from its output without hiding any other log text. The contextual elements themselves do not necessarily need to be presented in; human-readable output. However, the information they impart may be essential to; understanding the logging text even after symbolization. So it's recommended; that this information be preserved in some form when the original raw log with; markup may no longer be readily accessible for whatever reason. Contextual elements should appear in the logging stream before they are needed.; That is, if some piece of context may affect how the symbolizing filter would; interpret or present a later presentation element, the necessary contextual; elements should have appeared somewhere earlier in the logging stream. It should; always be possible for the symbolizing filter to be implemented as a single pass; over the raw logging stream, accumulating context and massaging text as it goes. ``{{{reset}}}``. This should be output before any other contextual element. The need for this; contextual element is to support implementations that handle logs coming from; multiple processes. Such implementations might not know when a new process; starts or ends. Because some identifying info",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:17680,Testability,log,log,17680," need to feed some distilled form of the contextual information to those; processes. An example of a type identifier is ``sancov``, for dumps from LLVM; `SanitizerCoverage <https://clang.llvm.org/docs/SanitizerCoverage.html>`_. Example::. {{{dumpfile:sancov:sancov.8675}}}. Contextual elements; ===================. These are elements that supply information necessary to convert presentation; elements to symbolic form. Unlike presentation elements, they are not directly; related to the surrounding text. Contextual elements should appear alone on; lines with no other non-whitespace text, so that the symbolizing filter might; elide the whole line from its output without hiding any other log text. The contextual elements themselves do not necessarily need to be presented in; human-readable output. However, the information they impart may be essential to; understanding the logging text even after symbolization. So it's recommended; that this information be preserved in some form when the original raw log with; markup may no longer be readily accessible for whatever reason. Contextual elements should appear in the logging stream before they are needed.; That is, if some piece of context may affect how the symbolizing filter would; interpret or present a later presentation element, the necessary contextual; elements should have appeared somewhere earlier in the logging stream. It should; always be possible for the symbolizing filter to be implemented as a single pass; over the raw logging stream, accumulating context and massaging text as it goes. ``{{{reset}}}``. This should be output before any other contextual element. The need for this; contextual element is to support implementations that handle logs coming from; multiple processes. Such implementations might not know when a new process; starts or ends. Because some identifying information (like process IDs) might; be the same between old and new processes, a way is needed to distinguish two; processes with such identic",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:17795,Testability,log,logging,17795,"ancov``, for dumps from LLVM; `SanitizerCoverage <https://clang.llvm.org/docs/SanitizerCoverage.html>`_. Example::. {{{dumpfile:sancov:sancov.8675}}}. Contextual elements; ===================. These are elements that supply information necessary to convert presentation; elements to symbolic form. Unlike presentation elements, they are not directly; related to the surrounding text. Contextual elements should appear alone on; lines with no other non-whitespace text, so that the symbolizing filter might; elide the whole line from its output without hiding any other log text. The contextual elements themselves do not necessarily need to be presented in; human-readable output. However, the information they impart may be essential to; understanding the logging text even after symbolization. So it's recommended; that this information be preserved in some form when the original raw log with; markup may no longer be readily accessible for whatever reason. Contextual elements should appear in the logging stream before they are needed.; That is, if some piece of context may affect how the symbolizing filter would; interpret or present a later presentation element, the necessary contextual; elements should have appeared somewhere earlier in the logging stream. It should; always be possible for the symbolizing filter to be implemented as a single pass; over the raw logging stream, accumulating context and massaging text as it goes. ``{{{reset}}}``. This should be output before any other contextual element. The need for this; contextual element is to support implementations that handle logs coming from; multiple processes. Such implementations might not know when a new process; starts or ends. Because some identifying information (like process IDs) might; be the same between old and new processes, a way is needed to distinguish two; processes with such identical identifying information. This element informs; such implementations to reset the state of a filter so that information ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:18046,Testability,log,logging,18046,"textual elements; ===================. These are elements that supply information necessary to convert presentation; elements to symbolic form. Unlike presentation elements, they are not directly; related to the surrounding text. Contextual elements should appear alone on; lines with no other non-whitespace text, so that the symbolizing filter might; elide the whole line from its output without hiding any other log text. The contextual elements themselves do not necessarily need to be presented in; human-readable output. However, the information they impart may be essential to; understanding the logging text even after symbolization. So it's recommended; that this information be preserved in some form when the original raw log with; markup may no longer be readily accessible for whatever reason. Contextual elements should appear in the logging stream before they are needed.; That is, if some piece of context may affect how the symbolizing filter would; interpret or present a later presentation element, the necessary contextual; elements should have appeared somewhere earlier in the logging stream. It should; always be possible for the symbolizing filter to be implemented as a single pass; over the raw logging stream, accumulating context and massaging text as it goes. ``{{{reset}}}``. This should be output before any other contextual element. The need for this; contextual element is to support implementations that handle logs coming from; multiple processes. Such implementations might not know when a new process; starts or ends. Because some identifying information (like process IDs) might; be the same between old and new processes, a way is needed to distinguish two; processes with such identical identifying information. This element informs; such implementations to reset the state of a filter so that information from a; previous process's contextual elements is not assumed for new process that; just happens have the same identifying information. ``{{{module:%i:%s:",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:18168,Testability,log,logging,18168,"ted to the surrounding text. Contextual elements should appear alone on; lines with no other non-whitespace text, so that the symbolizing filter might; elide the whole line from its output without hiding any other log text. The contextual elements themselves do not necessarily need to be presented in; human-readable output. However, the information they impart may be essential to; understanding the logging text even after symbolization. So it's recommended; that this information be preserved in some form when the original raw log with; markup may no longer be readily accessible for whatever reason. Contextual elements should appear in the logging stream before they are needed.; That is, if some piece of context may affect how the symbolizing filter would; interpret or present a later presentation element, the necessary contextual; elements should have appeared somewhere earlier in the logging stream. It should; always be possible for the symbolizing filter to be implemented as a single pass; over the raw logging stream, accumulating context and massaging text as it goes. ``{{{reset}}}``. This should be output before any other contextual element. The need for this; contextual element is to support implementations that handle logs coming from; multiple processes. Such implementations might not know when a new process; starts or ends. Because some identifying information (like process IDs) might; be the same between old and new processes, a way is needed to distinguish two; processes with such identical identifying information. This element informs; such implementations to reset the state of a filter so that information from a; previous process's contextual elements is not assumed for new process that; just happens have the same identifying information. ``{{{module:%i:%s:%s:...}}}``. This element represents a so-called ""module"". A ""module"" is a single linked; binary, such as a loaded ELF file. Usually each module occupies a contiguous; range of memory. Here ``%i`` is t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:18392,Testability,log,logs,18392,". The contextual elements themselves do not necessarily need to be presented in; human-readable output. However, the information they impart may be essential to; understanding the logging text even after symbolization. So it's recommended; that this information be preserved in some form when the original raw log with; markup may no longer be readily accessible for whatever reason. Contextual elements should appear in the logging stream before they are needed.; That is, if some piece of context may affect how the symbolizing filter would; interpret or present a later presentation element, the necessary contextual; elements should have appeared somewhere earlier in the logging stream. It should; always be possible for the symbolizing filter to be implemented as a single pass; over the raw logging stream, accumulating context and massaging text as it goes. ``{{{reset}}}``. This should be output before any other contextual element. The need for this; contextual element is to support implementations that handle logs coming from; multiple processes. Such implementations might not know when a new process; starts or ends. Because some identifying information (like process IDs) might; be the same between old and new processes, a way is needed to distinguish two; processes with such identical identifying information. This element informs; such implementations to reset the state of a filter so that information from a; previous process's contextual elements is not assumed for new process that; just happens have the same identifying information. ``{{{module:%i:%s:%s:...}}}``. This element represents a so-called ""module"". A ""module"" is a single linked; binary, such as a loaded ELF file. Usually each module occupies a contiguous; range of memory. Here ``%i`` is the module ID which is used by other contextual elements to; refer to this module. The first ``%s`` is a human-readable identifier for the; module, such as an ELF ``DT_SONAME`` string or a file name; but it might be; empty.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:1320,Usability,simpl,simple,1320,"ss values and so forth, without the logging code doing any real work to; convert those values to human-readable form. Instead, logging text uses the; markup format defined here to identify pieces of information that should be; converted to human-readable form after the fact. As with other markup formats,; the expectation is that most of the text will be displayed as is, while the; markup elements will be replaced with expanded text, or converted into active UI; elements, that present more details in symbolic form. This means there is no need for symbol tables, DWARF debugging sections, or; similar information to be directly accessible at runtime. There is also no need; at runtime for any logic intended to compute human-readable presentation of; information, such as C++ symbol demangling. Instead, logging must include markup; elements that give the contextual information necessary to make sense of the raw; data, such as memory layout details. This format identifies markup elements with a syntax that is both simple and; distinctive. It's simple enough to be matched and parsed with straightforward; code. It's distinctive enough that character sequences that look like the start; or end of a markup element should rarely if ever appear incidentally in logging; text. It's specifically intended not to require sanitizing plain text, such as; the HTML/XML requirement to replace ``<`` with ``&lt;`` and the like. :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` includes a symbolizing; filter via its ``--filter-markup`` option. Also, LLVM utilites emit stack; traces as markup when the ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` environment; variable is set. Scope and assumptions; =====================. A symbolizing filter implementation will be independent both of the target; operating system and machine architecture where the logs are generated and of; the host operating system and machine architecture where the filter runs. This format assumes that the symbolizing filter processes ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:1350,Usability,simpl,simple,1350,"hose values to human-readable form. Instead, logging text uses the; markup format defined here to identify pieces of information that should be; converted to human-readable form after the fact. As with other markup formats,; the expectation is that most of the text will be displayed as is, while the; markup elements will be replaced with expanded text, or converted into active UI; elements, that present more details in symbolic form. This means there is no need for symbol tables, DWARF debugging sections, or; similar information to be directly accessible at runtime. There is also no need; at runtime for any logic intended to compute human-readable presentation of; information, such as C++ symbol demangling. Instead, logging must include markup; elements that give the contextual information necessary to make sense of the raw; data, such as memory layout details. This format identifies markup elements with a syntax that is both simple and; distinctive. It's simple enough to be matched and parsed with straightforward; code. It's distinctive enough that character sequences that look like the start; or end of a markup element should rarely if ever appear incidentally in logging; text. It's specifically intended not to require sanitizing plain text, such as; the HTML/XML requirement to replace ``<`` with ``&lt;`` and the like. :doc:`llvm-symbolizer <CommandGuide/llvm-symbolizer>` includes a symbolizing; filter via its ``--filter-markup`` option. Also, LLVM utilites emit stack; traces as markup when the ``LLVM_ENABLE_SYMBOLIZER_MARKUP`` environment; variable is set. Scope and assumptions; =====================. A symbolizing filter implementation will be independent both of the target; operating system and machine architecture where the logs are generated and of; the host operating system and machine architecture where the filter runs. This format assumes that the symbolizing filter processes intact whole lines. If; long lines might be split during some stage of a logging ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:6741,Usability,simpl,simple,6741,"r markup element.; However, other markup elements may appear between SGR control sequences and the; color/bold state is expected to apply to the symbolic output that replaces the; markup element in the filter's output. The accepted SGR control sequences all have the form ``""\033[%um""`` (expressed here; using C string syntax), where ``%u`` is one of these:. ==== ============================ ===============================================; Code Effect Notes; ==== ============================ ===============================================; 0 Reset to default formatting.; 1 Bold text Combines with color states, doesn't reset them.; 30 Black foreground; 31 Red foreground; 32 Green foreground; 33 Yellow foreground; 34 Blue foreground; 35 Magenta foreground; 36 Cyan foreground; 37 White foreground; ==== ============================ ===============================================. Common markup element syntax; ============================. All the markup elements share a common syntactic structure to facilitate simple; matching and parsing code. Each element has the form::. {{{tag:fields}}}. ``tag`` identifies one of the element types described below, and is always a; short alphabetic string that must be in lower case. The rest of the element; consists of one or more fields. Fields are separated by ``:`` and cannot contain; any ``:`` or ``}`` characters. How many fields must be or may be present and; what they contain is specified for each element type. No markup elements or ANSI SGR control sequences are interpreted inside the; contents of a field. Implementations must ignore markup fields after those expected; this allows; adding new fields to backwards-compatibly extend elements. Implementations need; not ignore them silently, but the element should behave otherwise as if the; fields were removed. In the descriptions of each element type, ``printf``-style placeholders indicate; field contents:. ``%s``; A string of printable characters, not including ``:`` or ``}``. ``%p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:12159,Usability,simpl,simple,12159,"nrelated source locations rather than just a line away, making the; confusion of showing the return site rather the call site quite severe. Often the first frame in a backtrace (""frame zero"") identifies the precise; code location of a fault, trap, or asynchronous interrupt rather than a return; address. At other times, even the first frame is actually a return address; (for example, backtraces collected at the time of an object allocation and; reported later when the allocated object is used or misused). When a system; supports in-thread trap handling, there may also be frames after the first; that represent a precise interrupted code location rather than a return; address, presented as the ""caller"" of a trap handler function (for example,; signal handlers in POSIX systems). Return address frames are identified by the ``:ra`` suffix. Precise code; location frames are identified by the ``:pc`` suffix. Traditional practice has often been to collect backtraces as simple address; lists, losing the distinction between return address code locations and; precise code locations. Some such code applies the ""subtract one"" adjustment; described above to the address values before reporting them, and it's not; always clear or consistent whether this adjustment has been applied or not.; These ambiguous cases are supported by the ``bt`` and ``pc`` forms with no; ``:ra`` or ``:pc`` suffix, which indicate it's unclear which sort of code; location this is. However, it's highly recommended that all emitters use the; suffixed forms and deliver address values with no adjustments applied. When; traditional practice has been ambiguous, the majority of cases seem to have; been of printing addresses that are return address code locations and printing; them without adjustment. So the symbolizing filter will usually apply the; ""subtract one byte"" adjustment to an address printed without a disambiguating; suffix. Assuming that a call instruction is longer than one byte on all; supported machin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst:12408,Usability,clear,clear,12408,""") identifies the precise; code location of a fault, trap, or asynchronous interrupt rather than a return; address. At other times, even the first frame is actually a return address; (for example, backtraces collected at the time of an object allocation and; reported later when the allocated object is used or misused). When a system; supports in-thread trap handling, there may also be frames after the first; that represent a precise interrupted code location rather than a return; address, presented as the ""caller"" of a trap handler function (for example,; signal handlers in POSIX systems). Return address frames are identified by the ``:ra`` suffix. Precise code; location frames are identified by the ``:pc`` suffix. Traditional practice has often been to collect backtraces as simple address; lists, losing the distinction between return address code locations and; precise code locations. Some such code applies the ""subtract one"" adjustment; described above to the address values before reporting them, and it's not; always clear or consistent whether this adjustment has been applied or not.; These ambiguous cases are supported by the ``bt`` and ``pc`` forms with no; ``:ra`` or ``:pc`` suffix, which indicate it's unclear which sort of code; location this is. However, it's highly recommended that all emitters use the; suffixed forms and deliver address values with no adjustments applied. When; traditional practice has been ambiguous, the majority of cases seem to have; been of printing addresses that are return address code locations and printing; them without adjustment. So the symbolizing filter will usually apply the; ""subtract one byte"" adjustment to an address printed without a disambiguating; suffix. Assuming that a call instruction is longer than one byte on all; supported machines, applying the ""subtract one byte"" adjustment a second time; still results in an address somewhere in the call instruction, so a little; sloppiness here often does little or no harm. Examp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SymbolizerMarkupFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SystemLibrary.rst:137,Availability,avail,available,137,"==============; System Library; ==============. Moved; =====. The System Library has been renamed to Support Library with documentation; available at :doc:`SupportLibrary`. Please, change your links to that page.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/SystemLibrary.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/SystemLibrary.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGenFundamentals.rst:171,Availability,avail,available,171,"=====================; TableGen Fundamentals; =====================. Moved; =====. The TableGen fundamentals documentation has moved to a directory on its own; and is now available at :doc:`TableGen/index`. Please, change your links to; that page.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TableGenFundamentals.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TableGenFundamentals.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:8419,Availability,error,error,8419," but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; executes to run the test case. The syntax of the RUN lines is similar to a; shell's syntax for pipelines including I/O redirection and variable; substitution. However, even though these lines may *look* like a shell; script, they are not. RUN lines are interpreted by :program:`lit`.; Consequently, the syntax differs from shell in a few ways. You can specify; as many RUN lines as needed. :program:`lit` performs substitution on each RUN line to replace LLVM tool names; with the full paths to the executable built for each tool (in; ``$(LLVM_OBJ_ROOT)/bin``). This ensures that :program:`lit` does; not invoke any stray LLVM tools in the user's path during testing. Each RUN line is executed on its own, distinct from other lines unless; i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11375,Availability,avail,available,11375," quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:17058,Availability,down,download,17058,"ident = !{!0}; !0 = metadata !{metadata !""Compiler V3""}. For symmetry reasons, ``ident.ll`` is just a dummy file that doesn't; actually participate in the test besides holding the ``RUN:`` lines. .. note::. Some existing tests use ``RUN: true`` in extra files instead of just; putting the extra files in an ``Inputs/`` directory. This pattern is; deprecated. Fragile tests; -------------. It is easy to write a fragile test that would fail spuriously if the tool being; tested outputs a full path to the input file. For example, :program:`opt` by; default outputs a ``ModuleID``:. .. code-block:: console. $ cat example.ll; define i32 @main() nounwind {; ret i32 0; }. $ opt -S /path/to/example.ll; ; ModuleID = '/path/to/example.ll'. define i32 @main() nounwind {; ret i32 0; }. ``ModuleID`` can unexpectedly match against ``CHECK`` lines. For example:. .. code-block:: llvm. ; RUN: opt -S %s | FileCheck. define i32 @main() nounwind {; ; CHECK-NOT: load; ret i32 0; }. This test will fail if placed into a ``download`` directory. To make your tests robust, always use ``opt ... < %s`` in the RUN line.; :program:`opt` does not output a ``ModuleID`` when input comes from stdin. Platform-Specific Tests; -----------------------. Whenever adding tests that require the knowledge of a specific platform,; either related to code generated, specific output or back-end features,; you must make sure to isolate the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:17099,Availability,robust,robust,17099,"}. For symmetry reasons, ``ident.ll`` is just a dummy file that doesn't; actually participate in the test besides holding the ``RUN:`` lines. .. note::. Some existing tests use ``RUN: true`` in extra files instead of just; putting the extra files in an ``Inputs/`` directory. This pattern is; deprecated. Fragile tests; -------------. It is easy to write a fragile test that would fail spuriously if the tool being; tested outputs a full path to the input file. For example, :program:`opt` by; default outputs a ``ModuleID``:. .. code-block:: console. $ cat example.ll; define i32 @main() nounwind {; ret i32 0; }. $ opt -S /path/to/example.ll; ; ModuleID = '/path/to/example.ll'. define i32 @main() nounwind {; ret i32 0; }. ``ModuleID`` can unexpectedly match against ``CHECK`` lines. For example:. .. code-block:: llvm. ; RUN: opt -S %s | FileCheck. define i32 @main() nounwind {; ; CHECK-NOT: load; ret i32 0; }. This test will fail if placed into a ``download`` directory. To make your tests robust, always use ``opt ... < %s`` in the RUN line.; :program:`opt` does not output a ``ModuleID`` when input comes from stdin. Platform-Specific Tests; -----------------------. Whenever adding tests that require the knowledge of a specific platform,; either related to code generated, specific output or back-end features,; you must make sure to isolate the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:18296,Availability,avail,available,18296,"stdin. Platform-Specific Tests; -----------------------. Whenever adding tests that require the knowledge of a specific platform,; either related to code generated, specific output or back-end features,; you must make sure to isolate the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you'",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:19873,Availability,failure,failure,19873,"c -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:19959,Availability,failure,failure,19959,"x2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:22614,Availability,failure,failure,22614,"xpected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, and ``UNSUPPORTED`` to exclude cases where; the test is expected never to work. **``UNSUPPORTED`` and ``XFAIL``**. Both of these indicate that the test isn't expected to work; however, they; have different effects. ``UNSUPPORTED`` causes the test to be skipped;; this saves execution time, but then you'll never know whether the test; actually would start working. Conversely, ``XFAIL`` actually runs the test; but expects a failure output, taking extra execution time but alerting you; if/when the test begins to behave correctly (an XPASS test result). You; need to decide which is more appropriate in each case. **Using ``target=...``**. Checking the target triple can be tricky; it's easy to mis-specify. For; example, ``target=mips{{.*}}`` will match not only mips, but also mipsel,; mips64, and mips64el. ``target={{.*}}-linux-gnu`` will match; x86_64-unknown-linux-gnu, but not armv8l-unknown-linux-gnueabihf.; Prefer to use hyphens to delimit triple components (``target=mips-{{.*}}``); and it's generally a good idea to use a trailing wildcard to allow for; unexpected suffixes. Also, it's generally better to write regular expressions that use entire; triple components, than to do something clever to shorten them. For; example, to match both freebsd and netbsd in an expression, you could write; ``target={{.*(free|net)bsd.*}}`` and that would work. However, it would; prevent a ``grep freebsd`` from finding this test. Better to use:; ``target={{",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:26197,Availability,error,error,26197,"`` or ``\`` on Windows. ``%/s, %/S, %/t, %/T``. Act like the corresponding substitution above but replace any ``\``; character with a ``/``. This is useful to normalize path separators. Example: ``%s: C:\Desktop Files/foo_test.s.tmp``. Example: ``%/s: C:/Desktop Files/foo_test.s.tmp``. ``%{s:real}, %{S:real}, %{t:real}, %{T:real}``; ``%{/s:real}, %{/S:real}, %{/t:real}, %{/T:real}``. Act like the corresponding substitution, including with ``/``, but use; the real path by expanding all symbolic links and substitute drives. Example: ``%s: S:\foo_test.s.tmp``. Example: ``%{/s:real}: C:/SDrive/foo_test.s.tmp``. ``%:s, %:S, %:t, %:T``. Act like the corresponding substitution above but remove colons at; the beginning of Windows paths. This is useful to allow concatenation; of absolute paths on Windows to produce a legal path. Example: ``%s: C:\Desktop Files\foo_test.s.tmp``. Example: ``%:s: C\Desktop Files\foo_test.s.tmp``. ``%errc_<ERRCODE>``. Some error messages may be substituted to allow different spellings; based on the host platform. The following error codes are currently supported:; ENOENT, EISDIR, EINVAL, EACCES. Example: ``Linux %errc_ENOENT: No such file or directory``. Example: ``Windows %errc_ENOENT: no such file or directory``. ``%if feature %{<if branch>%} %else %{<else branch>%}``. Conditional substitution: if ``feature`` is available it expands to; ``<if branch>``, otherwise it expands to ``<else branch>``.; ``%else %{<else branch>%}`` is optional and treated like ``%else %{%}``; if not present. ``%(line)``, ``%(line+<number>)``, ``%(line-<number>)``. The number of the line where this substitution is used, with an; optional integer offset. These expand only if they appear; immediately in ``RUN:``, ``DEFINE:``, and ``REDEFINE:`` directives.; Occurrences in substitutions defined elsewhere are never expanded.; For example, this can be used in tests with multiple RUN lines,; which reference the test file's line numbers. **LLVM-specific substitutions:**. ``%shl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:26303,Availability,error,error,26303,"ve but replace any ``\``; character with a ``/``. This is useful to normalize path separators. Example: ``%s: C:\Desktop Files/foo_test.s.tmp``. Example: ``%/s: C:/Desktop Files/foo_test.s.tmp``. ``%{s:real}, %{S:real}, %{t:real}, %{T:real}``; ``%{/s:real}, %{/S:real}, %{/t:real}, %{/T:real}``. Act like the corresponding substitution, including with ``/``, but use; the real path by expanding all symbolic links and substitute drives. Example: ``%s: S:\foo_test.s.tmp``. Example: ``%{/s:real}: C:/SDrive/foo_test.s.tmp``. ``%:s, %:S, %:t, %:T``. Act like the corresponding substitution above but remove colons at; the beginning of Windows paths. This is useful to allow concatenation; of absolute paths on Windows to produce a legal path. Example: ``%s: C:\Desktop Files\foo_test.s.tmp``. Example: ``%:s: C\Desktop Files\foo_test.s.tmp``. ``%errc_<ERRCODE>``. Some error messages may be substituted to allow different spellings; based on the host platform. The following error codes are currently supported:; ENOENT, EISDIR, EINVAL, EACCES. Example: ``Linux %errc_ENOENT: No such file or directory``. Example: ``Windows %errc_ENOENT: no such file or directory``. ``%if feature %{<if branch>%} %else %{<else branch>%}``. Conditional substitution: if ``feature`` is available it expands to; ``<if branch>``, otherwise it expands to ``<else branch>``.; ``%else %{<else branch>%}`` is optional and treated like ``%else %{%}``; if not present. ``%(line)``, ``%(line+<number>)``, ``%(line-<number>)``. The number of the line where this substitution is used, with an; optional integer offset. These expand only if they appear; immediately in ``RUN:``, ``DEFINE:``, and ``REDEFINE:`` directives.; Occurrences in substitutions defined elsewhere are never expanded.; For example, this can be used in tests with multiple RUN lines,; which reference the test file's line numbers. **LLVM-specific substitutions:**. ``%shlibext``; The suffix for the host platforms shared library files. This includes the; period",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:26596,Availability,avail,available,26596,"T:real}``. Act like the corresponding substitution, including with ``/``, but use; the real path by expanding all symbolic links and substitute drives. Example: ``%s: S:\foo_test.s.tmp``. Example: ``%{/s:real}: C:/SDrive/foo_test.s.tmp``. ``%:s, %:S, %:t, %:T``. Act like the corresponding substitution above but remove colons at; the beginning of Windows paths. This is useful to allow concatenation; of absolute paths on Windows to produce a legal path. Example: ``%s: C:\Desktop Files\foo_test.s.tmp``. Example: ``%:s: C\Desktop Files\foo_test.s.tmp``. ``%errc_<ERRCODE>``. Some error messages may be substituted to allow different spellings; based on the host platform. The following error codes are currently supported:; ENOENT, EISDIR, EINVAL, EACCES. Example: ``Linux %errc_ENOENT: No such file or directory``. Example: ``Windows %errc_ENOENT: no such file or directory``. ``%if feature %{<if branch>%} %else %{<else branch>%}``. Conditional substitution: if ``feature`` is available it expands to; ``<if branch>``, otherwise it expands to ``<else branch>``.; ``%else %{<else branch>%}`` is optional and treated like ``%else %{%}``; if not present. ``%(line)``, ``%(line+<number>)``, ``%(line-<number>)``. The number of the line where this substitution is used, with an; optional integer offset. These expand only if they appear; immediately in ``RUN:``, ``DEFINE:``, and ``REDEFINE:`` directives.; Occurrences in substitutions defined elsewhere are never expanded.; For example, this can be used in tests with multiple RUN lines,; which reference the test file's line numbers. **LLVM-specific substitutions:**. ``%shlibext``; The suffix for the host platforms shared library files. This includes the; period as the first character. Example: ``.so`` (Linux), ``.dylib`` (macOS), ``.dll`` (Windows). ``%exeext``; The suffix for the host platforms executable files. This includes the; period as the first character. Example: ``.exe`` (Windows), empty on Linux. **Clang-specific substitutions:**. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:32673,Availability,error,error,32673," passes through the substitution list by; setting `recursiveExpansionLimit`_ in a lit configuration file.); - While lit configuration files can insert anywhere in the substitution list,; the insertion behavior of the ``DEFINE:`` and ``REDEFINE:`` directives is; specified below and is designed specifically for the use case presented in the; example above.; - Defining a substitution in terms of itself, whether directly or via other; substitutions, should be avoided. It usually produces an infinitely recursive; definition that cannot be fully expanded. It does *not* define the; substitution in terms of its previous value, even when using ``REDEFINE:``. The relationship between the ``DEFINE:`` and ``REDEFINE:`` directive is; analogous to the relationship between a variable declaration and variable; assignment in many programming languages:. - ``DEFINE: %{name} = value``. This directive assigns the specified value to a new substitution whose; pattern is ``%{name}``, or it reports an error if there is already a; substitution whose pattern contains ``%{name}`` because that could produce; confusing expansions (e.g., a lit configuration file might define a; substitution with the pattern ``%{name}\[0\]``). The new substitution is; inserted at the start of the substitution list so that it will expand first.; Thus, its value can contain any substitution previously defined, whether in; the same test file or in a lit configuration file, and both will expand. - ``REDEFINE: %{name} = value``. This directive assigns the specified value to an existing substitution whose; pattern is ``%{name}``, or it reports an error if there are no substitutions; with that pattern or if there are multiple substitutions whose patterns; contain ``%{name}``. The substitution's current position in the substitution; list does not change so that expansion order relative to other existing; substitutions is preserved. The following properties apply to both the ``DEFINE:`` and ``REDEFINE:``; directives:. - **",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:33301,Availability,error,error,33301," even when using ``REDEFINE:``. The relationship between the ``DEFINE:`` and ``REDEFINE:`` directive is; analogous to the relationship between a variable declaration and variable; assignment in many programming languages:. - ``DEFINE: %{name} = value``. This directive assigns the specified value to a new substitution whose; pattern is ``%{name}``, or it reports an error if there is already a; substitution whose pattern contains ``%{name}`` because that could produce; confusing expansions (e.g., a lit configuration file might define a; substitution with the pattern ``%{name}\[0\]``). The new substitution is; inserted at the start of the substitution list so that it will expand first.; Thus, its value can contain any substitution previously defined, whether in; the same test file or in a lit configuration file, and both will expand. - ``REDEFINE: %{name} = value``. This directive assigns the specified value to an existing substitution whose; pattern is ``%{name}``, or it reports an error if there are no substitutions; with that pattern or if there are multiple substitutions whose patterns; contain ``%{name}``. The substitution's current position in the substitution; list does not change so that expansion order relative to other existing; substitutions is preserved. The following properties apply to both the ``DEFINE:`` and ``REDEFINE:``; directives:. - **Substitution name**: In the directive, whitespace immediately before or; after ``%{name}`` is optional and discarded. ``%{name}`` must start with; ``%{``, it must end with ``}``, and the rest must start with a letter or; underscore and contain only alphanumeric characters, hyphens, underscores, and; colons. This syntax has a few advantages:. - It is impossible for ``%{name}`` to contain sequences that are special in; python's ``re.sub`` patterns. Otherwise, attempting to specify; ``%{name}`` as a substitution pattern in a lit configuration file could; produce confusing expansions.; - The braces help avoid the possibil",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:35140,Availability,error,error,35140,"empting to specify; ``%{name}`` as a substitution pattern in a lit configuration file could; produce confusing expansions.; - The braces help avoid the possibility that another substitution's pattern; will match part of ``%{name}`` or vice-versa, producing confusing; expansions. However, the patterns of substitutions defined by lit; configuration files and by lit itself are not restricted to this form, so; overlaps are still theoretically possible. - **Substitution value**: The value includes all text from the first; non-whitespace character after ``=`` to the last non-whitespace character. If; there is no non-whitespace character after ``=``, the value is the empty; string. Escape sequences that can appear in python ``re.sub`` replacement; strings are treated as plain text in the value.; - **Line continuations**: If the last non-whitespace character on the line after; ``:`` is ``\``, then the next directive must use the same directive keyword; (e.g., ``DEFINE:``) , and it is an error if there is no additional directive.; That directive serves as a continuation. That is, before following the rules; above to parse the text after ``:`` in either directive, lit joins that text; together to form a single directive, replaces the ``\`` with a single space,; and removes any other whitespace that is now adjacent to that space. A; continuation can be continued in the same manner. A continuation containing; only whitespace after its ``:`` is an error. .. _recursiveExpansionLimit:. **recursiveExpansionLimit:**. As described in the previous section, when expanding substitutions in a ``RUN:``; line, lit makes only one pass through the substitution list by default. Thus,; if substitutions are not defined in the proper order, some will remain in the; ``RUN:`` line unexpanded. For example, the following directives refer to; ``%{inner}`` within ``%{outer}`` but do not define ``%{inner}`` until after; ``%{outer}``:. .. code-block:: llvm. ; By default, this definition order does not e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:35605,Availability,error,error,35605,"theoretically possible. - **Substitution value**: The value includes all text from the first; non-whitespace character after ``=`` to the last non-whitespace character. If; there is no non-whitespace character after ``=``, the value is the empty; string. Escape sequences that can appear in python ``re.sub`` replacement; strings are treated as plain text in the value.; - **Line continuations**: If the last non-whitespace character on the line after; ``:`` is ``\``, then the next directive must use the same directive keyword; (e.g., ``DEFINE:``) , and it is an error if there is no additional directive.; That directive serves as a continuation. That is, before following the rules; above to parse the text after ``:`` in either directive, lit joins that text; together to form a single directive, replaces the ``\`` with a single space,; and removes any other whitespace that is now adjacent to that space. A; continuation can be continued in the same manner. A continuation containing; only whitespace after its ``:`` is an error. .. _recursiveExpansionLimit:. **recursiveExpansionLimit:**. As described in the previous section, when expanding substitutions in a ``RUN:``; line, lit makes only one pass through the substitution list by default. Thus,; if substitutions are not defined in the proper order, some will remain in the; ``RUN:`` line unexpanded. For example, the following directives refer to; ``%{inner}`` within ``%{outer}`` but do not define ``%{inner}`` until after; ``%{outer}``:. .. code-block:: llvm. ; By default, this definition order does not enable full expansion. ; DEFINE: %{outer} = %{inner}; ; DEFINE: %{inner} = expanded. ; RUN: echo '%{outer}'. ``DEFINE:`` inserts substitutions at the start of the substitution list, so; ``%{inner}`` expands first but has no effect because the original ``RUN:`` line; does not contain ``%{inner}``. Next, ``%{outer}`` expands, and the output of; the ``echo`` command becomes:. .. code-block:: shell. %{inner}. Of course, one way to",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:36237,Availability,echo,echo,36237,"following the rules; above to parse the text after ``:`` in either directive, lit joins that text; together to form a single directive, replaces the ``\`` with a single space,; and removes any other whitespace that is now adjacent to that space. A; continuation can be continued in the same manner. A continuation containing; only whitespace after its ``:`` is an error. .. _recursiveExpansionLimit:. **recursiveExpansionLimit:**. As described in the previous section, when expanding substitutions in a ``RUN:``; line, lit makes only one pass through the substitution list by default. Thus,; if substitutions are not defined in the proper order, some will remain in the; ``RUN:`` line unexpanded. For example, the following directives refer to; ``%{inner}`` within ``%{outer}`` but do not define ``%{inner}`` until after; ``%{outer}``:. .. code-block:: llvm. ; By default, this definition order does not enable full expansion. ; DEFINE: %{outer} = %{inner}; ; DEFINE: %{inner} = expanded. ; RUN: echo '%{outer}'. ``DEFINE:`` inserts substitutions at the start of the substitution list, so; ``%{inner}`` expands first but has no effect because the original ``RUN:`` line; does not contain ``%{inner}``. Next, ``%{outer}`` expands, and the output of; the ``echo`` command becomes:. .. code-block:: shell. %{inner}. Of course, one way to fix this simple case is to reverse the definitions of; ``%{outer}`` and ``%{inner}``. However, if a test has a complex set of; substitutions that can all reference each other, there might not exist a; sufficient substitution order. To address such use cases, lit configuration files support; ``config.recursiveExpansionLimit``, which can be set to a non-negative integer; to specify the maximum number of passes through the substitution list. Thus, in; the above example, setting the limit to 2 would cause lit to make a second pass; that expands ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. exp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:36496,Availability,echo,echo,36496,"pace. A; continuation can be continued in the same manner. A continuation containing; only whitespace after its ``:`` is an error. .. _recursiveExpansionLimit:. **recursiveExpansionLimit:**. As described in the previous section, when expanding substitutions in a ``RUN:``; line, lit makes only one pass through the substitution list by default. Thus,; if substitutions are not defined in the proper order, some will remain in the; ``RUN:`` line unexpanded. For example, the following directives refer to; ``%{inner}`` within ``%{outer}`` but do not define ``%{inner}`` until after; ``%{outer}``:. .. code-block:: llvm. ; By default, this definition order does not enable full expansion. ; DEFINE: %{outer} = %{inner}; ; DEFINE: %{inner} = expanded. ; RUN: echo '%{outer}'. ``DEFINE:`` inserts substitutions at the start of the substitution list, so; ``%{inner}`` expands first but has no effect because the original ``RUN:`` line; does not contain ``%{inner}``. Next, ``%{outer}`` expands, and the output of; the ``echo`` command becomes:. .. code-block:: shell. %{inner}. Of course, one way to fix this simple case is to reverse the definitions of; ``%{outer}`` and ``%{inner}``. However, if a test has a complex set of; substitutions that can all reference each other, there might not exist a; sufficient substitution order. To address such use cases, lit configuration files support; ``config.recursiveExpansionLimit``, which can be set to a non-negative integer; to specify the maximum number of passes through the substitution list. Thus, in; the above example, setting the limit to 2 would cause lit to make a second pass; that expands ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. expanded. To improve performance, lit will stop making passes when it notices the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:37184,Availability,echo,echo,37184,"is definition order does not enable full expansion. ; DEFINE: %{outer} = %{inner}; ; DEFINE: %{inner} = expanded. ; RUN: echo '%{outer}'. ``DEFINE:`` inserts substitutions at the start of the substitution list, so; ``%{inner}`` expands first but has no effect because the original ``RUN:`` line; does not contain ``%{inner}``. Next, ``%{outer}`` expands, and the output of; the ``echo`` command becomes:. .. code-block:: shell. %{inner}. Of course, one way to fix this simple case is to reverse the definitions of; ``%{outer}`` and ``%{inner}``. However, if a test has a complex set of; substitutions that can all reference each other, there might not exist a; sufficient substitution order. To address such use cases, lit configuration files support; ``config.recursiveExpansionLimit``, which can be set to a non-negative integer; to specify the maximum number of passes through the substitution list. Thus, in; the above example, setting the limit to 2 would cause lit to make a second pass; that expands ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. expanded. To improve performance, lit will stop making passes when it notices the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm tool name with a custom command line. This; allows to specify custom paths and default arguments for these tools.; Example:. % llvm-lit ""-Dllc=llc -verify-machineinstrs"". ``run_long_tests``; Enable the execution of long running tests. ``llvm_site_config``; Load the specifi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:37525,Availability,error,error,37525,"cho`` command becomes:. .. code-block:: shell. %{inner}. Of course, one way to fix this simple case is to reverse the definitions of; ``%{outer}`` and ``%{inner}``. However, if a test has a complex set of; substitutions that can all reference each other, there might not exist a; sufficient substitution order. To address such use cases, lit configuration files support; ``config.recursiveExpansionLimit``, which can be set to a non-negative integer; to specify the maximum number of passes through the substitution list. Thus, in; the above example, setting the limit to 2 would cause lit to make a second pass; that expands ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. expanded. To improve performance, lit will stop making passes when it notices the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm tool name with a custom command line. This; allows to specify custom paths and default arguments for these tools.; Example:. % llvm-lit ""-Dllc=llc -verify-machineinstrs"". ``run_long_tests``; Enable the execution of long running tests. ``llvm_site_config``; Load the specified lit configuration instead of the default one. Other Features; --------------. To make RUN line writing easier, there are several helper programs. These; helpers are in the PATH when running tests, so you can just call them using; their name. For example:. ``not``; This program runs its arguments and then inverts the result code from it.; Zero result codes become 1. Non-zero re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:37646,Availability,error,error,37646,"f; ``%{outer}`` and ``%{inner}``. However, if a test has a complex set of; substitutions that can all reference each other, there might not exist a; sufficient substitution order. To address such use cases, lit configuration files support; ``config.recursiveExpansionLimit``, which can be set to a non-negative integer; to specify the maximum number of passes through the substitution list. Thus, in; the above example, setting the limit to 2 would cause lit to make a second pass; that expands ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. expanded. To improve performance, lit will stop making passes when it notices the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm tool name with a custom command line. This; allows to specify custom paths and default arguments for these tools.; Example:. % llvm-lit ""-Dllc=llc -verify-machineinstrs"". ``run_long_tests``; Enable the execution of long running tests. ``llvm_site_config``; Load the specified lit configuration instead of the default one. Other Features; --------------. To make RUN line writing easier, there are several helper programs. These; helpers are in the PATH when running tests, so you can just call them using; their name. For example:. ``not``; This program runs its arguments and then inverts the result code from it.; Zero result codes become 1. Non-zero result codes become 0. To make the output more useful, :program:`lit` will scan; the lines of the test case for ones that contain a p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:5369,Deployability,release,release,5369," is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:6352,Deployability,install,installed,6352,"uild LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:6404,Deployability,install,install,6404,"AKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:6471,Deployability,install,install,6471,"lvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:6520,Deployability,install,install,6520,"lvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:8580,Deployability,pipeline,pipeline,8580,"est/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; executes to run the test case. The syntax of the RUN lines is similar to a; shell's syntax for pipelines including I/O redirection and variable; substitution. However, even though these lines may *look* like a shell; script, they are not. RUN lines are interpreted by :program:`lit`.; Consequently, the syntax differs from shell in a few ways. You can specify; as many RUN lines as needed. :program:`lit` performs substitution on each RUN line to replace LLVM tool names; with the full paths to the executable built for each tool (in; ``$(LLVM_OBJ_ROOT)/bin``). This ensures that :program:`lit` does; not invoke any stray LLVM tools in the user's path during testing. Each RUN line is executed on its own, distinct from other lines unless; its last character is ``\``. This continuation character causes the RUN; line to be concatenated with the next one. In th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:8759,Deployability,pipeline,pipelines,8759,"le to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; executes to run the test case. The syntax of the RUN lines is similar to a; shell's syntax for pipelines including I/O redirection and variable; substitution. However, even though these lines may *look* like a shell; script, they are not. RUN lines are interpreted by :program:`lit`.; Consequently, the syntax differs from shell in a few ways. You can specify; as many RUN lines as needed. :program:`lit` performs substitution on each RUN line to replace LLVM tool names; with the full paths to the executable built for each tool (in; ``$(LLVM_OBJ_ROOT)/bin``). This ensures that :program:`lit` does; not invoke any stray LLVM tools in the user's path during testing. Each RUN line is executed on its own, distinct from other lines unless; its last character is ``\``. This continuation character causes the RUN; line to be concatenated with the next one. In this way you can build up; long pipelines of commands without making huge line lengths. The lines; ending in ``\`` are concatenated until a RUN line that doesn't end in; ``\`` is found. This concatenated set of RUN lines then constitut",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:9555,Deployability,pipeline,pipelines,9555,"ly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; executes to run the test case. The syntax of the RUN lines is similar to a; shell's syntax for pipelines including I/O redirection and variable; substitution. However, even though these lines may *look* like a shell; script, they are not. RUN lines are interpreted by :program:`lit`.; Consequently, the syntax differs from shell in a few ways. You can specify; as many RUN lines as needed. :program:`lit` performs substitution on each RUN line to replace LLVM tool names; with the full paths to the executable built for each tool (in; ``$(LLVM_OBJ_ROOT)/bin``). This ensures that :program:`lit` does; not invoke any stray LLVM tools in the user's path during testing. Each RUN line is executed on its own, distinct from other lines unless; its last character is ``\``. This continuation character causes the RUN; line to be concatenated with the next one. In this way you can build up; long pipelines of commands without making huge line lengths. The lines; ending in ``\`` are concatenated until a RUN line that doesn't end in; ``\`` is found. This concatenated set of RUN lines then constitutes one; execution. :program:`lit` will substitute variables and arrange for the pipeline; to be executed. If any process in the pipeline fails, the entire line (and; test case) fails too. Below is an example of legal RUN lines in a ``.ll`` file:. .. code-block:: llvm. ; RUN: llvm-as < %s | llvm-dis > %t1; ; RUN: llvm-dis < %s.bc-13 > %t2; ; RUN: diff %t1 %t2. As with a Unix shell, the RUN lines permit pipelines and I/O; redirection to be used. There are some quoting rules that you must pay attention to when writing; your RUN lines. In general nothing needs to be quoted. :program:`lit` won't; strip off any quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you sh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:9838,Deployability,pipeline,pipeline,9838,"on. However, even though these lines may *look* like a shell; script, they are not. RUN lines are interpreted by :program:`lit`.; Consequently, the syntax differs from shell in a few ways. You can specify; as many RUN lines as needed. :program:`lit` performs substitution on each RUN line to replace LLVM tool names; with the full paths to the executable built for each tool (in; ``$(LLVM_OBJ_ROOT)/bin``). This ensures that :program:`lit` does; not invoke any stray LLVM tools in the user's path during testing. Each RUN line is executed on its own, distinct from other lines unless; its last character is ``\``. This continuation character causes the RUN; line to be concatenated with the next one. In this way you can build up; long pipelines of commands without making huge line lengths. The lines; ending in ``\`` are concatenated until a RUN line that doesn't end in; ``\`` is found. This concatenated set of RUN lines then constitutes one; execution. :program:`lit` will substitute variables and arrange for the pipeline; to be executed. If any process in the pipeline fails, the entire line (and; test case) fails too. Below is an example of legal RUN lines in a ``.ll`` file:. .. code-block:: llvm. ; RUN: llvm-as < %s | llvm-dis > %t1; ; RUN: llvm-dis < %s.bc-13 > %t2; ; RUN: diff %t1 %t2. As with a Unix shell, the RUN lines permit pipelines and I/O; redirection to be used. There are some quoting rules that you must pay attention to when writing; your RUN lines. In general nothing needs to be quoted. :program:`lit` won't; strip off any quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandG",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:9886,Deployability,pipeline,pipeline,9886,"UN lines are interpreted by :program:`lit`.; Consequently, the syntax differs from shell in a few ways. You can specify; as many RUN lines as needed. :program:`lit` performs substitution on each RUN line to replace LLVM tool names; with the full paths to the executable built for each tool (in; ``$(LLVM_OBJ_ROOT)/bin``). This ensures that :program:`lit` does; not invoke any stray LLVM tools in the user's path during testing. Each RUN line is executed on its own, distinct from other lines unless; its last character is ``\``. This continuation character causes the RUN; line to be concatenated with the next one. In this way you can build up; long pipelines of commands without making huge line lengths. The lines; ending in ``\`` are concatenated until a RUN line that doesn't end in; ``\`` is found. This concatenated set of RUN lines then constitutes one; execution. :program:`lit` will substitute variables and arrange for the pipeline; to be executed. If any process in the pipeline fails, the entire line (and; test case) fails too. Below is an example of legal RUN lines in a ``.ll`` file:. .. code-block:: llvm. ; RUN: llvm-as < %s | llvm-dis > %t1; ; RUN: llvm-dis < %s.bc-13 > %t2; ; RUN: diff %t1 %t2. As with a Unix shell, the RUN lines permit pipelines and I/O; redirection to be used. There are some quoting rules that you must pay attention to when writing; your RUN lines. In general nothing needs to be quoted. :program:`lit` won't; strip off any quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not se",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:10163,Deployability,pipeline,pipelines,10163," executable built for each tool (in; ``$(LLVM_OBJ_ROOT)/bin``). This ensures that :program:`lit` does; not invoke any stray LLVM tools in the user's path during testing. Each RUN line is executed on its own, distinct from other lines unless; its last character is ``\``. This continuation character causes the RUN; line to be concatenated with the next one. In this way you can build up; long pipelines of commands without making huge line lengths. The lines; ending in ``\`` are concatenated until a RUN line that doesn't end in; ``\`` is found. This concatenated set of RUN lines then constitutes one; execution. :program:`lit` will substitute variables and arrange for the pipeline; to be executed. If any process in the pipeline fails, the entire line (and; test case) fails too. Below is an example of legal RUN lines in a ``.ll`` file:. .. code-block:: llvm. ; RUN: llvm-as < %s | llvm-dis > %t1; ; RUN: llvm-dis < %s.bc-13 > %t2; ; RUN: diff %t1 %t2. As with a Unix shell, the RUN lines permit pipelines and I/O; redirection to be used. There are some quoting rules that you must pay attention to when writing; your RUN lines. In general nothing needs to be quoted. :program:`lit` won't; strip off any quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating ass",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:10917,Deployability,patch,patches,10917,"ipeline fails, the entire line (and; test case) fails too. Below is an example of legal RUN lines in a ``.ll`` file:. .. code-block:: llvm. ; RUN: llvm-as < %s | llvm-dis > %t1; ; RUN: llvm-dis < %s.bc-13 > %t2; ; RUN: diff %t1 %t2. As with a Unix shell, the RUN lines permit pipelines and I/O; redirection to be used. There are some quoting rules that you must pay attention to when writing; your RUN lines. In general nothing needs to be quoted. :program:`lit` won't; strip off any quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11297,Deployability,update,update,11297,"riting; your RUN lines. In general nothing needs to be quoted. :program:`lit` won't; strip off any quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11790,Deployability,update,update,11790,"f grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline ch",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:13041,Deployability,patch,patch,13041,"e`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrd",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:13175,Deployability,patch,patch,13175,"e`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrd",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:13305,Deployability,patch,patch,13305,"mmon scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumber",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:14588,Deployability,pipeline,pipeline,14588,"oned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumbering on future test modifications. These can be removed by; running the test through ``opt -S -passes=instnamer``.; - Try to give values (including variables, blocks and functions) meaningful; names, and avoid retaining complex names generated by the optimization; pipeline (such as ``%foo.0.0.0.0.0.0``). Extra files; -----------. If your test requires extra files besides the file containing the ``RUN:`` lines; and the extra files are small, consider specifying them in the same file and; using ``split-file`` to extract them. For example,. .. code-block:: llvm. ; RUN: split-file %s %t; ; RUN: llvm-link -S %t/a.ll %t/b.ll | FileCheck %s. ; CHECK: ... ;--- a.ll; ...; ;--- b.ll; ... The parts are separated by the regex ``^(.|//)--- <part>``. If you want to test relative line numbers like ``[[#@LINE+1]]``, specify; ``--leading-lines`` to add leading empty lines to preserve line numbers. If the extra files are large, the idiomatic place to put them is in a subdirectory ``Inputs``.; You can then refer to the extra files as ``%S/Inputs/foo.bar``. For example, consider ``test/Linker/ident.ll``. The directory structure is; as follows::. test/; Linker/; ident.ll; Inputs/; ident.a.ll; ident.b.ll.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:18183,Deployability,configurat,configuration,18183,"stdin. Platform-Specific Tests; -----------------------. Whenever adding tests that require the knowledge of a specific platform,; either related to code generated, specific output or back-end features,; you must make sure to isolate the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you'",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:19589,Deployability,configurat,configurations,19589,"-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any P",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:20461,Deployability,configurat,configuration,20461," all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windows{{.*}}``; to match any Windows target triple). | ``REQUIRES`` enables the test if all expressions are true.; | ``UNSUPPORTED`` disables the test if any expression is true.; | ``XFAIL`` expects the test to fail if any expression is true. As a special case, ``XFAIL: *`` is expected to fail everywhere. .. code-block:: llvm. ; This test is disabled when ru",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:28640,Deployability,configurat,configuration,28640,"iver. ``%clang_cpp``; Invokes the Clang driver for C++. ``%clang_cl``; Invokes the CL-compatible Clang driver. ``%clangxx``; Invokes the G++-compatible Clang driver. ``%clang_cc1``; Invokes the Clang frontend. ``%itanium_abi_triple``, ``%ms_abi_triple``; These substitutions can be used to get the current target triple adjusted to; the desired ABI. For example, if the test suite is running with the; ``i686-pc-win32`` target, ``%itanium_abi_triple`` will expand to; ``i686-pc-mingw32``. This allows a test to run with a specific ABI without; constraining it to a specific triple. **FileCheck-specific substitutions:**. ``%ProtectFileCheckOutput``; This should precede a ``FileCheck`` call if and only if the call's textual; output affects test results. It's usually easy to tell: just look for; redirection or piping of the ``FileCheck`` call's stdout or stderr. .. _Test-specific substitutions:. **Test-specific substitutions:**. Additional substitutions can be defined as follows:. - Lit configuration files (e.g., ``lit.cfg`` or ``lit.local.cfg``) can define; substitutions for all tests in a test directory. They do so by extending the; substitution list, ``config.substitutions``. Each item in the list is a tuple; consisting of a pattern and its replacement, which lit applies using python's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFINE:`` directives, described in detail below. So that; they have no effect on other test files, these directives modify a copy of the; substitution list that is produced by lit configuration files. For example, the following directives can be inserted into a test file to define; ``%{cflags}`` and ``%{fcflags}`` substitutions with empty initial values, which; serve as the parameters of another newly defined ``%{check}`` substitution:. .. code-block:: llvm. ; DEFINE: %{cflags} =; ; DEFINE: %{fcflags} =. ; DEFINE: %{check} = \; ; DEFINE: %clang_cc1 -verify -fopenmp -fopenmp-versi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:29242,Deployability,configurat,configuration,29242,"hout; constraining it to a specific triple. **FileCheck-specific substitutions:**. ``%ProtectFileCheckOutput``; This should precede a ``FileCheck`` call if and only if the call's textual; output affects test results. It's usually easy to tell: just look for; redirection or piping of the ``FileCheck`` call's stdout or stderr. .. _Test-specific substitutions:. **Test-specific substitutions:**. Additional substitutions can be defined as follows:. - Lit configuration files (e.g., ``lit.cfg`` or ``lit.local.cfg``) can define; substitutions for all tests in a test directory. They do so by extending the; substitution list, ``config.substitutions``. Each item in the list is a tuple; consisting of a pattern and its replacement, which lit applies using python's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFINE:`` directives, described in detail below. So that; they have no effect on other test files, these directives modify a copy of the; substitution list that is produced by lit configuration files. For example, the following directives can be inserted into a test file to define; ``%{cflags}`` and ``%{fcflags}`` substitutions with empty initial values, which; serve as the parameters of another newly defined ``%{check}`` substitution:. .. code-block:: llvm. ; DEFINE: %{cflags} =; ; DEFINE: %{fcflags} =. ; DEFINE: %{check} = \; ; DEFINE: %clang_cc1 -verify -fopenmp -fopenmp-version=51 %{cflags} \; ; DEFINE: -emit-llvm -o - %s | \; ; DEFINE: FileCheck %{fcflags} %s. Alternatively, the above substitutions can be defined in a lit configuration; file to be shared with other test files. Either way, the test file can then; specify directives like the following to redefine the parameter substitutions as; desired before each use of ``%{check}`` in a ``RUN:`` line:. .. code-block:: llvm. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0 -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{che",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:29799,Deployability,configurat,configuration,29799,"stitution list, ``config.substitutions``. Each item in the list is a tuple; consisting of a pattern and its replacement, which lit applies using python's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFINE:`` directives, described in detail below. So that; they have no effect on other test files, these directives modify a copy of the; substitution list that is produced by lit configuration files. For example, the following directives can be inserted into a test file to define; ``%{cflags}`` and ``%{fcflags}`` substitutions with empty initial values, which; serve as the parameters of another newly defined ``%{check}`` substitution:. .. code-block:: llvm. ; DEFINE: %{cflags} =; ; DEFINE: %{fcflags} =. ; DEFINE: %{check} = \; ; DEFINE: %clang_cc1 -verify -fopenmp -fopenmp-version=51 %{cflags} \; ; DEFINE: -emit-llvm -o - %s | \; ; DEFINE: FileCheck %{fcflags} %s. Alternatively, the above substitutions can be defined in a lit configuration; file to be shared with other test files. Either way, the test file can then; specify directives like the following to redefine the parameter substitutions as; desired before each use of ``%{check}`` in a ``RUN:`` line:. .. code-block:: llvm. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0 -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-unknown-linux-gnu -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0; ; REDEFINE: %{fcflags} = -check-prefix=NO-SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-unknown-linux-gnu; ; REDEFINE: %{fcflags} = -check-prefix=NO-SIMD; ; RUN: %{check}. Besides providing initial values, the initial ``DEFINE:`` directives for the; parameter substitutions in the above example serve a second purpose: they; establish the substitution order so that both ``%{check}`` and its par",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:31766,Deployability,configurat,configuration,31766,"nd purpose: they; establish the substitution order so that both ``%{check}`` and its parameters; expand as desired. There's a simple way to remember the required definition; order in a test file: define a substitution before any substitution that might; refer to it. In general, substitution expansion behaves as follows:. - Upon arriving at each ``RUN:`` line, lit expands all substitutions in that; ``RUN:`` line using their current values from the substitution list. No; substitution expansion is performed immediately at ``DEFINE:`` and; ``REDEFINE:`` directives except ``%(line)``, ``%(line+<number>)``, and; ``%(line-<number>)``.; - When expanding substitutions in a ``RUN:`` line, lit makes only one pass; through the substitution list by default. In this case, a substitution must; have been inserted earlier in the substitution list than any substitution; appearing in its value in order for the latter to expand. (For greater; flexibility, you can enable multiple passes through the substitution list by; setting `recursiveExpansionLimit`_ in a lit configuration file.); - While lit configuration files can insert anywhere in the substitution list,; the insertion behavior of the ``DEFINE:`` and ``REDEFINE:`` directives is; specified below and is designed specifically for the use case presented in the; example above.; - Defining a substitution in terms of itself, whether directly or via other; substitutions, should be avoided. It usually produces an infinitely recursive; definition that cannot be fully expanded. It does *not* define the; substitution in terms of its previous value, even when using ``REDEFINE:``. The relationship between the ``DEFINE:`` and ``REDEFINE:`` directive is; analogous to the relationship between a variable declaration and variable; assignment in many programming languages:. - ``DEFINE: %{name} = value``. This directive assigns the specified value to a new substitution whose; pattern is ``%{name}``, or it reports an error if there is already a; subst",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:31800,Deployability,configurat,configuration,31800,"a substitution before any substitution that might; refer to it. In general, substitution expansion behaves as follows:. - Upon arriving at each ``RUN:`` line, lit expands all substitutions in that; ``RUN:`` line using their current values from the substitution list. No; substitution expansion is performed immediately at ``DEFINE:`` and; ``REDEFINE:`` directives except ``%(line)``, ``%(line+<number>)``, and; ``%(line-<number>)``.; - When expanding substitutions in a ``RUN:`` line, lit makes only one pass; through the substitution list by default. In this case, a substitution must; have been inserted earlier in the substitution list than any substitution; appearing in its value in order for the latter to expand. (For greater; flexibility, you can enable multiple passes through the substitution list by; setting `recursiveExpansionLimit`_ in a lit configuration file.); - While lit configuration files can insert anywhere in the substitution list,; the insertion behavior of the ``DEFINE:`` and ``REDEFINE:`` directives is; specified below and is designed specifically for the use case presented in the; example above.; - Defining a substitution in terms of itself, whether directly or via other; substitutions, should be avoided. It usually produces an infinitely recursive; definition that cannot be fully expanded. It does *not* define the; substitution in terms of its previous value, even when using ``REDEFINE:``. The relationship between the ``DEFINE:`` and ``REDEFINE:`` directive is; analogous to the relationship between a variable declaration and variable; assignment in many programming languages:. - ``DEFINE: %{name} = value``. This directive assigns the specified value to a new substitution whose; pattern is ``%{name}``, or it reports an error if there is already a; substitution whose pattern contains ``%{name}`` because that could produce; confusing expansions (e.g., a lit configuration file might define a; substitution with the pattern ``%{name}\[0\]``). The new substit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:32812,Deployability,configurat,configuration,32812,"bstitution list,; the insertion behavior of the ``DEFINE:`` and ``REDEFINE:`` directives is; specified below and is designed specifically for the use case presented in the; example above.; - Defining a substitution in terms of itself, whether directly or via other; substitutions, should be avoided. It usually produces an infinitely recursive; definition that cannot be fully expanded. It does *not* define the; substitution in terms of its previous value, even when using ``REDEFINE:``. The relationship between the ``DEFINE:`` and ``REDEFINE:`` directive is; analogous to the relationship between a variable declaration and variable; assignment in many programming languages:. - ``DEFINE: %{name} = value``. This directive assigns the specified value to a new substitution whose; pattern is ``%{name}``, or it reports an error if there is already a; substitution whose pattern contains ``%{name}`` because that could produce; confusing expansions (e.g., a lit configuration file might define a; substitution with the pattern ``%{name}\[0\]``). The new substitution is; inserted at the start of the substitution list so that it will expand first.; Thus, its value can contain any substitution previously defined, whether in; the same test file or in a lit configuration file, and both will expand. - ``REDEFINE: %{name} = value``. This directive assigns the specified value to an existing substitution whose; pattern is ``%{name}``, or it reports an error if there are no substitutions; with that pattern or if there are multiple substitutions whose patterns; contain ``%{name}``. The substitution's current position in the substitution; list does not change so that expansion order relative to other existing; substitutions is preserved. The following properties apply to both the ``DEFINE:`` and ``REDEFINE:``; directives:. - **Substitution name**: In the directive, whitespace immediately before or; after ``%{name}`` is optional and discarded. ``%{name}`` must start with; ``%{``, it must end wi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:33107,Deployability,configurat,configuration,33107," of itself, whether directly or via other; substitutions, should be avoided. It usually produces an infinitely recursive; definition that cannot be fully expanded. It does *not* define the; substitution in terms of its previous value, even when using ``REDEFINE:``. The relationship between the ``DEFINE:`` and ``REDEFINE:`` directive is; analogous to the relationship between a variable declaration and variable; assignment in many programming languages:. - ``DEFINE: %{name} = value``. This directive assigns the specified value to a new substitution whose; pattern is ``%{name}``, or it reports an error if there is already a; substitution whose pattern contains ``%{name}`` because that could produce; confusing expansions (e.g., a lit configuration file might define a; substitution with the pattern ``%{name}\[0\]``). The new substitution is; inserted at the start of the substitution list so that it will expand first.; Thus, its value can contain any substitution previously defined, whether in; the same test file or in a lit configuration file, and both will expand. - ``REDEFINE: %{name} = value``. This directive assigns the specified value to an existing substitution whose; pattern is ``%{name}``, or it reports an error if there are no substitutions; with that pattern or if there are multiple substitutions whose patterns; contain ``%{name}``. The substitution's current position in the substitution; list does not change so that expansion order relative to other existing; substitutions is preserved. The following properties apply to both the ``DEFINE:`` and ``REDEFINE:``; directives:. - **Substitution name**: In the directive, whitespace immediately before or; after ``%{name}`` is optional and discarded. ``%{name}`` must start with; ``%{``, it must end with ``}``, and the rest must start with a letter or; underscore and contain only alphanumeric characters, hyphens, underscores, and; colons. This syntax has a few advantages:. - It is impossible for ``%{name}`` to contain se",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:34213,Deployability,configurat,configuration,34213,"signs the specified value to an existing substitution whose; pattern is ``%{name}``, or it reports an error if there are no substitutions; with that pattern or if there are multiple substitutions whose patterns; contain ``%{name}``. The substitution's current position in the substitution; list does not change so that expansion order relative to other existing; substitutions is preserved. The following properties apply to both the ``DEFINE:`` and ``REDEFINE:``; directives:. - **Substitution name**: In the directive, whitespace immediately before or; after ``%{name}`` is optional and discarded. ``%{name}`` must start with; ``%{``, it must end with ``}``, and the rest must start with a letter or; underscore and contain only alphanumeric characters, hyphens, underscores, and; colons. This syntax has a few advantages:. - It is impossible for ``%{name}`` to contain sequences that are special in; python's ``re.sub`` patterns. Otherwise, attempting to specify; ``%{name}`` as a substitution pattern in a lit configuration file could; produce confusing expansions.; - The braces help avoid the possibility that another substitution's pattern; will match part of ``%{name}`` or vice-versa, producing confusing; expansions. However, the patterns of substitutions defined by lit; configuration files and by lit itself are not restricted to this form, so; overlaps are still theoretically possible. - **Substitution value**: The value includes all text from the first; non-whitespace character after ``=`` to the last non-whitespace character. If; there is no non-whitespace character after ``=``, the value is the empty; string. Escape sequences that can appear in python ``re.sub`` replacement; strings are treated as plain text in the value.; - **Line continuations**: If the last non-whitespace character on the line after; ``:`` is ``\``, then the next directive must use the same directive keyword; (e.g., ``DEFINE:``) , and it is an error if there is no additional directive.; That directive s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:34481,Deployability,configurat,configuration,34481,"o that expansion order relative to other existing; substitutions is preserved. The following properties apply to both the ``DEFINE:`` and ``REDEFINE:``; directives:. - **Substitution name**: In the directive, whitespace immediately before or; after ``%{name}`` is optional and discarded. ``%{name}`` must start with; ``%{``, it must end with ``}``, and the rest must start with a letter or; underscore and contain only alphanumeric characters, hyphens, underscores, and; colons. This syntax has a few advantages:. - It is impossible for ``%{name}`` to contain sequences that are special in; python's ``re.sub`` patterns. Otherwise, attempting to specify; ``%{name}`` as a substitution pattern in a lit configuration file could; produce confusing expansions.; - The braces help avoid the possibility that another substitution's pattern; will match part of ``%{name}`` or vice-versa, producing confusing; expansions. However, the patterns of substitutions defined by lit; configuration files and by lit itself are not restricted to this form, so; overlaps are still theoretically possible. - **Substitution value**: The value includes all text from the first; non-whitespace character after ``=`` to the last non-whitespace character. If; there is no non-whitespace character after ``=``, the value is the empty; string. Escape sequences that can appear in python ``re.sub`` replacement; strings are treated as plain text in the value.; - **Line continuations**: If the last non-whitespace character on the line after; ``:`` is ``\``, then the next directive must use the same directive keyword; (e.g., ``DEFINE:``) , and it is an error if there is no additional directive.; That directive serves as a continuation. That is, before following the rules; above to parse the text after ``:`` in either directive, lit joins that text; together to form a single directive, replaces the ``\`` with a single space,; and removes any other whitespace that is now adjacent to that space. A; continuation can be co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:36839,Deployability,configurat,configuration,36839,"tutions are not defined in the proper order, some will remain in the; ``RUN:`` line unexpanded. For example, the following directives refer to; ``%{inner}`` within ``%{outer}`` but do not define ``%{inner}`` until after; ``%{outer}``:. .. code-block:: llvm. ; By default, this definition order does not enable full expansion. ; DEFINE: %{outer} = %{inner}; ; DEFINE: %{inner} = expanded. ; RUN: echo '%{outer}'. ``DEFINE:`` inserts substitutions at the start of the substitution list, so; ``%{inner}`` expands first but has no effect because the original ``RUN:`` line; does not contain ``%{inner}``. Next, ``%{outer}`` expands, and the output of; the ``echo`` command becomes:. .. code-block:: shell. %{inner}. Of course, one way to fix this simple case is to reverse the definitions of; ``%{outer}`` and ``%{inner}``. However, if a test has a complex set of; substitutions that can all reference each other, there might not exist a; sufficient substitution order. To address such use cases, lit configuration files support; ``config.recursiveExpansionLimit``, which can be set to a non-negative integer; to specify the maximum number of passes through the substitution list. Thus, in; the above example, setting the limit to 2 would cause lit to make a second pass; that expands ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. expanded. To improve performance, lit will stop making passes when it notices the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:37723,Deployability,configurat,configuration,37723,"er, there might not exist a; sufficient substitution order. To address such use cases, lit configuration files support; ``config.recursiveExpansionLimit``, which can be set to a non-negative integer; to specify the maximum number of passes through the substitution list. Thus, in; the above example, setting the limit to 2 would cause lit to make a second pass; that expands ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. expanded. To improve performance, lit will stop making passes when it notices the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm tool name with a custom command line. This; allows to specify custom paths and default arguments for these tools.; Example:. % llvm-lit ""-Dllc=llc -verify-machineinstrs"". ``run_long_tests``; Enable the execution of long running tests. ``llvm_site_config``; Load the specified lit configuration instead of the default one. Other Features; --------------. To make RUN line writing easier, there are several helper programs. These; helpers are in the PATH when running tests, so you can just call them using; their name. For example:. ``not``; This program runs its arguments and then inverts the result code from it.; Zero result codes become 1. Non-zero result codes become 0. To make the output more useful, :program:`lit` will scan; the lines of the test case for ones that contain a pattern that matches; ``PR[0-9]+``. This is the syntax for specifying a PR (Problem Report) number; that is related to th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:38123,Deployability,configurat,configuration,38123,"ds ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. expanded. To improve performance, lit will stop making passes when it notices the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm tool name with a custom command line. This; allows to specify custom paths and default arguments for these tools.; Example:. % llvm-lit ""-Dllc=llc -verify-machineinstrs"". ``run_long_tests``; Enable the execution of long running tests. ``llvm_site_config``; Load the specified lit configuration instead of the default one. Other Features; --------------. To make RUN line writing easier, there are several helper programs. These; helpers are in the PATH when running tests, so you can just call them using; their name. For example:. ``not``; This program runs its arguments and then inverts the result code from it.; Zero result codes become 1. Non-zero result codes become 0. To make the output more useful, :program:`lit` will scan; the lines of the test case for ones that contain a pattern that matches; ``PR[0-9]+``. This is the syntax for specifying a PR (Problem Report) number; that is related to the test case. The number after ""PR"" specifies the; LLVM Bugzilla number. When a PR number is specified, it will be used in; the pass/fail reporting. This is useful to quickly get some context when; a test fails. Finally, any line that contains ""END."" will cause the special; interpretation of lines to terminate. This is generally done right after; the last RUN: line. This",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11330,Energy Efficiency,reduce,reduce,11330," quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:14053,Energy Efficiency,reduce,reduce,14053,"anges to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumbering on future test modifications. These can be removed by; running the test through ``opt -S -passes=instnamer``.; - Try to give values (including variables, blocks and functions) meaningful; names, and avoid retaining complex names generated by the optimization; pipeline (such as ``%foo.0.0.0.0.0.0``). Extra files; -----------. If your test requires extra files besides the file containing the ``RUN:`` lines; and the extra files are small, consider specifying them in the same file and; using ``split-file`` to extract them. For example,. .. code-block:: llvm. ; RUN: split-file %s %t; ; RUN: llvm-link -S %t/a.ll %t/b.ll | FileCheck %s. ; CHECK: ... ;--- a.ll; ...; ;--- b.ll; ... The parts are separated by the regex ``^(.|//)--- ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:20248,Energy Efficiency,power,powerpc,20248,"iour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windows{{.*}}``; to match any Windows target triple). | ``REQUIRES`` enables the test if all expressions are true.; | ``UNSUPPORTED`` disab",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:21726,Energy Efficiency,power,powerpc,21726,"hes the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windows{{.*}}``; to match any Windows target triple). | ``REQUIRES`` enables the test if all expressions are true.; | ``UNSUPPORTED`` disables the test if any expression is true.; | ``XFAIL`` expects the test to fail if any expression is true. As a special case, ``XFAIL: *`` is expected to fail everywhere. .. code-block:: llvm. ; This test is disabled when running on Windows,; ; and is disabled when targeting Linux, except for Android Linux.; ; UNSUPPORTED: system-windows, target={{.*linux.*}} && !target={{.*android.*}}; ; This test is expected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, and ``UNSUPPORTED`` to exclude cases where; the test is expected never to work. **``UNSUPPORTED`` and ``XFAIL``**. Both of these indicate that the test isn't expected to work; however, they; have different effects. ``UNSUPPORTED`` causes the test to be skipped;; this saves execution time, but then you'll never know whether the test; actually would start working. Conversely, ``XFAIL`` actually runs the test; but expects a failure output, taking extra execution time but alerting you; if/when the test begins to behave correctly (a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:2093,Integrability,depend,depends,2093,"(or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11958,Integrability,depend,depends,11958," having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; som",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:18557,Integrability,depend,depend,18557,"em is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific con",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:19288,Integrability,depend,depends,19288,"``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:22156,Integrability,depend,depends,22156,"les the test if all expressions are true.; | ``UNSUPPORTED`` disables the test if any expression is true.; | ``XFAIL`` expects the test to fail if any expression is true. As a special case, ``XFAIL: *`` is expected to fail everywhere. .. code-block:: llvm. ; This test is disabled when running on Windows,; ; and is disabled when targeting Linux, except for Android Linux.; ; UNSUPPORTED: system-windows, target={{.*linux.*}} && !target={{.*android.*}}; ; This test is expected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, and ``UNSUPPORTED`` to exclude cases where; the test is expected never to work. **``UNSUPPORTED`` and ``XFAIL``**. Both of these indicate that the test isn't expected to work; however, they; have different effects. ``UNSUPPORTED`` causes the test to be skipped;; this saves execution time, but then you'll never know whether the test; actually would start working. Conversely, ``XFAIL`` actually runs the test; but expects a failure output, taking extra execution time but alerting you; if/when the test begins to behave correctly (an XPASS test result). You; need to decide which is more appropriate in each case. **Using ``target=...``**. Checking the target triple can be tricky; it's easy to mis-specify. For; example, ``target=mips{{.*}}`` will match not only mips, but also mipsel,; mips64, and mips64el. ``target={{.*}}-linux-gnu`` will match; x86_64-unknown-linux-gnu, but not armv8l-unknown-linux-gnueabihf.; Prefer to use hyphens to delimit triple components (``target=mips-{{.*}}",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:26203,Integrability,message,messages,26203,"`` or ``\`` on Windows. ``%/s, %/S, %/t, %/T``. Act like the corresponding substitution above but replace any ``\``; character with a ``/``. This is useful to normalize path separators. Example: ``%s: C:\Desktop Files/foo_test.s.tmp``. Example: ``%/s: C:/Desktop Files/foo_test.s.tmp``. ``%{s:real}, %{S:real}, %{t:real}, %{T:real}``; ``%{/s:real}, %{/S:real}, %{/t:real}, %{/T:real}``. Act like the corresponding substitution, including with ``/``, but use; the real path by expanding all symbolic links and substitute drives. Example: ``%s: S:\foo_test.s.tmp``. Example: ``%{/s:real}: C:/SDrive/foo_test.s.tmp``. ``%:s, %:S, %:t, %:T``. Act like the corresponding substitution above but remove colons at; the beginning of Windows paths. This is useful to allow concatenation; of absolute paths on Windows to produce a legal path. Example: ``%s: C:\Desktop Files\foo_test.s.tmp``. Example: ``%:s: C\Desktop Files\foo_test.s.tmp``. ``%errc_<ERRCODE>``. Some error messages may be substituted to allow different spellings; based on the host platform. The following error codes are currently supported:; ENOENT, EISDIR, EINVAL, EACCES. Example: ``Linux %errc_ENOENT: No such file or directory``. Example: ``Windows %errc_ENOENT: no such file or directory``. ``%if feature %{<if branch>%} %else %{<else branch>%}``. Conditional substitution: if ``feature`` is available it expands to; ``<if branch>``, otherwise it expands to ``<else branch>``.; ``%else %{<else branch>%}`` is optional and treated like ``%else %{%}``; if not present. ``%(line)``, ``%(line+<number>)``, ``%(line-<number>)``. The number of the line where this substitution is used, with an; optional integer offset. These expand only if they appear; immediately in ``RUN:``, ``DEFINE:``, and ``REDEFINE:`` directives.; Occurrences in substitutions defined elsewhere are never expanded.; For example, this can be used in tests with multiple RUN lines,; which reference the test file's line numbers. **LLVM-specific substitutions:**. ``%shl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:5728,Modifiability,variab,variable,5728,"ts`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Infor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:7845,Modifiability,flexible,flexible,7845,"ABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; executes to run the test case. The syntax of the RUN lines is similar to a; shell's syntax for pipelines including I/O redirection and variable; substitution. However, even though these line",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:8799,Modifiability,variab,variable,8799,"le to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; executes to run the test case. The syntax of the RUN lines is similar to a; shell's syntax for pipelines including I/O redirection and variable; substitution. However, even though these lines may *look* like a shell; script, they are not. RUN lines are interpreted by :program:`lit`.; Consequently, the syntax differs from shell in a few ways. You can specify; as many RUN lines as needed. :program:`lit` performs substitution on each RUN line to replace LLVM tool names; with the full paths to the executable built for each tool (in; ``$(LLVM_OBJ_ROOT)/bin``). This ensures that :program:`lit` does; not invoke any stray LLVM tools in the user's path during testing. Each RUN line is executed on its own, distinct from other lines unless; its last character is ``\``. This continuation character causes the RUN; line to be concatenated with the next one. In this way you can build up; long pipelines of commands without making huge line lengths. The lines; ending in ``\`` are concatenated until a RUN line that doesn't end in; ``\`` is found. This concatenated set of RUN lines then constitut",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:9808,Modifiability,variab,variables,9808,"on. However, even though these lines may *look* like a shell; script, they are not. RUN lines are interpreted by :program:`lit`.; Consequently, the syntax differs from shell in a few ways. You can specify; as many RUN lines as needed. :program:`lit` performs substitution on each RUN line to replace LLVM tool names; with the full paths to the executable built for each tool (in; ``$(LLVM_OBJ_ROOT)/bin``). This ensures that :program:`lit` does; not invoke any stray LLVM tools in the user's path during testing. Each RUN line is executed on its own, distinct from other lines unless; its last character is ``\``. This continuation character causes the RUN; line to be concatenated with the next one. In this way you can build up; long pipelines of commands without making huge line lengths. The lines; ending in ``\`` are concatenated until a RUN line that doesn't end in; ``\`` is found. This concatenated set of RUN lines then constitutes one; execution. :program:`lit` will substitute variables and arrange for the pipeline; to be executed. If any process in the pipeline fails, the entire line (and; test case) fails too. Below is an example of legal RUN lines in a ``.ll`` file:. .. code-block:: llvm. ; RUN: llvm-as < %s | llvm-dis > %t1; ; RUN: llvm-dis < %s.bc-13 > %t2; ; RUN: diff %t1 %t2. As with a Unix shell, the RUN lines permit pipelines and I/O; redirection to be used. There are some quoting rules that you must pay attention to when writing; your RUN lines. In general nothing needs to be quoted. :program:`lit` won't; strip off any quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandG",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:14471,Modifiability,variab,variables,14471,"oned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumbering on future test modifications. These can be removed by; running the test through ``opt -S -passes=instnamer``.; - Try to give values (including variables, blocks and functions) meaningful; names, and avoid retaining complex names generated by the optimization; pipeline (such as ``%foo.0.0.0.0.0.0``). Extra files; -----------. If your test requires extra files besides the file containing the ``RUN:`` lines; and the extra files are small, consider specifying them in the same file and; using ``split-file`` to extract them. For example,. .. code-block:: llvm. ; RUN: split-file %s %t; ; RUN: llvm-link -S %t/a.ll %t/b.ll | FileCheck %s. ; CHECK: ... ;--- a.ll; ...; ;--- b.ll; ... The parts are separated by the regex ``^(.|//)--- <part>``. If you want to test relative line numbers like ``[[#@LINE+1]]``, specify; ``--leading-lines`` to add leading empty lines to preserve line numbers. If the extra files are large, the idiomatic place to put them is in a subdirectory ``Inputs``.; You can then refer to the extra files as ``%S/Inputs/foo.bar``. For example, consider ``test/Linker/ident.ll``. The directory structure is; as follows::. test/; Linker/; ident.ll; Inputs/; ident.a.ll; ident.b.ll.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:18183,Modifiability,config,configuration,18183,"stdin. Platform-Specific Tests; -----------------------. Whenever adding tests that require the knowledge of a specific platform,; either related to code generated, specific output or back-end features,; you must make sure to isolate the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you'",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:18397,Modifiability,config,config,18397,"t or back-end features,; you must make sure to isolate the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific File",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:18463,Modifiability,config,config,18463," the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:18485,Modifiability,config,config,18485,"ots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other archite",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:19589,Modifiability,config,configurations,19589,"-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any P",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:20430,Modifiability,config,config,20430,"the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windows{{.*}}``; to match any Windows target triple). | ``REQUIRES`` enables the test if all expressions are true.; | ``UNSUPPORTED`` disables the test if any expression is true.; | ``XFAIL`` expects the test to fail if any expression is true. As a special case, ``XFAIL: *`` is expected to fail everywhere. .. code-b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:20461,Modifiability,config,configuration,20461," all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windows{{.*}}``; to match any Windows target triple). | ``REQUIRES`` enables the test if all expressions are true.; | ``UNSUPPORTED`` disables the test if any expression is true.; | ``XFAIL`` expects the test to fail if any expression is true. As a special case, ``XFAIL: *`` is expected to fail everywhere. .. code-block:: llvm. ; This test is disabled when ru",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:28640,Modifiability,config,configuration,28640,"iver. ``%clang_cpp``; Invokes the Clang driver for C++. ``%clang_cl``; Invokes the CL-compatible Clang driver. ``%clangxx``; Invokes the G++-compatible Clang driver. ``%clang_cc1``; Invokes the Clang frontend. ``%itanium_abi_triple``, ``%ms_abi_triple``; These substitutions can be used to get the current target triple adjusted to; the desired ABI. For example, if the test suite is running with the; ``i686-pc-win32`` target, ``%itanium_abi_triple`` will expand to; ``i686-pc-mingw32``. This allows a test to run with a specific ABI without; constraining it to a specific triple. **FileCheck-specific substitutions:**. ``%ProtectFileCheckOutput``; This should precede a ``FileCheck`` call if and only if the call's textual; output affects test results. It's usually easy to tell: just look for; redirection or piping of the ``FileCheck`` call's stdout or stderr. .. _Test-specific substitutions:. **Test-specific substitutions:**. Additional substitutions can be defined as follows:. - Lit configuration files (e.g., ``lit.cfg`` or ``lit.local.cfg``) can define; substitutions for all tests in a test directory. They do so by extending the; substitution list, ``config.substitutions``. Each item in the list is a tuple; consisting of a pattern and its replacement, which lit applies using python's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFINE:`` directives, described in detail below. So that; they have no effect on other test files, these directives modify a copy of the; substitution list that is produced by lit configuration files. For example, the following directives can be inserted into a test file to define; ``%{cflags}`` and ``%{fcflags}`` substitutions with empty initial values, which; serve as the parameters of another newly defined ``%{check}`` substitution:. .. code-block:: llvm. ; DEFINE: %{cflags} =; ; DEFINE: %{fcflags} =. ; DEFINE: %{check} = \; ; DEFINE: %clang_cc1 -verify -fopenmp -fopenmp-versi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:28776,Modifiability,extend,extending,28776,"ompatible Clang driver. ``%clang_cc1``; Invokes the Clang frontend. ``%itanium_abi_triple``, ``%ms_abi_triple``; These substitutions can be used to get the current target triple adjusted to; the desired ABI. For example, if the test suite is running with the; ``i686-pc-win32`` target, ``%itanium_abi_triple`` will expand to; ``i686-pc-mingw32``. This allows a test to run with a specific ABI without; constraining it to a specific triple. **FileCheck-specific substitutions:**. ``%ProtectFileCheckOutput``; This should precede a ``FileCheck`` call if and only if the call's textual; output affects test results. It's usually easy to tell: just look for; redirection or piping of the ``FileCheck`` call's stdout or stderr. .. _Test-specific substitutions:. **Test-specific substitutions:**. Additional substitutions can be defined as follows:. - Lit configuration files (e.g., ``lit.cfg`` or ``lit.local.cfg``) can define; substitutions for all tests in a test directory. They do so by extending the; substitution list, ``config.substitutions``. Each item in the list is a tuple; consisting of a pattern and its replacement, which lit applies using python's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFINE:`` directives, described in detail below. So that; they have no effect on other test files, these directives modify a copy of the; substitution list that is produced by lit configuration files. For example, the following directives can be inserted into a test file to define; ``%{cflags}`` and ``%{fcflags}`` substitutions with empty initial values, which; serve as the parameters of another newly defined ``%{check}`` substitution:. .. code-block:: llvm. ; DEFINE: %{cflags} =; ; DEFINE: %{fcflags} =. ; DEFINE: %{check} = \; ; DEFINE: %clang_cc1 -verify -fopenmp -fopenmp-version=51 %{cflags} \; ; DEFINE: -emit-llvm -o - %s | \; ; DEFINE: FileCheck %{fcflags} %s. Alternatively, the above substitutions can be defined ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:28812,Modifiability,config,config,28812,"ompatible Clang driver. ``%clang_cc1``; Invokes the Clang frontend. ``%itanium_abi_triple``, ``%ms_abi_triple``; These substitutions can be used to get the current target triple adjusted to; the desired ABI. For example, if the test suite is running with the; ``i686-pc-win32`` target, ``%itanium_abi_triple`` will expand to; ``i686-pc-mingw32``. This allows a test to run with a specific ABI without; constraining it to a specific triple. **FileCheck-specific substitutions:**. ``%ProtectFileCheckOutput``; This should precede a ``FileCheck`` call if and only if the call's textual; output affects test results. It's usually easy to tell: just look for; redirection or piping of the ``FileCheck`` call's stdout or stderr. .. _Test-specific substitutions:. **Test-specific substitutions:**. Additional substitutions can be defined as follows:. - Lit configuration files (e.g., ``lit.cfg`` or ``lit.local.cfg``) can define; substitutions for all tests in a test directory. They do so by extending the; substitution list, ``config.substitutions``. Each item in the list is a tuple; consisting of a pattern and its replacement, which lit applies using python's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFINE:`` directives, described in detail below. So that; they have no effect on other test files, these directives modify a copy of the; substitution list that is produced by lit configuration files. For example, the following directives can be inserted into a test file to define; ``%{cflags}`` and ``%{fcflags}`` substitutions with empty initial values, which; serve as the parameters of another newly defined ``%{check}`` substitution:. .. code-block:: llvm. ; DEFINE: %{cflags} =; ; DEFINE: %{fcflags} =. ; DEFINE: %{check} = \; ; DEFINE: %clang_cc1 -verify -fopenmp -fopenmp-version=51 %{cflags} \; ; DEFINE: -emit-llvm -o - %s | \; ; DEFINE: FileCheck %{fcflags} %s. Alternatively, the above substitutions can be defined ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:29242,Modifiability,config,configuration,29242,"hout; constraining it to a specific triple. **FileCheck-specific substitutions:**. ``%ProtectFileCheckOutput``; This should precede a ``FileCheck`` call if and only if the call's textual; output affects test results. It's usually easy to tell: just look for; redirection or piping of the ``FileCheck`` call's stdout or stderr. .. _Test-specific substitutions:. **Test-specific substitutions:**. Additional substitutions can be defined as follows:. - Lit configuration files (e.g., ``lit.cfg`` or ``lit.local.cfg``) can define; substitutions for all tests in a test directory. They do so by extending the; substitution list, ``config.substitutions``. Each item in the list is a tuple; consisting of a pattern and its replacement, which lit applies using python's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFINE:`` directives, described in detail below. So that; they have no effect on other test files, these directives modify a copy of the; substitution list that is produced by lit configuration files. For example, the following directives can be inserted into a test file to define; ``%{cflags}`` and ``%{fcflags}`` substitutions with empty initial values, which; serve as the parameters of another newly defined ``%{check}`` substitution:. .. code-block:: llvm. ; DEFINE: %{cflags} =; ; DEFINE: %{fcflags} =. ; DEFINE: %{check} = \; ; DEFINE: %clang_cc1 -verify -fopenmp -fopenmp-version=51 %{cflags} \; ; DEFINE: -emit-llvm -o - %s | \; ; DEFINE: FileCheck %{fcflags} %s. Alternatively, the above substitutions can be defined in a lit configuration; file to be shared with other test files. Either way, the test file can then; specify directives like the following to redefine the parameter substitutions as; desired before each use of ``%{check}`` in a ``RUN:`` line:. .. code-block:: llvm. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0 -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{che",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:29799,Modifiability,config,configuration,29799,"stitution list, ``config.substitutions``. Each item in the list is a tuple; consisting of a pattern and its replacement, which lit applies using python's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFINE:`` directives, described in detail below. So that; they have no effect on other test files, these directives modify a copy of the; substitution list that is produced by lit configuration files. For example, the following directives can be inserted into a test file to define; ``%{cflags}`` and ``%{fcflags}`` substitutions with empty initial values, which; serve as the parameters of another newly defined ``%{check}`` substitution:. .. code-block:: llvm. ; DEFINE: %{cflags} =; ; DEFINE: %{fcflags} =. ; DEFINE: %{check} = \; ; DEFINE: %clang_cc1 -verify -fopenmp -fopenmp-version=51 %{cflags} \; ; DEFINE: -emit-llvm -o - %s | \; ; DEFINE: FileCheck %{fcflags} %s. Alternatively, the above substitutions can be defined in a lit configuration; file to be shared with other test files. Either way, the test file can then; specify directives like the following to redefine the parameter substitutions as; desired before each use of ``%{check}`` in a ``RUN:`` line:. .. code-block:: llvm. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0 -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-unknown-linux-gnu -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0; ; REDEFINE: %{fcflags} = -check-prefix=NO-SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-unknown-linux-gnu; ; REDEFINE: %{fcflags} = -check-prefix=NO-SIMD; ; RUN: %{check}. Besides providing initial values, the initial ``DEFINE:`` directives for the; parameter substitutions in the above example serve a second purpose: they; establish the substitution order so that both ``%{check}`` and its par",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:31766,Modifiability,config,configuration,31766,"nd purpose: they; establish the substitution order so that both ``%{check}`` and its parameters; expand as desired. There's a simple way to remember the required definition; order in a test file: define a substitution before any substitution that might; refer to it. In general, substitution expansion behaves as follows:. - Upon arriving at each ``RUN:`` line, lit expands all substitutions in that; ``RUN:`` line using their current values from the substitution list. No; substitution expansion is performed immediately at ``DEFINE:`` and; ``REDEFINE:`` directives except ``%(line)``, ``%(line+<number>)``, and; ``%(line-<number>)``.; - When expanding substitutions in a ``RUN:`` line, lit makes only one pass; through the substitution list by default. In this case, a substitution must; have been inserted earlier in the substitution list than any substitution; appearing in its value in order for the latter to expand. (For greater; flexibility, you can enable multiple passes through the substitution list by; setting `recursiveExpansionLimit`_ in a lit configuration file.); - While lit configuration files can insert anywhere in the substitution list,; the insertion behavior of the ``DEFINE:`` and ``REDEFINE:`` directives is; specified below and is designed specifically for the use case presented in the; example above.; - Defining a substitution in terms of itself, whether directly or via other; substitutions, should be avoided. It usually produces an infinitely recursive; definition that cannot be fully expanded. It does *not* define the; substitution in terms of its previous value, even when using ``REDEFINE:``. The relationship between the ``DEFINE:`` and ``REDEFINE:`` directive is; analogous to the relationship between a variable declaration and variable; assignment in many programming languages:. - ``DEFINE: %{name} = value``. This directive assigns the specified value to a new substitution whose; pattern is ``%{name}``, or it reports an error if there is already a; subst",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:31800,Modifiability,config,configuration,31800,"a substitution before any substitution that might; refer to it. In general, substitution expansion behaves as follows:. - Upon arriving at each ``RUN:`` line, lit expands all substitutions in that; ``RUN:`` line using their current values from the substitution list. No; substitution expansion is performed immediately at ``DEFINE:`` and; ``REDEFINE:`` directives except ``%(line)``, ``%(line+<number>)``, and; ``%(line-<number>)``.; - When expanding substitutions in a ``RUN:`` line, lit makes only one pass; through the substitution list by default. In this case, a substitution must; have been inserted earlier in the substitution list than any substitution; appearing in its value in order for the latter to expand. (For greater; flexibility, you can enable multiple passes through the substitution list by; setting `recursiveExpansionLimit`_ in a lit configuration file.); - While lit configuration files can insert anywhere in the substitution list,; the insertion behavior of the ``DEFINE:`` and ``REDEFINE:`` directives is; specified below and is designed specifically for the use case presented in the; example above.; - Defining a substitution in terms of itself, whether directly or via other; substitutions, should be avoided. It usually produces an infinitely recursive; definition that cannot be fully expanded. It does *not* define the; substitution in terms of its previous value, even when using ``REDEFINE:``. The relationship between the ``DEFINE:`` and ``REDEFINE:`` directive is; analogous to the relationship between a variable declaration and variable; assignment in many programming languages:. - ``DEFINE: %{name} = value``. This directive assigns the specified value to a new substitution whose; pattern is ``%{name}``, or it reports an error if there is already a; substitution whose pattern contains ``%{name}`` because that could produce; confusing expansions (e.g., a lit configuration file might define a; substitution with the pattern ``%{name}\[0\]``). The new substit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:32451,Modifiability,variab,variable,32451,"substitution list by default. In this case, a substitution must; have been inserted earlier in the substitution list than any substitution; appearing in its value in order for the latter to expand. (For greater; flexibility, you can enable multiple passes through the substitution list by; setting `recursiveExpansionLimit`_ in a lit configuration file.); - While lit configuration files can insert anywhere in the substitution list,; the insertion behavior of the ``DEFINE:`` and ``REDEFINE:`` directives is; specified below and is designed specifically for the use case presented in the; example above.; - Defining a substitution in terms of itself, whether directly or via other; substitutions, should be avoided. It usually produces an infinitely recursive; definition that cannot be fully expanded. It does *not* define the; substitution in terms of its previous value, even when using ``REDEFINE:``. The relationship between the ``DEFINE:`` and ``REDEFINE:`` directive is; analogous to the relationship between a variable declaration and variable; assignment in many programming languages:. - ``DEFINE: %{name} = value``. This directive assigns the specified value to a new substitution whose; pattern is ``%{name}``, or it reports an error if there is already a; substitution whose pattern contains ``%{name}`` because that could produce; confusing expansions (e.g., a lit configuration file might define a; substitution with the pattern ``%{name}\[0\]``). The new substitution is; inserted at the start of the substitution list so that it will expand first.; Thus, its value can contain any substitution previously defined, whether in; the same test file or in a lit configuration file, and both will expand. - ``REDEFINE: %{name} = value``. This directive assigns the specified value to an existing substitution whose; pattern is ``%{name}``, or it reports an error if there are no substitutions; with that pattern or if there are multiple substitutions whose patterns; contain ``%{name}``. T",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:32476,Modifiability,variab,variable,32476,"substitution list by default. In this case, a substitution must; have been inserted earlier in the substitution list than any substitution; appearing in its value in order for the latter to expand. (For greater; flexibility, you can enable multiple passes through the substitution list by; setting `recursiveExpansionLimit`_ in a lit configuration file.); - While lit configuration files can insert anywhere in the substitution list,; the insertion behavior of the ``DEFINE:`` and ``REDEFINE:`` directives is; specified below and is designed specifically for the use case presented in the; example above.; - Defining a substitution in terms of itself, whether directly or via other; substitutions, should be avoided. It usually produces an infinitely recursive; definition that cannot be fully expanded. It does *not* define the; substitution in terms of its previous value, even when using ``REDEFINE:``. The relationship between the ``DEFINE:`` and ``REDEFINE:`` directive is; analogous to the relationship between a variable declaration and variable; assignment in many programming languages:. - ``DEFINE: %{name} = value``. This directive assigns the specified value to a new substitution whose; pattern is ``%{name}``, or it reports an error if there is already a; substitution whose pattern contains ``%{name}`` because that could produce; confusing expansions (e.g., a lit configuration file might define a; substitution with the pattern ``%{name}\[0\]``). The new substitution is; inserted at the start of the substitution list so that it will expand first.; Thus, its value can contain any substitution previously defined, whether in; the same test file or in a lit configuration file, and both will expand. - ``REDEFINE: %{name} = value``. This directive assigns the specified value to an existing substitution whose; pattern is ``%{name}``, or it reports an error if there are no substitutions; with that pattern or if there are multiple substitutions whose patterns; contain ``%{name}``. T",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:32812,Modifiability,config,configuration,32812,"bstitution list,; the insertion behavior of the ``DEFINE:`` and ``REDEFINE:`` directives is; specified below and is designed specifically for the use case presented in the; example above.; - Defining a substitution in terms of itself, whether directly or via other; substitutions, should be avoided. It usually produces an infinitely recursive; definition that cannot be fully expanded. It does *not* define the; substitution in terms of its previous value, even when using ``REDEFINE:``. The relationship between the ``DEFINE:`` and ``REDEFINE:`` directive is; analogous to the relationship between a variable declaration and variable; assignment in many programming languages:. - ``DEFINE: %{name} = value``. This directive assigns the specified value to a new substitution whose; pattern is ``%{name}``, or it reports an error if there is already a; substitution whose pattern contains ``%{name}`` because that could produce; confusing expansions (e.g., a lit configuration file might define a; substitution with the pattern ``%{name}\[0\]``). The new substitution is; inserted at the start of the substitution list so that it will expand first.; Thus, its value can contain any substitution previously defined, whether in; the same test file or in a lit configuration file, and both will expand. - ``REDEFINE: %{name} = value``. This directive assigns the specified value to an existing substitution whose; pattern is ``%{name}``, or it reports an error if there are no substitutions; with that pattern or if there are multiple substitutions whose patterns; contain ``%{name}``. The substitution's current position in the substitution; list does not change so that expansion order relative to other existing; substitutions is preserved. The following properties apply to both the ``DEFINE:`` and ``REDEFINE:``; directives:. - **Substitution name**: In the directive, whitespace immediately before or; after ``%{name}`` is optional and discarded. ``%{name}`` must start with; ``%{``, it must end wi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:33107,Modifiability,config,configuration,33107," of itself, whether directly or via other; substitutions, should be avoided. It usually produces an infinitely recursive; definition that cannot be fully expanded. It does *not* define the; substitution in terms of its previous value, even when using ``REDEFINE:``. The relationship between the ``DEFINE:`` and ``REDEFINE:`` directive is; analogous to the relationship between a variable declaration and variable; assignment in many programming languages:. - ``DEFINE: %{name} = value``. This directive assigns the specified value to a new substitution whose; pattern is ``%{name}``, or it reports an error if there is already a; substitution whose pattern contains ``%{name}`` because that could produce; confusing expansions (e.g., a lit configuration file might define a; substitution with the pattern ``%{name}\[0\]``). The new substitution is; inserted at the start of the substitution list so that it will expand first.; Thus, its value can contain any substitution previously defined, whether in; the same test file or in a lit configuration file, and both will expand. - ``REDEFINE: %{name} = value``. This directive assigns the specified value to an existing substitution whose; pattern is ``%{name}``, or it reports an error if there are no substitutions; with that pattern or if there are multiple substitutions whose patterns; contain ``%{name}``. The substitution's current position in the substitution; list does not change so that expansion order relative to other existing; substitutions is preserved. The following properties apply to both the ``DEFINE:`` and ``REDEFINE:``; directives:. - **Substitution name**: In the directive, whitespace immediately before or; after ``%{name}`` is optional and discarded. ``%{name}`` must start with; ``%{``, it must end with ``}``, and the rest must start with a letter or; underscore and contain only alphanumeric characters, hyphens, underscores, and; colons. This syntax has a few advantages:. - It is impossible for ``%{name}`` to contain se",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:34213,Modifiability,config,configuration,34213,"signs the specified value to an existing substitution whose; pattern is ``%{name}``, or it reports an error if there are no substitutions; with that pattern or if there are multiple substitutions whose patterns; contain ``%{name}``. The substitution's current position in the substitution; list does not change so that expansion order relative to other existing; substitutions is preserved. The following properties apply to both the ``DEFINE:`` and ``REDEFINE:``; directives:. - **Substitution name**: In the directive, whitespace immediately before or; after ``%{name}`` is optional and discarded. ``%{name}`` must start with; ``%{``, it must end with ``}``, and the rest must start with a letter or; underscore and contain only alphanumeric characters, hyphens, underscores, and; colons. This syntax has a few advantages:. - It is impossible for ``%{name}`` to contain sequences that are special in; python's ``re.sub`` patterns. Otherwise, attempting to specify; ``%{name}`` as a substitution pattern in a lit configuration file could; produce confusing expansions.; - The braces help avoid the possibility that another substitution's pattern; will match part of ``%{name}`` or vice-versa, producing confusing; expansions. However, the patterns of substitutions defined by lit; configuration files and by lit itself are not restricted to this form, so; overlaps are still theoretically possible. - **Substitution value**: The value includes all text from the first; non-whitespace character after ``=`` to the last non-whitespace character. If; there is no non-whitespace character after ``=``, the value is the empty; string. Escape sequences that can appear in python ``re.sub`` replacement; strings are treated as plain text in the value.; - **Line continuations**: If the last non-whitespace character on the line after; ``:`` is ``\``, then the next directive must use the same directive keyword; (e.g., ``DEFINE:``) , and it is an error if there is no additional directive.; That directive s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:34481,Modifiability,config,configuration,34481,"o that expansion order relative to other existing; substitutions is preserved. The following properties apply to both the ``DEFINE:`` and ``REDEFINE:``; directives:. - **Substitution name**: In the directive, whitespace immediately before or; after ``%{name}`` is optional and discarded. ``%{name}`` must start with; ``%{``, it must end with ``}``, and the rest must start with a letter or; underscore and contain only alphanumeric characters, hyphens, underscores, and; colons. This syntax has a few advantages:. - It is impossible for ``%{name}`` to contain sequences that are special in; python's ``re.sub`` patterns. Otherwise, attempting to specify; ``%{name}`` as a substitution pattern in a lit configuration file could; produce confusing expansions.; - The braces help avoid the possibility that another substitution's pattern; will match part of ``%{name}`` or vice-versa, producing confusing; expansions. However, the patterns of substitutions defined by lit; configuration files and by lit itself are not restricted to this form, so; overlaps are still theoretically possible. - **Substitution value**: The value includes all text from the first; non-whitespace character after ``=`` to the last non-whitespace character. If; there is no non-whitespace character after ``=``, the value is the empty; string. Escape sequences that can appear in python ``re.sub`` replacement; strings are treated as plain text in the value.; - **Line continuations**: If the last non-whitespace character on the line after; ``:`` is ``\``, then the next directive must use the same directive keyword; (e.g., ``DEFINE:``) , and it is an error if there is no additional directive.; That directive serves as a continuation. That is, before following the rules; above to parse the text after ``:`` in either directive, lit joins that text; together to form a single directive, replaces the ``\`` with a single space,; and removes any other whitespace that is now adjacent to that space. A; continuation can be co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:36839,Modifiability,config,configuration,36839,"tutions are not defined in the proper order, some will remain in the; ``RUN:`` line unexpanded. For example, the following directives refer to; ``%{inner}`` within ``%{outer}`` but do not define ``%{inner}`` until after; ``%{outer}``:. .. code-block:: llvm. ; By default, this definition order does not enable full expansion. ; DEFINE: %{outer} = %{inner}; ; DEFINE: %{inner} = expanded. ; RUN: echo '%{outer}'. ``DEFINE:`` inserts substitutions at the start of the substitution list, so; ``%{inner}`` expands first but has no effect because the original ``RUN:`` line; does not contain ``%{inner}``. Next, ``%{outer}`` expands, and the output of; the ``echo`` command becomes:. .. code-block:: shell. %{inner}. Of course, one way to fix this simple case is to reverse the definitions of; ``%{outer}`` and ``%{inner}``. However, if a test has a complex set of; substitutions that can all reference each other, there might not exist a; sufficient substitution order. To address such use cases, lit configuration files support; ``config.recursiveExpansionLimit``, which can be set to a non-negative integer; to specify the maximum number of passes through the substitution list. Thus, in; the above example, setting the limit to 2 would cause lit to make a second pass; that expands ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. expanded. To improve performance, lit will stop making passes when it notices the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:36870,Modifiability,config,config,36870,"tutions are not defined in the proper order, some will remain in the; ``RUN:`` line unexpanded. For example, the following directives refer to; ``%{inner}`` within ``%{outer}`` but do not define ``%{inner}`` until after; ``%{outer}``:. .. code-block:: llvm. ; By default, this definition order does not enable full expansion. ; DEFINE: %{outer} = %{inner}; ; DEFINE: %{inner} = expanded. ; RUN: echo '%{outer}'. ``DEFINE:`` inserts substitutions at the start of the substitution list, so; ``%{inner}`` expands first but has no effect because the original ``RUN:`` line; does not contain ``%{inner}``. Next, ``%{outer}`` expands, and the output of; the ``echo`` command becomes:. .. code-block:: shell. %{inner}. Of course, one way to fix this simple case is to reverse the definitions of; ``%{outer}`` and ``%{inner}``. However, if a test has a complex set of; substitutions that can all reference each other, there might not exist a; sufficient substitution order. To address such use cases, lit configuration files support; ``config.recursiveExpansionLimit``, which can be set to a non-negative integer; to specify the maximum number of passes through the substitution list. Thus, in; the above example, setting the limit to 2 would cause lit to make a second pass; that expands ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. expanded. To improve performance, lit will stop making passes when it notices the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:37723,Modifiability,config,configuration,37723,"er, there might not exist a; sufficient substitution order. To address such use cases, lit configuration files support; ``config.recursiveExpansionLimit``, which can be set to a non-negative integer; to specify the maximum number of passes through the substitution list. Thus, in; the above example, setting the limit to 2 would cause lit to make a second pass; that expands ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. expanded. To improve performance, lit will stop making passes when it notices the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm tool name with a custom command line. This; allows to specify custom paths and default arguments for these tools.; Example:. % llvm-lit ""-Dllc=llc -verify-machineinstrs"". ``run_long_tests``; Enable the execution of long running tests. ``llvm_site_config``; Load the specified lit configuration instead of the default one. Other Features; --------------. To make RUN line writing easier, there are several helper programs. These; helpers are in the PATH when running tests, so you can just call them using; their name. For example:. ``not``; This program runs its arguments and then inverts the result code from it.; Zero result codes become 1. Non-zero result codes become 0. To make the output more useful, :program:`lit` will scan; the lines of the test case for ones that contain a pattern that matches; ``PR[0-9]+``. This is the syntax for specifying a PR (Problem Report) number; that is related to th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:38123,Modifiability,config,configuration,38123,"ds ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. expanded. To improve performance, lit will stop making passes when it notices the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm tool name with a custom command line. This; allows to specify custom paths and default arguments for these tools.; Example:. % llvm-lit ""-Dllc=llc -verify-machineinstrs"". ``run_long_tests``; Enable the execution of long running tests. ``llvm_site_config``; Load the specified lit configuration instead of the default one. Other Features; --------------. To make RUN line writing easier, there are several helper programs. These; helpers are in the PATH when running tests, so you can just call them using; their name. For example:. ``not``; This program runs its arguments and then inverts the result code from it.; Zero result codes become 1. Non-zero result codes become 0. To make the output more useful, :program:`lit` will scan; the lines of the test case for ones that contain a pattern that matches; ``PR[0-9]+``. This is the syntax for specifying a PR (Problem Report) number; that is related to the test case. The number after ""PR"" specifies the; LLVM Bugzilla number. When a PR number is specified, it will be used in; the pass/fail reporting. This is useful to quickly get some context when; a test fails. Finally, any line that contains ""END."" will cause the special; interpretation of lines to terminate. This is generally done right after; the last RUN: line. This",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:3748,Performance,perform,performance,3748,"ts, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:3868,Performance,optimiz,optimizes,3868,"ts, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:5325,Performance,perform,performance,5325," is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:9069,Performance,perform,performs,9069,"rectories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; executes to run the test case. The syntax of the RUN lines is similar to a; shell's syntax for pipelines including I/O redirection and variable; substitution. However, even though these lines may *look* like a shell; script, they are not. RUN lines are interpreted by :program:`lit`.; Consequently, the syntax differs from shell in a few ways. You can specify; as many RUN lines as needed. :program:`lit` performs substitution on each RUN line to replace LLVM tool names; with the full paths to the executable built for each tool (in; ``$(LLVM_OBJ_ROOT)/bin``). This ensures that :program:`lit` does; not invoke any stray LLVM tools in the user's path during testing. Each RUN line is executed on its own, distinct from other lines unless; its last character is ``\``. This continuation character causes the RUN; line to be concatenated with the next one. In this way you can build up; long pipelines of commands without making huge line lengths. The lines; ending in ``\`` are concatenated until a RUN line that doesn't end in; ``\`` is found. This concatenated set of RUN lines then constitutes one; execution. :program:`lit` will substitute variables and arrange for the pipeline; to be executed. If any process in the pipeline fails, the entire line (and; test case) fails too. Below is an example of legal RUN lines in a ``.ll`` file:. .. code-block:: llvm. ; RUN: llvm-as < %s | llvm-dis > %t1; ; RUN: llvm-dis < %s.bc-13 > %t2; ; RUN: diff %t1 %t2. As with a Unix shel",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:12922,Performance,optimiz,optimization,12922,"and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likel",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:13936,Performance,optimiz,optimizations,13936,"l show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumbering on future test modifications. These can be removed by; running the test through ``opt -S -passes=instnamer``.; - Try to give values (including variables, blocks and functions) meaningful; names, and avoid retaining complex names generated by the optimization; pipeline (such as ``%foo.0.0.0.0.0.0``). Extra files; -----------. If your test requires extra files besides the file containing the ``RUN:`` lines; and the extra files are small, consider specifying them in the same file and; using ``split-file`` to extract them. For example,. .. code-block:: llvm. ;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:14574,Performance,optimiz,optimization,14574,"oned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumbering on future test modifications. These can be removed by; running the test through ``opt -S -passes=instnamer``.; - Try to give values (including variables, blocks and functions) meaningful; names, and avoid retaining complex names generated by the optimization; pipeline (such as ``%foo.0.0.0.0.0.0``). Extra files; -----------. If your test requires extra files besides the file containing the ``RUN:`` lines; and the extra files are small, consider specifying them in the same file and; using ``split-file`` to extract them. For example,. .. code-block:: llvm. ; RUN: split-file %s %t; ; RUN: llvm-link -S %t/a.ll %t/b.ll | FileCheck %s. ; CHECK: ... ;--- a.ll; ...; ;--- b.ll; ... The parts are separated by the regex ``^(.|//)--- <part>``. If you want to test relative line numbers like ``[[#@LINE+1]]``, specify; ``--leading-lines`` to add leading empty lines to preserve line numbers. If the extra files are large, the idiomatic place to put them is in a subdirectory ``Inputs``.; You can then refer to the extra files as ``%S/Inputs/foo.bar``. For example, consider ``test/Linker/ident.ll``. The directory structure is; as follows::. test/; Linker/; ident.ll; Inputs/; ident.a.ll; ident.b.ll.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:16999,Performance,load,load,16999,"a !{metadata !""Compiler V2""}. ;;;;; Inputs/ident.b.ll:. !llvm.ident = !{!0}; !0 = metadata !{metadata !""Compiler V3""}. For symmetry reasons, ``ident.ll`` is just a dummy file that doesn't; actually participate in the test besides holding the ``RUN:`` lines. .. note::. Some existing tests use ``RUN: true`` in extra files instead of just; putting the extra files in an ``Inputs/`` directory. This pattern is; deprecated. Fragile tests; -------------. It is easy to write a fragile test that would fail spuriously if the tool being; tested outputs a full path to the input file. For example, :program:`opt` by; default outputs a ``ModuleID``:. .. code-block:: console. $ cat example.ll; define i32 @main() nounwind {; ret i32 0; }. $ opt -S /path/to/example.ll; ; ModuleID = '/path/to/example.ll'. define i32 @main() nounwind {; ret i32 0; }. ``ModuleID`` can unexpectedly match against ``CHECK`` lines. For example:. .. code-block:: llvm. ; RUN: opt -S %s | FileCheck. define i32 @main() nounwind {; ; CHECK-NOT: load; ret i32 0; }. This test will fail if placed into a ``download`` directory. To make your tests robust, always use ``opt ... < %s`` in the RUN line.; :program:`opt` does not output a ``ModuleID`` when input comes from stdin. Platform-Specific Tests; -----------------------. Whenever adding tests that require the knowledge of a specific platform,; either related to code generated, specific output or back-end features,; you must make sure to isolate the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:23788,Performance,perform,performed,23788,"ch is more appropriate in each case. **Using ``target=...``**. Checking the target triple can be tricky; it's easy to mis-specify. For; example, ``target=mips{{.*}}`` will match not only mips, but also mipsel,; mips64, and mips64el. ``target={{.*}}-linux-gnu`` will match; x86_64-unknown-linux-gnu, but not armv8l-unknown-linux-gnueabihf.; Prefer to use hyphens to delimit triple components (``target=mips-{{.*}}``); and it's generally a good idea to use a trailing wildcard to allow for; unexpected suffixes. Also, it's generally better to write regular expressions that use entire; triple components, than to do something clever to shorten them. For; example, to match both freebsd and netbsd in an expression, you could write; ``target={{.*(free|net)bsd.*}}`` and that would work. However, it would; prevent a ``grep freebsd`` from finding this test. Better to use:; ``target={{.+-freebsd.*}} || target={{.+-netbsd.*}}``. Substitutions; -------------. Besides replacing LLVM tool names the following substitutions are performed in; RUN lines:. ``%%``; Replaced by a single ``%``. This allows escaping other substitutions. ``%s``; File path to the test case's source. This is suitable for passing on the; command line as the input to an LLVM tool. Example: ``/home/user/llvm/test/MC/ELF/foo_test.s``. ``%S``; Directory path to the test case's source. Example: ``/home/user/llvm/test/MC/ELF``. ``%t``; File path to a temporary file name that could be used for this test case.; The file name won't conflict with other test cases. You can append to it; if you need multiple temporaries. This is useful as the destination of; some redirected output. Example: ``/home/user/llvm.build/test/MC/ELF/Output/foo_test.s.tmp``. ``%T``; Directory of ``%t``. Deprecated. Shouldn't be used, because it can be easily; misused and cause race conditions between tests. Use ``rm -rf %t && mkdir %t`` instead if a temporary directory is necessary. Example: ``/home/user/llvm.build/test/MC/ELF/Output``. ``%{pathsep}``.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:24589,Performance,race condition,race conditions,24589,"event a ``grep freebsd`` from finding this test. Better to use:; ``target={{.+-freebsd.*}} || target={{.+-netbsd.*}}``. Substitutions; -------------. Besides replacing LLVM tool names the following substitutions are performed in; RUN lines:. ``%%``; Replaced by a single ``%``. This allows escaping other substitutions. ``%s``; File path to the test case's source. This is suitable for passing on the; command line as the input to an LLVM tool. Example: ``/home/user/llvm/test/MC/ELF/foo_test.s``. ``%S``; Directory path to the test case's source. Example: ``/home/user/llvm/test/MC/ELF``. ``%t``; File path to a temporary file name that could be used for this test case.; The file name won't conflict with other test cases. You can append to it; if you need multiple temporaries. This is useful as the destination of; some redirected output. Example: ``/home/user/llvm.build/test/MC/ELF/Output/foo_test.s.tmp``. ``%T``; Directory of ``%t``. Deprecated. Shouldn't be used, because it can be easily; misused and cause race conditions between tests. Use ``rm -rf %t && mkdir %t`` instead if a temporary directory is necessary. Example: ``/home/user/llvm.build/test/MC/ELF/Output``. ``%{pathsep}``. Expands to the path separator, i.e. ``:`` (or ``;`` on Windows). ``${fs-src-root}``; Expands to the root component of file system paths for the source directory,; i.e. ``/`` on Unix systems or ``C:\`` (or another drive) on Windows. ``${fs-tmp-root}``; Expands to the root component of file system paths for the test's temporary; directory, i.e. ``/`` on Unix systems or ``C:\`` (or another drive) on; Windows. ``${fs-sep}``; Expands to the file system separator, i.e. ``/`` or ``\`` on Windows. ``%/s, %/S, %/t, %/T``. Act like the corresponding substitution above but replace any ``\``; character with a ``/``. This is useful to normalize path separators. Example: ``%s: C:\Desktop Files/foo_test.s.tmp``. Example: ``%/s: C:/Desktop Files/foo_test.s.tmp``. ``%{s:real}, %{S:real}, %{t:real}, %{T:real}``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:31207,Performance,perform,performed,31207,"md; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0; ; REDEFINE: %{fcflags} = -check-prefix=NO-SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-unknown-linux-gnu; ; REDEFINE: %{fcflags} = -check-prefix=NO-SIMD; ; RUN: %{check}. Besides providing initial values, the initial ``DEFINE:`` directives for the; parameter substitutions in the above example serve a second purpose: they; establish the substitution order so that both ``%{check}`` and its parameters; expand as desired. There's a simple way to remember the required definition; order in a test file: define a substitution before any substitution that might; refer to it. In general, substitution expansion behaves as follows:. - Upon arriving at each ``RUN:`` line, lit expands all substitutions in that; ``RUN:`` line using their current values from the substitution list. No; substitution expansion is performed immediately at ``DEFINE:`` and; ``REDEFINE:`` directives except ``%(line)``, ``%(line+<number>)``, and; ``%(line-<number>)``.; - When expanding substitutions in a ``RUN:`` line, lit makes only one pass; through the substitution list by default. In this case, a substitution must; have been inserted earlier in the substitution list than any substitution; appearing in its value in order for the latter to expand. (For greater; flexibility, you can enable multiple passes through the substitution list by; setting `recursiveExpansionLimit`_ in a lit configuration file.); - While lit configuration files can insert anywhere in the substitution list,; the insertion behavior of the ``DEFINE:`` and ``REDEFINE:`` directives is; specified below and is designed specifically for the use case presented in the; example above.; - Defining a substitution in terms of itself, whether directly or via other; substitutions, should be avoided. It usually produces an infinitely recursive; definition that cannot be fully expanded. It does *not* define th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:37259,Performance,perform,performance,37259,"of the substitution list, so; ``%{inner}`` expands first but has no effect because the original ``RUN:`` line; does not contain ``%{inner}``. Next, ``%{outer}`` expands, and the output of; the ``echo`` command becomes:. .. code-block:: shell. %{inner}. Of course, one way to fix this simple case is to reverse the definitions of; ``%{outer}`` and ``%{inner}``. However, if a test has a complex set of; substitutions that can all reference each other, there might not exist a; sufficient substitution order. To address such use cases, lit configuration files support; ``config.recursiveExpansionLimit``, which can be set to a non-negative integer; to specify the maximum number of passes through the substitution list. Thus, in; the above example, setting the limit to 2 would cause lit to make a second pass; that expands ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. expanded. To improve performance, lit will stop making passes when it notices the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm tool name with a custom command line. This; allows to specify custom paths and default arguments for these tools.; Example:. % llvm-lit ""-Dllc=llc -verify-machineinstrs"". ``run_long_tests``; Enable the execution of long running tests. ``llvm_site_config``; Load the specified lit configuration instead of the default one. Other Features; --------------. To make RUN line writing easier, there are several helper programs. These; helpers are in the PATH when r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:10440,Safety,avoid,avoid,10440,"ncatenated with the next one. In this way you can build up; long pipelines of commands without making huge line lengths. The lines; ending in ``\`` are concatenated until a RUN line that doesn't end in; ``\`` is found. This concatenated set of RUN lines then constitutes one; execution. :program:`lit` will substitute variables and arrange for the pipeline; to be executed. If any process in the pipeline fails, the entire line (and; test case) fails too. Below is an example of legal RUN lines in a ``.ll`` file:. .. code-block:: llvm. ; RUN: llvm-as < %s | llvm-dis > %t1; ; RUN: llvm-dis < %s.bc-13 > %t2; ; RUN: diff %t1 %t2. As with a Unix shell, the RUN lines permit pipelines and I/O; redirection to be used. There are some quoting rules that you must pay attention to when writing; your RUN lines. In general nothing needs to be quoted. :program:`lit` won't; strip off any quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:14527,Safety,avoid,avoid,14527,"oned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumbering on future test modifications. These can be removed by; running the test through ``opt -S -passes=instnamer``.; - Try to give values (including variables, blocks and functions) meaningful; names, and avoid retaining complex names generated by the optimization; pipeline (such as ``%foo.0.0.0.0.0.0``). Extra files; -----------. If your test requires extra files besides the file containing the ``RUN:`` lines; and the extra files are small, consider specifying them in the same file and; using ``split-file`` to extract them. For example,. .. code-block:: llvm. ; RUN: split-file %s %t; ; RUN: llvm-link -S %t/a.ll %t/b.ll | FileCheck %s. ; CHECK: ... ;--- a.ll; ...; ;--- b.ll; ... The parts are separated by the regex ``^(.|//)--- <part>``. If you want to test relative line numbers like ``[[#@LINE+1]]``, specify; ``--leading-lines`` to add leading empty lines to preserve line numbers. If the extra files are large, the idiomatic place to put them is in a subdirectory ``Inputs``.; You can then refer to the extra files as ``%S/Inputs/foo.bar``. For example, consider ``test/Linker/ident.ll``. The directory structure is; as follows::. test/; Linker/; ident.ll; Inputs/; ident.a.ll; ident.b.ll.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:19821,Safety,detect,detect,19821,"u=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:32140,Safety,avoid,avoided,32140,"utions in that; ``RUN:`` line using their current values from the substitution list. No; substitution expansion is performed immediately at ``DEFINE:`` and; ``REDEFINE:`` directives except ``%(line)``, ``%(line+<number>)``, and; ``%(line-<number>)``.; - When expanding substitutions in a ``RUN:`` line, lit makes only one pass; through the substitution list by default. In this case, a substitution must; have been inserted earlier in the substitution list than any substitution; appearing in its value in order for the latter to expand. (For greater; flexibility, you can enable multiple passes through the substitution list by; setting `recursiveExpansionLimit`_ in a lit configuration file.); - While lit configuration files can insert anywhere in the substitution list,; the insertion behavior of the ``DEFINE:`` and ``REDEFINE:`` directives is; specified below and is designed specifically for the use case presented in the; example above.; - Defining a substitution in terms of itself, whether directly or via other; substitutions, should be avoided. It usually produces an infinitely recursive; definition that cannot be fully expanded. It does *not* define the; substitution in terms of its previous value, even when using ``REDEFINE:``. The relationship between the ``DEFINE:`` and ``REDEFINE:`` directive is; analogous to the relationship between a variable declaration and variable; assignment in many programming languages:. - ``DEFINE: %{name} = value``. This directive assigns the specified value to a new substitution whose; pattern is ``%{name}``, or it reports an error if there is already a; substitution whose pattern contains ``%{name}`` because that could produce; confusing expansions (e.g., a lit configuration file might define a; substitution with the pattern ``%{name}\[0\]``). The new substitution is; inserted at the start of the substitution list so that it will expand first.; Thus, its value can contain any substitution previously defined, whether in; the same test fi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:34288,Safety,avoid,avoid,34288,"t pattern or if there are multiple substitutions whose patterns; contain ``%{name}``. The substitution's current position in the substitution; list does not change so that expansion order relative to other existing; substitutions is preserved. The following properties apply to both the ``DEFINE:`` and ``REDEFINE:``; directives:. - **Substitution name**: In the directive, whitespace immediately before or; after ``%{name}`` is optional and discarded. ``%{name}`` must start with; ``%{``, it must end with ``}``, and the rest must start with a letter or; underscore and contain only alphanumeric characters, hyphens, underscores, and; colons. This syntax has a few advantages:. - It is impossible for ``%{name}`` to contain sequences that are special in; python's ``re.sub`` patterns. Otherwise, attempting to specify; ``%{name}`` as a substitution pattern in a lit configuration file could; produce confusing expansions.; - The braces help avoid the possibility that another substitution's pattern; will match part of ``%{name}`` or vice-versa, producing confusing; expansions. However, the patterns of substitutions defined by lit; configuration files and by lit itself are not restricted to this form, so; overlaps are still theoretically possible. - **Substitution value**: The value includes all text from the first; non-whitespace character after ``=`` to the last non-whitespace character. If; there is no non-whitespace character after ``=``, the value is the empty; string. Escape sequences that can appear in python ``re.sub`` replacement; strings are treated as plain text in the value.; - **Line continuations**: If the last non-whitespace character on the line after; ``:`` is ``\``, then the next directive must use the same directive keyword; (e.g., ``DEFINE:``) , and it is an error if there is no additional directive.; That directive serves as a continuation. That is, before following the rules; above to parse the text after ``:`` in either directive, lit joins that text; togethe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:39326,Safety,avoid,avoiding,39326,"ting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm tool name with a custom command line. This; allows to specify custom paths and default arguments for these tools.; Example:. % llvm-lit ""-Dllc=llc -verify-machineinstrs"". ``run_long_tests``; Enable the execution of long running tests. ``llvm_site_config``; Load the specified lit configuration instead of the default one. Other Features; --------------. To make RUN line writing easier, there are several helper programs. These; helpers are in the PATH when running tests, so you can just call them using; their name. For example:. ``not``; This program runs its arguments and then inverts the result code from it.; Zero result codes become 1. Non-zero result codes become 0. To make the output more useful, :program:`lit` will scan; the lines of the test case for ones that contain a pattern that matches; ``PR[0-9]+``. This is the syntax for specifying a PR (Problem Report) number; that is related to the test case. The number after ""PR"" specifies the; LLVM Bugzilla number. When a PR number is specified, it will be used in; the pass/fail reporting. This is useful to quickly get some context when; a test fails. Finally, any line that contains ""END."" will cause the special; interpretation of lines to terminate. This is generally done right after; the last RUN: line. This has two side effects:. (a) it prevents special interpretation of lines that are part of the test; program, not the instructions to the test case, and. (b) it speeds things up for really big test cases by avoiding; interpretation of the remainder of the file.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:4352,Security,validat,validate,4352," such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:13380,Security,access,access,13380,"mmon scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumber",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:264,Testability,test,testing,264,"=================================; LLVM Testing Infrastructure Guide; =================================. .. contents::; :local:. .. toctree::; :hidden:. TestSuiteGuide; TestSuiteMakefileGuide. Overview; ========. This document is the reference manual for the LLVM testing; infrastructure. It documents the structure of the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a spe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:328,Testability,test,testing,328,"=================================; LLVM Testing Infrastructure Guide; =================================. .. contents::; :local:. .. toctree::; :hidden:. TestSuiteGuide; TestSuiteMakefileGuide. Overview; ========. This document is the reference manual for the LLVM testing; infrastructure. It documents the structure of the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a spe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:405,Testability,test,tests,405,"=================================; LLVM Testing Infrastructure Guide; =================================. .. contents::; :local:. .. toctree::; :hidden:. TestSuiteGuide; TestSuiteMakefileGuide. Overview; ========. This document is the reference manual for the LLVM testing; infrastructure. It documents the structure of the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a spe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:465,Testability,test,testing,465,"=================================; LLVM Testing Infrastructure Guide; =================================. .. contents::; :local:. .. toctree::; :hidden:. TestSuiteGuide; TestSuiteMakefileGuide. Overview; ========. This document is the reference manual for the LLVM testing; infrastructure. It documents the structure of the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a spe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:697,Testability,test,testing,697,"=================================; LLVM Testing Infrastructure Guide; =================================. .. contents::; :local:. .. toctree::; :hidden:. TestSuiteGuide; TestSuiteMakefileGuide. Overview; ========. This document is the reference manual for the LLVM testing; infrastructure. It documents the structure of the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a spe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:755,Testability,test,tests,755,"=================================; LLVM Testing Infrastructure Guide; =================================. .. contents::; :local:. .. toctree::; :hidden:. TestSuiteGuide; TestSuiteMakefileGuide. Overview; ========. This document is the reference manual for the LLVM testing; infrastructure. It documents the structure of the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a spe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:768,Testability,test,tests,768,"=================================; LLVM Testing Infrastructure Guide; =================================. .. contents::; :local:. .. toctree::; :hidden:. TestSuiteGuide; TestSuiteMakefileGuide. Overview; ========. This document is the reference manual for the LLVM testing; infrastructure. It documents the structure of the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a spe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:786,Testability,test,tests,786,"=================================; LLVM Testing Infrastructure Guide; =================================. .. contents::; :local:. .. toctree::; :hidden:. TestSuiteGuide; TestSuiteMakefileGuide. Overview; ========. This document is the reference manual for the LLVM testing; infrastructure. It documents the structure of the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a spe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:821,Testability,test,tests,821,"=================================; LLVM Testing Infrastructure Guide; =================================. .. contents::; :local:. .. toctree::; :hidden:. TestSuiteGuide; TestSuiteMakefileGuide. Overview; ========. This document is the reference manual for the LLVM testing; infrastructure. It documents the structure of the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a spe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:843,Testability,test,tests,843,"=================================; LLVM Testing Infrastructure Guide; =================================. .. contents::; :local:. .. toctree::; :hidden:. TestSuiteGuide; TestSuiteMakefileGuide. Overview; ========. This document is the reference manual for the LLVM testing; infrastructure. It documents the structure of the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a spe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:934,Testability,test,test,934,"=================================; LLVM Testing Infrastructure Guide; =================================. .. contents::; :local:. .. toctree::; :hidden:. TestSuiteGuide; TestSuiteMakefileGuide. Overview; ========. This document is the reference manual for the LLVM testing; infrastructure. It documents the structure of the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a spe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:1049,Testability,test,tests,1049,". contents::; :local:. .. toctree::; :hidden:. TestSuiteGuide; TestSuiteMakefileGuide. Overview; ========. This document is the reference manual for the LLVM testing; infrastructure. It documents the structure of the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:1084,Testability,test,test,1084,". contents::; :local:. .. toctree::; :hidden:. TestSuiteGuide; TestSuiteMakefileGuide. Overview; ========. This document is the reference manual for the LLVM testing; infrastructure. It documents the structure of the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:1102,Testability,test,test-suite,1102,". contents::; :local:. .. toctree::; :hidden:. TestSuiteGuide; TestSuiteMakefileGuide. Overview; ========. This document is the reference manual for the LLVM testing; infrastructure. It documents the structure of the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:1132,Testability,test,test-suite,1132,". contents::; :local:. .. toctree::; :hidden:. TestSuiteGuide; TestSuiteMakefileGuide. Overview; ========. This document is the reference manual for the LLVM testing; infrastructure. It documents the structure of the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:1198,Testability,test,test-suite,1198,"rview; ========. This document is the reference manual for the LLVM testing; infrastructure. It documents the structure of the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:1248,Testability,test,tests,1248,"the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLV",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:1292,Testability,test,tests,1292,"the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLV",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:1340,Testability,test,test-suite,1340,"the LLVM testing; infrastructure, the tools needed to use it, and how to add and run; tests. Requirements; ============. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLV",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:1428,Testability,test,tests,1428,"====. In order to use the LLVM testing infrastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:1452,Testability,test,tests,1452,"frastructure, you will need all of the; software required to build LLVM, as well as `Python <http://python.org>`_ 3.6 or; later. LLVM Testing Infrastructure Organization; ========================================. The LLVM testing infrastructure contains three major categories of tests:; unit tests, regression tests and whole programs. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:1725,Testability,test,tests,1725,"grams. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer""",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:1845,Testability,test,tests,1845,"grams. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer""",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:1855,Testability,test,testing,1855,"grams. The unit tests and regression; tests are contained inside the LLVM repository itself under ``llvm/unittests``; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer""",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:1915,Testability,test,tests,1915,"; and ``llvm/test`` respectively and are expected to always pass -- they should be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileChec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:1955,Testability,test,tests,1955,"ld be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:1991,Testability,test,test,1991,"ld be; run before every commit. The whole programs tests are referred to as the ""LLVM test suite"" (or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:2127,Testability,test,tested,2127,"(or; ""test-suite"") and are in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:2141,Testability,test,tests,2141,".git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code wh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:2196,Testability,test,testing,2196,".git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code wh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:2265,Testability,test,test,2265,".git>`_.; For historical reasons, these tests are also referred to as the ""nightly; tests"" in places, which is less ambiguous than ""test-suite"" and remains; in use although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code wh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:2335,Testability,test,test,2335," although we run them much more often than nightly. Unit tests; ----------. Unit tests are written using `Google Test <https://github.com/google/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. T",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:2550,Testability,benchmark,benchmark,2550,"oogle/googletest/blob/master/docs/primer.md>`_; and `Google Mock <https://github.com/google/googletest/blob/master/docs/gmock_for_dummies.md>`_; and are located in the ``llvm/unittests`` directory.; In general unit tests are reserved for targeting the support library and other; generic data structure, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:2699,Testability,test,tested,2699,"cture, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the progr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:2766,Testability,test,tests,2766,"cture, we prefer relying on regression tests for testing; transformations and analysis on the IR. Regression tests; ----------------. The regression tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the progr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:2935,Testability,test,test,2935,"ssion tests are small pieces of code that test a specific; feature of LLVM or trigger a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:3032,Testability,test,test,3032," a specific bug in LLVM. The language they are; written in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`T",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:3103,Testability,test,test,3103,"in depends on the part of LLVM being tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:3111,Testability,test,test-suite,3111,"ng tested. These tests are driven by; the :doc:`Lit <CommandGuide/lit>` testing tool (which is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:3145,Testability,test,test,3145,"h is part of LLVM), and; are located in the ``llvm/test`` directory. Typically when a bug is found in LLVM, a regression test containing just; enough code to reproduce the problem should be written and placed; somewhere underneath this directory. For example, it can be a small; piece of LLVM IR distilled from an actual application or benchmark. Testing Analysis; ----------------. An analysis is a pass that infer properties on some part of the IR and not; transforming it. They are tested in general using the same infrastructure as the; regression tests, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:3705,Testability,test,tests,3705,"ts, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:3730,Testability,benchmark,benchmarking,3730,"ts, by creating a separate ""Printer"" pass to consume the analysis; result and print it on the standard output in a textual format suitable for; FileCheck.; See `llvm/test/Analysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:3903,Testability,test,test-suite,3903,"alysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests includin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:3934,Testability,test,test-suite,3934,"alysis/BranchProbabilityInfo/loop.ll <https://github.com/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests includin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:4000,Testability,test,test-suite,4000,"/llvm/llvm-project/blob/main/llvm/test/Analysis/BranchProbabilityInfo/loop.ll>`_; for an example of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:4084,Testability,test,tests,4084,"mple of such test. ``test-suite``; --------------. The test suite contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:4124,Testability,test,test,4124," contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:4144,Testability,test,tests,4144," contains whole programs, which are pieces of code which; can be compiled and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:4198,Testability,test,test,4198," and linked into a stand-alone program that can be; executed. These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:4272,Testability,test,tests,4272,"These programs are generally written in high level languages; such as C or C++. These programs are compiled using a user specified compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. I",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:4410,Testability,test,test,4410," compiler and set of; flags, and then executed to capture the program output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -D",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:4448,Testability,test,test,4448,"gram output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you ha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:4494,Testability,test,tests,4494,"gram output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you ha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:4510,Testability,test,tests,4510,"gram output and timing; information. The output of these programs is compared to a reference; output to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you ha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:4559,Testability,test,tests,4559,"utput to ensure that the program is being compiled correctly. In addition to compiling and executing programs, whole program tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang te",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:4632,Testability,test,tests,4632,"rogram tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:4725,Testability,test,test,4725,"rogram tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:4750,Testability,test,tests,4750,"rogram tests; serve as a way of benchmarking LLVM performance, both in terms of the; efficiency of the programs generated as well as the speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:4846,Testability,test,tests,4846,"he speed with which; LLVM compiles, optimizes, and generates code. The test-suite is located in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make ch",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:4880,Testability,test,test-suite,4880,"ted in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:4928,Testability,test,tests,4928,"ted in the ``test-suite``; `repository on GitHub <https://github.com/llvm/llvm-test-suite.git>`_. See the :doc:`TestSuiteGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:5034,Testability,test,tests,5034,"teGuide` for details. Debugging Information tests; ---------------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LL",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:5096,Testability,test,tests,5096,"------------------. The test suite contains tests to check quality of debugging information.; The test are written in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:5215,Testability,test,tests,5215," in C based languages or in LLVM assembly language. These tests are compiled and run under a debugger. The debugger output; is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:5317,Testability,test,testing,5317," is checked to validate of debugging information. See README.txt in the; test suite for more information. This test suite is located in the; ``cross-project-tests/debuginfo-tests`` directory. Quick start; ===========. The tests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:5578,Testability,test,tests,5578,"ests are located in two separate repositories. The unit and; regression tests are in the main ""llvm""/ directory under the directories; ``llvm/unittests`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:5658,Testability,test,tests,5658,"ts`` and ``llvm/test`` (so you get these tests for free with the; main LLVM tree). Use ``make check-all`` to run the unit and regression tests; after building LLVM. The ``test-suite`` module contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Infor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:5876,Testability,test,testing,5876,"le contains more comprehensive tests including whole C; and C++ programs. See the :doc:`TestSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:5948,Testability,test,tests,5948,"estSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests ar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:5968,Testability,test,tests,5968,"estSuiteGuide` for details. Unit and Regression tests; -------------------------. To run all of the LLVM unit tests use the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests ar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:6094,Testability,test,test,6094," the check-llvm-unit target:. .. code-block:: bash. % make check-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of sma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:6163,Testability,test,test,6163,"heck-llvm-unit. To run all of the LLVM regression tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ens",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:6223,Testability,test,tests,6223,"ssion tests use the check-llvm target:. .. code-block:: bash. % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The direc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:6271,Testability,test,test,6271," % make check-llvm. In order to get reasonable testing performance, build LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:6304,Testability,test,tests,6304,"uild LLVM and subprojects; in release mode, i.e. .. code-block:: bash. % cmake -DCMAKE_BUILD_TYPE=""Release"" -DLLVM_ENABLE_ASSERTIONS=On. If you have `Clang <https://clang.llvm.org/>`_ checked out and built, you; can run the LLVM and Clang tests simultaneously using:. .. code-block:: bash. % make check-all. To run the tests with Valgrind (Memcheck by default), use the ``LIT_ARGS`` make; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:6717,Testability,test,tests,6717,"ake; variable to pass the required options to lit. For example, you can use:. .. code-block:: bash. % make check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` fil",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:6782,Testability,test,tests,6782,"ke check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:6819,Testability,test,tests,6819,"ke check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:6915,Testability,test,test,6915,"To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:6978,Testability,test,tests,6978,"pt which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to ge",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:7044,Testability,test,test,7044,"pt which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to ge",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:7109,Testability,test,tests,7109,"-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:7322,Testability,test,tests,7322,"n psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:7374,Testability,test,test,7374,"install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:7523,Testability,test,test,7523,"ll users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:7582,Testability,test,test,7582,"ng the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:7650,Testability,test,tests,7650," man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:7683,Testability,test,tests,7683," man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:7790,Testability,test,tests,7790,"debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; executes to run the test case. The syntax of the RUN lines is similar to a; shell's syntax for pi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:7905,Testability,test,tests,7905,"ABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; executes to run the test case. The syntax of the RUN lines is similar to a; shell's syntax for pipelines including I/O redirection and variable; substitution. However, even though these line",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:7945,Testability,test,tests,7945,"=================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; executes to run the test case. The syntax of the RUN lines is similar to a; shell's syntax for pipelines including I/O redirection and variable; substitution. However, even though these lines may *look* like a shell; script, they are not. RUN lines are interpreted by :program",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:8096,Testability,test,tests,8096,"ory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; executes to run the test case. The syntax of the RUN lines is similar to a; shell's syntax for pipelines including I/O redirection and variable; substitution. However, even though these lines may *look* like a shell; script, they are not. RUN lines are interpreted by :program:`lit`.; Consequently, the syntax differs from shell in a few ways. You can specify; as many RUN lines as needed. :program:`lit` perfo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:8272,Testability,test,test,8272,"ression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; executes to run the test case. The syntax of the RUN lines is similar to a; shell's syntax for pipelines including I/O redirection and variable; substitution. However, even though these lines may *look* like a shell; script, they are not. RUN lines are interpreted by :program:`lit`.; Consequently, the syntax differs from shell in a few ways. You can specify; as many RUN lines as needed. :program:`lit` performs substitution on each RUN line to replace LLVM tool names; with the full paths to the executable built for each tool (in; ``$(LLVM_OBJ_ROOT)/bin``). This ensures that :program:`lit` does; not invoke any stray LLVM tools in the user's pat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:8442,Testability,test,test,8442," but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; executes to run the test case. The syntax of the RUN lines is similar to a; shell's syntax for pipelines including I/O redirection and variable; substitution. However, even though these lines may *look* like a shell; script, they are not. RUN lines are interpreted by :program:`lit`.; Consequently, the syntax differs from shell in a few ways. You can specify; as many RUN lines as needed. :program:`lit` performs substitution on each RUN line to replace LLVM tool names; with the full paths to the executable built for each tool (in; ``$(LLVM_OBJ_ROOT)/bin``). This ensures that :program:`lit` does; not invoke any stray LLVM tools in the user's path during testing. Each RUN line is executed on its own, distinct from other lines unless; i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:8495,Testability,test,test,8495,"est/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; executes to run the test case. The syntax of the RUN lines is similar to a; shell's syntax for pipelines including I/O redirection and variable; substitution. However, even though these lines may *look* like a shell; script, they are not. RUN lines are interpreted by :program:`lit`.; Consequently, the syntax differs from shell in a few ways. You can specify; as many RUN lines as needed. :program:`lit` performs substitution on each RUN line to replace LLVM tool names; with the full paths to the executable built for each tool (in; ``$(LLVM_OBJ_ROOT)/bin``). This ensures that :program:`lit` does; not invoke any stray LLVM tools in the user's path during testing. Each RUN line is executed on its own, distinct from other lines unless; its last character is ``\``. This continuation character causes the RUN; line to be concatenated with the next one. In th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:8684,Testability,test,test,8684,"n tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; executes to run the test case. The syntax of the RUN lines is similar to a; shell's syntax for pipelines including I/O redirection and variable; substitution. However, even though these lines may *look* like a shell; script, they are not. RUN lines are interpreted by :program:`lit`.; Consequently, the syntax differs from shell in a few ways. You can specify; as many RUN lines as needed. :program:`lit` performs substitution on each RUN line to replace LLVM tool names; with the full paths to the executable built for each tool (in; ``$(LLVM_OBJ_ROOT)/bin``). This ensures that :program:`lit` does; not invoke any stray LLVM tools in the user's path during testing. Each RUN line is executed on its own, distinct from other lines unless; its last character is ``\``. This continuation character causes the RUN; line to be concatenated with the next one. In this way you can build up; long pipelines of commands without making huge line lengths. The lines; ending in ``\`` are concat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:9323,Testability,test,testing,9323,"ile must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; executes to run the test case. The syntax of the RUN lines is similar to a; shell's syntax for pipelines including I/O redirection and variable; substitution. However, even though these lines may *look* like a shell; script, they are not. RUN lines are interpreted by :program:`lit`.; Consequently, the syntax differs from shell in a few ways. You can specify; as many RUN lines as needed. :program:`lit` performs substitution on each RUN line to replace LLVM tool names; with the full paths to the executable built for each tool (in; ``$(LLVM_OBJ_ROOT)/bin``). This ensures that :program:`lit` does; not invoke any stray LLVM tools in the user's path during testing. Each RUN line is executed on its own, distinct from other lines unless; its last character is ``\``. This continuation character causes the RUN; line to be concatenated with the next one. In this way you can build up; long pipelines of commands without making huge line lengths. The lines; ending in ``\`` are concatenated until a RUN line that doesn't end in; ``\`` is found. This concatenated set of RUN lines then constitutes one; execution. :program:`lit` will substitute variables and arrange for the pipeline; to be executed. If any process in the pipeline fails, the entire line (and; test case) fails too. Below is an example of legal RUN lines in a ``.ll`` file:. .. code-block:: llvm. ; RUN: llvm-as < %s | llvm-dis > %t1; ; RUN: llvm-dis < %s.bc-13 > %t2; ; RUN: diff %t1 %t2. As with a Unix shell, the RUN lines permit pipelines and I/O; redirection to be used. There are some quoting rules that you must pay attention to when writing",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:9924,Testability,test,test,9924,"UN lines are interpreted by :program:`lit`.; Consequently, the syntax differs from shell in a few ways. You can specify; as many RUN lines as needed. :program:`lit` performs substitution on each RUN line to replace LLVM tool names; with the full paths to the executable built for each tool (in; ``$(LLVM_OBJ_ROOT)/bin``). This ensures that :program:`lit` does; not invoke any stray LLVM tools in the user's path during testing. Each RUN line is executed on its own, distinct from other lines unless; its last character is ``\``. This continuation character causes the RUN; line to be concatenated with the next one. In this way you can build up; long pipelines of commands without making huge line lengths. The lines; ending in ``\`` are concatenated until a RUN line that doesn't end in; ``\`` is found. This concatenated set of RUN lines then constitutes one; execution. :program:`lit` will substitute variables and arrange for the pipeline; to be executed. If any process in the pipeline fails, the entire line (and; test case) fails too. Below is an example of legal RUN lines in a ``.ll`` file:. .. code-block:: llvm. ; RUN: llvm-as < %s | llvm-dis > %t1; ; RUN: llvm-dis < %s.bc-13 > %t2; ; RUN: diff %t1 %t2. As with a Unix shell, the RUN lines permit pipelines and I/O; redirection to be used. There are some quoting rules that you must pay attention to when writing; your RUN lines. In general nothing needs to be quoted. :program:`lit` won't; strip off any quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not se",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:10764,Testability,test,test,10764,"ution. :program:`lit` will substitute variables and arrange for the pipeline; to be executed. If any process in the pipeline fails, the entire line (and; test case) fails too. Below is an example of legal RUN lines in a ``.ll`` file:. .. code-block:: llvm. ; RUN: llvm-as < %s | llvm-dis > %t1; ; RUN: llvm-dis < %s.bc-13 > %t2; ; RUN: diff %t1 %t2. As with a Unix shell, the RUN lines permit pipelines and I/O; redirection to be used. There are some quoting rules that you must pay attention to when writing; your RUN lines. In general nothing needs to be quoted. :program:`lit` won't; strip off any quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically genera",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:10953,Testability,test,tests,10953,"nes in a ``.ll`` file:. .. code-block:: llvm. ; RUN: llvm-as < %s | llvm-dis > %t1; ; RUN: llvm-dis < %s.bc-13 > %t2; ; RUN: diff %t1 %t2. As with a Unix shell, the RUN lines permit pipelines and I/O; redirection to be used. There are some quoting rules that you must pay attention to when writing; your RUN lines. In general nothing needs to be quoted. :program:`lit` won't; strip off any quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11018,Testability,test,test,11018,"nes in a ``.ll`` file:. .. code-block:: llvm. ; RUN: llvm-as < %s | llvm-dis > %t1; ; RUN: llvm-dis < %s.bc-13 > %t2; ; RUN: diff %t1 %t2. As with a Unix shell, the RUN lines permit pipelines and I/O; redirection to be used. There are some quoting rules that you must pay attention to when writing; your RUN lines. In general nothing needs to be quoted. :program:`lit` won't; strip off any quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11159,Testability,assert,assertions,11159,"ion to be used. There are some quoting rules that you must pay attention to when writing; your RUN lines. In general nothing needs to be quoted. :program:`lit` won't; strip off any quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to expl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11184,Testability,test,tests,11184,"ion to be used. There are some quoting rules that you must pay attention to when writing; your RUN lines. In general nothing needs to be quoted. :program:`lit` won't; strip off any quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to expl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11250,Testability,test,test,11250,"riting; your RUN lines. In general nothing needs to be quoted. :program:`lit` won't; strip off any quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11417,Testability,assert,assertions,11417," quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11453,Testability,assert,assertions,11453,"m:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11491,Testability,test,test,11491,"m:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11627,Testability,test,test,11627,"ossible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_chec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
