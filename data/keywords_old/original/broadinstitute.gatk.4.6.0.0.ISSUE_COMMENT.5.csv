id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546:1890,Testability,test,testng,1890,gIndexedFastaSequenceFile.java:96); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:138); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:126); 	at org.broadinstitute.hellbender.utils.test.BaseTest.initGenomeLocParser(BaseTest.java:187); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:523); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:224); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:146); 	at org.testng.internal.TestMethodWorker.invokeBeforeClassMethods(TestMethodWorker.java:166); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:105); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:127); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546
https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546:1944,Testability,test,testng,1944,gIndexedFastaSequenceFile.java:96); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:138); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:126); 	at org.broadinstitute.hellbender.utils.test.BaseTest.initGenomeLocParser(BaseTest.java:187); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:523); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:224); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:146); 	at org.testng.internal.TestMethodWorker.invokeBeforeClassMethods(TestMethodWorker.java:166); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:105); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:127); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546
https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546:2014,Testability,test,testng,2014,gIndexedFastaSequenceFile.java:96); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:138); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:126); 	at org.broadinstitute.hellbender.utils.test.BaseTest.initGenomeLocParser(BaseTest.java:187); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:523); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:224); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:146); 	at org.testng.internal.TestMethodWorker.invokeBeforeClassMethods(TestMethodWorker.java:166); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:105); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:127); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546
https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546:2079,Testability,test,testng,2079,gIndexedFastaSequenceFile.java:96); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:138); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:126); 	at org.broadinstitute.hellbender.utils.test.BaseTest.initGenomeLocParser(BaseTest.java:187); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:523); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:224); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:146); 	at org.testng.internal.TestMethodWorker.invokeBeforeClassMethods(TestMethodWorker.java:166); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:105); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:127); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546
https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546:2086,Testability,Test,TestNG,2086,gIndexedFastaSequenceFile.java:96); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:138); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:126); 	at org.broadinstitute.hellbender.utils.test.BaseTest.initGenomeLocParser(BaseTest.java:187); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:523); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:224); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:146); 	at org.testng.internal.TestMethodWorker.invokeBeforeClassMethods(TestMethodWorker.java:166); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:105); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:127); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546
https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546:2115,Testability,Test,TestNG,2115,gIndexedFastaSequenceFile.java:96); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:138); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:126); 	at org.broadinstitute.hellbender.utils.test.BaseTest.initGenomeLocParser(BaseTest.java:187); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:523); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:224); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:146); 	at org.testng.internal.TestMethodWorker.invokeBeforeClassMethods(TestMethodWorker.java:166); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:105); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:127); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546
https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546:2142,Testability,test,testng,2142,gIndexedFastaSequenceFile.java:96); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:138); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:126); 	at org.broadinstitute.hellbender.utils.test.BaseTest.initGenomeLocParser(BaseTest.java:187); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:523); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:224); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:146); 	at org.testng.internal.TestMethodWorker.invokeBeforeClassMethods(TestMethodWorker.java:166); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:105); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:127); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546
https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546:2149,Testability,Test,TestNG,2149,gIndexedFastaSequenceFile.java:96); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:138); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:126); 	at org.broadinstitute.hellbender.utils.test.BaseTest.initGenomeLocParser(BaseTest.java:187); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:523); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:224); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:146); 	at org.testng.internal.TestMethodWorker.invokeBeforeClassMethods(TestMethodWorker.java:166); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:105); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:127); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546
https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546:2173,Testability,Test,TestNG,2173,gIndexedFastaSequenceFile.java:96); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:138); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:126); 	at org.broadinstitute.hellbender.utils.test.BaseTest.initGenomeLocParser(BaseTest.java:187); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:523); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:224); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:146); 	at org.testng.internal.TestMethodWorker.invokeBeforeClassMethods(TestMethodWorker.java:166); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:105); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:127); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546
https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546:2200,Testability,test,testng,2200,gIndexedFastaSequenceFile.java:96); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:138); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:126); 	at org.broadinstitute.hellbender.utils.test.BaseTest.initGenomeLocParser(BaseTest.java:187); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:523); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:224); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:146); 	at org.testng.internal.TestMethodWorker.invokeBeforeClassMethods(TestMethodWorker.java:166); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:105); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:127); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546
https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546:2207,Testability,Test,TestNG,2207,gIndexedFastaSequenceFile.java:96); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:138); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:126); 	at org.broadinstitute.hellbender.utils.test.BaseTest.initGenomeLocParser(BaseTest.java:187); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:523); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:224); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:146); 	at org.testng.internal.TestMethodWorker.invokeBeforeClassMethods(TestMethodWorker.java:166); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:105); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:127); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546
https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546:2224,Testability,Test,TestNG,2224,gIndexedFastaSequenceFile.java:96); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:138); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:126); 	at org.broadinstitute.hellbender.utils.test.BaseTest.initGenomeLocParser(BaseTest.java:187); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:523); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:224); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:146); 	at org.testng.internal.TestMethodWorker.invokeBeforeClassMethods(TestMethodWorker.java:166); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:105); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:127); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546
https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546:2251,Testability,test,testng,2251,gIndexedFastaSequenceFile.java:96); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:138); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:126); 	at org.broadinstitute.hellbender.utils.test.BaseTest.initGenomeLocParser(BaseTest.java:187); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:523); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:224); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:146); 	at org.testng.internal.TestMethodWorker.invokeBeforeClassMethods(TestMethodWorker.java:166); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:105); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:127); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546
https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546:2258,Testability,Test,TestNG,2258,gIndexedFastaSequenceFile.java:96); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:138); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:126); 	at org.broadinstitute.hellbender.utils.test.BaseTest.initGenomeLocParser(BaseTest.java:187); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:523); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:224); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:146); 	at org.testng.internal.TestMethodWorker.invokeBeforeClassMethods(TestMethodWorker.java:166); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:105); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:127); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546
https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546:2269,Testability,Test,TestNG,2269,gIndexedFastaSequenceFile.java:96); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:138); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:126); 	at org.broadinstitute.hellbender.utils.test.BaseTest.initGenomeLocParser(BaseTest.java:187); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:523); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:224); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:146); 	at org.testng.internal.TestMethodWorker.invokeBeforeClassMethods(TestMethodWorker.java:166); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:105); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:127); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546
https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546:2296,Testability,test,testng,2296,gIndexedFastaSequenceFile.java:96); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:138); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:126); 	at org.broadinstitute.hellbender.utils.test.BaseTest.initGenomeLocParser(BaseTest.java:187); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:523); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:224); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:146); 	at org.testng.internal.TestMethodWorker.invokeBeforeClassMethods(TestMethodWorker.java:166); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:105); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:127); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546
https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546:2359,Testability,test,testng,2359,gIndexedFastaSequenceFile.java:96); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:138); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:126); 	at org.broadinstitute.hellbender.utils.test.BaseTest.initGenomeLocParser(BaseTest.java:187); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:108); 	at org.testng.internal.Invoker.invokeConfigurationMethod(Invoker.java:523); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:224); 	at org.testng.internal.Invoker.invokeConfigurations(Invoker.java:146); 	at org.testng.internal.TestMethodWorker.invokeBeforeClassMethods(TestMethodWorker.java:166); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:105); 	at org.testng.TestRunner.privateRun(TestRunner.java:744); 	at org.testng.TestRunner.run(TestRunner.java:602); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:380); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:375); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:340); 	at org.testng.SuiteRunner.run(SuiteRunner.java:289); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1301); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1226); 	at org.testng.TestNG.runSuites(TestNG.java:1144); 	at org.testng.TestNG.run(TestNG.java:1115); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:127); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3029#issuecomment-306355546
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306381135:16,Availability,error,error,16,@sooheelee That error message occurs after the tool has done all the hard work and ju isst has to emit the `VariantContext`s to a file. It seems like the inputs are out of order. Could you check two things: 1) is the input vcf ordered? and 2) are you outputting a vcf or a vcf.gz? I'm curious if the error occurs for both.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306381135
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306381135:300,Availability,error,error,300,@sooheelee That error message occurs after the tool has done all the hard work and ju isst has to emit the `VariantContext`s to a file. It seems like the inputs are out of order. Could you check two things: 1) is the input vcf ordered? and 2) are you outputting a vcf or a vcf.gz? I'm curious if the error occurs for both.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306381135
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306381135:22,Integrability,message,message,22,@sooheelee That error message occurs after the tool has done all the hard work and ju isst has to emit the `VariantContext`s to a file. It seems like the inputs are out of order. Could you check two things: 1) is the input vcf ordered? and 2) are you outputting a vcf or a vcf.gz? I'm curious if the error occurs for both.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306381135
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891:94,Availability,error,error,94,"I was outputting to .vcf.gz. . I reran the command to output to just. vcf and it runs without error:; ```; /gatk-launch FilterByOrientationBias --artifactModes 'G/T' -V /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz -P ~/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics -O test_filterbyorientationbias.vcf; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk FilterByOrientationBias --artifactModes G/T -V /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz -P /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics -O test_filterbyorientationbias.vcf; 01:16:16.916 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.4.3.jar!/com/intel/gkl/native/libgkl_compression.dylib; [June 6, 2017 1:16:16 AM EDT] FilterByOrientationBias --output test_filterbyorientationbias.vcf --preAdapterDetailFile /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics --artifactModes G/T --variant /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891:5572,Availability,down,down,5572,"g traversal; 01:16:17.470 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 01:16:17.493 INFO ProgressMeter - unmapped 0.0 4 10434.8; 01:16:17.493 INFO ProgressMeter - Traversal complete. Processed 4 total variants in 0.0 minutes.; 01:16:17.493 INFO FilterByOrientationBias - Tagging whether genotypes are in one of the artifact modes.; 01:16:17.496 INFO ProgressMeter - Starting traversal; 01:16:17.496 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 01:16:17.497 INFO ProgressMeter - unmapped 0.0 8 480000.0; 01:16:17.498 INFO ProgressMeter - Traversal complete. Processed 8 total records in 0.0 minutes.; 01:16:17.500 INFO OrientationBiasFilterer - NORMAL: Nothing to filter.; 01:16:17.500 INFO OrientationBiasFilterer - TUMOR: Nothing to filter.; 01:16:17.500 INFO OrientationBiasFilterer - Updating genotypes and creating final list of variants...; 01:16:17.500 INFO ProgressMeter - Starting traversal; 01:16:17.501 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 01:16:17.501 INFO ProgressMeter - unmapped 0.0 4 Infinity; 01:16:17.501 INFO ProgressMeter - Traversal complete. Processed 4 total records in 0.0 minutes.; 01:16:17.501 INFO FilterByOrientationBias - Writing variants to VCF...; 01:16:17.512 INFO FilterByOrientationBias - Writing a simple summary table...; 01:16:17.576 INFO FilterByOrientationBias - Shutting down engine; [June 6, 2017 1:16:17 AM EDT] org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=232259584; WMCF9-CB5:hellbender shlee$ ; ```. This is the case for the file that I augmented with what the sed command was meant to do. Otherwise, the command errors. I think the tool should be able to take CollectSequencingArtifactMetrics whether run using Picard or GATK. I say this since folks may have these metrics from old runs before the as-of-yet-available Picard tools in the GATK jar.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891:5897,Availability,error,errors,5897,"g traversal; 01:16:17.470 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 01:16:17.493 INFO ProgressMeter - unmapped 0.0 4 10434.8; 01:16:17.493 INFO ProgressMeter - Traversal complete. Processed 4 total variants in 0.0 minutes.; 01:16:17.493 INFO FilterByOrientationBias - Tagging whether genotypes are in one of the artifact modes.; 01:16:17.496 INFO ProgressMeter - Starting traversal; 01:16:17.496 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 01:16:17.497 INFO ProgressMeter - unmapped 0.0 8 480000.0; 01:16:17.498 INFO ProgressMeter - Traversal complete. Processed 8 total records in 0.0 minutes.; 01:16:17.500 INFO OrientationBiasFilterer - NORMAL: Nothing to filter.; 01:16:17.500 INFO OrientationBiasFilterer - TUMOR: Nothing to filter.; 01:16:17.500 INFO OrientationBiasFilterer - Updating genotypes and creating final list of variants...; 01:16:17.500 INFO ProgressMeter - Starting traversal; 01:16:17.501 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 01:16:17.501 INFO ProgressMeter - unmapped 0.0 4 Infinity; 01:16:17.501 INFO ProgressMeter - Traversal complete. Processed 4 total records in 0.0 minutes.; 01:16:17.501 INFO FilterByOrientationBias - Writing variants to VCF...; 01:16:17.512 INFO FilterByOrientationBias - Writing a simple summary table...; 01:16:17.576 INFO FilterByOrientationBias - Shutting down engine; [June 6, 2017 1:16:17 AM EDT] org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=232259584; WMCF9-CB5:hellbender shlee$ ; ```. This is the case for the file that I augmented with what the sed command was meant to do. Otherwise, the command errors. I think the tool should be able to take CollectSequencingArtifactMetrics whether run using Picard or GATK. I say this since folks may have these metrics from old runs before the as-of-yet-available Picard tools in the GATK jar.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891:6093,Availability,avail,available,6093,"g traversal; 01:16:17.470 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 01:16:17.493 INFO ProgressMeter - unmapped 0.0 4 10434.8; 01:16:17.493 INFO ProgressMeter - Traversal complete. Processed 4 total variants in 0.0 minutes.; 01:16:17.493 INFO FilterByOrientationBias - Tagging whether genotypes are in one of the artifact modes.; 01:16:17.496 INFO ProgressMeter - Starting traversal; 01:16:17.496 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 01:16:17.497 INFO ProgressMeter - unmapped 0.0 8 480000.0; 01:16:17.498 INFO ProgressMeter - Traversal complete. Processed 8 total records in 0.0 minutes.; 01:16:17.500 INFO OrientationBiasFilterer - NORMAL: Nothing to filter.; 01:16:17.500 INFO OrientationBiasFilterer - TUMOR: Nothing to filter.; 01:16:17.500 INFO OrientationBiasFilterer - Updating genotypes and creating final list of variants...; 01:16:17.500 INFO ProgressMeter - Starting traversal; 01:16:17.501 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 01:16:17.501 INFO ProgressMeter - unmapped 0.0 4 Infinity; 01:16:17.501 INFO ProgressMeter - Traversal complete. Processed 4 total records in 0.0 minutes.; 01:16:17.501 INFO FilterByOrientationBias - Writing variants to VCF...; 01:16:17.512 INFO FilterByOrientationBias - Writing a simple summary table...; 01:16:17.576 INFO FilterByOrientationBias - Shutting down engine; [June 6, 2017 1:16:17 AM EDT] org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=232259584; WMCF9-CB5:hellbender shlee$ ; ```. This is the case for the file that I augmented with what the sed command was meant to do. Otherwise, the command errors. I think the tool should be able to take CollectSequencingArtifactMetrics whether run using Picard or GATK. I say this since folks may have these metrics from old runs before the as-of-yet-available Picard tools in the GATK jar.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891:485,Deployability,install,install,485,"I was outputting to .vcf.gz. . I reran the command to output to just. vcf and it runs without error:; ```; /gatk-launch FilterByOrientationBias --artifactModes 'G/T' -V /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz -P ~/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics -O test_filterbyorientationbias.vcf; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk FilterByOrientationBias --artifactModes G/T -V /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz -P /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics -O test_filterbyorientationbias.vcf; 01:16:16.916 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.4.3.jar!/com/intel/gkl/native/libgkl_compression.dylib; [June 6, 2017 1:16:16 AM EDT] FilterByOrientationBias --output test_filterbyorientationbias.vcf --preAdapterDetailFile /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics --artifactModes G/T --variant /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891:567,Deployability,install,install,567,"I was outputting to .vcf.gz. . I reran the command to output to just. vcf and it runs without error:; ```; /gatk-launch FilterByOrientationBias --artifactModes 'G/T' -V /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz -P ~/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics -O test_filterbyorientationbias.vcf; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk FilterByOrientationBias --artifactModes G/T -V /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz -P /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics -O test_filterbyorientationbias.vcf; 01:16:16.916 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.4.3.jar!/com/intel/gkl/native/libgkl_compression.dylib; [June 6, 2017 1:16:16 AM EDT] FilterByOrientationBias --output test_filterbyorientationbias.vcf --preAdapterDetailFile /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics --artifactModes G/T --variant /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891:1024,Deployability,install,install,1024," was outputting to .vcf.gz. . I reran the command to output to just. vcf and it runs without error:; ```; /gatk-launch FilterByOrientationBias --artifactModes 'G/T' -V /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz -P ~/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics -O test_filterbyorientationbias.vcf; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk FilterByOrientationBias --artifactModes G/T -V /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz -P /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics -O test_filterbyorientationbias.vcf; 01:16:16.916 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.4.3.jar!/com/intel/gkl/native/libgkl_compression.dylib; [June 6, 2017 1:16:16 AM EDT] FilterByOrientationBias --output test_filterbyorientationbias.vcf --preAdapterDetailFile /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics --artifactModes G/T --variant /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891:421,Integrability,wrap,wrapper,421,"I was outputting to .vcf.gz. . I reran the command to output to just. vcf and it runs without error:; ```; /gatk-launch FilterByOrientationBias --artifactModes 'G/T' -V /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz -P ~/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics -O test_filterbyorientationbias.vcf; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk FilterByOrientationBias --artifactModes G/T -V /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz -P /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics -O test_filterbyorientationbias.vcf; 01:16:16.916 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.4.3.jar!/com/intel/gkl/native/libgkl_compression.dylib; [June 6, 2017 1:16:16 AM EDT] FilterByOrientationBias --output test_filterbyorientationbias.vcf --preAdapterDetailFile /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics --artifactModes G/T --variant /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891:928,Performance,Load,Loading,928,"I was outputting to .vcf.gz. . I reran the command to output to just. vcf and it runs without error:; ```; /gatk-launch FilterByOrientationBias --artifactModes 'G/T' -V /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz -P ~/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics -O test_filterbyorientationbias.vcf; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk FilterByOrientationBias --artifactModes G/T -V /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz -P /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics -O test_filterbyorientationbias.vcf; 01:16:16.916 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.4.3.jar!/com/intel/gkl/native/libgkl_compression.dylib; [June 6, 2017 1:16:16 AM EDT] FilterByOrientationBias --output test_filterbyorientationbias.vcf --preAdapterDetailFile /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/gatk_6_T_artifact.pre_adapter_detail_metrics --artifactModes G/T --variant /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/8_mutect2.vcf.gz --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891:5494,Usability,simpl,simple,5494,"g traversal; 01:16:17.470 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 01:16:17.493 INFO ProgressMeter - unmapped 0.0 4 10434.8; 01:16:17.493 INFO ProgressMeter - Traversal complete. Processed 4 total variants in 0.0 minutes.; 01:16:17.493 INFO FilterByOrientationBias - Tagging whether genotypes are in one of the artifact modes.; 01:16:17.496 INFO ProgressMeter - Starting traversal; 01:16:17.496 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 01:16:17.497 INFO ProgressMeter - unmapped 0.0 8 480000.0; 01:16:17.498 INFO ProgressMeter - Traversal complete. Processed 8 total records in 0.0 minutes.; 01:16:17.500 INFO OrientationBiasFilterer - NORMAL: Nothing to filter.; 01:16:17.500 INFO OrientationBiasFilterer - TUMOR: Nothing to filter.; 01:16:17.500 INFO OrientationBiasFilterer - Updating genotypes and creating final list of variants...; 01:16:17.500 INFO ProgressMeter - Starting traversal; 01:16:17.501 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute; 01:16:17.501 INFO ProgressMeter - unmapped 0.0 4 Infinity; 01:16:17.501 INFO ProgressMeter - Traversal complete. Processed 4 total records in 0.0 minutes.; 01:16:17.501 INFO FilterByOrientationBias - Writing variants to VCF...; 01:16:17.512 INFO FilterByOrientationBias - Writing a simple summary table...; 01:16:17.576 INFO FilterByOrientationBias - Shutting down engine; [June 6, 2017 1:16:17 AM EDT] org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=232259584; WMCF9-CB5:hellbender shlee$ ; ```. This is the case for the file that I augmented with what the sed command was meant to do. Otherwise, the command errors. I think the tool should be able to take CollectSequencingArtifactMetrics whether run using Picard or GATK. I say this since folks may have these metrics from old runs before the as-of-yet-available Picard tools in the GATK jar.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306384891
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306456760:197,Availability,error,errors,197,"GATK version of collect sequencing artifact metrics has bugs. You have to use Picard version as workaround, but the output of Picard must be changed. @sooheelee your input file is also busted. The errors you are getting are in dependencies of FilterByOrientationBias. Also, I don't think you can just cut and paste the sed command from the WDL (Don't ask.... Subtleties of WDL parsing). . Vcf vs tar.gz is in the engine. Maybe the VCF writer does not look at the extension when doing a VCF write? Therefore, maybe FilterByOrientationBias will write VCF no matter what the extension? does not automatically write the proper output? @lbergelson might know",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306456760
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306456760:227,Integrability,depend,dependencies,227,"GATK version of collect sequencing artifact metrics has bugs. You have to use Picard version as workaround, but the output of Picard must be changed. @sooheelee your input file is also busted. The errors you are getting are in dependencies of FilterByOrientationBias. Also, I don't think you can just cut and paste the sed command from the WDL (Don't ask.... Subtleties of WDL parsing). . Vcf vs tar.gz is in the engine. Maybe the VCF writer does not look at the extension when doing a VCF write? Therefore, maybe FilterByOrientationBias will write VCF no matter what the extension? does not automatically write the proper output? @lbergelson might know",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306456760
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306508511:357,Availability,error,errors,357,"As for my input files being busted. Which file do you mean? As you can see from my late-night post, I do get the tool to run using the odd workarounds. . Also, why @LeeTL1220 have you changed the title of this issue ticket? Can you please explain? Again, I reiterate that CollectSequencingArtifactMetrics works just fine. It is FilterByOrientationBias that errors without these workarounds. Also, FilterByOrientationBias does not output bgzipped VCFs. So this is not in line with how GATK tools should work. Again, FilterByOrientationBias is not production worthy and I think at this point it should get an experimental or BETA label.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306508511
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143:332,Availability,down,downstream,332,"There is a lot going on here... Let me see if I can explain... . First things first, there are two versions of ``CollectSequencingArtifactMetrics`` ... a GATK port and the Picard version. The GATK port has show-stopping issues, so the picard version is used in the meantime, which necessitates that ``sed`` stuff... Second, the way downstream tools are forced to parse the ``CollectSequencingArtifactMetrics`` output file is a bit weird. The class to parse the file is specified in a comment. So if this is incorrect or does not match GATK vs. Picard, the downstream tool (e.g. ``FilterByOrientationBias``) gets an error. > As for my input files being busted. Which file do you mean? As you can see from my late-night post, I do get the tool to run using the odd workarounds. ``java.lang.IllegalArgumentException: Features added out of order: previous (TabixFeature{referenceIndex=0, start=118314029, end=118314036, featureStartFilePosition=1403632633, featureEndFilePosition=-1}) > next (TabixFeature{referenceIndex=0, start=33414233, end=33414234, featureStartFilePosition=1403632876, featureEndFilePosition=-1})``. This is has something to do with your input file. If I am wrong and this is truly a code error, then the fix is not in ``FilterByOrientationBias``. @lbergelson Can you confirm? . > Also, why @LeeTL1220 have you changed the title of this issue ticket? Can you please explain? Again, I reiterate that CollectSequencingArtifactMetrics works just fine. It is FilterByOrientationBias that errors without these workarounds. ``CollectSequencingArtifactMetrics`` (GATK version) definitely does not work just fine. I've cited the issue above. I do not think that any of the code fixes would actually go into FilterByOrientationBias. If the GATK version worked just fine, we would ditch the ``sed`` command and use that. ``CollectSequencingArtifactMetrics`` (Picard version) works just fine BUT it introduces that string which requires the ``sed`` statement. If you do not use ``sed``, a (gene",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143:556,Availability,down,downstream,556,"There is a lot going on here... Let me see if I can explain... . First things first, there are two versions of ``CollectSequencingArtifactMetrics`` ... a GATK port and the Picard version. The GATK port has show-stopping issues, so the picard version is used in the meantime, which necessitates that ``sed`` stuff... Second, the way downstream tools are forced to parse the ``CollectSequencingArtifactMetrics`` output file is a bit weird. The class to parse the file is specified in a comment. So if this is incorrect or does not match GATK vs. Picard, the downstream tool (e.g. ``FilterByOrientationBias``) gets an error. > As for my input files being busted. Which file do you mean? As you can see from my late-night post, I do get the tool to run using the odd workarounds. ``java.lang.IllegalArgumentException: Features added out of order: previous (TabixFeature{referenceIndex=0, start=118314029, end=118314036, featureStartFilePosition=1403632633, featureEndFilePosition=-1}) > next (TabixFeature{referenceIndex=0, start=33414233, end=33414234, featureStartFilePosition=1403632876, featureEndFilePosition=-1})``. This is has something to do with your input file. If I am wrong and this is truly a code error, then the fix is not in ``FilterByOrientationBias``. @lbergelson Can you confirm? . > Also, why @LeeTL1220 have you changed the title of this issue ticket? Can you please explain? Again, I reiterate that CollectSequencingArtifactMetrics works just fine. It is FilterByOrientationBias that errors without these workarounds. ``CollectSequencingArtifactMetrics`` (GATK version) definitely does not work just fine. I've cited the issue above. I do not think that any of the code fixes would actually go into FilterByOrientationBias. If the GATK version worked just fine, we would ditch the ``sed`` command and use that. ``CollectSequencingArtifactMetrics`` (Picard version) works just fine BUT it introduces that string which requires the ``sed`` statement. If you do not use ``sed``, a (gene",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143:615,Availability,error,error,615,"There is a lot going on here... Let me see if I can explain... . First things first, there are two versions of ``CollectSequencingArtifactMetrics`` ... a GATK port and the Picard version. The GATK port has show-stopping issues, so the picard version is used in the meantime, which necessitates that ``sed`` stuff... Second, the way downstream tools are forced to parse the ``CollectSequencingArtifactMetrics`` output file is a bit weird. The class to parse the file is specified in a comment. So if this is incorrect or does not match GATK vs. Picard, the downstream tool (e.g. ``FilterByOrientationBias``) gets an error. > As for my input files being busted. Which file do you mean? As you can see from my late-night post, I do get the tool to run using the odd workarounds. ``java.lang.IllegalArgumentException: Features added out of order: previous (TabixFeature{referenceIndex=0, start=118314029, end=118314036, featureStartFilePosition=1403632633, featureEndFilePosition=-1}) > next (TabixFeature{referenceIndex=0, start=33414233, end=33414234, featureStartFilePosition=1403632876, featureEndFilePosition=-1})``. This is has something to do with your input file. If I am wrong and this is truly a code error, then the fix is not in ``FilterByOrientationBias``. @lbergelson Can you confirm? . > Also, why @LeeTL1220 have you changed the title of this issue ticket? Can you please explain? Again, I reiterate that CollectSequencingArtifactMetrics works just fine. It is FilterByOrientationBias that errors without these workarounds. ``CollectSequencingArtifactMetrics`` (GATK version) definitely does not work just fine. I've cited the issue above. I do not think that any of the code fixes would actually go into FilterByOrientationBias. If the GATK version worked just fine, we would ditch the ``sed`` command and use that. ``CollectSequencingArtifactMetrics`` (Picard version) works just fine BUT it introduces that string which requires the ``sed`` statement. If you do not use ``sed``, a (gene",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143:1207,Availability,error,error,1207,"ing issues, so the picard version is used in the meantime, which necessitates that ``sed`` stuff... Second, the way downstream tools are forced to parse the ``CollectSequencingArtifactMetrics`` output file is a bit weird. The class to parse the file is specified in a comment. So if this is incorrect or does not match GATK vs. Picard, the downstream tool (e.g. ``FilterByOrientationBias``) gets an error. > As for my input files being busted. Which file do you mean? As you can see from my late-night post, I do get the tool to run using the odd workarounds. ``java.lang.IllegalArgumentException: Features added out of order: previous (TabixFeature{referenceIndex=0, start=118314029, end=118314036, featureStartFilePosition=1403632633, featureEndFilePosition=-1}) > next (TabixFeature{referenceIndex=0, start=33414233, end=33414234, featureStartFilePosition=1403632876, featureEndFilePosition=-1})``. This is has something to do with your input file. If I am wrong and this is truly a code error, then the fix is not in ``FilterByOrientationBias``. @lbergelson Can you confirm? . > Also, why @LeeTL1220 have you changed the title of this issue ticket? Can you please explain? Again, I reiterate that CollectSequencingArtifactMetrics works just fine. It is FilterByOrientationBias that errors without these workarounds. ``CollectSequencingArtifactMetrics`` (GATK version) definitely does not work just fine. I've cited the issue above. I do not think that any of the code fixes would actually go into FilterByOrientationBias. If the GATK version worked just fine, we would ditch the ``sed`` command and use that. ``CollectSequencingArtifactMetrics`` (Picard version) works just fine BUT it introduces that string which requires the ``sed`` statement. If you do not use ``sed``, a (general-use/engine) dependency of ``FilterByOrientationBias`` will try to instantiate a class that does not exist. The ``sed`` was supposed to be temporary until picard was wrapped properly in GATK. But until then, it d",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143:1502,Availability,error,errors,1502,"his is incorrect or does not match GATK vs. Picard, the downstream tool (e.g. ``FilterByOrientationBias``) gets an error. > As for my input files being busted. Which file do you mean? As you can see from my late-night post, I do get the tool to run using the odd workarounds. ``java.lang.IllegalArgumentException: Features added out of order: previous (TabixFeature{referenceIndex=0, start=118314029, end=118314036, featureStartFilePosition=1403632633, featureEndFilePosition=-1}) > next (TabixFeature{referenceIndex=0, start=33414233, end=33414234, featureStartFilePosition=1403632876, featureEndFilePosition=-1})``. This is has something to do with your input file. If I am wrong and this is truly a code error, then the fix is not in ``FilterByOrientationBias``. @lbergelson Can you confirm? . > Also, why @LeeTL1220 have you changed the title of this issue ticket? Can you please explain? Again, I reiterate that CollectSequencingArtifactMetrics works just fine. It is FilterByOrientationBias that errors without these workarounds. ``CollectSequencingArtifactMetrics`` (GATK version) definitely does not work just fine. I've cited the issue above. I do not think that any of the code fixes would actually go into FilterByOrientationBias. If the GATK version worked just fine, we would ditch the ``sed`` command and use that. ``CollectSequencingArtifactMetrics`` (Picard version) works just fine BUT it introduces that string which requires the ``sed`` statement. If you do not use ``sed``, a (general-use/engine) dependency of ``FilterByOrientationBias`` will try to instantiate a class that does not exist. The ``sed`` was supposed to be temporary until picard was wrapped properly in GATK. But until then, it does mean that all GATK-based downstream dependencies of ``CollectSequencingArtifactMetrics`` will fail without the sed. Again, the fix is not in ``FilterByOrientationBias``. > Also, FilterByOrientationBias does not output bgzipped VCFs. So this is not in line with how GATK tools shoul",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143:2245,Availability,down,downstream,2245,"is is truly a code error, then the fix is not in ``FilterByOrientationBias``. @lbergelson Can you confirm? . > Also, why @LeeTL1220 have you changed the title of this issue ticket? Can you please explain? Again, I reiterate that CollectSequencingArtifactMetrics works just fine. It is FilterByOrientationBias that errors without these workarounds. ``CollectSequencingArtifactMetrics`` (GATK version) definitely does not work just fine. I've cited the issue above. I do not think that any of the code fixes would actually go into FilterByOrientationBias. If the GATK version worked just fine, we would ditch the ``sed`` command and use that. ``CollectSequencingArtifactMetrics`` (Picard version) works just fine BUT it introduces that string which requires the ``sed`` statement. If you do not use ``sed``, a (general-use/engine) dependency of ``FilterByOrientationBias`` will try to instantiate a class that does not exist. The ``sed`` was supposed to be temporary until picard was wrapped properly in GATK. But until then, it does mean that all GATK-based downstream dependencies of ``CollectSequencingArtifactMetrics`` will fail without the sed. Again, the fix is not in ``FilterByOrientationBias``. > Also, FilterByOrientationBias does not output bgzipped VCFs. So this is not in line with how GATK tools should work. . ``FilterByOrientationBias`` just farms it out to a VCF Writer. That dependency (VCF Writer) should handle that. Can you confirm, @lbergelson ? Is there an additional step to make this work that I did not know about?. > Again, FilterByOrientationBias is not production worthy and I think at this point it should get an experimental or BETA label. Only because of the ``sed`` nonsense, as near as I can tell. Definitely, BETA -- not experimental. All I'm saying is that I don't believe any code change needs to go into ``FilterByOrientationBias`` (with the possible exception of the bgzip VCF). These issues are all in its dependencies, which are part of the engine/picard-ports.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143:2017,Integrability,depend,dependency,2017,"d=33414234, featureStartFilePosition=1403632876, featureEndFilePosition=-1})``. This is has something to do with your input file. If I am wrong and this is truly a code error, then the fix is not in ``FilterByOrientationBias``. @lbergelson Can you confirm? . > Also, why @LeeTL1220 have you changed the title of this issue ticket? Can you please explain? Again, I reiterate that CollectSequencingArtifactMetrics works just fine. It is FilterByOrientationBias that errors without these workarounds. ``CollectSequencingArtifactMetrics`` (GATK version) definitely does not work just fine. I've cited the issue above. I do not think that any of the code fixes would actually go into FilterByOrientationBias. If the GATK version worked just fine, we would ditch the ``sed`` command and use that. ``CollectSequencingArtifactMetrics`` (Picard version) works just fine BUT it introduces that string which requires the ``sed`` statement. If you do not use ``sed``, a (general-use/engine) dependency of ``FilterByOrientationBias`` will try to instantiate a class that does not exist. The ``sed`` was supposed to be temporary until picard was wrapped properly in GATK. But until then, it does mean that all GATK-based downstream dependencies of ``CollectSequencingArtifactMetrics`` will fail without the sed. Again, the fix is not in ``FilterByOrientationBias``. > Also, FilterByOrientationBias does not output bgzipped VCFs. So this is not in line with how GATK tools should work. . ``FilterByOrientationBias`` just farms it out to a VCF Writer. That dependency (VCF Writer) should handle that. Can you confirm, @lbergelson ? Is there an additional step to make this work that I did not know about?. > Again, FilterByOrientationBias is not production worthy and I think at this point it should get an experimental or BETA label. Only because of the ``sed`` nonsense, as near as I can tell. Definitely, BETA -- not experimental. All I'm saying is that I don't believe any code change needs to go into ``FilterByO",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143:2170,Integrability,wrap,wrapped,2170,"ur input file. If I am wrong and this is truly a code error, then the fix is not in ``FilterByOrientationBias``. @lbergelson Can you confirm? . > Also, why @LeeTL1220 have you changed the title of this issue ticket? Can you please explain? Again, I reiterate that CollectSequencingArtifactMetrics works just fine. It is FilterByOrientationBias that errors without these workarounds. ``CollectSequencingArtifactMetrics`` (GATK version) definitely does not work just fine. I've cited the issue above. I do not think that any of the code fixes would actually go into FilterByOrientationBias. If the GATK version worked just fine, we would ditch the ``sed`` command and use that. ``CollectSequencingArtifactMetrics`` (Picard version) works just fine BUT it introduces that string which requires the ``sed`` statement. If you do not use ``sed``, a (general-use/engine) dependency of ``FilterByOrientationBias`` will try to instantiate a class that does not exist. The ``sed`` was supposed to be temporary until picard was wrapped properly in GATK. But until then, it does mean that all GATK-based downstream dependencies of ``CollectSequencingArtifactMetrics`` will fail without the sed. Again, the fix is not in ``FilterByOrientationBias``. > Also, FilterByOrientationBias does not output bgzipped VCFs. So this is not in line with how GATK tools should work. . ``FilterByOrientationBias`` just farms it out to a VCF Writer. That dependency (VCF Writer) should handle that. Can you confirm, @lbergelson ? Is there an additional step to make this work that I did not know about?. > Again, FilterByOrientationBias is not production worthy and I think at this point it should get an experimental or BETA label. Only because of the ``sed`` nonsense, as near as I can tell. Definitely, BETA -- not experimental. All I'm saying is that I don't believe any code change needs to go into ``FilterByOrientationBias`` (with the possible exception of the bgzip VCF). These issues are all in its dependencies, which a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143:2256,Integrability,depend,dependencies,2256,"is is truly a code error, then the fix is not in ``FilterByOrientationBias``. @lbergelson Can you confirm? . > Also, why @LeeTL1220 have you changed the title of this issue ticket? Can you please explain? Again, I reiterate that CollectSequencingArtifactMetrics works just fine. It is FilterByOrientationBias that errors without these workarounds. ``CollectSequencingArtifactMetrics`` (GATK version) definitely does not work just fine. I've cited the issue above. I do not think that any of the code fixes would actually go into FilterByOrientationBias. If the GATK version worked just fine, we would ditch the ``sed`` command and use that. ``CollectSequencingArtifactMetrics`` (Picard version) works just fine BUT it introduces that string which requires the ``sed`` statement. If you do not use ``sed``, a (general-use/engine) dependency of ``FilterByOrientationBias`` will try to instantiate a class that does not exist. The ``sed`` was supposed to be temporary until picard was wrapped properly in GATK. But until then, it does mean that all GATK-based downstream dependencies of ``CollectSequencingArtifactMetrics`` will fail without the sed. Again, the fix is not in ``FilterByOrientationBias``. > Also, FilterByOrientationBias does not output bgzipped VCFs. So this is not in line with how GATK tools should work. . ``FilterByOrientationBias`` just farms it out to a VCF Writer. That dependency (VCF Writer) should handle that. Can you confirm, @lbergelson ? Is there an additional step to make this work that I did not know about?. > Again, FilterByOrientationBias is not production worthy and I think at this point it should get an experimental or BETA label. Only because of the ``sed`` nonsense, as near as I can tell. Definitely, BETA -- not experimental. All I'm saying is that I don't believe any code change needs to go into ``FilterByOrientationBias`` (with the possible exception of the bgzip VCF). These issues are all in its dependencies, which are part of the engine/picard-ports.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143:2579,Integrability,depend,dependency,2579,"is is truly a code error, then the fix is not in ``FilterByOrientationBias``. @lbergelson Can you confirm? . > Also, why @LeeTL1220 have you changed the title of this issue ticket? Can you please explain? Again, I reiterate that CollectSequencingArtifactMetrics works just fine. It is FilterByOrientationBias that errors without these workarounds. ``CollectSequencingArtifactMetrics`` (GATK version) definitely does not work just fine. I've cited the issue above. I do not think that any of the code fixes would actually go into FilterByOrientationBias. If the GATK version worked just fine, we would ditch the ``sed`` command and use that. ``CollectSequencingArtifactMetrics`` (Picard version) works just fine BUT it introduces that string which requires the ``sed`` statement. If you do not use ``sed``, a (general-use/engine) dependency of ``FilterByOrientationBias`` will try to instantiate a class that does not exist. The ``sed`` was supposed to be temporary until picard was wrapped properly in GATK. But until then, it does mean that all GATK-based downstream dependencies of ``CollectSequencingArtifactMetrics`` will fail without the sed. Again, the fix is not in ``FilterByOrientationBias``. > Also, FilterByOrientationBias does not output bgzipped VCFs. So this is not in line with how GATK tools should work. . ``FilterByOrientationBias`` just farms it out to a VCF Writer. That dependency (VCF Writer) should handle that. Can you confirm, @lbergelson ? Is there an additional step to make this work that I did not know about?. > Again, FilterByOrientationBias is not production worthy and I think at this point it should get an experimental or BETA label. Only because of the ``sed`` nonsense, as near as I can tell. Definitely, BETA -- not experimental. All I'm saying is that I don't believe any code change needs to go into ``FilterByOrientationBias`` (with the possible exception of the bgzip VCF). These issues are all in its dependencies, which are part of the engine/picard-ports.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143:3132,Integrability,depend,dependencies,3132,"is is truly a code error, then the fix is not in ``FilterByOrientationBias``. @lbergelson Can you confirm? . > Also, why @LeeTL1220 have you changed the title of this issue ticket? Can you please explain? Again, I reiterate that CollectSequencingArtifactMetrics works just fine. It is FilterByOrientationBias that errors without these workarounds. ``CollectSequencingArtifactMetrics`` (GATK version) definitely does not work just fine. I've cited the issue above. I do not think that any of the code fixes would actually go into FilterByOrientationBias. If the GATK version worked just fine, we would ditch the ``sed`` command and use that. ``CollectSequencingArtifactMetrics`` (Picard version) works just fine BUT it introduces that string which requires the ``sed`` statement. If you do not use ``sed``, a (general-use/engine) dependency of ``FilterByOrientationBias`` will try to instantiate a class that does not exist. The ``sed`` was supposed to be temporary until picard was wrapped properly in GATK. But until then, it does mean that all GATK-based downstream dependencies of ``CollectSequencingArtifactMetrics`` will fail without the sed. Again, the fix is not in ``FilterByOrientationBias``. > Also, FilterByOrientationBias does not output bgzipped VCFs. So this is not in line with how GATK tools should work. . ``FilterByOrientationBias`` just farms it out to a VCF Writer. That dependency (VCF Writer) should handle that. Can you confirm, @lbergelson ? Is there an additional step to make this work that I did not know about?. > Again, FilterByOrientationBias is not production worthy and I think at this point it should get an experimental or BETA label. Only because of the ``sed`` nonsense, as near as I can tell. Definitely, BETA -- not experimental. All I'm saying is that I don't believe any code change needs to go into ``FilterByOrientationBias`` (with the possible exception of the bgzip VCF). These issues are all in its dependencies, which are part of the engine/picard-ports.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306525143
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306528306:173,Deployability,integrat,integration,173,@sooheelee I do agree. USers cannot be expected to do this. @lbergelson @droazen Any ideas how best to address this? Tell me if you need more details. This ties into Picard integration.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306528306
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306528306:173,Integrability,integrat,integration,173,@sooheelee I do agree. USers cannot be expected to do this. @lbergelson @droazen Any ideas how best to address this? Tell me if you need more details. This ties into Picard integration.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306528306
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306531581:82,Availability,error,errors,82,"I have never used the GATK version CollectSequencingArtifactMetrics. So all of my errors stem from using the results of Picard's CollectSequencingArtifactMetrics, which we can expect our users to do for the foreseeable future, given the merging of the toolsets is not something in the works as far as I know. . @LeeTL1220 It seems peculiar to me that we should have to fix Picard's CollectSequencingArtifactMetrics for compatibility with this new tool FilterByOrientationBias. Rather, shouldn't you fix FilterByOrientationBias to accept either string?. Given other tools can read and write bgzipped VCFs, I would conjecture the way in which FilterByOrientationBias is utilizing dependencies is flawed, and not that dependencies require fixes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306531581
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306531581:678,Integrability,depend,dependencies,678,"I have never used the GATK version CollectSequencingArtifactMetrics. So all of my errors stem from using the results of Picard's CollectSequencingArtifactMetrics, which we can expect our users to do for the foreseeable future, given the merging of the toolsets is not something in the works as far as I know. . @LeeTL1220 It seems peculiar to me that we should have to fix Picard's CollectSequencingArtifactMetrics for compatibility with this new tool FilterByOrientationBias. Rather, shouldn't you fix FilterByOrientationBias to accept either string?. Given other tools can read and write bgzipped VCFs, I would conjecture the way in which FilterByOrientationBias is utilizing dependencies is flawed, and not that dependencies require fixes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306531581
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306531581:715,Integrability,depend,dependencies,715,"I have never used the GATK version CollectSequencingArtifactMetrics. So all of my errors stem from using the results of Picard's CollectSequencingArtifactMetrics, which we can expect our users to do for the foreseeable future, given the merging of the toolsets is not something in the works as far as I know. . @LeeTL1220 It seems peculiar to me that we should have to fix Picard's CollectSequencingArtifactMetrics for compatibility with this new tool FilterByOrientationBias. Rather, shouldn't you fix FilterByOrientationBias to accept either string?. Given other tools can read and write bgzipped VCFs, I would conjecture the way in which FilterByOrientationBias is utilizing dependencies is flawed, and not that dependencies require fixes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306531581
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306535543:183,Integrability,depend,dependency,183,"@sooheelee Was not my call to implement the parser that way. Hence, to support both would require a big hack that we would throw away later, anyway. . Possible that FBOB is using the dependency wrong for writing out bgz VCF. But it seems to be doing it in a pretty standard way. I'm just going to have to ask @droazen and @lbergelson on that one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306535543
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306632877:523,Availability,error,error,523,"I'm honestly not sure what's going on here. The picard/gatk differences will be resolved soon and then the sed command can go away. I don't think it's worth doing anything until then. We should be able to write vcf.gz so if there's an issue there we want to know about it. There could either be an issue in the TabixIndex writer (which we know for sure has issues, one is a blocker on the 11k project at the moment. ) Alternatively the input file could just be invalid, in which case our vcf writer should be detecting the error and is not.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306632877
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306632877:509,Safety,detect,detecting,509,"I'm honestly not sure what's going on here. The picard/gatk differences will be resolved soon and then the sed command can go away. I don't think it's worth doing anything until then. We should be able to write vcf.gz so if there's an issue there we want to know about it. There could either be an issue in the TabixIndex writer (which we know for sure has issues, one is a blocker on the 11k project at the moment. ) Alternatively the input file could just be invalid, in which case our vcf writer should be detecting the error and is not.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306632877
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306668026:126,Availability,error,error,126,"@sooheelee Is the input ""8_mutect2.vcf.gz"" file that you used above the same one that David sent me today ? If so, the second error above (the ""Features added out of order..."") that happens when the output is a .gz, is a legitimate error. That input file was not sorted (even though it had a companion .tbi index file, which I suspect is not it's actual companion), so the output tabix index can't be created. You can try adding `--createOutputVariantIndex false` to the command line and see if that eliminates the error message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306668026
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306668026:232,Availability,error,error,232,"@sooheelee Is the input ""8_mutect2.vcf.gz"" file that you used above the same one that David sent me today ? If so, the second error above (the ""Features added out of order..."") that happens when the output is a .gz, is a legitimate error. That input file was not sorted (even though it had a companion .tbi index file, which I suspect is not it's actual companion), so the output tabix index can't be created. You can try adding `--createOutputVariantIndex false` to the command line and see if that eliminates the error message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306668026
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306668026:515,Availability,error,error,515,"@sooheelee Is the input ""8_mutect2.vcf.gz"" file that you used above the same one that David sent me today ? If so, the second error above (the ""Features added out of order..."") that happens when the output is a .gz, is a legitimate error. That input file was not sorted (even though it had a companion .tbi index file, which I suspect is not it's actual companion), so the output tabix index can't be created. You can try adding `--createOutputVariantIndex false` to the command line and see if that eliminates the error message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306668026
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306668026:521,Integrability,message,message,521,"@sooheelee Is the input ""8_mutect2.vcf.gz"" file that you used above the same one that David sent me today ? If so, the second error above (the ""Features added out of order..."") that happens when the output is a .gz, is a legitimate error. That input file was not sorted (even though it had a companion .tbi index file, which I suspect is not it's actual companion), so the output tabix index can't be created. You can try adding `--createOutputVariantIndex false` to the command line and see if that eliminates the error message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-306668026
https://github.com/broadinstitute/gatk/issues/3030#issuecomment-350775211:53,Testability,test,tested,53,FilterByOrientation now takes in the Picard metrics (tested with GATK4.beta.6) and my original question has been addressed.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3030#issuecomment-350775211
https://github.com/broadinstitute/gatk/pull/3031#issuecomment-306370974:1560,Performance,Perform,PerformAlleleFractionSegmentation,1560,===========; Files 1139 1146 +7 ; Lines 60902 62029 +1127 ; Branches 9437 9684 +247 ; ===============================================; + Hits 48705 49752 +1047 ; - Misses 8401 8435 +34 ; - Partials 3796 3842 +46; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3031?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ellbender/tools/exome/FilterByOrientationBias.java](https://codecov.io/gh/broadinstitute/gatk/pull/3031?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9GaWx0ZXJCeU9yaWVudGF0aW9uQmlhcy5qYXZh) | `83.019% <> ()` | `14 <0> ()` | :arrow_down: |; | [...ls/walkers/mutect/CreateSomaticPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/3031?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHMuamF2YQ==) | `100% <0%> ()` | `10% <0%> (+3%)` | :arrow_up: |; | [...egmentation/PerformAlleleFractionSegmentation.java](https://codecov.io/gh/broadinstitute/gatk/pull/3031?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9zZWdtZW50YXRpb24vUGVyZm9ybUFsbGVsZUZyYWN0aW9uU2VnbWVudGF0aW9uLmphdmE=) | `88.889% <0%> ()` | `4% <0%> (+2%)` | :arrow_up: |; | [...itute/hellbender/tools/walkers/mutect/Mutect2.java](https://codecov.io/gh/broadinstitute/gatk/pull/3031?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyLmphdmE=) | `92.593% <0%> ()` | `32% <0%> (+16%)` | :arrow_up: |; | [...s/spark/pathseq/PSBuildReferenceTaxonomyUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3031?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTQnVpbGRSZWZlcmVuY2VUYXhvbm9teVV0aWxzLmphdmE=) | `88.961% <0%> ()` | `39% <0%> (?)` | |; | [.../hellbender/tools/spark/utils/LongBloomFilter.java](https://codecov.io/gh/broadinstitute/gat,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3031#issuecomment-306370974
https://github.com/broadinstitute/gatk/pull/3031#issuecomment-306563045:158,Deployability,release,release,158,"Lee is looking for someone else to evaluate it @davidbenjamin. In the meanwhile, because we have the BETA/Experimental label on this tool, it should be ok to release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3031#issuecomment-306563045
https://github.com/broadinstitute/gatk/pull/3032#issuecomment-306375449:1515,Performance,Perform,PerformAlleleFractionSegmentation,1515,cov.io/gh/broadinstitute/gatk/pull/3032?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/84fbda69bf9528059777496a415be8eb6db63e61?src=pr&el=desc) will **increase** coverage by `0.012%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #3032 +/- ##; ===============================================; + Coverage 79.973% 79.985% +0.012% ; - Complexity 16727 16745 +18 ; ===============================================; Files 1139 1139 ; Lines 60902 60938 +36 ; Branches 9437 9439 +2 ; ===============================================; + Hits 48705 48741 +36 ; + Misses 8401 8398 -3 ; - Partials 3796 3799 +3; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3032?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...itute/hellbender/tools/walkers/SplitIntervals.java](https://codecov.io/gh/broadinstitute/gatk/pull/3032?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1NwbGl0SW50ZXJ2YWxzLmphdmE=) | `88.235% <> ()` | `6 <0> ()` | :arrow_down: |; | [...itute/hellbender/tools/walkers/mutect/Mutect2.java](https://codecov.io/gh/broadinstitute/gatk/pull/3032?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyLmphdmE=) | `92.593% <0%> ()` | `32% <0%> (+16%)` | :arrow_up: |; | [...egmentation/PerformAlleleFractionSegmentation.java](https://codecov.io/gh/broadinstitute/gatk/pull/3032?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9zZWdtZW50YXRpb24vUGVyZm9ybUFsbGVsZUZyYWN0aW9uU2VnbWVudGF0aW9uLmphdmE=) | `88.889% <0%> ()` | `4% <0%> (+2%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3032?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `73.649% <0%> (+2.027%)` | `34% <0%> ()` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3032#issuecomment-306375449
https://github.com/broadinstitute/gatk/pull/3033#issuecomment-306379926:2425,Deployability,pipeline,pipelines,2425,W50V2l0aFBoYXNlUG9zdGVyaW9yc0NvbGxlY3Rpb24uamF2YQ==) | `64.286% <0%> (-3.571%)` | `5% <0%> (-1%)` | |; | [...ols/exome/alleliccount/AllelicCountCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3033?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9hbGxlbGljY291bnQvQWxsZWxpY0NvdW50Q29sbGVjdGlvbi5qYXZh) | `72.727% <0%> (-3.03%)` | `9% <0%> (-1%)` | |; | [.../broadinstitute/hellbender/utils/tsv/DataLine.java](https://codecov.io/gh/broadinstitute/gatk/pull/3033?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvRGF0YUxpbmUuamF2YQ==) | `90.598% <0%> (-0.855%)` | `62% <0%> (-1%)` | |; | [...nstitute/hellbender/utils/help/GATKHelpDoclet.java](https://codecov.io/gh/broadinstitute/gatk/pull/3033?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oZWxwL0dBVEtIZWxwRG9jbGV0LmphdmE=) | `100% <0%> ()` | `9% <0%> (+3%)` | :arrow_up: |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3033?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `100% <0%> ()` | `15% <0%> (+7%)` | :arrow_up: |; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3033?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `92.908% <0%> (+3.324%)` | `58% <0%> (+29%)` | :arrow_up: |; | [.../hellbender/tools/genomicsdb/GenomicsDBImport.java](https://codecov.io/gh/broadinstitute/gatk/pull/3033?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWljc2RiL0dlbm9taWNzREJJbXBvcnQuamF2YQ==) | `77.5% <0%> (+4.461%)` | `72% <0%> (+24%)` | :arrow_up: |; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/3033?src=pr&el=tree,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3033#issuecomment-306379926
https://github.com/broadinstitute/gatk/pull/3033#issuecomment-306541526:35,Security,authoriz,authorized,35,"@samuelklee @davidbenjamin I'm not authorized to merge PRs, so one of yous will have to.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3033#issuecomment-306541526
https://github.com/broadinstitute/gatk/pull/3033#issuecomment-306542782:17,Security,authoriz,authorized,17,@droazen I'm not authorized either.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3033#issuecomment-306542782
https://github.com/broadinstitute/gatk/pull/3035#issuecomment-306412418:1253,Performance,cache,cachemanager,1253,db63e61?src=pr&el=desc) will **increase** coverage by `0.169%`.; > The diff coverage is `90%`. ```diff; @@ Coverage Diff @@; ## master #3035 +/- ##; ===============================================; + Coverage 79.973% 80.142% +0.169% ; - Complexity 16727 16787 +60 ; ===============================================; Files 1139 1140 +1 ; Lines 60902 60867 -35 ; Branches 9437 9437 ; ===============================================; + Hits 48705 48780 +75 ; + Misses 8401 8296 -105 ; + Partials 3796 3791 -5; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...coveragemodel/CoverageModelArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL0NvdmVyYWdlTW9kZWxBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `86.592% <> ()` | `40 <0> ()` | :arrow_down: |; | [...gemodel/cachemanager/ComputableGraphStructure.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9Db21wdXRhYmxlR3JhcGhTdHJ1Y3R1cmUuamF2YQ==) | `100% <100%> (+26.994%)` | `63 <62> (+24)` | :arrow_up: |; | [...ragemodel/cachemanager/ComputableNodeFunction.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9Db21wdXRhYmxlTm9kZUZ1bmN0aW9uLmphdmE=) | `100% <100%> (+66.667%)` | `4 <1> (+2)` | :arrow_up: |; | [.../coveragemodel/cachemanager/DuplicableNDArray.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9EdXBsaWNhYmxlTkRBcnJheS5qYXZh) | `81.818% <100%> (+38.068%)` | `6 <2> (+2)` | :arrow_up: |; | [...s/coveragemodel/cachemanager/Du,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3035#issuecomment-306412418
https://github.com/broadinstitute/gatk/pull/3035#issuecomment-306412418:1592,Performance,cache,cachemanager,1592,ines 60902 60867 -35 ; Branches 9437 9437 ; ===============================================; + Hits 48705 48780 +75 ; + Misses 8401 8296 -105 ; + Partials 3796 3791 -5; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...coveragemodel/CoverageModelArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL0NvdmVyYWdlTW9kZWxBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `86.592% <> ()` | `40 <0> ()` | :arrow_down: |; | [...gemodel/cachemanager/ComputableGraphStructure.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9Db21wdXRhYmxlR3JhcGhTdHJ1Y3R1cmUuamF2YQ==) | `100% <100%> (+26.994%)` | `63 <62> (+24)` | :arrow_up: |; | [...ragemodel/cachemanager/ComputableNodeFunction.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9Db21wdXRhYmxlTm9kZUZ1bmN0aW9uLmphdmE=) | `100% <100%> (+66.667%)` | `4 <1> (+2)` | :arrow_up: |; | [.../coveragemodel/cachemanager/DuplicableNDArray.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9EdXBsaWNhYmxlTkRBcnJheS5qYXZh) | `81.818% <100%> (+38.068%)` | `6 <2> (+2)` | :arrow_up: |; | [...s/coveragemodel/cachemanager/DuplicableNumber.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9EdXBsaWNhYmxlTnVtYmVyLmphdmE=) | `80% <100%> (+80%)` | `5 <2> (+5)` | :arrow_up: |; | [...coveragemodel/cachemanager/PrimitiveCacheNode.java],MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3035#issuecomment-306412418
https://github.com/broadinstitute/gatk/pull/3035#issuecomment-306412418:1927,Performance,cache,cachemanager,1927,el/CoverageModelArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL0NvdmVyYWdlTW9kZWxBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `86.592% <> ()` | `40 <0> ()` | :arrow_down: |; | [...gemodel/cachemanager/ComputableGraphStructure.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9Db21wdXRhYmxlR3JhcGhTdHJ1Y3R1cmUuamF2YQ==) | `100% <100%> (+26.994%)` | `63 <62> (+24)` | :arrow_up: |; | [...ragemodel/cachemanager/ComputableNodeFunction.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9Db21wdXRhYmxlTm9kZUZ1bmN0aW9uLmphdmE=) | `100% <100%> (+66.667%)` | `4 <1> (+2)` | :arrow_up: |; | [.../coveragemodel/cachemanager/DuplicableNDArray.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9EdXBsaWNhYmxlTkRBcnJheS5qYXZh) | `81.818% <100%> (+38.068%)` | `6 <2> (+2)` | :arrow_up: |; | [...s/coveragemodel/cachemanager/DuplicableNumber.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9EdXBsaWNhYmxlTnVtYmVyLmphdmE=) | `80% <100%> (+80%)` | `5 <2> (+5)` | :arrow_up: |; | [...coveragemodel/cachemanager/PrimitiveCacheNode.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9QcmltaXRpdmVDYWNoZU5vZGUuamF2YQ==) | `83.333% <71.429%> (+30.702%)` | `10 <7> (+3)` | :arrow_up: |; | [...er/tools/coveragemodel/cachemanager/CacheNode.ja,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3035#issuecomment-306412418
https://github.com/broadinstitute/gatk/pull/3035#issuecomment-306412418:2253,Performance,cache,cachemanager,2253,nager/ComputableGraphStructure.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9Db21wdXRhYmxlR3JhcGhTdHJ1Y3R1cmUuamF2YQ==) | `100% <100%> (+26.994%)` | `63 <62> (+24)` | :arrow_up: |; | [...ragemodel/cachemanager/ComputableNodeFunction.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9Db21wdXRhYmxlTm9kZUZ1bmN0aW9uLmphdmE=) | `100% <100%> (+66.667%)` | `4 <1> (+2)` | :arrow_up: |; | [.../coveragemodel/cachemanager/DuplicableNDArray.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9EdXBsaWNhYmxlTkRBcnJheS5qYXZh) | `81.818% <100%> (+38.068%)` | `6 <2> (+2)` | :arrow_up: |; | [...s/coveragemodel/cachemanager/DuplicableNumber.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9EdXBsaWNhYmxlTnVtYmVyLmphdmE=) | `80% <100%> (+80%)` | `5 <2> (+5)` | :arrow_up: |; | [...coveragemodel/cachemanager/PrimitiveCacheNode.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9QcmltaXRpdmVDYWNoZU5vZGUuamF2YQ==) | `83.333% <71.429%> (+30.702%)` | `10 <7> (+3)` | :arrow_up: |; | [...er/tools/coveragemodel/cachemanager/CacheNode.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9DYWNoZU5vZGUuamF2YQ==) | `80.645% <76.923%> (+30.645%)` | `9 <8> (+4)` | :arrow_up: |; | [...overagemodel/cachemanager/ComputableCacheNode.java](h,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3035#issuecomment-306412418
https://github.com/broadinstitute/gatk/pull/3035#issuecomment-306412418:2568,Performance,cache,cachemanager,2568, [...ragemodel/cachemanager/ComputableNodeFunction.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9Db21wdXRhYmxlTm9kZUZ1bmN0aW9uLmphdmE=) | `100% <100%> (+66.667%)` | `4 <1> (+2)` | :arrow_up: |; | [.../coveragemodel/cachemanager/DuplicableNDArray.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9EdXBsaWNhYmxlTkRBcnJheS5qYXZh) | `81.818% <100%> (+38.068%)` | `6 <2> (+2)` | :arrow_up: |; | [...s/coveragemodel/cachemanager/DuplicableNumber.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9EdXBsaWNhYmxlTnVtYmVyLmphdmE=) | `80% <100%> (+80%)` | `5 <2> (+5)` | :arrow_up: |; | [...coveragemodel/cachemanager/PrimitiveCacheNode.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9QcmltaXRpdmVDYWNoZU5vZGUuamF2YQ==) | `83.333% <71.429%> (+30.702%)` | `10 <7> (+3)` | :arrow_up: |; | [...er/tools/coveragemodel/cachemanager/CacheNode.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9DYWNoZU5vZGUuamF2YQ==) | `80.645% <76.923%> (+30.645%)` | `9 <8> (+4)` | :arrow_up: |; | [...overagemodel/cachemanager/ComputableCacheNode.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9Db21wdXRhYmxlQ2FjaGVOb2RlLmphdmE=) | `89.189% <80%> (+32.779%)` | `18 <17> (+2)` | :arrow_up: |; | [...ols/coveragemodel/CoverageModelEMCompute,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3035#issuecomment-306412418
https://github.com/broadinstitute/gatk/pull/3035#issuecomment-306412418:2910,Performance,cache,cachemanager,2910,../coveragemodel/cachemanager/DuplicableNDArray.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9EdXBsaWNhYmxlTkRBcnJheS5qYXZh) | `81.818% <100%> (+38.068%)` | `6 <2> (+2)` | :arrow_up: |; | [...s/coveragemodel/cachemanager/DuplicableNumber.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9EdXBsaWNhYmxlTnVtYmVyLmphdmE=) | `80% <100%> (+80%)` | `5 <2> (+5)` | :arrow_up: |; | [...coveragemodel/cachemanager/PrimitiveCacheNode.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9QcmltaXRpdmVDYWNoZU5vZGUuamF2YQ==) | `83.333% <71.429%> (+30.702%)` | `10 <7> (+3)` | :arrow_up: |; | [...er/tools/coveragemodel/cachemanager/CacheNode.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9DYWNoZU5vZGUuamF2YQ==) | `80.645% <76.923%> (+30.645%)` | `9 <8> (+4)` | :arrow_up: |; | [...overagemodel/cachemanager/ComputableCacheNode.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9Db21wdXRhYmxlQ2FjaGVOb2RlLmphdmE=) | `89.189% <80%> (+32.779%)` | `18 <17> (+2)` | :arrow_up: |; | [...ols/coveragemodel/CoverageModelEMComputeBlock.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL0NvdmVyYWdlTW9kZWxFTUNvbXB1dGVCbG9jay5qYXZh) | `77.617% <82.558%> (-1.61%)` | `49 <2> (-1)` | |; | [...dinstitute/hellbender/utils/MathObjectAsserts.java](https://c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3035#issuecomment-306412418
https://github.com/broadinstitute/gatk/pull/3035#issuecomment-306412418:2923,Performance,Cache,CacheNode,2923,../coveragemodel/cachemanager/DuplicableNDArray.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9EdXBsaWNhYmxlTkRBcnJheS5qYXZh) | `81.818% <100%> (+38.068%)` | `6 <2> (+2)` | :arrow_up: |; | [...s/coveragemodel/cachemanager/DuplicableNumber.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9EdXBsaWNhYmxlTnVtYmVyLmphdmE=) | `80% <100%> (+80%)` | `5 <2> (+5)` | :arrow_up: |; | [...coveragemodel/cachemanager/PrimitiveCacheNode.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9QcmltaXRpdmVDYWNoZU5vZGUuamF2YQ==) | `83.333% <71.429%> (+30.702%)` | `10 <7> (+3)` | :arrow_up: |; | [...er/tools/coveragemodel/cachemanager/CacheNode.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9DYWNoZU5vZGUuamF2YQ==) | `80.645% <76.923%> (+30.645%)` | `9 <8> (+4)` | :arrow_up: |; | [...overagemodel/cachemanager/ComputableCacheNode.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9Db21wdXRhYmxlQ2FjaGVOb2RlLmphdmE=) | `89.189% <80%> (+32.779%)` | `18 <17> (+2)` | :arrow_up: |; | [...ols/coveragemodel/CoverageModelEMComputeBlock.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL0NvdmVyYWdlTW9kZWxFTUNvbXB1dGVCbG9jay5qYXZh) | `77.617% <82.558%> (-1.61%)` | `49 <2> (-1)` | |; | [...dinstitute/hellbender/utils/MathObjectAsserts.java](https://c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3035#issuecomment-306412418
https://github.com/broadinstitute/gatk/pull/3035#issuecomment-306412418:3220,Performance,cache,cachemanager,3220, | [...s/coveragemodel/cachemanager/DuplicableNumber.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9EdXBsaWNhYmxlTnVtYmVyLmphdmE=) | `80% <100%> (+80%)` | `5 <2> (+5)` | :arrow_up: |; | [...coveragemodel/cachemanager/PrimitiveCacheNode.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9QcmltaXRpdmVDYWNoZU5vZGUuamF2YQ==) | `83.333% <71.429%> (+30.702%)` | `10 <7> (+3)` | :arrow_up: |; | [...er/tools/coveragemodel/cachemanager/CacheNode.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9DYWNoZU5vZGUuamF2YQ==) | `80.645% <76.923%> (+30.645%)` | `9 <8> (+4)` | :arrow_up: |; | [...overagemodel/cachemanager/ComputableCacheNode.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9Db21wdXRhYmxlQ2FjaGVOb2RlLmphdmE=) | `89.189% <80%> (+32.779%)` | `18 <17> (+2)` | :arrow_up: |; | [...ols/coveragemodel/CoverageModelEMComputeBlock.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL0NvdmVyYWdlTW9kZWxFTUNvbXB1dGVCbG9jay5qYXZh) | `77.617% <82.558%> (-1.61%)` | `49 <2> (-1)` | |; | [...dinstitute/hellbender/utils/MathObjectAsserts.java](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9NYXRoT2JqZWN0QXNzZXJ0cy5qYXZh) | `63.636% <84.615%> (+15.249%)` | `9 <3> (+4)` | :arrow_up: |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/3035?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3035#issuecomment-306412418
https://github.com/broadinstitute/gatk/pull/3036#issuecomment-306513201:960,Performance,Perform,PerformCopyRatioSegmentation,960,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3036?src=pr&el=h1) Report; > Merging [#3036](https://codecov.io/gh/broadinstitute/gatk/pull/3036?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/84fbda69bf9528059777496a415be8eb6db63e61?src=pr&el=desc) will **increase** coverage by `0.331%`.; > The diff coverage is `88.554%`. ```diff; @@ Coverage Diff @@; ## master #3036 +/- ##; ===============================================; + Coverage 79.973% 80.304% +0.331% ; - Complexity 16727 17771 +1044 ; ===============================================; Files 1139 1152 +13 ; Lines 60902 65165 +4263 ; Branches 9437 10284 +847 ; ===============================================; + Hits 48705 52330 +3625 ; - Misses 8401 8900 +499 ; - Partials 3796 3935 +139; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3036?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ome/segmentation/PerformCopyRatioSegmentation.java](https://codecov.io/gh/broadinstitute/gatk/pull/3036?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9zZWdtZW50YXRpb24vUGVyZm9ybUNvcHlSYXRpb1NlZ21lbnRhdGlvbi5qYXZh) | `86.667% <> (+6.667%)` | `4 <0> (+2)` | :arrow_up: |; | [...institute/hellbender/tools/exome/ACNVModeller.java](https://codecov.io/gh/broadinstitute/gatk/pull/3036?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9BQ05WTW9kZWxsZXIuamF2YQ==) | `97.143% <> (-0.079%)` | `17 <0> ()` | |; | [...ellbender/tools/exome/copyratio/CopyRatioData.java](https://codecov.io/gh/broadinstitute/gatk/pull/3036?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9jb3B5cmF0aW8vQ29weVJhdGlvRGF0YS5qYXZh) | `95.349% <0%> (-2.27%)` | `14 <1> (+1)` | |; | [...nder/tools/exome/segmentation/AFCRHiddenState.java](https://codecov.io/gh/broadinstitute/gatk/pull/3036?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3036#issuecomment-306513201
https://github.com/broadinstitute/gatk/pull/3036#issuecomment-306513201:3334,Performance,Perform,PerformAlleleFractionSegmentation,3334,UkhpZGRlblN0YXRlLmphdmE=) | `100% <100%> ()` | `4 <1> (+1)` | :arrow_up: |; | [...tools/exome/segmentation/ClusteringGenomicHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/3036?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9zZWdtZW50YXRpb24vQ2x1c3RlcmluZ0dlbm9taWNITU0uamF2YQ==) | `100% <100%> ()` | `14 <6> (+1)` | :arrow_up: |; | [...a/org/broadinstitute/hellbender/utils/hmm/HMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/3036?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9obW0vSE1NLmphdmE=) | `38.462% <100%> (+11.189%)` | `7 <3> (+3)` | :arrow_up: |; | [...hellbender/utils/hmm/ForwardBackwardAlgorithm.java](https://codecov.io/gh/broadinstitute/gatk/pull/3036?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9obW0vRm9yd2FyZEJhY2t3YXJkQWxnb3JpdGhtLmphdmE=) | `87.766% <100%> (-0.469%)` | `13 <0> ()` | |; | [...lbender/tools/exome/segmentation/CopyRatioHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/3036?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9zZWdtZW50YXRpb24vQ29weVJhdGlvSE1NLmphdmE=) | `100% <100%> ()` | `5 <1> ()` | :arrow_down: |; | [...egmentation/PerformAlleleFractionSegmentation.java](https://codecov.io/gh/broadinstitute/gatk/pull/3036?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9zZWdtZW50YXRpb24vUGVyZm9ybUFsbGVsZUZyYWN0aW9uU2VnbWVudGF0aW9uLmphdmE=) | `88.889% <100%> ()` | `4 <0> (+2)` | :arrow_up: |; | [...r/tools/exome/segmentation/JointAFCRSegmenter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3036?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9zZWdtZW50YXRpb24vSm9pbnRBRkNSU2VnbWVudGVyLmphdmE=) | `100% <100%> (+0.99%)` | `32 <5> ()` | :arrow_down: |; | ... and [103 more](https://codecov.io/gh/broadinstitute/gatk/pull/3036?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3036#issuecomment-306513201
https://github.com/broadinstitute/gatk/pull/3041#issuecomment-306570934:232,Availability,error,error-reference,232,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3041?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@9ca461c`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #3041 +/- ##; ==========================================; Coverage ? 79.996% ; Complexity ? 16751 ; ==========================================; Files ? 1139 ; Lines ? 60989 ; Branches ? 9443 ; ==========================================; Hits ? 48789 ; Misses ? 8403 ; Partials ? 3797; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3041#issuecomment-306570934
https://github.com/broadinstitute/gatk/pull/3041#issuecomment-306570934:180,Usability,learn,learn,180,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3041?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@9ca461c`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #3041 +/- ##; ==========================================; Coverage ? 79.996% ; Complexity ? 16751 ; ==========================================; Files ? 1139 ; Lines ? 60989 ; Branches ? 9443 ; ==========================================; Hits ? 48789 ; Misses ? 8403 ; Partials ? 3797; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3041#issuecomment-306570934
https://github.com/broadinstitute/gatk/pull/3042#issuecomment-357305812:11,Deployability,update,updated,11,@droazen I updated this branch to the new code. I think its good but just want someone to quickly look at it before t goes in.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3042#issuecomment-357305812
https://github.com/broadinstitute/gatk/pull/3042#issuecomment-358747258:60,Deployability,update,updated,60,@lbergelson Could you take a quick look at this one? I just updated it to be in line with the changes I've made to our annotaiton framework.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3042#issuecomment-358747258
https://github.com/broadinstitute/gatk/pull/3042#issuecomment-453565602:46,Testability,test,test,46,"@jamesemery Can you remove the non-functional test, and merge this once tests pass?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3042#issuecomment-453565602
https://github.com/broadinstitute/gatk/pull/3042#issuecomment-453565602:72,Testability,test,tests,72,"@jamesemery Can you remove the non-functional test, and merge this once tests pass?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3042#issuecomment-453565602
https://github.com/broadinstitute/gatk/pull/3043#issuecomment-306585614:1227,Safety,detect,detectcoveragedropout,1227,9f29bba22fa8bb0512350bf93?src=pr&el=desc) will **increase** coverage by `0.078%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #3043 +/- ##; ===============================================; + Coverage 79.902% 79.979% +0.077% ; - Complexity 16668 16733 +65 ; ===============================================; Files 1134 1139 +5 ; Lines 60702 60917 +215 ; Branches 9423 9438 +15 ; ===============================================; + Hits 48502 48721 +219 ; + Misses 8412 8400 -12 ; - Partials 3788 3796 +8; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [.../tools/exome/CalculatePulldownPhasePosteriors.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9DYWxjdWxhdGVQdWxsZG93blBoYXNlUG9zdGVyaW9ycy5qYXZh) | `85.366% <0%> ()` | `8% <0%> (?)` | |; | [...detectcoveragedropout/CoverageDropoutDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9kZXRlY3Rjb3ZlcmFnZWRyb3BvdXQvQ292ZXJhZ2VEcm9wb3V0RGV0ZWN0b3IuamF2YQ==) | `91.803% <0%> ()` | `20% <0%> (?)` | |; | [...e/detectcoveragedropout/DetectCoverageDropout.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9kZXRlY3Rjb3ZlcmFnZWRyb3BvdXQvRGV0ZWN0Q292ZXJhZ2VEcm9wb3V0LmphdmE=) | `84% <0%> ()` | `4% <0%> (?)` | |; | [...ellbender/tools/exome/DecomposeSingularValues.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9EZWNvbXBvc2VTaW5ndWxhclZhbHVlcy5qYXZh) | `89.474% <0%> ()` | `5% <0%> (?)` | |; | [...e/detectcoveragedropout/CoverageDropoutResult.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3043#issuecomment-306585614
https://github.com/broadinstitute/gatk/pull/3043#issuecomment-306585614:1548,Safety,detect,detectcoveragedropout,1548,============; Files 1134 1139 +5 ; Lines 60702 60917 +215 ; Branches 9423 9438 +15 ; ===============================================; + Hits 48502 48721 +219 ; + Misses 8412 8400 -12 ; - Partials 3788 3796 +8; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [.../tools/exome/CalculatePulldownPhasePosteriors.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9DYWxjdWxhdGVQdWxsZG93blBoYXNlUG9zdGVyaW9ycy5qYXZh) | `85.366% <0%> ()` | `8% <0%> (?)` | |; | [...detectcoveragedropout/CoverageDropoutDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9kZXRlY3Rjb3ZlcmFnZWRyb3BvdXQvQ292ZXJhZ2VEcm9wb3V0RGV0ZWN0b3IuamF2YQ==) | `91.803% <0%> ()` | `20% <0%> (?)` | |; | [...e/detectcoveragedropout/DetectCoverageDropout.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9kZXRlY3Rjb3ZlcmFnZWRyb3BvdXQvRGV0ZWN0Q292ZXJhZ2VEcm9wb3V0LmphdmE=) | `84% <0%> ()` | `4% <0%> (?)` | |; | [...ellbender/tools/exome/DecomposeSingularValues.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9EZWNvbXBvc2VTaW5ndWxhclZhbHVlcy5qYXZh) | `89.474% <0%> ()` | `5% <0%> (?)` | |; | [...e/detectcoveragedropout/CoverageDropoutResult.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9kZXRlY3Rjb3ZlcmFnZWRyb3BvdXQvQ292ZXJhZ2VEcm9wb3V0UmVzdWx0LmphdmE=) | `92.593% <0%> ()` | `17% <0%> (?)` | |; | [.../broadinstitute/hellbender/utils/tsv/DataLine.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&e,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3043#issuecomment-306585614
https://github.com/broadinstitute/gatk/pull/3043#issuecomment-306585614:1570,Safety,Detect,DetectCoverageDropout,1570,============; Files 1134 1139 +5 ; Lines 60702 60917 +215 ; Branches 9423 9438 +15 ; ===============================================; + Hits 48502 48721 +219 ; + Misses 8412 8400 -12 ; - Partials 3788 3796 +8; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [.../tools/exome/CalculatePulldownPhasePosteriors.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9DYWxjdWxhdGVQdWxsZG93blBoYXNlUG9zdGVyaW9ycy5qYXZh) | `85.366% <0%> ()` | `8% <0%> (?)` | |; | [...detectcoveragedropout/CoverageDropoutDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9kZXRlY3Rjb3ZlcmFnZWRyb3BvdXQvQ292ZXJhZ2VEcm9wb3V0RGV0ZWN0b3IuamF2YQ==) | `91.803% <0%> ()` | `20% <0%> (?)` | |; | [...e/detectcoveragedropout/DetectCoverageDropout.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9kZXRlY3Rjb3ZlcmFnZWRyb3BvdXQvRGV0ZWN0Q292ZXJhZ2VEcm9wb3V0LmphdmE=) | `84% <0%> ()` | `4% <0%> (?)` | |; | [...ellbender/tools/exome/DecomposeSingularValues.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9EZWNvbXBvc2VTaW5ndWxhclZhbHVlcy5qYXZh) | `89.474% <0%> ()` | `5% <0%> (?)` | |; | [...e/detectcoveragedropout/CoverageDropoutResult.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9kZXRlY3Rjb3ZlcmFnZWRyb3BvdXQvQ292ZXJhZ2VEcm9wb3V0UmVzdWx0LmphdmE=) | `92.593% <0%> ()` | `17% <0%> (?)` | |; | [.../broadinstitute/hellbender/utils/tsv/DataLine.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&e,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3043#issuecomment-306585614
https://github.com/broadinstitute/gatk/pull/3043#issuecomment-306585614:2144,Safety,detect,detectcoveragedropout,2144,aW9ycy5qYXZh) | `85.366% <0%> ()` | `8% <0%> (?)` | |; | [...detectcoveragedropout/CoverageDropoutDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9kZXRlY3Rjb3ZlcmFnZWRyb3BvdXQvQ292ZXJhZ2VEcm9wb3V0RGV0ZWN0b3IuamF2YQ==) | `91.803% <0%> ()` | `20% <0%> (?)` | |; | [...e/detectcoveragedropout/DetectCoverageDropout.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9kZXRlY3Rjb3ZlcmFnZWRyb3BvdXQvRGV0ZWN0Q292ZXJhZ2VEcm9wb3V0LmphdmE=) | `84% <0%> ()` | `4% <0%> (?)` | |; | [...ellbender/tools/exome/DecomposeSingularValues.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9EZWNvbXBvc2VTaW5ndWxhclZhbHVlcy5qYXZh) | `89.474% <0%> ()` | `5% <0%> (?)` | |; | [...e/detectcoveragedropout/CoverageDropoutResult.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9kZXRlY3Rjb3ZlcmFnZWRyb3BvdXQvQ292ZXJhZ2VEcm9wb3V0UmVzdWx0LmphdmE=) | `92.593% <0%> ()` | `17% <0%> (?)` | |; | [.../broadinstitute/hellbender/utils/tsv/DataLine.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvRGF0YUxpbmUuamF2YQ==) | `91.453% <0%> (+0.855%)` | `63% <0%> (+1%)` | :arrow_up: |; | [...itute/hellbender/tools/walkers/SplitIntervals.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1NwbGl0SW50ZXJ2YWxzLmphdmE=) | `90.625% <0%> (+2.39%)` | `12% <0%> (+6%)` | :arrow_up: |; | [...ols/exome/alleliccount/AllelicCountCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3043?src=pr&el=tree#diff-c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3043#issuecomment-306585614
https://github.com/broadinstitute/gatk/pull/3044#issuecomment-306581247:57,Deployability,release,releases,57,https://github.com/GoogleCloudPlatform/google-cloud-java/releases/tag/v0.19.0,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3044#issuecomment-306581247
https://github.com/broadinstitute/gatk/pull/3044#issuecomment-306581466:0,Deployability,update,updated,0,updated to 0.19,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3044#issuecomment-306581466
https://github.com/broadinstitute/gatk/pull/3044#issuecomment-306597002:105,Testability,test,tests,105,"@jean-philippe-martin You're going to have to rebase this branch onto the latest master in order to pass tests, due to a change @lbergelson made in master.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3044#issuecomment-306597002
https://github.com/broadinstitute/gatk/pull/3044#issuecomment-306604461:232,Availability,error,error-reference,232,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3044?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@6f5bab9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #3044 +/- ##; ==========================================; Coverage ? 80.026% ; Complexity ? 16934 ; ==========================================; Files ? 1142 ; Lines ? 61616 ; Branches ? 9594 ; ==========================================; Hits ? 49309 ; Misses ? 8476 ; Partials ? 3831; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3044?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3044?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `71.622% <100%> ()` | `34 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3044#issuecomment-306604461
https://github.com/broadinstitute/gatk/pull/3044#issuecomment-306604461:180,Usability,learn,learn,180,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3044?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@6f5bab9`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #3044 +/- ##; ==========================================; Coverage ? 80.026% ; Complexity ? 16934 ; ==========================================; Files ? 1142 ; Lines ? 61616 ; Branches ? 9594 ; ==========================================; Hits ? 49309 ; Misses ? 8476 ; Partials ? 3831; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3044?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3044?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `71.622% <100%> ()` | `34 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3044#issuecomment-306604461
https://github.com/broadinstitute/gatk/pull/3044#issuecomment-306867623:29,Testability,test,testing,29,@jean-philippe-martin We are testing this internally now to see if it resolves our GCS connection issues -- fingers crossed!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3044#issuecomment-306867623
https://github.com/broadinstitute/gatk/pull/3045#issuecomment-307525890:145,Testability,test,test,145,"Should we mention that when calls are being made (non-GVCF workflow) there is an option for a new QUAL model?. I restarted the one failed travis test. It had failed with; ```; The command ""sudo Rscript scripts/install_R_packages.R"" failed and exited with 1 during .; Your build has been stopped.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3045#issuecomment-307525890
https://github.com/broadinstitute/gatk/pull/3045#issuecomment-309612946:1549,Security,validat,validation,1549,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3045?src=pr&el=h1) Report; > Merging [#3045](https://codecov.io/gh/broadinstitute/gatk/pull/3045?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/b01b71e2e84ceea6df6268594f0ee7aa4e7fe38f?src=pr&el=desc) will **increase** coverage by `0.017%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #3045 +/- ##; ===============================================; + Coverage 80.131% 80.149% +0.017% ; - Complexity 16990 17003 +13 ; ===============================================; Files 1144 1144 ; Lines 61630 61673 +43 ; Branches 9605 9621 +16 ; ===============================================; + Hits 49385 49430 +45 ; + Misses 8422 8419 -3 ; - Partials 3823 3824 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3045?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...tools/walkers/haplotypecaller/HaplotypeCaller.java](https://codecov.io/gh/broadinstitute/gatk/pull/3045?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXIuamF2YQ==) | `94.118% <> ()` | `18 <0> ()` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3045?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `73.649% <0%> (+2.027%)` | `34% <0%> ()` | :arrow_down: |; | [...llbender/tools/walkers/validation/Concordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/3045?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2UuamF2YQ==) | `91.367% <0%> (+2.825%)` | `39% <0%> (+11%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3045#issuecomment-309612946
https://github.com/broadinstitute/gatk/issues/3049#issuecomment-306832820:20,Integrability,message,message,20,"I typoed the commit message that closed this, it was done in #3052",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3049#issuecomment-306832820
https://github.com/broadinstitute/gatk/issues/3050#issuecomment-306836459:69,Availability,error,error,69,"@TianJin297 I'm sorry you're hitting this issue. I haven't seen this error myself so I'm not sure exactly what's going on. We test with spark 2.0.2 and hadoop 2.7.3. (We're currently using google dataproc for most of our work, using [image version 1.1](https://cloud.google.com/dataproc/docs/concepts/dataproc-versions)) I would suspect that newer versions would also work, but I can definitely tell you that gatk has issues with any spark before 2.0.2. . We'll need to see if we can reproduce locally, it's possible that it's a bug unrelated to the spark version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050#issuecomment-306836459
https://github.com/broadinstitute/gatk/issues/3050#issuecomment-306836459:126,Testability,test,test,126,"@TianJin297 I'm sorry you're hitting this issue. I haven't seen this error myself so I'm not sure exactly what's going on. We test with spark 2.0.2 and hadoop 2.7.3. (We're currently using google dataproc for most of our work, using [image version 1.1](https://cloud.google.com/dataproc/docs/concepts/dataproc-versions)) I would suspect that newer versions would also work, but I can definitely tell you that gatk has issues with any spark before 2.0.2. . We'll need to see if we can reproduce locally, it's possible that it's a bug unrelated to the spark version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050#issuecomment-306836459
https://github.com/broadinstitute/gatk/issues/3050#issuecomment-306963267:97,Availability,error,error,97,@lbergelson Thank you for your response. I tried this version of Spark and it did not change the error message. Please tell me what information you may need to reproduce the error.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050#issuecomment-306963267
https://github.com/broadinstitute/gatk/issues/3050#issuecomment-306963267:174,Availability,error,error,174,@lbergelson Thank you for your response. I tried this version of Spark and it did not change the error message. Please tell me what information you may need to reproduce the error.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050#issuecomment-306963267
https://github.com/broadinstitute/gatk/issues/3050#issuecomment-306963267:103,Integrability,message,message,103,@lbergelson Thank you for your response. I tried this version of Spark and it did not change the error message. Please tell me what information you may need to reproduce the error.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050#issuecomment-306963267
https://github.com/broadinstitute/gatk/issues/3050#issuecomment-307204194:206,Deployability,configurat,configuration,206,"@lbergelson Hi, I want to inform you that I have solved the problem. It is because the JAVA version that the master and the worker used are different. It is solved by adding the JAVA_HOME path to the spark configuration file. It is not really a GATK problem, sorry for that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050#issuecomment-307204194
https://github.com/broadinstitute/gatk/issues/3050#issuecomment-307204194:206,Modifiability,config,configuration,206,"@lbergelson Hi, I want to inform you that I have solved the problem. It is because the JAVA version that the master and the worker used are different. It is solved by adding the JAVA_HOME path to the spark configuration file. It is not really a GATK problem, sorry for that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3050#issuecomment-307204194
https://github.com/broadinstitute/gatk/pull/3051#issuecomment-306760437:2422,Testability,test,test,2422,SZWFkTGVuZ3RoUmVhZEZpbHRlci5qYXZh) | `100% <> ()` | `4 <0> ()` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3051?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-80.612%)` | `0% <0%> (-19%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3051?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3051?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3051?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3051?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `41.216% <0%> (-30.405%)` | `26% <0%> (-8%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3051?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3051?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGV,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3051#issuecomment-306760437
https://github.com/broadinstitute/gatk/pull/3052#issuecomment-306832269:84,Testability,test,tests,84," Thanks @davidbenjamin. Someone cancelled the pr build, but I think the push build tests are enough for this change :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3052#issuecomment-306832269
https://github.com/broadinstitute/gatk/issues/3055#issuecomment-306854889:159,Availability,avail,available,159,"For this first-pass documentation, the goal was to add a `@DocumentedFeature` tag _only_. I also added in example use commands from the repo's WDL scripts, if available, or scoured the integration test for an example command. Testing of the commands was extremely limited. Some tools required discussion to decide how to archive. Finally, I completely overhauled the Mutect2 documentation, which reflected GATK3's M2.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3055#issuecomment-306854889
https://github.com/broadinstitute/gatk/issues/3055#issuecomment-306854889:185,Deployability,integrat,integration,185,"For this first-pass documentation, the goal was to add a `@DocumentedFeature` tag _only_. I also added in example use commands from the repo's WDL scripts, if available, or scoured the integration test for an example command. Testing of the commands was extremely limited. Some tools required discussion to decide how to archive. Finally, I completely overhauled the Mutect2 documentation, which reflected GATK3's M2.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3055#issuecomment-306854889
https://github.com/broadinstitute/gatk/issues/3055#issuecomment-306854889:185,Integrability,integrat,integration,185,"For this first-pass documentation, the goal was to add a `@DocumentedFeature` tag _only_. I also added in example use commands from the repo's WDL scripts, if available, or scoured the integration test for an example command. Testing of the commands was extremely limited. Some tools required discussion to decide how to archive. Finally, I completely overhauled the Mutect2 documentation, which reflected GATK3's M2.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3055#issuecomment-306854889
https://github.com/broadinstitute/gatk/issues/3055#issuecomment-306854889:197,Testability,test,test,197,"For this first-pass documentation, the goal was to add a `@DocumentedFeature` tag _only_. I also added in example use commands from the repo's WDL scripts, if available, or scoured the integration test for an example command. Testing of the commands was extremely limited. Some tools required discussion to decide how to archive. Finally, I completely overhauled the Mutect2 documentation, which reflected GATK3's M2.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3055#issuecomment-306854889
https://github.com/broadinstitute/gatk/issues/3055#issuecomment-306854889:226,Testability,Test,Testing,226,"For this first-pass documentation, the goal was to add a `@DocumentedFeature` tag _only_. I also added in example use commands from the repo's WDL scripts, if available, or scoured the integration test for an example command. Testing of the commands was extremely limited. Some tools required discussion to decide how to archive. Finally, I completely overhauled the Mutect2 documentation, which reflected GATK3's M2.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3055#issuecomment-306854889
https://github.com/broadinstitute/gatk/pull/3058#issuecomment-306895297:1248,Testability,test,test,1248,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3058?src=pr&el=h1) Report; > Merging [#3058](https://codecov.io/gh/broadinstitute/gatk/pull/3058?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/33d316f0e8e35572bb60c83a144297c8557bb37d?src=pr&el=desc) will **increase** coverage by `<.001%`.; > The diff coverage is `81.818%`. ```diff; @@ Coverage Diff @@; ## master #3058 +/- ##; ===============================================; + Coverage 80.131% 80.132% +<.001% ; - Complexity 16971 16977 +6 ; ===============================================; Files 1143 1143 ; Lines 61569 61590 +21 ; Branches 9592 9597 +5 ; ===============================================; + Hits 49336 49353 +17 ; - Misses 8417 8419 +2 ; - Partials 3816 3818 +2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3058?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3058?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1N0YW5kYXJkQXJndW1lbnREZWZpbml0aW9ucy5qYXZh) | `0% <> ()` | `0 <0> ()` | :arrow_down: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3058?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `83.582% <100%> (+0.376%)` | `36 <0> ()` | :arrow_down: |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/3058?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `91.282% <78.947%> (-1.373%)` | `89 <8> (+6)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3058#issuecomment-306895297
https://github.com/broadinstitute/gatk/issues/3061#issuecomment-306888339:76,Deployability,update,update,76,"I just heard that production is moving to GatherVCFs, which is getting some update that might be pertinent. I know that the workflows say that they are using MergeVCFs because of other issues:. ```; # using MergeVcfs instead of GatherVcfs so we can create indices; # WARNING 2015-10-28 15:01:48 GatherVcfs Index creation not currently supported when gathering block compressed VCFs.; ```. ---. This concern is germane to any WGS analyses and perhaps not concerning for WES analyses. So perhaps our current WDL workflows that use SplitIntervals could expressly state that they are not safe for WGS variant calling analyses.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-306888339
https://github.com/broadinstitute/gatk/issues/3061#issuecomment-306888339:584,Safety,safe,safe,584,"I just heard that production is moving to GatherVCFs, which is getting some update that might be pertinent. I know that the workflows say that they are using MergeVCFs because of other issues:. ```; # using MergeVcfs instead of GatherVcfs so we can create indices; # WARNING 2015-10-28 15:01:48 GatherVcfs Index creation not currently supported when gathering block compressed VCFs.; ```. ---. This concern is germane to any WGS analyses and perhaps not concerning for WES analyses. So perhaps our current WDL workflows that use SplitIntervals could expressly state that they are not safe for WGS variant calling analyses.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-306888339
https://github.com/broadinstitute/gatk/issues/3061#issuecomment-306889518:4301,Availability,error,error,4301,"112,0:0.00:0:0:3730,0:62:50	0/1:66,70:0.534:25:41:2209,2350:26:40; chr6	33442919	.	A	C	.	alt_allele_in_normal	ECNT=1;HCNT=32;MAX_ED=.;MIN_ED=.;NLOD=2.94;TLOD=6.35	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/0:88,17:0.193:4:13:0.765:2231,128:38:50	0/1:123,29:0.156:13:16:0.552:3124,283:60:60; chr6	71886972	.	TC	T	.	PASS	ECNT=1;HCNT=1;MAX_ED=.;MIN_ED=.;NLOD=2.41;RPA=2,1;RU=C;STR;TLOD=14.12	GT:AD:AF:ALT_F1R2:ALT_F2R1:QSS:REF_F1R2:REF_F2R1	0/0:10,0:0.00:0:0:282,0:3:7	0/1:14,5:0.278:0:4:384,148:6:8; chr6	71886972	.	TC	T	.	PASS	ECNT=1;HCNT=1;MAX_ED=.;MIN_ED=.;NLOD=2.41;RPA=2,1;RU=C;STR;TLOD=14.12	GT:AD:AF:ALT_F1R2:ALT_F2R1:QSS:REF_F1R2:REF_F2R1	0/0:10,0:0.00:0:0:282,0:3:7	0/1:14,5:0.278:0:4:384,148:6:8; chr6	118314029	.	TTTCAGGA	T	.	PASS	ECNT=1;HCNT=16;MAX_ED=.;MIN_ED=.;NLOD=20.42;TLOD=80.46	GT:AD:AF:ALT_F1R2:ALT_F2R1:QSS:REF_F1R2:REF_F2R1	0/0:69,0:0.00:0:0:2115,0:35:34	0/1:68,26:0.261:13:10:2100,793:37:29; ```. **output to non-block-compressed gives desired error**; ```; WMCF9-CB5:precomputed_results shlee$ java -jar $PICARD GatherVcfs I=split3_8.vcf.gz I=split2_8.vcf.gz O=../test_gathervcf_split8_overlap2.vcf; [Wed Jun 07 14:56:26 EDT 2017] picard.vcf.GatherVcfs INPUT=[split3_8.vcf.gz, split2_8.vcf.gz] OUTPUT=../test_gathervcf_split8_overlap2.vcf VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=true CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json; [Wed Jun 07 14:56:26 EDT 2017] Executing as shlee@WMCF9-CB5 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14; Picard version: 2.9.2-SNAPSHOT; INFO	2017-06-07 14:56:26	GatherVcfs	Checking inputs.; INFO	2017-06-07 14:56:26	GatherVcfs	Checking file headers and first records to ensure compatibility.; INFO	2017-06-07 14:56:27	GatherVcfs	Gathering by conventional means.; [Wed Jun 07 14:56:27 EDT 2017] picard.vcf.GatherVcfs done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=257425408; To get help, see http://br",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-306889518
https://github.com/broadinstitute/gatk/issues/3061#issuecomment-306889518:2414,Security,validat,validate,2414,"8,26:0.261:13:10:2100,793:37:29; ```. **output GatherVcfs to .vcf.gz allows for duplicate records**; ```; WMCF9-CB5:precomputed_results shlee$ java -jar $PICARD GatherVcfs I=split3_8.vcf.gz I=split2_8.vcf.gz O=../test_gathervcf_split8_overlap.vcf.gz; [Wed Jun 07 14:51:32 EDT 2017] picard.vcf.GatherVcfs INPUT=[split3_8.vcf.gz, split2_8.vcf.gz] OUTPUT=../test_gathervcf_split8_overlap.vcf.gz VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=true CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json; [Wed Jun 07 14:51:32 EDT 2017] Executing as shlee@WMCF9-CB5 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14; Picard version: 2.9.2-SNAPSHOT; INFO	2017-06-07 14:51:32	GatherVcfs	Checking inputs.; INFO	2017-06-07 14:51:32	GatherVcfs	Checking file headers and first records to ensure compatibility.; INFO	2017-06-07 14:51:32	GatherVcfs	Gathering by copying gzip blocks. Will not be able to validate position non-overlap of files.; WARNING	2017-06-07 14:51:32	GatherVcfs	Index creation not currently supported when gathering block compressed VCFs.; INFO	2017-06-07 14:51:32	GatherVcfs	Gathering /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/precomputed_results/split3_8.vcf.gz; INFO	2017-06-07 14:51:32	GatherVcfs	Gathering /Users/shlee/Documents/workshop_materials/mutect2_tutorial/mutect2_handson/precomputed_results/split2_8.vcf.gz; [Wed Jun 07 14:51:32 EDT 2017] picard.vcf.GatherVcfs done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=257425408; WMCF9-CB5:precomputed_results shlee$ gzcat ../test_gathervcf_split8_overlap.vcf.gz | grep -v '##' ; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NORMAL	TUMOR; chr6	33414233	.	GT	G	.	PASS	ECNT=1;HCNT=1;MAX_ED=.;MIN_ED=.;NLOD=28.24;RPA=5,4;RU=T;STR;TLOD=154.53	GT:AD:AF:ALT_F1R2:ALT_F2R1:QSS:REF_F1R2:REF_F2R1	0/0:112,0:0.00:0:0:3730,0:62:50	0/1:66,70:0.534:25:41:2209,2350:26:40; chr6	33442919	.	A	C	.	alt_allele_i",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-306889518
https://github.com/broadinstitute/gatk/issues/3061#issuecomment-306889518:12,Testability,test,tests,12,"Here are my tests of GatherVcfs that show something interesting. **input1**; ```; WMCF9-CB5:precomputed_results shlee$ gzcat split3_8.vcf.gz | grep -v '##' ; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NORMAL	TUMOR; chr6	33414233	.	GT	G	.	PASS	ECNT=1;HCNT=1;MAX_ED=.;MIN_ED=.;NLOD=28.24;RPA=5,4;RU=T;STR;TLOD=154.53	GT:AD:AF:ALT_F1R2:ALT_F2R1:QSS:REF_F1R2:REF_F2R1	0/0:112,0:0.00:0:0:3730,0:62:50	0/1:66,70:0.534:25:41:2209,2350:26:40; chr6	33442919	.	A	C	.	alt_allele_in_normal	ECNT=1;HCNT=32;MAX_ED=.;MIN_ED=.;NLOD=2.94;TLOD=6.35	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/0:88,17:0.193:4:13:0.765:2231,128:38:50	0/1:123,29:0.156:13:16:0.552:3124,283:60:60; chr6	71886972	.	TC	T	.	PASS	ECNT=1;HCNT=1;MAX_ED=.;MIN_ED=.;NLOD=2.41;RPA=2,1;RU=C;STR;TLOD=14.12	GT:AD:AF:ALT_F1R2:ALT_F2R1:QSS:REF_F1R2:REF_F2R1	0/0:10,0:0.00:0:0:282,0:3:7	0/1:14,5:0.278:0:4:384,148:6:8; ```; **input2**; ```; WMCF9-CB5:precomputed_results shlee$ gzcat split2_8.vcf.gz | grep -v '##' ; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NORMAL	TUMOR; chr6	71886972	.	TC	T	.	PASS	ECNT=1;HCNT=1;MAX_ED=.;MIN_ED=.;NLOD=2.41;RPA=2,1;RU=C;STR;TLOD=14.12	GT:AD:AF:ALT_F1R2:ALT_F2R1:QSS:REF_F1R2:REF_F2R1	0/0:10,0:0.00:0:0:282,0:3:7	0/1:14,5:0.278:0:4:384,148:6:8; chr6	118314029	.	TTTCAGGA	T	.	PASS	ECNT=1;HCNT=16;MAX_ED=.;MIN_ED=.;NLOD=20.42;TLOD=80.46	GT:AD:AF:ALT_F1R2:ALT_F2R1:QSS:REF_F1R2:REF_F2R1	0/0:69,0:0.00:0:0:2115,0:35:34	0/1:68,26:0.261:13:10:2100,793:37:29; ```. **output GatherVcfs to .vcf.gz allows for duplicate records**; ```; WMCF9-CB5:precomputed_results shlee$ java -jar $PICARD GatherVcfs I=split3_8.vcf.gz I=split2_8.vcf.gz O=../test_gathervcf_split8_overlap.vcf.gz; [Wed Jun 07 14:51:32 EDT 2017] picard.vcf.GatherVcfs INPUT=[split3_8.vcf.gz, split2_8.vcf.gz] OUTPUT=../test_gathervcf_split8_overlap.vcf.gz VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=true CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json; [W",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-306889518
https://github.com/broadinstitute/gatk/issues/3061#issuecomment-314866090:186,Modifiability,extend,extend,186,"@sooheelee It looks like split2_8.vcf.gz and split3_8.vcf.gz were generated with GATK 3 M2. In GATK 4 we only emit calls that are within the unpadded read shards, which I believe do not extend past the input intervals. Thus, as long as `SplitIntervals` returns disjoint subintervals (which it does), different scatters of M2 should produce disjoint calls. Could you try to reproduce the issue with GATK 4 M2?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-314866090
https://github.com/broadinstitute/gatk/issues/3061#issuecomment-349727030:201,Integrability,depend,depend,201,"I still feel strongly about not using outputs of SplitIntervals with any reassembly caller as these will expand active regions beyond the intervals given. It is thus possible to end up with calls that depend on identical reads. That is, read evidence is being counted twice for different calls and/or we end up with duplicate calls.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-349727030
https://github.com/broadinstitute/gatk/issues/3061#issuecomment-350088492:75,Safety,avoid,avoid,75,"@sooheelee Do we have a known case in GATK4? I thought we had some code to avoid it but when I recently looked I couldn't find it. So perhaps it was a figment of my imagination, in which case it's certainly an issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-350088492
https://github.com/broadinstitute/gatk/issues/3061#issuecomment-350093043:56,Deployability,pipeline,pipeline,56,"I'm pretty sure we've done this in the exome production pipeline forever, though not with SplitIntervals. HaplotypeCaller (and presumably MuTect) will only output calls in the specified region, no matter how much territory goes into the active region. If a small interval gets split, it will likely have the same active region for both calls.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3061#issuecomment-350093043
https://github.com/broadinstitute/gatk/pull/3062#issuecomment-308630687:57,Deployability,pipeline,pipeline,57,@sooheelee we'll document that separately as part of the pipeline docs; that doesn't belong in individual tool docs imho,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3062#issuecomment-308630687
https://github.com/broadinstitute/gatk/pull/3062#issuecomment-309615020:16,Testability,test,tests,16,will merge when tests pass,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3062#issuecomment-309615020
https://github.com/broadinstitute/gatk/pull/3063#issuecomment-320948324:190,Integrability,rout,routines,190,"Added a few comments of my own -- requested that you refactor to check the index modification time in the `FeatureDataSource` constructors, rather than in the sequence dictionary validation routines.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3063#issuecomment-320948324
https://github.com/broadinstitute/gatk/pull/3063#issuecomment-320948324:53,Modifiability,refactor,refactor,53,"Added a few comments of my own -- requested that you refactor to check the index modification time in the `FeatureDataSource` constructors, rather than in the sequence dictionary validation routines.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3063#issuecomment-320948324
https://github.com/broadinstitute/gatk/pull/3063#issuecomment-320948324:179,Security,validat,validation,179,"Added a few comments of my own -- requested that you refactor to check the index modification time in the `FeatureDataSource` constructors, rather than in the sequence dictionary validation routines.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3063#issuecomment-320948324
https://github.com/broadinstitute/gatk/pull/3065#issuecomment-328703783:1598,Testability,test,testutils,1598, 145236 144960 -276 ; Branches 16096 16061 -35 ; ===============================================; - Hits 126480 126189 -291 ; - Misses 12903 12928 +25 ; + Partials 5853 5843 -10; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3065?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...aplotypecaller/HaplotypeCallerIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3065/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `88.262% <100%> (+0.027%)` | `84 <0> ()` | :arrow_down: |; | [...te/hellbender/utils/pileup/ReadPileupUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3065/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9waWxldXAvUmVhZFBpbGV1cFVuaXRUZXN0LmphdmE=) | `96.352% <100%> ()` | `77 <0> ()` | :arrow_down: |; | [...ellbender/testutils/SamAssertionUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3065/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90ZXN0dXRpbHMvU2FtQXNzZXJ0aW9uVXRpbHNVbml0VGVzdC5qYXZh) | `89.744% <100%> (+0.855%)` | `12 <1> (+1)` | :arrow_up: |; | [...ender/utils/haplotype/HaplotypeBAMDestination.java](https://codecov.io/gh/broadinstitute/gatk/pull/3065/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oYXBsb3R5cGUvSGFwbG90eXBlQkFNRGVzdGluYXRpb24uamF2YQ==) | `100% <100%> ()` | `4 <0> ()` | :arrow_down: |; | [...er/utils/haplotype/HaplotypeBAMWriterUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3065/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oYXBsb3R5cGUvSGFwbG90eXBlQkFNV3JpdGVyVW5pdFRlc3QuamF2YQ==) | `89.076% <100%> ()` | `23 <0> ()` | :arrow_down: |; | [...ute/hellbender/utils/read/ArtificialReadUtils.java](https://codecov.io/gh/broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3065#issuecomment-328703783
https://github.com/broadinstitute/gatk/issues/3066#issuecomment-354314573:5,Availability,error,error,5,This error also happens in AWS EMR. Is there a plan to fix this bug. @vdauwera ; Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066#issuecomment-354314573
https://github.com/broadinstitute/gatk/issues/3066#issuecomment-368469233:1606,Availability,ERROR,ERROR,1606,"ls=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 \; --driver-memory 20g --executor-cores 4 --executor-memory 8g \; /gatk/build/libs/gatk-spark.jar HaplotypeCallerSpark --bam-partition-size 4000000 \; --input hdfs://namenode:8020/PREPROCESSING/PFC_0028_SW_CGTACG_R_recal_reads.bam \; --reference hdfs://namenode:8020/hg19-ucsc/ucsc.hg19.2bit \; --output /NGS-SparkGATK/docker/run/output/PREPROCESSING/PFC_0028_SW_CGTACG_R_raw_variants.g.vcf \; --emit-ref-confidence GVCF --spark-master spark://d16a85842e24:7077; ```. As you can see in my case I executed HaplotypeCallerSpark and I declared the output file in normal File System, not HDFS (I hope it's not a problem, because of pipeline requirements). And so I faced with this exception:. ```; ***********************************************************************. A USER ERROR has occurred: Couldn't write file /NGS-SparkGATK/docker/run/output/PREPROCESSING/PFC_0028_SW_CGTACG_R_raw_variants.g.vcf because writing failed with exception /NGS-SparkGATK/docker/run/output/PREPROCESSING/PFC_0028_SW_CGTACG_R_raw_variants.g.vcf.parts/_SUCCESS: Unable to find _SUCCESS file. ***********************************************************************; ```. Moreover while executing this tool in local mode with the same input sample took about 200 minutes, this time took 3606 minutes in cluster mode. Is it because I used --bam-partition-size 4000000? Or because HaplotypeCallerSpark doesn't get a good speed-up in cluster mode?. **EDIT**; I re-executed the tool in cluster mode without `--bam-partition-size 4000000` and this time I receive this error:; ```; org.apache.spark.shuffle.FetchFailedException: /tmp/spark-31a7c944-0916-4d67-aeab-13afa3b0c302/executor-df44c1b5-632d-403b-9655-9b3be2ea979a/blockmgr-6a0d5d3e-e533-42f4-90d2-8800ed637366/30/shuffle_2_19_0.index (No such file or directory); ```; After 3,586.79 minutes. What I a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066#issuecomment-368469233
https://github.com/broadinstitute/gatk/issues/3066#issuecomment-368469233:2373,Availability,error,error,2373,"dk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 \; --driver-memory 20g --executor-cores 4 --executor-memory 8g \; /gatk/build/libs/gatk-spark.jar HaplotypeCallerSpark --bam-partition-size 4000000 \; --input hdfs://namenode:8020/PREPROCESSING/PFC_0028_SW_CGTACG_R_recal_reads.bam \; --reference hdfs://namenode:8020/hg19-ucsc/ucsc.hg19.2bit \; --output /NGS-SparkGATK/docker/run/output/PREPROCESSING/PFC_0028_SW_CGTACG_R_raw_variants.g.vcf \; --emit-ref-confidence GVCF --spark-master spark://d16a85842e24:7077; ```. As you can see in my case I executed HaplotypeCallerSpark and I declared the output file in normal File System, not HDFS (I hope it's not a problem, because of pipeline requirements). And so I faced with this exception:. ```; ***********************************************************************. A USER ERROR has occurred: Couldn't write file /NGS-SparkGATK/docker/run/output/PREPROCESSING/PFC_0028_SW_CGTACG_R_raw_variants.g.vcf because writing failed with exception /NGS-SparkGATK/docker/run/output/PREPROCESSING/PFC_0028_SW_CGTACG_R_raw_variants.g.vcf.parts/_SUCCESS: Unable to find _SUCCESS file. ***********************************************************************; ```. Moreover while executing this tool in local mode with the same input sample took about 200 minutes, this time took 3606 minutes in cluster mode. Is it because I used --bam-partition-size 4000000? Or because HaplotypeCallerSpark doesn't get a good speed-up in cluster mode?. **EDIT**; I re-executed the tool in cluster mode without `--bam-partition-size 4000000` and this time I receive this error:; ```; org.apache.spark.shuffle.FetchFailedException: /tmp/spark-31a7c944-0916-4d67-aeab-13afa3b0c302/executor-df44c1b5-632d-403b-9655-9b3be2ea979a/blockmgr-6a0d5d3e-e533-42f4-90d2-8800ed637366/30/shuffle_2_19_0.index (No such file or directory); ```; After 3,586.79 minutes. What I am doing wrong?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066#issuecomment-368469233
https://github.com/broadinstitute/gatk/issues/3066#issuecomment-368469233:1460,Deployability,pipeline,pipeline,1460,"se -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 \; --driver-memory 20g --executor-cores 4 --executor-memory 8g \; /gatk/build/libs/gatk-spark.jar HaplotypeCallerSpark --bam-partition-size 4000000 \; --input hdfs://namenode:8020/PREPROCESSING/PFC_0028_SW_CGTACG_R_recal_reads.bam \; --reference hdfs://namenode:8020/hg19-ucsc/ucsc.hg19.2bit \; --output /NGS-SparkGATK/docker/run/output/PREPROCESSING/PFC_0028_SW_CGTACG_R_raw_variants.g.vcf \; --emit-ref-confidence GVCF --spark-master spark://d16a85842e24:7077; ```. As you can see in my case I executed HaplotypeCallerSpark and I declared the output file in normal File System, not HDFS (I hope it's not a problem, because of pipeline requirements). And so I faced with this exception:. ```; ***********************************************************************. A USER ERROR has occurred: Couldn't write file /NGS-SparkGATK/docker/run/output/PREPROCESSING/PFC_0028_SW_CGTACG_R_raw_variants.g.vcf because writing failed with exception /NGS-SparkGATK/docker/run/output/PREPROCESSING/PFC_0028_SW_CGTACG_R_raw_variants.g.vcf.parts/_SUCCESS: Unable to find _SUCCESS file. ***********************************************************************; ```. Moreover while executing this tool in local mode with the same input sample took about 200 minutes, this time took 3606 minutes in cluster mode. Is it because I used --bam-partition-size 4000000? Or because HaplotypeCallerSpark doesn't get a good speed-up in cluster mode?. **EDIT**; I re-executed the tool in cluster mode without `--bam-partition-size 4000000` and this time I receive this error:; ```; org.a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066#issuecomment-368469233
https://github.com/broadinstitute/gatk/issues/3066#issuecomment-407103385:23,Deployability,update,update,23,"Hi folks, is there any update on resolving this issue? I still have encountered this in gatk-4.0.6.0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066#issuecomment-407103385
https://github.com/broadinstitute/gatk/issues/3066#issuecomment-407791242:377,Safety,avoid,avoid,377,"Does the problem go away if you use an output path with the 'hdfs://' scheme? E.g. _hdfs://namenode:8020/user/yaron/output.bam_ (where _namenode_ is the hostname of the namenode). There are two libraries being used internally for accessing the filesystem - the Hadoop filesystem API, and the NIO API - and they have slightly different behaviour if no scheme is provided. So to avoid problems it's best to give full paths with URI schemes for all input and output paths.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066#issuecomment-407791242
https://github.com/broadinstitute/gatk/issues/3066#issuecomment-407791242:230,Security,access,accessing,230,"Does the problem go away if you use an output path with the 'hdfs://' scheme? E.g. _hdfs://namenode:8020/user/yaron/output.bam_ (where _namenode_ is the hostname of the namenode). There are two libraries being used internally for accessing the filesystem - the Hadoop filesystem API, and the NIO API - and they have slightly different behaviour if no scheme is provided. So to avoid problems it's best to give full paths with URI schemes for all input and output paths.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3066#issuecomment-407791242
https://github.com/broadinstitute/gatk/issues/3068#issuecomment-307822412:10,Deployability,update,update,10,"I want to update my dependencies, but the last commits are not in the new artifactory. Which one is the latest?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3068#issuecomment-307822412
https://github.com/broadinstitute/gatk/issues/3068#issuecomment-307822412:20,Integrability,depend,dependencies,20,"I want to update my dependencies, but the last commits are not in the new artifactory. Which one is the latest?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3068#issuecomment-307822412
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:136,Availability,error,error,136,With this new version I'm able to make it fail again; I opened a million channels to read the same file (across 1k threads) and got the error below. Yes I know a million parallel reads on a single file is more than a normal user would issue. ```; shaded.cloud_nio.com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:156); 	at shaded.cloud_nio.c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:3960,Availability,down,down,3960,ent.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:5130); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:494); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.io.EOFException: SSL peer shut down incorrectly; 	at sun.security.ssl.InputRecord.read(InputRecord.java:505); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	... 34 more; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:772,Integrability,protocol,protocol,772,With this new version I'm able to make it fail again; I opened a million channels to read the same file (across 1k threads) and got the error below. Yes I know a million parallel reads on a single file is more than a normal user would issue. ```; shaded.cloud_nio.com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:156); 	at shaded.cloud_nio.c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:851,Integrability,protocol,protocol,851,With this new version I'm able to make it fail again; I opened a million channels to read the same file (across 1k threads) and got the error below. Yes I know a million parallel reads on a single file is more than a normal user would issue. ```; shaded.cloud_nio.com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:156); 	at shaded.cloud_nio.c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:971,Integrability,protocol,protocol,971,With this new version I'm able to make it fail again; I opened a million channels to read the same file (across 1k threads) and got the error below. Yes I know a million parallel reads on a single file is more than a normal user would issue. ```; shaded.cloud_nio.com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:156); 	at shaded.cloud_nio.c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:1066,Integrability,protocol,protocol,1066,on channels to read the same file (across 1k threads) and got the error below. Yes I know a million parallel reads on a single file is more than a normal user would issue. ```; shaded.cloud_nio.com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:156); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestF,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:1160,Integrability,protocol,protocol,1160,llion parallel reads on a single file is more than a normal user would issue. ```; shaded.cloud_nio.com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:156); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogle,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:554,Performance,perform,performInitialHandshake,554,With this new version I'm able to make it fail again; I opened a million channels to read the same file (across 1k threads) and got the error below. Yes I know a million parallel reads on a single file is more than a normal user would issue. ```; shaded.cloud_nio.com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:156); 	at shaded.cloud_nio.c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:3652,Performance,concurren,concurrent,3652,ent.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:5130); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:494); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.io.EOFException: SSL peer shut down incorrectly; 	at sun.security.ssl.InputRecord.read(InputRecord.java:505); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	... 34 more; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:3714,Performance,concurren,concurrent,3714,ent.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:5130); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:494); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.io.EOFException: SSL peer shut down incorrectly; 	at sun.security.ssl.InputRecord.read(InputRecord.java:505); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	... 34 more; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:3799,Performance,concurren,concurrent,3799,ent.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:5130); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:494); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.io.EOFException: SSL peer shut down incorrectly; 	at sun.security.ssl.InputRecord.read(InputRecord.java:505); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	... 34 more; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:456,Security,secur,security,456,With this new version I'm able to make it fail again; I opened a million channels to read the same file (across 1k threads) and got the error below. Yes I know a million parallel reads on a single file is more than a normal user would issue. ```; shaded.cloud_nio.com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:156); 	at shaded.cloud_nio.c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:527,Security,secur,security,527,With this new version I'm able to make it fail again; I opened a million channels to read the same file (across 1k threads) and got the error below. Yes I know a million parallel reads on a single file is more than a normal user would issue. ```; shaded.cloud_nio.com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:156); 	at shaded.cloud_nio.c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:612,Security,secur,security,612,With this new version I'm able to make it fail again; I opened a million channels to read the same file (across 1k threads) and got the error below. Yes I know a million parallel reads on a single file is more than a normal user would issue. ```; shaded.cloud_nio.com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:156); 	at shaded.cloud_nio.c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:688,Security,secur,security,688,With this new version I'm able to make it fail again; I opened a million channels to read the same file (across 1k threads) and got the error below. Yes I know a million parallel reads on a single file is more than a normal user would issue. ```; shaded.cloud_nio.com.google.api.client.http.HttpRequest execute; WARNING: exception thrown while executing request; javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:992); 	at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1375); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1403); 	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1387); 	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:559); 	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream0(HttpURLConnection.java:1316); 	at sun.net.www.protocol.http.HttpURLConnection.getOutputStream(HttpURLConnection.java:1291); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:250); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:77); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972); 	at shaded.cloud_nio.com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:365); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:149); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:135); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:156); 	at shaded.cloud_nio.c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:3986,Security,secur,security,3986,ent.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:5130); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:494); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.io.EOFException: SSL peer shut down incorrectly; 	at sun.security.ssl.InputRecord.read(InputRecord.java:505); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	... 34 more; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156:4047,Security,secur,security,4047,ent.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeMedia(AbstractGoogleClientRequest.java:380); 	at shaded.cloud_nio.com.google.api.services.storage.Storage$Objects$Get.executeMedia(Storage.java:5130); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:494); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.io.EOFException: SSL peer shut down incorrectly; 	at sun.security.ssl.InputRecord.read(InputRecord.java:505); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	... 34 more; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-309120156
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-330331684:77,Availability,failure,failures,77,"@jean-philippe-martin Given that we've finally resolved our intermittent GCS failures at scale, do you think it's still valuable to keep this around, or should this PR be closed?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-330331684
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-330364525:163,Testability,test,test,163,I think we should merge this PR. Our fixes are a sort of workaround the fact that GCS doesn't warm up as quickly as we'd like it to. It's good to have the code to test that again if needed.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-330364525
https://github.com/broadinstitute/gatk/pull/3070#issuecomment-331986909:135,Testability,test,tests,135,@jean-philippe-martin Could you please rebase this onto the latest master? This branch needs a git-lfs-related change in order to pass tests. Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3070#issuecomment-331986909
https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307404453:328,Safety,timeout,timeout,328,"@jean-philippe-martin We've found that with the current NIO retry settings, we're still exhausting all retries and failing ~1-2% of the time on large runs. This PR increases the number of retries from 3 to 20, which should trigger waits of several minutes rather than several seconds in the later retries. It also increases the timeout settings in `BucketUtils.setGenerousTimeouts()` by quite a bit, also with the goal of allowing waits in minutes rather than seconds when necessary. We'll try running with this and see what happens, but in the meantime please review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307404453
https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307443641:103,Performance,throttle,throttled,103,"The change is good :thumbsup:. You may also want to investigate having fewer parallel reads, so we get throttled less.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307443641
https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307444524:243,Security,access,accessing,243,"Thanks JP! We do have an argument to control the number of simultaneous GCS readers in the tool in question. However, even setting it to a low value is triggering the throttling, since we're running about 10,000 ways parallel, and each job is accessing the same set of files. We can currently only control the number of simultaneous readers within each of the 10,000 individual jobs, not across all jobs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307444524
https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307499683:3,Availability,failure,failures,3,No failures so far on the latest run -- think this may have done the trick :),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307499683
https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307499814:130,Testability,test,tests,130,"Not sure about the number of jobs per physical machine @jean-philippe-martin , I'd have to check with @Horneth who is running the tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307499814
https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307506558:19,Availability,failure,failure,19,"Turns out that the failure rate with this patch was greatly reduced, but there were still a few failures. We're trying a run now where we tell the tool to import one file at a time (as opposed to a batch of 25 or 100), and we'll see how that goes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307506558
https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307506558:96,Availability,failure,failures,96,"Turns out that the failure rate with this patch was greatly reduced, but there were still a few failures. We're trying a run now where we tell the tool to import one file at a time (as opposed to a batch of 25 or 100), and we'll see how that goes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307506558
https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307506558:42,Deployability,patch,patch,42,"Turns out that the failure rate with this patch was greatly reduced, but there were still a few failures. We're trying a run now where we tell the tool to import one file at a time (as opposed to a batch of 25 or 100), and we'll see how that goes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307506558
https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307506558:60,Energy Efficiency,reduce,reduced,60,"Turns out that the failure rate with this patch was greatly reduced, but there were still a few failures. We're trying a run now where we tell the tool to import one file at a time (as opposed to a batch of 25 or 100), and we'll see how that goes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3072#issuecomment-307506558
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307472726:26,Deployability,Configurat,Configuration,26,First candidate is Apache Configuration.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307472726
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307472726:26,Modifiability,Config,Configuration,26,First candidate is Apache Configuration.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307472726
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307729448:160,Deployability,Configurat,Configuration,160,"For the second point (file format) I would prefer something different than Java Properties, because for lists will be a bit messy (separated by comma in Apache Configuration). Maybe YML or JSON will be better for this purpose?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307729448
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307729448:160,Modifiability,Config,Configuration,160,"For the second point (file format) I would prefer something different than Java Properties, because for lists will be a bit messy (separated by comma in Apache Configuration). Maybe YML or JSON will be better for this purpose?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307729448
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307794543:223,Availability,error,error-prone,223,"Have to disagree with you on that point, @magicDGS. Comma-separated values for lists seems like the most straightforward/simple/human-editable approach, whereas the other options seem more complex (and therefore more messy/error-prone). (Unless it turns out that we need nested lists, which I'm hoping is not the case!)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307794543
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307794543:121,Usability,simpl,simple,121,"Have to disagree with you on that point, @magicDGS. Comma-separated values for lists seems like the most straightforward/simple/human-editable approach, whereas the other options seem more complex (and therefore more messy/error-prone). (Unless it turns out that we need nested lists, which I'm hoping is not the case!)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307794543
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307798804:58,Modifiability,config,configure,58,@magicDGS Do you have an example of something you need to configure that doesn't work well with java properties?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307798804
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675:279,Deployability,configurat,configuration,279,"I'm thinking about lists such as filters packages (in the filter plugin): I can imagine a list with long package names separated by commas, which might be complicated to read due to the repetition of the same organization name. I think that it might be also more organize if the configuration file is an YML with sections for the different configurations: this will make the file more readable and easier to modify. Something like the codecov configuration will be interesting, separating configurations for spark, plugins, feature codecs, etc. For example, if I want to use a custom codec for BED files while including the HTSJDK codec packages, I would find a problem. Doing it in a granular level may be interesting for having something like:. ```yml; - codecs:; - packages:; - htsjdk.variant; - htsjdk.tribble; - exclude: bed.BEDCodec; - org.broadinstitute.hellbender.utils.codecs; - org.magicdgs.htsjdk.codecs; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675:340,Deployability,configurat,configurations,340,"I'm thinking about lists such as filters packages (in the filter plugin): I can imagine a list with long package names separated by commas, which might be complicated to read due to the repetition of the same organization name. I think that it might be also more organize if the configuration file is an YML with sections for the different configurations: this will make the file more readable and easier to modify. Something like the codecov configuration will be interesting, separating configurations for spark, plugins, feature codecs, etc. For example, if I want to use a custom codec for BED files while including the HTSJDK codec packages, I would find a problem. Doing it in a granular level may be interesting for having something like:. ```yml; - codecs:; - packages:; - htsjdk.variant; - htsjdk.tribble; - exclude: bed.BEDCodec; - org.broadinstitute.hellbender.utils.codecs; - org.magicdgs.htsjdk.codecs; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675:443,Deployability,configurat,configuration,443,"I'm thinking about lists such as filters packages (in the filter plugin): I can imagine a list with long package names separated by commas, which might be complicated to read due to the repetition of the same organization name. I think that it might be also more organize if the configuration file is an YML with sections for the different configurations: this will make the file more readable and easier to modify. Something like the codecov configuration will be interesting, separating configurations for spark, plugins, feature codecs, etc. For example, if I want to use a custom codec for BED files while including the HTSJDK codec packages, I would find a problem. Doing it in a granular level may be interesting for having something like:. ```yml; - codecs:; - packages:; - htsjdk.variant; - htsjdk.tribble; - exclude: bed.BEDCodec; - org.broadinstitute.hellbender.utils.codecs; - org.magicdgs.htsjdk.codecs; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675:489,Deployability,configurat,configurations,489,"I'm thinking about lists such as filters packages (in the filter plugin): I can imagine a list with long package names separated by commas, which might be complicated to read due to the repetition of the same organization name. I think that it might be also more organize if the configuration file is an YML with sections for the different configurations: this will make the file more readable and easier to modify. Something like the codecov configuration will be interesting, separating configurations for spark, plugins, feature codecs, etc. For example, if I want to use a custom codec for BED files while including the HTSJDK codec packages, I would find a problem. Doing it in a granular level may be interesting for having something like:. ```yml; - codecs:; - packages:; - htsjdk.variant; - htsjdk.tribble; - exclude: bed.BEDCodec; - org.broadinstitute.hellbender.utils.codecs; - org.magicdgs.htsjdk.codecs; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675:65,Modifiability,plugin,plugin,65,"I'm thinking about lists such as filters packages (in the filter plugin): I can imagine a list with long package names separated by commas, which might be complicated to read due to the repetition of the same organization name. I think that it might be also more organize if the configuration file is an YML with sections for the different configurations: this will make the file more readable and easier to modify. Something like the codecov configuration will be interesting, separating configurations for spark, plugins, feature codecs, etc. For example, if I want to use a custom codec for BED files while including the HTSJDK codec packages, I would find a problem. Doing it in a granular level may be interesting for having something like:. ```yml; - codecs:; - packages:; - htsjdk.variant; - htsjdk.tribble; - exclude: bed.BEDCodec; - org.broadinstitute.hellbender.utils.codecs; - org.magicdgs.htsjdk.codecs; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675:279,Modifiability,config,configuration,279,"I'm thinking about lists such as filters packages (in the filter plugin): I can imagine a list with long package names separated by commas, which might be complicated to read due to the repetition of the same organization name. I think that it might be also more organize if the configuration file is an YML with sections for the different configurations: this will make the file more readable and easier to modify. Something like the codecov configuration will be interesting, separating configurations for spark, plugins, feature codecs, etc. For example, if I want to use a custom codec for BED files while including the HTSJDK codec packages, I would find a problem. Doing it in a granular level may be interesting for having something like:. ```yml; - codecs:; - packages:; - htsjdk.variant; - htsjdk.tribble; - exclude: bed.BEDCodec; - org.broadinstitute.hellbender.utils.codecs; - org.magicdgs.htsjdk.codecs; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675:340,Modifiability,config,configurations,340,"I'm thinking about lists such as filters packages (in the filter plugin): I can imagine a list with long package names separated by commas, which might be complicated to read due to the repetition of the same organization name. I think that it might be also more organize if the configuration file is an YML with sections for the different configurations: this will make the file more readable and easier to modify. Something like the codecov configuration will be interesting, separating configurations for spark, plugins, feature codecs, etc. For example, if I want to use a custom codec for BED files while including the HTSJDK codec packages, I would find a problem. Doing it in a granular level may be interesting for having something like:. ```yml; - codecs:; - packages:; - htsjdk.variant; - htsjdk.tribble; - exclude: bed.BEDCodec; - org.broadinstitute.hellbender.utils.codecs; - org.magicdgs.htsjdk.codecs; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675:443,Modifiability,config,configuration,443,"I'm thinking about lists such as filters packages (in the filter plugin): I can imagine a list with long package names separated by commas, which might be complicated to read due to the repetition of the same organization name. I think that it might be also more organize if the configuration file is an YML with sections for the different configurations: this will make the file more readable and easier to modify. Something like the codecov configuration will be interesting, separating configurations for spark, plugins, feature codecs, etc. For example, if I want to use a custom codec for BED files while including the HTSJDK codec packages, I would find a problem. Doing it in a granular level may be interesting for having something like:. ```yml; - codecs:; - packages:; - htsjdk.variant; - htsjdk.tribble; - exclude: bed.BEDCodec; - org.broadinstitute.hellbender.utils.codecs; - org.magicdgs.htsjdk.codecs; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675:489,Modifiability,config,configurations,489,"I'm thinking about lists such as filters packages (in the filter plugin): I can imagine a list with long package names separated by commas, which might be complicated to read due to the repetition of the same organization name. I think that it might be also more organize if the configuration file is an YML with sections for the different configurations: this will make the file more readable and easier to modify. Something like the codecov configuration will be interesting, separating configurations for spark, plugins, feature codecs, etc. For example, if I want to use a custom codec for BED files while including the HTSJDK codec packages, I would find a problem. Doing it in a granular level may be interesting for having something like:. ```yml; - codecs:; - packages:; - htsjdk.variant; - htsjdk.tribble; - exclude: bed.BEDCodec; - org.broadinstitute.hellbender.utils.codecs; - org.magicdgs.htsjdk.codecs; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675:515,Modifiability,plugin,plugins,515,"I'm thinking about lists such as filters packages (in the filter plugin): I can imagine a list with long package names separated by commas, which might be complicated to read due to the repetition of the same organization name. I think that it might be also more organize if the configuration file is an YML with sections for the different configurations: this will make the file more readable and easier to modify. Something like the codecov configuration will be interesting, separating configurations for spark, plugins, feature codecs, etc. For example, if I want to use a custom codec for BED files while including the HTSJDK codec packages, I would find a problem. Doing it in a granular level may be interesting for having something like:. ```yml; - codecs:; - packages:; - htsjdk.variant; - htsjdk.tribble; - exclude: bed.BEDCodec; - org.broadinstitute.hellbender.utils.codecs; - org.magicdgs.htsjdk.codecs; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-307803675
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-309543856:52,Availability,avail,available,52,"As a result of @jonn-smith 's initial survey of the available libraries, we are going to test out Owner (https://github.com/lviggiano/owner), which appears to satisfy all of our requirements in an elegant and straightforward way.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-309543856
https://github.com/broadinstitute/gatk/issues/3078#issuecomment-309543856:89,Testability,test,test,89,"As a result of @jonn-smith 's initial survey of the available libraries, we are going to test out Owner (https://github.com/lviggiano/owner), which appears to satisfy all of our requirements in an elegant and straightforward way.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3078#issuecomment-309543856
https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322552565:19,Deployability,configurat,configurations,19,Some info on Spark configurations:. https://stackoverflow.com/questions/29441316/specifying-an-external-configuration-file-for-apache-spark,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322552565
https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322552565:104,Deployability,configurat,configuration-file-for-apache-spark,104,Some info on Spark configurations:. https://stackoverflow.com/questions/29441316/specifying-an-external-configuration-file-for-apache-spark,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322552565
https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322552565:19,Modifiability,config,configurations,19,Some info on Spark configurations:. https://stackoverflow.com/questions/29441316/specifying-an-external-configuration-file-for-apache-spark,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322552565
https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322552565:104,Modifiability,config,configuration-file-for-apache-spark,104,Some info on Spark configurations:. https://stackoverflow.com/questions/29441316/specifying-an-external-configuration-file-for-apache-spark,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322552565
https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322554798:134,Deployability,configurat,configuration-mess-solved,134,Here's another one with our exact problem (solved largely by putting the config onto HDFS). http://progexc.blogspot.com/2014/12/spark-configuration-mess-solved.html,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322554798
https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322554798:73,Modifiability,config,config,73,Here's another one with our exact problem (solved largely by putting the config onto HDFS). http://progexc.blogspot.com/2014/12/spark-configuration-mess-solved.html,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322554798
https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322554798:134,Modifiability,config,configuration-mess-solved,134,Here's another one with our exact problem (solved largely by putting the config onto HDFS). http://progexc.blogspot.com/2014/12/spark-configuration-mess-solved.html,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3079#issuecomment-322554798
https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307529642:53,Deployability,release,release,53,"All Picard tools will be packaged in the final GATK4 release. Selected additional tools from GATK3, such as `DepthOfCoverage` and `VariantAnnotator`, will also be ported.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307529642
https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307530128:11,Deployability,release,release,11,Does final release = beta release or the production release?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307530128
https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307530128:26,Deployability,release,release,26,Does final release = beta release or the production release?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307530128
https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307530128:52,Deployability,release,release,52,Does final release = beta release or the production release?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307530128
https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307530154:17,Deployability,release,release,17,"The official 4.0 release, not the beta release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307530154
https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307530154:39,Deployability,release,release,39,"The official 4.0 release, not the beta release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307530154
https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307734736:54,Deployability,pipeline,pipeline,54,"I would like to eventually port the indel realignment pipeline, but I don't know if I will have time. @sooheelee, maybe you can tell me if people is interested on it? I think that it is still important for Pool-Seq data, where haplotype-based calling is not usually performed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307734736
https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307734736:266,Performance,perform,performed,266,"I would like to eventually port the indel realignment pipeline, but I don't know if I will have time. @sooheelee, maybe you can tell me if people is interested on it? I think that it is still important for Pool-Seq data, where haplotype-based calling is not usually performed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307734736
https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307895094:33,Deployability,continuous,continuous,33,"Yes, @magicDGS I have answered a continuous stream of questions on indel realignment in the forum and these questions are ongoing. Here's one I answered just last week: http://gatkforums.broadinstitute.org/gatk/discussion/comment/39359#Comment_39359. So it appears that it is a step that folks continue to use. . I would add that indel realignment is especially important for Mutect1 pipelines, which continues as the standard in somatic calling, pending performance of Mutect2. Even if Mutect2 were to outperform Mutect1 calling, because of the extreme difference in compute between the two, I conjecture folks will continue to use Mutect1. In fact, the only sane way to output a BAM for the entirety of a somatic sample set is via indel realignment. Somatic folks are keen on manual review and indel realignment is the cheapest way to get there. Here's another scenerio for which indel realignment is useful: the case of a low coverage site where multiple haplotypes are present. These cannot be resolved by HaplotypeCaller if the difference in allele depth between reads supporting either haplotype does not pass some threshold. In this case, sites receive `./.` no calls. Indel realignment using a known sites resource can aid in the resolution of haplotypes at sites that correspond to common population variants. One could argue that the cohort-level analysis could aid in resolution of these, but it may be that large cohorts are a luxury that cannot be afforded by many research groups. ### I vote yes please to porting the indel realignment pipeline.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307895094
https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307895094:384,Deployability,pipeline,pipelines,384,"Yes, @magicDGS I have answered a continuous stream of questions on indel realignment in the forum and these questions are ongoing. Here's one I answered just last week: http://gatkforums.broadinstitute.org/gatk/discussion/comment/39359#Comment_39359. So it appears that it is a step that folks continue to use. . I would add that indel realignment is especially important for Mutect1 pipelines, which continues as the standard in somatic calling, pending performance of Mutect2. Even if Mutect2 were to outperform Mutect1 calling, because of the extreme difference in compute between the two, I conjecture folks will continue to use Mutect1. In fact, the only sane way to output a BAM for the entirety of a somatic sample set is via indel realignment. Somatic folks are keen on manual review and indel realignment is the cheapest way to get there. Here's another scenerio for which indel realignment is useful: the case of a low coverage site where multiple haplotypes are present. These cannot be resolved by HaplotypeCaller if the difference in allele depth between reads supporting either haplotype does not pass some threshold. In this case, sites receive `./.` no calls. Indel realignment using a known sites resource can aid in the resolution of haplotypes at sites that correspond to common population variants. One could argue that the cohort-level analysis could aid in resolution of these, but it may be that large cohorts are a luxury that cannot be afforded by many research groups. ### I vote yes please to porting the indel realignment pipeline.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307895094
https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307895094:1550,Deployability,pipeline,pipeline,1550,"Yes, @magicDGS I have answered a continuous stream of questions on indel realignment in the forum and these questions are ongoing. Here's one I answered just last week: http://gatkforums.broadinstitute.org/gatk/discussion/comment/39359#Comment_39359. So it appears that it is a step that folks continue to use. . I would add that indel realignment is especially important for Mutect1 pipelines, which continues as the standard in somatic calling, pending performance of Mutect2. Even if Mutect2 were to outperform Mutect1 calling, because of the extreme difference in compute between the two, I conjecture folks will continue to use Mutect1. In fact, the only sane way to output a BAM for the entirety of a somatic sample set is via indel realignment. Somatic folks are keen on manual review and indel realignment is the cheapest way to get there. Here's another scenerio for which indel realignment is useful: the case of a low coverage site where multiple haplotypes are present. These cannot be resolved by HaplotypeCaller if the difference in allele depth between reads supporting either haplotype does not pass some threshold. In this case, sites receive `./.` no calls. Indel realignment using a known sites resource can aid in the resolution of haplotypes at sites that correspond to common population variants. One could argue that the cohort-level analysis could aid in resolution of these, but it may be that large cohorts are a luxury that cannot be afforded by many research groups. ### I vote yes please to porting the indel realignment pipeline.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307895094
https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307895094:455,Performance,perform,performance,455,"Yes, @magicDGS I have answered a continuous stream of questions on indel realignment in the forum and these questions are ongoing. Here's one I answered just last week: http://gatkforums.broadinstitute.org/gatk/discussion/comment/39359#Comment_39359. So it appears that it is a step that folks continue to use. . I would add that indel realignment is especially important for Mutect1 pipelines, which continues as the standard in somatic calling, pending performance of Mutect2. Even if Mutect2 were to outperform Mutect1 calling, because of the extreme difference in compute between the two, I conjecture folks will continue to use Mutect1. In fact, the only sane way to output a BAM for the entirety of a somatic sample set is via indel realignment. Somatic folks are keen on manual review and indel realignment is the cheapest way to get there. Here's another scenerio for which indel realignment is useful: the case of a low coverage site where multiple haplotypes are present. These cannot be resolved by HaplotypeCaller if the difference in allele depth between reads supporting either haplotype does not pass some threshold. In this case, sites receive `./.` no calls. Indel realignment using a known sites resource can aid in the resolution of haplotypes at sites that correspond to common population variants. One could argue that the cohort-level analysis could aid in resolution of these, but it may be that large cohorts are a luxury that cannot be afforded by many research groups. ### I vote yes please to porting the indel realignment pipeline.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3084#issuecomment-307895094
https://github.com/broadinstitute/gatk/issues/3088#issuecomment-1887867443:93,Deployability,integrat,integrated,93,"just curious, is deTin model already part of the GATK4 MuTect2 algorithm, or it has not been integrated yet?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3088#issuecomment-1887867443
https://github.com/broadinstitute/gatk/issues/3088#issuecomment-1887867443:93,Integrability,integrat,integrated,93,"just curious, is deTin model already part of the GATK4 MuTect2 algorithm, or it has not been integrated yet?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3088#issuecomment-1887867443
https://github.com/broadinstitute/gatk/pull/3096#issuecomment-307753904:933,Deployability,pipeline,pipelines,933,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=h1) Report; > Merging [#3096](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/c18e7800ed85c55f81387cf02fdcbf6cb3aaaf5e?src=pr&el=desc) will **decrease** coverage by `0.46%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #3096 +/- ##; ==============================================; - Coverage 80.129% 79.669% -0.46% ; + Complexity 16970 16898 -72 ; ==============================================; Files 1143 1143 ; Lines 61566 61566 ; Branches 9592 9592 ; ==============================================; - Hits 49332 49049 -283 ; - Misses 8417 8711 +294 ; + Partials 3817 3806 -11; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ender/tools/spark/pipelines/SortReadFileSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvU29ydFJlYWRGaWxlU3BhcmsuamF2YQ==) | `70.588% <100%> ()` | `4 <0> ()` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-80.612%)` | `0% <0%> (-19%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3096#issuecomment-307753904
https://github.com/broadinstitute/gatk/pull/3096#issuecomment-307753904:2139,Testability,test,test,2139,FJlYWRGaWxlU3BhcmsuamF2YQ==) | `70.588% <100%> ()` | `4 <0> ()` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-80.612%)` | `0% <0%> (-19%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `41.216% <0%> (-30.405%)` | `26% <0%> (-8%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGV,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3096#issuecomment-307753904
https://github.com/broadinstitute/gatk/pull/3096#issuecomment-307753904:3589,Testability,test,test,3589,aW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `41.216% <0%> (-30.405%)` | `26% <0%> (-8%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `70.37% <0%> (-11.111%)` | `10% <0%> ()` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/3096?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3096#issuecomment-307753904
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431:527,Deployability,configurat,configuration,527,"Yeah, the workaround was simply to add the library jar to the classpath and not try to compile them together. I created the issue to soon, Sorry. . As for the NIO library, it is for AWS S3. We are adapting this one https://github.com/Upplication/Amazon-S3-FileSystem-NIO2 to meet our needs. We didn't like the way it handles s3 endpoints because AWS EMR Spark clusters don't support s3 uri's with that particular syntax. Our version modifies it to support normal s3 uri's without endpoints, instead setting the endpoint with a configuration parameter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431:197,Energy Efficiency,adapt,adapting,197,"Yeah, the workaround was simply to add the library jar to the classpath and not try to compile them together. I created the issue to soon, Sorry. . As for the NIO library, it is for AWS S3. We are adapting this one https://github.com/Upplication/Amazon-S3-FileSystem-NIO2 to meet our needs. We didn't like the way it handles s3 endpoints because AWS EMR Spark clusters don't support s3 uri's with that particular syntax. Our version modifies it to support normal s3 uri's without endpoints, instead setting the endpoint with a configuration parameter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431:197,Modifiability,adapt,adapting,197,"Yeah, the workaround was simply to add the library jar to the classpath and not try to compile them together. I created the issue to soon, Sorry. . As for the NIO library, it is for AWS S3. We are adapting this one https://github.com/Upplication/Amazon-S3-FileSystem-NIO2 to meet our needs. We didn't like the way it handles s3 endpoints because AWS EMR Spark clusters don't support s3 uri's with that particular syntax. Our version modifies it to support normal s3 uri's without endpoints, instead setting the endpoint with a configuration parameter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431:527,Modifiability,config,configuration,527,"Yeah, the workaround was simply to add the library jar to the classpath and not try to compile them together. I created the issue to soon, Sorry. . As for the NIO library, it is for AWS S3. We are adapting this one https://github.com/Upplication/Amazon-S3-FileSystem-NIO2 to meet our needs. We didn't like the way it handles s3 endpoints because AWS EMR Spark clusters don't support s3 uri's with that particular syntax. Our version modifies it to support normal s3 uri's without endpoints, instead setting the endpoint with a configuration parameter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431:25,Usability,simpl,simply,25,"Yeah, the workaround was simply to add the library jar to the classpath and not try to compile them together. I created the issue to soon, Sorry. . As for the NIO library, it is for AWS S3. We are adapting this one https://github.com/Upplication/Amazon-S3-FileSystem-NIO2 to meet our needs. We didn't like the way it handles s3 endpoints because AWS EMR Spark clusters don't support s3 uri's with that particular syntax. Our version modifies it to support normal s3 uri's without endpoints, instead setting the endpoint with a configuration parameter.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308161431
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516:83,Availability,failure,failures,83,"I tried a quick upgrade of our guava dependency from 18 -> 22, but it ends in test failures. It looks like at least one of our hadoop dependencies requires guava <= 18. I'm not totally clear if it's an issue for hadoop-core or only in hadoop-minicluster which is a library we use for running tests. If you're not using hdfs I think you won't have any problems including 22, but I'm afraid we can't upgrade our default version without some work. . Hopefully hadoop 3.x will solve the problem in general by shading their internal version of guava. ; https://issues.apache.org/jira/browse/HADOOP-14284, https://issues.apache.org/jira/browse/HADOOP-10101. It sounds like you have a reasonable workaround, let us know if you have further issues with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516:16,Deployability,upgrade,upgrade,16,"I tried a quick upgrade of our guava dependency from 18 -> 22, but it ends in test failures. It looks like at least one of our hadoop dependencies requires guava <= 18. I'm not totally clear if it's an issue for hadoop-core or only in hadoop-minicluster which is a library we use for running tests. If you're not using hdfs I think you won't have any problems including 22, but I'm afraid we can't upgrade our default version without some work. . Hopefully hadoop 3.x will solve the problem in general by shading their internal version of guava. ; https://issues.apache.org/jira/browse/HADOOP-14284, https://issues.apache.org/jira/browse/HADOOP-10101. It sounds like you have a reasonable workaround, let us know if you have further issues with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516:398,Deployability,upgrade,upgrade,398,"I tried a quick upgrade of our guava dependency from 18 -> 22, but it ends in test failures. It looks like at least one of our hadoop dependencies requires guava <= 18. I'm not totally clear if it's an issue for hadoop-core or only in hadoop-minicluster which is a library we use for running tests. If you're not using hdfs I think you won't have any problems including 22, but I'm afraid we can't upgrade our default version without some work. . Hopefully hadoop 3.x will solve the problem in general by shading their internal version of guava. ; https://issues.apache.org/jira/browse/HADOOP-14284, https://issues.apache.org/jira/browse/HADOOP-10101. It sounds like you have a reasonable workaround, let us know if you have further issues with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516:37,Integrability,depend,dependency,37,"I tried a quick upgrade of our guava dependency from 18 -> 22, but it ends in test failures. It looks like at least one of our hadoop dependencies requires guava <= 18. I'm not totally clear if it's an issue for hadoop-core or only in hadoop-minicluster which is a library we use for running tests. If you're not using hdfs I think you won't have any problems including 22, but I'm afraid we can't upgrade our default version without some work. . Hopefully hadoop 3.x will solve the problem in general by shading their internal version of guava. ; https://issues.apache.org/jira/browse/HADOOP-14284, https://issues.apache.org/jira/browse/HADOOP-10101. It sounds like you have a reasonable workaround, let us know if you have further issues with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516:134,Integrability,depend,dependencies,134,"I tried a quick upgrade of our guava dependency from 18 -> 22, but it ends in test failures. It looks like at least one of our hadoop dependencies requires guava <= 18. I'm not totally clear if it's an issue for hadoop-core or only in hadoop-minicluster which is a library we use for running tests. If you're not using hdfs I think you won't have any problems including 22, but I'm afraid we can't upgrade our default version without some work. . Hopefully hadoop 3.x will solve the problem in general by shading their internal version of guava. ; https://issues.apache.org/jira/browse/HADOOP-14284, https://issues.apache.org/jira/browse/HADOOP-10101. It sounds like you have a reasonable workaround, let us know if you have further issues with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516:78,Testability,test,test,78,"I tried a quick upgrade of our guava dependency from 18 -> 22, but it ends in test failures. It looks like at least one of our hadoop dependencies requires guava <= 18. I'm not totally clear if it's an issue for hadoop-core or only in hadoop-minicluster which is a library we use for running tests. If you're not using hdfs I think you won't have any problems including 22, but I'm afraid we can't upgrade our default version without some work. . Hopefully hadoop 3.x will solve the problem in general by shading their internal version of guava. ; https://issues.apache.org/jira/browse/HADOOP-14284, https://issues.apache.org/jira/browse/HADOOP-10101. It sounds like you have a reasonable workaround, let us know if you have further issues with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516:292,Testability,test,tests,292,"I tried a quick upgrade of our guava dependency from 18 -> 22, but it ends in test failures. It looks like at least one of our hadoop dependencies requires guava <= 18. I'm not totally clear if it's an issue for hadoop-core or only in hadoop-minicluster which is a library we use for running tests. If you're not using hdfs I think you won't have any problems including 22, but I'm afraid we can't upgrade our default version without some work. . Hopefully hadoop 3.x will solve the problem in general by shading their internal version of guava. ; https://issues.apache.org/jira/browse/HADOOP-14284, https://issues.apache.org/jira/browse/HADOOP-10101. It sounds like you have a reasonable workaround, let us know if you have further issues with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516:185,Usability,clear,clear,185,"I tried a quick upgrade of our guava dependency from 18 -> 22, but it ends in test failures. It looks like at least one of our hadoop dependencies requires guava <= 18. I'm not totally clear if it's an issue for hadoop-core or only in hadoop-minicluster which is a library we use for running tests. If you're not using hdfs I think you won't have any problems including 22, but I'm afraid we can't upgrade our default version without some work. . Hopefully hadoop 3.x will solve the problem in general by shading their internal version of guava. ; https://issues.apache.org/jira/browse/HADOOP-14284, https://issues.apache.org/jira/browse/HADOOP-10101. It sounds like you have a reasonable workaround, let us know if you have further issues with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-308181516
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368:28,Availability,avail,available,28,@david-wb Is your s3 plugin available as an open source plugin that others could use? We had another question about s3 support in gatk and I thought you might have some insight about it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368:21,Modifiability,plugin,plugin,21,@david-wb Is your s3 plugin available as an open source plugin that others could use? We had another question about s3 support in gatk and I thought you might have some insight about it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368:56,Modifiability,plugin,plugin,56,@david-wb Is your s3 plugin available as an open source plugin that others could use? We had another question about s3 support in gatk and I thought you might have some insight about it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834:914,Availability,avail,available,914,"@lbergelson. Our simple s3 nio library is not currently open source, but we would be willing to make it so after testing it properly. We found that to get the s3 nio library work with GATK, a few minor changes needed to be made in the GATK source. This is especially true for the spark tools because, on AWS EMR Spark clusters, s3 uris can be treated exactly as if they are HDFS uris. Therefore, it was not quite as simple for us to just add the s3 nio library to the classpath and have everything work as expected. For that reason we put the project on hold until GATK is closer to release. Thanks,; David. ________________________________; From: Louis Bergelson <notifications@github.com>; Sent: Monday, July 31, 2017 11:57 AM; To: broadinstitute/gatk; Cc: David Brown; Mention; Subject: Re: [broadinstitute/gatk] update com.google.guava version (#3102). @david-wb<https://github.com/david-wb> Is your s3 plugin available as an open source plugin that others could use? We had another question about s3 support in gatk and I thought you might have some insight about it. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ABxO-d5XTtUyeAI0GzCFLP5eVGYiyQJEks5sThWegaJpZM4N31U->.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834:583,Deployability,release,release,583,"@lbergelson. Our simple s3 nio library is not currently open source, but we would be willing to make it so after testing it properly. We found that to get the s3 nio library work with GATK, a few minor changes needed to be made in the GATK source. This is especially true for the spark tools because, on AWS EMR Spark clusters, s3 uris can be treated exactly as if they are HDFS uris. Therefore, it was not quite as simple for us to just add the s3 nio library to the classpath and have everything work as expected. For that reason we put the project on hold until GATK is closer to release. Thanks,; David. ________________________________; From: Louis Bergelson <notifications@github.com>; Sent: Monday, July 31, 2017 11:57 AM; To: broadinstitute/gatk; Cc: David Brown; Mention; Subject: Re: [broadinstitute/gatk] update com.google.guava version (#3102). @david-wb<https://github.com/david-wb> Is your s3 plugin available as an open source plugin that others could use? We had another question about s3 support in gatk and I thought you might have some insight about it. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ABxO-d5XTtUyeAI0GzCFLP5eVGYiyQJEks5sThWegaJpZM4N31U->.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834:816,Deployability,update,update,816,"@lbergelson. Our simple s3 nio library is not currently open source, but we would be willing to make it so after testing it properly. We found that to get the s3 nio library work with GATK, a few minor changes needed to be made in the GATK source. This is especially true for the spark tools because, on AWS EMR Spark clusters, s3 uris can be treated exactly as if they are HDFS uris. Therefore, it was not quite as simple for us to just add the s3 nio library to the classpath and have everything work as expected. For that reason we put the project on hold until GATK is closer to release. Thanks,; David. ________________________________; From: Louis Bergelson <notifications@github.com>; Sent: Monday, July 31, 2017 11:57 AM; To: broadinstitute/gatk; Cc: David Brown; Mention; Subject: Re: [broadinstitute/gatk] update com.google.guava version (#3102). @david-wb<https://github.com/david-wb> Is your s3 plugin available as an open source plugin that others could use? We had another question about s3 support in gatk and I thought you might have some insight about it. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ABxO-d5XTtUyeAI0GzCFLP5eVGYiyQJEks5sThWegaJpZM4N31U->.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834:907,Modifiability,plugin,plugin,907,"@lbergelson. Our simple s3 nio library is not currently open source, but we would be willing to make it so after testing it properly. We found that to get the s3 nio library work with GATK, a few minor changes needed to be made in the GATK source. This is especially true for the spark tools because, on AWS EMR Spark clusters, s3 uris can be treated exactly as if they are HDFS uris. Therefore, it was not quite as simple for us to just add the s3 nio library to the classpath and have everything work as expected. For that reason we put the project on hold until GATK is closer to release. Thanks,; David. ________________________________; From: Louis Bergelson <notifications@github.com>; Sent: Monday, July 31, 2017 11:57 AM; To: broadinstitute/gatk; Cc: David Brown; Mention; Subject: Re: [broadinstitute/gatk] update com.google.guava version (#3102). @david-wb<https://github.com/david-wb> Is your s3 plugin available as an open source plugin that others could use? We had another question about s3 support in gatk and I thought you might have some insight about it. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ABxO-d5XTtUyeAI0GzCFLP5eVGYiyQJEks5sThWegaJpZM4N31U->.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834:942,Modifiability,plugin,plugin,942,"@lbergelson. Our simple s3 nio library is not currently open source, but we would be willing to make it so after testing it properly. We found that to get the s3 nio library work with GATK, a few minor changes needed to be made in the GATK source. This is especially true for the spark tools because, on AWS EMR Spark clusters, s3 uris can be treated exactly as if they are HDFS uris. Therefore, it was not quite as simple for us to just add the s3 nio library to the classpath and have everything work as expected. For that reason we put the project on hold until GATK is closer to release. Thanks,; David. ________________________________; From: Louis Bergelson <notifications@github.com>; Sent: Monday, July 31, 2017 11:57 AM; To: broadinstitute/gatk; Cc: David Brown; Mention; Subject: Re: [broadinstitute/gatk] update com.google.guava version (#3102). @david-wb<https://github.com/david-wb> Is your s3 plugin available as an open source plugin that others could use? We had another question about s3 support in gatk and I thought you might have some insight about it. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ABxO-d5XTtUyeAI0GzCFLP5eVGYiyQJEks5sThWegaJpZM4N31U->.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834:113,Testability,test,testing,113,"@lbergelson. Our simple s3 nio library is not currently open source, but we would be willing to make it so after testing it properly. We found that to get the s3 nio library work with GATK, a few minor changes needed to be made in the GATK source. This is especially true for the spark tools because, on AWS EMR Spark clusters, s3 uris can be treated exactly as if they are HDFS uris. Therefore, it was not quite as simple for us to just add the s3 nio library to the classpath and have everything work as expected. For that reason we put the project on hold until GATK is closer to release. Thanks,; David. ________________________________; From: Louis Bergelson <notifications@github.com>; Sent: Monday, July 31, 2017 11:57 AM; To: broadinstitute/gatk; Cc: David Brown; Mention; Subject: Re: [broadinstitute/gatk] update com.google.guava version (#3102). @david-wb<https://github.com/david-wb> Is your s3 plugin available as an open source plugin that others could use? We had another question about s3 support in gatk and I thought you might have some insight about it. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ABxO-d5XTtUyeAI0GzCFLP5eVGYiyQJEks5sThWegaJpZM4N31U->.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834:17,Usability,simpl,simple,17,"@lbergelson. Our simple s3 nio library is not currently open source, but we would be willing to make it so after testing it properly. We found that to get the s3 nio library work with GATK, a few minor changes needed to be made in the GATK source. This is especially true for the spark tools because, on AWS EMR Spark clusters, s3 uris can be treated exactly as if they are HDFS uris. Therefore, it was not quite as simple for us to just add the s3 nio library to the classpath and have everything work as expected. For that reason we put the project on hold until GATK is closer to release. Thanks,; David. ________________________________; From: Louis Bergelson <notifications@github.com>; Sent: Monday, July 31, 2017 11:57 AM; To: broadinstitute/gatk; Cc: David Brown; Mention; Subject: Re: [broadinstitute/gatk] update com.google.guava version (#3102). @david-wb<https://github.com/david-wb> Is your s3 plugin available as an open source plugin that others could use? We had another question about s3 support in gatk and I thought you might have some insight about it. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ABxO-d5XTtUyeAI0GzCFLP5eVGYiyQJEks5sThWegaJpZM4N31U->.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834:416,Usability,simpl,simple,416,"@lbergelson. Our simple s3 nio library is not currently open source, but we would be willing to make it so after testing it properly. We found that to get the s3 nio library work with GATK, a few minor changes needed to be made in the GATK source. This is especially true for the spark tools because, on AWS EMR Spark clusters, s3 uris can be treated exactly as if they are HDFS uris. Therefore, it was not quite as simple for us to just add the s3 nio library to the classpath and have everything work as expected. For that reason we put the project on hold until GATK is closer to release. Thanks,; David. ________________________________; From: Louis Bergelson <notifications@github.com>; Sent: Monday, July 31, 2017 11:57 AM; To: broadinstitute/gatk; Cc: David Brown; Mention; Subject: Re: [broadinstitute/gatk] update com.google.guava version (#3102). @david-wb<https://github.com/david-wb> Is your s3 plugin available as an open source plugin that others could use? We had another question about s3 support in gatk and I thought you might have some insight about it. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319146368>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ABxO-d5XTtUyeAI0GzCFLP5eVGYiyQJEks5sThWegaJpZM4N31U->.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319185834
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319189638:598,Energy Efficiency,schedul,schedule,598,"Hi David, . Thanks for the reply. I'm sorry to hear that you had to put things on hold. A lot of the spark tools are not refined to the point they need to be for productive use. We hope to fix a lot of the spark issues towards the end of the summer or beginning of fall, so maybe we can revisit this then. . I'm curious what changes you ended up making to gatk. We've had to do quite a lot of work to get gcs NIO support working well so it's not surprising that there would be similar changes needed for s3. . We'd definitely be interested in hearing about your work on this though, maybe we could schedule a chat at some point once we're nearing the end of beta. It would be really valuable to have native support for s3 in gatk, and I think you've gotten the closest to making it happen.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319189638
https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319206378:256,Modifiability,rewrite,rewrite,256,"Sure thing. I can find out which changes I needed to make in gatk to get certain tools to work, like `PrintReads` and `MarkDuplicates`, though they were certainly not exhaustive. We will also see about open sourcing our s3 nio library which is basically a rewrite of https://github.com/Upplication/Amazon-S3-FileSystem-NIO2 with changes for handling s3 endpoints.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3102#issuecomment-319206378
https://github.com/broadinstitute/gatk/issues/3103#issuecomment-308445066:66,Deployability,pipeline,pipeline,66,"At the moment there's no way to do joint genotyping in spark. The pipeline we use for our production data is to take the gvcfs from haplotype caller -> GenomicsDBImport -> GenotypeGVCFs -> GatherVCFs -> VariantRecalibration. We're still fine-tuning the non-spark version of the pipeline. Once that's finished we would like to implement a version in spark, but there are other things that have higher priority for us so I'm not sure when we will get to it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3103#issuecomment-308445066
https://github.com/broadinstitute/gatk/issues/3103#issuecomment-308445066:278,Deployability,pipeline,pipeline,278,"At the moment there's no way to do joint genotyping in spark. The pipeline we use for our production data is to take the gvcfs from haplotype caller -> GenomicsDBImport -> GenotypeGVCFs -> GatherVCFs -> VariantRecalibration. We're still fine-tuning the non-spark version of the pipeline. Once that's finished we would like to implement a version in spark, but there are other things that have higher priority for us so I'm not sure when we will get to it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3103#issuecomment-308445066
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308060263:59,Deployability,integrat,integration,59,"Can you provide me some test data for include in the tools integration test, @vdauwera and/or @sooheelee? If not, I will try to use some BAM files already in the repository...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308060263
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308060263:59,Integrability,integrat,integration,59,"Can you provide me some test data for include in the tools integration test, @vdauwera and/or @sooheelee? If not, I will try to use some BAM files already in the repository...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308060263
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308060263:24,Testability,test,test,24,"Can you provide me some test data for include in the tools integration test, @vdauwera and/or @sooheelee? If not, I will try to use some BAM files already in the repository...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308060263
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308060263:71,Testability,test,test,71,"Can you provide me some test data for include in the tools integration test, @vdauwera and/or @sooheelee? If not, I will try to use some BAM files already in the repository...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308060263
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308451988:1303,Modifiability,plugin,plugin,1303,"It's not clear to me that we want these tools in Gatk4. We deliberately didn't port them because we felt they were unnecessary going forward. . I understand that there are some legitimate use cases that require them: ex low coverage naive variant calling from high ploidy pools which haplotype caller would do poorly on. (Also, do we know that haplotype caller doesn't do well on those sorts of things? Maybe we should consider modifications there if it doesn't?) I'm not sure that supporting that use case is worth the added complexity of maintaining and supporting these tools. Especially since we don't provide a pileup based variant caller as part of gatk4... . @vdauwera Can you comment? . @sooheelee I'm not sure I agree with you that supporting this for mutect 1 is useful. ; A) We don't want to support the use of mutect 1 anymore and would like to encourage people to switch to mutect 2 which I think we now believe is a better variant caller for both snps and indels. ; B) Mutect 1 users are already using gatk3, so they have access to these tools already. Mutect 1 also requires co-cleaning which I believe is a different but related tool to indel realignment. . For the variant review issue, we have thoughts on implementing a much better solution for variant review by creating an assembly plugin for igv.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308451988
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308451988:1036,Security,access,access,1036,"It's not clear to me that we want these tools in Gatk4. We deliberately didn't port them because we felt they were unnecessary going forward. . I understand that there are some legitimate use cases that require them: ex low coverage naive variant calling from high ploidy pools which haplotype caller would do poorly on. (Also, do we know that haplotype caller doesn't do well on those sorts of things? Maybe we should consider modifications there if it doesn't?) I'm not sure that supporting that use case is worth the added complexity of maintaining and supporting these tools. Especially since we don't provide a pileup based variant caller as part of gatk4... . @vdauwera Can you comment? . @sooheelee I'm not sure I agree with you that supporting this for mutect 1 is useful. ; A) We don't want to support the use of mutect 1 anymore and would like to encourage people to switch to mutect 2 which I think we now believe is a better variant caller for both snps and indels. ; B) Mutect 1 users are already using gatk3, so they have access to these tools already. Mutect 1 also requires co-cleaning which I believe is a different but related tool to indel realignment. . For the variant review issue, we have thoughts on implementing a much better solution for variant review by creating an assembly plugin for igv.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308451988
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308451988:9,Usability,clear,clear,9,"It's not clear to me that we want these tools in Gatk4. We deliberately didn't port them because we felt they were unnecessary going forward. . I understand that there are some legitimate use cases that require them: ex low coverage naive variant calling from high ploidy pools which haplotype caller would do poorly on. (Also, do we know that haplotype caller doesn't do well on those sorts of things? Maybe we should consider modifications there if it doesn't?) I'm not sure that supporting that use case is worth the added complexity of maintaining and supporting these tools. Especially since we don't provide a pileup based variant caller as part of gatk4... . @vdauwera Can you comment? . @sooheelee I'm not sure I agree with you that supporting this for mutect 1 is useful. ; A) We don't want to support the use of mutect 1 anymore and would like to encourage people to switch to mutect 2 which I think we now believe is a better variant caller for both snps and indels. ; B) Mutect 1 users are already using gatk3, so they have access to these tools already. Mutect 1 also requires co-cleaning which I believe is a different but related tool to indel realignment. . For the variant review issue, we have thoughts on implementing a much better solution for variant review by creating an assembly plugin for igv.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308451988
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308460892:1113,Deployability,pipeline,pipeline,1113,"I thought after the last comment of @vdauwera in the [blog post about the removal](http://gatkforums.broadinstitute.org/gatk/discussion/7131/is-indel-realignment-removed-from-gatk4) that it will be possible to port it here as a contribution (without too much effort from your dev team). If the final solution is that this is not going to be maintained in GATK4, I would port this code to my own software if you give me the permission; but it is definitely something that the community is interested. For example, I'm working with Pool-Seq data with hundreds of individuals together, so `HaplotypeCaller` is not a possibility in our case. I'm actually evaluating other approaches for realignment, such as [ABRA](https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/btu376) or [SRMA](https://genomebiology.biomedcentral.com/articles/10.1186/gb-2010-11-10-r99). I'm even thinking on implementing a new realigner based on the GATK's assembler engine and its PairHMM; but this requires more time for evaluation, and it will be nice to be able to compare with the current indel realignment pipeline. Anyway, I can close the issues and PRs in the gatk repo, and port them to my toolkit ([ReadTools](https://github.com/magicDGS/ReadTools)), to maintain the code for the community.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-308460892
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-314886000:499,Availability,down,down,499,@magicDGS I provide some example data for a tutorial at <https://gatkforums.broadinstitute.org/gatk/discussion/7156/howto-perform-local-realignment-around-indels>. Search the page for ` tutorial_7156.tar.gz`. I showcase illustrative sites within the tutorial and also in <https://software.broadinstitute.org/gatk/blog?id=7847>. I'm actually new to test data so what cases are you hoping to test with the data? The snippet in the tutorial data is much larger than you need so it would be good narrow down the test case.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-314886000
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-314886000:122,Performance,perform,perform-local-realignment-around-indels,122,@magicDGS I provide some example data for a tutorial at <https://gatkforums.broadinstitute.org/gatk/discussion/7156/howto-perform-local-realignment-around-indels>. Search the page for ` tutorial_7156.tar.gz`. I showcase illustrative sites within the tutorial and also in <https://software.broadinstitute.org/gatk/blog?id=7847>. I'm actually new to test data so what cases are you hoping to test with the data? The snippet in the tutorial data is much larger than you need so it would be good narrow down the test case.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-314886000
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-314886000:348,Testability,test,test,348,@magicDGS I provide some example data for a tutorial at <https://gatkforums.broadinstitute.org/gatk/discussion/7156/howto-perform-local-realignment-around-indels>. Search the page for ` tutorial_7156.tar.gz`. I showcase illustrative sites within the tutorial and also in <https://software.broadinstitute.org/gatk/blog?id=7847>. I'm actually new to test data so what cases are you hoping to test with the data? The snippet in the tutorial data is much larger than you need so it would be good narrow down the test case.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-314886000
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-314886000:390,Testability,test,test,390,@magicDGS I provide some example data for a tutorial at <https://gatkforums.broadinstitute.org/gatk/discussion/7156/howto-perform-local-realignment-around-indels>. Search the page for ` tutorial_7156.tar.gz`. I showcase illustrative sites within the tutorial and also in <https://software.broadinstitute.org/gatk/blog?id=7847>. I'm actually new to test data so what cases are you hoping to test with the data? The snippet in the tutorial data is much larger than you need so it would be good narrow down the test case.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-314886000
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-314886000:508,Testability,test,test,508,@magicDGS I provide some example data for a tutorial at <https://gatkforums.broadinstitute.org/gatk/discussion/7156/howto-perform-local-realignment-around-indels>. Search the page for ` tutorial_7156.tar.gz`. I showcase illustrative sites within the tutorial and also in <https://software.broadinstitute.org/gatk/blog?id=7847>. I'm actually new to test data so what cases are you hoping to test with the data? The snippet in the tutorial data is much larger than you need so it would be good narrow down the test case.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-314886000
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-319602267:41,Deployability,Update,Update,41,"As I understand, there are two ways:; 1) Update all guides that include tools not ported to GATK4 so users could use GATK4 to get the results as they did earlier.; 2) Add all tools from GATK3.6 to GATK4. Otherwise non official forks will appear.. For now could you please add all tools to GATK4?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-319602267
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-319602267:52,Usability,guid,guides,52,"As I understand, there are two ways:; 1) Update all guides that include tools not ported to GATK4 so users could use GATK4 to get the results as they did earlier.; 2) Add all tools from GATK3.6 to GATK4. Otherwise non official forks will appear.. For now could you please add all tools to GATK4?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-319602267
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-319627989:78,Energy Efficiency,reduce,reduced,78,"That example data from the tutorial is good @sooheelee, but maybe it could be reduced in size to avoid adding it to the large file directory? It will be nice to include that example in the `RealignerTargetCreator` PR (#3112)...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-319627989
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-319627989:97,Safety,avoid,avoid,97,"That example data from the tutorial is good @sooheelee, but maybe it could be reduced in size to avoid adding it to the large file directory? It will be nice to include that example in the `RealignerTargetCreator` PR (#3112)...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-319627989
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-325612165:710,Availability,down,downloaded,710,"@sooheelee, I was coming back to the port this week and I found run the tutorial that you provide me, and the port of `RealignerTargetCreator` (#3112) is providing the same result. Nevertheless, I cannot add the test data to the resources because the reference used is huge (3GB). The **7156_snippet.bam** is of a good size to include it, but it requires the whole reference because some pairs are mapped in other chromosomes. Can it be possible to get another example that it is limited to a couple of chromosomes, preferably 20 and 21 because a reference is already provided for that chromosomes? Thanks in advance!. In addition, I realized that the links to the data are broken in the tutorial; hopefully I downloaded it time ago, but it will be nice if they can be retrieved again in case I lose them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-325612165
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-325612165:212,Testability,test,test,212,"@sooheelee, I was coming back to the port this week and I found run the tutorial that you provide me, and the port of `RealignerTargetCreator` (#3112) is providing the same result. Nevertheless, I cannot add the test data to the resources because the reference used is huge (3GB). The **7156_snippet.bam** is of a good size to include it, but it requires the whole reference because some pairs are mapped in other chromosomes. Can it be possible to get another example that it is limited to a couple of chromosomes, preferably 20 and 21 because a reference is already provided for that chromosomes? Thanks in advance!. In addition, I realized that the links to the data are broken in the tutorial; hopefully I downloaded it time ago, but it will be nice if they can be retrieved again in case I lose them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-325612165
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-361748301:4,Deployability,update,update,4,Any update on this issue? What is the recommended way to use the RealignerTargetCreator and IndelRealigner in other non-GATK pipelines?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-361748301
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-361748301:125,Deployability,pipeline,pipelines,125,Any update on this issue? What is the recommended way to use the RealignerTargetCreator and IndelRealigner in other non-GATK pipelines?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-361748301
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-361892345:75,Availability,avail,available,75,"No update, sorry. The PRs are pending of review, and the data is still not available for proper testing...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-361892345
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-361892345:3,Deployability,update,update,3,"No update, sorry. The PRs are pending of review, and the data is still not available for proper testing...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-361892345
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-361892345:96,Testability,test,testing,96,"No update, sorry. The PRs are pending of review, and the data is still not available for proper testing...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-361892345
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-389534114:298,Availability,avail,available,298,"@lbergelson havent seen it mentioned but the biggest issue (for us at least) is that of licensing. GATK 4 is free for commercial use, while GATK 3 is not. Some of our non-commercial pipelines rely on these GATK 3 tools for processing data for use cases beyond GATK variant callers. Not having them available in GATK 4 means that these pipelines are difficult to move to a commercial setting. If the goal is to move everyone to GATK 4, then dropping support for these tools is counter productive. I am eagerly awaiting updates on their availability in GATK 4.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-389534114
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-389534114:535,Availability,avail,availability,535,"@lbergelson havent seen it mentioned but the biggest issue (for us at least) is that of licensing. GATK 4 is free for commercial use, while GATK 3 is not. Some of our non-commercial pipelines rely on these GATK 3 tools for processing data for use cases beyond GATK variant callers. Not having them available in GATK 4 means that these pipelines are difficult to move to a commercial setting. If the goal is to move everyone to GATK 4, then dropping support for these tools is counter productive. I am eagerly awaiting updates on their availability in GATK 4.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-389534114
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-389534114:182,Deployability,pipeline,pipelines,182,"@lbergelson havent seen it mentioned but the biggest issue (for us at least) is that of licensing. GATK 4 is free for commercial use, while GATK 3 is not. Some of our non-commercial pipelines rely on these GATK 3 tools for processing data for use cases beyond GATK variant callers. Not having them available in GATK 4 means that these pipelines are difficult to move to a commercial setting. If the goal is to move everyone to GATK 4, then dropping support for these tools is counter productive. I am eagerly awaiting updates on their availability in GATK 4.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-389534114
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-389534114:335,Deployability,pipeline,pipelines,335,"@lbergelson havent seen it mentioned but the biggest issue (for us at least) is that of licensing. GATK 4 is free for commercial use, while GATK 3 is not. Some of our non-commercial pipelines rely on these GATK 3 tools for processing data for use cases beyond GATK variant callers. Not having them available in GATK 4 means that these pipelines are difficult to move to a commercial setting. If the goal is to move everyone to GATK 4, then dropping support for these tools is counter productive. I am eagerly awaiting updates on their availability in GATK 4.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-389534114
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-389534114:518,Deployability,update,updates,518,"@lbergelson havent seen it mentioned but the biggest issue (for us at least) is that of licensing. GATK 4 is free for commercial use, while GATK 3 is not. Some of our non-commercial pipelines rely on these GATK 3 tools for processing data for use cases beyond GATK variant callers. Not having them available in GATK 4 means that these pipelines are difficult to move to a commercial setting. If the goal is to move everyone to GATK 4, then dropping support for these tools is counter productive. I am eagerly awaiting updates on their availability in GATK 4.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-389534114
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-389566194:135,Deployability,pipeline,pipelines,135,"@stevekm I agree it would be beneficial to have the indel realignment tools in GATK 4. It helps with reproducing results from existing pipelines and resolves any licensing issues. Having said that, you may want to have a look at the GATK 3 source code. RealignerTargetCreator and IndelRealigner are both in the public subfolder of the gatk-protected repo. https://github.com/broadgsa/gatk-protected/tree/master/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/tools/walkers/indels/RealignerTargetCreator.java . https://github.com/broadgsa/gatk-protected/tree/master/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/tools/walkers/indels/IndelRealigner.java. I 'm not a legal expert, but the source code for RealignerTargetCreator and IndelRealigner both contain this comment which looks to me like permission to use in a commercial setting:. ```; * Permission is hereby granted, free of charge, to any person; * obtaining a copy of this software and associated documentation; * files (the ""Software""), to deal in the Software without; * restriction, including without limitation the rights to use,; * copy, modify, merge, publish, distribute, sublicense, and/or sell; * copies of the Software, and to permit persons to whom the; * Software is furnished to do so, subject to the following; * conditions:; * ; * The above copyright notice and this permission notice shall be; * included in all copies or substantial portions of the Software.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-389566194
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-389566194:914,Energy Efficiency,charge,charge,914,"@stevekm I agree it would be beneficial to have the indel realignment tools in GATK 4. It helps with reproducing results from existing pipelines and resolves any licensing issues. Having said that, you may want to have a look at the GATK 3 source code. RealignerTargetCreator and IndelRealigner are both in the public subfolder of the gatk-protected repo. https://github.com/broadgsa/gatk-protected/tree/master/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/tools/walkers/indels/RealignerTargetCreator.java . https://github.com/broadgsa/gatk-protected/tree/master/public/gatk-tools-public/src/main/java/org/broadinstitute/gatk/tools/walkers/indels/IndelRealigner.java. I 'm not a legal expert, but the source code for RealignerTargetCreator and IndelRealigner both contain this comment which looks to me like permission to use in a commercial setting:. ```; * Permission is hereby granted, free of charge, to any person; * obtaining a copy of this software and associated documentation; * files (the ""Software""), to deal in the Software without; * restriction, including without limitation the rights to use,; * copy, modify, merge, publish, distribute, sublicense, and/or sell; * copies of the Software, and to permit persons to whom the; * Software is furnished to do so, subject to the following; * conditions:; * ; * The above copyright notice and this permission notice shall be; * included in all copies or substantial portions of the Software.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-389566194
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-401850707:154,Deployability,update,update,154,"Hi @magicDGS, thanks for tackling this. I would also like to be able to use IndelRealigner with GATK4. Where are you at with the porting so far? The last update to the PR is sooheelee providing you with some test data in March.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-401850707
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-401850707:208,Testability,test,test,208,"Hi @magicDGS, thanks for tackling this. I would also like to be able to use IndelRealigner with GATK4. Where are you at with the porting so far? The last update to the PR is sooheelee providing you with some test data in March.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-401850707
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-401857759:220,Testability,test,tests,220,"Sorry for all the interested people, but I had lately some deadlines unrelated with software development that took most of my time. Now I will have time to come back to other projects, and I would implement the port and tests with @sooheelee data this/next week. I hope that it works for you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-401857759
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-464410020:13,Deployability,update,update,13,"Is there any update on this? From what I understand, most non-GATK variant callers (such as bcftools or platypus) could still benefit from this. Additionally, the [documentation](http://www.htslib.org/workflow/#mapping_to_variant) for htslib still references GATK's IndelRealigner. If there's no replacement forthcoming, I will open an issue of htslib to have this updated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-464410020
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-464410020:365,Deployability,update,updated,365,"Is there any update on this? From what I understand, most non-GATK variant callers (such as bcftools or platypus) could still benefit from this. Additionally, the [documentation](http://www.htslib.org/workflow/#mapping_to_variant) for htslib still references GATK's IndelRealigner. If there's no replacement forthcoming, I will open an issue of htslib to have this updated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-464410020
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-496488542:4,Deployability,update,updates,4,Any updates?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-496488542
https://github.com/broadinstitute/gatk/issues/3104#issuecomment-1126334162:76,Deployability,update,updates,76,There haven't been any comments here for about 3 years. Have there been any updates in a separate thread or offline? Is there any hope there may be any eventually?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3104#issuecomment-1126334162
https://github.com/broadinstitute/gatk/pull/3106#issuecomment-308123572:1884,Availability,Down,DownsampleableSparkReadShard,1884,e  | Complexity  | |; |---|---|---|---|; | [...bender/engine/spark/AddContextDataToReadSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3106?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvQWRkQ29udGV4dERhdGFUb1JlYWRTcGFyay5qYXZh) | `72.727% <0%> (-3.03%)` | `4 <0> ()` | |; | [...walkers/haplotypecaller/HaplotypeCallerEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/3106?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJFbmdpbmUuamF2YQ==) | `72.519% <100%> (+0.426%)` | `54 <1> (+2)` | :arrow_up: |; | [...r/engine/spark/BroadcastJoinReadsWithVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/3106?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvQnJvYWRjYXN0Sm9pblJlYWRzV2l0aFZhcmlhbnRzLmphdmE=) | `62.5% <66.667%> (-4.167%)` | `4 <3> (+2)` | |; | [...hellbender/tools/DownsampleableSparkReadShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/3106?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Eb3duc2FtcGxlYWJsZVNwYXJrUmVhZFNoYXJkLmphdmE=) | `90.909% <90.909%> ()` | `4 <4> (?)` | |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3106?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `79.048% <92.593%> (-4.626%)` | `24 <7> (-3)` | |; | [...s/spark/sv/discovery/AnnotatedVariantProducer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3106?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQW5ub3RhdGVkVmFyaWFudFByb2R1Y2VyLmphdmE=) | `91.667% <0%> (-1.316%)` | `18% <0%> (+2%)` | |; | [...ls/spark/sv/discovery/GappedAlignmentSplitter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3106?src=pr&el=tree#diff-c3JjL21haW,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3106#issuecomment-308123572
https://github.com/broadinstitute/gatk/pull/3107#issuecomment-308122779:100,Integrability,interface,interface,100,"Could you nominate someone for this one, @droazen?. In addition, I would like to use the `GATKRead` interface instead of `SAMRecord`, but I do not look into the logic enough to do the change yet...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3107#issuecomment-308122779
https://github.com/broadinstitute/gatk/pull/3107#issuecomment-308122779:161,Testability,log,logic,161,"Could you nominate someone for this one, @droazen?. In addition, I would like to use the `GATKRead` interface instead of `SAMRecord`, but I do not look into the logic enough to do the change yet...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3107#issuecomment-308122779
https://github.com/broadinstitute/gatk/pull/3107#issuecomment-308136922:2159,Testability,test,test,2159,aW5lZE1hdGVGaXhpbmdNYW5hZ2VyLmphdmE=) | `44.966% <44.966%> ()` | `35 <35> (?)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3107?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3107?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3107?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3107?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3107?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3107?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-23.729%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3107?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvY,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3107#issuecomment-308136922
https://github.com/broadinstitute/gatk/pull/3107#issuecomment-308136922:3604,Testability,test,test,3604,L21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3107?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3107?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3107?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-23.729%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3107?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `55.263% <0%> (-19.079%)` | `30% <0%> (-8%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3107?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `70.37% <0%> (-11.111%)` | `10% <0%> ()` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3107?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | ... and [10 more](https://codecov.io/gh/broadinstitute/gatk/pull/3107?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3107#issuecomment-308136922
https://github.com/broadinstitute/gatk/pull/3107#issuecomment-381659988:75,Deployability,pipeline,pipeline,75,Closing (will be part of a bigger PR with the port for both tools from the pipeline),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3107#issuecomment-381659988
https://github.com/broadinstitute/gatk/pull/3108#issuecomment-308209516:926,Security,validat,validation,926,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3108?src=pr&el=h1) Report; > Merging [#3108](https://codecov.io/gh/broadinstitute/gatk/pull/3108?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/994b25194cb1a697903e8db749412cba9b422481?src=pr&el=desc) will **increase** coverage by `0.005%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #3108 +/- ##; ===============================================; + Coverage 80.131% 80.136% +0.005% ; Complexity 16992 16992 ; ===============================================; Files 1144 1144 ; Lines 61630 61630 ; Branches 9605 9605 ; ===============================================; + Hits 49385 49388 +3 ; + Misses 8422 8419 -3 ; Partials 3823 3823; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3108?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...llbender/tools/walkers/validation/Concordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/3108?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2UuamF2YQ==) | `88.542% <> ()` | `28 <0> ()` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3108?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `73.649% <0%> (+2.027%)` | `34% <0%> ()` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3108#issuecomment-308209516
https://github.com/broadinstitute/gatk/pull/3108#issuecomment-309578120:16,Testability,test,tests,16,Will merge once tests pass,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3108#issuecomment-309578120
https://github.com/broadinstitute/gatk/pull/3111#issuecomment-308324914:1823,Testability,test,test,1823,/gatk/pull/3111?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-80.612%)` | `0% <0%> (-19%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `41.216% <0%> (-30.405%)` | `26% <0%> (-8%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGV,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3111#issuecomment-308324914
https://github.com/broadinstitute/gatk/pull/3111#issuecomment-308324914:3273,Testability,test,test,3273,=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `41.216% <0%> (-30.405%)` | `26% <0%> (-8%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `70.37% <0%> (-11.111%)` | `10% <0%> ()` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `77.863% <0%> (-5.344%)` | `31% <0%> (-5%)` | |; | ... and [5 more](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3111#issuecomment-308324914
https://github.com/broadinstitute/gatk/pull/3111#issuecomment-308324914:3568,Testability,test,test,3568,=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `41.216% <0%> (-30.405%)` | `26% <0%> (-8%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `70.37% <0%> (-11.111%)` | `10% <0%> ()` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `77.863% <0%> (-5.344%)` | `31% <0%> (-5%)` | |; | ... and [5 more](https://codecov.io/gh/broadinstitute/gatk/pull/3111?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3111#issuecomment-308324914
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-325405652:2150,Testability,test,test,2150,ZWFsaWduZXJUYXJnZXRDcmVhdG9yLmphdmE=) | `74.534% <74.534%> ()` | `31 <31> (?)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3112?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3112?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3112?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3112?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3112?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3112?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-23.729%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3112?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvY,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-325405652
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-325405652:3595,Testability,test,test,3595,L21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3112?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3112?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3112?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-23.729%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3112?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `55.263% <0%> (-19.079%)` | `30% <0%> (-8%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3112?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `70.37% <0%> (-11.111%)` | `10% <0%> ()` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3112?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | ... and [10 more](https://codecov.io/gh/broadinstitute/gatk/pull/3112?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-325405652
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643:429,Integrability,depend,dependent,429,"@magicDGS My apologies for the long delay on this. It looks like there are still quite a few standard porting issues that need to be addressed in this PR (brackets, finals, multiple top-level public classes, outdated GATK3 usage example, remove references to RODs, kebabify, etc., etc.). There is also the bigger issue of testing and validation - ideally at a minimum we'd reproduce the existing GATK3 tests, but since these are dependent on large, private files, those tests will have to be replaced with new tests, and validated/compared against GATK3. These same issues will come up with IndelRealigner. @vdauwera @sooheelee Even with @magicDGS graciously volunteering to do the work of porting the code, retaining the indel realignment tools will require internal review, helping with test development and validation, and support. Before we commit to that, I guess I want to make sure that this is indeed a high priority, and that you think porting this to GATK4 is a better option than relying on GATK3, or letting @magicDGS port it to ReadTools ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643:334,Security,validat,validation,334,"@magicDGS My apologies for the long delay on this. It looks like there are still quite a few standard porting issues that need to be addressed in this PR (brackets, finals, multiple top-level public classes, outdated GATK3 usage example, remove references to RODs, kebabify, etc., etc.). There is also the bigger issue of testing and validation - ideally at a minimum we'd reproduce the existing GATK3 tests, but since these are dependent on large, private files, those tests will have to be replaced with new tests, and validated/compared against GATK3. These same issues will come up with IndelRealigner. @vdauwera @sooheelee Even with @magicDGS graciously volunteering to do the work of porting the code, retaining the indel realignment tools will require internal review, helping with test development and validation, and support. Before we commit to that, I guess I want to make sure that this is indeed a high priority, and that you think porting this to GATK4 is a better option than relying on GATK3, or letting @magicDGS port it to ReadTools ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643:521,Security,validat,validated,521,"@magicDGS My apologies for the long delay on this. It looks like there are still quite a few standard porting issues that need to be addressed in this PR (brackets, finals, multiple top-level public classes, outdated GATK3 usage example, remove references to RODs, kebabify, etc., etc.). There is also the bigger issue of testing and validation - ideally at a minimum we'd reproduce the existing GATK3 tests, but since these are dependent on large, private files, those tests will have to be replaced with new tests, and validated/compared against GATK3. These same issues will come up with IndelRealigner. @vdauwera @sooheelee Even with @magicDGS graciously volunteering to do the work of porting the code, retaining the indel realignment tools will require internal review, helping with test development and validation, and support. Before we commit to that, I guess I want to make sure that this is indeed a high priority, and that you think porting this to GATK4 is a better option than relying on GATK3, or letting @magicDGS port it to ReadTools ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643:810,Security,validat,validation,810,"@magicDGS My apologies for the long delay on this. It looks like there are still quite a few standard porting issues that need to be addressed in this PR (brackets, finals, multiple top-level public classes, outdated GATK3 usage example, remove references to RODs, kebabify, etc., etc.). There is also the bigger issue of testing and validation - ideally at a minimum we'd reproduce the existing GATK3 tests, but since these are dependent on large, private files, those tests will have to be replaced with new tests, and validated/compared against GATK3. These same issues will come up with IndelRealigner. @vdauwera @sooheelee Even with @magicDGS graciously volunteering to do the work of porting the code, retaining the indel realignment tools will require internal review, helping with test development and validation, and support. Before we commit to that, I guess I want to make sure that this is indeed a high priority, and that you think porting this to GATK4 is a better option than relying on GATK3, or letting @magicDGS port it to ReadTools ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643:322,Testability,test,testing,322,"@magicDGS My apologies for the long delay on this. It looks like there are still quite a few standard porting issues that need to be addressed in this PR (brackets, finals, multiple top-level public classes, outdated GATK3 usage example, remove references to RODs, kebabify, etc., etc.). There is also the bigger issue of testing and validation - ideally at a minimum we'd reproduce the existing GATK3 tests, but since these are dependent on large, private files, those tests will have to be replaced with new tests, and validated/compared against GATK3. These same issues will come up with IndelRealigner. @vdauwera @sooheelee Even with @magicDGS graciously volunteering to do the work of porting the code, retaining the indel realignment tools will require internal review, helping with test development and validation, and support. Before we commit to that, I guess I want to make sure that this is indeed a high priority, and that you think porting this to GATK4 is a better option than relying on GATK3, or letting @magicDGS port it to ReadTools ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643:402,Testability,test,tests,402,"@magicDGS My apologies for the long delay on this. It looks like there are still quite a few standard porting issues that need to be addressed in this PR (brackets, finals, multiple top-level public classes, outdated GATK3 usage example, remove references to RODs, kebabify, etc., etc.). There is also the bigger issue of testing and validation - ideally at a minimum we'd reproduce the existing GATK3 tests, but since these are dependent on large, private files, those tests will have to be replaced with new tests, and validated/compared against GATK3. These same issues will come up with IndelRealigner. @vdauwera @sooheelee Even with @magicDGS graciously volunteering to do the work of porting the code, retaining the indel realignment tools will require internal review, helping with test development and validation, and support. Before we commit to that, I guess I want to make sure that this is indeed a high priority, and that you think porting this to GATK4 is a better option than relying on GATK3, or letting @magicDGS port it to ReadTools ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643:470,Testability,test,tests,470,"@magicDGS My apologies for the long delay on this. It looks like there are still quite a few standard porting issues that need to be addressed in this PR (brackets, finals, multiple top-level public classes, outdated GATK3 usage example, remove references to RODs, kebabify, etc., etc.). There is also the bigger issue of testing and validation - ideally at a minimum we'd reproduce the existing GATK3 tests, but since these are dependent on large, private files, those tests will have to be replaced with new tests, and validated/compared against GATK3. These same issues will come up with IndelRealigner. @vdauwera @sooheelee Even with @magicDGS graciously volunteering to do the work of porting the code, retaining the indel realignment tools will require internal review, helping with test development and validation, and support. Before we commit to that, I guess I want to make sure that this is indeed a high priority, and that you think porting this to GATK4 is a better option than relying on GATK3, or letting @magicDGS port it to ReadTools ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643:510,Testability,test,tests,510,"@magicDGS My apologies for the long delay on this. It looks like there are still quite a few standard porting issues that need to be addressed in this PR (brackets, finals, multiple top-level public classes, outdated GATK3 usage example, remove references to RODs, kebabify, etc., etc.). There is also the bigger issue of testing and validation - ideally at a minimum we'd reproduce the existing GATK3 tests, but since these are dependent on large, private files, those tests will have to be replaced with new tests, and validated/compared against GATK3. These same issues will come up with IndelRealigner. @vdauwera @sooheelee Even with @magicDGS graciously volunteering to do the work of porting the code, retaining the indel realignment tools will require internal review, helping with test development and validation, and support. Before we commit to that, I guess I want to make sure that this is indeed a high priority, and that you think porting this to GATK4 is a better option than relying on GATK3, or letting @magicDGS port it to ReadTools ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643:789,Testability,test,test,789,"@magicDGS My apologies for the long delay on this. It looks like there are still quite a few standard porting issues that need to be addressed in this PR (brackets, finals, multiple top-level public classes, outdated GATK3 usage example, remove references to RODs, kebabify, etc., etc.). There is also the bigger issue of testing and validation - ideally at a minimum we'd reproduce the existing GATK3 tests, but since these are dependent on large, private files, those tests will have to be replaced with new tests, and validated/compared against GATK3. These same issues will come up with IndelRealigner. @vdauwera @sooheelee Even with @magicDGS graciously volunteering to do the work of porting the code, retaining the indel realignment tools will require internal review, helping with test development and validation, and support. Before we commit to that, I guess I want to make sure that this is indeed a high priority, and that you think porting this to GATK4 is a better option than relying on GATK3, or letting @magicDGS port it to ReadTools ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363451643
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363745763:472,Deployability,pipeline,pipeline,472,"My first idea was to port it to ReadTools (that's why I asked to change it to the public code when GATK3 was divided into the non-free version and the plan was not to port indel-realignment). Nevertheless, someone showed interest into this and that's why I did this PRs; in addition, it is much better than the original authors (if still at Broad) can contribute to see if the port is correct. Anyway, I don't have any strong feeling about this, and I can always port the pipeline to ReadTools and maintain it there (actually, I had some ideas for other realignment methods and it will be interesting to compare with this). @cmnbroad - this was a long time ago, when even some of the standards (documentation and kebab-case arguments) were not even implemented. Regarding the tests, the last commit includes one using a BAM file in the repository, and the output was generated with GATK3 (if I remember correctly, although I can't remember the version). I think that the best way to go is to re-open a PR to have a cleaner history and proper standards. The idea will be:. 1. Copy of the GATK3 files (from the latest release); 2. Reformat (license and coding-style); 3. Port to the new framework.; 4. Convert documentation and arguments to the GATK4 format; 5. Add tests by running the latest GATK3 release on data in the repository and checking concordance. If a different dataset should be used for the tests, it will be nice if you can provide some. Otherwise, I will use data in the repository (b37_reference_20_21 and NA12878_20_21_WGS_bam)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363745763
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363745763:1116,Deployability,release,release,1116,"My first idea was to port it to ReadTools (that's why I asked to change it to the public code when GATK3 was divided into the non-free version and the plan was not to port indel-realignment). Nevertheless, someone showed interest into this and that's why I did this PRs; in addition, it is much better than the original authors (if still at Broad) can contribute to see if the port is correct. Anyway, I don't have any strong feeling about this, and I can always port the pipeline to ReadTools and maintain it there (actually, I had some ideas for other realignment methods and it will be interesting to compare with this). @cmnbroad - this was a long time ago, when even some of the standards (documentation and kebab-case arguments) were not even implemented. Regarding the tests, the last commit includes one using a BAM file in the repository, and the output was generated with GATK3 (if I remember correctly, although I can't remember the version). I think that the best way to go is to re-open a PR to have a cleaner history and proper standards. The idea will be:. 1. Copy of the GATK3 files (from the latest release); 2. Reformat (license and coding-style); 3. Port to the new framework.; 4. Convert documentation and arguments to the GATK4 format; 5. Add tests by running the latest GATK3 release on data in the repository and checking concordance. If a different dataset should be used for the tests, it will be nice if you can provide some. Otherwise, I will use data in the repository (b37_reference_20_21 and NA12878_20_21_WGS_bam)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363745763
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363745763:1298,Deployability,release,release,1298,"My first idea was to port it to ReadTools (that's why I asked to change it to the public code when GATK3 was divided into the non-free version and the plan was not to port indel-realignment). Nevertheless, someone showed interest into this and that's why I did this PRs; in addition, it is much better than the original authors (if still at Broad) can contribute to see if the port is correct. Anyway, I don't have any strong feeling about this, and I can always port the pipeline to ReadTools and maintain it there (actually, I had some ideas for other realignment methods and it will be interesting to compare with this). @cmnbroad - this was a long time ago, when even some of the standards (documentation and kebab-case arguments) were not even implemented. Regarding the tests, the last commit includes one using a BAM file in the repository, and the output was generated with GATK3 (if I remember correctly, although I can't remember the version). I think that the best way to go is to re-open a PR to have a cleaner history and proper standards. The idea will be:. 1. Copy of the GATK3 files (from the latest release); 2. Reformat (license and coding-style); 3. Port to the new framework.; 4. Convert documentation and arguments to the GATK4 format; 5. Add tests by running the latest GATK3 release on data in the repository and checking concordance. If a different dataset should be used for the tests, it will be nice if you can provide some. Otherwise, I will use data in the repository (b37_reference_20_21 and NA12878_20_21_WGS_bam)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363745763
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363745763:776,Testability,test,tests,776,"My first idea was to port it to ReadTools (that's why I asked to change it to the public code when GATK3 was divided into the non-free version and the plan was not to port indel-realignment). Nevertheless, someone showed interest into this and that's why I did this PRs; in addition, it is much better than the original authors (if still at Broad) can contribute to see if the port is correct. Anyway, I don't have any strong feeling about this, and I can always port the pipeline to ReadTools and maintain it there (actually, I had some ideas for other realignment methods and it will be interesting to compare with this). @cmnbroad - this was a long time ago, when even some of the standards (documentation and kebab-case arguments) were not even implemented. Regarding the tests, the last commit includes one using a BAM file in the repository, and the output was generated with GATK3 (if I remember correctly, although I can't remember the version). I think that the best way to go is to re-open a PR to have a cleaner history and proper standards. The idea will be:. 1. Copy of the GATK3 files (from the latest release); 2. Reformat (license and coding-style); 3. Port to the new framework.; 4. Convert documentation and arguments to the GATK4 format; 5. Add tests by running the latest GATK3 release on data in the repository and checking concordance. If a different dataset should be used for the tests, it will be nice if you can provide some. Otherwise, I will use data in the repository (b37_reference_20_21 and NA12878_20_21_WGS_bam)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363745763
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363745763:1264,Testability,test,tests,1264,"My first idea was to port it to ReadTools (that's why I asked to change it to the public code when GATK3 was divided into the non-free version and the plan was not to port indel-realignment). Nevertheless, someone showed interest into this and that's why I did this PRs; in addition, it is much better than the original authors (if still at Broad) can contribute to see if the port is correct. Anyway, I don't have any strong feeling about this, and I can always port the pipeline to ReadTools and maintain it there (actually, I had some ideas for other realignment methods and it will be interesting to compare with this). @cmnbroad - this was a long time ago, when even some of the standards (documentation and kebab-case arguments) were not even implemented. Regarding the tests, the last commit includes one using a BAM file in the repository, and the output was generated with GATK3 (if I remember correctly, although I can't remember the version). I think that the best way to go is to re-open a PR to have a cleaner history and proper standards. The idea will be:. 1. Copy of the GATK3 files (from the latest release); 2. Reformat (license and coding-style); 3. Port to the new framework.; 4. Convert documentation and arguments to the GATK4 format; 5. Add tests by running the latest GATK3 release on data in the repository and checking concordance. If a different dataset should be used for the tests, it will be nice if you can provide some. Otherwise, I will use data in the repository (b37_reference_20_21 and NA12878_20_21_WGS_bam)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363745763
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363745763:1404,Testability,test,tests,1404,"My first idea was to port it to ReadTools (that's why I asked to change it to the public code when GATK3 was divided into the non-free version and the plan was not to port indel-realignment). Nevertheless, someone showed interest into this and that's why I did this PRs; in addition, it is much better than the original authors (if still at Broad) can contribute to see if the port is correct. Anyway, I don't have any strong feeling about this, and I can always port the pipeline to ReadTools and maintain it there (actually, I had some ideas for other realignment methods and it will be interesting to compare with this). @cmnbroad - this was a long time ago, when even some of the standards (documentation and kebab-case arguments) were not even implemented. Regarding the tests, the last commit includes one using a BAM file in the repository, and the output was generated with GATK3 (if I remember correctly, although I can't remember the version). I think that the best way to go is to re-open a PR to have a cleaner history and proper standards. The idea will be:. 1. Copy of the GATK3 files (from the latest release); 2. Reformat (license and coding-style); 3. Port to the new framework.; 4. Convert documentation and arguments to the GATK4 format; 5. Add tests by running the latest GATK3 release on data in the repository and checking concordance. If a different dataset should be used for the tests, it will be nice if you can provide some. Otherwise, I will use data in the repository (b37_reference_20_21 and NA12878_20_21_WGS_bam)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-363745763
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364606227:149,Testability,test,tests,149,"@magicDGS We face this same issue with many of these tool ports - porting the code is often the easy part by far. I think we'd want to have a set of tests with reasonably good code coverage to start reviewing these PRs, as well as getting concordance with GATK3. And we'll have the same issue with IndelRealigner. I don't have any dataset at the ready other than the one used in GATK3. I can see if any of that data, which is currently private, can be shared with you if thats helpful.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364606227
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364866520:45,Availability,avail,available,45,"@cmnbroad - I can add more tests if there is available data for it, so it will be nice if you can figure out if the data can be made public. Now, the coverage for the tool is 74-75%, because there is no test for known indels; but the test outputs were generated with GATK3 (I can't remember, as I told you before, with which version). Should I close this PR and open a new one with the documentation and arguments with the current style of GATK4, and the tests that are now? I can also add the tests from the tutorial that @sooheelee has gave me, but they are kind of big (probably they should be added with lfs). Just let me know the approach that we should take here...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364866520
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364866520:27,Testability,test,tests,27,"@cmnbroad - I can add more tests if there is available data for it, so it will be nice if you can figure out if the data can be made public. Now, the coverage for the tool is 74-75%, because there is no test for known indels; but the test outputs were generated with GATK3 (I can't remember, as I told you before, with which version). Should I close this PR and open a new one with the documentation and arguments with the current style of GATK4, and the tests that are now? I can also add the tests from the tutorial that @sooheelee has gave me, but they are kind of big (probably they should be added with lfs). Just let me know the approach that we should take here...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364866520
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364866520:203,Testability,test,test,203,"@cmnbroad - I can add more tests if there is available data for it, so it will be nice if you can figure out if the data can be made public. Now, the coverage for the tool is 74-75%, because there is no test for known indels; but the test outputs were generated with GATK3 (I can't remember, as I told you before, with which version). Should I close this PR and open a new one with the documentation and arguments with the current style of GATK4, and the tests that are now? I can also add the tests from the tutorial that @sooheelee has gave me, but they are kind of big (probably they should be added with lfs). Just let me know the approach that we should take here...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364866520
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364866520:234,Testability,test,test,234,"@cmnbroad - I can add more tests if there is available data for it, so it will be nice if you can figure out if the data can be made public. Now, the coverage for the tool is 74-75%, because there is no test for known indels; but the test outputs were generated with GATK3 (I can't remember, as I told you before, with which version). Should I close this PR and open a new one with the documentation and arguments with the current style of GATK4, and the tests that are now? I can also add the tests from the tutorial that @sooheelee has gave me, but they are kind of big (probably they should be added with lfs). Just let me know the approach that we should take here...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364866520
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364866520:455,Testability,test,tests,455,"@cmnbroad - I can add more tests if there is available data for it, so it will be nice if you can figure out if the data can be made public. Now, the coverage for the tool is 74-75%, because there is no test for known indels; but the test outputs were generated with GATK3 (I can't remember, as I told you before, with which version). Should I close this PR and open a new one with the documentation and arguments with the current style of GATK4, and the tests that are now? I can also add the tests from the tutorial that @sooheelee has gave me, but they are kind of big (probably they should be added with lfs). Just let me know the approach that we should take here...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364866520
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364866520:494,Testability,test,tests,494,"@cmnbroad - I can add more tests if there is available data for it, so it will be nice if you can figure out if the data can be made public. Now, the coverage for the tool is 74-75%, because there is no test for known indels; but the test outputs were generated with GATK3 (I can't remember, as I told you before, with which version). Should I close this PR and open a new one with the documentation and arguments with the current style of GATK4, and the tests that are now? I can also add the tests from the tutorial that @sooheelee has gave me, but they are kind of big (probably they should be added with lfs). Just let me know the approach that we should take here...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364866520
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-365644765:62,Availability,avail,available,62,"@magicDGS I will check on whether any of the data can be made available to you. However, the existing GATK3 tests look to be written against the b36 reference, which we can't include in GATK4 even using git-lfs. So either way, I think new tests have to be developed. A new PR would be fine (please include a link to this one), but my suggestion would be that we make sure we have a plan for how to get good test coverage for IndelRealigner before we go any further with RealignerTargetCreator.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-365644765
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-365644765:108,Testability,test,tests,108,"@magicDGS I will check on whether any of the data can be made available to you. However, the existing GATK3 tests look to be written against the b36 reference, which we can't include in GATK4 even using git-lfs. So either way, I think new tests have to be developed. A new PR would be fine (please include a link to this one), but my suggestion would be that we make sure we have a plan for how to get good test coverage for IndelRealigner before we go any further with RealignerTargetCreator.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-365644765
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-365644765:239,Testability,test,tests,239,"@magicDGS I will check on whether any of the data can be made available to you. However, the existing GATK3 tests look to be written against the b36 reference, which we can't include in GATK4 even using git-lfs. So either way, I think new tests have to be developed. A new PR would be fine (please include a link to this one), but my suggestion would be that we make sure we have a plan for how to get good test coverage for IndelRealigner before we go any further with RealignerTargetCreator.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-365644765
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-365644765:407,Testability,test,test,407,"@magicDGS I will check on whether any of the data can be made available to you. However, the existing GATK3 tests look to be written against the b36 reference, which we can't include in GATK4 even using git-lfs. So either way, I think new tests have to be developed. A new PR would be fine (please include a link to this one), but my suggestion would be that we make sure we have a plan for how to get good test coverage for IndelRealigner before we go any further with RealignerTargetCreator.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-365644765
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366187605:1017,Availability,down,downstream,1017,"I think that a proper example would be the one in the tutorial from @sooheelee (https://software.broadinstitute.org/gatk/blog?id=7847, see also https://github.com/broadinstitute/gatk/issues/3104#issuecomment-314886000). I divided the PRs for the `IndelRealignment` into 4 different sections for better review (2 components of indel-realignment, `RealignerTargetCreator`and `IndelRealignment`). This strategy is because I dissected the pipeline into the easy `RealignerTargetCreator` to found regions worth to look at (this could be marked as experimental/beta before the indel-realignment is in) and the more complicated and component-based `IndelRealigner` (the same as with other tools, this can be marked as experimental/beta until a really good coverage is achieved - in the meantime, I have some test with the current data in the repository and the GATK3 counterpart). There are two parts that are usable outside `IndelRealigner` that are worthy to separate into two commits, and might be useful for other tools/downstream projects: `ConstrainedMateFixingManager` and `NWaySAMFileWriter`. That's the reason of making the port in split PRs. One option can be to have the PRs open, and reviewed independently without acceptance until every component is ready. Otherwise, I think that an experimental tag would be good until we find a good set of tests for edge cases. Does this approach make sense for you, @cmnbroad?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366187605
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366187605:435,Deployability,pipeline,pipeline,435,"I think that a proper example would be the one in the tutorial from @sooheelee (https://software.broadinstitute.org/gatk/blog?id=7847, see also https://github.com/broadinstitute/gatk/issues/3104#issuecomment-314886000). I divided the PRs for the `IndelRealignment` into 4 different sections for better review (2 components of indel-realignment, `RealignerTargetCreator`and `IndelRealignment`). This strategy is because I dissected the pipeline into the easy `RealignerTargetCreator` to found regions worth to look at (this could be marked as experimental/beta before the indel-realignment is in) and the more complicated and component-based `IndelRealigner` (the same as with other tools, this can be marked as experimental/beta until a really good coverage is achieved - in the meantime, I have some test with the current data in the repository and the GATK3 counterpart). There are two parts that are usable outside `IndelRealigner` that are worthy to separate into two commits, and might be useful for other tools/downstream projects: `ConstrainedMateFixingManager` and `NWaySAMFileWriter`. That's the reason of making the port in split PRs. One option can be to have the PRs open, and reviewed independently without acceptance until every component is ready. Otherwise, I think that an experimental tag would be good until we find a good set of tests for edge cases. Does this approach make sense for you, @cmnbroad?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366187605
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366187605:801,Testability,test,test,801,"I think that a proper example would be the one in the tutorial from @sooheelee (https://software.broadinstitute.org/gatk/blog?id=7847, see also https://github.com/broadinstitute/gatk/issues/3104#issuecomment-314886000). I divided the PRs for the `IndelRealignment` into 4 different sections for better review (2 components of indel-realignment, `RealignerTargetCreator`and `IndelRealignment`). This strategy is because I dissected the pipeline into the easy `RealignerTargetCreator` to found regions worth to look at (this could be marked as experimental/beta before the indel-realignment is in) and the more complicated and component-based `IndelRealigner` (the same as with other tools, this can be marked as experimental/beta until a really good coverage is achieved - in the meantime, I have some test with the current data in the repository and the GATK3 counterpart). There are two parts that are usable outside `IndelRealigner` that are worthy to separate into two commits, and might be useful for other tools/downstream projects: `ConstrainedMateFixingManager` and `NWaySAMFileWriter`. That's the reason of making the port in split PRs. One option can be to have the PRs open, and reviewed independently without acceptance until every component is ready. Otherwise, I think that an experimental tag would be good until we find a good set of tests for edge cases. Does this approach make sense for you, @cmnbroad?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366187605
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366187605:1349,Testability,test,tests,1349,"I think that a proper example would be the one in the tutorial from @sooheelee (https://software.broadinstitute.org/gatk/blog?id=7847, see also https://github.com/broadinstitute/gatk/issues/3104#issuecomment-314886000). I divided the PRs for the `IndelRealignment` into 4 different sections for better review (2 components of indel-realignment, `RealignerTargetCreator`and `IndelRealignment`). This strategy is because I dissected the pipeline into the easy `RealignerTargetCreator` to found regions worth to look at (this could be marked as experimental/beta before the indel-realignment is in) and the more complicated and component-based `IndelRealigner` (the same as with other tools, this can be marked as experimental/beta until a really good coverage is achieved - in the meantime, I have some test with the current data in the repository and the GATK3 counterpart). There are two parts that are usable outside `IndelRealigner` that are worthy to separate into two commits, and might be useful for other tools/downstream projects: `ConstrainedMateFixingManager` and `NWaySAMFileWriter`. That's the reason of making the port in split PRs. One option can be to have the PRs open, and reviewed independently without acceptance until every component is ready. Otherwise, I think that an experimental tag would be good until we find a good set of tests for edge cases. Does this approach make sense for you, @cmnbroad?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366187605
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366187605:903,Usability,usab,usable,903,"I think that a proper example would be the one in the tutorial from @sooheelee (https://software.broadinstitute.org/gatk/blog?id=7847, see also https://github.com/broadinstitute/gatk/issues/3104#issuecomment-314886000). I divided the PRs for the `IndelRealignment` into 4 different sections for better review (2 components of indel-realignment, `RealignerTargetCreator`and `IndelRealignment`). This strategy is because I dissected the pipeline into the easy `RealignerTargetCreator` to found regions worth to look at (this could be marked as experimental/beta before the indel-realignment is in) and the more complicated and component-based `IndelRealigner` (the same as with other tools, this can be marked as experimental/beta until a really good coverage is achieved - in the meantime, I have some test with the current data in the repository and the GATK3 counterpart). There are two parts that are usable outside `IndelRealigner` that are worthy to separate into two commits, and might be useful for other tools/downstream projects: `ConstrainedMateFixingManager` and `NWaySAMFileWriter`. That's the reason of making the port in split PRs. One option can be to have the PRs open, and reviewed independently without acceptance until every component is ready. Otherwise, I think that an experimental tag would be good until we find a good set of tests for edge cases. Does this approach make sense for you, @cmnbroad?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366187605
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366271857:471,Integrability,depend,depends,471,"The tutorial data would be an option, except that it covers reference territory not currently in the repo. It looks like that would add nearly 1 gig just for the reference data, which I think we'd really want to avoid. Ideally we'd have just one PR for each of the (two) tools. If you want to keep `ConstrainedMateFixingManager` and `NWaySAMFileWriter` as separate PRs, thats fine, but I don't think we'd take them until we know there is, or will very soon be, code that depends on them. Certainly using `@Experimental` for the tools could make sense, once we're certain that we have a way forward for test coverage. One other note, it's very helpful to include the original GATK3 file as the first commit, as you did in this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366271857
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366271857:212,Safety,avoid,avoid,212,"The tutorial data would be an option, except that it covers reference territory not currently in the repo. It looks like that would add nearly 1 gig just for the reference data, which I think we'd really want to avoid. Ideally we'd have just one PR for each of the (two) tools. If you want to keep `ConstrainedMateFixingManager` and `NWaySAMFileWriter` as separate PRs, thats fine, but I don't think we'd take them until we know there is, or will very soon be, code that depends on them. Certainly using `@Experimental` for the tools could make sense, once we're certain that we have a way forward for test coverage. One other note, it's very helpful to include the original GATK3 file as the first commit, as you did in this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366271857
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366271857:602,Testability,test,test,602,"The tutorial data would be an option, except that it covers reference territory not currently in the repo. It looks like that would add nearly 1 gig just for the reference data, which I think we'd really want to avoid. Ideally we'd have just one PR for each of the (two) tools. If you want to keep `ConstrainedMateFixingManager` and `NWaySAMFileWriter` as separate PRs, thats fine, but I don't think we'd take them until we know there is, or will very soon be, code that depends on them. Certainly using `@Experimental` for the tools could make sense, once we're certain that we have a way forward for test coverage. One other note, it's very helpful to include the original GATK3 file as the first commit, as you did in this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-366271857
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371208290:120,Testability,test,test,120,"Sorry, I completely missed this one in the last weeks. I was waiting for your answer (and @sooheelee's):. 1. I need the test data for the public repository if we would like to reproduce the complete test suite that GATK3 has (see my comment above, https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364866520); 1. The tutorial data might be a possibility for the `IndelRealignment` test suite, but it requires the full reference genome (which is huge and not possible to include in the repository, see https://github.com/broadinstitute/gatk/issues/3104#issuecomment-325612165 for more information). @sooheelee might have an idea about the data and if it can be limited to the reference already on the repository (if I am correct, 20 and 21).; 1. This just came out now when I was looking at my port branches, both this and some backup for others part of the code. If the tool is going to be experimental, I would like to know if it is ok to do not have fully featured tools and fill in some issues in the meantime. For example, in this PR the part of the code uncovered by tests is the `known` indels: the main idea is to comment out the code and throw an exception if the argument is specified, saying that it is not supported yet. In the case of `IndelRealignment`, I would like to leave out in the first iteration for the tool the `NWaySAMFileWriter`, to speed up development and add the support for split output later. Once I know this I will close the PR and sent another one with the `RealignmentTargetCreator`. On the other hand, the `IndelRealigner` tool will take a bit longer, because I haven't look at it for the longest time. Thanks for looking into this @cmnbroad!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371208290
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371208290:199,Testability,test,test,199,"Sorry, I completely missed this one in the last weeks. I was waiting for your answer (and @sooheelee's):. 1. I need the test data for the public repository if we would like to reproduce the complete test suite that GATK3 has (see my comment above, https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364866520); 1. The tutorial data might be a possibility for the `IndelRealignment` test suite, but it requires the full reference genome (which is huge and not possible to include in the repository, see https://github.com/broadinstitute/gatk/issues/3104#issuecomment-325612165 for more information). @sooheelee might have an idea about the data and if it can be limited to the reference already on the repository (if I am correct, 20 and 21).; 1. This just came out now when I was looking at my port branches, both this and some backup for others part of the code. If the tool is going to be experimental, I would like to know if it is ok to do not have fully featured tools and fill in some issues in the meantime. For example, in this PR the part of the code uncovered by tests is the `known` indels: the main idea is to comment out the code and throw an exception if the argument is specified, saying that it is not supported yet. In the case of `IndelRealignment`, I would like to leave out in the first iteration for the tool the `NWaySAMFileWriter`, to speed up development and add the support for split output later. Once I know this I will close the PR and sent another one with the `RealignmentTargetCreator`. On the other hand, the `IndelRealigner` tool will take a bit longer, because I haven't look at it for the longest time. Thanks for looking into this @cmnbroad!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371208290
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371208290:393,Testability,test,test,393,"Sorry, I completely missed this one in the last weeks. I was waiting for your answer (and @sooheelee's):. 1. I need the test data for the public repository if we would like to reproduce the complete test suite that GATK3 has (see my comment above, https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364866520); 1. The tutorial data might be a possibility for the `IndelRealignment` test suite, but it requires the full reference genome (which is huge and not possible to include in the repository, see https://github.com/broadinstitute/gatk/issues/3104#issuecomment-325612165 for more information). @sooheelee might have an idea about the data and if it can be limited to the reference already on the repository (if I am correct, 20 and 21).; 1. This just came out now when I was looking at my port branches, both this and some backup for others part of the code. If the tool is going to be experimental, I would like to know if it is ok to do not have fully featured tools and fill in some issues in the meantime. For example, in this PR the part of the code uncovered by tests is the `known` indels: the main idea is to comment out the code and throw an exception if the argument is specified, saying that it is not supported yet. In the case of `IndelRealignment`, I would like to leave out in the first iteration for the tool the `NWaySAMFileWriter`, to speed up development and add the support for split output later. Once I know this I will close the PR and sent another one with the `RealignmentTargetCreator`. On the other hand, the `IndelRealigner` tool will take a bit longer, because I haven't look at it for the longest time. Thanks for looking into this @cmnbroad!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371208290
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371208290:1084,Testability,test,tests,1084,"Sorry, I completely missed this one in the last weeks. I was waiting for your answer (and @sooheelee's):. 1. I need the test data for the public repository if we would like to reproduce the complete test suite that GATK3 has (see my comment above, https://github.com/broadinstitute/gatk/pull/3112#issuecomment-364866520); 1. The tutorial data might be a possibility for the `IndelRealignment` test suite, but it requires the full reference genome (which is huge and not possible to include in the repository, see https://github.com/broadinstitute/gatk/issues/3104#issuecomment-325612165 for more information). @sooheelee might have an idea about the data and if it can be limited to the reference already on the repository (if I am correct, 20 and 21).; 1. This just came out now when I was looking at my port branches, both this and some backup for others part of the code. If the tool is going to be experimental, I would like to know if it is ok to do not have fully featured tools and fill in some issues in the meantime. For example, in this PR the part of the code uncovered by tests is the `known` indels: the main idea is to comment out the code and throw an exception if the argument is specified, saying that it is not supported yet. In the case of `IndelRealignment`, I would like to leave out in the first iteration for the tool the `NWaySAMFileWriter`, to speed up development and add the support for split output later. Once I know this I will close the PR and sent another one with the `RealignmentTargetCreator`. On the other hand, the `IndelRealigner` tool will take a bit longer, because I haven't look at it for the longest time. Thanks for looking into this @cmnbroad!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371208290
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371244790:92,Testability,test,test,92,"@magicDGS I think we covered all of these points earlier in this thread, but both the GATK3 test data and the tutorial data are written against reference(s) we don't have in GATK4, and are much larger than we want to include in the repo. We would need tests that work against one of the references we already have included. See my other comments above regarding `@Experiemtnal`/`@Beta`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371244790
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371244790:252,Testability,test,tests,252,"@magicDGS I think we covered all of these points earlier in this thread, but both the GATK3 test data and the tutorial data are written against reference(s) we don't have in GATK4, and are much larger than we want to include in the repo. We would need tests that work against one of the references we already have included. See my other comments above regarding `@Experiemtnal`/`@Beta`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371244790
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371287334:175,Testability,test,test,175,"@magicDGS I'm just seeing this ticket. Sorry, I've been focused elsewhere, so many tickets come through my inbox, and my main work is mostly not through this repo. I can make test data. . Can you clarify which of hg19 and b37 is represented for which contig (20 or 21) in the repo?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371287334
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371497870:196,Testability,test,tests,196,"Thanks @sooheelee. There are two large-ish reference files in the repo, both of which contain contigs for both 20 and 21: Homo_sapiens_assembly38.20.21.fasta and human_g1k_v37.20.21.fasta. So the tests would need to work against one of those.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371497870
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371499166:265,Availability,avail,available,265,"@cmnbroad could you point me to the relevant tests so I can figure out the various resource files that I assume the tests use in their commands? I want to make sure I get you everything you need, as I may make you a new small reference, given the small data I have available right now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371499166
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371499166:45,Testability,test,tests,45,"@cmnbroad could you point me to the relevant tests so I can figure out the various resource files that I assume the tests use in their commands? I want to make sure I get you everything you need, as I may make you a new small reference, given the small data I have available right now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371499166
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371499166:116,Testability,test,tests,116,"@cmnbroad could you point me to the relevant tests so I can figure out the various resource files that I assume the tests use in their commands? I want to make sure I get you everything you need, as I may make you a new small reference, given the small data I have available right now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371499166
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500028:180,Integrability,depend,depending,180,"Also, it may be prudent for me to run the data through the commands the tests use, as the data I will make comes from an external source and may not validate in its current state, depending on the tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500028
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500028:149,Security,validat,validate,149,"Also, it may be prudent for me to run the data through the commands the tests use, as the data I will make comes from an external source and may not validate in its current state, depending on the tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500028
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500028:72,Testability,test,tests,72,"Also, it may be prudent for me to run the data through the commands the tests use, as the data I will make comes from an external source and may not validate in its current state, depending on the tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500028
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500428:88,Testability,test,tests,88,Sorry for the late answer @sooheelee and thanks for looking into this. I guess that the tests for the two tools that are in the GATK3 code are the ones that we should reproduce (maybe the large scale will be too large):. * https://github.com/broadgsa/gatk/blob/0b73e380436aaa5a41fb3aab97ab651207669f47/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/RealignerTargetCreatorLargeScaleTest.java; * https://github.com/broadgsa/gatk/blob/0b73e380436aaa5a41fb3aab97ab651207669f47/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/RealignerTargetCreatorIntegrationTest.java; * https://github.com/broadgsa/gatk/blob/0b73e380436aaa5a41fb3aab97ab651207669f47/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/IndelRealignerLargeScaleTest.java; * https://github.com/broadgsa/gatk/blob/7f75fa449605851bc84d1da4e77a7cfed489ea33/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/IndelRealignerIntegrationTest.java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500428
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500428:331,Testability,test,test,331,Sorry for the late answer @sooheelee and thanks for looking into this. I guess that the tests for the two tools that are in the GATK3 code are the ones that we should reproduce (maybe the large scale will be too large):. * https://github.com/broadgsa/gatk/blob/0b73e380436aaa5a41fb3aab97ab651207669f47/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/RealignerTargetCreatorLargeScaleTest.java; * https://github.com/broadgsa/gatk/blob/0b73e380436aaa5a41fb3aab97ab651207669f47/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/RealignerTargetCreatorIntegrationTest.java; * https://github.com/broadgsa/gatk/blob/0b73e380436aaa5a41fb3aab97ab651207669f47/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/IndelRealignerLargeScaleTest.java; * https://github.com/broadgsa/gatk/blob/7f75fa449605851bc84d1da4e77a7cfed489ea33/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/IndelRealignerIntegrationTest.java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500428
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500428:539,Testability,test,test,539,Sorry for the late answer @sooheelee and thanks for looking into this. I guess that the tests for the two tools that are in the GATK3 code are the ones that we should reproduce (maybe the large scale will be too large):. * https://github.com/broadgsa/gatk/blob/0b73e380436aaa5a41fb3aab97ab651207669f47/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/RealignerTargetCreatorLargeScaleTest.java; * https://github.com/broadgsa/gatk/blob/0b73e380436aaa5a41fb3aab97ab651207669f47/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/RealignerTargetCreatorIntegrationTest.java; * https://github.com/broadgsa/gatk/blob/0b73e380436aaa5a41fb3aab97ab651207669f47/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/IndelRealignerLargeScaleTest.java; * https://github.com/broadgsa/gatk/blob/7f75fa449605851bc84d1da4e77a7cfed489ea33/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/IndelRealignerIntegrationTest.java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500428
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500428:748,Testability,test,test,748,Sorry for the late answer @sooheelee and thanks for looking into this. I guess that the tests for the two tools that are in the GATK3 code are the ones that we should reproduce (maybe the large scale will be too large):. * https://github.com/broadgsa/gatk/blob/0b73e380436aaa5a41fb3aab97ab651207669f47/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/RealignerTargetCreatorLargeScaleTest.java; * https://github.com/broadgsa/gatk/blob/0b73e380436aaa5a41fb3aab97ab651207669f47/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/RealignerTargetCreatorIntegrationTest.java; * https://github.com/broadgsa/gatk/blob/0b73e380436aaa5a41fb3aab97ab651207669f47/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/IndelRealignerLargeScaleTest.java; * https://github.com/broadgsa/gatk/blob/7f75fa449605851bc84d1da4e77a7cfed489ea33/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/IndelRealignerIntegrationTest.java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500428
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500428:948,Testability,test,test,948,Sorry for the late answer @sooheelee and thanks for looking into this. I guess that the tests for the two tools that are in the GATK3 code are the ones that we should reproduce (maybe the large scale will be too large):. * https://github.com/broadgsa/gatk/blob/0b73e380436aaa5a41fb3aab97ab651207669f47/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/RealignerTargetCreatorLargeScaleTest.java; * https://github.com/broadgsa/gatk/blob/0b73e380436aaa5a41fb3aab97ab651207669f47/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/RealignerTargetCreatorIntegrationTest.java; * https://github.com/broadgsa/gatk/blob/0b73e380436aaa5a41fb3aab97ab651207669f47/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/IndelRealignerLargeScaleTest.java; * https://github.com/broadgsa/gatk/blob/7f75fa449605851bc84d1da4e77a7cfed489ea33/public/gatk-tools-public/src/test/java/org/broadinstitute/gatk/tools/walkers/indels/IndelRealignerIntegrationTest.java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371500428
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371501208:265,Testability,test,tests,265,"@magicDGS We'd definitely prefer to not take partially developed versions of either of these tools (or @Experimental or @Beta versions). We should aim to have either a single PR with everything, or two PRs, one for each tool, with complete functionality, including tests and test data, rather than an ongoing stream of partial PRs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371501208
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371501208:275,Testability,test,test,275,"@magicDGS We'd definitely prefer to not take partially developed versions of either of these tools (or @Experimental or @Beta versions). We should aim to have either a single PR with everything, or two PRs, one for each tool, with complete functionality, including tests and test data, rather than an ongoing stream of partial PRs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371501208
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371501418:66,Testability,test,test,66,"@sooheelee - the main idea is to run both tools with GATK3 on the test data, and then check if the port provides the same answer. Thanks a lot @cmnbroad and @sooheelee to look into this. I will try to make today a new PR for `RealignerTargetCreator` and start the work from scratch for `IndelRealignment` (it will take a bit longer, although without some support it might be actually a bit lighter too).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371501418
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371506127:74,Security,validat,validation,74,"@magicDGS I glanced at the tests and it appears there may be a scientific validation component, which I am unfamiliar with (I'm in an intro to Java course currently). Is this the case? If scientific validation is needed, then it is best to involve someone familiar with validation, e.g. Laura or Yossi. If all you need is data that can be run through these commands, I can put this together. Let me know. I'm late to these efforts, but I'd like to check one thing. Because of the way GRCh38 contigs are parsed, e.g. the HLAs that contain colons in their names, I believe we now prefer Picard-style intervals lists that tab-separate values instead of the `10:96000399-96000421` format that RealignerTargetCreator produces. I'm not certain of the status of GATK-style intervals lists, but I do know that the CNV developers have swiched to Picard-style. Is this what is produced by the new RealignerTargetCreator?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371506127
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371506127:199,Security,validat,validation,199,"@magicDGS I glanced at the tests and it appears there may be a scientific validation component, which I am unfamiliar with (I'm in an intro to Java course currently). Is this the case? If scientific validation is needed, then it is best to involve someone familiar with validation, e.g. Laura or Yossi. If all you need is data that can be run through these commands, I can put this together. Let me know. I'm late to these efforts, but I'd like to check one thing. Because of the way GRCh38 contigs are parsed, e.g. the HLAs that contain colons in their names, I believe we now prefer Picard-style intervals lists that tab-separate values instead of the `10:96000399-96000421` format that RealignerTargetCreator produces. I'm not certain of the status of GATK-style intervals lists, but I do know that the CNV developers have swiched to Picard-style. Is this what is produced by the new RealignerTargetCreator?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371506127
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371506127:270,Security,validat,validation,270,"@magicDGS I glanced at the tests and it appears there may be a scientific validation component, which I am unfamiliar with (I'm in an intro to Java course currently). Is this the case? If scientific validation is needed, then it is best to involve someone familiar with validation, e.g. Laura or Yossi. If all you need is data that can be run through these commands, I can put this together. Let me know. I'm late to these efforts, but I'd like to check one thing. Because of the way GRCh38 contigs are parsed, e.g. the HLAs that contain colons in their names, I believe we now prefer Picard-style intervals lists that tab-separate values instead of the `10:96000399-96000421` format that RealignerTargetCreator produces. I'm not certain of the status of GATK-style intervals lists, but I do know that the CNV developers have swiched to Picard-style. Is this what is produced by the new RealignerTargetCreator?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371506127
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371506127:27,Testability,test,tests,27,"@magicDGS I glanced at the tests and it appears there may be a scientific validation component, which I am unfamiliar with (I'm in an intro to Java course currently). Is this the case? If scientific validation is needed, then it is best to involve someone familiar with validation, e.g. Laura or Yossi. If all you need is data that can be run through these commands, I can put this together. Let me know. I'm late to these efforts, but I'd like to check one thing. Because of the way GRCh38 contigs are parsed, e.g. the HLAs that contain colons in their names, I believe we now prefer Picard-style intervals lists that tab-separate values instead of the `10:96000399-96000421` format that RealignerTargetCreator produces. I'm not certain of the status of GATK-style intervals lists, but I do know that the CNV developers have swiched to Picard-style. Is this what is produced by the new RealignerTargetCreator?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371506127
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115:2221,Availability,avail,available,2221,"ot sure if that was already covered. @sooheelee - this is going to be an exact port of the indel-realignment pipeline, as it is in the GATK3 code, so that means that I won't modify the interval list format or anything (although I will use the HTSJDK/Picard classes as used on GATK3). Because this will be an experimental/beta feature, I think that I can have a look to the new format after acceptance of the original port. @cmnbroad - I understand that a fully functional tool is a requirement for acceptance, but what I mean is that some specific features might require more work than others. I am only concerned about the `NWaySAMFileWriter`, which is just an specific way of output the data but does not add anything to the real realignment process (actually, I think that I've never heard about anyone around me using it). That is a nice feature, but I don't think that it is a high-priority - I care more about having the algorithm implemented to test if the actual processing of the data works, and add support for some way of output the data in a different PR. In addition, if the people still using indel-realignment does not require the n-way output, then it is pointless to spend time on it. I was also thinking about the mate-fixing algorithm in the tool, because it can be performed afterwards with Picard, which is not constraining by any distance between reads or records in RAM - nevertheless, this is really a drop of functionality that will change results, and that's why I didn't propose that. About the target-creator, known indels are really easy to port because the code is within the tool and is simpler - the only problem might be code coverage if there is no data for known indels. I will propose very soon two PRs with fully functional tools (without the n-way out feature for indel-realignment), and trying to add simple integration tests with the data already available on the repository and running with GATK3.8-1. If that is OK for you, I will proceed with this approach.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115:443,Deployability,pipeline,pipeline,443,"@sooheelee - I think that to have a proper test suite similar to GATK's 3, we need also some test that exercise some code paths that requires some specific scientifically meaningful data (for example, known indels that are also included in some sample). I am not that familiar with the test data on this or GATK3 repository, so I am not sure if that was already covered. @sooheelee - this is going to be an exact port of the indel-realignment pipeline, as it is in the GATK3 code, so that means that I won't modify the interval list format or anything (although I will use the HTSJDK/Picard classes as used on GATK3). Because this will be an experimental/beta feature, I think that I can have a look to the new format after acceptance of the original port. @cmnbroad - I understand that a fully functional tool is a requirement for acceptance, but what I mean is that some specific features might require more work than others. I am only concerned about the `NWaySAMFileWriter`, which is just an specific way of output the data but does not add anything to the real realignment process (actually, I think that I've never heard about anyone around me using it). That is a nice feature, but I don't think that it is a high-priority - I care more about having the algorithm implemented to test if the actual processing of the data works, and add support for some way of output the data in a different PR. In addition, if the people still using indel-realignment does not require the n-way output, then it is pointless to spend time on it. I was also thinking about the mate-fixing algorithm in the tool, because it can be performed afterwards with Picard, which is not constraining by any distance between reads or records in RAM - nevertheless, this is really a drop of functionality that will change results, and that's why I didn't propose that. About the target-creator, known indels are really easy to port because the code is within the tool and is simpler - the only problem might be code coverage",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115:2181,Deployability,integrat,integration,2181,"ot sure if that was already covered. @sooheelee - this is going to be an exact port of the indel-realignment pipeline, as it is in the GATK3 code, so that means that I won't modify the interval list format or anything (although I will use the HTSJDK/Picard classes as used on GATK3). Because this will be an experimental/beta feature, I think that I can have a look to the new format after acceptance of the original port. @cmnbroad - I understand that a fully functional tool is a requirement for acceptance, but what I mean is that some specific features might require more work than others. I am only concerned about the `NWaySAMFileWriter`, which is just an specific way of output the data but does not add anything to the real realignment process (actually, I think that I've never heard about anyone around me using it). That is a nice feature, but I don't think that it is a high-priority - I care more about having the algorithm implemented to test if the actual processing of the data works, and add support for some way of output the data in a different PR. In addition, if the people still using indel-realignment does not require the n-way output, then it is pointless to spend time on it. I was also thinking about the mate-fixing algorithm in the tool, because it can be performed afterwards with Picard, which is not constraining by any distance between reads or records in RAM - nevertheless, this is really a drop of functionality that will change results, and that's why I didn't propose that. About the target-creator, known indels are really easy to port because the code is within the tool and is simpler - the only problem might be code coverage if there is no data for known indels. I will propose very soon two PRs with fully functional tools (without the n-way out feature for indel-realignment), and trying to add simple integration tests with the data already available on the repository and running with GATK3.8-1. If that is OK for you, I will proceed with this approach.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115:2181,Integrability,integrat,integration,2181,"ot sure if that was already covered. @sooheelee - this is going to be an exact port of the indel-realignment pipeline, as it is in the GATK3 code, so that means that I won't modify the interval list format or anything (although I will use the HTSJDK/Picard classes as used on GATK3). Because this will be an experimental/beta feature, I think that I can have a look to the new format after acceptance of the original port. @cmnbroad - I understand that a fully functional tool is a requirement for acceptance, but what I mean is that some specific features might require more work than others. I am only concerned about the `NWaySAMFileWriter`, which is just an specific way of output the data but does not add anything to the real realignment process (actually, I think that I've never heard about anyone around me using it). That is a nice feature, but I don't think that it is a high-priority - I care more about having the algorithm implemented to test if the actual processing of the data works, and add support for some way of output the data in a different PR. In addition, if the people still using indel-realignment does not require the n-way output, then it is pointless to spend time on it. I was also thinking about the mate-fixing algorithm in the tool, because it can be performed afterwards with Picard, which is not constraining by any distance between reads or records in RAM - nevertheless, this is really a drop of functionality that will change results, and that's why I didn't propose that. About the target-creator, known indels are really easy to port because the code is within the tool and is simpler - the only problem might be code coverage if there is no data for known indels. I will propose very soon two PRs with fully functional tools (without the n-way out feature for indel-realignment), and trying to add simple integration tests with the data already available on the repository and running with GATK3.8-1. If that is OK for you, I will proceed with this approach.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115:1619,Performance,perform,performed,1619,"ot sure if that was already covered. @sooheelee - this is going to be an exact port of the indel-realignment pipeline, as it is in the GATK3 code, so that means that I won't modify the interval list format or anything (although I will use the HTSJDK/Picard classes as used on GATK3). Because this will be an experimental/beta feature, I think that I can have a look to the new format after acceptance of the original port. @cmnbroad - I understand that a fully functional tool is a requirement for acceptance, but what I mean is that some specific features might require more work than others. I am only concerned about the `NWaySAMFileWriter`, which is just an specific way of output the data but does not add anything to the real realignment process (actually, I think that I've never heard about anyone around me using it). That is a nice feature, but I don't think that it is a high-priority - I care more about having the algorithm implemented to test if the actual processing of the data works, and add support for some way of output the data in a different PR. In addition, if the people still using indel-realignment does not require the n-way output, then it is pointless to spend time on it. I was also thinking about the mate-fixing algorithm in the tool, because it can be performed afterwards with Picard, which is not constraining by any distance between reads or records in RAM - nevertheless, this is really a drop of functionality that will change results, and that's why I didn't propose that. About the target-creator, known indels are really easy to port because the code is within the tool and is simpler - the only problem might be code coverage if there is no data for known indels. I will propose very soon two PRs with fully functional tools (without the n-way out feature for indel-realignment), and trying to add simple integration tests with the data already available on the repository and running with GATK3.8-1. If that is OK for you, I will proceed with this approach.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115:43,Testability,test,test,43,"@sooheelee - I think that to have a proper test suite similar to GATK's 3, we need also some test that exercise some code paths that requires some specific scientifically meaningful data (for example, known indels that are also included in some sample). I am not that familiar with the test data on this or GATK3 repository, so I am not sure if that was already covered. @sooheelee - this is going to be an exact port of the indel-realignment pipeline, as it is in the GATK3 code, so that means that I won't modify the interval list format or anything (although I will use the HTSJDK/Picard classes as used on GATK3). Because this will be an experimental/beta feature, I think that I can have a look to the new format after acceptance of the original port. @cmnbroad - I understand that a fully functional tool is a requirement for acceptance, but what I mean is that some specific features might require more work than others. I am only concerned about the `NWaySAMFileWriter`, which is just an specific way of output the data but does not add anything to the real realignment process (actually, I think that I've never heard about anyone around me using it). That is a nice feature, but I don't think that it is a high-priority - I care more about having the algorithm implemented to test if the actual processing of the data works, and add support for some way of output the data in a different PR. In addition, if the people still using indel-realignment does not require the n-way output, then it is pointless to spend time on it. I was also thinking about the mate-fixing algorithm in the tool, because it can be performed afterwards with Picard, which is not constraining by any distance between reads or records in RAM - nevertheless, this is really a drop of functionality that will change results, and that's why I didn't propose that. About the target-creator, known indels are really easy to port because the code is within the tool and is simpler - the only problem might be code coverage",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115:93,Testability,test,test,93,"@sooheelee - I think that to have a proper test suite similar to GATK's 3, we need also some test that exercise some code paths that requires some specific scientifically meaningful data (for example, known indels that are also included in some sample). I am not that familiar with the test data on this or GATK3 repository, so I am not sure if that was already covered. @sooheelee - this is going to be an exact port of the indel-realignment pipeline, as it is in the GATK3 code, so that means that I won't modify the interval list format or anything (although I will use the HTSJDK/Picard classes as used on GATK3). Because this will be an experimental/beta feature, I think that I can have a look to the new format after acceptance of the original port. @cmnbroad - I understand that a fully functional tool is a requirement for acceptance, but what I mean is that some specific features might require more work than others. I am only concerned about the `NWaySAMFileWriter`, which is just an specific way of output the data but does not add anything to the real realignment process (actually, I think that I've never heard about anyone around me using it). That is a nice feature, but I don't think that it is a high-priority - I care more about having the algorithm implemented to test if the actual processing of the data works, and add support for some way of output the data in a different PR. In addition, if the people still using indel-realignment does not require the n-way output, then it is pointless to spend time on it. I was also thinking about the mate-fixing algorithm in the tool, because it can be performed afterwards with Picard, which is not constraining by any distance between reads or records in RAM - nevertheless, this is really a drop of functionality that will change results, and that's why I didn't propose that. About the target-creator, known indels are really easy to port because the code is within the tool and is simpler - the only problem might be code coverage",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115:286,Testability,test,test,286,"@sooheelee - I think that to have a proper test suite similar to GATK's 3, we need also some test that exercise some code paths that requires some specific scientifically meaningful data (for example, known indels that are also included in some sample). I am not that familiar with the test data on this or GATK3 repository, so I am not sure if that was already covered. @sooheelee - this is going to be an exact port of the indel-realignment pipeline, as it is in the GATK3 code, so that means that I won't modify the interval list format or anything (although I will use the HTSJDK/Picard classes as used on GATK3). Because this will be an experimental/beta feature, I think that I can have a look to the new format after acceptance of the original port. @cmnbroad - I understand that a fully functional tool is a requirement for acceptance, but what I mean is that some specific features might require more work than others. I am only concerned about the `NWaySAMFileWriter`, which is just an specific way of output the data but does not add anything to the real realignment process (actually, I think that I've never heard about anyone around me using it). That is a nice feature, but I don't think that it is a high-priority - I care more about having the algorithm implemented to test if the actual processing of the data works, and add support for some way of output the data in a different PR. In addition, if the people still using indel-realignment does not require the n-way output, then it is pointless to spend time on it. I was also thinking about the mate-fixing algorithm in the tool, because it can be performed afterwards with Picard, which is not constraining by any distance between reads or records in RAM - nevertheless, this is really a drop of functionality that will change results, and that's why I didn't propose that. About the target-creator, known indels are really easy to port because the code is within the tool and is simpler - the only problem might be code coverage",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115:1286,Testability,test,test,1286,"h the test data on this or GATK3 repository, so I am not sure if that was already covered. @sooheelee - this is going to be an exact port of the indel-realignment pipeline, as it is in the GATK3 code, so that means that I won't modify the interval list format or anything (although I will use the HTSJDK/Picard classes as used on GATK3). Because this will be an experimental/beta feature, I think that I can have a look to the new format after acceptance of the original port. @cmnbroad - I understand that a fully functional tool is a requirement for acceptance, but what I mean is that some specific features might require more work than others. I am only concerned about the `NWaySAMFileWriter`, which is just an specific way of output the data but does not add anything to the real realignment process (actually, I think that I've never heard about anyone around me using it). That is a nice feature, but I don't think that it is a high-priority - I care more about having the algorithm implemented to test if the actual processing of the data works, and add support for some way of output the data in a different PR. In addition, if the people still using indel-realignment does not require the n-way output, then it is pointless to spend time on it. I was also thinking about the mate-fixing algorithm in the tool, because it can be performed afterwards with Picard, which is not constraining by any distance between reads or records in RAM - nevertheless, this is really a drop of functionality that will change results, and that's why I didn't propose that. About the target-creator, known indels are really easy to port because the code is within the tool and is simpler - the only problem might be code coverage if there is no data for known indels. I will propose very soon two PRs with fully functional tools (without the n-way out feature for indel-realignment), and trying to add simple integration tests with the data already available on the repository and running with GATK3.8-1. If t",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115:2193,Testability,test,tests,2193,"ot sure if that was already covered. @sooheelee - this is going to be an exact port of the indel-realignment pipeline, as it is in the GATK3 code, so that means that I won't modify the interval list format or anything (although I will use the HTSJDK/Picard classes as used on GATK3). Because this will be an experimental/beta feature, I think that I can have a look to the new format after acceptance of the original port. @cmnbroad - I understand that a fully functional tool is a requirement for acceptance, but what I mean is that some specific features might require more work than others. I am only concerned about the `NWaySAMFileWriter`, which is just an specific way of output the data but does not add anything to the real realignment process (actually, I think that I've never heard about anyone around me using it). That is a nice feature, but I don't think that it is a high-priority - I care more about having the algorithm implemented to test if the actual processing of the data works, and add support for some way of output the data in a different PR. In addition, if the people still using indel-realignment does not require the n-way output, then it is pointless to spend time on it. I was also thinking about the mate-fixing algorithm in the tool, because it can be performed afterwards with Picard, which is not constraining by any distance between reads or records in RAM - nevertheless, this is really a drop of functionality that will change results, and that's why I didn't propose that. About the target-creator, known indels are really easy to port because the code is within the tool and is simpler - the only problem might be code coverage if there is no data for known indels. I will propose very soon two PRs with fully functional tools (without the n-way out feature for indel-realignment), and trying to add simple integration tests with the data already available on the repository and running with GATK3.8-1. If that is OK for you, I will proceed with this approach.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115:1952,Usability,simpl,simpler,1952,"ot sure if that was already covered. @sooheelee - this is going to be an exact port of the indel-realignment pipeline, as it is in the GATK3 code, so that means that I won't modify the interval list format or anything (although I will use the HTSJDK/Picard classes as used on GATK3). Because this will be an experimental/beta feature, I think that I can have a look to the new format after acceptance of the original port. @cmnbroad - I understand that a fully functional tool is a requirement for acceptance, but what I mean is that some specific features might require more work than others. I am only concerned about the `NWaySAMFileWriter`, which is just an specific way of output the data but does not add anything to the real realignment process (actually, I think that I've never heard about anyone around me using it). That is a nice feature, but I don't think that it is a high-priority - I care more about having the algorithm implemented to test if the actual processing of the data works, and add support for some way of output the data in a different PR. In addition, if the people still using indel-realignment does not require the n-way output, then it is pointless to spend time on it. I was also thinking about the mate-fixing algorithm in the tool, because it can be performed afterwards with Picard, which is not constraining by any distance between reads or records in RAM - nevertheless, this is really a drop of functionality that will change results, and that's why I didn't propose that. About the target-creator, known indels are really easy to port because the code is within the tool and is simpler - the only problem might be code coverage if there is no data for known indels. I will propose very soon two PRs with fully functional tools (without the n-way out feature for indel-realignment), and trying to add simple integration tests with the data already available on the repository and running with GATK3.8-1. If that is OK for you, I will proceed with this approach.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115:2174,Usability,simpl,simple,2174,"ot sure if that was already covered. @sooheelee - this is going to be an exact port of the indel-realignment pipeline, as it is in the GATK3 code, so that means that I won't modify the interval list format or anything (although I will use the HTSJDK/Picard classes as used on GATK3). Because this will be an experimental/beta feature, I think that I can have a look to the new format after acceptance of the original port. @cmnbroad - I understand that a fully functional tool is a requirement for acceptance, but what I mean is that some specific features might require more work than others. I am only concerned about the `NWaySAMFileWriter`, which is just an specific way of output the data but does not add anything to the real realignment process (actually, I think that I've never heard about anyone around me using it). That is a nice feature, but I don't think that it is a high-priority - I care more about having the algorithm implemented to test if the actual processing of the data works, and add support for some way of output the data in a different PR. In addition, if the people still using indel-realignment does not require the n-way output, then it is pointless to spend time on it. I was also thinking about the mate-fixing algorithm in the tool, because it can be performed afterwards with Picard, which is not constraining by any distance between reads or records in RAM - nevertheless, this is really a drop of functionality that will change results, and that's why I didn't propose that. About the target-creator, known indels are really easy to port because the code is within the tool and is simpler - the only problem might be code coverage if there is no data for known indels. I will propose very soon two PRs with fully functional tools (without the n-way out feature for indel-realignment), and trying to add simple integration tests with the data already available on the repository and running with GATK3.8-1. If that is OK for you, I will proceed with this approach.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371515115
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371519632:277,Security,validat,validate,277,"Thanks for the clarification @magicDGS. What I have are 1000 Genomes Project BAMs, which were preprocessed by the 1000 Genomes Project. The BAMs are aligned to GRCh38 and have undergone indel realignment (GATK3), so they represent a state of preprocessing against which we can validate the new indel realignment. If some representation of indels in such a BAM is sufficient as a truthset, then I can make this VCF. These samples, being from the 1000 Genomes Project, are well-analyzed and their indels will be represented in dbSNP and gnomAD resources. Of course, the test data will have been re-mapped with BWA and be without any trace of indel realignment. We should probably get someone familiar with the test suite to weigh in on the scope of the validation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371519632
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371519632:751,Security,validat,validation,751,"Thanks for the clarification @magicDGS. What I have are 1000 Genomes Project BAMs, which were preprocessed by the 1000 Genomes Project. The BAMs are aligned to GRCh38 and have undergone indel realignment (GATK3), so they represent a state of preprocessing against which we can validate the new indel realignment. If some representation of indels in such a BAM is sufficient as a truthset, then I can make this VCF. These samples, being from the 1000 Genomes Project, are well-analyzed and their indels will be represented in dbSNP and gnomAD resources. Of course, the test data will have been re-mapped with BWA and be without any trace of indel realignment. We should probably get someone familiar with the test suite to weigh in on the scope of the validation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371519632
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371519632:568,Testability,test,test,568,"Thanks for the clarification @magicDGS. What I have are 1000 Genomes Project BAMs, which were preprocessed by the 1000 Genomes Project. The BAMs are aligned to GRCh38 and have undergone indel realignment (GATK3), so they represent a state of preprocessing against which we can validate the new indel realignment. If some representation of indels in such a BAM is sufficient as a truthset, then I can make this VCF. These samples, being from the 1000 Genomes Project, are well-analyzed and their indels will be represented in dbSNP and gnomAD resources. Of course, the test data will have been re-mapped with BWA and be without any trace of indel realignment. We should probably get someone familiar with the test suite to weigh in on the scope of the validation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371519632
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371519632:708,Testability,test,test,708,"Thanks for the clarification @magicDGS. What I have are 1000 Genomes Project BAMs, which were preprocessed by the 1000 Genomes Project. The BAMs are aligned to GRCh38 and have undergone indel realignment (GATK3), so they represent a state of preprocessing against which we can validate the new indel realignment. If some representation of indels in such a BAM is sufficient as a truthset, then I can make this VCF. These samples, being from the 1000 Genomes Project, are well-analyzed and their indels will be represented in dbSNP and gnomAD resources. Of course, the test data will have been re-mapped with BWA and be without any trace of indel realignment. We should probably get someone familiar with the test suite to weigh in on the scope of the validation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371519632
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371528161:447,Safety,detect,detect,447,"@sooheelee I can't speak for CNV, but there isn't any general reason to prefer Picard interval lists in GATK. There was previously an issue with parsing interval queries that used contig names that contained "":"", but thats fixed now. The only time we prefer a Picard list is the theoretical case were you use a query interval against a sequence dictionary that contains contigs that make that query ambiguous (hg38 is not one of those). GATK will detect and reject such a query and suggest using a Picard interval file to disambiguate it. @magicDGS I'm not sure how/if writing tests against existing files in the repository will be useful. I want to restate that we don't want to take ports of these tools if they're marked `@Experimental `or `@Beta` because they haven't been validated, or don't have good test coverage. We need to find a way need to have valid tests so they'll be production ready.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371528161
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371528161:777,Security,validat,validated,777,"@sooheelee I can't speak for CNV, but there isn't any general reason to prefer Picard interval lists in GATK. There was previously an issue with parsing interval queries that used contig names that contained "":"", but thats fixed now. The only time we prefer a Picard list is the theoretical case were you use a query interval against a sequence dictionary that contains contigs that make that query ambiguous (hg38 is not one of those). GATK will detect and reject such a query and suggest using a Picard interval file to disambiguate it. @magicDGS I'm not sure how/if writing tests against existing files in the repository will be useful. I want to restate that we don't want to take ports of these tools if they're marked `@Experimental `or `@Beta` because they haven't been validated, or don't have good test coverage. We need to find a way need to have valid tests so they'll be production ready.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371528161
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371528161:577,Testability,test,tests,577,"@sooheelee I can't speak for CNV, but there isn't any general reason to prefer Picard interval lists in GATK. There was previously an issue with parsing interval queries that used contig names that contained "":"", but thats fixed now. The only time we prefer a Picard list is the theoretical case were you use a query interval against a sequence dictionary that contains contigs that make that query ambiguous (hg38 is not one of those). GATK will detect and reject such a query and suggest using a Picard interval file to disambiguate it. @magicDGS I'm not sure how/if writing tests against existing files in the repository will be useful. I want to restate that we don't want to take ports of these tools if they're marked `@Experimental `or `@Beta` because they haven't been validated, or don't have good test coverage. We need to find a way need to have valid tests so they'll be production ready.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371528161
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371528161:807,Testability,test,test,807,"@sooheelee I can't speak for CNV, but there isn't any general reason to prefer Picard interval lists in GATK. There was previously an issue with parsing interval queries that used contig names that contained "":"", but thats fixed now. The only time we prefer a Picard list is the theoretical case were you use a query interval against a sequence dictionary that contains contigs that make that query ambiguous (hg38 is not one of those). GATK will detect and reject such a query and suggest using a Picard interval file to disambiguate it. @magicDGS I'm not sure how/if writing tests against existing files in the repository will be useful. I want to restate that we don't want to take ports of these tools if they're marked `@Experimental `or `@Beta` because they haven't been validated, or don't have good test coverage. We need to find a way need to have valid tests so they'll be production ready.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371528161
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371528161:863,Testability,test,tests,863,"@sooheelee I can't speak for CNV, but there isn't any general reason to prefer Picard interval lists in GATK. There was previously an issue with parsing interval queries that used contig names that contained "":"", but thats fixed now. The only time we prefer a Picard list is the theoretical case were you use a query interval against a sequence dictionary that contains contigs that make that query ambiguous (hg38 is not one of those). GATK will detect and reject such a query and suggest using a Picard interval file to disambiguate it. @magicDGS I'm not sure how/if writing tests against existing files in the repository will be useful. I want to restate that we don't want to take ports of these tools if they're marked `@Experimental `or `@Beta` because they haven't been validated, or don't have good test coverage. We need to find a way need to have valid tests so they'll be production ready.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371528161
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774:165,Availability,fault,fault,165,"Sorry @cmnbroad, I misunderstood your comment before - what I've got is that it is ok to have beta/experimental for this, but it's obviosly not what you said, so my fault for not reading carefully. In that case, I would like to have a proposal for how to proceed here:. * I will implement the port for the tools in two independent PRs - just direct translation into the new framework, documentation and kebab-case argument style.; * The port for `RealignerTargetCreator` will be similar to this one; * The port for `IndelRealigner` would not have support for n-way output, although it will be fully functional in other ways. The n-way option can be ported in the future as an extra feature if necessary (maybe the communications team can weight in, and tell if it is really a needed feature); * For the first test, which will be removed before merging, I will use the data from the tutorial. This will be the validation for the port before test data valid for the repository is provided; * For the final tests, I will draft the class with the tests from GAKT3 without the data and disabled, waiting for @sooheelee for meaningful tests (or other people from your team). The main idea is to have two PRs with the port validated with the tutorial data, and add other tests similar to the GATK3's ones for extra validation and/or covering missing codepaths using @sooheelee or ported GATK3 data. Does it makes sense, @cmnbroad and @sooheelee?. @sooheelee - I think that the 1000G data can be a good validation if chromosomes 20/21 have realigned reads without a pair mapping on other chromosomes. In that case, some of that reads can be extracted and reset to the state previous to realignment to validate the new tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774:909,Security,validat,validation,909,"Sorry @cmnbroad, I misunderstood your comment before - what I've got is that it is ok to have beta/experimental for this, but it's obviosly not what you said, so my fault for not reading carefully. In that case, I would like to have a proposal for how to proceed here:. * I will implement the port for the tools in two independent PRs - just direct translation into the new framework, documentation and kebab-case argument style.; * The port for `RealignerTargetCreator` will be similar to this one; * The port for `IndelRealigner` would not have support for n-way output, although it will be fully functional in other ways. The n-way option can be ported in the future as an extra feature if necessary (maybe the communications team can weight in, and tell if it is really a needed feature); * For the first test, which will be removed before merging, I will use the data from the tutorial. This will be the validation for the port before test data valid for the repository is provided; * For the final tests, I will draft the class with the tests from GAKT3 without the data and disabled, waiting for @sooheelee for meaningful tests (or other people from your team). The main idea is to have two PRs with the port validated with the tutorial data, and add other tests similar to the GATK3's ones for extra validation and/or covering missing codepaths using @sooheelee or ported GATK3 data. Does it makes sense, @cmnbroad and @sooheelee?. @sooheelee - I think that the 1000G data can be a good validation if chromosomes 20/21 have realigned reads without a pair mapping on other chromosomes. In that case, some of that reads can be extracted and reset to the state previous to realignment to validate the new tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774:1216,Security,validat,validated,1216,"Sorry @cmnbroad, I misunderstood your comment before - what I've got is that it is ok to have beta/experimental for this, but it's obviosly not what you said, so my fault for not reading carefully. In that case, I would like to have a proposal for how to proceed here:. * I will implement the port for the tools in two independent PRs - just direct translation into the new framework, documentation and kebab-case argument style.; * The port for `RealignerTargetCreator` will be similar to this one; * The port for `IndelRealigner` would not have support for n-way output, although it will be fully functional in other ways. The n-way option can be ported in the future as an extra feature if necessary (maybe the communications team can weight in, and tell if it is really a needed feature); * For the first test, which will be removed before merging, I will use the data from the tutorial. This will be the validation for the port before test data valid for the repository is provided; * For the final tests, I will draft the class with the tests from GAKT3 without the data and disabled, waiting for @sooheelee for meaningful tests (or other people from your team). The main idea is to have two PRs with the port validated with the tutorial data, and add other tests similar to the GATK3's ones for extra validation and/or covering missing codepaths using @sooheelee or ported GATK3 data. Does it makes sense, @cmnbroad and @sooheelee?. @sooheelee - I think that the 1000G data can be a good validation if chromosomes 20/21 have realigned reads without a pair mapping on other chromosomes. In that case, some of that reads can be extracted and reset to the state previous to realignment to validate the new tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774:1308,Security,validat,validation,1308,"Sorry @cmnbroad, I misunderstood your comment before - what I've got is that it is ok to have beta/experimental for this, but it's obviosly not what you said, so my fault for not reading carefully. In that case, I would like to have a proposal for how to proceed here:. * I will implement the port for the tools in two independent PRs - just direct translation into the new framework, documentation and kebab-case argument style.; * The port for `RealignerTargetCreator` will be similar to this one; * The port for `IndelRealigner` would not have support for n-way output, although it will be fully functional in other ways. The n-way option can be ported in the future as an extra feature if necessary (maybe the communications team can weight in, and tell if it is really a needed feature); * For the first test, which will be removed before merging, I will use the data from the tutorial. This will be the validation for the port before test data valid for the repository is provided; * For the final tests, I will draft the class with the tests from GAKT3 without the data and disabled, waiting for @sooheelee for meaningful tests (or other people from your team). The main idea is to have two PRs with the port validated with the tutorial data, and add other tests similar to the GATK3's ones for extra validation and/or covering missing codepaths using @sooheelee or ported GATK3 data. Does it makes sense, @cmnbroad and @sooheelee?. @sooheelee - I think that the 1000G data can be a good validation if chromosomes 20/21 have realigned reads without a pair mapping on other chromosomes. In that case, some of that reads can be extracted and reset to the state previous to realignment to validate the new tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774:1495,Security,validat,validation,1495,"Sorry @cmnbroad, I misunderstood your comment before - what I've got is that it is ok to have beta/experimental for this, but it's obviosly not what you said, so my fault for not reading carefully. In that case, I would like to have a proposal for how to proceed here:. * I will implement the port for the tools in two independent PRs - just direct translation into the new framework, documentation and kebab-case argument style.; * The port for `RealignerTargetCreator` will be similar to this one; * The port for `IndelRealigner` would not have support for n-way output, although it will be fully functional in other ways. The n-way option can be ported in the future as an extra feature if necessary (maybe the communications team can weight in, and tell if it is really a needed feature); * For the first test, which will be removed before merging, I will use the data from the tutorial. This will be the validation for the port before test data valid for the repository is provided; * For the final tests, I will draft the class with the tests from GAKT3 without the data and disabled, waiting for @sooheelee for meaningful tests (or other people from your team). The main idea is to have two PRs with the port validated with the tutorial data, and add other tests similar to the GATK3's ones for extra validation and/or covering missing codepaths using @sooheelee or ported GATK3 data. Does it makes sense, @cmnbroad and @sooheelee?. @sooheelee - I think that the 1000G data can be a good validation if chromosomes 20/21 have realigned reads without a pair mapping on other chromosomes. In that case, some of that reads can be extracted and reset to the state previous to realignment to validate the new tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774:1693,Security,validat,validate,1693,"Sorry @cmnbroad, I misunderstood your comment before - what I've got is that it is ok to have beta/experimental for this, but it's obviosly not what you said, so my fault for not reading carefully. In that case, I would like to have a proposal for how to proceed here:. * I will implement the port for the tools in two independent PRs - just direct translation into the new framework, documentation and kebab-case argument style.; * The port for `RealignerTargetCreator` will be similar to this one; * The port for `IndelRealigner` would not have support for n-way output, although it will be fully functional in other ways. The n-way option can be ported in the future as an extra feature if necessary (maybe the communications team can weight in, and tell if it is really a needed feature); * For the first test, which will be removed before merging, I will use the data from the tutorial. This will be the validation for the port before test data valid for the repository is provided; * For the final tests, I will draft the class with the tests from GAKT3 without the data and disabled, waiting for @sooheelee for meaningful tests (or other people from your team). The main idea is to have two PRs with the port validated with the tutorial data, and add other tests similar to the GATK3's ones for extra validation and/or covering missing codepaths using @sooheelee or ported GATK3 data. Does it makes sense, @cmnbroad and @sooheelee?. @sooheelee - I think that the 1000G data can be a good validation if chromosomes 20/21 have realigned reads without a pair mapping on other chromosomes. In that case, some of that reads can be extracted and reset to the state previous to realignment to validate the new tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774:809,Testability,test,test,809,"Sorry @cmnbroad, I misunderstood your comment before - what I've got is that it is ok to have beta/experimental for this, but it's obviosly not what you said, so my fault for not reading carefully. In that case, I would like to have a proposal for how to proceed here:. * I will implement the port for the tools in two independent PRs - just direct translation into the new framework, documentation and kebab-case argument style.; * The port for `RealignerTargetCreator` will be similar to this one; * The port for `IndelRealigner` would not have support for n-way output, although it will be fully functional in other ways. The n-way option can be ported in the future as an extra feature if necessary (maybe the communications team can weight in, and tell if it is really a needed feature); * For the first test, which will be removed before merging, I will use the data from the tutorial. This will be the validation for the port before test data valid for the repository is provided; * For the final tests, I will draft the class with the tests from GAKT3 without the data and disabled, waiting for @sooheelee for meaningful tests (or other people from your team). The main idea is to have two PRs with the port validated with the tutorial data, and add other tests similar to the GATK3's ones for extra validation and/or covering missing codepaths using @sooheelee or ported GATK3 data. Does it makes sense, @cmnbroad and @sooheelee?. @sooheelee - I think that the 1000G data can be a good validation if chromosomes 20/21 have realigned reads without a pair mapping on other chromosomes. In that case, some of that reads can be extracted and reset to the state previous to realignment to validate the new tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774:940,Testability,test,test,940,"Sorry @cmnbroad, I misunderstood your comment before - what I've got is that it is ok to have beta/experimental for this, but it's obviosly not what you said, so my fault for not reading carefully. In that case, I would like to have a proposal for how to proceed here:. * I will implement the port for the tools in two independent PRs - just direct translation into the new framework, documentation and kebab-case argument style.; * The port for `RealignerTargetCreator` will be similar to this one; * The port for `IndelRealigner` would not have support for n-way output, although it will be fully functional in other ways. The n-way option can be ported in the future as an extra feature if necessary (maybe the communications team can weight in, and tell if it is really a needed feature); * For the first test, which will be removed before merging, I will use the data from the tutorial. This will be the validation for the port before test data valid for the repository is provided; * For the final tests, I will draft the class with the tests from GAKT3 without the data and disabled, waiting for @sooheelee for meaningful tests (or other people from your team). The main idea is to have two PRs with the port validated with the tutorial data, and add other tests similar to the GATK3's ones for extra validation and/or covering missing codepaths using @sooheelee or ported GATK3 data. Does it makes sense, @cmnbroad and @sooheelee?. @sooheelee - I think that the 1000G data can be a good validation if chromosomes 20/21 have realigned reads without a pair mapping on other chromosomes. In that case, some of that reads can be extracted and reset to the state previous to realignment to validate the new tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774:1004,Testability,test,tests,1004,"Sorry @cmnbroad, I misunderstood your comment before - what I've got is that it is ok to have beta/experimental for this, but it's obviosly not what you said, so my fault for not reading carefully. In that case, I would like to have a proposal for how to proceed here:. * I will implement the port for the tools in two independent PRs - just direct translation into the new framework, documentation and kebab-case argument style.; * The port for `RealignerTargetCreator` will be similar to this one; * The port for `IndelRealigner` would not have support for n-way output, although it will be fully functional in other ways. The n-way option can be ported in the future as an extra feature if necessary (maybe the communications team can weight in, and tell if it is really a needed feature); * For the first test, which will be removed before merging, I will use the data from the tutorial. This will be the validation for the port before test data valid for the repository is provided; * For the final tests, I will draft the class with the tests from GAKT3 without the data and disabled, waiting for @sooheelee for meaningful tests (or other people from your team). The main idea is to have two PRs with the port validated with the tutorial data, and add other tests similar to the GATK3's ones for extra validation and/or covering missing codepaths using @sooheelee or ported GATK3 data. Does it makes sense, @cmnbroad and @sooheelee?. @sooheelee - I think that the 1000G data can be a good validation if chromosomes 20/21 have realigned reads without a pair mapping on other chromosomes. In that case, some of that reads can be extracted and reset to the state previous to realignment to validate the new tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774:1043,Testability,test,tests,1043,"Sorry @cmnbroad, I misunderstood your comment before - what I've got is that it is ok to have beta/experimental for this, but it's obviosly not what you said, so my fault for not reading carefully. In that case, I would like to have a proposal for how to proceed here:. * I will implement the port for the tools in two independent PRs - just direct translation into the new framework, documentation and kebab-case argument style.; * The port for `RealignerTargetCreator` will be similar to this one; * The port for `IndelRealigner` would not have support for n-way output, although it will be fully functional in other ways. The n-way option can be ported in the future as an extra feature if necessary (maybe the communications team can weight in, and tell if it is really a needed feature); * For the first test, which will be removed before merging, I will use the data from the tutorial. This will be the validation for the port before test data valid for the repository is provided; * For the final tests, I will draft the class with the tests from GAKT3 without the data and disabled, waiting for @sooheelee for meaningful tests (or other people from your team). The main idea is to have two PRs with the port validated with the tutorial data, and add other tests similar to the GATK3's ones for extra validation and/or covering missing codepaths using @sooheelee or ported GATK3 data. Does it makes sense, @cmnbroad and @sooheelee?. @sooheelee - I think that the 1000G data can be a good validation if chromosomes 20/21 have realigned reads without a pair mapping on other chromosomes. In that case, some of that reads can be extracted and reset to the state previous to realignment to validate the new tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774:1129,Testability,test,tests,1129,"Sorry @cmnbroad, I misunderstood your comment before - what I've got is that it is ok to have beta/experimental for this, but it's obviosly not what you said, so my fault for not reading carefully. In that case, I would like to have a proposal for how to proceed here:. * I will implement the port for the tools in two independent PRs - just direct translation into the new framework, documentation and kebab-case argument style.; * The port for `RealignerTargetCreator` will be similar to this one; * The port for `IndelRealigner` would not have support for n-way output, although it will be fully functional in other ways. The n-way option can be ported in the future as an extra feature if necessary (maybe the communications team can weight in, and tell if it is really a needed feature); * For the first test, which will be removed before merging, I will use the data from the tutorial. This will be the validation for the port before test data valid for the repository is provided; * For the final tests, I will draft the class with the tests from GAKT3 without the data and disabled, waiting for @sooheelee for meaningful tests (or other people from your team). The main idea is to have two PRs with the port validated with the tutorial data, and add other tests similar to the GATK3's ones for extra validation and/or covering missing codepaths using @sooheelee or ported GATK3 data. Does it makes sense, @cmnbroad and @sooheelee?. @sooheelee - I think that the 1000G data can be a good validation if chromosomes 20/21 have realigned reads without a pair mapping on other chromosomes. In that case, some of that reads can be extracted and reset to the state previous to realignment to validate the new tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774:1264,Testability,test,tests,1264,"Sorry @cmnbroad, I misunderstood your comment before - what I've got is that it is ok to have beta/experimental for this, but it's obviosly not what you said, so my fault for not reading carefully. In that case, I would like to have a proposal for how to proceed here:. * I will implement the port for the tools in two independent PRs - just direct translation into the new framework, documentation and kebab-case argument style.; * The port for `RealignerTargetCreator` will be similar to this one; * The port for `IndelRealigner` would not have support for n-way output, although it will be fully functional in other ways. The n-way option can be ported in the future as an extra feature if necessary (maybe the communications team can weight in, and tell if it is really a needed feature); * For the first test, which will be removed before merging, I will use the data from the tutorial. This will be the validation for the port before test data valid for the repository is provided; * For the final tests, I will draft the class with the tests from GAKT3 without the data and disabled, waiting for @sooheelee for meaningful tests (or other people from your team). The main idea is to have two PRs with the port validated with the tutorial data, and add other tests similar to the GATK3's ones for extra validation and/or covering missing codepaths using @sooheelee or ported GATK3 data. Does it makes sense, @cmnbroad and @sooheelee?. @sooheelee - I think that the 1000G data can be a good validation if chromosomes 20/21 have realigned reads without a pair mapping on other chromosomes. In that case, some of that reads can be extracted and reset to the state previous to realignment to validate the new tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371728774
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371944022:230,Energy Efficiency,efficient,efficient,230,"@magicDGS `--nWayOut` is absolutely necessary for co-cleaning tumor-normal pairs of samples. This allows upfront filtering of tumor mutations against the matched-normal, the panel of normals and the germline sites to be much more efficient (in somatic mutation calling). . I will then go ahead and start making a base test dataset. The repo tests look like they tested all sorts of things, e.g. bad CIGARs. Will you be altering the base data I provide towards these other tests or are we focused just on the primary functionality? If more than just a normal dataset is needed, then do specify these requirements. Remember that I do not as of yet understand Java code. It would be helpful to also see the previous test data if its features are what we want to recapitulate. If we are instead making up new tests, then that is fine too. Since you bring up nwayout, it seems the test should accommodate two samples. I was thinking to make alt-ware mapped GRCh38 snippets that included ALT/HLA contigs, just to cover our bases. In fact, I can make test data on post-alt processed reads, to further accommodate recent advances in genomics. Let me know your thoughts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371944022
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371944022:318,Testability,test,test,318,"@magicDGS `--nWayOut` is absolutely necessary for co-cleaning tumor-normal pairs of samples. This allows upfront filtering of tumor mutations against the matched-normal, the panel of normals and the germline sites to be much more efficient (in somatic mutation calling). . I will then go ahead and start making a base test dataset. The repo tests look like they tested all sorts of things, e.g. bad CIGARs. Will you be altering the base data I provide towards these other tests or are we focused just on the primary functionality? If more than just a normal dataset is needed, then do specify these requirements. Remember that I do not as of yet understand Java code. It would be helpful to also see the previous test data if its features are what we want to recapitulate. If we are instead making up new tests, then that is fine too. Since you bring up nwayout, it seems the test should accommodate two samples. I was thinking to make alt-ware mapped GRCh38 snippets that included ALT/HLA contigs, just to cover our bases. In fact, I can make test data on post-alt processed reads, to further accommodate recent advances in genomics. Let me know your thoughts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371944022
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371944022:341,Testability,test,tests,341,"@magicDGS `--nWayOut` is absolutely necessary for co-cleaning tumor-normal pairs of samples. This allows upfront filtering of tumor mutations against the matched-normal, the panel of normals and the germline sites to be much more efficient (in somatic mutation calling). . I will then go ahead and start making a base test dataset. The repo tests look like they tested all sorts of things, e.g. bad CIGARs. Will you be altering the base data I provide towards these other tests or are we focused just on the primary functionality? If more than just a normal dataset is needed, then do specify these requirements. Remember that I do not as of yet understand Java code. It would be helpful to also see the previous test data if its features are what we want to recapitulate. If we are instead making up new tests, then that is fine too. Since you bring up nwayout, it seems the test should accommodate two samples. I was thinking to make alt-ware mapped GRCh38 snippets that included ALT/HLA contigs, just to cover our bases. In fact, I can make test data on post-alt processed reads, to further accommodate recent advances in genomics. Let me know your thoughts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371944022
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371944022:362,Testability,test,tested,362,"@magicDGS `--nWayOut` is absolutely necessary for co-cleaning tumor-normal pairs of samples. This allows upfront filtering of tumor mutations against the matched-normal, the panel of normals and the germline sites to be much more efficient (in somatic mutation calling). . I will then go ahead and start making a base test dataset. The repo tests look like they tested all sorts of things, e.g. bad CIGARs. Will you be altering the base data I provide towards these other tests or are we focused just on the primary functionality? If more than just a normal dataset is needed, then do specify these requirements. Remember that I do not as of yet understand Java code. It would be helpful to also see the previous test data if its features are what we want to recapitulate. If we are instead making up new tests, then that is fine too. Since you bring up nwayout, it seems the test should accommodate two samples. I was thinking to make alt-ware mapped GRCh38 snippets that included ALT/HLA contigs, just to cover our bases. In fact, I can make test data on post-alt processed reads, to further accommodate recent advances in genomics. Let me know your thoughts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371944022
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371944022:472,Testability,test,tests,472,"@magicDGS `--nWayOut` is absolutely necessary for co-cleaning tumor-normal pairs of samples. This allows upfront filtering of tumor mutations against the matched-normal, the panel of normals and the germline sites to be much more efficient (in somatic mutation calling). . I will then go ahead and start making a base test dataset. The repo tests look like they tested all sorts of things, e.g. bad CIGARs. Will you be altering the base data I provide towards these other tests or are we focused just on the primary functionality? If more than just a normal dataset is needed, then do specify these requirements. Remember that I do not as of yet understand Java code. It would be helpful to also see the previous test data if its features are what we want to recapitulate. If we are instead making up new tests, then that is fine too. Since you bring up nwayout, it seems the test should accommodate two samples. I was thinking to make alt-ware mapped GRCh38 snippets that included ALT/HLA contigs, just to cover our bases. In fact, I can make test data on post-alt processed reads, to further accommodate recent advances in genomics. Let me know your thoughts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371944022
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371944022:713,Testability,test,test,713,"@magicDGS `--nWayOut` is absolutely necessary for co-cleaning tumor-normal pairs of samples. This allows upfront filtering of tumor mutations against the matched-normal, the panel of normals and the germline sites to be much more efficient (in somatic mutation calling). . I will then go ahead and start making a base test dataset. The repo tests look like they tested all sorts of things, e.g. bad CIGARs. Will you be altering the base data I provide towards these other tests or are we focused just on the primary functionality? If more than just a normal dataset is needed, then do specify these requirements. Remember that I do not as of yet understand Java code. It would be helpful to also see the previous test data if its features are what we want to recapitulate. If we are instead making up new tests, then that is fine too. Since you bring up nwayout, it seems the test should accommodate two samples. I was thinking to make alt-ware mapped GRCh38 snippets that included ALT/HLA contigs, just to cover our bases. In fact, I can make test data on post-alt processed reads, to further accommodate recent advances in genomics. Let me know your thoughts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371944022
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371944022:805,Testability,test,tests,805,"@magicDGS `--nWayOut` is absolutely necessary for co-cleaning tumor-normal pairs of samples. This allows upfront filtering of tumor mutations against the matched-normal, the panel of normals and the germline sites to be much more efficient (in somatic mutation calling). . I will then go ahead and start making a base test dataset. The repo tests look like they tested all sorts of things, e.g. bad CIGARs. Will you be altering the base data I provide towards these other tests or are we focused just on the primary functionality? If more than just a normal dataset is needed, then do specify these requirements. Remember that I do not as of yet understand Java code. It would be helpful to also see the previous test data if its features are what we want to recapitulate. If we are instead making up new tests, then that is fine too. Since you bring up nwayout, it seems the test should accommodate two samples. I was thinking to make alt-ware mapped GRCh38 snippets that included ALT/HLA contigs, just to cover our bases. In fact, I can make test data on post-alt processed reads, to further accommodate recent advances in genomics. Let me know your thoughts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371944022
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371944022:876,Testability,test,test,876,"@magicDGS `--nWayOut` is absolutely necessary for co-cleaning tumor-normal pairs of samples. This allows upfront filtering of tumor mutations against the matched-normal, the panel of normals and the germline sites to be much more efficient (in somatic mutation calling). . I will then go ahead and start making a base test dataset. The repo tests look like they tested all sorts of things, e.g. bad CIGARs. Will you be altering the base data I provide towards these other tests or are we focused just on the primary functionality? If more than just a normal dataset is needed, then do specify these requirements. Remember that I do not as of yet understand Java code. It would be helpful to also see the previous test data if its features are what we want to recapitulate. If we are instead making up new tests, then that is fine too. Since you bring up nwayout, it seems the test should accommodate two samples. I was thinking to make alt-ware mapped GRCh38 snippets that included ALT/HLA contigs, just to cover our bases. In fact, I can make test data on post-alt processed reads, to further accommodate recent advances in genomics. Let me know your thoughts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371944022
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371944022:1044,Testability,test,test,1044,"@magicDGS `--nWayOut` is absolutely necessary for co-cleaning tumor-normal pairs of samples. This allows upfront filtering of tumor mutations against the matched-normal, the panel of normals and the germline sites to be much more efficient (in somatic mutation calling). . I will then go ahead and start making a base test dataset. The repo tests look like they tested all sorts of things, e.g. bad CIGARs. Will you be altering the base data I provide towards these other tests or are we focused just on the primary functionality? If more than just a normal dataset is needed, then do specify these requirements. Remember that I do not as of yet understand Java code. It would be helpful to also see the previous test data if its features are what we want to recapitulate. If we are instead making up new tests, then that is fine too. Since you bring up nwayout, it seems the test should accommodate two samples. I was thinking to make alt-ware mapped GRCh38 snippets that included ALT/HLA contigs, just to cover our bases. In fact, I can make test data on post-alt processed reads, to further accommodate recent advances in genomics. Let me know your thoughts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-371944022
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373131560:225,Testability,test,test,225,"I have to say, too bad we don't have a mechanism in place that allows for the full reference, e.g. NIO only the contigs or portions thereof that are needed for a particular analysis @droazen @cmnbroad. That would make making test data so much easier. I would imagine this is simple to implement, given the reference is indexed. Such a feature would be useful for cloud analyses. I have to jump through ridiculous hoops to make small test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373131560
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373131560:433,Testability,test,test,433,"I have to say, too bad we don't have a mechanism in place that allows for the full reference, e.g. NIO only the contigs or portions thereof that are needed for a particular analysis @droazen @cmnbroad. That would make making test data so much easier. I would imagine this is simple to implement, given the reference is indexed. Such a feature would be useful for cloud analyses. I have to jump through ridiculous hoops to make small test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373131560
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373131560:275,Usability,simpl,simple,275,"I have to say, too bad we don't have a mechanism in place that allows for the full reference, e.g. NIO only the contigs or portions thereof that are needed for a particular analysis @droazen @cmnbroad. That would make making test data so much easier. I would imagine this is simple to implement, given the reference is indexed. Such a feature would be useful for cloud analyses. I have to jump through ridiculous hoops to make small test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373131560
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373162196:4,Testability,test,test,4,"The test data I have for you requires its own mini-reference, which I have prepared this afternoon. I am in the process of working on the alignment data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373162196
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373170450:197,Testability,test,test,197,"@cmnbroad, is 400MB (fasta, dictionary & index) too large for you?; It is possible for me to ~halve this but I have to construct artificial contigs. It is also possible to gz zip the fasta and the test would have to include a step to expand it out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373170450
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373176079:105,Availability,down,down,105,"@cmnbroad says a 400MB reference is too large and the largest file they have is 250MB. So I need to pare down the reference and data further. This will involve making artificial contigs that are basically just snippets of the original GRCh38 contigs. The data will still represent real data. Let me know what you think @cmnbroad @magicDGS, before I spend more time towards this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373176079
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231:2292,Deployability,pipeline,pipeline,2292," is a lot of complication to get the reader ID for each read. It will require to modify the `GATKRead` interface, the data source for reads, or find an *ad hoc* solution on `IndelRealignment` to set the procedence of the read. This requires going into the engine-level code, which in my experience is difficult to port from GATK3 and also slow on the reviewing/acceptance process.; 1. My idea for developing a new writer of general use as the n-way output (which can be used in other tools as well) is to factor out some code from `SplitReads` to have a custom `GATKReadWriter` for arbitrary splitting. i'm already using a similar solution on `ReadTools`, so backporting the code to GATK might be a solution. Nevertheless, this still requires that the `GATKRead` has somehow the identity store at the object level, which requires to address point 1.; 1. The use case of the tumor-normal pair can be resolved by an extra processing step (split by read group). I understand that it is quite convenient to add this argument, but I would suggest that until it can be develop.; 1. Last, bu quite important for me as a developer, I don't have time to spend looking at that engine-level features required to include that argument. I would definitely use some of my time on such a feature if it wasn't possible to workaround the use case of tumor-normal data, but my previous suggestion is enough until someone (even myself) can spend some time on developing the feature. All this said, I am really interested in getting the indel realignment pipeline out in GATK4, and that's why I am implementing it. If the only way is adding support for every extra-feature of the tools, I have no other chance than doing it, but I can't promise that my schedule allows me to do it soon. I already started porting `IndelRealigner` without some features, and thus I think that if the n-way out can wait a bit, I can have the tool sooner than if I need to spend some time on working around the problems at the engine level.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231:2490,Energy Efficiency,schedul,schedule,2490," is a lot of complication to get the reader ID for each read. It will require to modify the `GATKRead` interface, the data source for reads, or find an *ad hoc* solution on `IndelRealignment` to set the procedence of the read. This requires going into the engine-level code, which in my experience is difficult to port from GATK3 and also slow on the reviewing/acceptance process.; 1. My idea for developing a new writer of general use as the n-way output (which can be used in other tools as well) is to factor out some code from `SplitReads` to have a custom `GATKReadWriter` for arbitrary splitting. i'm already using a similar solution on `ReadTools`, so backporting the code to GATK might be a solution. Nevertheless, this still requires that the `GATKRead` has somehow the identity store at the object level, which requires to address point 1.; 1. The use case of the tumor-normal pair can be resolved by an extra processing step (split by read group). I understand that it is quite convenient to add this argument, but I would suggest that until it can be develop.; 1. Last, bu quite important for me as a developer, I don't have time to spend looking at that engine-level features required to include that argument. I would definitely use some of my time on such a feature if it wasn't possible to workaround the use case of tumor-normal data, but my previous suggestion is enough until someone (even myself) can spend some time on developing the feature. All this said, I am really interested in getting the indel realignment pipeline out in GATK4, and that's why I am implementing it. If the only way is adding support for every extra-feature of the tools, I have no other chance than doing it, but I can't promise that my schedule allows me to do it soon. I already started porting `IndelRealigner` without some features, and thus I think that if the n-way out can wait a bit, I can have the tool sooner than if I need to spend some time on working around the problems at the engine level.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231:860,Integrability,interface,interface,860,"Thanks a lot for looking into this @sooheelee - I understand the pain of making the small data for the tests, so I really appreciate your work there. I have almost prepare a PR for the new port of `RealignerTargetCreator` that will have TODOs for the test data prepared by you, and with some tests using files already in the repository (for the target-creator, I guess that the validation for getting the regions to realign would be enough, because thanks to that tests I realized of a small bug due to not including all the loci in the `LocusWalker`). On the other hand, I will still fight for the `--nWayOut` not blocking the inclusion of `IndelRealigner` in the first place. My reasons are the following:; ; 1. Looking a bit into the code of GATK3, there is a lot of complication to get the reader ID for each read. It will require to modify the `GATKRead` interface, the data source for reads, or find an *ad hoc* solution on `IndelRealignment` to set the procedence of the read. This requires going into the engine-level code, which in my experience is difficult to port from GATK3 and also slow on the reviewing/acceptance process.; 1. My idea for developing a new writer of general use as the n-way output (which can be used in other tools as well) is to factor out some code from `SplitReads` to have a custom `GATKReadWriter` for arbitrary splitting. i'm already using a similar solution on `ReadTools`, so backporting the code to GATK might be a solution. Nevertheless, this still requires that the `GATKRead` has somehow the identity store at the object level, which requires to address point 1.; 1. The use case of the tumor-normal pair can be resolved by an extra processing step (split by read group). I understand that it is quite convenient to add this argument, but I would suggest that until it can be develop.; 1. Last, bu quite important for me as a developer, I don't have time to spend looking at that engine-level features required to include that argument. I would definitely u",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231:378,Security,validat,validation,378,"Thanks a lot for looking into this @sooheelee - I understand the pain of making the small data for the tests, so I really appreciate your work there. I have almost prepare a PR for the new port of `RealignerTargetCreator` that will have TODOs for the test data prepared by you, and with some tests using files already in the repository (for the target-creator, I guess that the validation for getting the regions to realign would be enough, because thanks to that tests I realized of a small bug due to not including all the loci in the `LocusWalker`). On the other hand, I will still fight for the `--nWayOut` not blocking the inclusion of `IndelRealigner` in the first place. My reasons are the following:; ; 1. Looking a bit into the code of GATK3, there is a lot of complication to get the reader ID for each read. It will require to modify the `GATKRead` interface, the data source for reads, or find an *ad hoc* solution on `IndelRealignment` to set the procedence of the read. This requires going into the engine-level code, which in my experience is difficult to port from GATK3 and also slow on the reviewing/acceptance process.; 1. My idea for developing a new writer of general use as the n-way output (which can be used in other tools as well) is to factor out some code from `SplitReads` to have a custom `GATKReadWriter` for arbitrary splitting. i'm already using a similar solution on `ReadTools`, so backporting the code to GATK might be a solution. Nevertheless, this still requires that the `GATKRead` has somehow the identity store at the object level, which requires to address point 1.; 1. The use case of the tumor-normal pair can be resolved by an extra processing step (split by read group). I understand that it is quite convenient to add this argument, but I would suggest that until it can be develop.; 1. Last, bu quite important for me as a developer, I don't have time to spend looking at that engine-level features required to include that argument. I would definitely u",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231:103,Testability,test,tests,103,"Thanks a lot for looking into this @sooheelee - I understand the pain of making the small data for the tests, so I really appreciate your work there. I have almost prepare a PR for the new port of `RealignerTargetCreator` that will have TODOs for the test data prepared by you, and with some tests using files already in the repository (for the target-creator, I guess that the validation for getting the regions to realign would be enough, because thanks to that tests I realized of a small bug due to not including all the loci in the `LocusWalker`). On the other hand, I will still fight for the `--nWayOut` not blocking the inclusion of `IndelRealigner` in the first place. My reasons are the following:; ; 1. Looking a bit into the code of GATK3, there is a lot of complication to get the reader ID for each read. It will require to modify the `GATKRead` interface, the data source for reads, or find an *ad hoc* solution on `IndelRealignment` to set the procedence of the read. This requires going into the engine-level code, which in my experience is difficult to port from GATK3 and also slow on the reviewing/acceptance process.; 1. My idea for developing a new writer of general use as the n-way output (which can be used in other tools as well) is to factor out some code from `SplitReads` to have a custom `GATKReadWriter` for arbitrary splitting. i'm already using a similar solution on `ReadTools`, so backporting the code to GATK might be a solution. Nevertheless, this still requires that the `GATKRead` has somehow the identity store at the object level, which requires to address point 1.; 1. The use case of the tumor-normal pair can be resolved by an extra processing step (split by read group). I understand that it is quite convenient to add this argument, but I would suggest that until it can be develop.; 1. Last, bu quite important for me as a developer, I don't have time to spend looking at that engine-level features required to include that argument. I would definitely u",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231:251,Testability,test,test,251,"Thanks a lot for looking into this @sooheelee - I understand the pain of making the small data for the tests, so I really appreciate your work there. I have almost prepare a PR for the new port of `RealignerTargetCreator` that will have TODOs for the test data prepared by you, and with some tests using files already in the repository (for the target-creator, I guess that the validation for getting the regions to realign would be enough, because thanks to that tests I realized of a small bug due to not including all the loci in the `LocusWalker`). On the other hand, I will still fight for the `--nWayOut` not blocking the inclusion of `IndelRealigner` in the first place. My reasons are the following:; ; 1. Looking a bit into the code of GATK3, there is a lot of complication to get the reader ID for each read. It will require to modify the `GATKRead` interface, the data source for reads, or find an *ad hoc* solution on `IndelRealignment` to set the procedence of the read. This requires going into the engine-level code, which in my experience is difficult to port from GATK3 and also slow on the reviewing/acceptance process.; 1. My idea for developing a new writer of general use as the n-way output (which can be used in other tools as well) is to factor out some code from `SplitReads` to have a custom `GATKReadWriter` for arbitrary splitting. i'm already using a similar solution on `ReadTools`, so backporting the code to GATK might be a solution. Nevertheless, this still requires that the `GATKRead` has somehow the identity store at the object level, which requires to address point 1.; 1. The use case of the tumor-normal pair can be resolved by an extra processing step (split by read group). I understand that it is quite convenient to add this argument, but I would suggest that until it can be develop.; 1. Last, bu quite important for me as a developer, I don't have time to spend looking at that engine-level features required to include that argument. I would definitely u",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231:292,Testability,test,tests,292,"Thanks a lot for looking into this @sooheelee - I understand the pain of making the small data for the tests, so I really appreciate your work there. I have almost prepare a PR for the new port of `RealignerTargetCreator` that will have TODOs for the test data prepared by you, and with some tests using files already in the repository (for the target-creator, I guess that the validation for getting the regions to realign would be enough, because thanks to that tests I realized of a small bug due to not including all the loci in the `LocusWalker`). On the other hand, I will still fight for the `--nWayOut` not blocking the inclusion of `IndelRealigner` in the first place. My reasons are the following:; ; 1. Looking a bit into the code of GATK3, there is a lot of complication to get the reader ID for each read. It will require to modify the `GATKRead` interface, the data source for reads, or find an *ad hoc* solution on `IndelRealignment` to set the procedence of the read. This requires going into the engine-level code, which in my experience is difficult to port from GATK3 and also slow on the reviewing/acceptance process.; 1. My idea for developing a new writer of general use as the n-way output (which can be used in other tools as well) is to factor out some code from `SplitReads` to have a custom `GATKReadWriter` for arbitrary splitting. i'm already using a similar solution on `ReadTools`, so backporting the code to GATK might be a solution. Nevertheless, this still requires that the `GATKRead` has somehow the identity store at the object level, which requires to address point 1.; 1. The use case of the tumor-normal pair can be resolved by an extra processing step (split by read group). I understand that it is quite convenient to add this argument, but I would suggest that until it can be develop.; 1. Last, bu quite important for me as a developer, I don't have time to spend looking at that engine-level features required to include that argument. I would definitely u",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231:464,Testability,test,tests,464,"Thanks a lot for looking into this @sooheelee - I understand the pain of making the small data for the tests, so I really appreciate your work there. I have almost prepare a PR for the new port of `RealignerTargetCreator` that will have TODOs for the test data prepared by you, and with some tests using files already in the repository (for the target-creator, I guess that the validation for getting the regions to realign would be enough, because thanks to that tests I realized of a small bug due to not including all the loci in the `LocusWalker`). On the other hand, I will still fight for the `--nWayOut` not blocking the inclusion of `IndelRealigner` in the first place. My reasons are the following:; ; 1. Looking a bit into the code of GATK3, there is a lot of complication to get the reader ID for each read. It will require to modify the `GATKRead` interface, the data source for reads, or find an *ad hoc* solution on `IndelRealignment` to set the procedence of the read. This requires going into the engine-level code, which in my experience is difficult to port from GATK3 and also slow on the reviewing/acceptance process.; 1. My idea for developing a new writer of general use as the n-way output (which can be used in other tools as well) is to factor out some code from `SplitReads` to have a custom `GATKReadWriter` for arbitrary splitting. i'm already using a similar solution on `ReadTools`, so backporting the code to GATK might be a solution. Nevertheless, this still requires that the `GATKRead` has somehow the identity store at the object level, which requires to address point 1.; 1. The use case of the tumor-normal pair can be resolved by an extra processing step (split by read group). I understand that it is quite convenient to add this argument, but I would suggest that until it can be develop.; 1. Last, bu quite important for me as a developer, I don't have time to spend looking at that engine-level features required to include that argument. I would definitely u",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373376231
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600:158,Deployability,update,updates,158,"@magicDGS, after much discussion with @droazen, we will make this test set even smaller. Also, the current test set will be temporary, to unimpede you, until updates to the main test set can be made (discussion to start next week). @cmnbroad says we need to keep an eye out for coverage in the tests, given the need to make this dataset extremely small. So I removed chr17 from the mini-reference, such that only four small snippets of reference from various chromosomes remained. However, it appears there are only two usable indel realignments going on with GATK3. Note thate these are targeted exome samples with comparatively low coverage. [for_magicDGS.zip](https://github.com/broadinstitute/gatk/files/1820785/for_magicDGS.zip). There are two samples, so as to enable testing nWayOut, and an artificial reference `hg38_Shl01`. The two sites to hone in on are chr11:177568 and chr11:207134. Note also that the BAMs are in an invalid state according to ValidateSamFile. However, GATK3 RealignerTargetCreator and IndelRealigner did not seem to mind. I think these tools should allow processing of BAMs in any validation state. Apologies for the meager state of the data. On the bright side, the data set including the ref is only 23MB and will meet with @droazen's approval in terms of size. . Good luck @magicDGS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600:957,Security,Validat,ValidateSamFile,957,"@magicDGS, after much discussion with @droazen, we will make this test set even smaller. Also, the current test set will be temporary, to unimpede you, until updates to the main test set can be made (discussion to start next week). @cmnbroad says we need to keep an eye out for coverage in the tests, given the need to make this dataset extremely small. So I removed chr17 from the mini-reference, such that only four small snippets of reference from various chromosomes remained. However, it appears there are only two usable indel realignments going on with GATK3. Note thate these are targeted exome samples with comparatively low coverage. [for_magicDGS.zip](https://github.com/broadinstitute/gatk/files/1820785/for_magicDGS.zip). There are two samples, so as to enable testing nWayOut, and an artificial reference `hg38_Shl01`. The two sites to hone in on are chr11:177568 and chr11:207134. Note also that the BAMs are in an invalid state according to ValidateSamFile. However, GATK3 RealignerTargetCreator and IndelRealigner did not seem to mind. I think these tools should allow processing of BAMs in any validation state. Apologies for the meager state of the data. On the bright side, the data set including the ref is only 23MB and will meet with @droazen's approval in terms of size. . Good luck @magicDGS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600:1112,Security,validat,validation,1112,"@magicDGS, after much discussion with @droazen, we will make this test set even smaller. Also, the current test set will be temporary, to unimpede you, until updates to the main test set can be made (discussion to start next week). @cmnbroad says we need to keep an eye out for coverage in the tests, given the need to make this dataset extremely small. So I removed chr17 from the mini-reference, such that only four small snippets of reference from various chromosomes remained. However, it appears there are only two usable indel realignments going on with GATK3. Note thate these are targeted exome samples with comparatively low coverage. [for_magicDGS.zip](https://github.com/broadinstitute/gatk/files/1820785/for_magicDGS.zip). There are two samples, so as to enable testing nWayOut, and an artificial reference `hg38_Shl01`. The two sites to hone in on are chr11:177568 and chr11:207134. Note also that the BAMs are in an invalid state according to ValidateSamFile. However, GATK3 RealignerTargetCreator and IndelRealigner did not seem to mind. I think these tools should allow processing of BAMs in any validation state. Apologies for the meager state of the data. On the bright side, the data set including the ref is only 23MB and will meet with @droazen's approval in terms of size. . Good luck @magicDGS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600:66,Testability,test,test,66,"@magicDGS, after much discussion with @droazen, we will make this test set even smaller. Also, the current test set will be temporary, to unimpede you, until updates to the main test set can be made (discussion to start next week). @cmnbroad says we need to keep an eye out for coverage in the tests, given the need to make this dataset extremely small. So I removed chr17 from the mini-reference, such that only four small snippets of reference from various chromosomes remained. However, it appears there are only two usable indel realignments going on with GATK3. Note thate these are targeted exome samples with comparatively low coverage. [for_magicDGS.zip](https://github.com/broadinstitute/gatk/files/1820785/for_magicDGS.zip). There are two samples, so as to enable testing nWayOut, and an artificial reference `hg38_Shl01`. The two sites to hone in on are chr11:177568 and chr11:207134. Note also that the BAMs are in an invalid state according to ValidateSamFile. However, GATK3 RealignerTargetCreator and IndelRealigner did not seem to mind. I think these tools should allow processing of BAMs in any validation state. Apologies for the meager state of the data. On the bright side, the data set including the ref is only 23MB and will meet with @droazen's approval in terms of size. . Good luck @magicDGS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600:107,Testability,test,test,107,"@magicDGS, after much discussion with @droazen, we will make this test set even smaller. Also, the current test set will be temporary, to unimpede you, until updates to the main test set can be made (discussion to start next week). @cmnbroad says we need to keep an eye out for coverage in the tests, given the need to make this dataset extremely small. So I removed chr17 from the mini-reference, such that only four small snippets of reference from various chromosomes remained. However, it appears there are only two usable indel realignments going on with GATK3. Note thate these are targeted exome samples with comparatively low coverage. [for_magicDGS.zip](https://github.com/broadinstitute/gatk/files/1820785/for_magicDGS.zip). There are two samples, so as to enable testing nWayOut, and an artificial reference `hg38_Shl01`. The two sites to hone in on are chr11:177568 and chr11:207134. Note also that the BAMs are in an invalid state according to ValidateSamFile. However, GATK3 RealignerTargetCreator and IndelRealigner did not seem to mind. I think these tools should allow processing of BAMs in any validation state. Apologies for the meager state of the data. On the bright side, the data set including the ref is only 23MB and will meet with @droazen's approval in terms of size. . Good luck @magicDGS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600:178,Testability,test,test,178,"@magicDGS, after much discussion with @droazen, we will make this test set even smaller. Also, the current test set will be temporary, to unimpede you, until updates to the main test set can be made (discussion to start next week). @cmnbroad says we need to keep an eye out for coverage in the tests, given the need to make this dataset extremely small. So I removed chr17 from the mini-reference, such that only four small snippets of reference from various chromosomes remained. However, it appears there are only two usable indel realignments going on with GATK3. Note thate these are targeted exome samples with comparatively low coverage. [for_magicDGS.zip](https://github.com/broadinstitute/gatk/files/1820785/for_magicDGS.zip). There are two samples, so as to enable testing nWayOut, and an artificial reference `hg38_Shl01`. The two sites to hone in on are chr11:177568 and chr11:207134. Note also that the BAMs are in an invalid state according to ValidateSamFile. However, GATK3 RealignerTargetCreator and IndelRealigner did not seem to mind. I think these tools should allow processing of BAMs in any validation state. Apologies for the meager state of the data. On the bright side, the data set including the ref is only 23MB and will meet with @droazen's approval in terms of size. . Good luck @magicDGS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600:294,Testability,test,tests,294,"@magicDGS, after much discussion with @droazen, we will make this test set even smaller. Also, the current test set will be temporary, to unimpede you, until updates to the main test set can be made (discussion to start next week). @cmnbroad says we need to keep an eye out for coverage in the tests, given the need to make this dataset extremely small. So I removed chr17 from the mini-reference, such that only four small snippets of reference from various chromosomes remained. However, it appears there are only two usable indel realignments going on with GATK3. Note thate these are targeted exome samples with comparatively low coverage. [for_magicDGS.zip](https://github.com/broadinstitute/gatk/files/1820785/for_magicDGS.zip). There are two samples, so as to enable testing nWayOut, and an artificial reference `hg38_Shl01`. The two sites to hone in on are chr11:177568 and chr11:207134. Note also that the BAMs are in an invalid state according to ValidateSamFile. However, GATK3 RealignerTargetCreator and IndelRealigner did not seem to mind. I think these tools should allow processing of BAMs in any validation state. Apologies for the meager state of the data. On the bright side, the data set including the ref is only 23MB and will meet with @droazen's approval in terms of size. . Good luck @magicDGS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600:774,Testability,test,testing,774,"@magicDGS, after much discussion with @droazen, we will make this test set even smaller. Also, the current test set will be temporary, to unimpede you, until updates to the main test set can be made (discussion to start next week). @cmnbroad says we need to keep an eye out for coverage in the tests, given the need to make this dataset extremely small. So I removed chr17 from the mini-reference, such that only four small snippets of reference from various chromosomes remained. However, it appears there are only two usable indel realignments going on with GATK3. Note thate these are targeted exome samples with comparatively low coverage. [for_magicDGS.zip](https://github.com/broadinstitute/gatk/files/1820785/for_magicDGS.zip). There are two samples, so as to enable testing nWayOut, and an artificial reference `hg38_Shl01`. The two sites to hone in on are chr11:177568 and chr11:207134. Note also that the BAMs are in an invalid state according to ValidateSamFile. However, GATK3 RealignerTargetCreator and IndelRealigner did not seem to mind. I think these tools should allow processing of BAMs in any validation state. Apologies for the meager state of the data. On the bright side, the data set including the ref is only 23MB and will meet with @droazen's approval in terms of size. . Good luck @magicDGS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600:520,Usability,usab,usable,520,"@magicDGS, after much discussion with @droazen, we will make this test set even smaller. Also, the current test set will be temporary, to unimpede you, until updates to the main test set can be made (discussion to start next week). @cmnbroad says we need to keep an eye out for coverage in the tests, given the need to make this dataset extremely small. So I removed chr17 from the mini-reference, such that only four small snippets of reference from various chromosomes remained. However, it appears there are only two usable indel realignments going on with GATK3. Note thate these are targeted exome samples with comparatively low coverage. [for_magicDGS.zip](https://github.com/broadinstitute/gatk/files/1820785/for_magicDGS.zip). There are two samples, so as to enable testing nWayOut, and an artificial reference `hg38_Shl01`. The two sites to hone in on are chr11:177568 and chr11:207134. Note also that the BAMs are in an invalid state according to ValidateSamFile. However, GATK3 RealignerTargetCreator and IndelRealigner did not seem to mind. I think these tools should allow processing of BAMs in any validation state. Apologies for the meager state of the data. On the bright side, the data set including the ref is only 23MB and will meet with @droazen's approval in terms of size. . Good luck @magicDGS.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-373845600
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-453573374:86,Testability,test,test,86,"@magicDGS Now that we have full-sized b37 and hg38 references checked in to the large test data, is this old PR unblocked?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-453573374
https://github.com/broadinstitute/gatk/pull/3112#issuecomment-463765960:41,Testability,test,test,41,Let me know if you need me to rework the test data @magicDGS.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3112#issuecomment-463765960
https://github.com/broadinstitute/gatk/pull/3114#issuecomment-308535831:3332,Deployability,pipeline,pipelines,3332,0% <0%> (-1%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/3114?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SYW5kb21MaWtlbGlob29kQ2FsY3VsYXRpb25FbmdpbmUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...bender/tools/walkers/annotator/MappingQuality.java](https://codecov.io/gh/broadinstitute/gatk/pull/3114?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9NYXBwaW5nUXVhbGl0eS5qYXZh) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...llbender/tools/walkers/annotator/ReadPosition.java](https://codecov.io/gh/broadinstitute/gatk/pull/3114?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SZWFkUG9zaXRpb24uamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-8%)` | |; | [...alc/GeneralPloidyFailOverAFCalculatorProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/3114?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvR2VuZXJhbFBsb2lkeUZhaWxPdmVyQUZDYWxjdWxhdG9yUHJvdmlkZXIuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3114?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-8%)` | |; | [...tractOpticalDuplicateFinderCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3114?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL0Fic3RyYWN0T3B0aWNhbER1cGxpY2F0ZUZpbmRlckNvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | ... and [1044 more](https://codecov.io/gh/broadinstitute/gatk/pull/3114?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3114#issuecomment-308535831
https://github.com/broadinstitute/gatk/issues/3117#issuecomment-309060263:14,Testability,test,testing,14,"After further testing, we've found that this problem also occurs with the JDK deflater/inflater at compression level 9. This makes it much more likely to be a bug in the tool or the test itself, rather than the Intel deflater/inflater.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3117#issuecomment-309060263
https://github.com/broadinstitute/gatk/issues/3117#issuecomment-309060263:182,Testability,test,test,182,"After further testing, we've found that this problem also occurs with the JDK deflater/inflater at compression level 9. This makes it much more likely to be a bug in the tool or the test itself, rather than the Intel deflater/inflater.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3117#issuecomment-309060263
https://github.com/broadinstitute/gatk/issues/3118#issuecomment-316801259:117,Deployability,update,updated,117,"Re-opening this one, since the ""craft test case"" part of this ticket has not yet been done -- we've just moved to an updated snapshot.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3118#issuecomment-316801259
https://github.com/broadinstitute/gatk/issues/3118#issuecomment-316801259:38,Testability,test,test,38,"Re-opening this one, since the ""craft test case"" part of this ticket has not yet been done -- we've just moved to an updated snapshot.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3118#issuecomment-316801259
https://github.com/broadinstitute/gatk/issues/3119#issuecomment-428714850:53,Testability,Test,Test,53,I'm going to close this until someone sees it again. Test data is gone.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3119#issuecomment-428714850
https://github.com/broadinstitute/gatk/issues/3120#issuecomment-309128063:376,Availability,down,down,376,"@jean-philippe-martin Mind prioritizing this one? We are building a custom snapshot of `google-cloud-java` with `maxChannelReopens` hardcoded to the value we want, which should resolve https://github.com/broadinstitute/gatk/issues/2685 for now, but it would be great to have a permanent solution in master. Requiring GATK to construct Path objects a certain way and pass them down into libraries like htsjdk is just too brittle, as those libraries often need to create Path objects on-the-fly and we lose our settings. Ideally we'd just be able to call a static method (or similar) at GATK startup to force all instances of `CloudStorageReadChannel` to use our desired settings.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3120#issuecomment-309128063
https://github.com/broadinstitute/gatk/issues/3121#issuecomment-309919374:59,Testability,log,logic,59,"Closing since without implementing the entire JEXL parsing logic, it's possible to incorrectly modify the JEXL expression.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3121#issuecomment-309919374
https://github.com/broadinstitute/gatk/pull/3124#issuecomment-309833042:23,Usability,feedback,feedback,23,I've incorporated your feedback @davidbenjamin. Many thanks for the review. Waiting for checks to pass.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3124#issuecomment-309833042
https://github.com/broadinstitute/gatk/pull/3124#issuecomment-309868749:48,Testability,test,tests,48,@sooheelee Looks good to me. You can merge once tests pass.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3124#issuecomment-309868749
https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309543353:65,Modifiability,config,config,65,"Also as part of the mock-up, we should actually package the mock config files inside of our jar, load them off the classpath, and test file-based override ability.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309543353
https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309543353:97,Performance,load,load,97,"Also as part of the mock-up, we should actually package the mock config files inside of our jar, load them off the classpath, and test file-based override ability.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309543353
https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309543353:20,Testability,mock,mock-up,20,"Also as part of the mock-up, we should actually package the mock config files inside of our jar, load them off the classpath, and test file-based override ability.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309543353
https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309543353:60,Testability,mock,mock,60,"Also as part of the mock-up, we should actually package the mock config files inside of our jar, load them off the classpath, and test file-based override ability.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309543353
https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309543353:130,Testability,test,test,130,"Also as part of the mock-up, we should actually package the mock config files inside of our jar, load them off the classpath, and test file-based override ability.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309543353
https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309680944:47,Deployability,configurat,configuration,47,"Just an idea: it will be nice to propagate the configuration from `Main` to the tools, and obtain from it the packages/classes to include in the command line tools (this is one of the things that I implemented in #2322).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309680944
https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309680944:47,Modifiability,config,configuration,47,"Just an idea: it will be nice to propagate the configuration from `Main` to the tools, and obtain from it the packages/classes to include in the command line tools (this is one of the things that I implemented in #2322).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3126#issuecomment-309680944
https://github.com/broadinstitute/gatk/pull/3128#issuecomment-314424123:9,Availability,ping,ping,9,"Friendly ping here, @vdauwera :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3128#issuecomment-314424123
https://github.com/broadinstitute/gatk/pull/3128#issuecomment-316838737:118,Deployability,release,release,118,"Whoops sorry @magicDGS, I've been out doing workshops. Kicking myself now for not doing this in time for the new beta release. Putting this on my todo for the next few days.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3128#issuecomment-316838737
https://github.com/broadinstitute/gatk/pull/3128#issuecomment-319623957:258,Deployability,update,update,258,"I run locally the gradle gatkDoc task and I fixed some HTML formatting (and a missing summary line in `MetricsReadFilter`. Can you have a look to the last commit to be sure, @vdauwera?. I will add fixes if I find problems in my own documentation code when I update the gatk dependency. Thanks for reviewing and accepting these changes!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3128#issuecomment-319623957
https://github.com/broadinstitute/gatk/pull/3128#issuecomment-319623957:274,Integrability,depend,dependency,274,"I run locally the gradle gatkDoc task and I fixed some HTML formatting (and a missing summary line in `MetricsReadFilter`. Can you have a look to the last commit to be sure, @vdauwera?. I will add fixes if I find problems in my own documentation code when I update the gatk dependency. Thanks for reviewing and accepting these changes!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3128#issuecomment-319623957
https://github.com/broadinstitute/gatk/pull/3129#issuecomment-309827195:1850,Deployability,pipeline,pipelines,1850,; | [...lines/metrics/CollectQualityYieldMetricsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0UXVhbGl0eVlpZWxkTWV0cmljc1NwYXJrLmphdmE=) | `100% <> ()` | `7 <0> ()` | :arrow_down: |; | [...s/metrics/CollectBaseDistributionByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0QmFzZURpc3RyaWJ1dGlvbkJ5Q3ljbGVTcGFyay5qYXZh) | `86.792% <> ()` | `8 <0> ()` | :arrow_down: |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `23.729% <> ()` | `2 <0> ()` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountBasesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRCYXNlc1NwYXJrLmphdmE=) | `90% <> ()` | `5 <0> ()` | :arrow_down: |; | [...transforms/markduplicates/MarkDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `90.909% <> ()` | `9 <0> ()` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrLmphdmE=) | `90% <> ()` | `4 <0> ()` | :arrow_down: |; | [...itute/hellbender/tools/walkers/mutect/Mutect2.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3129#issuecomment-309827195
https://github.com/broadinstitute/gatk/pull/3129#issuecomment-309827195:2474,Deployability,pipeline,pipelines,2474,% <> ()` | `8 <0> ()` | :arrow_down: |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `23.729% <> ()` | `2 <0> ()` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountBasesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRCYXNlc1NwYXJrLmphdmE=) | `90% <> ()` | `5 <0> ()` | :arrow_down: |; | [...transforms/markduplicates/MarkDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `90.909% <> ()` | `9 <0> ()` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrLmphdmE=) | `90% <> ()` | `4 <0> ()` | :arrow_down: |; | [...itute/hellbender/tools/walkers/mutect/Mutect2.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyLmphdmE=) | `92.593% <> ()` | `16 <0> ()` | :arrow_down: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `66.667% <> ()` | `4 <0> ()` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYW,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3129#issuecomment-309827195
https://github.com/broadinstitute/gatk/pull/3129#issuecomment-309827195:3660,Deployability,pipeline,pipelines,3660,y9waXBlbGluZXMvQ291bnRCYXNlc1NwYXJrLmphdmE=) | `90% <> ()` | `5 <0> ()` | :arrow_down: |; | [...transforms/markduplicates/MarkDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `90.909% <> ()` | `9 <0> ()` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrLmphdmE=) | `90% <> ()` | `4 <0> ()` | :arrow_down: |; | [...itute/hellbender/tools/walkers/mutect/Mutect2.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyLmphdmE=) | `92.593% <> ()` | `16 <0> ()` | :arrow_down: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `66.667% <> ()` | `4 <0> ()` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `80.612% <> ()` | `19 <0> ()` | :arrow_down: |; | [...lbender/tools/spark/pipelines/PrintReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRSZWFkc1NwYXJrLmphdmE=) | `100% <> ()` | `4 <0> ()` | :arrow_down: |; | ... and [22 more](https://codecov.io/gh/broadinstitute/gatk/pull/3129?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3129#issuecomment-309827195
https://github.com/broadinstitute/gatk/pull/3133#issuecomment-309907784:215,Testability,test,tests,215,"@tedsharpe, please take another look. I have changed a few things apart from your comments... Now I'm addressing another separated yet related issue (getName returns now the read name and nothing else), and get the tests to pass (hopefully).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3133#issuecomment-309907784
https://github.com/broadinstitute/gatk/pull/3133#issuecomment-310490622:2701,Performance,Perform,PerformSegmentation,2701,W50RXZpZGVuY2UuamF2YQ==) | `0% <0%> (-83.036%)` | `0 <0> (-13)` | |; | [...er/tools/spark/sv/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3133?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `8.523% <0%> (-63.352%)` | `0 <0> (-43)` | |; | [...ellbender/tools/spark/sv/ReadsForQNamesFinder.java](https://codecov.io/gh/broadinstitute/gatk/pull/3133?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9SZWFkc0ZvclFOYW1lc0ZpbmRlci5qYXZh) | `0% <0%> (-93.548%)` | `0 <0> (-7)` | |; | [...exome/germlinehmm/xhmm/XHMMArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3133?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9nZXJtbGluZWhtbS94aG1tL1hITU1Bcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-2%)` | |; | [...te/hellbender/tools/exome/PerformSegmentation.java](https://codecov.io/gh/broadinstitute/gatk/pull/3133?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9QZXJmb3JtU2VnbWVudGF0aW9uLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | [...dinstitute/hellbender/utils/svd/OjAlgoAdapter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3133?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zdmQvT2pBbGdvQWRhcHRlci5qYXZh) | `0% <0%> (-100%)` | `0% <0%> (-10%)` | |; | [...llbender/tools/walkers/bqsr/GatherBQSRReports.java](https://codecov.io/gh/broadinstitute/gatk/pull/3133?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvR2F0aGVyQlFTUlJlcG9ydHMuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-2%)` | |; | [...itute/hellbender/tools/exome/SampleCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3133?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlb,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3133#issuecomment-310490622
https://github.com/broadinstitute/gatk/pull/3133#issuecomment-311404369:64,Performance,cache,cached,64,"@tedsharpe, I have changed the implementation to use a lazy non-cached recreation of the read mapping information. . I have not added the additional mapping information in your branch like the MQ value. I would do that in a separate commit. . Please take a look and perhaps run your benchmark.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3133#issuecomment-311404369
https://github.com/broadinstitute/gatk/pull/3133#issuecomment-311404369:283,Testability,benchmark,benchmark,283,"@tedsharpe, I have changed the implementation to use a lazy non-cached recreation of the read mapping information. . I have not added the additional mapping information in your branch like the MQ value. I would do that in a separate commit. . Please take a look and perhaps run your benchmark.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3133#issuecomment-311404369
https://github.com/broadinstitute/gatk/pull/3135#issuecomment-309876624:2345,Performance,Perform,PerformAlleleFractionSegmentation,2345,9scy9leG9tZS9Bbm5vdGF0ZVRhcmdldHMuamF2YQ==) | `78.049% <> ()` | `7 <0> ()` | :arrow_down: |; | [...llbender/tools/exome/plotting/PlotACNVResults.java](https://codecov.io/gh/broadinstitute/gatk/pull/3135?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9wbG90dGluZy9QbG90QUNOVlJlc3VsdHMuamF2YQ==) | `84.615% <> ()` | `22 <0> ()` | :arrow_down: |; | [...adinstitute/hellbender/tools/exome/PadTargets.java](https://codecov.io/gh/broadinstitute/gatk/pull/3135?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9QYWRUYXJnZXRzLmphdmE=) | `100% <> ()` | `3 <0> ()` | :arrow_down: |; | [...hellbender/tools/genome/SparkGenomeReadCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/3135?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWUvU3BhcmtHZW5vbWVSZWFkQ291bnRzLmphdmE=) | `91.089% <> ()` | `18 <0> ()` | :arrow_down: |; | [...egmentation/PerformAlleleFractionSegmentation.java](https://codecov.io/gh/broadinstitute/gatk/pull/3135?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9zZWdtZW50YXRpb24vUGVyZm9ybUFsbGVsZUZyYWN0aW9uU2VnbWVudGF0aW9uLmphdmE=) | `88.889% <> ()` | `2 <0> ()` | :arrow_down: |; | [...llbender/tools/walkers/validation/Concordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/3135?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2UuamF2YQ==) | `88.542% <> ()` | `28 <0> ()` | :arrow_down: |; | [...ute/hellbender/tools/exome/ConvertACNVResults.java](https://codecov.io/gh/broadinstitute/gatk/pull/3135?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9Db252ZXJ0QUNOVlJlc3VsdHMuamF2YQ==) | `87.805% <> ()` | `4 <0> ()` | :arrow_down: |; | [...idation/AnnotateVcfWithExpectedAlleleFraction.java](https://codecov.io/gh/broadinstitute/gatk/pull/313,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3135#issuecomment-309876624
https://github.com/broadinstitute/gatk/pull/3135#issuecomment-309876624:2684,Security,validat,validation,2684,VsdHMuamF2YQ==) | `84.615% <> ()` | `22 <0> ()` | :arrow_down: |; | [...adinstitute/hellbender/tools/exome/PadTargets.java](https://codecov.io/gh/broadinstitute/gatk/pull/3135?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9QYWRUYXJnZXRzLmphdmE=) | `100% <> ()` | `3 <0> ()` | :arrow_down: |; | [...hellbender/tools/genome/SparkGenomeReadCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/3135?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWUvU3BhcmtHZW5vbWVSZWFkQ291bnRzLmphdmE=) | `91.089% <> ()` | `18 <0> ()` | :arrow_down: |; | [...egmentation/PerformAlleleFractionSegmentation.java](https://codecov.io/gh/broadinstitute/gatk/pull/3135?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9zZWdtZW50YXRpb24vUGVyZm9ybUFsbGVsZUZyYWN0aW9uU2VnbWVudGF0aW9uLmphdmE=) | `88.889% <> ()` | `2 <0> ()` | :arrow_down: |; | [...llbender/tools/walkers/validation/Concordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/3135?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2UuamF2YQ==) | `88.542% <> ()` | `28 <0> ()` | :arrow_down: |; | [...ute/hellbender/tools/exome/ConvertACNVResults.java](https://codecov.io/gh/broadinstitute/gatk/pull/3135?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9Db252ZXJ0QUNOVlJlc3VsdHMuamF2YQ==) | `87.805% <> ()` | `4 <0> ()` | :arrow_down: |; | [...idation/AnnotateVcfWithExpectedAlleleFraction.java](https://codecov.io/gh/broadinstitute/gatk/pull/3135?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQW5ub3RhdGVWY2ZXaXRoRXhwZWN0ZWRBbGxlbGVGcmFjdGlvbi5qYXZh) | `96.429% <> ()` | `7 <0> ()` | :arrow_down: |; | [...tools/exome/convertbed/ConvertBedToTargetFile.java](https://codecov.io/gh/broadinstitute/gatk/pull,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3135#issuecomment-309876624
https://github.com/broadinstitute/gatk/issues/3137#issuecomment-319113656:81,Availability,error,error,81,"That is a good question Soo Hee. I myself don't set the argument unless I get an error. If I do get an error, I just set is to 100G which is outrageous, but I don't know how much is appropriate. If anyone else has suggestions, I would be interested in the answer too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3137#issuecomment-319113656
https://github.com/broadinstitute/gatk/issues/3137#issuecomment-319113656:103,Availability,error,error,103,"That is a good question Soo Hee. I myself don't set the argument unless I get an error. If I do get an error, I just set is to 100G which is outrageous, but I don't know how much is appropriate. If anyone else has suggestions, I would be interested in the answer too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3137#issuecomment-319113656
https://github.com/broadinstitute/gatk/issues/3137#issuecomment-319124674:234,Deployability,pipeline,pipeline,234,"I'm not crazy about the idea of specifying this in the example commands in general. It will depend a lot on what data and use case a user is going through at any given time. I would much prefer leaving specific recommendations to our pipeline scripts, where we can use whatever the prod pipeline uses, and say ""given this use case and example data, this is what works, ymmv"". So I would actually advocate for removing all -Xmx values in the tool docs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3137#issuecomment-319124674
https://github.com/broadinstitute/gatk/issues/3137#issuecomment-319124674:287,Deployability,pipeline,pipeline,287,"I'm not crazy about the idea of specifying this in the example commands in general. It will depend a lot on what data and use case a user is going through at any given time. I would much prefer leaving specific recommendations to our pipeline scripts, where we can use whatever the prod pipeline uses, and say ""given this use case and example data, this is what works, ymmv"". So I would actually advocate for removing all -Xmx values in the tool docs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3137#issuecomment-319124674
https://github.com/broadinstitute/gatk/issues/3137#issuecomment-319124674:92,Integrability,depend,depend,92,"I'm not crazy about the idea of specifying this in the example commands in general. It will depend a lot on what data and use case a user is going through at any given time. I would much prefer leaving specific recommendations to our pipeline scripts, where we can use whatever the prod pipeline uses, and say ""given this use case and example data, this is what works, ymmv"". So I would actually advocate for removing all -Xmx values in the tool docs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3137#issuecomment-319124674
https://github.com/broadinstitute/gatk/issues/3137#issuecomment-319384386:366,Integrability,message,messages,366,"@vdauwera There are some tools that have very specific requirements with regards to `-Xmx`, however. For example, `GenomicsDBImport` requires that you size your `-Xmx` value significantly **smaller** than the total amount of free memory on the machine, in order to leave enough room for the native heap. If you don't do this, you will get truly horrific and cryptic messages when the native code crashes with out-of-memory. This is really something that needs to be documented prominently!. I'd advocate for selective inclusion of recommended `-Xmx` values in the docs, for cases like the above where it really matters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3137#issuecomment-319384386
https://github.com/broadinstitute/gatk/issues/3137#issuecomment-346066876:40,Deployability,update,update,40,This is left to the developers who will update the tool docs in <https://github.com/broadinstitute/gatk/issues/3853>.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3137#issuecomment-346066876
https://github.com/broadinstitute/gatk/issues/3137#issuecomment-358068521:44,Deployability,update,updates,44,"We've taken a stab at this with the tooldoc updates. There may be things to change going forward, but we can deal with them as they come.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3137#issuecomment-358068521
https://github.com/broadinstitute/gatk/pull/3138#issuecomment-309897833:75,Availability,down,down,75,"Boosts discovery of all classes of variants, but nothing dramatic. Runtime down to 41 minutes.; Contains quite a bit of cleanup (sorry).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3138#issuecomment-309897833
https://github.com/broadinstitute/gatk/pull/3139#issuecomment-312341540:139,Testability,test,testBlockGather,139,"Addressed code review comments:. * Pulled `if( firstNonHeaderByteIndex == -1 ){` check out of while loop in `gatherWithBlockCopying()`; * `testBlockGather()` writes output to a temp file, not a hardcoded path; * Corrected docs for `--gatherType` argument. Will merge once tests pass in travis",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3139#issuecomment-312341540
https://github.com/broadinstitute/gatk/pull/3139#issuecomment-312341540:272,Testability,test,tests,272,"Addressed code review comments:. * Pulled `if( firstNonHeaderByteIndex == -1 ){` check out of while loop in `gatherWithBlockCopying()`; * `testBlockGather()` writes output to a temp file, not a hardcoded path; * Corrected docs for `--gatherType` argument. Will merge once tests pass in travis",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3139#issuecomment-312341540
https://github.com/broadinstitute/gatk/pull/3139#issuecomment-312503544:33,Testability,test,testBlockGather,33,"I've had to temporarily disable `testBlockGather()` to get tests to pass here -- the test passes locally, but appears to run out of memory on travis (gets killed with signal 9). Will open a ticket for this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3139#issuecomment-312503544
https://github.com/broadinstitute/gatk/pull/3139#issuecomment-312503544:59,Testability,test,tests,59,"I've had to temporarily disable `testBlockGather()` to get tests to pass here -- the test passes locally, but appears to run out of memory on travis (gets killed with signal 9). Will open a ticket for this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3139#issuecomment-312503544
https://github.com/broadinstitute/gatk/pull/3139#issuecomment-312503544:85,Testability,test,test,85,"I've had to temporarily disable `testBlockGather()` to get tests to pass here -- the test passes locally, but appears to run out of memory on travis (gets killed with signal 9). Will open a ticket for this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3139#issuecomment-312503544
https://github.com/broadinstitute/gatk/pull/3140#issuecomment-309932124:100,Availability,down,down,100,Looks good to me except for one minor thing. Hopefully this does the trick! Thanks also for cutting down on the test runtime.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3140#issuecomment-309932124
https://github.com/broadinstitute/gatk/pull/3140#issuecomment-309932124:112,Testability,test,test,112,Looks good to me except for one minor thing. Hopefully this does the trick! Thanks also for cutting down on the test runtime.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3140#issuecomment-309932124
https://github.com/broadinstitute/gatk/pull/3140#issuecomment-311422682:84,Availability,failure,failures,84,@mbabadi Can you rebase this onto the latest master (which has a fix for the travis failures) and merge ASAP? Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3140#issuecomment-311422682
https://github.com/broadinstitute/gatk/pull/3140#issuecomment-311466607:29,Availability,failure,failure,29,M2 WDL tests had a transient failure on this branch -- re-running them.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3140#issuecomment-311466607
https://github.com/broadinstitute/gatk/pull/3140#issuecomment-311466607:7,Testability,test,tests,7,M2 WDL tests had a transient failure on this branch -- re-running them.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3140#issuecomment-311466607
https://github.com/broadinstitute/gatk/pull/3140#issuecomment-311484682:61,Availability,error,error,61,"Merging this despite the unrelated ""No space left on device"" error in the M2 WDL tests, which is definitely unrelated to this change.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3140#issuecomment-311484682
https://github.com/broadinstitute/gatk/pull/3140#issuecomment-311484682:81,Testability,test,tests,81,"Merging this despite the unrelated ""No space left on device"" error in the M2 WDL tests, which is definitely unrelated to this change.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3140#issuecomment-311484682
https://github.com/broadinstitute/gatk/pull/3146#issuecomment-310676868:23,Usability,feedback,feedback,23,I've incorporated your feedback @samuelklee. Thanks for the review.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3146#issuecomment-310676868
https://github.com/broadinstitute/gatk/pull/3146#issuecomment-311448971:53,Testability,test,tests,53,"Based on DR's email, I will rebase to get the travis tests going.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3146#issuecomment-311448971
https://github.com/broadinstitute/gatk/pull/3146#issuecomment-311542216:1843,Performance,Perform,PerformSegmentation,1843,/3146?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ellbender/tools/exome/CalculateTargetCoverage.java](https://codecov.io/gh/broadinstitute/gatk/pull/3146?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9DYWxjdWxhdGVUYXJnZXRDb3ZlcmFnZS5qYXZh) | `92.265% <> ()` | `32 <0> ()` | :arrow_down: |; | [...bender/tools/exome/NormalizeSomaticReadCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/3146?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9Ob3JtYWxpemVTb21hdGljUmVhZENvdW50cy5qYXZh) | `77.143% <0%> (-2.024%)` | `10% <0%> (+4%)` | |; | [...bender/tools/exome/germlinehmm/xhmm/XHMMModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/3146?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9nZXJtbGluZWhtbS94aG1tL1hITU1Nb2RlbC5qYXZh) | `100% <0%> ()` | `14% <0%> (+7%)` | :arrow_up: |; | [...te/hellbender/tools/exome/PerformSegmentation.java](https://codecov.io/gh/broadinstitute/gatk/pull/3146?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9QZXJmb3JtU2VnbWVudGF0aW9uLmphdmE=) | `100% <0%> ()` | `6% <0%> (+3%)` | :arrow_up: |; | [...ender/utils/hmm/segmentation/HMMPostProcessor.java](https://codecov.io/gh/broadinstitute/gatk/pull/3146?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9obW0vc2VnbWVudGF0aW9uL0hNTVBvc3RQcm9jZXNzb3IuamF2YQ==) | `85.439% <0%> (+1.215%)` | `92% <0%> (+15%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3146?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `73.649% <0%> (+2.027%)` | `34% <0%> ()` | :arrow_down: |; | [.../coverage/pca/HDF5PCACoveragePoNCreationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3146?src=pr&el=tree#diff-c3,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3146#issuecomment-311542216
https://github.com/broadinstitute/gatk/issues/3151#issuecomment-356736140:15,Usability,learn,learned,15,"I did this and learned some things. However, it will be easier to evaluate the impact of GC correction with a standard evaluation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3151#issuecomment-356736140
https://github.com/broadinstitute/gatk/issues/3153#issuecomment-310507118:653,Modifiability,refactor,refactoring,653,"Also, a necessary functionality is fragment-based counts. Perhaps a good starting point is bringing back Valentin's GATKReadPair which was removed as a part of XHMM-related code cleanup. Eventually, it is also useful to have the option of collecting various summary statistics and empirical distribution for features such as insert length, mapping quality, the position with respect to bins. Other things to consider are summary of orphan reads, reads with mates on other contigs, and reads with multiple alternate alignments. This requires a bit of good software engineering but it's a necessary one-time investment. This is a relatively high-priority refactoring given the growing interest in running gCNV on large datasets (gnomAD, gen psy cohort, TCGA).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3153#issuecomment-310507118
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-316687434:102,Deployability,update,update,102,Fix is merged in htsjdk now https://github.com/samtools/htsjdk/pull/889. I'll keep this open until we update GATK with a new htsjdk.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-316687434
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828:234,Availability,avail,available,234,"Hmm, looks like I deleted the CRAM `/humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/cram/HG02759.alt_bwamem_GRCh38DH.20150826.GWD.exome.cram`. (I was a high storage cost offender and asked to clean up.) Luckily, I have another CRAM available that I left for testing purposes. I can recapitulate the error with this other CRAM using the old `gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT` jar. ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT/gatk-launch PrintReads -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam; ```. Gives the same error at an approximately similar region:; ```; ...; 10:50:54.603 INFO ProgressMeter - chr1:224042054 2.2 11004000 5016945.0; 10:51:04.609 INFO ProgressMeter - chr1:248061327 2.4 11905000 5044206.5; ERROR	2017-10-02 10:51:05	Slice	Reference MD5 mismatch for slice 0:248574592-248771907, AGTGGATGAG...TGTCGGTATG; 10:51:06.940 INFO PrintReads - Shutting down engine; [October 2, 2017 10:51:06 AM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 2.45 minutes.; Runtime.totalMemory()=5995233280; htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248574592, span 197316, expected MD5 cc8ace0545facc11349da783af07a076; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:601); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.hasNext(SAMRecordToReadIterator.java:24); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.cop",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828:301,Availability,error,error,301,"Hmm, looks like I deleted the CRAM `/humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/cram/HG02759.alt_bwamem_GRCh38DH.20150826.GWD.exome.cram`. (I was a high storage cost offender and asked to clean up.) Luckily, I have another CRAM available that I left for testing purposes. I can recapitulate the error with this other CRAM using the old `gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT` jar. ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT/gatk-launch PrintReads -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam; ```. Gives the same error at an approximately similar region:; ```; ...; 10:50:54.603 INFO ProgressMeter - chr1:224042054 2.2 11004000 5016945.0; 10:51:04.609 INFO ProgressMeter - chr1:248061327 2.4 11905000 5044206.5; ERROR	2017-10-02 10:51:05	Slice	Reference MD5 mismatch for slice 0:248574592-248771907, AGTGGATGAG...TGTCGGTATG; 10:51:06.940 INFO PrintReads - Shutting down engine; [October 2, 2017 10:51:06 AM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 2.45 minutes.; Runtime.totalMemory()=5995233280; htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248574592, span 197316, expected MD5 cc8ace0545facc11349da783af07a076; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:601); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.hasNext(SAMRecordToReadIterator.java:24); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.cop",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828:796,Availability,error,error,796,"Hmm, looks like I deleted the CRAM `/humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/cram/HG02759.alt_bwamem_GRCh38DH.20150826.GWD.exome.cram`. (I was a high storage cost offender and asked to clean up.) Luckily, I have another CRAM available that I left for testing purposes. I can recapitulate the error with this other CRAM using the old `gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT` jar. ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT/gatk-launch PrintReads -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam; ```. Gives the same error at an approximately similar region:; ```; ...; 10:50:54.603 INFO ProgressMeter - chr1:224042054 2.2 11004000 5016945.0; 10:51:04.609 INFO ProgressMeter - chr1:248061327 2.4 11905000 5044206.5; ERROR	2017-10-02 10:51:05	Slice	Reference MD5 mismatch for slice 0:248574592-248771907, AGTGGATGAG...TGTCGGTATG; 10:51:06.940 INFO PrintReads - Shutting down engine; [October 2, 2017 10:51:06 AM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 2.45 minutes.; Runtime.totalMemory()=5995233280; htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248574592, span 197316, expected MD5 cc8ace0545facc11349da783af07a076; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:601); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.hasNext(SAMRecordToReadIterator.java:24); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.cop",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828:995,Availability,ERROR,ERROR,995,"/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/cram/HG02759.alt_bwamem_GRCh38DH.20150826.GWD.exome.cram`. (I was a high storage cost offender and asked to clean up.) Luckily, I have another CRAM available that I left for testing purposes. I can recapitulate the error with this other CRAM using the old `gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT` jar. ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT/gatk-launch PrintReads -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam; ```. Gives the same error at an approximately similar region:; ```; ...; 10:50:54.603 INFO ProgressMeter - chr1:224042054 2.2 11004000 5016945.0; 10:51:04.609 INFO ProgressMeter - chr1:248061327 2.4 11905000 5044206.5; ERROR	2017-10-02 10:51:05	Slice	Reference MD5 mismatch for slice 0:248574592-248771907, AGTGGATGAG...TGTCGGTATG; 10:51:06.940 INFO PrintReads - Shutting down engine; [October 2, 2017 10:51:06 AM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 2.45 minutes.; Runtime.totalMemory()=5995233280; htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248574592, span 197316, expected MD5 cc8ace0545facc11349da783af07a076; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:601); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.hasNext(SAMRecordToReadIterator.java:24); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828:1148,Availability,down,down,1148," storage cost offender and asked to clean up.) Luckily, I have another CRAM available that I left for testing purposes. I can recapitulate the error with this other CRAM using the old `gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT` jar. ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT/gatk-launch PrintReads -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam; ```. Gives the same error at an approximately similar region:; ```; ...; 10:50:54.603 INFO ProgressMeter - chr1:224042054 2.2 11004000 5016945.0; 10:51:04.609 INFO ProgressMeter - chr1:248061327 2.4 11905000 5044206.5; ERROR	2017-10-02 10:51:05	Slice	Reference MD5 mismatch for slice 0:248574592-248771907, AGTGGATGAG...TGTCGGTATG; 10:51:06.940 INFO PrintReads - Shutting down engine; [October 2, 2017 10:51:06 AM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 2.45 minutes.; Runtime.totalMemory()=5995233280; htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248574592, span 197316, expected MD5 cc8ace0545facc11349da783af07a076; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:601); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.hasNext(SAMRecordToReadIterator.java:24); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828:4260,Availability,error,error,4260,"(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:779); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:143); 	at org.broadinstitute.hellbender.Main.main(Main.java:221); ```. Now using the latest jar `gatk-4.beta.5` in the same command: . ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch PrintReads -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam; ```. I see that the run goes past the problem region. ; ```; ...; 10:56:39.570 INFO ProgressMeter - chr1:179846959 2.2 9271000 4228249.1; 10:56:49.572 INFO ProgressMeter - chr1:198702508 2.4 9889000 4191438.3; 10:56:59.631 INFO ProgressMeter - chr1:219611298 2.5 10821000 4282152.8; 10:57:09.660 INFO ProgressMeter - chr1:242292327 2.7 11691000 4339428.9; 10:57:19.665 INFO ProgressMeter - chr2:6849819 2.9 12102000 4230137.4; 10:57:29.667 INFO ProgressMeter - chr2:26448455 3.0 12672000 4185516.5; 10:57:39.696 INFO ProgressMeter - chr2:48688700 3.2 13582000 4251349.9; 10:57:49.698 INFO ProgressMeter - chr2:74009861 3.4 14355000 4270478.5; ...; ```; I'll let this finish (and post again if there is an error), but I suspect the issue is solved. Thank you @cmnbroad for the fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828:2073,Integrability,wrap,wrapAndCopyInto,2073,"TGAG...TGTCGGTATG; 10:51:06.940 INFO PrintReads - Shutting down engine; [October 2, 2017 10:51:06 AM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 2.45 minutes.; Runtime.totalMemory()=5995233280; htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248574592, span 197316, expected MD5 cc8ace0545facc11349da783af07a076; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:601); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.hasNext(SAMRecordToReadIterator.java:24); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:779); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:122); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:143); 	at org.broadinstitute.hellbe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828:260,Testability,test,testing,260,"Hmm, looks like I deleted the CRAM `/humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/cram/HG02759.alt_bwamem_GRCh38DH.20150826.GWD.exome.cram`. (I was a high storage cost offender and asked to clean up.) Luckily, I have another CRAM available that I left for testing purposes. I can recapitulate the error with this other CRAM using the old `gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT` jar. ```; -bash-4.1$ /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.alpha.2-1134-ga9d9d91-SNAPSHOT/gatk-launch PrintReads -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -I /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam; ```. Gives the same error at an approximately similar region:; ```; ...; 10:50:54.603 INFO ProgressMeter - chr1:224042054 2.2 11004000 5016945.0; 10:51:04.609 INFO ProgressMeter - chr1:248061327 2.4 11905000 5044206.5; ERROR	2017-10-02 10:51:05	Slice	Reference MD5 mismatch for slice 0:248574592-248771907, AGTGGATGAG...TGTCGGTATG; 10:51:06.940 INFO PrintReads - Shutting down engine; [October 2, 2017 10:51:06 AM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 2.45 minutes.; Runtime.totalMemory()=5995233280; htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248574592, span 197316, expected MD5 cc8ace0545facc11349da783af07a076; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:601); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.hasNext(SAMRecordToReadIterator.java:24); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.cop",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828:1648,Testability,Assert,AssertingIterator,1648,".alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -O /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam; ```. Gives the same error at an approximately similar region:; ```; ...; 10:50:54.603 INFO ProgressMeter - chr1:224042054 2.2 11004000 5016945.0; 10:51:04.609 INFO ProgressMeter - chr1:248061327 2.4 11905000 5044206.5; ERROR	2017-10-02 10:51:05	Slice	Reference MD5 mismatch for slice 0:248574592-248771907, AGTGGATGAG...TGTCGGTATG; 10:51:06.940 INFO PrintReads - Shutting down engine; [October 2, 2017 10:51:06 AM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 2.45 minutes.; Runtime.totalMemory()=5995233280; htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248574592, span 197316, expected MD5 cc8ace0545facc11349da783af07a076; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:601); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.hasNext(SAMRecordToReadIterator.java:24); 	at java.util.Iterator.forEachRemaining(Iterator.java:115); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:779); 	at org.broadinstitute.hellbender.cmdline.CommandLine",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333560828
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333567016:1587,Availability,down,down,1587,"315.4; 11:16:47.479 INFO ProgressMeter - chr6_GL000251v2_alt:3288752 22.3 111608000 4999358.0; 11:16:57.479 INFO ProgressMeter - chr19_KI270915v1_alt:116858 22.5 112656000 5008907.2; 11:17:07.482 INFO ProgressMeter - chr6_GL000252v2_alt:3648002 22.7 113732000 5019540.7; 11:17:17.485 INFO ProgressMeter - chr19_GL000209v2_alt:107854 22.8 114378000 5011183.1; 11:17:27.485 INFO ProgressMeter - chr6_GL000254v2_alt:4706141 23.0 115453000 5021609.7; 11:17:37.489 INFO ProgressMeter - chr6_GL000256v2_alt:3229060 23.2 116516000 5031360.7; 11:17:47.495 INFO ProgressMeter - chrUn_KN707963v1_decoy:59481 23.3 117352000 5031225.8; 11:17:57.500 INFO ProgressMeter - HLA-A*02:53N:2725 23.5 117662000 5008712.4; 11:18:02.114 INFO PrintReads - No reads filtered by: WellformedReadFilter; 11:18:02.114 INFO ProgressMeter - unmapped 23.6 118064258 5009433.9; 11:18:02.114 INFO ProgressMeter - Traversal complete. Processed 118064258 total reads in 23.6 minutes.; 11:18:05.615 INFO PrintReads - Shutting down engine; [October 2, 2017 11:18:05 AM EDT] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 23.67 minutes.; Runtime.totalMemory()=11493965824; ```. And I can view the BAM with Samtools:; ```; samtools view /humgen/gsa-hpprojects/dev/shlee/1kg_GRCh38_exome/test_decram_20171002.bam | less; SRR070790.20928984 99 chr1 10004 0 3S97M = 10036 116 AACCCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAAC <<<<<BFBBBBBFBBBBBBBBBBBFBBBBBFBBBBBBBBBBBBBBBBBBBBBBBBBBBBBFBBBBBBBBB7B<BBBB<F<B<<BBBB<<BFB<770<<<7 MC:Z:61M1D22M17S RG:Z:SRR070790 MQ:i:0 AS:i:97 XS:i:100; SRR070503.24638125 145 chr1 10008 0 100M chr6 8088710 0 AGCCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACC ''''''''''''BBB<<<<7<7<<BBBBFBBBFFBBBBBBFBFBBBFBBBBBFBFBBBFBFBBBF<BBBBFBBBBBFBBBBBFBBBBBFBBBBBB<<<<< RG:Z:SRR070503 MQ:i:60 AS:i:98 XS:i:98; SRR070790.26540140 65 chr1 10016 0 20M3D9M3D13M1I57M chr4 190122739 0 CCCTAACCCTAACCACAAC",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-333567016
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334159313:95,Testability,test,testing,95,"No problem Chris. I'm going to assume we can run on CRAMs any tool that takes a BAM. I will be testing this and if I find otherwise, I'll let the team know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334159313
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334173702:240,Testability,test,tested,240,"@ldgauthier @sooheelee AFAIK, this was the main blocking issue. One caveat though - last week we replaced all of the copies of the Picard tools in GATK with the ACTUAL tools from the Picard jar. The GATK copies were mostly CRAM enabled and tested, but I think the Picard ones have various mixed states wrt read/write capabilities for CRAM.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334173702
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334823449:87,Testability,test,tested,87,"Supposing I wanted to re-run HaplotypeCaller from the CRAM, is that a tool that's been tested with CRAM?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334823449
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334825090:72,Testability,test,testing,72,Related issue <https://github.com/broadinstitute/gatk/issues/3669> from testing CRAM usage.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334825090
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334831157:82,Deployability,integrat,integration,82,"I doubt much CRAM testing has been done with HaplotypeCaller, and I don't see any integration tests for it using CRAM. FWIW, since we have a CRAM version of the BAM we use for those tests, I did just try running them on the CRAM and they passed. As SooHee mentioned though, you'll have issues if the reference you use is in a GCS bucket, or if you specify intervals and the CRAM (and it's index) are in a bucket.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334831157
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334831157:82,Integrability,integrat,integration,82,"I doubt much CRAM testing has been done with HaplotypeCaller, and I don't see any integration tests for it using CRAM. FWIW, since we have a CRAM version of the BAM we use for those tests, I did just try running them on the CRAM and they passed. As SooHee mentioned though, you'll have issues if the reference you use is in a GCS bucket, or if you specify intervals and the CRAM (and it's index) are in a bucket.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334831157
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334831157:18,Testability,test,testing,18,"I doubt much CRAM testing has been done with HaplotypeCaller, and I don't see any integration tests for it using CRAM. FWIW, since we have a CRAM version of the BAM we use for those tests, I did just try running them on the CRAM and they passed. As SooHee mentioned though, you'll have issues if the reference you use is in a GCS bucket, or if you specify intervals and the CRAM (and it's index) are in a bucket.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334831157
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334831157:94,Testability,test,tests,94,"I doubt much CRAM testing has been done with HaplotypeCaller, and I don't see any integration tests for it using CRAM. FWIW, since we have a CRAM version of the BAM we use for those tests, I did just try running them on the CRAM and they passed. As SooHee mentioned though, you'll have issues if the reference you use is in a GCS bucket, or if you specify intervals and the CRAM (and it's index) are in a bucket.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334831157
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334831157:182,Testability,test,tests,182,"I doubt much CRAM testing has been done with HaplotypeCaller, and I don't see any integration tests for it using CRAM. FWIW, since we have a CRAM version of the BAM we use for those tests, I did just try running them on the CRAM and they passed. As SooHee mentioned though, you'll have issues if the reference you use is in a GCS bucket, or if you specify intervals and the CRAM (and it's index) are in a bucket.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334831157
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678:2869,Availability,recover,recoverDanglingHeads,2869,FGQBands 22 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCFGQBands 32 --GVCFGQBands 33 --GVCFGQBands 34 --GVCFGQBands 35 --GVCFGQBands 36 --GVCFGQBands 37 --GVCFGQBands 38 --GVCFGQBands 39 --GVCFGQBands 40 --GVCFGQBands 41 --GVCFGQBands 42 --GVCFGQBands 43 --GVCFGQBands 44 --GVCFGQBands 45 --GVCFGQBands 46 --GVCFGQBands 47 --GVCFGQBands 48 --GVCFGQBands 49 --GVCFGQBands 50 --GVCFGQBands 51 --GVCFGQBands 52 --GVCFGQBands 53 --GVCFGQBands 54 --GVCFGQBands 55 --GVCFGQBands 56 --GVCFGQBands 57 --GVCFGQBands 58 --GVCFGQBands 59 --GVCFGQBands 60 --GVCFGQBands 70 --GVCFGQBands 80 --GVCFGQBands 90 --GVCFGQBands 99 --indelSizeToEliminateInRefModel 10 --useAllelesTrigger false --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotRecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredScaledGlobalReadMismappingRate 45 --nativePairHmmThreads 4 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --emitRefConfidence NONE --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_score 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678:3016,Availability,error,errorCorrectKmers,3016,FGQBands 22 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCFGQBands 32 --GVCFGQBands 33 --GVCFGQBands 34 --GVCFGQBands 35 --GVCFGQBands 36 --GVCFGQBands 37 --GVCFGQBands 38 --GVCFGQBands 39 --GVCFGQBands 40 --GVCFGQBands 41 --GVCFGQBands 42 --GVCFGQBands 43 --GVCFGQBands 44 --GVCFGQBands 45 --GVCFGQBands 46 --GVCFGQBands 47 --GVCFGQBands 48 --GVCFGQBands 49 --GVCFGQBands 50 --GVCFGQBands 51 --GVCFGQBands 52 --GVCFGQBands 53 --GVCFGQBands 54 --GVCFGQBands 55 --GVCFGQBands 56 --GVCFGQBands 57 --GVCFGQBands 58 --GVCFGQBands 59 --GVCFGQBands 60 --GVCFGQBands 70 --GVCFGQBands 80 --GVCFGQBands 90 --GVCFGQBands 99 --indelSizeToEliminateInRefModel 10 --useAllelesTrigger false --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotRecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredScaledGlobalReadMismappingRate 45 --nativePairHmmThreads 4 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --emitRefConfidence NONE --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_score 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678:3681,Availability,error,errorCorrectReads,3681,FGQBands 22 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCFGQBands 32 --GVCFGQBands 33 --GVCFGQBands 34 --GVCFGQBands 35 --GVCFGQBands 36 --GVCFGQBands 37 --GVCFGQBands 38 --GVCFGQBands 39 --GVCFGQBands 40 --GVCFGQBands 41 --GVCFGQBands 42 --GVCFGQBands 43 --GVCFGQBands 44 --GVCFGQBands 45 --GVCFGQBands 46 --GVCFGQBands 47 --GVCFGQBands 48 --GVCFGQBands 49 --GVCFGQBands 50 --GVCFGQBands 51 --GVCFGQBands 52 --GVCFGQBands 53 --GVCFGQBands 54 --GVCFGQBands 55 --GVCFGQBands 56 --GVCFGQBands 57 --GVCFGQBands 58 --GVCFGQBands 59 --GVCFGQBands 60 --GVCFGQBands 70 --GVCFGQBands 80 --GVCFGQBands 90 --GVCFGQBands 99 --indelSizeToEliminateInRefModel 10 --useAllelesTrigger false --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotRecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredScaledGlobalReadMismappingRate 45 --nativePairHmmThreads 4 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --emitRefConfidence NONE --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_score 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678:7110,Availability,Avail,Available,7110,"om intervals; 14:50:18.965 INFO HaplotypeCaller - Done initializing engine; 14:50:19.021 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 14:50:19.280 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 14:50:19.481 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 14:50:19.776 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_utils.so; 14:50:19.795 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 14:50:19.847 WARN IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 14:50:19.848 INFO IntelPairHmm - Available threads: 48; 14:50:19.848 INFO IntelPairHmm - Requested threads: 4; 14:50:19.848 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 14:50:19.926 INFO ProgressMeter - Starting traversal; 14:50:19.926 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 14:50:30.309 INFO ProgressMeter - chr17:740224 0.2 3010 17395.5; 14:50:41.016 INFO ProgressMeter - chr17:1675683 0.4 7020 19973.4; 14:50:51.041 INFO ProgressMeter - chr17:2415218 0.5 10100 19477.4; 14:51:01.041 INFO ProgressMeter - chr17:3591332 0.7 14920 21773.6; 14:51:11.059 INFO ProgressMeter - chr17:4574538 0.9 19100 22412.6; 14:51:21.089 INFO ProgressMeter - chr17:5381890 1.0 22460 22033.3; 14:51:31.097 INFO ProgressMeter - chr17:6474462 1.2 27070 22821.4; 14:51:41.535 INFO ProgressMeter - chr17:7455949 1.4 31150 22902.4; 14:51:51.542 INFO ProgressMeter - chr17:8073825 1.5 33820 22149.2; 14:52:01.549 INFO ProgressMeter - chr17:9138632 1.7 38220 22566.0; ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678:5865,Deployability,patch,patch,5865,"lse --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --gcs_max_retries 20 --disableToolDefaultReadFilters false --minimumMappingQuality 20; [October 6, 2017 2:50:16 PM EDT] Executing as shlee@gsa5.broadinstitute.org on Linux 2.6.32-642.15.1.el6.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Version: 4.beta.5; 14:50:16.818 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 14:50:16.818 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:50:16.818 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:50:16.818 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:50:16.818 INFO HaplotypeCaller - Deflater: IntelDeflater; 14:50:16.818 INFO HaplotypeCaller - Inflater: IntelInflater; 14:50:16.818 INFO HaplotypeCaller - GCS max retries/reopens: 20; 14:50:16.818 INFO HaplotypeCaller - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:50:16.819 INFO HaplotypeCaller - Initializing engine; 14:50:18.950 INFO IntervalArgumentCollection - Processing 83257441 bp from intervals; 14:50:18.965 INFO HaplotypeCaller - Done initializing engine; 14:50:19.021 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 14:50:19.280 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 14:50:19.481 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 14:50:19.776 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_utils.so; 14:50:19.795 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/humgen",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678:993,Performance,Load,Loading,993,"Yes, I have also just tested HaplotypeCaller on a CRAM and it seems to run fine locally.; ```; /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch HaplotypeCaller \; -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; -I HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; -O HG00190_cram_HC.vcf \; -L chr17; ```; gives; ```; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar HaplotypeCaller -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -I HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -O HG00190_cram_HC.vcf -L chr17; 14:50:16.528 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_compression.so; [October 6, 2017 2:50:16 PM EDT] HaplotypeCaller --output HG00190_cram_HC.vcf --intervals chr17 --input HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram --reference /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa --group StandardAnnotation --group StandardHCAnnotation --GVCFGQBands 1 --GVCFGQBands 2 --GVCFGQBands 3 --GVCFGQBands 4 --GVCFGQBands 5 --GVCFGQBands 6 --GVCFGQBands 7 --GVCFGQBands 8 --GVCFGQBands 9 --GVCFGQBands 10 --GVCFGQBands 11 --GVCFGQBands 12 --GVCFGQBands 13 --GVCFGQBands 14 --GVCFGQBands 15 --GVCFGQBands 16 --GVCFGQBands 17 --GVCFGQBands 18 --GVCFGQBands 19 --GVCFGQBands 20 --GVCFGQBands 21 --GVCFGQBands 22 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCF",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678:6625,Performance,Load,Loading,6625,":50:16.818 INFO HaplotypeCaller - Deflater: IntelDeflater; 14:50:16.818 INFO HaplotypeCaller - Inflater: IntelInflater; 14:50:16.818 INFO HaplotypeCaller - GCS max retries/reopens: 20; 14:50:16.818 INFO HaplotypeCaller - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:50:16.819 INFO HaplotypeCaller - Initializing engine; 14:50:18.950 INFO IntervalArgumentCollection - Processing 83257441 bp from intervals; 14:50:18.965 INFO HaplotypeCaller - Done initializing engine; 14:50:19.021 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 14:50:19.280 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 14:50:19.481 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 14:50:19.776 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_utils.so; 14:50:19.795 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 14:50:19.847 WARN IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 14:50:19.848 INFO IntelPairHmm - Available threads: 48; 14:50:19.848 INFO IntelPairHmm - Requested threads: 4; 14:50:19.848 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 14:50:19.926 INFO ProgressMeter - Starting traversal; 14:50:19.926 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 14:50:30.309 INFO ProgressMeter - chr17:740224 0.2 3010 17395.5; 14:50:41.016 INFO ProgressMeter - chr17:1675683 0.4 7020 19973.4; 14:50:51.041 INFO ProgressMeter - chr17:24",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678:6822,Performance,Load,Loading,6822,"FO HaplotypeCaller - Using google-cloud-java patch c035098b5e62cb4fe9155eff07ce88449a361f5d from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 14:50:16.819 INFO HaplotypeCaller - Initializing engine; 14:50:18.950 INFO IntervalArgumentCollection - Processing 83257441 bp from intervals; 14:50:18.965 INFO HaplotypeCaller - Done initializing engine; 14:50:19.021 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; 14:50:19.280 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 14:50:19.481 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 14:50:19.776 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_utils.so; 14:50:19.795 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 14:50:19.847 WARN IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 14:50:19.848 INFO IntelPairHmm - Available threads: 48; 14:50:19.848 INFO IntelPairHmm - Requested threads: 4; 14:50:19.848 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 14:50:19.926 INFO ProgressMeter - Starting traversal; 14:50:19.926 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 14:50:30.309 INFO ProgressMeter - chr17:740224 0.2 3010 17395.5; 14:50:41.016 INFO ProgressMeter - chr17:1675683 0.4 7020 19973.4; 14:50:51.041 INFO ProgressMeter - chr17:2415218 0.5 10100 19477.4; 14:51:01.041 INFO ProgressMeter - chr17:3591332 0.7 14920 21773.6; 14:51:11.059 INFO ProgressMeter - chr17:4574538 0.9 19100 22412.6; 14:51:21.089 INFO ProgressMeter - chr17:5",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678:7233,Performance,multi-thread,multi-threaded,7233," phasing, which is supported only for reference-model confidence output; 14:50:19.280 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 14:50:19.481 WARN PossibleDeNovo - Annotation will not be calculated, must provide a valid PED file (-ped) from the command line.; 14:50:19.776 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_utils.so; 14:50:19.795 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 14:50:19.847 WARN IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 14:50:19.848 INFO IntelPairHmm - Available threads: 48; 14:50:19.848 INFO IntelPairHmm - Requested threads: 4; 14:50:19.848 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 14:50:19.926 INFO ProgressMeter - Starting traversal; 14:50:19.926 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 14:50:30.309 INFO ProgressMeter - chr17:740224 0.2 3010 17395.5; 14:50:41.016 INFO ProgressMeter - chr17:1675683 0.4 7020 19973.4; 14:50:51.041 INFO ProgressMeter - chr17:2415218 0.5 10100 19477.4; 14:51:01.041 INFO ProgressMeter - chr17:3591332 0.7 14920 21773.6; 14:51:11.059 INFO ProgressMeter - chr17:4574538 0.9 19100 22412.6; 14:51:21.089 INFO ProgressMeter - chr17:5381890 1.0 22460 22033.3; 14:51:31.097 INFO ProgressMeter - chr17:6474462 1.2 27070 22821.4; 14:51:41.535 INFO ProgressMeter - chr17:7455949 1.4 31150 22902.4; 14:51:51.542 INFO ProgressMeter - chr17:8073825 1.5 33820 22149.2; 14:52:01.549 INFO ProgressMeter - chr17:9138632 1.7 38220 22566.0; 14:52:11.962 INFO ProgressMeter - chr17:10514361 1.9 43840 23478.4; 14:52:21.975 INFO ProgressMeter - chr17:11679575 2.0 48560 23872.6; 1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678:2869,Safety,recover,recoverDanglingHeads,2869,FGQBands 22 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCFGQBands 32 --GVCFGQBands 33 --GVCFGQBands 34 --GVCFGQBands 35 --GVCFGQBands 36 --GVCFGQBands 37 --GVCFGQBands 38 --GVCFGQBands 39 --GVCFGQBands 40 --GVCFGQBands 41 --GVCFGQBands 42 --GVCFGQBands 43 --GVCFGQBands 44 --GVCFGQBands 45 --GVCFGQBands 46 --GVCFGQBands 47 --GVCFGQBands 48 --GVCFGQBands 49 --GVCFGQBands 50 --GVCFGQBands 51 --GVCFGQBands 52 --GVCFGQBands 53 --GVCFGQBands 54 --GVCFGQBands 55 --GVCFGQBands 56 --GVCFGQBands 57 --GVCFGQBands 58 --GVCFGQBands 59 --GVCFGQBands 60 --GVCFGQBands 70 --GVCFGQBands 80 --GVCFGQBands 90 --GVCFGQBands 99 --indelSizeToEliminateInRefModel 10 --useAllelesTrigger false --dontTrimActiveRegions false --maxDiscARExtension 25 --maxGGAARExtension 300 --paddingAroundIndels 150 --paddingAroundSNPs 20 --kmerSize 10 --kmerSize 25 --dontIncreaseKmerSizesForCycles false --allowNonUniqueKmersInRef false --numPruningSamples 1 --recoverDanglingHeads false --doNotRecoverDanglingBranches false --minDanglingBranchLength 4 --consensus false --maxNumHaplotypesInPopulation 128 --errorCorrectKmers false --minPruning 2 --debugGraphTransformations false --kmerLengthForReadErrorCorrection 25 --minObservationsForKmerToBeSolid 20 --likelihoodCalculationEngine PairHMM --base_quality_score_threshold 18 --gcpHMM 10 --pair_hmm_implementation FASTEST_AVAILABLE --pcr_indel_model CONSERVATIVE --phredScaledGlobalReadMismappingRate 45 --nativePairHmmThreads 4 --useDoublePrecision false --debug false --useFilteredReadsForAnnotations false --emitRefConfidence NONE --bamWriterType CALLED_HAPLOTYPES --disableOptimizations false --justDetermineActiveRegions false --dontGenotype false --dontUseSoftClippedBases false --captureAssemblyFailureBAM false --errorCorrectReads false --doNotRunPhysicalPhasing false --min_base_quality_score 10 --useNewAFCalculator false --annotateNDA false --heterozygosity 0.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678:22,Testability,test,tested,22,"Yes, I have also just tested HaplotypeCaller on a CRAM and it seems to run fine locally.; ```; /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-launch HaplotypeCaller \; -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa \; -I HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram \; -O HG00190_cram_HC.vcf \; -L chr17; ```; gives; ```; Using GATK jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -jar /humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar HaplotypeCaller -R /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa -I HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram -O HG00190_cram_HC.vcf -L chr17; 14:50:16.528 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/humgen/gsa-hpprojects/GATK/gatk4/gatk-4.beta.5/gatk-package-4.beta.5-local.jar!/com/intel/gkl/native/libgkl_compression.so; [October 6, 2017 2:50:16 PM EDT] HaplotypeCaller --output HG00190_cram_HC.vcf --intervals chr17 --input HG00190.alt_bwamem_GRCh38DH.20150826.FIN.exome.cram --reference /humgen/gsa-hpprojects/dev/shlee/ref/GRCh38_1kg/GRCh38_full_analysis_set_plus_decoy_hla.fa --group StandardAnnotation --group StandardHCAnnotation --GVCFGQBands 1 --GVCFGQBands 2 --GVCFGQBands 3 --GVCFGQBands 4 --GVCFGQBands 5 --GVCFGQBands 6 --GVCFGQBands 7 --GVCFGQBands 8 --GVCFGQBands 9 --GVCFGQBands 10 --GVCFGQBands 11 --GVCFGQBands 12 --GVCFGQBands 13 --GVCFGQBands 14 --GVCFGQBands 15 --GVCFGQBands 16 --GVCFGQBands 17 --GVCFGQBands 18 --GVCFGQBands 19 --GVCFGQBands 20 --GVCFGQBands 21 --GVCFGQBands 22 --GVCFGQBands 23 --GVCFGQBands 24 --GVCFGQBands 25 --GVCFGQBands 26 --GVCFGQBands 27 --GVCFGQBands 28 --GVCFGQBands 29 --GVCFGQBands 30 --GVCFGQBands 31 --GVCF",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-334840678
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1413175981:78,Deployability,upgrade,upgrade,78,@NeginValizadegan If you really mean picard 2.10.1 then you should definitely upgrade. That version is ancient. The current is [2.27.5](https://github.com/broadinstitute/picard/releases),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1413175981
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1413175981:177,Deployability,release,releases,177,@NeginValizadegan If you really mean picard 2.10.1 then you should definitely upgrade. That version is ancient. The current is [2.27.5](https://github.com/broadinstitute/picard/releases),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1413175981
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1413949994:102,Availability,error,error,102,"Yes our cluster had this version. I asked them to upgrade it to 2.27.5 and tried that one. Still same error at the same exact chromosome location:. `ERROR	2023-02-01 16:32:52	Slice	Reference MD5 mismatch for slice 0:248735807-248774361, AAGATTTGTG...AAGTCTAAGC; [Wed Feb 01 16:32:52 CST 2023] picard.analysis.CollectInsertSizeMetrics done. Elapsed time: 4.70 minutes.; Runtime.totalMemory()=5790236672; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; Exception in thread ""main"" htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248735807, span 38555, expected MD5 51a4da6ed30bd549660b19193faae437; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:592); 	at picard.analysis.SinglePassSamProgram.makeItSo(SinglePassSamProgram.java:129); 	at picard.analysis.SinglePassSamProgram.doWork(SinglePassSamProgram.java:77); 	at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:205); 	at picard.cmdline.PicardCommandLine.instanceMain(PicardCommandLine.java:94); 	at picard.cmdline.PicardCommandLine.main(PicardCommandLine.java:104)`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1413949994
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1413949994:149,Availability,ERROR,ERROR,149,"Yes our cluster had this version. I asked them to upgrade it to 2.27.5 and tried that one. Still same error at the same exact chromosome location:. `ERROR	2023-02-01 16:32:52	Slice	Reference MD5 mismatch for slice 0:248735807-248774361, AAGATTTGTG...AAGTCTAAGC; [Wed Feb 01 16:32:52 CST 2023] picard.analysis.CollectInsertSizeMetrics done. Elapsed time: 4.70 minutes.; Runtime.totalMemory()=5790236672; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; Exception in thread ""main"" htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248735807, span 38555, expected MD5 51a4da6ed30bd549660b19193faae437; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:592); 	at picard.analysis.SinglePassSamProgram.makeItSo(SinglePassSamProgram.java:129); 	at picard.analysis.SinglePassSamProgram.doWork(SinglePassSamProgram.java:77); 	at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:205); 	at picard.cmdline.PicardCommandLine.instanceMain(PicardCommandLine.java:94); 	at picard.cmdline.PicardCommandLine.main(PicardCommandLine.java:104)`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1413949994
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1413949994:50,Deployability,upgrade,upgrade,50,"Yes our cluster had this version. I asked them to upgrade it to 2.27.5 and tried that one. Still same error at the same exact chromosome location:. `ERROR	2023-02-01 16:32:52	Slice	Reference MD5 mismatch for slice 0:248735807-248774361, AAGATTTGTG...AAGTCTAAGC; [Wed Feb 01 16:32:52 CST 2023] picard.analysis.CollectInsertSizeMetrics done. Elapsed time: 4.70 minutes.; Runtime.totalMemory()=5790236672; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; Exception in thread ""main"" htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248735807, span 38555, expected MD5 51a4da6ed30bd549660b19193faae437; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:592); 	at picard.analysis.SinglePassSamProgram.makeItSo(SinglePassSamProgram.java:129); 	at picard.analysis.SinglePassSamProgram.doWork(SinglePassSamProgram.java:77); 	at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:205); 	at picard.cmdline.PicardCommandLine.instanceMain(PicardCommandLine.java:94); 	at picard.cmdline.PicardCommandLine.main(PicardCommandLine.java:104)`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1413949994
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1413949994:846,Testability,Assert,AssertingIterator,846,"Yes our cluster had this version. I asked them to upgrade it to 2.27.5 and tried that one. Still same error at the same exact chromosome location:. `ERROR	2023-02-01 16:32:52	Slice	Reference MD5 mismatch for slice 0:248735807-248774361, AAGATTTGTG...AAGTCTAAGC; [Wed Feb 01 16:32:52 CST 2023] picard.analysis.CollectInsertSizeMetrics done. Elapsed time: 4.70 minutes.; Runtime.totalMemory()=5790236672; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; Exception in thread ""main"" htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248735807, span 38555, expected MD5 51a4da6ed30bd549660b19193faae437; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:592); 	at picard.analysis.SinglePassSamProgram.makeItSo(SinglePassSamProgram.java:129); 	at picard.analysis.SinglePassSamProgram.doWork(SinglePassSamProgram.java:77); 	at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:205); 	at picard.cmdline.PicardCommandLine.instanceMain(PicardCommandLine.java:94); 	at picard.cmdline.PicardCommandLine.main(PicardCommandLine.java:104)`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1413949994
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414024739:97,Availability,error,error,97,"@NeginValizadegan Thanks for looking into it, and sorry you're still seeing the issue. . Is that error message from the 2.10.1 version? It doesn't line up with the code in 2.27.1 so either you're posting your original error, or you're not getting the version of picard you expect. Would it be possible to include the entire program log, and the command line to run it here?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414024739
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414024739:218,Availability,error,error,218,"@NeginValizadegan Thanks for looking into it, and sorry you're still seeing the issue. . Is that error message from the 2.10.1 version? It doesn't line up with the code in 2.27.1 so either you're posting your original error, or you're not getting the version of picard you expect. Would it be possible to include the entire program log, and the command line to run it here?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414024739
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414024739:103,Integrability,message,message,103,"@NeginValizadegan Thanks for looking into it, and sorry you're still seeing the issue. . Is that error message from the 2.10.1 version? It doesn't line up with the code in 2.27.1 so either you're posting your original error, or you're not getting the version of picard you expect. Would it be possible to include the entire program log, and the command line to run it here?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414024739
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414024739:332,Testability,log,log,332,"@NeginValizadegan Thanks for looking into it, and sorry you're still seeing the issue. . Is that error message from the 2.10.1 version? It doesn't line up with the code in 2.27.1 so either you're posting your original error, or you're not getting the version of picard you expect. Would it be possible to include the entire program log, and the command line to run it here?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414024739
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414237417:24,Availability,error,error,24,"> . @lbergelson Yes the error was from a previous version as I didn't have the new error recorded. I ran it again and here is the code and error. Just for clarity, I simplified the code paste here, removed long paths and stuff but some of those are shown in the error. Thanks!. `java -jar /home/apps/software/picard/2.27.5-Java-1.8.0_201/picard.jar CollectInsertSizeMetrics \; I=HG03125.final.cram \; O=insertSize_metrics.txt \; H=insertSize_hist.pdf \; R=GRCh38_full_analysis_set_plus_decoy_hla.fa \; M=0.5`. `[Thu Feb 02 13:05:04 CST 2023] picard.analysis.CollectInsertSizeMetrics HISTOGRAM_FILE=results/bowtie2/assembly/Read-Prep/Bowtie/Aligned/stats/HG03125_insertSize_hist.pdf MINIMUM_PCT=0.5 INPUT=./crams/AFR/HG03125.final.cram OUTPUT=results/bowtie2/assembly/Read-Prep/Bowtie/Aligned/stats/HG03125_insertSize_metrics.txt REFERENCE_SEQUENCE=/home/groups/h3abionet/RefGraph/data/genomes/human/GRCh38/GRCh38_full_analysis_set_plus_decoy_hla.fa DEVIATIONS=10.0 METRIC_ACCUMULATION_LEVEL=[ALL_READS] INCLUDE_DUPLICATES=false ASSUME_SORTED=true STOP_AFTER=0 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json; [Thu Feb 02 13:05:04 CST 2023] Executing as valizad2@compute-5-1 on Linux 4.18.0-348.23.1.el8_5.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_201-b09; Picard version: 2.9.0-1-gf5b9f50-SNAPSHOT; INFO	2023-02-02 13:05:15	SinglePassSamProgram	Processed 1,000,000 records. Elapsed time: 00:00:11s. Time for last 1,000,000: 6s. Last read position: chr1:3,185,445; INFO	2023-02-02 13:05:20	SinglePassSamProgram	Processed 2,000,000 records. Elapsed time: 00:00:16s. Time for last 1,000,000: 5s. Last read position: chr1:6,814,058; INFO	2023-02-02 13:05:25	SinglePassSamProgram	Processed 3,000,000 records. Elapsed time: 00:00:21s. Time for last 1,000,000: 4s. Last read position: chr1:10,463,599; INFO	2023-02-02 13:05:30	SinglePassSamProgram	Processed 4,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414237417
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414237417:83,Availability,error,error,83,"> . @lbergelson Yes the error was from a previous version as I didn't have the new error recorded. I ran it again and here is the code and error. Just for clarity, I simplified the code paste here, removed long paths and stuff but some of those are shown in the error. Thanks!. `java -jar /home/apps/software/picard/2.27.5-Java-1.8.0_201/picard.jar CollectInsertSizeMetrics \; I=HG03125.final.cram \; O=insertSize_metrics.txt \; H=insertSize_hist.pdf \; R=GRCh38_full_analysis_set_plus_decoy_hla.fa \; M=0.5`. `[Thu Feb 02 13:05:04 CST 2023] picard.analysis.CollectInsertSizeMetrics HISTOGRAM_FILE=results/bowtie2/assembly/Read-Prep/Bowtie/Aligned/stats/HG03125_insertSize_hist.pdf MINIMUM_PCT=0.5 INPUT=./crams/AFR/HG03125.final.cram OUTPUT=results/bowtie2/assembly/Read-Prep/Bowtie/Aligned/stats/HG03125_insertSize_metrics.txt REFERENCE_SEQUENCE=/home/groups/h3abionet/RefGraph/data/genomes/human/GRCh38/GRCh38_full_analysis_set_plus_decoy_hla.fa DEVIATIONS=10.0 METRIC_ACCUMULATION_LEVEL=[ALL_READS] INCLUDE_DUPLICATES=false ASSUME_SORTED=true STOP_AFTER=0 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json; [Thu Feb 02 13:05:04 CST 2023] Executing as valizad2@compute-5-1 on Linux 4.18.0-348.23.1.el8_5.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_201-b09; Picard version: 2.9.0-1-gf5b9f50-SNAPSHOT; INFO	2023-02-02 13:05:15	SinglePassSamProgram	Processed 1,000,000 records. Elapsed time: 00:00:11s. Time for last 1,000,000: 6s. Last read position: chr1:3,185,445; INFO	2023-02-02 13:05:20	SinglePassSamProgram	Processed 2,000,000 records. Elapsed time: 00:00:16s. Time for last 1,000,000: 5s. Last read position: chr1:6,814,058; INFO	2023-02-02 13:05:25	SinglePassSamProgram	Processed 3,000,000 records. Elapsed time: 00:00:21s. Time for last 1,000,000: 4s. Last read position: chr1:10,463,599; INFO	2023-02-02 13:05:30	SinglePassSamProgram	Processed 4,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414237417
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414237417:139,Availability,error,error,139,"> . @lbergelson Yes the error was from a previous version as I didn't have the new error recorded. I ran it again and here is the code and error. Just for clarity, I simplified the code paste here, removed long paths and stuff but some of those are shown in the error. Thanks!. `java -jar /home/apps/software/picard/2.27.5-Java-1.8.0_201/picard.jar CollectInsertSizeMetrics \; I=HG03125.final.cram \; O=insertSize_metrics.txt \; H=insertSize_hist.pdf \; R=GRCh38_full_analysis_set_plus_decoy_hla.fa \; M=0.5`. `[Thu Feb 02 13:05:04 CST 2023] picard.analysis.CollectInsertSizeMetrics HISTOGRAM_FILE=results/bowtie2/assembly/Read-Prep/Bowtie/Aligned/stats/HG03125_insertSize_hist.pdf MINIMUM_PCT=0.5 INPUT=./crams/AFR/HG03125.final.cram OUTPUT=results/bowtie2/assembly/Read-Prep/Bowtie/Aligned/stats/HG03125_insertSize_metrics.txt REFERENCE_SEQUENCE=/home/groups/h3abionet/RefGraph/data/genomes/human/GRCh38/GRCh38_full_analysis_set_plus_decoy_hla.fa DEVIATIONS=10.0 METRIC_ACCUMULATION_LEVEL=[ALL_READS] INCLUDE_DUPLICATES=false ASSUME_SORTED=true STOP_AFTER=0 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json; [Thu Feb 02 13:05:04 CST 2023] Executing as valizad2@compute-5-1 on Linux 4.18.0-348.23.1.el8_5.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_201-b09; Picard version: 2.9.0-1-gf5b9f50-SNAPSHOT; INFO	2023-02-02 13:05:15	SinglePassSamProgram	Processed 1,000,000 records. Elapsed time: 00:00:11s. Time for last 1,000,000: 6s. Last read position: chr1:3,185,445; INFO	2023-02-02 13:05:20	SinglePassSamProgram	Processed 2,000,000 records. Elapsed time: 00:00:16s. Time for last 1,000,000: 5s. Last read position: chr1:6,814,058; INFO	2023-02-02 13:05:25	SinglePassSamProgram	Processed 3,000,000 records. Elapsed time: 00:00:21s. Time for last 1,000,000: 4s. Last read position: chr1:10,463,599; INFO	2023-02-02 13:05:30	SinglePassSamProgram	Processed 4,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414237417
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414237417:262,Availability,error,error,262,"> . @lbergelson Yes the error was from a previous version as I didn't have the new error recorded. I ran it again and here is the code and error. Just for clarity, I simplified the code paste here, removed long paths and stuff but some of those are shown in the error. Thanks!. `java -jar /home/apps/software/picard/2.27.5-Java-1.8.0_201/picard.jar CollectInsertSizeMetrics \; I=HG03125.final.cram \; O=insertSize_metrics.txt \; H=insertSize_hist.pdf \; R=GRCh38_full_analysis_set_plus_decoy_hla.fa \; M=0.5`. `[Thu Feb 02 13:05:04 CST 2023] picard.analysis.CollectInsertSizeMetrics HISTOGRAM_FILE=results/bowtie2/assembly/Read-Prep/Bowtie/Aligned/stats/HG03125_insertSize_hist.pdf MINIMUM_PCT=0.5 INPUT=./crams/AFR/HG03125.final.cram OUTPUT=results/bowtie2/assembly/Read-Prep/Bowtie/Aligned/stats/HG03125_insertSize_metrics.txt REFERENCE_SEQUENCE=/home/groups/h3abionet/RefGraph/data/genomes/human/GRCh38/GRCh38_full_analysis_set_plus_decoy_hla.fa DEVIATIONS=10.0 METRIC_ACCUMULATION_LEVEL=[ALL_READS] INCLUDE_DUPLICATES=false ASSUME_SORTED=true STOP_AFTER=0 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json; [Thu Feb 02 13:05:04 CST 2023] Executing as valizad2@compute-5-1 on Linux 4.18.0-348.23.1.el8_5.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_201-b09; Picard version: 2.9.0-1-gf5b9f50-SNAPSHOT; INFO	2023-02-02 13:05:15	SinglePassSamProgram	Processed 1,000,000 records. Elapsed time: 00:00:11s. Time for last 1,000,000: 6s. Last read position: chr1:3,185,445; INFO	2023-02-02 13:05:20	SinglePassSamProgram	Processed 2,000,000 records. Elapsed time: 00:00:16s. Time for last 1,000,000: 5s. Last read position: chr1:6,814,058; INFO	2023-02-02 13:05:25	SinglePassSamProgram	Processed 3,000,000 records. Elapsed time: 00:00:21s. Time for last 1,000,000: 4s. Last read position: chr1:10,463,599; INFO	2023-02-02 13:05:30	SinglePassSamProgram	Processed 4,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414237417
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414237417:11827,Availability,ERROR,ERROR,11827,"Program	Processed 57,000,000 records. Elapsed time: 00:04:45s. Time for last 1,000,000: 5s. Last read position: chr1:225,314,304; INFO	2023-02-02 13:09:54	SinglePassSamProgram	Processed 58,000,000 records. Elapsed time: 00:04:49s. Time for last 1,000,000: 4s. Last read position: chr1:228,891,181; INFO	2023-02-02 13:09:58	SinglePassSamProgram	Processed 59,000,000 records. Elapsed time: 00:04:54s. Time for last 1,000,000: 4s. Last read position: chr1:232,844,624; INFO	2023-02-02 13:10:03	SinglePassSamProgram	Processed 60,000,000 records. Elapsed time: 00:04:59s. Time for last 1,000,000: 4s. Last read position: chr1:236,642,862; INFO	2023-02-02 13:10:08	SinglePassSamProgram	Processed 61,000,000 records. Elapsed time: 00:05:03s. Time for last 1,000,000: 4s. Last read position: chr1:241,003,784; INFO	2023-02-02 13:10:13	SinglePassSamProgram	Processed 62,000,000 records. Elapsed time: 00:05:08s. Time for last 1,000,000: 5s. Last read position: chr1:245,019,923; ERROR	2023-02-02 13:10:18	Slice	Reference MD5 mismatch for slice 0:248741017-248780008, GATGGGAGAT...AGGGAAATAT; [Thu Feb 02 13:10:18 CST 2023] picard.analysis.CollectInsertSizeMetrics done. Elapsed time: 5.23 minutes.; Runtime.totalMemory()=5051514880; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; Exception in thread ""main"" htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248741017, span 38992, expected MD5 37a71701c8b7513578af280cdbcc4bda; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:592); 	at picard.analysis.SinglePassSamProgram.makeItSo(SinglePassSamProgram.java:129); 	at picard.analysis.SinglePassSamProgram.doWork(SinglePassSamProgram.java:77); 	at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:205); 	at picard.cmdline.PicardCommandLine.instanc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414237417
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414237417:12524,Testability,Assert,AssertingIterator,12524,"sition: chr1:225,314,304; INFO	2023-02-02 13:09:54	SinglePassSamProgram	Processed 58,000,000 records. Elapsed time: 00:04:49s. Time for last 1,000,000: 4s. Last read position: chr1:228,891,181; INFO	2023-02-02 13:09:58	SinglePassSamProgram	Processed 59,000,000 records. Elapsed time: 00:04:54s. Time for last 1,000,000: 4s. Last read position: chr1:232,844,624; INFO	2023-02-02 13:10:03	SinglePassSamProgram	Processed 60,000,000 records. Elapsed time: 00:04:59s. Time for last 1,000,000: 4s. Last read position: chr1:236,642,862; INFO	2023-02-02 13:10:08	SinglePassSamProgram	Processed 61,000,000 records. Elapsed time: 00:05:03s. Time for last 1,000,000: 4s. Last read position: chr1:241,003,784; INFO	2023-02-02 13:10:13	SinglePassSamProgram	Processed 62,000,000 records. Elapsed time: 00:05:08s. Time for last 1,000,000: 5s. Last read position: chr1:245,019,923; ERROR	2023-02-02 13:10:18	Slice	Reference MD5 mismatch for slice 0:248741017-248780008, GATGGGAGAT...AGGGAAATAT; [Thu Feb 02 13:10:18 CST 2023] picard.analysis.CollectInsertSizeMetrics done. Elapsed time: 5.23 minutes.; Runtime.totalMemory()=5051514880; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; Exception in thread ""main"" htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 248741017, span 38992, expected MD5 37a71701c8b7513578af280cdbcc4bda; 	at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:187); 	at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:261); 	at htsjdk.samtools.SamReader$AssertingIterator.hasNext(SamReader.java:592); 	at picard.analysis.SinglePassSamProgram.makeItSo(SinglePassSamProgram.java:129); 	at picard.analysis.SinglePassSamProgram.doWork(SinglePassSamProgram.java:77); 	at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:205); 	at picard.cmdline.PicardCommandLine.instanceMain(PicardCommandLine.java:94); 	at picard.cmdline.PicardCommandLine.main(PicardCommandLine.java:104)`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414237417
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414237417:166,Usability,simpl,simplified,166,"> . @lbergelson Yes the error was from a previous version as I didn't have the new error recorded. I ran it again and here is the code and error. Just for clarity, I simplified the code paste here, removed long paths and stuff but some of those are shown in the error. Thanks!. `java -jar /home/apps/software/picard/2.27.5-Java-1.8.0_201/picard.jar CollectInsertSizeMetrics \; I=HG03125.final.cram \; O=insertSize_metrics.txt \; H=insertSize_hist.pdf \; R=GRCh38_full_analysis_set_plus_decoy_hla.fa \; M=0.5`. `[Thu Feb 02 13:05:04 CST 2023] picard.analysis.CollectInsertSizeMetrics HISTOGRAM_FILE=results/bowtie2/assembly/Read-Prep/Bowtie/Aligned/stats/HG03125_insertSize_hist.pdf MINIMUM_PCT=0.5 INPUT=./crams/AFR/HG03125.final.cram OUTPUT=results/bowtie2/assembly/Read-Prep/Bowtie/Aligned/stats/HG03125_insertSize_metrics.txt REFERENCE_SEQUENCE=/home/groups/h3abionet/RefGraph/data/genomes/human/GRCh38/GRCh38_full_analysis_set_plus_decoy_hla.fa DEVIATIONS=10.0 METRIC_ACCUMULATION_LEVEL=[ALL_READS] INCLUDE_DUPLICATES=false ASSUME_SORTED=true STOP_AFTER=0 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json; [Thu Feb 02 13:05:04 CST 2023] Executing as valizad2@compute-5-1 on Linux 4.18.0-348.23.1.el8_5.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_201-b09; Picard version: 2.9.0-1-gf5b9f50-SNAPSHOT; INFO	2023-02-02 13:05:15	SinglePassSamProgram	Processed 1,000,000 records. Elapsed time: 00:00:11s. Time for last 1,000,000: 6s. Last read position: chr1:3,185,445; INFO	2023-02-02 13:05:20	SinglePassSamProgram	Processed 2,000,000 records. Elapsed time: 00:00:16s. Time for last 1,000,000: 5s. Last read position: chr1:6,814,058; INFO	2023-02-02 13:05:25	SinglePassSamProgram	Processed 3,000,000 records. Elapsed time: 00:00:21s. Time for last 1,000,000: 4s. Last read position: chr1:10,463,599; INFO	2023-02-02 13:05:30	SinglePassSamProgram	Processed 4,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1414237417
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1416093097:13,Availability,error,error,13,The previous error was for another sample too. The was the only one I had recorded. That's why the chr position are not exactly the same,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1416093097
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419101274:102,Availability,error,error,102,@NeginValizadegan For some reason you appear to be running very old Picard versions. This most recent error message you posted is coming from an even older version of Picard (`2.9.0-1-gf5b9f50-SNAPSHOT`) than the first one you posted (which you said was `2.10.1`). I would suggest upgrading to [2.27.5](https://github.com/broadinstitute/picard/releases).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419101274
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419101274:344,Deployability,release,releases,344,@NeginValizadegan For some reason you appear to be running very old Picard versions. This most recent error message you posted is coming from an even older version of Picard (`2.9.0-1-gf5b9f50-SNAPSHOT`) than the first one you posted (which you said was `2.10.1`). I would suggest upgrading to [2.27.5](https://github.com/broadinstitute/picard/releases).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419101274
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419101274:108,Integrability,message,message,108,@NeginValizadegan For some reason you appear to be running very old Picard versions. This most recent error message you posted is coming from an even older version of Picard (`2.9.0-1-gf5b9f50-SNAPSHOT`) than the first one you posted (which you said was `2.10.1`). I would suggest upgrading to [2.27.5](https://github.com/broadinstitute/picard/releases).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419101274
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419783633:69,Availability,down,downloaded,69,"Okay apparently there is not a version number in the picard.jar file downloaded from https://github.com/broadinstitute/picard/releases and thus if easybuild detects a cache copy, it will use that instead of downloading it which was an older version. They forced it to download and now version is correct. I will re-try and see if the error persists. Thanks for catching that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419783633
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419783633:207,Availability,down,downloading,207,"Okay apparently there is not a version number in the picard.jar file downloaded from https://github.com/broadinstitute/picard/releases and thus if easybuild detects a cache copy, it will use that instead of downloading it which was an older version. They forced it to download and now version is correct. I will re-try and see if the error persists. Thanks for catching that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419783633
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419783633:268,Availability,down,download,268,"Okay apparently there is not a version number in the picard.jar file downloaded from https://github.com/broadinstitute/picard/releases and thus if easybuild detects a cache copy, it will use that instead of downloading it which was an older version. They forced it to download and now version is correct. I will re-try and see if the error persists. Thanks for catching that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419783633
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419783633:334,Availability,error,error,334,"Okay apparently there is not a version number in the picard.jar file downloaded from https://github.com/broadinstitute/picard/releases and thus if easybuild detects a cache copy, it will use that instead of downloading it which was an older version. They forced it to download and now version is correct. I will re-try and see if the error persists. Thanks for catching that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419783633
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419783633:126,Deployability,release,releases,126,"Okay apparently there is not a version number in the picard.jar file downloaded from https://github.com/broadinstitute/picard/releases and thus if easybuild detects a cache copy, it will use that instead of downloading it which was an older version. They forced it to download and now version is correct. I will re-try and see if the error persists. Thanks for catching that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419783633
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419783633:167,Performance,cache,cache,167,"Okay apparently there is not a version number in the picard.jar file downloaded from https://github.com/broadinstitute/picard/releases and thus if easybuild detects a cache copy, it will use that instead of downloading it which was an older version. They forced it to download and now version is correct. I will re-try and see if the error persists. Thanks for catching that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419783633
https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419783633:157,Safety,detect,detects,157,"Okay apparently there is not a version number in the picard.jar file downloaded from https://github.com/broadinstitute/picard/releases and thus if easybuild detects a cache copy, it will use that instead of downloading it which was an older version. They forced it to download and now version is correct. I will re-try and see if the error persists. Thanks for catching that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3154#issuecomment-1419783633
https://github.com/broadinstitute/gatk/issues/3156#issuecomment-310684230:28,Testability,test,tests,28,The PR is undergoing Travis tests.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3156#issuecomment-310684230
https://github.com/broadinstitute/gatk/pull/3157#issuecomment-311458151:29,Usability,feedback,feedback,29,@samuelklee Expanded on your feedback. Let me know if the changes are okay.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3157#issuecomment-311458151
https://github.com/broadinstitute/gatk/pull/3157#issuecomment-311459570:63,Testability,test,tests,63,"Based on DR's email, I rebased these commits to get the travis tests going.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3157#issuecomment-311459570
https://github.com/broadinstitute/gatk/pull/3157#issuecomment-311469829:887,Performance,Perform,PerformSegmentation,887,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3157?src=pr&el=h1) Report; > Merging [#3157](https://codecov.io/gh/broadinstitute/gatk/pull/3157?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/eab8761cbdfdaf24a5bf7551172b9f262d26d8cf?src=pr&el=desc) will **not change** coverage.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #3157 +/- ##; ===========================================; Coverage 80.132% 80.132% ; Complexity 16993 16993 ; ===========================================; Files 1145 1145 ; Lines 61641 61641 ; Branches 9606 9606 ; ===========================================; Hits 49394 49394 ; Misses 8419 8419 ; Partials 3828 3828; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3157?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...te/hellbender/tools/exome/PerformSegmentation.java](https://codecov.io/gh/broadinstitute/gatk/pull/3157?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9QZXJmb3JtU2VnbWVudGF0aW9uLmphdmE=) | `100% <> ()` | `3 <0> ()` | :arrow_down: |; | [...bender/tools/exome/NormalizeSomaticReadCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/3157?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9Ob3JtYWxpemVTb21hdGljUmVhZENvdW50cy5qYXZh) | `79.167% <> ()` | `6 <0> ()` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3157#issuecomment-311469829
https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310720489:232,Availability,error,error-reference,232,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3158?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@8ab015d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #3158 +/- ##; =========================================; Coverage ? 9.901% ; Complexity ? 2034 ; =========================================; Files ? 1145 ; Lines ? 61641 ; Branches ? 9606 ; =========================================; Hits ? 6103 ; Misses ? 54604 ; Partials ? 934; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310720489
https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310720489:180,Usability,learn,learn,180,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3158?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@8ab015d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #3158 +/- ##; =========================================; Coverage ? 9.901% ; Complexity ? 2034 ; =========================================; Files ? 1145 ; Lines ? 61641 ; Branches ? 9606 ; =========================================; Hits ? 6103 ; Misses ? 54604 ; Partials ? 934; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310720489
https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310760238:158,Deployability,release,release,158,"@vdauwera Have to disagree -- the wiki on github is not versioned, and we definitely want this README to be versioned, since we distribute it with the binary release (there's VERY little that is not version-dependent). We also care a lot about being able to search through the README efficiently. I think having a table of contents makes the README a bit less intimidating :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310760238
https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310760238:284,Energy Efficiency,efficient,efficiently,284,"@vdauwera Have to disagree -- the wiki on github is not versioned, and we definitely want this README to be versioned, since we distribute it with the binary release (there's VERY little that is not version-dependent). We also care a lot about being able to search through the README efficiently. I think having a table of contents makes the README a bit less intimidating :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310760238
https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310760238:207,Integrability,depend,dependent,207,"@vdauwera Have to disagree -- the wiki on github is not versioned, and we definitely want this README to be versioned, since we distribute it with the binary release (there's VERY little that is not version-dependent). We also care a lot about being able to search through the README efficiently. I think having a table of contents makes the README a bit less intimidating :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310760238
https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310772135:196,Safety,safe,safe,196,"All comments addressed. Since tests on travis are broken at the moment, we're unfortunately forced to merge this without travis passing, however since only documentation is touched this should be safe.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310772135
https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310772135:30,Testability,test,tests,30,"All comments addressed. Since tests on travis are broken at the moment, we're unfortunately forced to merge this without travis passing, however since only documentation is touched this should be safe.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310772135
https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310784825:80,Deployability,update,update,80,"Hmm ok @droazen, I bow to your preference (if not entirely to your logic). Nice update overall by the way ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310784825
https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310784825:67,Testability,log,logic,67,"Hmm ok @droazen, I bow to your preference (if not entirely to your logic). Nice update overall by the way ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3158#issuecomment-310784825
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-310752620:232,Availability,error,error-reference,232,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3159?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@8ab015d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #3159 +/- ##; ==========================================; Coverage ? 62.624% ; Complexity ? 12641 ; ==========================================; Files ? 1145 ; Lines ? 61646 ; Branches ? 9606 ; ==========================================; Hits ? 38605 ; Misses ? 19096 ; Partials ? 3945; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3159?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/3159?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `68.224% <100%> ()` | `22 <0> (?)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3159?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `69.231% <100%> ()` | `10 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-310752620
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-310752620:180,Usability,learn,learn,180,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3159?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@8ab015d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #3159 +/- ##; ==========================================; Coverage ? 62.624% ; Complexity ? 12641 ; ==========================================; Files ? 1145 ; Lines ? 61646 ; Branches ? 9606 ; ==========================================; Hits ? 38605 ; Misses ? 19096 ; Partials ? 3945; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3159?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/3159?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `68.224% <100%> ()` | `22 <0> (?)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3159?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `69.231% <100%> ()` | `10 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-310752620
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-310768892:18,Availability,error,error,18,"Same issue:. ```; error: external filter 'git-lfs filter-process' failed; fatal: src/test/resources/large/cnv/create-pon-control-target-coord-only.pcov: smudge filter lfs failed; warning: Clone succeeded, but checkout failed.; You can inspect what was checked out with 'git status'; and retry the checkout with 'git checkout -f HEAD'; The command ""eval git clone --depth=9999999 https://github.com/broadinstitute/gatk.git broadinstitute/gatk "" failed. Retrying, 2 of 3.; fatal: destination path 'broadinstitute/gatk' already exists and is not an empty directory.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-310768892
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-310768892:85,Testability,test,test,85,"Same issue:. ```; error: external filter 'git-lfs filter-process' failed; fatal: src/test/resources/large/cnv/create-pon-control-target-coord-only.pcov: smudge filter lfs failed; warning: Clone succeeded, but checkout failed.; You can inspect what was checked out with 'git status'; and retry the checkout with 'git checkout -f HEAD'; The command ""eval git clone --depth=9999999 https://github.com/broadinstitute/gatk.git broadinstitute/gatk "" failed. Retrying, 2 of 3.; fatal: destination path 'broadinstitute/gatk' already exists and is not an empty directory.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-310768892
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-310770001:86,Availability,error,errors,86,"Don't worry @jean-philippe-martin, it's not just your branch. We are seeing `git lfs` errors across-the-board due to quota issues. We've opened a support ticket with github.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-310770001
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367:299,Availability,down,downloaded,299,"Tests with `TEST_DOCKER = true` failed, I'm not entirely clear why. Here's a bit of the log:. > Building 85% > :test > Resolving dependencies ':jacocoAgent'aven.org/maven2/org/jacoco/org.jacoco.agent/0.7.7.201606060606/org.jacoco.agent-0.7.7.201606060606.jar; > Building 85% > :test > 207 KB/233 KB downloaded> Building 85% > :test > 0 tests completed> Resolving dependencies ':testRuntime':test FAILED",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367:129,Integrability,depend,dependencies,129,"Tests with `TEST_DOCKER = true` failed, I'm not entirely clear why. Here's a bit of the log:. > Building 85% > :test > Resolving dependencies ':jacocoAgent'aven.org/maven2/org/jacoco/org.jacoco.agent/0.7.7.201606060606/org.jacoco.agent-0.7.7.201606060606.jar; > Building 85% > :test > 207 KB/233 KB downloaded> Building 85% > :test > 0 tests completed> Resolving dependencies ':testRuntime':test FAILED",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367:363,Integrability,depend,dependencies,363,"Tests with `TEST_DOCKER = true` failed, I'm not entirely clear why. Here's a bit of the log:. > Building 85% > :test > Resolving dependencies ':jacocoAgent'aven.org/maven2/org/jacoco/org.jacoco.agent/0.7.7.201606060606/org.jacoco.agent-0.7.7.201606060606.jar; > Building 85% > :test > 207 KB/233 KB downloaded> Building 85% > :test > 0 tests completed> Resolving dependencies ':testRuntime':test FAILED",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367:0,Testability,Test,Tests,0,"Tests with `TEST_DOCKER = true` failed, I'm not entirely clear why. Here's a bit of the log:. > Building 85% > :test > Resolving dependencies ':jacocoAgent'aven.org/maven2/org/jacoco/org.jacoco.agent/0.7.7.201606060606/org.jacoco.agent-0.7.7.201606060606.jar; > Building 85% > :test > 207 KB/233 KB downloaded> Building 85% > :test > 0 tests completed> Resolving dependencies ':testRuntime':test FAILED",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367:88,Testability,log,log,88,"Tests with `TEST_DOCKER = true` failed, I'm not entirely clear why. Here's a bit of the log:. > Building 85% > :test > Resolving dependencies ':jacocoAgent'aven.org/maven2/org/jacoco/org.jacoco.agent/0.7.7.201606060606/org.jacoco.agent-0.7.7.201606060606.jar; > Building 85% > :test > 207 KB/233 KB downloaded> Building 85% > :test > 0 tests completed> Resolving dependencies ':testRuntime':test FAILED",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367:112,Testability,test,test,112,"Tests with `TEST_DOCKER = true` failed, I'm not entirely clear why. Here's a bit of the log:. > Building 85% > :test > Resolving dependencies ':jacocoAgent'aven.org/maven2/org/jacoco/org.jacoco.agent/0.7.7.201606060606/org.jacoco.agent-0.7.7.201606060606.jar; > Building 85% > :test > 207 KB/233 KB downloaded> Building 85% > :test > 0 tests completed> Resolving dependencies ':testRuntime':test FAILED",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367:278,Testability,test,test,278,"Tests with `TEST_DOCKER = true` failed, I'm not entirely clear why. Here's a bit of the log:. > Building 85% > :test > Resolving dependencies ':jacocoAgent'aven.org/maven2/org/jacoco/org.jacoco.agent/0.7.7.201606060606/org.jacoco.agent-0.7.7.201606060606.jar; > Building 85% > :test > 207 KB/233 KB downloaded> Building 85% > :test > 0 tests completed> Resolving dependencies ':testRuntime':test FAILED",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367:327,Testability,test,test,327,"Tests with `TEST_DOCKER = true` failed, I'm not entirely clear why. Here's a bit of the log:. > Building 85% > :test > Resolving dependencies ':jacocoAgent'aven.org/maven2/org/jacoco/org.jacoco.agent/0.7.7.201606060606/org.jacoco.agent-0.7.7.201606060606.jar; > Building 85% > :test > 207 KB/233 KB downloaded> Building 85% > :test > 0 tests completed> Resolving dependencies ':testRuntime':test FAILED",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367:336,Testability,test,tests,336,"Tests with `TEST_DOCKER = true` failed, I'm not entirely clear why. Here's a bit of the log:. > Building 85% > :test > Resolving dependencies ':jacocoAgent'aven.org/maven2/org/jacoco/org.jacoco.agent/0.7.7.201606060606/org.jacoco.agent-0.7.7.201606060606.jar; > Building 85% > :test > 207 KB/233 KB downloaded> Building 85% > :test > 0 tests completed> Resolving dependencies ':testRuntime':test FAILED",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367:378,Testability,test,testRuntime,378,"Tests with `TEST_DOCKER = true` failed, I'm not entirely clear why. Here's a bit of the log:. > Building 85% > :test > Resolving dependencies ':jacocoAgent'aven.org/maven2/org/jacoco/org.jacoco.agent/0.7.7.201606060606/org.jacoco.agent-0.7.7.201606060606.jar; > Building 85% > :test > 207 KB/233 KB downloaded> Building 85% > :test > 0 tests completed> Resolving dependencies ':testRuntime':test FAILED",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367:391,Testability,test,test,391,"Tests with `TEST_DOCKER = true` failed, I'm not entirely clear why. Here's a bit of the log:. > Building 85% > :test > Resolving dependencies ':jacocoAgent'aven.org/maven2/org/jacoco/org.jacoco.agent/0.7.7.201606060606/org.jacoco.agent-0.7.7.201606060606.jar; > Building 85% > :test > 207 KB/233 KB downloaded> Building 85% > :test > 0 tests completed> Resolving dependencies ':testRuntime':test FAILED",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367:57,Usability,clear,clear,57,"Tests with `TEST_DOCKER = true` failed, I'm not entirely clear why. Here's a bit of the log:. > Building 85% > :test > Resolving dependencies ':jacocoAgent'aven.org/maven2/org/jacoco/org.jacoco.agent/0.7.7.201606060606/org.jacoco.agent-0.7.7.201606060606.jar; > Building 85% > :test > 207 KB/233 KB downloaded> Building 85% > :test > 0 tests completed> Resolving dependencies ':testRuntime':test FAILED",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314208367
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314237740:178,Availability,error,error,178,"@jean-philippe-martin Yeah, I'm seeing that. I suspect it's because we aren't passing the environment variables correctly to the docker tests so it's exploding with an unhelpful error during test initialization.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314237740
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314237740:102,Modifiability,variab,variables,102,"@jean-philippe-martin Yeah, I'm seeing that. I suspect it's because we aren't passing the environment variables correctly to the docker tests so it's exploding with an unhelpful error during test initialization.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314237740
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314237740:136,Testability,test,tests,136,"@jean-philippe-martin Yeah, I'm seeing that. I suspect it's because we aren't passing the environment variables correctly to the docker tests so it's exploding with an unhelpful error during test initialization.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314237740
https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314237740:191,Testability,test,test,191,"@jean-philippe-martin Yeah, I'm seeing that. I suspect it's because we aren't passing the environment variables correctly to the docker tests so it's exploding with an unhelpful error during test initialization.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3159#issuecomment-314237740
https://github.com/broadinstitute/gatk/issues/3163#issuecomment-310873860:75,Modifiability,extend,extends,75,"Just occured to me--Are we saying the application of a _germline workflow_ extends to the creation of a PoN consisting of germline normals for the _somatic workflow_?. If so, we should reorganize the directory structure of the CNV scripts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3163#issuecomment-310873860
https://github.com/broadinstitute/gatk/issues/3163#issuecomment-310874918:49,Testability,test,test,49,"### Too many PoNs, halp; Here are the options to test for PoN creation for the workshop tutorial. ![img_6819](https://user-images.githubusercontent.com/11543866/27512867-c1f82d26-591e-11e7-8bb3-f1290d6a76fa.JPG). I conjecture that the per-cohort various PoNs are _not_ equivalent, given the role of QC is to toss bad/outlier data points. If someone can tell me what is the best course of action, pictured or not (wait for PR to merge?), then I would be grateful. In the meanwhile, I will trudge ahead in my writing of the CNV tutorial, spending compute and moolah on the cloud.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3163#issuecomment-310874918
https://github.com/broadinstitute/gatk/issues/3163#issuecomment-310877132:158,Availability,error,error,158,"### Interestingly, I can in fact create a PoN from PCOV counts for my refined cohort (bifem). ; I almost did not run this thinking I would encounter the same error as the bad cohort (1kgmix). I had some inkling that perhaps results may be different (see my question below) and I wanted to square off my matrix of results. So I ran this just now. That I created a PoN for the bad cohort first on Friday is solely due to it finishing its counting well before the bifem cohort. One question I had on Friday was how the zero counts were counted. If the various samples have zero counts for different targets, or per target only some samples had zero counts and samples varied for each target, then does the QC look across the 2-D array for zero count patterns or just per 1-D dataset?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3163#issuecomment-310877132
https://github.com/broadinstitute/gatk/issues/3163#issuecomment-310879503:102,Testability,test,test,102,"Let's discuss more in person. It may be that the rounding is indeed a bug, but we'd want a regression test before we merge. For now, building a PoN using PCOV with noQC should be fine. (Note that QC is not the same as the filtering of targets/samples with too many zeros, etc., it specifically refers to the removal of samples with large events from the original PoN. But perhaps the ad hoc way this is done, along with the possible bug, is causing problems with the filtering step when creating the final PoN.) . Also, noQC is used in the WDL for a different reason---so that the small test BAMs can be used to build a PoN successfully. CreatePanelOfNormals belongs in the somatic workflow for now. You can think of it as a tool that produces a resource for denoising somatic samples. Eventually it will be replaced by gCNV, at which point we can discuss how the WDL should be organized. I can explain in more detail if you like.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3163#issuecomment-310879503
https://github.com/broadinstitute/gatk/issues/3163#issuecomment-310879503:587,Testability,test,test,587,"Let's discuss more in person. It may be that the rounding is indeed a bug, but we'd want a regression test before we merge. For now, building a PoN using PCOV with noQC should be fine. (Note that QC is not the same as the filtering of targets/samples with too many zeros, etc., it specifically refers to the removal of samples with large events from the original PoN. But perhaps the ad hoc way this is done, along with the possible bug, is causing problems with the filtering step when creating the final PoN.) . Also, noQC is used in the WDL for a different reason---so that the small test BAMs can be used to build a PoN successfully. CreatePanelOfNormals belongs in the somatic workflow for now. You can think of it as a tool that produces a resource for denoising somatic samples. Eventually it will be replaced by gCNV, at which point we can discuss how the WDL should be organized. I can explain in more detail if you like.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3163#issuecomment-310879503
https://github.com/broadinstitute/gatk/pull/3164#issuecomment-310950926:18,Testability,test,test,18,This needs a unit test.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3164#issuecomment-310950926
https://github.com/broadinstitute/gatk/pull/3165#issuecomment-311081582:143,Integrability,depend,dependent,143,I made a [PR](https://github.com/broadinstitute/gatk/pull/3169) for copying the CSS file that separate from the command line arg one since its dependent on this PR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3165#issuecomment-311081582
https://github.com/broadinstitute/gatk/pull/3165#issuecomment-311098545:102,Modifiability,config,configured,102,"Ah the ""Tool Docs Index"" link thing is because I left out the extension on purpose; our php server is configured to grab whatever file is present with that basename, with a rule of precedence in case there are several with different extensions (which is useful because of reasons). But locally the browser doesn't know to do that. I'm putting in some logic to handle this, thanks for pointing it out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3165#issuecomment-311098545
https://github.com/broadinstitute/gatk/pull/3165#issuecomment-311098545:351,Testability,log,logic,351,"Ah the ""Tool Docs Index"" link thing is because I left out the extension on purpose; our php server is configured to grab whatever file is present with that basename, with a rule of precedence in case there are several with different extensions (which is useful because of reasons). But locally the browser doesn't know to do that. I'm putting in some logic to handle this, thanks for pointing it out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3165#issuecomment-311098545
https://github.com/broadinstitute/gatk/pull/3165#issuecomment-311126776:19,Deployability,update,updated,19,No waivers! ;) . I updated the wiki with a note about the PHP functionality (anticipating the merge of your PR slightly) and describing the outputs a tad more. . @droazen Are we ok to merge this or holding off on everything until tests run again?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3165#issuecomment-311126776
https://github.com/broadinstitute/gatk/pull/3165#issuecomment-311126776:230,Testability,test,tests,230,No waivers! ;) . I updated the wiki with a note about the PHP functionality (anticipating the merge of your PR slightly) and describing the outputs a tad more. . @droazen Are we ok to merge this or holding off on everything until tests run again?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3165#issuecomment-311126776
https://github.com/broadinstitute/gatk/pull/3165#issuecomment-311466218:47,Testability,test,tests,47,Needs to be rebased onto latest master so that tests can pass in travis.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3165#issuecomment-311466218
https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311465823:19,Usability,simpl,simpler,19,Would it be better/simpler to just have both `./gradlew gatkDoc` and `./gradlew phpDoc`?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311465823
https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311466032:47,Testability,test,tests,47,Needs to be rebased onto latest master so that tests can pass in travis.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311466032
https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311473535:183,Usability,intuit,intuitive,183,"@droazen re: your earlier question, I think it's preferable to use the same base command and add a qualifier -- we may add other output format shortcuts in future, and I find it more intuitive to specify the format as an extra arg rather than a different target altogether.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311473535
https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311502481:73,Availability,failure,failures,73,"@cmnbroad This branch is failing, I don't know why (don't understand the failures). I just rebased it on latest master, which passes everything afaict.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311502481
https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311502730:86,Availability,failure,failures,86,"@vdauwera Well, the full truth is that the M2 WDL tests are experiencing intermittent failures at the moment due to out-of-disk-space issues on travis. You can safely merge this if only the M2 WDL tests failed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311502730
https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311502730:160,Safety,safe,safely,160,"@vdauwera Well, the full truth is that the M2 WDL tests are experiencing intermittent failures at the moment due to out-of-disk-space issues on travis. You can safely merge this if only the M2 WDL tests failed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311502730
https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311502730:50,Testability,test,tests,50,"@vdauwera Well, the full truth is that the M2 WDL tests are experiencing intermittent failures at the moment due to out-of-disk-space issues on travis. You can safely merge this if only the M2 WDL tests failed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311502730
https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311502730:197,Testability,test,tests,197,"@vdauwera Well, the full truth is that the M2 WDL tests are experiencing intermittent failures at the moment due to out-of-disk-space issues on travis. You can safely merge this if only the M2 WDL tests failed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311502730
https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311502937:11,Availability,failure,failure,11,"Yeah, this failure looks the same as the others, and unrelated to this change.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3167#issuecomment-311502937
https://github.com/broadinstitute/gatk/pull/3169#issuecomment-311466091:47,Testability,test,tests,47,Needs to be rebased onto latest master so that tests can pass in travis.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3169#issuecomment-311466091
https://github.com/broadinstitute/gatk/pull/3172#issuecomment-311672809:70,Testability,test,tests,70,Am going to rebase this branch by request of @LeeTL1220 to get travis tests to re-run,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3172#issuecomment-311672809
https://github.com/broadinstitute/gatk/pull/3172#issuecomment-311674562:62,Testability,test,tests,62,"@LeeTL1220 Ok, the branch is rebased/squashed, and the travis tests are re-running. Ready for your review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3172#issuecomment-311674562
https://github.com/broadinstitute/gatk/pull/3175#issuecomment-311651121:2157,Testability,test,test,2157,bGVGZWF0dXJlLmphdmE=) | `90.909% <100%> (+20.909%)` | `13 <5> (+5)` | :arrow_up: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3175?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-80.612%)` | `0% <0%> (-19%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3175?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3175?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3175?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3175?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...s/spark/pathseq/PSPairedUnpairedSplitterSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3175?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTUGFpcmVkVW5wYWlyZWRTcGxpdHRlclNwYXJrLmphdmE=) | `68.421% <0%> (-19.079%)` | `8% <0%> (-3%)` | |; | [...stitute/hellbender/tools/walkers/vqsr/Tranche.java](https://codecov.io/gh/broadinstitute/gatk/pull/3175?src=pr&el=tree#diff-c3JjL21haW4v,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3175#issuecomment-311651121
https://github.com/broadinstitute/gatk/pull/3175#issuecomment-324277969:27,Testability,test,tests,27,"@droazen, I think that the tests are failing here because a cromwell issue...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3175#issuecomment-324277969
https://github.com/broadinstitute/gatk/pull/3176#issuecomment-311650630:960,Testability,test,test,960,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=h1) Report; > Merging [#3176](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/2f2eb73be34e822ebea84b9f116c506768c625a1?src=pr&el=desc) will **decrease** coverage by `0.471%`.; > The diff coverage is `93.182%`. ```diff; @@ Coverage Diff @@; ## master #3176 +/- ##; ===============================================; - Coverage 80.128% 79.657% -0.471% ; + Complexity 16995 16924 -71 ; ===============================================; Files 1145 1146 +1 ; Lines 61650 61659 +9 ; Branches 9609 9609 ; ===============================================; - Hits 49399 49116 -283 ; - Misses 8422 8723 +301 ; + Partials 3829 3820 -9; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `70.707% <> (-12.875%)` | `27 <0> (-9)` | |; | [...institute/hellbender/utils/test/TestResources.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1Rlc3RSZXNvdXJjZXMuamF2YQ==) | `93.182% <93.182%> ()` | `8 <8> (?)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-80.612%)` | `0% <0%> (-19%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvb,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3176#issuecomment-311650630
https://github.com/broadinstitute/gatk/pull/3176#issuecomment-311650630:1227,Testability,test,test,1227,gatk/commit/2f2eb73be34e822ebea84b9f116c506768c625a1?src=pr&el=desc) will **decrease** coverage by `0.471%`.; > The diff coverage is `93.182%`. ```diff; @@ Coverage Diff @@; ## master #3176 +/- ##; ===============================================; - Coverage 80.128% 79.657% -0.471% ; + Complexity 16995 16924 -71 ; ===============================================; Files 1145 1146 +1 ; Lines 61650 61659 +9 ; Branches 9609 9609 ; ===============================================; - Hits 49399 49116 -283 ; - Misses 8422 8723 +301 ; + Partials 3829 3820 -9; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `70.707% <> (-12.875%)` | `27 <0> (-9)` | |; | [...institute/hellbender/utils/test/TestResources.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1Rlc3RSZXNvdXJjZXMuamF2YQ==) | `93.182% <93.182%> ()` | `8 <8> (?)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-80.612%)` | `0% <0%> (-19%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3176#issuecomment-311650630
https://github.com/broadinstitute/gatk/pull/3176#issuecomment-311650630:1232,Testability,Test,TestResources,1232,gatk/commit/2f2eb73be34e822ebea84b9f116c506768c625a1?src=pr&el=desc) will **decrease** coverage by `0.471%`.; > The diff coverage is `93.182%`. ```diff; @@ Coverage Diff @@; ## master #3176 +/- ##; ===============================================; - Coverage 80.128% 79.657% -0.471% ; + Complexity 16995 16924 -71 ; ===============================================; Files 1145 1146 +1 ; Lines 61650 61659 +9 ; Branches 9609 9609 ; ===============================================; - Hits 49399 49116 -283 ; - Misses 8422 8723 +301 ; + Partials 3829 3820 -9; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `70.707% <> (-12.875%)` | `27 <0> (-9)` | |; | [...institute/hellbender/utils/test/TestResources.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1Rlc3RSZXNvdXJjZXMuamF2YQ==) | `93.182% <93.182%> ()` | `8 <8> (?)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-80.612%)` | `0% <0%> (-19%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3176#issuecomment-311650630
https://github.com/broadinstitute/gatk/pull/3176#issuecomment-311650630:2394,Testability,test,test,2394,scy90ZXN0L1Rlc3RSZXNvdXJjZXMuamF2YQ==) | `93.182% <93.182%> ()` | `8 <8> (?)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-80.612%)` | `0% <0%> (-19%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `41.216% <0%> (-30.405%)` | `26% <0%> (-8%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3176?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGV,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3176#issuecomment-311650630
https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312061731:12,Testability,test,tests,12,Can you add tests that prove that #1572 and #3069 are fixed?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312061731
https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312295566:18,Testability,test,test,18,"I am working on a test for #1572. I am not sure what a test for #3069 would look like, or if it is really necessary. We simply changed the way GKL outputs warnings and information. Any ideas?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312295566
https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312295566:55,Testability,test,test,55,"I am working on a test for #1572. I am not sure what a test for #3069 would look like, or if it is really necessary. We simply changed the way GKL outputs warnings and information. Any ideas?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312295566
https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312295566:120,Usability,simpl,simply,120,"I am working on a test for #1572. I am not sure what a test for #3069 would look like, or if it is really necessary. We simply changed the way GKL outputs warnings and information. Any ideas?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312295566
https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141:233,Availability,failure,failures,233,"For testing #3069, creating a Java test that shows that the GKL messages are controlled by the [log4j logLevel](https://www.tutorialspoint.com/log4j/log4j_logging_levels.htm).; Also, this branch should be rebased. A fix for the test failures, due to an issue with 2 factor authentication for [GIt Large File Storage](https://git-lfs.github.com/) of test data was recently merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141
https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141:64,Integrability,message,messages,64,"For testing #3069, creating a Java test that shows that the GKL messages are controlled by the [log4j logLevel](https://www.tutorialspoint.com/log4j/log4j_logging_levels.htm).; Also, this branch should be rebased. A fix for the test failures, due to an issue with 2 factor authentication for [GIt Large File Storage](https://git-lfs.github.com/) of test data was recently merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141
https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141:273,Security,authenticat,authentication,273,"For testing #3069, creating a Java test that shows that the GKL messages are controlled by the [log4j logLevel](https://www.tutorialspoint.com/log4j/log4j_logging_levels.htm).; Also, this branch should be rebased. A fix for the test failures, due to an issue with 2 factor authentication for [GIt Large File Storage](https://git-lfs.github.com/) of test data was recently merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141
https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141:4,Testability,test,testing,4,"For testing #3069, creating a Java test that shows that the GKL messages are controlled by the [log4j logLevel](https://www.tutorialspoint.com/log4j/log4j_logging_levels.htm).; Also, this branch should be rebased. A fix for the test failures, due to an issue with 2 factor authentication for [GIt Large File Storage](https://git-lfs.github.com/) of test data was recently merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141
https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141:35,Testability,test,test,35,"For testing #3069, creating a Java test that shows that the GKL messages are controlled by the [log4j logLevel](https://www.tutorialspoint.com/log4j/log4j_logging_levels.htm).; Also, this branch should be rebased. A fix for the test failures, due to an issue with 2 factor authentication for [GIt Large File Storage](https://git-lfs.github.com/) of test data was recently merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141
https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141:102,Testability,log,logLevel,102,"For testing #3069, creating a Java test that shows that the GKL messages are controlled by the [log4j logLevel](https://www.tutorialspoint.com/log4j/log4j_logging_levels.htm).; Also, this branch should be rebased. A fix for the test failures, due to an issue with 2 factor authentication for [GIt Large File Storage](https://git-lfs.github.com/) of test data was recently merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141
https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141:228,Testability,test,test,228,"For testing #3069, creating a Java test that shows that the GKL messages are controlled by the [log4j logLevel](https://www.tutorialspoint.com/log4j/log4j_logging_levels.htm).; Also, this branch should be rebased. A fix for the test failures, due to an issue with 2 factor authentication for [GIt Large File Storage](https://git-lfs.github.com/) of test data was recently merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141
https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141:349,Testability,test,test,349,"For testing #3069, creating a Java test that shows that the GKL messages are controlled by the [log4j logLevel](https://www.tutorialspoint.com/log4j/log4j_logging_levels.htm).; Also, this branch should be rebased. A fix for the test failures, due to an issue with 2 factor authentication for [GIt Large File Storage](https://git-lfs.github.com/) of test data was recently merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3177#issuecomment-312404141
https://github.com/broadinstitute/gatk/issues/3178#issuecomment-314147710:183,Availability,down,downloading,183,"This sounds like a good idea, but it might be tricky because much of the file reading is likely done by native code that we're just wrapping. We could do something like automatically downloading and caching the file locally and handing the cached version to the native library. Would that suit your needs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3178#issuecomment-314147710
https://github.com/broadinstitute/gatk/issues/3178#issuecomment-314147710:132,Integrability,wrap,wrapping,132,"This sounds like a good idea, but it might be tricky because much of the file reading is likely done by native code that we're just wrapping. We could do something like automatically downloading and caching the file locally and handing the cached version to the native library. Would that suit your needs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3178#issuecomment-314147710
https://github.com/broadinstitute/gatk/issues/3178#issuecomment-314147710:240,Performance,cache,cached,240,"This sounds like a good idea, but it might be tricky because much of the file reading is likely done by native code that we're just wrapping. We could do something like automatically downloading and caching the file locally and handing the cached version to the native library. Would that suit your needs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3178#issuecomment-314147710
https://github.com/broadinstitute/gatk/pull/3179#issuecomment-311404012:90,Testability,test,tests,90,"@cmnbroad It looks like this resolves the git-lfs quota issues, but apparently the M2 WDL tests are failing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3179#issuecomment-311404012
https://github.com/broadinstitute/gatk/pull/3179#issuecomment-311408683:75,Availability,failure,failures,75,@droazen are you sure thats not transient ? The first (connection timeout) failures that happened don't appear in previous builds that succeeded.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3179#issuecomment-311408683
https://github.com/broadinstitute/gatk/pull/3179#issuecomment-311408683:66,Safety,timeout,timeout,66,@droazen are you sure thats not transient ? The first (connection timeout) failures that happened don't appear in previous builds that succeeded.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3179#issuecomment-311408683
https://github.com/broadinstitute/gatk/pull/3179#issuecomment-311409797:23,Availability,failure,failures,23,"@cmnbroad Yeah, the M2 failures went away in the most recent build, only to be replaced with the `XHMMSegmentCallerBaseIntegrationTest` transient failure :) . Since @mbabadi has a PR that fixes `XHMMSegmentCallerBaseIntegrationTest`, we can merge this into master, rebase that PR on top of it and merge, and then we should have passing tests again!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3179#issuecomment-311409797
https://github.com/broadinstitute/gatk/pull/3179#issuecomment-311409797:146,Availability,failure,failure,146,"@cmnbroad Yeah, the M2 failures went away in the most recent build, only to be replaced with the `XHMMSegmentCallerBaseIntegrationTest` transient failure :) . Since @mbabadi has a PR that fixes `XHMMSegmentCallerBaseIntegrationTest`, we can merge this into master, rebase that PR on top of it and merge, and then we should have passing tests again!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3179#issuecomment-311409797
https://github.com/broadinstitute/gatk/pull/3179#issuecomment-311409797:336,Testability,test,tests,336,"@cmnbroad Yeah, the M2 failures went away in the most recent build, only to be replaced with the `XHMMSegmentCallerBaseIntegrationTest` transient failure :) . Since @mbabadi has a PR that fixes `XHMMSegmentCallerBaseIntegrationTest`, we can merge this into master, rebase that PR on top of it and merge, and then we should have passing tests again!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3179#issuecomment-311409797
https://github.com/broadinstitute/gatk/issues/3181#issuecomment-356697320:26,Modifiability,rewrite,rewrite,26,Obviated by ModelSegments rewrite.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3181#issuecomment-356697320
https://github.com/broadinstitute/gatk/pull/3183#issuecomment-311481750:166,Deployability,continuous,continuous-integration,166,"@droazen @samuelklee this is a duplicate PR, I close the previous one. Travis was behaving strangely on the previous PR (oddly not picking up the correct commit for `continuous-integration/travis-ci/pr` test).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3183#issuecomment-311481750
https://github.com/broadinstitute/gatk/pull/3183#issuecomment-311481750:177,Integrability,integrat,integration,177,"@droazen @samuelklee this is a duplicate PR, I close the previous one. Travis was behaving strangely on the previous PR (oddly not picking up the correct commit for `continuous-integration/travis-ci/pr` test).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3183#issuecomment-311481750
https://github.com/broadinstitute/gatk/pull/3183#issuecomment-311481750:203,Testability,test,test,203,"@droazen @samuelklee this is a duplicate PR, I close the previous one. Travis was behaving strangely on the previous PR (oddly not picking up the correct commit for `continuous-integration/travis-ci/pr` test).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3183#issuecomment-311481750
https://github.com/broadinstitute/gatk/pull/3183#issuecomment-314618279:56,Availability,error,errors,56,@lbergelson @droazen I still get strange travis-related errors with this... could you please take a look? the latest complaint is a git lfs issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3183#issuecomment-314618279
https://github.com/broadinstitute/gatk/pull/3183#issuecomment-314620643:932,Performance,cache,cachemanager,932,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3183?src=pr&el=h1) Report; > Merging [#3183](https://codecov.io/gh/broadinstitute/gatk/pull/3183?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/64eba53c96ea739638d34222f0f2c61c39153a64?src=pr&el=desc) will **increase** coverage by `0.05%`.; > The diff coverage is `89.931%`. ```diff; @@ Coverage Diff @@; ## master #3183 +/- ##; ==============================================; + Coverage 80.415% 80.465% +0.05% ; - Complexity 17294 17368 +74 ; ==============================================; Files 1165 1165 ; Lines 62573 62785 +212 ; Branches 9763 9789 +26 ; ==============================================; + Hits 50318 50520 +202 ; - Misses 8350 8353 +3 ; - Partials 3905 3912 +7; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3183?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...gemodel/cachemanager/ComputableGraphStructure.java](https://codecov.io/gh/broadinstitute/gatk/pull/3183?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL2NhY2hlbWFuYWdlci9Db21wdXRhYmxlR3JhcGhTdHJ1Y3R1cmUuamF2YQ==) | `100% <> ()` | `63 <0> ()` | :arrow_down: |; | [...nder/cmdline/ExomeStandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3183?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0V4b21lU3RhbmRhcmRBcmd1bWVudERlZmluaXRpb25zLmphdmE=) | `0% <> ()` | `0 <0> ()` | :arrow_down: |; | [...der/tools/coveragemodel/nd4jutils/Nd4jIOUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3183?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3ZlcmFnZW1vZGVsL25kNGp1dGlscy9OZDRqSU9VdGlscy5qYXZh) | `81.731% <> ()` | `19 <0> ()` | :arrow_down: |; | [...bender/tools/exome/TargetAnnotationCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3183?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3183#issuecomment-314620643
https://github.com/broadinstitute/gatk/pull/3183#issuecomment-314813242:51,Availability,failure,failure,51,@mbabadi It looks like you hit a transient git-lfs failure. I'm not sure what we can do to prevent them but rerunning fixed it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3183#issuecomment-314813242
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963:600,Availability,error,error,600,"@droazen @sooheelee Anything involving adaptors is not my forte but here goes my best shot. The basic idea of `getAdaptorBoundary` is to find the end of the insert, that is, where the original fragment ends and the adaptor begins. Since the 5' ends of the paired reads define the bounds of a fragment, its approach is to look for the start of the forward strand mate if our read is on the reverse strand, or the end of a reverse strand mate if our read is on the forward strand. This protects us from the possibility of a read longer than its insert. So far, so good, I think. One possible source of error is that these boundaries are determined by the *alignment* starts of the paired reads. This might clip too much if a read has a soft-clipped end and it turns out that these soft-clipped bases were e.g. a real insertion. Then the soft-clipped bases would be considered part of the adaptor. However, this can't do the more harmful thing of failing to clip an adaptor as far as I can tell. So it looks to me like the only issue is the edge case of falsely soft-clipped bases in very short inserts, in which case we hard clip the soft clips and in theory could lose some sensitivity. . That said, @sooheelee may have something else in mind, and @yfarjoun will have a better-informed opinion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963:39,Energy Efficiency,adapt,adaptors,39,"@droazen @sooheelee Anything involving adaptors is not my forte but here goes my best shot. The basic idea of `getAdaptorBoundary` is to find the end of the insert, that is, where the original fragment ends and the adaptor begins. Since the 5' ends of the paired reads define the bounds of a fragment, its approach is to look for the start of the forward strand mate if our read is on the reverse strand, or the end of a reverse strand mate if our read is on the forward strand. This protects us from the possibility of a read longer than its insert. So far, so good, I think. One possible source of error is that these boundaries are determined by the *alignment* starts of the paired reads. This might clip too much if a read has a soft-clipped end and it turns out that these soft-clipped bases were e.g. a real insertion. Then the soft-clipped bases would be considered part of the adaptor. However, this can't do the more harmful thing of failing to clip an adaptor as far as I can tell. So it looks to me like the only issue is the edge case of falsely soft-clipped bases in very short inserts, in which case we hard clip the soft clips and in theory could lose some sensitivity. . That said, @sooheelee may have something else in mind, and @yfarjoun will have a better-informed opinion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963:215,Energy Efficiency,adapt,adaptor,215,"@droazen @sooheelee Anything involving adaptors is not my forte but here goes my best shot. The basic idea of `getAdaptorBoundary` is to find the end of the insert, that is, where the original fragment ends and the adaptor begins. Since the 5' ends of the paired reads define the bounds of a fragment, its approach is to look for the start of the forward strand mate if our read is on the reverse strand, or the end of a reverse strand mate if our read is on the forward strand. This protects us from the possibility of a read longer than its insert. So far, so good, I think. One possible source of error is that these boundaries are determined by the *alignment* starts of the paired reads. This might clip too much if a read has a soft-clipped end and it turns out that these soft-clipped bases were e.g. a real insertion. Then the soft-clipped bases would be considered part of the adaptor. However, this can't do the more harmful thing of failing to clip an adaptor as far as I can tell. So it looks to me like the only issue is the edge case of falsely soft-clipped bases in very short inserts, in which case we hard clip the soft clips and in theory could lose some sensitivity. . That said, @sooheelee may have something else in mind, and @yfarjoun will have a better-informed opinion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963:886,Energy Efficiency,adapt,adaptor,886,"@droazen @sooheelee Anything involving adaptors is not my forte but here goes my best shot. The basic idea of `getAdaptorBoundary` is to find the end of the insert, that is, where the original fragment ends and the adaptor begins. Since the 5' ends of the paired reads define the bounds of a fragment, its approach is to look for the start of the forward strand mate if our read is on the reverse strand, or the end of a reverse strand mate if our read is on the forward strand. This protects us from the possibility of a read longer than its insert. So far, so good, I think. One possible source of error is that these boundaries are determined by the *alignment* starts of the paired reads. This might clip too much if a read has a soft-clipped end and it turns out that these soft-clipped bases were e.g. a real insertion. Then the soft-clipped bases would be considered part of the adaptor. However, this can't do the more harmful thing of failing to clip an adaptor as far as I can tell. So it looks to me like the only issue is the edge case of falsely soft-clipped bases in very short inserts, in which case we hard clip the soft clips and in theory could lose some sensitivity. . That said, @sooheelee may have something else in mind, and @yfarjoun will have a better-informed opinion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963:963,Energy Efficiency,adapt,adaptor,963,"@droazen @sooheelee Anything involving adaptors is not my forte but here goes my best shot. The basic idea of `getAdaptorBoundary` is to find the end of the insert, that is, where the original fragment ends and the adaptor begins. Since the 5' ends of the paired reads define the bounds of a fragment, its approach is to look for the start of the forward strand mate if our read is on the reverse strand, or the end of a reverse strand mate if our read is on the forward strand. This protects us from the possibility of a read longer than its insert. So far, so good, I think. One possible source of error is that these boundaries are determined by the *alignment* starts of the paired reads. This might clip too much if a read has a soft-clipped end and it turns out that these soft-clipped bases were e.g. a real insertion. Then the soft-clipped bases would be considered part of the adaptor. However, this can't do the more harmful thing of failing to clip an adaptor as far as I can tell. So it looks to me like the only issue is the edge case of falsely soft-clipped bases in very short inserts, in which case we hard clip the soft clips and in theory could lose some sensitivity. . That said, @sooheelee may have something else in mind, and @yfarjoun will have a better-informed opinion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963:39,Modifiability,adapt,adaptors,39,"@droazen @sooheelee Anything involving adaptors is not my forte but here goes my best shot. The basic idea of `getAdaptorBoundary` is to find the end of the insert, that is, where the original fragment ends and the adaptor begins. Since the 5' ends of the paired reads define the bounds of a fragment, its approach is to look for the start of the forward strand mate if our read is on the reverse strand, or the end of a reverse strand mate if our read is on the forward strand. This protects us from the possibility of a read longer than its insert. So far, so good, I think. One possible source of error is that these boundaries are determined by the *alignment* starts of the paired reads. This might clip too much if a read has a soft-clipped end and it turns out that these soft-clipped bases were e.g. a real insertion. Then the soft-clipped bases would be considered part of the adaptor. However, this can't do the more harmful thing of failing to clip an adaptor as far as I can tell. So it looks to me like the only issue is the edge case of falsely soft-clipped bases in very short inserts, in which case we hard clip the soft clips and in theory could lose some sensitivity. . That said, @sooheelee may have something else in mind, and @yfarjoun will have a better-informed opinion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963:215,Modifiability,adapt,adaptor,215,"@droazen @sooheelee Anything involving adaptors is not my forte but here goes my best shot. The basic idea of `getAdaptorBoundary` is to find the end of the insert, that is, where the original fragment ends and the adaptor begins. Since the 5' ends of the paired reads define the bounds of a fragment, its approach is to look for the start of the forward strand mate if our read is on the reverse strand, or the end of a reverse strand mate if our read is on the forward strand. This protects us from the possibility of a read longer than its insert. So far, so good, I think. One possible source of error is that these boundaries are determined by the *alignment* starts of the paired reads. This might clip too much if a read has a soft-clipped end and it turns out that these soft-clipped bases were e.g. a real insertion. Then the soft-clipped bases would be considered part of the adaptor. However, this can't do the more harmful thing of failing to clip an adaptor as far as I can tell. So it looks to me like the only issue is the edge case of falsely soft-clipped bases in very short inserts, in which case we hard clip the soft clips and in theory could lose some sensitivity. . That said, @sooheelee may have something else in mind, and @yfarjoun will have a better-informed opinion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963:886,Modifiability,adapt,adaptor,886,"@droazen @sooheelee Anything involving adaptors is not my forte but here goes my best shot. The basic idea of `getAdaptorBoundary` is to find the end of the insert, that is, where the original fragment ends and the adaptor begins. Since the 5' ends of the paired reads define the bounds of a fragment, its approach is to look for the start of the forward strand mate if our read is on the reverse strand, or the end of a reverse strand mate if our read is on the forward strand. This protects us from the possibility of a read longer than its insert. So far, so good, I think. One possible source of error is that these boundaries are determined by the *alignment* starts of the paired reads. This might clip too much if a read has a soft-clipped end and it turns out that these soft-clipped bases were e.g. a real insertion. Then the soft-clipped bases would be considered part of the adaptor. However, this can't do the more harmful thing of failing to clip an adaptor as far as I can tell. So it looks to me like the only issue is the edge case of falsely soft-clipped bases in very short inserts, in which case we hard clip the soft clips and in theory could lose some sensitivity. . That said, @sooheelee may have something else in mind, and @yfarjoun will have a better-informed opinion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963:963,Modifiability,adapt,adaptor,963,"@droazen @sooheelee Anything involving adaptors is not my forte but here goes my best shot. The basic idea of `getAdaptorBoundary` is to find the end of the insert, that is, where the original fragment ends and the adaptor begins. Since the 5' ends of the paired reads define the bounds of a fragment, its approach is to look for the start of the forward strand mate if our read is on the reverse strand, or the end of a reverse strand mate if our read is on the forward strand. This protects us from the possibility of a read longer than its insert. So far, so good, I think. One possible source of error is that these boundaries are determined by the *alignment* starts of the paired reads. This might clip too much if a read has a soft-clipped end and it turns out that these soft-clipped bases were e.g. a real insertion. Then the soft-clipped bases would be considered part of the adaptor. However, this can't do the more harmful thing of failing to clip an adaptor as far as I can tell. So it looks to me like the only issue is the edge case of falsely soft-clipped bases in very short inserts, in which case we hard clip the soft clips and in theory could lose some sensitivity. . That said, @sooheelee may have something else in mind, and @yfarjoun will have a better-informed opinion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311548963
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311616771:132,Testability,test,test,132,"I agree with @sooheelee here, it would be better to use the unclipped 5' end as in mark-duplicates. ~also it would be better if the test; ```java; @Test(dataProvider = ""HasWellDefinedFragmentSizeData""); private void testHasWellDefinedFragmentSize(final String name, final GATKSAMRecord read, final boolean expected) {; Assert.assertEquals(ReadUtils.hasWellDefinedFragmentSize(read), expected);; }; ```; were public, so that it would be active...~ (doesn't need to be public)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311616771
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311616771:148,Testability,Test,Test,148,"I agree with @sooheelee here, it would be better to use the unclipped 5' end as in mark-duplicates. ~also it would be better if the test; ```java; @Test(dataProvider = ""HasWellDefinedFragmentSizeData""); private void testHasWellDefinedFragmentSize(final String name, final GATKSAMRecord read, final boolean expected) {; Assert.assertEquals(ReadUtils.hasWellDefinedFragmentSize(read), expected);; }; ```; were public, so that it would be active...~ (doesn't need to be public)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311616771
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311616771:216,Testability,test,testHasWellDefinedFragmentSize,216,"I agree with @sooheelee here, it would be better to use the unclipped 5' end as in mark-duplicates. ~also it would be better if the test; ```java; @Test(dataProvider = ""HasWellDefinedFragmentSizeData""); private void testHasWellDefinedFragmentSize(final String name, final GATKSAMRecord read, final boolean expected) {; Assert.assertEquals(ReadUtils.hasWellDefinedFragmentSize(read), expected);; }; ```; were public, so that it would be active...~ (doesn't need to be public)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311616771
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311616771:319,Testability,Assert,Assert,319,"I agree with @sooheelee here, it would be better to use the unclipped 5' end as in mark-duplicates. ~also it would be better if the test; ```java; @Test(dataProvider = ""HasWellDefinedFragmentSizeData""); private void testHasWellDefinedFragmentSize(final String name, final GATKSAMRecord read, final boolean expected) {; Assert.assertEquals(ReadUtils.hasWellDefinedFragmentSize(read), expected);; }; ```; were public, so that it would be active...~ (doesn't need to be public)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311616771
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311616771:326,Testability,assert,assertEquals,326,"I agree with @sooheelee here, it would be better to use the unclipped 5' end as in mark-duplicates. ~also it would be better if the test; ```java; @Test(dataProvider = ""HasWellDefinedFragmentSizeData""); private void testHasWellDefinedFragmentSize(final String name, final GATKSAMRecord read, final boolean expected) {; Assert.assertEquals(ReadUtils.hasWellDefinedFragmentSize(read), expected);; }; ```; were public, so that it would be active...~ (doesn't need to be public)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-311616771
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358740758:85,Energy Efficiency,adapt,adaptor,85,"@yfarjoun I'm not understanding... If we're on the reverse strand, then we reach the adaptor at the 5' end of the forward strand i.e. at one `getMateStart() + 1`, which is what the code does now. If we're on the forward strand the equivalent logic would be `getMateEnd() + 1`, but no such method exists, so we use `read.getStart() + abs(read.getFragmentLength())`. Why is this not equivalent?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358740758
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358740758:85,Modifiability,adapt,adaptor,85,"@yfarjoun I'm not understanding... If we're on the reverse strand, then we reach the adaptor at the 5' end of the forward strand i.e. at one `getMateStart() + 1`, which is what the code does now. If we're on the forward strand the equivalent logic would be `getMateEnd() + 1`, but no such method exists, so we use `read.getStart() + abs(read.getFragmentLength())`. Why is this not equivalent?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358740758
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358740758:242,Testability,log,logic,242,"@yfarjoun I'm not understanding... If we're on the reverse strand, then we reach the adaptor at the 5' end of the forward strand i.e. at one `getMateStart() + 1`, which is what the code does now. If we're on the forward strand the equivalent logic would be `getMateEnd() + 1`, but no such method exists, so we use `read.getStart() + abs(read.getFragmentLength())`. Why is this not equivalent?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358740758
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358768726:21,Usability,clear,clear,21,"@yfarjoun Just to be clear, are you saying that `getMateAlignmentEnd() + 1` is ideal for forward strand reads but `read.getStart() + abs(read.getFragmentLength())` will have to do if the `MC` tag is missing, and that we can leave it as `getMateStart() + 1` for reverse strand reads?. @droazen A priori I would expect the additional cost of parsing each read's mate CIGAR to be negligible compared to other stuff we do but I also understand the virtue of being careful. Given, however, that this is invoked for every assembled read in HaplotypeCaller it should suffice just to measure the wall clock time of HaplotypeCaller. Would seeing no change there be enough?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358768726
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358777173:48,Deployability,continuous,continuous,48,"@davidbenjamin I feel like we need to put good, continuous *performance* regression tests in place for the `HaplotypeCaller` so that we can make changes of this nature without fear. Testing for a performance regression in the `HaplotypeCaller` is currently very non-trivial -- you have to run with and without intervals, with and without -ERC GVCF, on both exome and genome to be confident that you haven't killed performance in a certain mode.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358777173
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358777173:60,Performance,perform,performance,60,"@davidbenjamin I feel like we need to put good, continuous *performance* regression tests in place for the `HaplotypeCaller` so that we can make changes of this nature without fear. Testing for a performance regression in the `HaplotypeCaller` is currently very non-trivial -- you have to run with and without intervals, with and without -ERC GVCF, on both exome and genome to be confident that you haven't killed performance in a certain mode.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358777173
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358777173:196,Performance,perform,performance,196,"@davidbenjamin I feel like we need to put good, continuous *performance* regression tests in place for the `HaplotypeCaller` so that we can make changes of this nature without fear. Testing for a performance regression in the `HaplotypeCaller` is currently very non-trivial -- you have to run with and without intervals, with and without -ERC GVCF, on both exome and genome to be confident that you haven't killed performance in a certain mode.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358777173
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358777173:414,Performance,perform,performance,414,"@davidbenjamin I feel like we need to put good, continuous *performance* regression tests in place for the `HaplotypeCaller` so that we can make changes of this nature without fear. Testing for a performance regression in the `HaplotypeCaller` is currently very non-trivial -- you have to run with and without intervals, with and without -ERC GVCF, on both exome and genome to be confident that you haven't killed performance in a certain mode.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358777173
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358777173:84,Testability,test,tests,84,"@davidbenjamin I feel like we need to put good, continuous *performance* regression tests in place for the `HaplotypeCaller` so that we can make changes of this nature without fear. Testing for a performance regression in the `HaplotypeCaller` is currently very non-trivial -- you have to run with and without intervals, with and without -ERC GVCF, on both exome and genome to be confident that you haven't killed performance in a certain mode.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358777173
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358777173:182,Testability,Test,Testing,182,"@davidbenjamin I feel like we need to put good, continuous *performance* regression tests in place for the `HaplotypeCaller` so that we can make changes of this nature without fear. Testing for a performance regression in the `HaplotypeCaller` is currently very non-trivial -- you have to run with and without intervals, with and without -ERC GVCF, on both exome and genome to be confident that you haven't killed performance in a certain mode.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358777173
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358794078:99,Testability,test,tests,99,If this is blocking us from making otherwise useful changes then we should prioritize adding these tests...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-358794078
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-413975723:161,Energy Efficiency,adapt,adaptorBoundary,161,"@davidbenjamin This seems to now be a problem for `PalindromeArtifactClipReadTransformer` as well. In cases where there are soft clips you can miscalculate the `adaptorBoundary`. For mitochondria this causes edge case problems if you're on the end of the contig. I suppose for that specific case it could be fixed in `PalindromeArtifactClipReadTransformer` directly, but it makes more sense to happen in `getAdaptorBoundary` (if cost was no issue).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-413975723
https://github.com/broadinstitute/gatk/issues/3184#issuecomment-413975723:161,Modifiability,adapt,adaptorBoundary,161,"@davidbenjamin This seems to now be a problem for `PalindromeArtifactClipReadTransformer` as well. In cases where there are soft clips you can miscalculate the `adaptorBoundary`. For mitochondria this causes edge case problems if you're on the end of the contig. I suppose for that specific case it could be fixed in `PalindromeArtifactClipReadTransformer` directly, but it makes more sense to happen in `getAdaptorBoundary` (if cost was no issue).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3184#issuecomment-413975723
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-311602501:91,Integrability,depend,dependency,91,This should be in the [gatk-bwamem-jni](https://github.com/broadinstitute/gatk-bwamem-jni) dependency. Maybe the artifact is not correctly packaged...but it is in the [gradle.build](https://github.com/broadinstitute/gatk/blob/master/build.gradle#L198)...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-311602501
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-311699030:68,Performance,load,load,68,So the null pointer is caused by bwa mem complaining that it cannot load the index from the HDFS.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-311699030
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-311908959:273,Security,access,accessible,273,"Could it be possible to read the file from a `java.nio.Path` in the [gatk-bwamem-jni](https://github.com/broadinstitute/gatk-bwamem-jni), @SHuang-Broad? It looks that it's a constraint of the native code, but it will be nice to be able to have just one index image in HDFS accessible for all the nodes...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-311908959
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:29,Availability,error,error,29,"Thank you @SHuang-Broad. The error was gone after I copied bwaindeximage file to lustre file system, which can be accessed by all worker nodes.; The new problem is: the program started but didn't give any informative message/progress (see log below). It was stopped (Ctl-C) after 16 hours. The sequence data is regular human exome, which could be mapped in 1-2 hours in our traditional pipeline. ```; ../gatk/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; -I hdfs://ln16/user/myname/NA12878/wes/NA12878-NGv3-LAB1360-A.unaligned.bam ; -O hdfs://ln16/user/myname/gatk4test/BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://ln16/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /TEST/hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=720 ; --executor-cores 20 ; --executor-memory 50g ; --conf spark.driver.memory=50g; Using GATK jar /home/myname/gatk4/gatk/build/libs/gatk-package-4.alpha.2-1125-g27b5190-SNAPSHOT-spark.jar; Running:; /opt/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --master spark://ln16:7077 --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOption; s=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.di$able=true --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --conf spark.cores.max=720 --executor-cores 20 --executor-memory 50g --conf spark.driver.memory=50g /home/myname/gatk4/gatk$build/libs/gatk",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:4403,Availability,ERROR,ERROR,4403,"ET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [June 29, 2017 4:55:20 PM CST] Executing as myname@ln14 on Linux 3.10.0-514.16.1.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b15; Version: 4.alpha.2-1125-g27b5190-SNAPSHOT; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""o",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:4521,Availability,ERROR,ERROR,4521," Linux 3.10.0-514.16.1.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b15; Version: 4.alpha.2-1125-g27b5190-SNAPSHOT; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a]",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:4586,Availability,ERROR,ERROR,4586,"Spot(TM) 64-Bit Server VM 1.8.0_112-b15; Version: 4.alpha.2-1125-g27b5190-SNAPSHOT; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:4666,Availability,ERROR,ERROR,4666,"5-g27b5190-SNAPSHOT; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:4787,Availability,ERROR,ERROR,4787,"SJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:4848,Availability,ERROR,ERROR,4848,"OLS : false; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" v",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:4966,Availability,ERROR,ERROR,4966,"; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@5",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5031,Availability,ERROR,ERROR,5031,"park - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""or",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5111,Availability,ERROR,ERROR,5111,"16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5232,Availability,ERROR,ERROR,5232," INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5293,Availability,ERROR,ERROR,5293," Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5414,Availability,ERROR,ERROR,5414,"he.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@5",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5479,Availability,ERROR,ERROR,5479,"e to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""or",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5559,Availability,ERROR,ERROR,5559,"lass ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5683,Availability,ERROR,ERROR,5683,"as loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is no",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5749,Availability,ERROR,ERROR,5749,"rstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5867,Availability,ERROR,ERROR,5867,".ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoade",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5932,Availability,ERROR,ERROR,5932,"org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6012,Availability,ERROR,ERROR,6012,"g.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6133,Availability,ERROR,ERROR,6133," loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ######",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6194,Availability,ERROR,ERROR,6194,"g.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ##############; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6315,Availability,ERROR,ERROR,6315,"g.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ##############; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6380,Availability,ERROR,ERROR,6380,"g.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ##############; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6460,Availability,ERROR,ERROR,6460,"g.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ##############; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6584,Availability,ERROR,ERROR,6584,"g.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ##############; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6650,Availability,ERROR,ERROR,6650,"g.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ##############; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6771,Availability,ERROR,ERROR,6771,"g.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ##############; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6836,Availability,ERROR,ERROR,6836,"g.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ##############; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6916,Availability,ERROR,ERROR,6916,"g.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ##############; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:7040,Availability,ERROR,ERROR,7040,"g.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ##############; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:386,Deployability,pipeline,pipeline,386,"Thank you @SHuang-Broad. The error was gone after I copied bwaindeximage file to lustre file system, which can be accessed by all worker nodes.; The new problem is: the program started but didn't give any informative message/progress (see log below). It was stopped (Ctl-C) after 16 hours. The sequence data is regular human exome, which could be mapped in 1-2 hours in our traditional pipeline. ```; ../gatk/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; -I hdfs://ln16/user/myname/NA12878/wes/NA12878-NGv3-LAB1360-A.unaligned.bam ; -O hdfs://ln16/user/myname/gatk4test/BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://ln16/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /TEST/hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=720 ; --executor-cores 20 ; --executor-memory 50g ; --conf spark.driver.memory=50g; Using GATK jar /home/myname/gatk4/gatk/build/libs/gatk-package-4.alpha.2-1125-g27b5190-SNAPSHOT-spark.jar; Running:; /opt/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --master spark://ln16:7077 --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOption; s=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.di$able=true --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --conf spark.cores.max=720 --executor-cores 20 --executor-memory 50g --conf spark.driver.memory=50g /home/myname/gatk4/gatk$build/libs/gatk",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:217,Integrability,message,message,217,"Thank you @SHuang-Broad. The error was gone after I copied bwaindeximage file to lustre file system, which can be accessed by all worker nodes.; The new problem is: the program started but didn't give any informative message/progress (see log below). It was stopped (Ctl-C) after 16 hours. The sequence data is regular human exome, which could be mapped in 1-2 hours in our traditional pipeline. ```; ../gatk/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; -I hdfs://ln16/user/myname/NA12878/wes/NA12878-NGv3-LAB1360-A.unaligned.bam ; -O hdfs://ln16/user/myname/gatk4test/BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://ln16/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /TEST/hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=720 ; --executor-cores 20 ; --executor-memory 50g ; --conf spark.driver.memory=50g; Using GATK jar /home/myname/gatk4/gatk/build/libs/gatk-package-4.alpha.2-1125-g27b5190-SNAPSHOT-spark.jar; Running:; /opt/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --master spark://ln16:7077 --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOption; s=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.di$able=true --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --conf spark.cores.max=720 --executor-cores 20 --executor-memory 50g --conf spark.driver.memory=50g /home/myname/gatk4/gatk$build/libs/gatk",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:4504,Modifiability,variab,variable,4504,"cuting as myname@ln14 on Linux 3.10.0-514.16.1.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_112-b15; Version: 4.alpha.2-1125-g27b5190-SNAPSHOT; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:4949,Modifiability,variab,variable,4949,"ITE_FOR_SAMTOOLS : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.L",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5397,Modifiability,variab,variable,5397," log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.L",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5850,Modifiability,variab,variable,5850,"RROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.mis",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6298,Modifiability,variab,variable,6298,"g.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ##############; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6754,Modifiability,variab,variable,6754,"g.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ##############; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:2468,Performance,Load,Loading,2468,"Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.di$able=true --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --conf spark.cores.max=720 --executor-cores 20 --executor-memory 50g --conf spark.driver.memory=50g /home/myname/gatk4/gatk$build/libs/gatk-package-4.alpha.2-1125-g27b5190-SNAPSHOT-spark.jar BwaAndMarkDuplicatesPipelineSpark -I hdfs://ln16/user/myname/NA12878/wes/NA12878-NGv3-LAB1360-A.unaligned.bam -O hdfs://ln16/user/myname/gatk4test/B$aAndMarkDuplicatesPipelineSpark_out.bam -R hdfs://ln16/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit --bwamemIndexImage /hadoop/myname/GRCh37.fa.img --disableSequenceDictionaryValidation --sparkMaster spark://$n16:7077; 16:55:20.195 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/myname/gatk4/gatk/build/libs/gatk-package-4.alpha.2-1125-g27b5190-SNAPSHOT-spark.jar!/com/intel/gkl/native/libgkl_compression.so; [June 29, 2017 4:55:20 PM CST] BwaAndMarkDuplicatesPipelineSpark --bwamemIndexImage /hadoop/myname/GRCh37.fa.img --output hdfs://ln16/user/myname/gatk4test/BwaAndMarkDuplicatesPipelineSpark_out.bam --reference hdfs$//ln16/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit --input hdfs://ln16/user/myname/NA12878/wes/NA12878-NGv3-LAB1360-A.unaligned.bam --disableSequenceDictionaryValidation true --sparkMaster spark://ln16:7077 --duplicates_scoring_strategy SUM_OF_BASE_QUALITIES --readValidationStringency SILENT --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --bamPartitionSize 0 --shardedOutput false --numReducers 0 --help fal$e --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters fals",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:4569,Performance,load,loaded,4569,"Spot(TM) 64-Bit Server VM 1.8.0_112-b15; Version: 4.alpha.2-1125-g27b5190-SNAPSHOT; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:4711,Performance,load,loaded,4711,"ark - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:55:20.229 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantia",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5014,Performance,load,loaded,5014,"park - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Deflater: IntelDeflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""or",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5156,Performance,load,loaded,5156,"Deflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Inflater: IntelInflater; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Initializing engine; 16:55:20.230 INFO BwaAndMarkDuplicatesPipelineSpark - Done initializing engine; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not inst",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5462,Performance,load,loaded,5462,"e to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""or",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5607,Performance,load,loaded,5607,"ncher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instan",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:5915,Performance,load,loaded,5915,"org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6057,Performance,load,loaded,6057,"r$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could no",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6363,Performance,load,loaded,6363,"g.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ##############; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6508,Performance,load,loaded,6508,"g.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ##############; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6819,Performance,load,loaded,6819,"g.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ##############; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:6964,Performance,load,loaded,6964,"g.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.ConsoleAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.ConsoleAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""console"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; log4j:ERROR A ""org.apache.log4j.varia.NullAppender"" object is not assignable to a ""org.apache.log4j.Appender"" variable.; log4j:ERROR The class ""org.apache.log4j.Appender"" was loaded by; log4j:ERROR [sun.misc.Launcher$AppClassLoader@53d8d10a] whereas object of type; log4j:ERROR ""org.apache.log4j.varia.NullAppender"" was loaded by [org.apache.spark.util.ChildFirstURLClassLoader@18a70f16].; log4j:ERROR Could not instantiate appender named ""NullAppender"".; ^C; ####################### Ctrl-C after 16 hours ##############; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:114,Security,access,accessed,114,"Thank you @SHuang-Broad. The error was gone after I copied bwaindeximage file to lustre file system, which can be accessed by all worker nodes.; The new problem is: the program started but didn't give any informative message/progress (see log below). It was stopped (Ctl-C) after 16 hours. The sequence data is regular human exome, which could be mapped in 1-2 hours in our traditional pipeline. ```; ../gatk/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; -I hdfs://ln16/user/myname/NA12878/wes/NA12878-NGv3-LAB1360-A.unaligned.bam ; -O hdfs://ln16/user/myname/gatk4test/BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://ln16/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /TEST/hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=720 ; --executor-cores 20 ; --executor-memory 50g ; --conf spark.driver.memory=50g; Using GATK jar /home/myname/gatk4/gatk/build/libs/gatk-package-4.alpha.2-1125-g27b5190-SNAPSHOT-spark.jar; Running:; /opt/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --master spark://ln16:7077 --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOption; s=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.di$able=true --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --conf spark.cores.max=720 --executor-cores 20 --executor-memory 50g --conf spark.driver.memory=50g /home/myname/gatk4/gatk$build/libs/gatk",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:239,Testability,log,log,239,"Thank you @SHuang-Broad. The error was gone after I copied bwaindeximage file to lustre file system, which can be accessed by all worker nodes.; The new problem is: the program started but didn't give any informative message/progress (see log below). It was stopped (Ctl-C) after 16 hours. The sequence data is regular human exome, which could be mapped in 1-2 hours in our traditional pipeline. ```; ../gatk/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; -I hdfs://ln16/user/myname/NA12878/wes/NA12878-NGv3-LAB1360-A.unaligned.bam ; -O hdfs://ln16/user/myname/gatk4test/BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://ln16/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /TEST/hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=720 ; --executor-cores 20 ; --executor-memory 50g ; --conf spark.driver.memory=50g; Using GATK jar /home/myname/gatk4/gatk/build/libs/gatk-package-4.alpha.2-1125-g27b5190-SNAPSHOT-spark.jar; Running:; /opt/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --master spark://ln16:7077 --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOption; s=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.di$able=true --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --conf spark.cores.max=720 --executor-cores 20 --executor-memory 50g --conf spark.driver.memory=50g /home/myname/gatk4/gatk$build/libs/gatk",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998:705,Testability,TEST,TEST,705,"Thank you @SHuang-Broad. The error was gone after I copied bwaindeximage file to lustre file system, which can be accessed by all worker nodes.; The new problem is: the program started but didn't give any informative message/progress (see log below). It was stopped (Ctl-C) after 16 hours. The sequence data is regular human exome, which could be mapped in 1-2 hours in our traditional pipeline. ```; ../gatk/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; -I hdfs://ln16/user/myname/NA12878/wes/NA12878-NGv3-LAB1360-A.unaligned.bam ; -O hdfs://ln16/user/myname/gatk4test/BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://ln16/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /TEST/hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=720 ; --executor-cores 20 ; --executor-memory 50g ; --conf spark.driver.memory=50g; Using GATK jar /home/myname/gatk4/gatk/build/libs/gatk-package-4.alpha.2-1125-g27b5190-SNAPSHOT-spark.jar; Running:; /opt/spark-2.1.0-bin-hadoop2.7/bin/spark-submit --master spark://ln16:7077 --conf spark.driver.userClassPathFirst=true --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOption; s=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.di$able=true --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --conf spark.cores.max=720 --executor-cores 20 --executor-memory 50g --conf spark.driver.memory=50g /home/myname/gatk4/gatk$build/libs/gatk",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312229998
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932:38,Deployability,configurat,configuration,38,"This likely has to do with your spark configuration. Check on the Spark job's progress through the web interface, which should be something like http://<driver_address>:4040 (see https://spark.apache.org/docs/latest/monitoring.html). . If your BAM is very small, you can also try increasing the number of partitions by reducing --bamPartitionSize.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932:216,Energy Efficiency,monitor,monitoring,216,"This likely has to do with your spark configuration. Check on the Spark job's progress through the web interface, which should be something like http://<driver_address>:4040 (see https://spark.apache.org/docs/latest/monitoring.html). . If your BAM is very small, you can also try increasing the number of partitions by reducing --bamPartitionSize.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932:103,Integrability,interface,interface,103,"This likely has to do with your spark configuration. Check on the Spark job's progress through the web interface, which should be something like http://<driver_address>:4040 (see https://spark.apache.org/docs/latest/monitoring.html). . If your BAM is very small, you can also try increasing the number of partitions by reducing --bamPartitionSize.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932:38,Modifiability,config,configuration,38,"This likely has to do with your spark configuration. Check on the Spark job's progress through the web interface, which should be something like http://<driver_address>:4040 (see https://spark.apache.org/docs/latest/monitoring.html). . If your BAM is very small, you can also try increasing the number of partitions by reducing --bamPartitionSize.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312316932
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312362074:190,Integrability,wrap,wrapper,190,"@magicDGS . I am afraid this is not easy. I didn't write the binding (@tedsharpe did), but I would asseme the limitation comes from bwa mem itself, not the binding, as the binding is a thin wrapper that delegates the loading of the index files (or the image that combines all 5 index files in this case) to bwa. . The SV team here have a script (`scripts/sv/default_init.sh`) that when the Spark cluster is created and initialized, the image file is distributed to all walker nodes. Spark clusters other than Google's Dataproc would probably allow you to provide scripts as initialization actions as well. On the other hand, there seem to be a `--files` argument that you can append to your cmd line arguments which yarn will parse and distribute the provided local file to all nodes, though in this case it will be very inefficient considering the image file's size.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312362074
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312362074:217,Performance,load,loading,217,"@magicDGS . I am afraid this is not easy. I didn't write the binding (@tedsharpe did), but I would asseme the limitation comes from bwa mem itself, not the binding, as the binding is a thin wrapper that delegates the loading of the index files (or the image that combines all 5 index files in this case) to bwa. . The SV team here have a script (`scripts/sv/default_init.sh`) that when the Spark cluster is created and initialized, the image file is distributed to all walker nodes. Spark clusters other than Google's Dataproc would probably allow you to provide scripts as initialization actions as well. On the other hand, there seem to be a `--files` argument that you can append to your cmd line arguments which yarn will parse and distribute the provided local file to all nodes, though in this case it will be very inefficient considering the image file's size.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312362074
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312362505:88,Availability,error,errors,88,"@hliang , the suggestion by @mwalker174 might be your solution. ; Note that those log4j errors are known and is on our radar to be fixed(it won't prevent real work being done in my experience, just annoying).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312362505
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312583534:289,Deployability,patch,patch,289,"Thanks for the answer @SHuang-Broad. It would be nice if the bwa-mem C library have the option to pass streams instead of files for the index, allowing passing in-memory and file-based (in whatever file system abstraction) indexes. I will try to look at the code and see if I can submit a patch, but I need to refresh my C++ for that...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312583534
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:293,Availability,error,errors,293,"Thank you @mwalker174 . The input bamfile is about 7 GB. If no `--bamPartitionSize` is specified, the job would stuck at the first step `collect at ReadsSparkSource.java:220`, until we killed it. So I tried `--bamPartitionSize 4000000`, and it went through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:541,Availability,down,down,541,"Thank you @mwalker174 . The input bamfile is about 7 GB. If no `--bamPartitionSize` is specified, the job would stuck at the first step `collect at ReadsSparkSource.java:220`, until we killed it. So I tried `--bamPartitionSize 4000000`, and it went through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:799,Availability,failure,failure,799,"Thank you @mwalker174 . The input bamfile is about 7 GB. If no `--bamPartitionSize` is specified, the job would stuck at the first step `collect at ReadsSparkSource.java:220`, until we killed it. So I tried `--bamPartitionSize 4000000`, and it went through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:858,Availability,failure,failure,858,"Thank you @mwalker174 . The input bamfile is about 7 GB. If no `--bamPartitionSize` is specified, the job would stuck at the first step `collect at ReadsSparkSource.java:220`, until we killed it. So I tried `--bamPartitionSize 4000000`, and it went through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1027,Availability,heartbeat,heartbeat,1027,"k you @mwalker174 . The input bamfile is about 7 GB. If no `--bamPartitionSize` is specified, the job would stuck at the first step `collect at ReadsSparkSource.java:220`, until we killed it. So I tried `--bamPartitionSize 4000000`, and it went through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:5766,Availability,error,error,5766,"Sink.writeReadsSingle(ReadsSparkSink.java:228); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:153); at org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark.runTool(BwaAndMarkDuplicatesPipelineSpark.java:62); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:230); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. I have to look more into BwaAndMarkDuplicatesPipelineSpark. The good news is at least we get BwaSpark working now: `BwaSpark` with `--bamPartitionSize`=4000000 or 64000000, the program finishes in less than 20 minutes without error. (It used to stalled if no `--bamPartitionSize` is specified).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:626,Deployability,pipeline,pipelines,626,"Thank you @mwalker174 . The input bamfile is about 7 GB. If no `--bamPartitionSize` is specified, the job would stuck at the first step `collect at ReadsSparkSource.java:220`, until we killed it. So I tried `--bamPartitionSize 4000000`, and it went through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:4037,Deployability,pipeline,pipelines,4037,ark.RangePartitioner.<init>(Partitioner.scala:152); at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:62); at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:61); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rdd.OrderedRDDFunctions.sortByKey(OrderedRDDFunctions.scala:61); at org.apache.spark.api.java.JavaPairRDD.sortByKey(JavaPairRDD.scala:936); at org.broadinstitute.hellbender.utils.spark.SparkUtils.sortReads(SparkUtils.java:153); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReadsSingle(ReadsSparkSink.java:228); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:153); at org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark.runTool(BwaAndMarkDuplicatesPipelineSpark.java:62); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:230); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:5166,Deployability,deploy,deploy,5166,"Sink.writeReadsSingle(ReadsSparkSink.java:228); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:153); at org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark.runTool(BwaAndMarkDuplicatesPipelineSpark.java:62); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:230); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. I have to look more into BwaAndMarkDuplicatesPipelineSpark. The good news is at least we get BwaSpark working now: `BwaSpark` with `--bamPartitionSize`=4000000 or 64000000, the program finishes in less than 20 minutes without error. (It used to stalled if no `--bamPartitionSize` is specified).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:5203,Deployability,deploy,deploy,5203,"Sink.writeReadsSingle(ReadsSparkSink.java:228); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:153); at org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark.runTool(BwaAndMarkDuplicatesPipelineSpark.java:62); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:230); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. I have to look more into BwaAndMarkDuplicatesPipelineSpark. The good news is at least we get BwaSpark working now: `BwaSpark` with `--bamPartitionSize`=4000000 or 64000000, the program finishes in less than 20 minutes without error. (It used to stalled if no `--bamPartitionSize` is specified).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:5275,Deployability,deploy,deploy,5275,"Sink.writeReadsSingle(ReadsSparkSink.java:228); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:153); at org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark.runTool(BwaAndMarkDuplicatesPipelineSpark.java:62); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:230); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. I have to look more into BwaAndMarkDuplicatesPipelineSpark. The good news is at least we get BwaSpark working now: `BwaSpark` with `--bamPartitionSize`=4000000 or 64000000, the program finishes in less than 20 minutes without error. (It used to stalled if no `--bamPartitionSize` is specified).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:5351,Deployability,deploy,deploy,5351,"Sink.writeReadsSingle(ReadsSparkSink.java:228); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:153); at org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark.runTool(BwaAndMarkDuplicatesPipelineSpark.java:62); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:230); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. I have to look more into BwaAndMarkDuplicatesPipelineSpark. The good news is at least we get BwaSpark working now: `BwaSpark` with `--bamPartitionSize`=4000000 or 64000000, the program finishes in less than 20 minutes without error. (It used to stalled if no `--bamPartitionSize` is specified).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:5422,Deployability,deploy,deploy,5422,"Sink.writeReadsSingle(ReadsSparkSink.java:228); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:153); at org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark.runTool(BwaAndMarkDuplicatesPipelineSpark.java:62); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:230); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. I have to look more into BwaAndMarkDuplicatesPipelineSpark. The good news is at least we get BwaSpark working now: `BwaSpark` with `--bamPartitionSize`=4000000 or 64000000, the program finishes in less than 20 minutes without error. (It used to stalled if no `--bamPartitionSize` is specified).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:5491,Deployability,deploy,deploy,5491,"Sink.writeReadsSingle(ReadsSparkSink.java:228); at org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSink.writeReads(ReadsSparkSink.java:153); at org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark.runTool(BwaAndMarkDuplicatesPipelineSpark.java:62); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:353); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:38); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); at org.broadinstitute.hellbender.Main.main(Main.java:230); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. I have to look more into BwaAndMarkDuplicatesPipelineSpark. The good news is at least we get BwaSpark working now: `BwaSpark` with `--bamPartitionSize`=4000000 or 64000000, the program finishes in less than 20 minutes without error. (It used to stalled if no `--bamPartitionSize` is specified).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1104,Energy Efficiency,schedul,scheduler,1104,"ld stuck at the first step `collect at ReadsSparkSource.java:220`, until we killed it. So I tried `--bamPartitionSize 4000000`, and it went through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1144,Energy Efficiency,schedul,scheduler,1144,"a:220`, until we killed it. So I tried `--bamPartitionSize 4000000`, and it went through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1242,Energy Efficiency,schedul,scheduler,1242,"t through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1339,Energy Efficiency,schedul,scheduler,1339,"ser-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1590,Energy Efficiency,schedul,scheduler,1590,"stitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(Sp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1670,Energy Efficiency,schedul,scheduler,1670," Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.sca",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1775,Energy Efficiency,schedul,scheduler,1775,"orted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935); at org.apache.spark.rdd.RD",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1923,Energy Efficiency,schedul,scheduler,1923, 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.a,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:2011,Energy Efficiency,schedul,scheduler,2011,: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rdd.RDD.collect(RDD.sc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:2108,Energy Efficiency,schedul,scheduler,2108,.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rdd.RDD.collect(RDD.scala:934); at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:152); at org.apache.spark,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:2203,Energy Efficiency,schedul,scheduler,2203,.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rdd.RDD.collect(RDD.scala:934); at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:152); at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:62); at org.apach,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:2366,Energy Efficiency,schedul,scheduler,2366,abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:935); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rdd.RDD.collect(RDD.scala:934); at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:152); at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:62); at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:61); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.sc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:276,Integrability,interface,interface,276,"Thank you @mwalker174 . The input bamfile is about 7 GB. If no `--bamPartitionSize` is specified, the job would stuck at the first step `collect at ReadsSparkSource.java:220`, until we killed it. So I tried `--bamPartitionSize 4000000`, and it went through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:778,Safety,abort,aborted,778,"Thank you @mwalker174 . The input bamfile is about 7 GB. If no `--bamPartitionSize` is specified, the job would stuck at the first step `collect at ReadsSparkSource.java:220`, until we killed it. So I tried `--bamPartitionSize 4000000`, and it went through, but the Spark web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1274,Safety,abort,abortStage,1274,"rk web interface showed errors in `sortByKey` steps:; ![sparkjob](https://user-images.githubusercontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1371,Safety,abort,abortStage,1371,"ontent.com/812850/27811313-9000019c-6097-11e7-82ac-aac557be31db.PNG).; And the program failed eventually:; ```; 18:24:57.885 INFO BwaAndMarkDuplicatesPipelineSpark - Shutting down engine; [July 3, 2017 6:24:57 PM CST] org.broadinstitute.hellbender.tools.spark.pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363:1613,Safety,abort,abortStage,1613,".pipelines.BwaAndMarkDuplicatesPipelineSpark done. Elapsed time: 269.29 minutes.; Runtime.totalMemory()=4172283904; org.apache.spark.SparkException: Job aborted due to stage failure: Task 607 in stage 3.0 failed 4 times, most recent failure: Lost task 607.13 in stage 3.0 (TID 14832, 12.9.68.0, executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 169939 ms; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-312758363
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313197140:134,Availability,error,error,134,"@hliang I see that many of the tasks are failing and it looks like one of the executors crashed. To find the cause, you can check the error logs of these tasks through the web UI. I suspect increasing executor memory will fix the problem. Heartbeat timeouts usually occur when an executor JVM runs out of memory or requests more memory than the node will allow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313197140
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313197140:239,Availability,Heartbeat,Heartbeat,239,"@hliang I see that many of the tasks are failing and it looks like one of the executors crashed. To find the cause, you can check the error logs of these tasks through the web UI. I suspect increasing executor memory will fix the problem. Heartbeat timeouts usually occur when an executor JVM runs out of memory or requests more memory than the node will allow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313197140
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313197140:249,Safety,timeout,timeouts,249,"@hliang I see that many of the tasks are failing and it looks like one of the executors crashed. To find the cause, you can check the error logs of these tasks through the web UI. I suspect increasing executor memory will fix the problem. Heartbeat timeouts usually occur when an executor JVM runs out of memory or requests more memory than the node will allow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313197140
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313197140:140,Testability,log,logs,140,"@hliang I see that many of the tasks are failing and it looks like one of the executors crashed. To find the cause, you can check the error logs of these tasks through the web UI. I suspect increasing executor memory will fix the problem. Heartbeat timeouts usually occur when an executor JVM runs out of memory or requests more memory than the node will allow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313197140
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313981314:285,Availability,error,errors,285,"Thank you @mwalker174 for the suggestions. I ended up writing for loops to test which configurations work. Driver memory: 2-50g; executor memory: 2-50g; executor cores: 1-20; bamPartitionSize: 1-64m. Some combinations failed in minutes, some failed in hours, and some finished without errors. Bellow are three of which work for a ~33X WGS data:; ```; ../gatk-4.beta.1/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; --bamPartitionSize 4000000 ; -I hdfs://bigdata/user/myname/gatk4test/wgs.sub4.unaligned.bam ; -O hdfs://bigdata/user/myname/gatk4test/wgs.sub4.BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://bigdata/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=600 ; --executor-cores 20 ; --executor-memory 10g ; --conf spark.driver.memory=50g. ../gatk-4.beta.1/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; --bamPartitionSize 4000000 ; -I hdfs://bigdata/user/myname/gatk4test/wgs.sub4.unaligned.bam ; -O hdfs://bigdata/user/myname/gatk4test/wgs.sub4.BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://bigdata/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=600 ; --executor-cores 5 ; --executor-memory 50g ; --conf spark.driver.memory=50g. ../gatk-4.beta.1/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; --bamPartitionSize 64000000 ; -I hdfs://bigdata/user/myname/gatk4test/wgs.sub4.unaligned.bam ; -O hdfs://bigdata/user/myname/gatk4test/wgs.sub4.BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://bigdata/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.core",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313981314
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313981314:86,Deployability,configurat,configurations,86,"Thank you @mwalker174 for the suggestions. I ended up writing for loops to test which configurations work. Driver memory: 2-50g; executor memory: 2-50g; executor cores: 1-20; bamPartitionSize: 1-64m. Some combinations failed in minutes, some failed in hours, and some finished without errors. Bellow are three of which work for a ~33X WGS data:; ```; ../gatk-4.beta.1/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; --bamPartitionSize 4000000 ; -I hdfs://bigdata/user/myname/gatk4test/wgs.sub4.unaligned.bam ; -O hdfs://bigdata/user/myname/gatk4test/wgs.sub4.BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://bigdata/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=600 ; --executor-cores 20 ; --executor-memory 10g ; --conf spark.driver.memory=50g. ../gatk-4.beta.1/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; --bamPartitionSize 4000000 ; -I hdfs://bigdata/user/myname/gatk4test/wgs.sub4.unaligned.bam ; -O hdfs://bigdata/user/myname/gatk4test/wgs.sub4.BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://bigdata/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=600 ; --executor-cores 5 ; --executor-memory 50g ; --conf spark.driver.memory=50g. ../gatk-4.beta.1/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; --bamPartitionSize 64000000 ; -I hdfs://bigdata/user/myname/gatk4test/wgs.sub4.unaligned.bam ; -O hdfs://bigdata/user/myname/gatk4test/wgs.sub4.BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://bigdata/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.core",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313981314
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313981314:86,Modifiability,config,configurations,86,"Thank you @mwalker174 for the suggestions. I ended up writing for loops to test which configurations work. Driver memory: 2-50g; executor memory: 2-50g; executor cores: 1-20; bamPartitionSize: 1-64m. Some combinations failed in minutes, some failed in hours, and some finished without errors. Bellow are three of which work for a ~33X WGS data:; ```; ../gatk-4.beta.1/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; --bamPartitionSize 4000000 ; -I hdfs://bigdata/user/myname/gatk4test/wgs.sub4.unaligned.bam ; -O hdfs://bigdata/user/myname/gatk4test/wgs.sub4.BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://bigdata/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=600 ; --executor-cores 20 ; --executor-memory 10g ; --conf spark.driver.memory=50g. ../gatk-4.beta.1/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; --bamPartitionSize 4000000 ; -I hdfs://bigdata/user/myname/gatk4test/wgs.sub4.unaligned.bam ; -O hdfs://bigdata/user/myname/gatk4test/wgs.sub4.BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://bigdata/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=600 ; --executor-cores 5 ; --executor-memory 50g ; --conf spark.driver.memory=50g. ../gatk-4.beta.1/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; --bamPartitionSize 64000000 ; -I hdfs://bigdata/user/myname/gatk4test/wgs.sub4.unaligned.bam ; -O hdfs://bigdata/user/myname/gatk4test/wgs.sub4.BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://bigdata/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.core",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313981314
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313981314:75,Testability,test,test,75,"Thank you @mwalker174 for the suggestions. I ended up writing for loops to test which configurations work. Driver memory: 2-50g; executor memory: 2-50g; executor cores: 1-20; bamPartitionSize: 1-64m. Some combinations failed in minutes, some failed in hours, and some finished without errors. Bellow are three of which work for a ~33X WGS data:; ```; ../gatk-4.beta.1/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; --bamPartitionSize 4000000 ; -I hdfs://bigdata/user/myname/gatk4test/wgs.sub4.unaligned.bam ; -O hdfs://bigdata/user/myname/gatk4test/wgs.sub4.BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://bigdata/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=600 ; --executor-cores 20 ; --executor-memory 10g ; --conf spark.driver.memory=50g. ../gatk-4.beta.1/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; --bamPartitionSize 4000000 ; -I hdfs://bigdata/user/myname/gatk4test/wgs.sub4.unaligned.bam ; -O hdfs://bigdata/user/myname/gatk4test/wgs.sub4.BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://bigdata/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.cores.max=600 ; --executor-cores 5 ; --executor-memory 50g ; --conf spark.driver.memory=50g. ../gatk-4.beta.1/gatk-launch BwaAndMarkDuplicatesPipelineSpark ; --bamPartitionSize 64000000 ; -I hdfs://bigdata/user/myname/gatk4test/wgs.sub4.unaligned.bam ; -O hdfs://bigdata/user/myname/gatk4test/wgs.sub4.BwaAndMarkDuplicatesPipelineSpark_out.bam ; -R hdfs://bigdata/user/myname/genomes/Hsapiens/GRCh37/seq/GRCh37.2bit ; --bwamemIndexImage /hadoop/myname/GRCh37.fa.img ; --disableSequenceDictionaryValidation ; -- --sparkRunner SPARK ; --sparkMaster spark://ln16:7077 ; --conf spark.core",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-313981314
https://github.com/broadinstitute/gatk/issues/3186#issuecomment-315969501:21,Availability,error,errors,21,"Just found the log4j errors could be fixed by editing `gatk-launch` and set `spark.driver.userClassPathFirst` to `false` (was `true` by default), or add `--conf spark.driver.userClassPathFirst=false` to gatk-launch command line.; Not sure if that would have any unexpected effect though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3186#issuecomment-315969501
https://github.com/broadinstitute/gatk/pull/3189#issuecomment-311745205:61,Deployability,pipeline,pipeline,61,"Before we merge, it might be good to get you to run the full pipeline with this change on a real data set. That'll require a little bit of an intro to GCP and dataproc. Come by and one of us can help step you through that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3189#issuecomment-311745205
https://github.com/broadinstitute/gatk/pull/3189#issuecomment-316996025:33,Testability,test,testing,33,"Closing and deleting. After more testing, change didn't help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3189#issuecomment-316996025
https://github.com/broadinstitute/gatk/pull/3190#issuecomment-318657514:0,Availability,Ping,Ping,0,Ping @vdauwera @lbergelson,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3190#issuecomment-318657514
https://github.com/broadinstitute/gatk/pull/3190#issuecomment-318688481:27,Deployability,update,update,27,"When you merge, be sure to update the commit comment and message to reflect the fact that it's been replaced instead of deprecated and that the default behavior is the opposite of what it used to be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3190#issuecomment-318688481
https://github.com/broadinstitute/gatk/pull/3190#issuecomment-318688481:57,Integrability,message,message,57,"When you merge, be sure to update the commit comment and message to reflect the fact that it's been replaced instead of deprecated and that the default behavior is the opposite of what it used to be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3190#issuecomment-318688481
https://github.com/broadinstitute/gatk/pull/3190#issuecomment-318691479:60,Availability,error,errorIfMissingData,60,Change commit message to `Replace --allowMissingData with --errorIfMissingData (gives opposite default behavior as previously) and print NA for null object in VariantsToTable`.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3190#issuecomment-318691479
https://github.com/broadinstitute/gatk/pull/3190#issuecomment-318691479:14,Integrability,message,message,14,Change commit message to `Replace --allowMissingData with --errorIfMissingData (gives opposite default behavior as previously) and print NA for null object in VariantsToTable`.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3190#issuecomment-318691479
https://github.com/broadinstitute/gatk/pull/3195#issuecomment-311922508:3333,Deployability,pipeline,pipelines,3333,93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `87.333% <100%> ()` | `42 <0> ()` | :arrow_down: |; | [...walkers/haplotypecaller/HaplotypeCallerEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/3195?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJFbmdpbmUuamF2YQ==) | `73.208% <100%> ()` | `55 <0> ()` | :arrow_down: |; | [...ellbender/tools/walkers/bqsr/BaseRecalibrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/3195?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQmFzZVJlY2FsaWJyYXRvci5qYXZh) | `88.372% <100%> ()` | `11 <0> ()` | :arrow_down: |; | [...itute/hellbender/tools/walkers/qc/CheckPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/3195?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3FjL0NoZWNrUGlsZXVwLmphdmE=) | `64.151% <100%> ()` | `11 <0> ()` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3195?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3195?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3195?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | ... and [16 more](https://codecov.io/gh/broadinstitute/gatk/pull/3195?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3195#issuecomment-311922508
https://github.com/broadinstitute/gatk/pull/3195#issuecomment-327440250:268,Usability,clear,clear,268,"Next commit includes:. * Change the name to PrimaryLineReadFilter; * Remove impl notes completely, because if they aren't tags, they will be populated to the user documentation. With the name change, I believe that it isn't necessary anymore: with the current text is clear that the concept of primary alignment is more stringent for this filter, the name change clarify that it is a different filter than the previous GATK versions, and the name of HTSJDK flag is also different. Back to you @cmnbroad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3195#issuecomment-327440250
https://github.com/broadinstitute/gatk/pull/3195#issuecomment-328841365:70,Deployability,update,update,70,"@magicDSG Can you rebase this since it now has conflicts with the doc update PR, and then we can merge when test pass (might as well squash as well.) Thx.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3195#issuecomment-328841365
https://github.com/broadinstitute/gatk/pull/3195#issuecomment-328841365:108,Testability,test,test,108,"@magicDSG Can you rebase this since it now has conflicts with the doc update PR, and then we can merge when test pass (might as well squash as well.) Thx.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3195#issuecomment-328841365
https://github.com/broadinstitute/gatk/pull/3195#issuecomment-329124206:61,Usability,feedback,feedback,61,Thanks you for accepting it... and all the reviewers for the feedback!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3195#issuecomment-329124206
https://github.com/broadinstitute/gatk/issues/3199#issuecomment-311986024:186,Security,authenticat,authentication,186,"Agree that a separate README for the binary distribution is a good idea, but the document linked to above lacks basic instructions on things like running on a cluster and setting up GCS authentication. I think the doc should be based on the repo README instead with some sections omitted. It would actually be best if it could be generated automatically somehow from the repo README, so that we don't have to edit two documents whenever we make a change.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3199#issuecomment-311986024
https://github.com/broadinstitute/gatk/issues/3199#issuecomment-312009716:73,Availability,down,down,73,"Not really... after further thought I think it would be cleaner to break down the main readme into two docs -- one quickstart doc for end users with usage instructions etc that we can include in the distro, and one for developers with compilation instructions etc that is repo only. I know you didn't want to move anything to the wiki in order to keep everything versioned, which I agree makes sense -- so this would preserve that. . Either one could be the ""main"" README, and each would have a preface pointing at the other, or we could have a very short master README pointing to both.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3199#issuecomment-312009716
https://github.com/broadinstitute/gatk/issues/3199#issuecomment-312054764:94,Security,authenticat,authentication,94,"Questions from developers, mainly, about things like ""my IntelliJ project is broken"" and ""GCS authentication not working"" -- you get the picture :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3199#issuecomment-312054764
https://github.com/broadinstitute/gatk/pull/3201#issuecomment-312320498:2470,Testability,test,test,2470,lYWRBZGFwdGVyLmphdmE=) | `89.756% <100%> (+0.05%)` | `125 <1> (+1)` | :arrow_up: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3201?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-80.612%)` | `0% <0%> (-19%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3201?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3201?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3201?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3201?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `41.216% <0%> (-30.405%)` | `26% <0%> (-8%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3201?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3201?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGV,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3201#issuecomment-312320498
https://github.com/broadinstitute/gatk/pull/3201#issuecomment-313631668:241,Integrability,interface,interface,241,"Opps, I've just realized that the SAM specs will use the US-ASCII encoding (https://github.com/samtools/hts-specs/pull/205) unless it is specified UTF-8. Maybe a method to retrieve the `String` with a provided charset should be added to the interface... Thoughts on that, @lbergelson? I think that it will be a good idea to include US-ASCII or whatever is the default in `ReadConstants` and specify that in the documentation...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3201#issuecomment-313631668
https://github.com/broadinstitute/gatk/pull/3203#issuecomment-313156153:12,Performance,Perform,Performance,12,"@samuelklee Performance was comparable on one exome bam using the 5M sites file. Each took ~15 minutes. Sample size of 1, though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3203#issuecomment-313156153
https://github.com/broadinstitute/gatk/pull/3203#issuecomment-314456914:53,Testability,test,test,53,"@cmnbroad and @samuelklee : I am going to remove the test (``testNonStrictBAMWithSilentValidationStringency`) and if auto-tests pass, I am going to merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3203#issuecomment-314456914
https://github.com/broadinstitute/gatk/pull/3203#issuecomment-314456914:61,Testability,test,testNonStrictBAMWithSilentValidationStringency,61,"@cmnbroad and @samuelklee : I am going to remove the test (``testNonStrictBAMWithSilentValidationStringency`) and if auto-tests pass, I am going to merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3203#issuecomment-314456914
https://github.com/broadinstitute/gatk/pull/3203#issuecomment-314456914:122,Testability,test,tests,122,"@cmnbroad and @samuelklee : I am going to remove the test (``testNonStrictBAMWithSilentValidationStringency`) and if auto-tests pass, I am going to merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3203#issuecomment-314456914
https://github.com/broadinstitute/gatk/pull/3203#issuecomment-314458485:32,Deployability,update,update,32,"@LeeTL1220 OK by me, but please update the example command line in the javadoc (change the siteIntervals argument).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3203#issuecomment-314458485
https://github.com/broadinstitute/gatk/issues/3207#issuecomment-312446583:342,Availability,down,download,342,"Hi @ycl6, please post your questions to the GATK forum at <http://gatkforums.broadinstitute.org/gatk>. . It has been removed in GATK4. GATK4 Mutect2 now takes a known population variants resource, e.g. gnomAD, with allele-specific frequencies. I've put such an example resource in the GATK bundle at <https://software.broadinstitute.org/gatk/download/bundle>, in the folder labeled `beta`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3207#issuecomment-312446583
https://github.com/broadinstitute/gatk/issues/3208#issuecomment-312504138:36,Testability,test,test,36,"For @lbergelson, since he wrote the test in question",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3208#issuecomment-312504138
https://github.com/broadinstitute/gatk/issues/3209#issuecomment-313504079:169,Availability,error,error,169,"@droazen I have a PR for gatk-bwa-mem that adds a footer to the image file so that we can test integrity. I also added code to test every (I think) call that returns an error indication, and pass this info up the chain. Could you review the PR or delegate, please?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3209#issuecomment-313504079
https://github.com/broadinstitute/gatk/issues/3209#issuecomment-313504079:95,Security,integrity,integrity,95,"@droazen I have a PR for gatk-bwa-mem that adds a footer to the image file so that we can test integrity. I also added code to test every (I think) call that returns an error indication, and pass this info up the chain. Could you review the PR or delegate, please?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3209#issuecomment-313504079
https://github.com/broadinstitute/gatk/issues/3209#issuecomment-313504079:90,Testability,test,test,90,"@droazen I have a PR for gatk-bwa-mem that adds a footer to the image file so that we can test integrity. I also added code to test every (I think) call that returns an error indication, and pass this info up the chain. Could you review the PR or delegate, please?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3209#issuecomment-313504079
https://github.com/broadinstitute/gatk/issues/3209#issuecomment-313504079:127,Testability,test,test,127,"@droazen I have a PR for gatk-bwa-mem that adds a footer to the image file so that we can test integrity. I also added code to test every (I think) call that returns an error indication, and pass this info up the chain. Could you review the PR or delegate, please?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3209#issuecomment-313504079
https://github.com/broadinstitute/gatk/issues/3209#issuecomment-313532473:68,Availability,error,error,68,"@droazen Ditto for gatk-fermi-lite: there's a new PR that adds some error handling. However, that artifact is hooked up to Travis, which fails. So I'll probably need some help from @lbergelson to get that sorted out -- gradle is missing an assemble verb. Can you review the PR or assign a reviewer, please?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3209#issuecomment-313532473
https://github.com/broadinstitute/gatk/issues/3210#issuecomment-312645404:1526,Availability,ping,ping,1526,"Was the NPE for a sample or shard?. Sent from an iPhone and typed with my thumbs. . > On Jul 3, 2017, at 8:31 AM, Eric Banks <notifications@github.com> wrote:; > ; > In a joint calling run with 11,000 samples, and broken up into over 10,000 scatters, a single one failed with a NPE. I was able to get around it for now by just ignoring that scatter for the output, but that's really not an ideal thing to do for joint calling (and we cannot do that for the CCDG callset). I can't give you the inputs because it was running on so many samples (and via GenomicsDB), but hopefully the stacktrace will help here:; > ; > java.lang.NullPointerException; > at org.broadinstitute.hellbender.tools.walkers.genotyper.AlleleSubsettingUtils.calculateLikelihoodSums(AlleleSubsettingUtils.java:234); > at org.broadinstitute.hellbender.tools.walkers.genotyper.AlleleSubsettingUtils.calculateMostLikelyAlleles(AlleleSubsettingUtils.java:199); > at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:241); > at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:205); > at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.calculateGenotypes(GenotypeGVCFs.java:276); > at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.regenotypeVC(GenotypeGVCFs.java:234); > at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:213); > ; > I'm not sure who now owns this code, so will ping @davidbenjamin, @ldgauthier, @droazen.; > ; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3210#issuecomment-312645404
https://github.com/broadinstitute/gatk/issues/3211#issuecomment-312964885:13,Deployability,update,updated,13,Done -- also updated to use software instead of www,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3211#issuecomment-312964885
https://github.com/broadinstitute/gatk/pull/3213#issuecomment-313071566:2126,Testability,test,test,2126,pbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `89.394% <100%> (-1.082%)` | `61 <2> ()` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3213?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-80.612%)` | `0% <0%> (-19%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3213?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3213?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3213?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3213?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `41.216% <0%> (-30.405%)` | `26% <0%> (-8%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3213?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...titute/hellbender/tools/spark/sv/SVFastqUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3213?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGV,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3213#issuecomment-313071566
https://github.com/broadinstitute/gatk/pull/3213#issuecomment-316107369:12,Testability,test,tests,12,I added the tests for the new method and default to unsorted. Back to you @lbergelson and thanks for reviewing!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3213#issuecomment-316107369
https://github.com/broadinstitute/gatk/pull/3217#issuecomment-313238500:57,Security,access,access,57,"looks like we need to run a special fetch command to get access to the pr merge commits, ex:; ```; git fetch origin +refs/pull/3217/merge; ```; Looks like the change is a bit more complicated than I hoped.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3217#issuecomment-313238500
https://github.com/broadinstitute/gatk/pull/3223#issuecomment-313637587:2152,Testability,test,test,2152,R0FUS1JlYWRBZGFwdGVyLmphdmE=) | `89.423% <66.667%> (-0.333%)` | `126 <0> (+1)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3223?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-80.612%)` | `0% <0%> (-19%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3223?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3223?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3223?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3223?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `41.216% <0%> (-32.432%)` | `26% <0%> (-8%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3223?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3223?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGV,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3223#issuecomment-313637587
https://github.com/broadinstitute/gatk/pull/3223#issuecomment-313637587:3602,Testability,test,test,3602,W4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3223?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3223?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `41.216% <0%> (-32.432%)` | `26% <0%> (-8%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3223?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3223?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3223?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `70.37% <0%> (-11.111%)` | `10% <0%> ()` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3223?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | ... and [38 more](https://codecov.io/gh/broadinstitute/gatk/pull/3223?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3223#issuecomment-313637587
https://github.com/broadinstitute/gatk/pull/3223#issuecomment-315860199:69,Testability,test,test,69,"@magicDGS Good catch, that's a bad bug. Would you mind adding a unit test for the new code?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3223#issuecomment-315860199
https://github.com/broadinstitute/gatk/pull/3223#issuecomment-316088747:56,Testability,test,tests,56,@magicDGS Thank you. Looks good. I will merge this once tests pass.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3223#issuecomment-316088747
https://github.com/broadinstitute/gatk/issues/3224#issuecomment-313876142:19,Modifiability,refactor,refactoring,19,Being handled in a refactoring branch. I can take it out and make a small PR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3224#issuecomment-313876142
https://github.com/broadinstitute/gatk/issues/3225#issuecomment-313876090:137,Performance,perform,performance,137,@cwhelan Can you please provide some of these calls? I am considering filtering the mapping/alignments and want to evaluate the filter's performance. Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3225#issuecomment-313876090
https://github.com/broadinstitute/gatk/pull/3228#issuecomment-313982114:16,Testability,test,tests,16,@takutosato Are tests failing because you still need to commit the wgs intervals file?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3228#issuecomment-313982114
https://github.com/broadinstitute/gatk/pull/3228#issuecomment-314209891:1208,Security,validat,validation,1208,titute/gatk/commit/9d9ca1ff31f99d8005c822e55aaccce967427383?src=pr&el=desc) will **increase** coverage by `0.008%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #3228 +/- ##; ===============================================; + Coverage 80.419% 80.427% +0.008% ; Complexity 17290 17290 ; ===============================================; Files 1165 1165 ; Lines 62596 62597 +1 ; Branches 9768 9768 ; ===============================================; + Hits 50339 50345 +6 ; + Misses 8352 8347 -5 ; Partials 3905 3905; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `83.704% <100%> (+0.122%)` | `36 <0> ()` | :arrow_down: |; | [.../tools/walkers/validation/CountFalsePositives.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ291bnRGYWxzZVBvc2l0aXZlcy5qYXZh) | `93.548% <100%> ()` | `7 <1> ()` | :arrow_down: |; | [.../tools/walkers/validation/FalsePositiveRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vRmFsc2VQb3NpdGl2ZVJlY29yZC5qYXZh) | `100% <100%> ()` | `7 <2> ()` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `73.649% <0%> (+2.027%)` | `34% <0%> ()` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3228#issuecomment-314209891
https://github.com/broadinstitute/gatk/pull/3228#issuecomment-314209891:1519,Security,validat,validation,1519,; ## master #3228 +/- ##; ===============================================; + Coverage 80.419% 80.427% +0.008% ; Complexity 17290 17290 ; ===============================================; Files 1165 1165 ; Lines 62596 62597 +1 ; Branches 9768 9768 ; ===============================================; + Hits 50339 50345 +6 ; + Misses 8352 8347 -5 ; Partials 3905 3905; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `83.704% <100%> (+0.122%)` | `36 <0> ()` | :arrow_down: |; | [.../tools/walkers/validation/CountFalsePositives.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ291bnRGYWxzZVBvc2l0aXZlcy5qYXZh) | `93.548% <100%> ()` | `7 <1> ()` | :arrow_down: |; | [.../tools/walkers/validation/FalsePositiveRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vRmFsc2VQb3NpdGl2ZVJlY29yZC5qYXZh) | `100% <100%> ()` | `7 <2> ()` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `73.649% <0%> (+2.027%)` | `34% <0%> ()` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `70% <0%> (+3.333%)` | `10% <0%> ()` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3228#issuecomment-314209891
https://github.com/broadinstitute/gatk/pull/3228#issuecomment-314209891:939,Testability,test,test,939,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=h1) Report; > Merging [#3228](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/9d9ca1ff31f99d8005c822e55aaccce967427383?src=pr&el=desc) will **increase** coverage by `0.008%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #3228 +/- ##; ===============================================; + Coverage 80.419% 80.427% +0.008% ; Complexity 17290 17290 ; ===============================================; Files 1165 1165 ; Lines 62596 62597 +1 ; Branches 9768 9768 ; ===============================================; + Hits 50339 50345 +6 ; + Misses 8352 8347 -5 ; Partials 3905 3905; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `83.704% <100%> (+0.122%)` | `36 <0> ()` | :arrow_down: |; | [.../tools/walkers/validation/CountFalsePositives.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ291bnRGYWxzZVBvc2l0aXZlcy5qYXZh) | `93.548% <100%> ()` | `7 <1> ()` | :arrow_down: |; | [.../tools/walkers/validation/FalsePositiveRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vRmFsc2VQb3NpdGl2ZVJlY29yZC5qYXZh) | `100% <100%> ()` | `7 <2> ()` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3228?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlsc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3228#issuecomment-314209891
https://github.com/broadinstitute/gatk/issues/3230#issuecomment-313891523:144,Security,validat,validation,144,@samuelklee the problem is that I need something pretty quickly here. I'm guessing that changing the GMM algorithm is going to require a ton of validation...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3230#issuecomment-313891523
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314173877:1273,Availability,down,downsampling,1273,l=desc) will **increase** coverage by `0.231%`.; > The diff coverage is `93.023%`. ```diff; @@ Coverage Diff @@; ## master #3238 +/- ##; ===============================================; + Coverage 80.415% 80.646% +0.231% ; - Complexity 17294 17689 +395 ; ===============================================; Files 1165 1169 +4 ; Lines 62573 63970 +1397 ; Branches 9763 10015 +252 ; ===============================================; + Hits 50318 51589 +1271 ; - Misses 8350 8450 +100 ; - Partials 3905 3931 +26; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...tools/walkers/haplotypecaller/HaplotypeCaller.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXIuamF2YQ==) | `94.595% <100%> (+0.477%)` | `21 <3> (+3)` | :arrow_up: |; | [...ender/utils/downsampling/ReservoirDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXIuamF2YQ==) | `100% <100%> ()` | `25 <3> (+4)` | :arrow_up: |; | [...itute/hellbender/tools/walkers/mutect/Mutect2.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyLmphdmE=) | `93.333% <100%> (+0.741%)` | `19 <3> (+3)` | :arrow_up: |; | [...er/tools/examples/ExampleAssemblyRegionWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9FeGFtcGxlQXNzZW1ibHlSZWdpb25XYWxrZXIuamF2YQ==) | `83.784% <100%> (+1.431%)` | `19 <3> (+3)` | :arrow_up: |; | [...titute/hellbender/engine/AssemblyRegionWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314173877
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314173877:2491,Availability,down,downsampling,2491,==) | `100% <100%> ()` | `25 <3> (+4)` | :arrow_up: |; | [...itute/hellbender/tools/walkers/mutect/Mutect2.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyLmphdmE=) | `93.333% <100%> (+0.741%)` | `19 <3> (+3)` | :arrow_up: |; | [...er/tools/examples/ExampleAssemblyRegionWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9FeGFtcGxlQXNzZW1ibHlSZWdpb25XYWxrZXIuamF2YQ==) | `83.784% <100%> (+1.431%)` | `19 <3> (+3)` | :arrow_up: |; | [...titute/hellbender/engine/AssemblyRegionWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXNzZW1ibHlSZWdpb25XYWxrZXIuamF2YQ==) | `85.135% <85.714%> (+1.312%)` | `15 <0> ()` | :arrow_down: |; | [...nder/utils/downsampling/PositionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUG9zaXRpb25hbERvd25zYW1wbGVyLmphdmE=) | `96% <88.889%> (-1.674%)` | `23 <7> (+3)` | |; | [...institute/hellbender/tools/exome/TargetWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9UYXJnZXRXcml0ZXIuamF2YQ==) | `89.744% <0%> (-3.805%)` | `9% <0%> (+2%)` | |; | [.../broadinstitute/hellbender/engine/LocusWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTG9jdXNXYWxrZXIuamF2YQ==) | `77.083% <0%> (-2.227%)` | `33% <0%> (+13%)` | |; | [...lbender/utils/read/SAMRecordToGATKReadAdapter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3238?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314173877
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314200383:130,Availability,down,downsampler,130,@davidbenjamin We should chat about this in person -- have some questions for you. Some of the functionality you removed from the downsampler interface is needed by code that is not yet ported.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314200383
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314200383:142,Integrability,interface,interface,142,@davidbenjamin We should chat about this in person -- have some questions for you. Some of the functionality you removed from the downsampler interface is needed by code that is not yet ported.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314200383
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314319556:156,Availability,down,downsampler,156,"@droazen yes, let's discuss. There's no need to remove those methods as far as Mutect is concerned. As long as we implement the new functionality in *some* downsampler class, we have what we need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314319556
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314545787:199,Availability,down,downsampler,199,"@davidbenjamin This branch seems to have a lot of unrelated refactoring bundled in with the substantive fix for `Mutect2`, and some of this refactoring seems problematic to me (eg., deletion of some downsampler API methods that will be needed when `ReadWalker` downsampling is ported). . Since mixing refactoring into the same PR as behavioral changes is asking for trouble as a general rule, could I ask you to strip out everything except the substantive change to `PositionalDownsampler` from this PR? Happy to do a quick review once this is done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314545787
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314545787:261,Availability,down,downsampling,261,"@davidbenjamin This branch seems to have a lot of unrelated refactoring bundled in with the substantive fix for `Mutect2`, and some of this refactoring seems problematic to me (eg., deletion of some downsampler API methods that will be needed when `ReadWalker` downsampling is ported). . Since mixing refactoring into the same PR as behavioral changes is asking for trouble as a general rule, could I ask you to strip out everything except the substantive change to `PositionalDownsampler` from this PR? Happy to do a quick review once this is done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314545787
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314545787:60,Modifiability,refactor,refactoring,60,"@davidbenjamin This branch seems to have a lot of unrelated refactoring bundled in with the substantive fix for `Mutect2`, and some of this refactoring seems problematic to me (eg., deletion of some downsampler API methods that will be needed when `ReadWalker` downsampling is ported). . Since mixing refactoring into the same PR as behavioral changes is asking for trouble as a general rule, could I ask you to strip out everything except the substantive change to `PositionalDownsampler` from this PR? Happy to do a quick review once this is done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314545787
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314545787:140,Modifiability,refactor,refactoring,140,"@davidbenjamin This branch seems to have a lot of unrelated refactoring bundled in with the substantive fix for `Mutect2`, and some of this refactoring seems problematic to me (eg., deletion of some downsampler API methods that will be needed when `ReadWalker` downsampling is ported). . Since mixing refactoring into the same PR as behavioral changes is asking for trouble as a general rule, could I ask you to strip out everything except the substantive change to `PositionalDownsampler` from this PR? Happy to do a quick review once this is done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314545787
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314545787:301,Modifiability,refactor,refactoring,301,"@davidbenjamin This branch seems to have a lot of unrelated refactoring bundled in with the substantive fix for `Mutect2`, and some of this refactoring seems problematic to me (eg., deletion of some downsampler API methods that will be needed when `ReadWalker` downsampling is ported). . Since mixing refactoring into the same PR as behavioral changes is asking for trouble as a general rule, could I ask you to strip out everything except the substantive change to `PositionalDownsampler` from this PR? Happy to do a quick review once this is done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-314545787
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-321352223:47,Deployability,patch,patch,47,@droazen Do you still want to give me a memory patch to test?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-321352223
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-321352223:56,Testability,test,test,56,@droazen Do you still want to give me a memory patch to test?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-321352223
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-321368872:38,Deployability,patch,patch,38,"@davidbenjamin Yes, I am testing that patch out now -- should be ready for you to try out tomorrow!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-321368872
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-321368872:25,Testability,test,testing,25,"@davidbenjamin Yes, I am testing that patch out now -- should be ready for you to try out tomorrow!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-321368872
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233:299,Availability,down,downsampling,299,"@davidbenjamin As discussed in person, it's my hope that the `AssemblyRegionWalker` changes in https://github.com/broadinstitute/gatk/commit/1ef09b3ca265209e0777c77a8519da74480908ce (which have now been merged into master!) will address `Mutect2` memory usage, and make these somewhat confusing new downsampling arguments unnecessary. That patch reduces the number of reads stored in memory at once by the engine by roughly an order of magnitude without doing any extra downsampling at all. I suggest that we do an evaluation to test whether this really resolves the issues you encountered. `Mutect2` is already hooked up to the new, lower-memory traversal code in the latest gatk/master, so all you have to do is re-run your benchmarking test. I'd suggest that you:. 1. Run with default settings in the latest master, and see if that alone does the trick!. 2. If not, try turning up the existing downsampling a bit. Eg., run with `--maxReadsPerAlignmentStart 10` instead of the default of 50. 3. If that still doesn't resolve the problem, we can revisit this PR and consider a simplified version of the downsampling args here for merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233:470,Availability,down,downsampling,470,"@davidbenjamin As discussed in person, it's my hope that the `AssemblyRegionWalker` changes in https://github.com/broadinstitute/gatk/commit/1ef09b3ca265209e0777c77a8519da74480908ce (which have now been merged into master!) will address `Mutect2` memory usage, and make these somewhat confusing new downsampling arguments unnecessary. That patch reduces the number of reads stored in memory at once by the engine by roughly an order of magnitude without doing any extra downsampling at all. I suggest that we do an evaluation to test whether this really resolves the issues you encountered. `Mutect2` is already hooked up to the new, lower-memory traversal code in the latest gatk/master, so all you have to do is re-run your benchmarking test. I'd suggest that you:. 1. Run with default settings in the latest master, and see if that alone does the trick!. 2. If not, try turning up the existing downsampling a bit. Eg., run with `--maxReadsPerAlignmentStart 10` instead of the default of 50. 3. If that still doesn't resolve the problem, we can revisit this PR and consider a simplified version of the downsampling args here for merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233:897,Availability,down,downsampling,897,"@davidbenjamin As discussed in person, it's my hope that the `AssemblyRegionWalker` changes in https://github.com/broadinstitute/gatk/commit/1ef09b3ca265209e0777c77a8519da74480908ce (which have now been merged into master!) will address `Mutect2` memory usage, and make these somewhat confusing new downsampling arguments unnecessary. That patch reduces the number of reads stored in memory at once by the engine by roughly an order of magnitude without doing any extra downsampling at all. I suggest that we do an evaluation to test whether this really resolves the issues you encountered. `Mutect2` is already hooked up to the new, lower-memory traversal code in the latest gatk/master, so all you have to do is re-run your benchmarking test. I'd suggest that you:. 1. Run with default settings in the latest master, and see if that alone does the trick!. 2. If not, try turning up the existing downsampling a bit. Eg., run with `--maxReadsPerAlignmentStart 10` instead of the default of 50. 3. If that still doesn't resolve the problem, we can revisit this PR and consider a simplified version of the downsampling args here for merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233:1104,Availability,down,downsampling,1104,"@davidbenjamin As discussed in person, it's my hope that the `AssemblyRegionWalker` changes in https://github.com/broadinstitute/gatk/commit/1ef09b3ca265209e0777c77a8519da74480908ce (which have now been merged into master!) will address `Mutect2` memory usage, and make these somewhat confusing new downsampling arguments unnecessary. That patch reduces the number of reads stored in memory at once by the engine by roughly an order of magnitude without doing any extra downsampling at all. I suggest that we do an evaluation to test whether this really resolves the issues you encountered. `Mutect2` is already hooked up to the new, lower-memory traversal code in the latest gatk/master, so all you have to do is re-run your benchmarking test. I'd suggest that you:. 1. Run with default settings in the latest master, and see if that alone does the trick!. 2. If not, try turning up the existing downsampling a bit. Eg., run with `--maxReadsPerAlignmentStart 10` instead of the default of 50. 3. If that still doesn't resolve the problem, we can revisit this PR and consider a simplified version of the downsampling args here for merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233:340,Deployability,patch,patch,340,"@davidbenjamin As discussed in person, it's my hope that the `AssemblyRegionWalker` changes in https://github.com/broadinstitute/gatk/commit/1ef09b3ca265209e0777c77a8519da74480908ce (which have now been merged into master!) will address `Mutect2` memory usage, and make these somewhat confusing new downsampling arguments unnecessary. That patch reduces the number of reads stored in memory at once by the engine by roughly an order of magnitude without doing any extra downsampling at all. I suggest that we do an evaluation to test whether this really resolves the issues you encountered. `Mutect2` is already hooked up to the new, lower-memory traversal code in the latest gatk/master, so all you have to do is re-run your benchmarking test. I'd suggest that you:. 1. Run with default settings in the latest master, and see if that alone does the trick!. 2. If not, try turning up the existing downsampling a bit. Eg., run with `--maxReadsPerAlignmentStart 10` instead of the default of 50. 3. If that still doesn't resolve the problem, we can revisit this PR and consider a simplified version of the downsampling args here for merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233:346,Energy Efficiency,reduce,reduces,346,"@davidbenjamin As discussed in person, it's my hope that the `AssemblyRegionWalker` changes in https://github.com/broadinstitute/gatk/commit/1ef09b3ca265209e0777c77a8519da74480908ce (which have now been merged into master!) will address `Mutect2` memory usage, and make these somewhat confusing new downsampling arguments unnecessary. That patch reduces the number of reads stored in memory at once by the engine by roughly an order of magnitude without doing any extra downsampling at all. I suggest that we do an evaluation to test whether this really resolves the issues you encountered. `Mutect2` is already hooked up to the new, lower-memory traversal code in the latest gatk/master, so all you have to do is re-run your benchmarking test. I'd suggest that you:. 1. Run with default settings in the latest master, and see if that alone does the trick!. 2. If not, try turning up the existing downsampling a bit. Eg., run with `--maxReadsPerAlignmentStart 10` instead of the default of 50. 3. If that still doesn't resolve the problem, we can revisit this PR and consider a simplified version of the downsampling args here for merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233:529,Testability,test,test,529,"@davidbenjamin As discussed in person, it's my hope that the `AssemblyRegionWalker` changes in https://github.com/broadinstitute/gatk/commit/1ef09b3ca265209e0777c77a8519da74480908ce (which have now been merged into master!) will address `Mutect2` memory usage, and make these somewhat confusing new downsampling arguments unnecessary. That patch reduces the number of reads stored in memory at once by the engine by roughly an order of magnitude without doing any extra downsampling at all. I suggest that we do an evaluation to test whether this really resolves the issues you encountered. `Mutect2` is already hooked up to the new, lower-memory traversal code in the latest gatk/master, so all you have to do is re-run your benchmarking test. I'd suggest that you:. 1. Run with default settings in the latest master, and see if that alone does the trick!. 2. If not, try turning up the existing downsampling a bit. Eg., run with `--maxReadsPerAlignmentStart 10` instead of the default of 50. 3. If that still doesn't resolve the problem, we can revisit this PR and consider a simplified version of the downsampling args here for merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233:726,Testability,benchmark,benchmarking,726,"@davidbenjamin As discussed in person, it's my hope that the `AssemblyRegionWalker` changes in https://github.com/broadinstitute/gatk/commit/1ef09b3ca265209e0777c77a8519da74480908ce (which have now been merged into master!) will address `Mutect2` memory usage, and make these somewhat confusing new downsampling arguments unnecessary. That patch reduces the number of reads stored in memory at once by the engine by roughly an order of magnitude without doing any extra downsampling at all. I suggest that we do an evaluation to test whether this really resolves the issues you encountered. `Mutect2` is already hooked up to the new, lower-memory traversal code in the latest gatk/master, so all you have to do is re-run your benchmarking test. I'd suggest that you:. 1. Run with default settings in the latest master, and see if that alone does the trick!. 2. If not, try turning up the existing downsampling a bit. Eg., run with `--maxReadsPerAlignmentStart 10` instead of the default of 50. 3. If that still doesn't resolve the problem, we can revisit this PR and consider a simplified version of the downsampling args here for merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233:739,Testability,test,test,739,"@davidbenjamin As discussed in person, it's my hope that the `AssemblyRegionWalker` changes in https://github.com/broadinstitute/gatk/commit/1ef09b3ca265209e0777c77a8519da74480908ce (which have now been merged into master!) will address `Mutect2` memory usage, and make these somewhat confusing new downsampling arguments unnecessary. That patch reduces the number of reads stored in memory at once by the engine by roughly an order of magnitude without doing any extra downsampling at all. I suggest that we do an evaluation to test whether this really resolves the issues you encountered. `Mutect2` is already hooked up to the new, lower-memory traversal code in the latest gatk/master, so all you have to do is re-run your benchmarking test. I'd suggest that you:. 1. Run with default settings in the latest master, and see if that alone does the trick!. 2. If not, try turning up the existing downsampling a bit. Eg., run with `--maxReadsPerAlignmentStart 10` instead of the default of 50. 3. If that still doesn't resolve the problem, we can revisit this PR and consider a simplified version of the downsampling args here for merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233:1078,Usability,simpl,simplified,1078,"@davidbenjamin As discussed in person, it's my hope that the `AssemblyRegionWalker` changes in https://github.com/broadinstitute/gatk/commit/1ef09b3ca265209e0777c77a8519da74480908ce (which have now been merged into master!) will address `Mutect2` memory usage, and make these somewhat confusing new downsampling arguments unnecessary. That patch reduces the number of reads stored in memory at once by the engine by roughly an order of magnitude without doing any extra downsampling at all. I suggest that we do an evaluation to test whether this really resolves the issues you encountered. `Mutect2` is already hooked up to the new, lower-memory traversal code in the latest gatk/master, so all you have to do is re-run your benchmarking test. I'd suggest that you:. 1. Run with default settings in the latest master, and see if that alone does the trick!. 2. If not, try turning up the existing downsampling a bit. Eg., run with `--maxReadsPerAlignmentStart 10` instead of the default of 50. 3. If that still doesn't resolve the problem, we can revisit this PR and consider a simplified version of the downsampling args here for merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-325073233
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-328114307:195,Availability,down,downsampling,195,"@lbergelson As David R asked I compared the run-time of this branch to the master branch, with his most recent changes to memory use in shards. His changes helped, but with equivalent amounts of downsampling this branch remains 30% faster in total CPU time and about 40% faster in wall clock time. He instructed me to pass the review on to you if a difference like this remained.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-328114307
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330324547:114,Deployability,patch,patch,114,"@davidbenjamin Let me do a bit of profiling/optimization on the new code path to see if I can narrow the gap. The patch was intended to address memory use rather than runtime, and could use a profiling pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330324547
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330324547:44,Performance,optimiz,optimization,44,"@davidbenjamin Let me do a bit of profiling/optimization on the new code path to see if I can narrow the gap. The patch was intended to address memory use rather than runtime, and could use a profiling pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330324547
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330904636:97,Testability,test,tests,97,@davidbenjamin Can you tell me whether you were running with or without an interval list in your tests?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330904636
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330910227:450,Availability,down,downsampling,450,"Aha, good -- that's consistent with @skwalker's results showing a ~30%-40% performance regression vs. GATK3 when using a large interval list + the latest GATK4 HC. I think this is something we can resolve through profiling -- I'll update you in a few days with my progress. In the mean time, it would be valuable to me to know whether you see the same performance difference in Mutect2 when running *without* an interval list (latest master vs. this downsampling branch). Perhaps you could create a large-but-not-too-large bam snippet to test that out?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330910227
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330910227:231,Deployability,update,update,231,"Aha, good -- that's consistent with @skwalker's results showing a ~30%-40% performance regression vs. GATK3 when using a large interval list + the latest GATK4 HC. I think this is something we can resolve through profiling -- I'll update you in a few days with my progress. In the mean time, it would be valuable to me to know whether you see the same performance difference in Mutect2 when running *without* an interval list (latest master vs. this downsampling branch). Perhaps you could create a large-but-not-too-large bam snippet to test that out?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330910227
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330910227:75,Performance,perform,performance,75,"Aha, good -- that's consistent with @skwalker's results showing a ~30%-40% performance regression vs. GATK3 when using a large interval list + the latest GATK4 HC. I think this is something we can resolve through profiling -- I'll update you in a few days with my progress. In the mean time, it would be valuable to me to know whether you see the same performance difference in Mutect2 when running *without* an interval list (latest master vs. this downsampling branch). Perhaps you could create a large-but-not-too-large bam snippet to test that out?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330910227
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330910227:352,Performance,perform,performance,352,"Aha, good -- that's consistent with @skwalker's results showing a ~30%-40% performance regression vs. GATK3 when using a large interval list + the latest GATK4 HC. I think this is something we can resolve through profiling -- I'll update you in a few days with my progress. In the mean time, it would be valuable to me to know whether you see the same performance difference in Mutect2 when running *without* an interval list (latest master vs. this downsampling branch). Perhaps you could create a large-but-not-too-large bam snippet to test that out?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330910227
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330910227:538,Testability,test,test,538,"Aha, good -- that's consistent with @skwalker's results showing a ~30%-40% performance regression vs. GATK3 when using a large interval list + the latest GATK4 HC. I think this is something we can resolve through profiling -- I'll update you in a few days with my progress. In the mean time, it would be valuable to me to know whether you see the same performance difference in Mutect2 when running *without* an interval list (latest master vs. this downsampling branch). Perhaps you could create a large-but-not-too-large bam snippet to test that out?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330910227
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330921307:243,Availability,down,downsampling,243,"Actually, if you have the time, an even more valuable test would be to repeat your comparison with latest master vs. a rebased copy of this branch onto latest master. That would tell us whether the performance difference you saw is due to the downsampling, or due to the differences in the traversal code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330921307
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330921307:198,Performance,perform,performance,198,"Actually, if you have the time, an even more valuable test would be to repeat your comparison with latest master vs. a rebased copy of this branch onto latest master. That would tell us whether the performance difference you saw is due to the downsampling, or due to the differences in the traversal code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330921307
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330921307:54,Testability,test,test,54,"Actually, if you have the time, an even more valuable test would be to repeat your comparison with latest master vs. a rebased copy of this branch onto latest master. That would tell us whether the performance difference you saw is due to the downsampling, or due to the differences in the traversal code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-330921307
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-341741374:176,Availability,down,downsampling,176,"@droazen I rebased against master on 11/1, and ran on several tumor-normal pairs with and without interval lists. The total CPU time remains about 30-40% better in the rebased downsampling branch than in the latest master branch. Also, wall clock time turns out to be a stronger argument in favor of these additions: scattering wgs bams 50 ways, the wall clock time tends to be 3-5x greater in master.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-341741374
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-341838476:97,Availability,down,downsampling,97,"@davidbenjamin I think one essential test you haven't done is to run master with more aggressive downsampling settings using the existing `--maxReadsPerAlignmentStart` argument, and compare that against your branch. This would help us determine whether or not the existing downsampling functionality really is inadequate to control peak memory use and runtime. The current default in `Mutect2` for `--maxReadsPerAlignmentStart` is 50, which is almost certainly much higher than it needs to be. That's 50 * 300 = 15,000 reads per assembly region, with on the order of ~2 regions in memory at any time = 30,000 reads. I propose that we try a run with the current vanilla master and `--maxReadsPerAlignmentStart 3`, and compare that to an identical run on your branch with your new downsampling options.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-341838476
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-341838476:273,Availability,down,downsampling,273,"@davidbenjamin I think one essential test you haven't done is to run master with more aggressive downsampling settings using the existing `--maxReadsPerAlignmentStart` argument, and compare that against your branch. This would help us determine whether or not the existing downsampling functionality really is inadequate to control peak memory use and runtime. The current default in `Mutect2` for `--maxReadsPerAlignmentStart` is 50, which is almost certainly much higher than it needs to be. That's 50 * 300 = 15,000 reads per assembly region, with on the order of ~2 regions in memory at any time = 30,000 reads. I propose that we try a run with the current vanilla master and `--maxReadsPerAlignmentStart 3`, and compare that to an identical run on your branch with your new downsampling options.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-341838476
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-341838476:779,Availability,down,downsampling,779,"@davidbenjamin I think one essential test you haven't done is to run master with more aggressive downsampling settings using the existing `--maxReadsPerAlignmentStart` argument, and compare that against your branch. This would help us determine whether or not the existing downsampling functionality really is inadequate to control peak memory use and runtime. The current default in `Mutect2` for `--maxReadsPerAlignmentStart` is 50, which is almost certainly much higher than it needs to be. That's 50 * 300 = 15,000 reads per assembly region, with on the order of ~2 regions in memory at any time = 30,000 reads. I propose that we try a run with the current vanilla master and `--maxReadsPerAlignmentStart 3`, and compare that to an identical run on your branch with your new downsampling options.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-341838476
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-341838476:37,Testability,test,test,37,"@davidbenjamin I think one essential test you haven't done is to run master with more aggressive downsampling settings using the existing `--maxReadsPerAlignmentStart` argument, and compare that against your branch. This would help us determine whether or not the existing downsampling functionality really is inadequate to control peak memory use and runtime. The current default in `Mutect2` for `--maxReadsPerAlignmentStart` is 50, which is almost certainly much higher than it needs to be. That's 50 * 300 = 15,000 reads per assembly region, with on the order of ~2 regions in memory at any time = 30,000 reads. I propose that we try a run with the current vanilla master and `--maxReadsPerAlignmentStart 3`, and compare that to an identical run on your branch with your new downsampling options.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-341838476
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-341939411:271,Availability,down,downsampling,271,"@droazen I agree that running master with default settings is not a fair comparison. Therefore, I set `-maxReadsPerAlignmentStart` to be equal and much lower than the default in both branches. I have tried a few values, but none lower than 10. I expect that using master downsampling to 3 reads per alignment start will handle most of the runtime issue at some small cost to sensitivity and precision, but let me run it and see what happens.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-341939411
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-342946075:135,Availability,down,downsampling,135,"@droazen Setting master to 3 reads per alignment start and this branch to 30 reads per alignment start with a stride of 10 (i.e. equal downsampling on average) and scattering four wgs bams 50 ways each, CPU time is almost identical but wall clock time is anywhere from 20% to 100% slower in master. Also, sensitivity in master goes down by 0.5% but is unchanged in this branch. I think this makes a good case for the alignment start stride and biasing downsampling to higher mapping quality, but those are not urgent. As we discussed in person, I *don't* like my maxReadsToIgnore region argument, which provides most of the benefit, and I want to explore a read start filter as an alternative. I think that will take less than a week to prototype.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-342946075
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-342946075:332,Availability,down,down,332,"@droazen Setting master to 3 reads per alignment start and this branch to 30 reads per alignment start with a stride of 10 (i.e. equal downsampling on average) and scattering four wgs bams 50 ways each, CPU time is almost identical but wall clock time is anywhere from 20% to 100% slower in master. Also, sensitivity in master goes down by 0.5% but is unchanged in this branch. I think this makes a good case for the alignment start stride and biasing downsampling to higher mapping quality, but those are not urgent. As we discussed in person, I *don't* like my maxReadsToIgnore region argument, which provides most of the benefit, and I want to explore a read start filter as an alternative. I think that will take less than a week to prototype.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-342946075
https://github.com/broadinstitute/gatk/pull/3238#issuecomment-342946075:452,Availability,down,downsampling,452,"@droazen Setting master to 3 reads per alignment start and this branch to 30 reads per alignment start with a stride of 10 (i.e. equal downsampling on average) and scattering four wgs bams 50 ways each, CPU time is almost identical but wall clock time is anywhere from 20% to 100% slower in master. Also, sensitivity in master goes down by 0.5% but is unchanged in this branch. I think this makes a good case for the alignment start stride and biasing downsampling to higher mapping quality, but those are not urgent. As we discussed in person, I *don't* like my maxReadsToIgnore region argument, which provides most of the benefit, and I want to explore a read start filter as an alternative. I think that will take less than a week to prototype.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3238#issuecomment-342946075
https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314260186:42,Availability,error,error,42,"@jean-philippe-martin I get the following error when trying to use the shaded google-cloud-java snapshot jar:. ```; /Users/droazen/.m2/repository/com/google/cloud/google-cloud-nio/0.20.2-alpha-SNAPSHOT/google-cloud-nio-0.20.2-alpha-SNAPSHOT-shaded.jar(com/google/cloud/storage/contrib/nio/CloudStorageFileSystemProvider.class): ; warning: Cannot find annotation method 'value()' in type 'AutoService': ; class file for com.google.auto.service.AutoService not found; ```. Checking the jar, `AutoService` is indeed not present, but is an annotation on `CloudStorageFileSystemProvider`. Any thoughts on what could be causing this? Shading error?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314260186
https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314260186:636,Availability,error,error,636,"@jean-philippe-martin I get the following error when trying to use the shaded google-cloud-java snapshot jar:. ```; /Users/droazen/.m2/repository/com/google/cloud/google-cloud-nio/0.20.2-alpha-SNAPSHOT/google-cloud-nio-0.20.2-alpha-SNAPSHOT-shaded.jar(com/google/cloud/storage/contrib/nio/CloudStorageFileSystemProvider.class): ; warning: Cannot find annotation method 'value()' in type 'AutoService': ; class file for com.google.auto.service.AutoService not found; ```. Checking the jar, `AutoService` is indeed not present, but is an annotation on `CloudStorageFileSystemProvider`. Any thoughts on what could be causing this? Shading error?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314260186
https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314265654:411,Availability,error,error,411,Marking `AuthService` as `optional` in gcloud-nio's pom fixes it:. ```; <dependency>; <groupId>com.google.auto.service</groupId>; <artifactId>auto-service</artifactId>; <version>1.0-rc3</version>; <optional>true</optional>; <scope>provided</scope> <!-- to leave out of the all-deps jar -->; </dependency>; ```. $ ./gradlew sparkJar; BUILD SUCCESSFUL. $ ./gatk-launch ExampleNioCountReads (...); (starts without error),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314265654
https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314265654:73,Integrability,depend,dependency,73,Marking `AuthService` as `optional` in gcloud-nio's pom fixes it:. ```; <dependency>; <groupId>com.google.auto.service</groupId>; <artifactId>auto-service</artifactId>; <version>1.0-rc3</version>; <optional>true</optional>; <scope>provided</scope> <!-- to leave out of the all-deps jar -->; </dependency>; ```. $ ./gradlew sparkJar; BUILD SUCCESSFUL. $ ./gatk-launch ExampleNioCountReads (...); (starts without error),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314265654
https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314265654:293,Integrability,depend,dependency,293,Marking `AuthService` as `optional` in gcloud-nio's pom fixes it:. ```; <dependency>; <groupId>com.google.auto.service</groupId>; <artifactId>auto-service</artifactId>; <version>1.0-rc3</version>; <optional>true</optional>; <scope>provided</scope> <!-- to leave out of the all-deps jar -->; </dependency>; ```. $ ./gradlew sparkJar; BUILD SUCCESSFUL. $ ./gatk-launch ExampleNioCountReads (...); (starts without error),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314265654
https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314302312:91,Deployability,update,update,91,"Thanks @jean-philippe-martin -- this worked, though it took me a while to realize that the update from `1.0-rc2` to `1.0-rc3` was also essential (still failed for me with `1.0-rc2`)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314302312
https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314487090:57,Testability,test,test,57,"ah sorry @droazen , I should have mentioned it. I didn't test with 1.0-rc2.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3241#issuecomment-314487090
https://github.com/broadinstitute/gatk/pull/3243#issuecomment-314324015:2174,Testability,test,test,2174,===========================================; - Coverage 80.422% 80.42% -0.003% ; - Complexity 17290 17299 +9 ; ==============================================; Files 1165 1165 ; Lines 62597 62644 +47 ; Branches 9768 9780 +12 ; ==============================================; + Hits 50342 50378 +36 ; - Misses 8350 8355 +5 ; - Partials 3905 3911 +6; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3243?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ypecaller/AssemblyBasedCallerGenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/3243?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyR2Vub3R5cGluZ0VuZ2luZS5qYXZh) | `77.848% <> ()` | `59 <0> ()` | :arrow_down: |; | [.../tools/walkers/mutect/SomaticGenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/3243?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9Tb21hdGljR2Vub3R5cGluZ0VuZ2luZS5qYXZh) | `93.617% <100%> (-0.045%)` | `57 <1> ()` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3243?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `66.667% <0%> (-3.333%)` | `10% <0%> ()` | |; | [...te/hellbender/utils/genotyper/ReadLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/3243?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvUmVhZExpa2VsaWhvb2RzLmphdmE=) | `86.106% <0%> (-0.391%)` | `141% <0%> (-2%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3243?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `84.153% <0%> (+0.449%)` | `47% <0%> (+11%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3243#issuecomment-314324015
https://github.com/broadinstitute/gatk/pull/3244#issuecomment-314333045:2117,Testability,test,test,2117,vQWxpZ25tZW50Q29udGV4dC5qYXZh) | `86.486% <> ()` | `21 <0> ()` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3244?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-80.612%)` | `0% <0%> (-19%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3244?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3244?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3244?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3244?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `41.216% <0%> (-30.405%)` | `26% <0%> (-8%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3244?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3244?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGV,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3244#issuecomment-314333045
https://github.com/broadinstitute/gatk/pull/3244#issuecomment-314333045:3567,Testability,test,test,3567,aW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3244?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3244?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `41.216% <0%> (-30.405%)` | `26% <0%> (-8%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3244?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3244?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3244?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `70.37% <0%> (-11.111%)` | `10% <0%> ()` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3244?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | ... and [7 more](https://codecov.io/gh/broadinstitute/gatk/pull/3244?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3244#issuecomment-314333045
https://github.com/broadinstitute/gatk/pull/3245#issuecomment-314334294:2117,Testability,test,test,2117,vU2hhcmRCb3VuZGFyeVNoYXJkLmphdmE=) | `100% <> ()` | `4 <0> ()` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3245?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-80.612%)` | `0% <0%> (-19%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3245?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3245?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3245?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3245?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `41.216% <0%> (-30.405%)` | `26% <0%> (-8%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3245?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3245?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGV,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3245#issuecomment-314334294
https://github.com/broadinstitute/gatk/pull/3245#issuecomment-314334294:3567,Testability,test,test,3567,aW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3245?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3245?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `41.216% <0%> (-30.405%)` | `26% <0%> (-8%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3245?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3245?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3245?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `70.37% <0%> (-11.111%)` | `10% <0%> ()` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3245?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | ... and [7 more](https://codecov.io/gh/broadinstitute/gatk/pull/3245?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3245#issuecomment-314334294
https://github.com/broadinstitute/gatk/issues/3246#issuecomment-314496762:26,Security,expose,expose,26,@samuelklee We can easily expose the `IntervalMergingRule` in `IntervalArgumentCollection` (which is where `-L` is defined) as an argument to prevent the merging of adjacent intervals. We could also add a way for individual tools to set a default value for `IntervalMergingRule` themselves.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3246#issuecomment-314496762
https://github.com/broadinstitute/gatk/issues/3247#issuecomment-580876289:185,Testability,test,test,185,"This still isn't perfect, but it will suffice. In the current master the arguments come out like:; ```; --resource:known,known=true,prior=10.0 known:/Users/gauthier/workspaces/gatk/src/test/resources/large/VQSR/dbsnp_132_b 37.leftAligned.20.1M-10M.vcf; --resource:truth_training1,truth=true,training=true,prior=15.0 truth_training1:/Users/gauthier/workspaces/gatk/src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf; --resource:truth_training2,training=true,truth=true,prior=12.0 truth_training2:/Users/gauthier/workspaces/gatk/src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf; ```; which don't parse perfectly if you try to run them as a command, but at least all the information is there. (false attributes are dropped, but will be interpreted correctly if omitted). This isn't causing me any problems, so I'm going to close it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3247#issuecomment-580876289
https://github.com/broadinstitute/gatk/issues/3247#issuecomment-580876289:368,Testability,test,test,368,"This still isn't perfect, but it will suffice. In the current master the arguments come out like:; ```; --resource:known,known=true,prior=10.0 known:/Users/gauthier/workspaces/gatk/src/test/resources/large/VQSR/dbsnp_132_b 37.leftAligned.20.1M-10M.vcf; --resource:truth_training1,truth=true,training=true,prior=15.0 truth_training1:/Users/gauthier/workspaces/gatk/src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf; --resource:truth_training2,training=true,truth=true,prior=12.0 truth_training2:/Users/gauthier/workspaces/gatk/src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf; ```; which don't parse perfectly if you try to run them as a command, but at least all the information is there. (false attributes are dropped, but will be interpreted correctly if omitted). This isn't causing me any problems, so I'm going to close it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3247#issuecomment-580876289
https://github.com/broadinstitute/gatk/issues/3247#issuecomment-580876289:545,Testability,test,test,545,"This still isn't perfect, but it will suffice. In the current master the arguments come out like:; ```; --resource:known,known=true,prior=10.0 known:/Users/gauthier/workspaces/gatk/src/test/resources/large/VQSR/dbsnp_132_b 37.leftAligned.20.1M-10M.vcf; --resource:truth_training1,truth=true,training=true,prior=15.0 truth_training1:/Users/gauthier/workspaces/gatk/src/test/resources/large/VQSR/sites_r27_nr.b37_fwd.20.1M-10M.vcf; --resource:truth_training2,training=true,truth=true,prior=12.0 truth_training2:/Users/gauthier/workspaces/gatk/src/test/resources/large/VQSR/Omni25_sites_1525_samples.b37.20.1M-10M.vcf; ```; which don't parse perfectly if you try to run them as a command, but at least all the information is there. (false attributes are dropped, but will be interpreted correctly if omitted). This isn't causing me any problems, so I'm going to close it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3247#issuecomment-580876289
https://github.com/broadinstitute/gatk/pull/3250#issuecomment-315760322:28,Integrability,depend,dependency,28,@LeeTL1220 Does GATK have a dependency on this change ? If so this will definitely need to be made in Picard as well since these GATK copies of the Picard tool are soon to be obsoleted.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3250#issuecomment-315760322
https://github.com/broadinstitute/gatk/pull/3250#issuecomment-316558645:58,Integrability,depend,dependency,58,"@cmnbroad I put in a test in GATK that should fail if the dependency is moved to Picard. So, you are 100% correct that these changes will need to go into Picard.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3250#issuecomment-316558645
https://github.com/broadinstitute/gatk/pull/3250#issuecomment-316558645:21,Testability,test,test,21,"@cmnbroad I put in a test in GATK that should fail if the dependency is moved to Picard. So, you are 100% correct that these changes will need to go into Picard.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3250#issuecomment-316558645
https://github.com/broadinstitute/gatk/pull/3252#issuecomment-314527518:36,Availability,redundant,redundant,36,"@ronlevine just pointed out this is redundant w/ another issue (see above). for that issue you guys requested I write a unit test, which I did this morning. Feel free to apply that or not. It's attached to that thread as a patch (sorry, dont have a good local enlistment right now). It's nothing special, but tests are rarely a bad thing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3252#issuecomment-314527518
https://github.com/broadinstitute/gatk/pull/3252#issuecomment-314527518:223,Deployability,patch,patch,223,"@ronlevine just pointed out this is redundant w/ another issue (see above). for that issue you guys requested I write a unit test, which I did this morning. Feel free to apply that or not. It's attached to that thread as a patch (sorry, dont have a good local enlistment right now). It's nothing special, but tests are rarely a bad thing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3252#issuecomment-314527518
https://github.com/broadinstitute/gatk/pull/3252#issuecomment-314527518:36,Safety,redund,redundant,36,"@ronlevine just pointed out this is redundant w/ another issue (see above). for that issue you guys requested I write a unit test, which I did this morning. Feel free to apply that or not. It's attached to that thread as a patch (sorry, dont have a good local enlistment right now). It's nothing special, but tests are rarely a bad thing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3252#issuecomment-314527518
https://github.com/broadinstitute/gatk/pull/3252#issuecomment-314527518:125,Testability,test,test,125,"@ronlevine just pointed out this is redundant w/ another issue (see above). for that issue you guys requested I write a unit test, which I did this morning. Feel free to apply that or not. It's attached to that thread as a patch (sorry, dont have a good local enlistment right now). It's nothing special, but tests are rarely a bad thing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3252#issuecomment-314527518
https://github.com/broadinstitute/gatk/pull/3252#issuecomment-314527518:309,Testability,test,tests,309,"@ronlevine just pointed out this is redundant w/ another issue (see above). for that issue you guys requested I write a unit test, which I did this morning. Feel free to apply that or not. It's attached to that thread as a patch (sorry, dont have a good local enlistment right now). It's nothing special, but tests are rarely a bad thing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3252#issuecomment-314527518
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314543187:56,Deployability,patch,patched,56,"For @jean-philippe-martin. I'll try to throw together a patched version of `google-cloud-java` locally for us to test, to see if this is the last of the 503-related problems.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314543187
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314543187:113,Testability,test,test,113,"For @jean-philippe-martin. I'll try to throw together a patched version of `google-cloud-java` locally for us to test, to see if this is the last of the 503-related problems.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314543187
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314549425:31,Deployability,patch,patch,31,"@jean-philippe-martin When you patch this one, could you also audit the rest of `CloudStorageReadChannel` for any other methods that could trigger a GCS access and require retries?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314549425
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314549425:62,Security,audit,audit,62,"@jean-philippe-martin When you patch this one, could you also audit the rest of `CloudStorageReadChannel` for any other methods that could trigger a GCS access and require retries?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314549425
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314549425:153,Security,access,access,153,"@jean-philippe-martin When you patch this one, could you also audit the rest of `CloudStorageReadChannel` for any other methods that could trigger a GCS access and require retries?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314549425
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314566670:50,Deployability,patch,patch,50,"@jean-philippe-martin I've implemented an initial patch for this issue here: https://github.com/droazen/google-cloud-java/tree/dr_retry_CloudStorageReadChannel_fetchSize. Since we still don't have our Google CLA issues worked out, I'm unable to PR it directly against `google-cloud-java`, so you'll have to do that part. We'll test it out on our end and see if the 503s are finally conquered once and for all!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314566670
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314566670:327,Testability,test,test,327,"@jean-philippe-martin I've implemented an initial patch for this issue here: https://github.com/droazen/google-cloud-java/tree/dr_retry_CloudStorageReadChannel_fetchSize. Since we still don't have our Google CLA issues worked out, I'm unable to PR it directly against `google-cloud-java`, so you'll have to do that part. We'll test it out on our end and see if the 503s are finally conquered once and for all!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314566670
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314813629:28,Availability,failure,failures,28,"The patch clears up the 503 failures due to `fetchSize()`, but we are STILL seeing 503's with other metadata operations such as `Files.exists()`:. ```; com.google.cloud.storage.StorageException: 503 Service Unavailable; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:586); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.tribble.util.ParsingUtils.resourceExists(ParsingUtils.java:428); at htsjdk.tribble.AbstractFeatureReader.isTabix(AbstractFeatureReader.java:217); at htsjdk.tribble.AbstractFeatureReader$ComponentMethods.isTabix(AbstractFeatureReader.java:223); ```. I'm going to continue modifying the patch until we see all 503s go away, then post here once it's ready.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314813629
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314813629:4,Deployability,patch,patch,4,"The patch clears up the 503 failures due to `fetchSize()`, but we are STILL seeing 503's with other metadata operations such as `Files.exists()`:. ```; com.google.cloud.storage.StorageException: 503 Service Unavailable; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:586); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.tribble.util.ParsingUtils.resourceExists(ParsingUtils.java:428); at htsjdk.tribble.AbstractFeatureReader.isTabix(AbstractFeatureReader.java:217); at htsjdk.tribble.AbstractFeatureReader$ComponentMethods.isTabix(AbstractFeatureReader.java:223); ```. I'm going to continue modifying the patch until we see all 503s go away, then post here once it's ready.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314813629
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314813629:1241,Deployability,patch,patch,1241,"The patch clears up the 503 failures due to `fetchSize()`, but we are STILL seeing 503's with other metadata operations such as `Files.exists()`:. ```; com.google.cloud.storage.StorageException: 503 Service Unavailable; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:586); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.tribble.util.ParsingUtils.resourceExists(ParsingUtils.java:428); at htsjdk.tribble.AbstractFeatureReader.isTabix(AbstractFeatureReader.java:217); at htsjdk.tribble.AbstractFeatureReader$ComponentMethods.isTabix(AbstractFeatureReader.java:223); ```. I'm going to continue modifying the patch until we see all 503s go away, then post here once it's ready.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314813629
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314813629:10,Usability,clear,clears,10,"The patch clears up the 503 failures due to `fetchSize()`, but we are STILL seeing 503's with other metadata operations such as `Files.exists()`:. ```; com.google.cloud.storage.StorageException: 503 Service Unavailable; at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:586); at java.nio.file.Files.exists(Files.java:2385); at htsjdk.tribble.util.ParsingUtils.resourceExists(ParsingUtils.java:428); at htsjdk.tribble.AbstractFeatureReader.isTabix(AbstractFeatureReader.java:217); at htsjdk.tribble.AbstractFeatureReader$ComponentMethods.isTabix(AbstractFeatureReader.java:223); ```. I'm going to continue modifying the patch until we see all 503s go away, then post here once it's ready.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314813629
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314825851:68,Testability,log,logic,68,@droazen it may be prudent to also include `innerOpen` in the retry logic.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314825851
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314832364:223,Testability,log,logic,223,"I looked at the code and opening the channel does not seem to send any RPC, not even to check that the file exists (I double-checked by calling it on a nonexistent file). So we'll be OK leaving `innerOpen` out of the retry logic.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314832364
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314891599:28,Integrability,wrap,wrap,28,"@jean-philippe-martin I can wrap the `CloudStorageFileSystemProvider.checkAccess()` method in a retry, but can you think of any other methods *outside* of `CloudStorageReadChannel` that might also require a retry?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-314891599
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315447319:80,Availability,error,errors,80,"Ok @jean-philippe-martin, I have an updated patch that seems to resolve the 503 errors! It's here: https://github.com/droazen/google-cloud-java/tree/dr_retry_CloudStorageReadChannel_fetchSize. Will you have time before you leave on vacation to open a PR against google-cloud-java? If not, let me know and we'll try to sort out our CLA issues and PR it ourselves. I didn't have time to write unit tests, unfortunately, though we're running it now with 1000 concurrent jobs each accessing 11,000 files and not seeing any errors.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315447319
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315447319:519,Availability,error,errors,519,"Ok @jean-philippe-martin, I have an updated patch that seems to resolve the 503 errors! It's here: https://github.com/droazen/google-cloud-java/tree/dr_retry_CloudStorageReadChannel_fetchSize. Will you have time before you leave on vacation to open a PR against google-cloud-java? If not, let me know and we'll try to sort out our CLA issues and PR it ourselves. I didn't have time to write unit tests, unfortunately, though we're running it now with 1000 concurrent jobs each accessing 11,000 files and not seeing any errors.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315447319
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315447319:36,Deployability,update,updated,36,"Ok @jean-philippe-martin, I have an updated patch that seems to resolve the 503 errors! It's here: https://github.com/droazen/google-cloud-java/tree/dr_retry_CloudStorageReadChannel_fetchSize. Will you have time before you leave on vacation to open a PR against google-cloud-java? If not, let me know and we'll try to sort out our CLA issues and PR it ourselves. I didn't have time to write unit tests, unfortunately, though we're running it now with 1000 concurrent jobs each accessing 11,000 files and not seeing any errors.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315447319
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315447319:44,Deployability,patch,patch,44,"Ok @jean-philippe-martin, I have an updated patch that seems to resolve the 503 errors! It's here: https://github.com/droazen/google-cloud-java/tree/dr_retry_CloudStorageReadChannel_fetchSize. Will you have time before you leave on vacation to open a PR against google-cloud-java? If not, let me know and we'll try to sort out our CLA issues and PR it ourselves. I didn't have time to write unit tests, unfortunately, though we're running it now with 1000 concurrent jobs each accessing 11,000 files and not seeing any errors.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315447319
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315447319:456,Performance,concurren,concurrent,456,"Ok @jean-philippe-martin, I have an updated patch that seems to resolve the 503 errors! It's here: https://github.com/droazen/google-cloud-java/tree/dr_retry_CloudStorageReadChannel_fetchSize. Will you have time before you leave on vacation to open a PR against google-cloud-java? If not, let me know and we'll try to sort out our CLA issues and PR it ourselves. I didn't have time to write unit tests, unfortunately, though we're running it now with 1000 concurrent jobs each accessing 11,000 files and not seeing any errors.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315447319
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315447319:477,Security,access,accessing,477,"Ok @jean-philippe-martin, I have an updated patch that seems to resolve the 503 errors! It's here: https://github.com/droazen/google-cloud-java/tree/dr_retry_CloudStorageReadChannel_fetchSize. Will you have time before you leave on vacation to open a PR against google-cloud-java? If not, let me know and we'll try to sort out our CLA issues and PR it ourselves. I didn't have time to write unit tests, unfortunately, though we're running it now with 1000 concurrent jobs each accessing 11,000 files and not seeing any errors.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315447319
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315447319:396,Testability,test,tests,396,"Ok @jean-philippe-martin, I have an updated patch that seems to resolve the 503 errors! It's here: https://github.com/droazen/google-cloud-java/tree/dr_retry_CloudStorageReadChannel_fetchSize. Will you have time before you leave on vacation to open a PR against google-cloud-java? If not, let me know and we'll try to sort out our CLA issues and PR it ourselves. I didn't have time to write unit tests, unfortunately, though we're running it now with 1000 concurrent jobs each accessing 11,000 files and not seeing any errors.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315447319
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315469074:148,Testability,log,logic,148,"This is odd, it looks like you retry unconditionally on delete (CloudStorageFileSystemProvider, line 419). It would make more sense to use the same logic as before to only retry if it's retriable, and reopen if it's reopenable. Do you mind if I do this change? We'll probably have to do it anyways for the PR to get through.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315469074
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315471923:116,Availability,failure,failures,116,"@jean-philippe-martin Yeah, I was being a bit over-aggressive with the retries to maximize my chances of fixing the failures. We could make the retries conditional, and I did extract `CloudStorageRetryHandler.isRetryable()` and `CloudStorageRetryHandler.isReopenable()` methods, but are we 100% sure that in `CloudStorageFileSystemProvider` we wouldn't want to retry any of the errors that in `CloudStorageReadChannel` result in a reopen? That wasn't clear to me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315471923
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315471923:378,Availability,error,errors,378,"@jean-philippe-martin Yeah, I was being a bit over-aggressive with the retries to maximize my chances of fixing the failures. We could make the retries conditional, and I did extract `CloudStorageRetryHandler.isRetryable()` and `CloudStorageRetryHandler.isReopenable()` methods, but are we 100% sure that in `CloudStorageFileSystemProvider` we wouldn't want to retry any of the errors that in `CloudStorageReadChannel` result in a reopen? That wasn't clear to me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315471923
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315471923:451,Usability,clear,clear,451,"@jean-philippe-martin Yeah, I was being a bit over-aggressive with the retries to maximize my chances of fixing the failures. We could make the retries conditional, and I did extract `CloudStorageRetryHandler.isRetryable()` and `CloudStorageRetryHandler.isReopenable()` methods, but are we 100% sure that in `CloudStorageFileSystemProvider` we wouldn't want to retry any of the errors that in `CloudStorageReadChannel` result in a reopen? That wasn't clear to me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315471923
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315472400:157,Availability,error,errors,157,"@droazen I'll put together my version and you can have a look. I'm making it always attempt a retry on retriable exceptions, so we don't have to worry about errors that would result in a reopen in `CloudStorageReadChannel`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315472400
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315474499:21,Availability,error,errors,21,But could any of the errors that result in a re-open in `CloudStorageReadChannel` succeed in `CloudStorageFileSystemProvider` if we retry when we encounter them?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315474499
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315476254:166,Availability,error,error,166,"I doubt it but I can change the code to retry in those circumstances so we're super aggressive. That means that there we'd be retrying 40 times instead of 20, for an error that is not marked as retriable (so that normally wouldn't be retried at all).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315476254
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315479752:116,Deployability,update,updated,116,"OK it's up at [#2239](https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2239), please have a look. I've updated the code to retry when reopens are indicated (since the two don't overlap I take back that line about it retrying 40 times). This means that it'll be close to the level of aggressive that you tested with.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315479752
https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315479752:316,Testability,test,tested,316,"OK it's up at [#2239](https://github.com/GoogleCloudPlatform/google-cloud-java/pull/2239), please have a look. I've updated the code to retry when reopens are indicated (since the two don't overlap I take back that line about it retrying 40 times). This means that it'll be close to the level of aggressive that you tested with.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3253#issuecomment-315479752
https://github.com/broadinstitute/gatk/pull/3255#issuecomment-314769738:14,Testability,test,test,14,"I did add new test files, but they should be in git lfs so they don't actually contribute to the repo size (technically). Maybe @droazen or @lbergelson want to weigh in and make sure I added the files correctly?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3255#issuecomment-314769738
https://github.com/broadinstitute/gatk/pull/3255#issuecomment-314785118:38,Testability,test,test,38,FYI I wasn't suggesting you added the test files incorrectly. It's just that I don't have a clue so wanted to make sure I was being a conscientious reviewer. :),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3255#issuecomment-314785118
https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316178074:360,Deployability,pipeline,pipeline,360,"@eitanbanks I added the tranche gathering code. I'm not 100% happy with the way the gatherer chooses the tranches corresponding with the requested truth sensitivity levels (VQSLODTranche.mergeAndConvertTranches), but it should do a good enough job for now. (Not to mention that we only ever use one tranche for production.) I'm going to start on modifying the pipeline WDL, but I'd appreciate a review of the new code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316178074
https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316188293:173,Integrability,message,message,173,"@ldgauthier The new test files you added were indeed correctly checked in as git-lfs files! You can tell this because in the diff for the PR these files are marked with the message ""Git LFS file not shown"". (I'll add that any new files added under `src/test/resources/large` get automatically tracked by lfs provided that you've completed the lfs setup instructions in https://github.com/broadinstitute/gatk#lfs -- we generally put files that are more than about 1 MB in there)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316188293
https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316188293:20,Testability,test,test,20,"@ldgauthier The new test files you added were indeed correctly checked in as git-lfs files! You can tell this because in the diff for the PR these files are marked with the message ""Git LFS file not shown"". (I'll add that any new files added under `src/test/resources/large` get automatically tracked by lfs provided that you've completed the lfs setup instructions in https://github.com/broadinstitute/gatk#lfs -- we generally put files that are more than about 1 MB in there)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316188293
https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316188293:253,Testability,test,test,253,"@ldgauthier The new test files you added were indeed correctly checked in as git-lfs files! You can tell this because in the diff for the PR these files are marked with the message ""Git LFS file not shown"". (I'll add that any new files added under `src/test/resources/large` get automatically tracked by lfs provided that you've completed the lfs setup instructions in https://github.com/broadinstitute/gatk#lfs -- we generally put files that are more than about 1 MB in there)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316188293
https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316709556:32,Testability,test,tests,32,"@eitanbanks Comments addressed, tests passing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316709556
https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316868380:297,Integrability,message,message,297,"@ldgauthier In GATK4 we require that all PRs be squashed into a single commit at the end of review (ie., ""Squash and merge"" is the only option enabled for this repo). But I'll add that github will do the final squash for you -- all you have to do is click ""Squash and merge"", then edit the commit message in the text box that pops up to cleanly describe the final feature (you can enlarge the text box while editing).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3255#issuecomment-316868380
https://github.com/broadinstitute/gatk/issues/3256#issuecomment-341518765:278,Testability,log,logic,278,"Long story short, our accuracy on a horrible tumor with at least three contaminants is a bit better than ContEst's on normals with a single contaminant. . Note that as contamination gets really high our estimate starts to flatten out, which does not surprise me. I could put in logic to handle this case, but for now I'm content to be able to say that something is > 12%. I also think that restricting to rarer SNPs would improve accuracy, and at some point I'll test that idea.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3256#issuecomment-341518765
https://github.com/broadinstitute/gatk/issues/3256#issuecomment-341518765:463,Testability,test,test,463,"Long story short, our accuracy on a horrible tumor with at least three contaminants is a bit better than ContEst's on normals with a single contaminant. . Note that as contamination gets really high our estimate starts to flatten out, which does not surprise me. I could put in logic to handle this case, but for now I'm content to be able to say that something is > 12%. I also think that restricting to rarer SNPs would improve accuracy, and at some point I'll test that idea.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3256#issuecomment-341518765
https://github.com/broadinstitute/gatk/pull/3257#issuecomment-314885776:28,Testability,test,test,28,Push failed running the WDL test... I think it was just a hiccup. Re-running.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3257#issuecomment-314885776
https://github.com/broadinstitute/gatk/issues/3265#issuecomment-315085428:76,Deployability,configurat,configuration,76,"Another con of hacky solution is that it may make calling replicates in T/N configuration difficult. I have not confirmed this, though, so it may not be an issue at all.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3265#issuecomment-315085428
https://github.com/broadinstitute/gatk/issues/3265#issuecomment-315085428:76,Modifiability,config,configuration,76,"Another con of hacky solution is that it may make calling replicates in T/N configuration difficult. I have not confirmed this, though, so it may not be an issue at all.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3265#issuecomment-315085428
https://github.com/broadinstitute/gatk/issues/3269#issuecomment-371176755:49,Deployability,patch,patch,49,"Not yet @ptranvan. @kgururaj and his team have a patch coming soon to add multi-interval support to this tool, so there's a good chance it will make it into a GATK release this month.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3269#issuecomment-371176755
https://github.com/broadinstitute/gatk/issues/3269#issuecomment-371176755:164,Deployability,release,release,164,"Not yet @ptranvan. @kgururaj and his team have a patch coming soon to add multi-interval support to this tool, so there's a good chance it will make it into a GATK release this month.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3269#issuecomment-371176755
https://github.com/broadinstitute/gatk/issues/3269#issuecomment-398891375:12,Deployability,update,update,12,"Hello,; Any update to the timeline here? It looks like there is only some lasts tests to be run? I am eagerly awaiting multi-interval support for a project I am working on. Thank you for all of your hard work!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3269#issuecomment-398891375
https://github.com/broadinstitute/gatk/issues/3269#issuecomment-398891375:80,Testability,test,tests,80,"Hello,; Any update to the timeline here? It looks like there is only some lasts tests to be run? I am eagerly awaiting multi-interval support for a project I am working on. Thank you for all of your hard work!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3269#issuecomment-398891375
https://github.com/broadinstitute/gatk/issues/3269#issuecomment-398900147:157,Deployability,release,release,157,"Should not be much longer @ajshultz -- https://github.com/broadinstitute/gatk/pull/4645 just needs a final review pass, so it's likely to make the next GATK release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3269#issuecomment-398900147
https://github.com/broadinstitute/gatk/issues/3279#issuecomment-363521731:31,Deployability,release,release,31,Added in data sources prior to release 4.0.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3279#issuecomment-363521731
https://github.com/broadinstitute/gatk/issues/3286#issuecomment-340717669:193,Integrability,depend,dependencies,193,Yes please! I'd also find this incredibly useful. @lbergelson any thoughts on how hard it would be to generate a separate build artifact for the local reassembly code that didn't have too many dependencies?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3286#issuecomment-340717669
https://github.com/broadinstitute/gatk/issues/3286#issuecomment-433201230:74,Modifiability,plugin,plugin,74,"Hey all, I'm still interested in supporting this. We don't really have a ""plugin API"", I am in fact the API, but if you give me something usable I'll plug it in. As this is marked ""QuixoticDream"" I don't think that's likely. I'm closing the corresponding IGV issue, too many open issues, but it doesn't mean I've lost interest.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3286#issuecomment-433201230
https://github.com/broadinstitute/gatk/issues/3286#issuecomment-433201230:138,Usability,usab,usable,138,"Hey all, I'm still interested in supporting this. We don't really have a ""plugin API"", I am in fact the API, but if you give me something usable I'll plug it in. As this is marked ""QuixoticDream"" I don't think that's likely. I'm closing the corresponding IGV issue, too many open issues, but it doesn't mean I've lost interest.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3286#issuecomment-433201230
https://github.com/broadinstitute/gatk/issues/3287#issuecomment-316077922:156,Modifiability,plugin,plugin,156,"I was looking into this because it is useful for me, and I have found that there is going to be redundancy between the `VariantAnnotatorEngine`code and the plugin. Here a couple of suggestions after trying to implement something in this regard time ago:. * Remove/deprecate the private class `AnnotationManager` in favor of the plugin. The current code is performing reflection operations by itself, and this can cause some problems.; * Refactor the `VariantAnnotatorEngine` constructors in favor of a constructor from the barclay plugin and a list of annotations to apply, to avoid the `AnnotationManager` implementation.; * Remove/deprecate static methods for creating an annotator engine (`ofAllMinusExcluded` and `ofSelectedMinusExcluded`) in favor of handling this in the plugin.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3287#issuecomment-316077922
https://github.com/broadinstitute/gatk/issues/3287#issuecomment-316077922:328,Modifiability,plugin,plugin,328,"I was looking into this because it is useful for me, and I have found that there is going to be redundancy between the `VariantAnnotatorEngine`code and the plugin. Here a couple of suggestions after trying to implement something in this regard time ago:. * Remove/deprecate the private class `AnnotationManager` in favor of the plugin. The current code is performing reflection operations by itself, and this can cause some problems.; * Refactor the `VariantAnnotatorEngine` constructors in favor of a constructor from the barclay plugin and a list of annotations to apply, to avoid the `AnnotationManager` implementation.; * Remove/deprecate static methods for creating an annotator engine (`ofAllMinusExcluded` and `ofSelectedMinusExcluded`) in favor of handling this in the plugin.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3287#issuecomment-316077922
https://github.com/broadinstitute/gatk/issues/3287#issuecomment-316077922:437,Modifiability,Refactor,Refactor,437,"I was looking into this because it is useful for me, and I have found that there is going to be redundancy between the `VariantAnnotatorEngine`code and the plugin. Here a couple of suggestions after trying to implement something in this regard time ago:. * Remove/deprecate the private class `AnnotationManager` in favor of the plugin. The current code is performing reflection operations by itself, and this can cause some problems.; * Refactor the `VariantAnnotatorEngine` constructors in favor of a constructor from the barclay plugin and a list of annotations to apply, to avoid the `AnnotationManager` implementation.; * Remove/deprecate static methods for creating an annotator engine (`ofAllMinusExcluded` and `ofSelectedMinusExcluded`) in favor of handling this in the plugin.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3287#issuecomment-316077922
https://github.com/broadinstitute/gatk/issues/3287#issuecomment-316077922:531,Modifiability,plugin,plugin,531,"I was looking into this because it is useful for me, and I have found that there is going to be redundancy between the `VariantAnnotatorEngine`code and the plugin. Here a couple of suggestions after trying to implement something in this regard time ago:. * Remove/deprecate the private class `AnnotationManager` in favor of the plugin. The current code is performing reflection operations by itself, and this can cause some problems.; * Refactor the `VariantAnnotatorEngine` constructors in favor of a constructor from the barclay plugin and a list of annotations to apply, to avoid the `AnnotationManager` implementation.; * Remove/deprecate static methods for creating an annotator engine (`ofAllMinusExcluded` and `ofSelectedMinusExcluded`) in favor of handling this in the plugin.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3287#issuecomment-316077922
https://github.com/broadinstitute/gatk/issues/3287#issuecomment-316077922:777,Modifiability,plugin,plugin,777,"I was looking into this because it is useful for me, and I have found that there is going to be redundancy between the `VariantAnnotatorEngine`code and the plugin. Here a couple of suggestions after trying to implement something in this regard time ago:. * Remove/deprecate the private class `AnnotationManager` in favor of the plugin. The current code is performing reflection operations by itself, and this can cause some problems.; * Refactor the `VariantAnnotatorEngine` constructors in favor of a constructor from the barclay plugin and a list of annotations to apply, to avoid the `AnnotationManager` implementation.; * Remove/deprecate static methods for creating an annotator engine (`ofAllMinusExcluded` and `ofSelectedMinusExcluded`) in favor of handling this in the plugin.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3287#issuecomment-316077922
https://github.com/broadinstitute/gatk/issues/3287#issuecomment-316077922:356,Performance,perform,performing,356,"I was looking into this because it is useful for me, and I have found that there is going to be redundancy between the `VariantAnnotatorEngine`code and the plugin. Here a couple of suggestions after trying to implement something in this regard time ago:. * Remove/deprecate the private class `AnnotationManager` in favor of the plugin. The current code is performing reflection operations by itself, and this can cause some problems.; * Refactor the `VariantAnnotatorEngine` constructors in favor of a constructor from the barclay plugin and a list of annotations to apply, to avoid the `AnnotationManager` implementation.; * Remove/deprecate static methods for creating an annotator engine (`ofAllMinusExcluded` and `ofSelectedMinusExcluded`) in favor of handling this in the plugin.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3287#issuecomment-316077922
https://github.com/broadinstitute/gatk/issues/3287#issuecomment-316077922:96,Safety,redund,redundancy,96,"I was looking into this because it is useful for me, and I have found that there is going to be redundancy between the `VariantAnnotatorEngine`code and the plugin. Here a couple of suggestions after trying to implement something in this regard time ago:. * Remove/deprecate the private class `AnnotationManager` in favor of the plugin. The current code is performing reflection operations by itself, and this can cause some problems.; * Refactor the `VariantAnnotatorEngine` constructors in favor of a constructor from the barclay plugin and a list of annotations to apply, to avoid the `AnnotationManager` implementation.; * Remove/deprecate static methods for creating an annotator engine (`ofAllMinusExcluded` and `ofSelectedMinusExcluded`) in favor of handling this in the plugin.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3287#issuecomment-316077922
https://github.com/broadinstitute/gatk/issues/3287#issuecomment-316077922:577,Safety,avoid,avoid,577,"I was looking into this because it is useful for me, and I have found that there is going to be redundancy between the `VariantAnnotatorEngine`code and the plugin. Here a couple of suggestions after trying to implement something in this regard time ago:. * Remove/deprecate the private class `AnnotationManager` in favor of the plugin. The current code is performing reflection operations by itself, and this can cause some problems.; * Refactor the `VariantAnnotatorEngine` constructors in favor of a constructor from the barclay plugin and a list of annotations to apply, to avoid the `AnnotationManager` implementation.; * Remove/deprecate static methods for creating an annotator engine (`ofAllMinusExcluded` and `ofSelectedMinusExcluded`) in favor of handling this in the plugin.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3287#issuecomment-316077922
https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491:43,Availability,error,errors,43,The SV discovery pipeline threw a bunch of errors seemingly related to this:; https://issues.apache.org/jira/browse/SPARK-21133. A sample error from my log:; 17/07/17 14:33:17 ERROR org.apache.spark.util.Utils: Exception encountered; java.lang.NullPointerException; 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply$mcV$sp(MapStatus.scala:171); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus.writeExternal(MapStatus.scala:167); 	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459); 	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178); 	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174); 	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply$mcV$sp(MapOutputTracker.scala:617); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.MapOutputTracker$.serializeMapStatuses(MapOutputTracker.scala:619); 	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:562); 	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:351); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.conc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491
https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491:138,Availability,error,error,138,The SV discovery pipeline threw a bunch of errors seemingly related to this:; https://issues.apache.org/jira/browse/SPARK-21133. A sample error from my log:; 17/07/17 14:33:17 ERROR org.apache.spark.util.Utils: Exception encountered; java.lang.NullPointerException; 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply$mcV$sp(MapStatus.scala:171); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus.writeExternal(MapStatus.scala:167); 	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459); 	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178); 	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174); 	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply$mcV$sp(MapOutputTracker.scala:617); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.MapOutputTracker$.serializeMapStatuses(MapOutputTracker.scala:619); 	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:562); 	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:351); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.conc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491
https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491:176,Availability,ERROR,ERROR,176,The SV discovery pipeline threw a bunch of errors seemingly related to this:; https://issues.apache.org/jira/browse/SPARK-21133. A sample error from my log:; 17/07/17 14:33:17 ERROR org.apache.spark.util.Utils: Exception encountered; java.lang.NullPointerException; 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply$mcV$sp(MapStatus.scala:171); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus.writeExternal(MapStatus.scala:167); 	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459); 	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178); 	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174); 	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply$mcV$sp(MapOutputTracker.scala:617); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.MapOutputTracker$.serializeMapStatuses(MapOutputTracker.scala:619); 	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:562); 	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:351); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.conc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491
https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491:17,Deployability,pipeline,pipeline,17,The SV discovery pipeline threw a bunch of errors seemingly related to this:; https://issues.apache.org/jira/browse/SPARK-21133. A sample error from my log:; 17/07/17 14:33:17 ERROR org.apache.spark.util.Utils: Exception encountered; java.lang.NullPointerException; 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply$mcV$sp(MapStatus.scala:171); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus.writeExternal(MapStatus.scala:167); 	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459); 	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178); 	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174); 	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply$mcV$sp(MapOutputTracker.scala:617); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.MapOutputTracker$.serializeMapStatuses(MapOutputTracker.scala:619); 	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:562); 	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:351); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.conc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491
https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491:287,Energy Efficiency,schedul,scheduler,287,The SV discovery pipeline threw a bunch of errors seemingly related to this:; https://issues.apache.org/jira/browse/SPARK-21133. A sample error from my log:; 17/07/17 14:33:17 ERROR org.apache.spark.util.Utils: Exception encountered; java.lang.NullPointerException; 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply$mcV$sp(MapStatus.scala:171); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus.writeExternal(MapStatus.scala:167); 	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459); 	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178); 	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174); 	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply$mcV$sp(MapOutputTracker.scala:617); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.MapOutputTracker$.serializeMapStatuses(MapOutputTracker.scala:619); 	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:562); 	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:351); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.conc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491
https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491:404,Energy Efficiency,schedul,scheduler,404,The SV discovery pipeline threw a bunch of errors seemingly related to this:; https://issues.apache.org/jira/browse/SPARK-21133. A sample error from my log:; 17/07/17 14:33:17 ERROR org.apache.spark.util.Utils: Exception encountered; java.lang.NullPointerException; 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply$mcV$sp(MapStatus.scala:171); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus.writeExternal(MapStatus.scala:167); 	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459); 	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178); 	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174); 	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply$mcV$sp(MapOutputTracker.scala:617); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.MapOutputTracker$.serializeMapStatuses(MapOutputTracker.scala:619); 	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:562); 	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:351); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.conc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491
https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491:514,Energy Efficiency,schedul,scheduler,514,The SV discovery pipeline threw a bunch of errors seemingly related to this:; https://issues.apache.org/jira/browse/SPARK-21133. A sample error from my log:; 17/07/17 14:33:17 ERROR org.apache.spark.util.Utils: Exception encountered; java.lang.NullPointerException; 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply$mcV$sp(MapStatus.scala:171); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus.writeExternal(MapStatus.scala:167); 	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459); 	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178); 	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174); 	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply$mcV$sp(MapOutputTracker.scala:617); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.MapOutputTracker$.serializeMapStatuses(MapOutputTracker.scala:619); 	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:562); 	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:351); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.conc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491
https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491:693,Energy Efficiency,schedul,scheduler,693,The SV discovery pipeline threw a bunch of errors seemingly related to this:; https://issues.apache.org/jira/browse/SPARK-21133. A sample error from my log:; 17/07/17 14:33:17 ERROR org.apache.spark.util.Utils: Exception encountered; java.lang.NullPointerException; 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply$mcV$sp(MapStatus.scala:171); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus.writeExternal(MapStatus.scala:167); 	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459); 	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178); 	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174); 	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply$mcV$sp(MapOutputTracker.scala:617); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.MapOutputTracker$.serializeMapStatuses(MapOutputTracker.scala:619); 	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:562); 	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:351); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.conc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491
https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491:1853,Integrability,Message,MessageLoop,1853,browse/SPARK-21133. A sample error from my log:; 17/07/17 14:33:17 ERROR org.apache.spark.util.Utils: Exception encountered; java.lang.NullPointerException; 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply$mcV$sp(MapStatus.scala:171); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus.writeExternal(MapStatus.scala:167); 	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459); 	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178); 	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174); 	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply$mcV$sp(MapOutputTracker.scala:617); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.MapOutputTracker$.serializeMapStatuses(MapOutputTracker.scala:619); 	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:562); 	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:351); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491
https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491:1912,Performance,concurren,concurrent,1912,browse/SPARK-21133. A sample error from my log:; 17/07/17 14:33:17 ERROR org.apache.spark.util.Utils: Exception encountered; java.lang.NullPointerException; 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply$mcV$sp(MapStatus.scala:171); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus.writeExternal(MapStatus.scala:167); 	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459); 	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178); 	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174); 	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply$mcV$sp(MapOutputTracker.scala:617); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.MapOutputTracker$.serializeMapStatuses(MapOutputTracker.scala:619); 	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:562); 	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:351); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491
https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491:1997,Performance,concurren,concurrent,1997,browse/SPARK-21133. A sample error from my log:; 17/07/17 14:33:17 ERROR org.apache.spark.util.Utils: Exception encountered; java.lang.NullPointerException; 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply$mcV$sp(MapStatus.scala:171); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus.writeExternal(MapStatus.scala:167); 	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459); 	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178); 	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174); 	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply$mcV$sp(MapOutputTracker.scala:617); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.MapOutputTracker$.serializeMapStatuses(MapOutputTracker.scala:619); 	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:562); 	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:351); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491
https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491:152,Testability,log,log,152,The SV discovery pipeline threw a bunch of errors seemingly related to this:; https://issues.apache.org/jira/browse/SPARK-21133. A sample error from my log:; 17/07/17 14:33:17 ERROR org.apache.spark.util.Utils: Exception encountered; java.lang.NullPointerException; 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply$mcV$sp(MapStatus.scala:171); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus$$anonfun$writeExternal$2.apply(MapStatus.scala:167); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.scheduler.HighlyCompressedMapStatus.writeExternal(MapStatus.scala:167); 	at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459); 	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178); 	at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378); 	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174); 	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply$mcV$sp(MapOutputTracker.scala:617); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.MapOutputTracker$$anonfun$serializeMapStatuses$1.apply(MapOutputTracker.scala:616); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); 	at org.apache.spark.MapOutputTracker$.serializeMapStatuses(MapOutputTracker.scala:619); 	at org.apache.spark.MapOutputTrackerMaster.getSerializedMapOutputStatuses(MapOutputTracker.scala:562); 	at org.apache.spark.MapOutputTrackerMaster$MessageLoop.run(MapOutputTracker.scala:351); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.conc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315846491
https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315847752:118,Deployability,update,updated,118,For added context it looks like the preview image changed this weekend (although the Google support page has not been updated to indicate that).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315847752
https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315853798:79,Testability,log,logs,79,I started seeing this in PathSeq as well. It also seems that the Spark history logs are broken.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3290#issuecomment-315853798
https://github.com/broadinstitute/gatk/issues/3292#issuecomment-316079921:137,Availability,down,downstream,137,It will be very useful to have an abstract class for the plugin arguments (as I did for the read filters plugin in #2355) to be able for downstream projects to change default values or hide arguments to the final user.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3292#issuecomment-316079921
https://github.com/broadinstitute/gatk/issues/3292#issuecomment-316079921:57,Modifiability,plugin,plugin,57,It will be very useful to have an abstract class for the plugin arguments (as I did for the read filters plugin in #2355) to be able for downstream projects to change default values or hide arguments to the final user.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3292#issuecomment-316079921
https://github.com/broadinstitute/gatk/issues/3292#issuecomment-316079921:105,Modifiability,plugin,plugin,105,It will be very useful to have an abstract class for the plugin arguments (as I did for the read filters plugin in #2355) to be able for downstream projects to change default values or hide arguments to the final user.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3292#issuecomment-316079921
https://github.com/broadinstitute/gatk/pull/3295#issuecomment-316210736:137,Deployability,patch,patch,137,Switched to version in https://github.com/droazen/google-cloud-java/tree/dr_better_nio_retries to test JP's modifications to my original patch.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3295#issuecomment-316210736
https://github.com/broadinstitute/gatk/pull/3295#issuecomment-316210736:98,Testability,test,test,98,Switched to version in https://github.com/droazen/google-cloud-java/tree/dr_better_nio_retries to test JP's modifications to my original patch.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3295#issuecomment-316210736
https://github.com/broadinstitute/gatk/pull/3295#issuecomment-316438413:86,Availability,error,errors,86,"Ran the updated version on 1000 shards with 11k samples, and there were no 503 or SSL errors at all.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3295#issuecomment-316438413
https://github.com/broadinstitute/gatk/pull/3295#issuecomment-316438413:8,Deployability,update,updated,8,"Ran the updated version on 1000 shards with 11k samples, and there were no 503 or SSL errors at all.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3295#issuecomment-316438413
https://github.com/broadinstitute/gatk/pull/3299#issuecomment-316138727:1240,Testability,log,logging,1240,pr&el=h1) Report; > Merging [#3299](https://codecov.io/gh/broadinstitute/gatk/pull/3299?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/5f6108935ddd202d2668714488cf155275de1a64?src=pr&el=desc) will **increase** coverage by `0.008%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #3299 +/- ##; ===============================================; + Coverage 80.366% 80.374% +0.008% ; - Complexity 17666 17673 +7 ; ===============================================; Files 1178 1179 +1 ; Lines 63864 63880 +16 ; Branches 9930 9930 ; ===============================================; + Hits 51325 51343 +18 ; + Misses 8584 8582 -2 ; Partials 3955 3955; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3299?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...bender/tools/walkers/annotator/ReferenceBases.java](https://codecov.io/gh/broadinstitute/gatk/pull/3299?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SZWZlcmVuY2VCYXNlcy5qYXZh) | `100% <100%> ()` | `5 <2> (+1)` | :arrow_up: |; | [...titute/hellbender/utils/logging/OneShotLogger.java](https://codecov.io/gh/broadinstitute/gatk/pull/3299?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9sb2dnaW5nL09uZVNob3RMb2dnZXIuamF2YQ==) | `100% <100%> ()` | `3 <3> (?)` | |; | [...nstitute/hellbender/engine/ShardBoundaryShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/3299?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvU2hhcmRCb3VuZGFyeVNoYXJkLmphdmE=) | `100% <0%> ()` | `7% <0%> (+3%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3299?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `73.973% <0%> (+2.74%)` | `11% <0%> ()` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3299#issuecomment-316138727
https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504:117,Availability,error,error,117,"User replies the missing element was the Rscript packages and once this was installed they were able to plot. So the error message needs to point to the repo's Rscript and the dependent R packages it installs. As of this writing, here is what the error message should say:. > Install R package dependencies using `Rscript install_R_packages.R` with the script from https://github.com/broadinstitute/gatk/blob/master/scripts/docker/gatkbase/install_R_packages.R. The script lists the packages.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504
https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504:247,Availability,error,error,247,"User replies the missing element was the Rscript packages and once this was installed they were able to plot. So the error message needs to point to the repo's Rscript and the dependent R packages it installs. As of this writing, here is what the error message should say:. > Install R package dependencies using `Rscript install_R_packages.R` with the script from https://github.com/broadinstitute/gatk/blob/master/scripts/docker/gatkbase/install_R_packages.R. The script lists the packages.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504
https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504:76,Deployability,install,installed,76,"User replies the missing element was the Rscript packages and once this was installed they were able to plot. So the error message needs to point to the repo's Rscript and the dependent R packages it installs. As of this writing, here is what the error message should say:. > Install R package dependencies using `Rscript install_R_packages.R` with the script from https://github.com/broadinstitute/gatk/blob/master/scripts/docker/gatkbase/install_R_packages.R. The script lists the packages.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504
https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504:200,Deployability,install,installs,200,"User replies the missing element was the Rscript packages and once this was installed they were able to plot. So the error message needs to point to the repo's Rscript and the dependent R packages it installs. As of this writing, here is what the error message should say:. > Install R package dependencies using `Rscript install_R_packages.R` with the script from https://github.com/broadinstitute/gatk/blob/master/scripts/docker/gatkbase/install_R_packages.R. The script lists the packages.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504
https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504:276,Deployability,Install,Install,276,"User replies the missing element was the Rscript packages and once this was installed they were able to plot. So the error message needs to point to the repo's Rscript and the dependent R packages it installs. As of this writing, here is what the error message should say:. > Install R package dependencies using `Rscript install_R_packages.R` with the script from https://github.com/broadinstitute/gatk/blob/master/scripts/docker/gatkbase/install_R_packages.R. The script lists the packages.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504
https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504:123,Integrability,message,message,123,"User replies the missing element was the Rscript packages and once this was installed they were able to plot. So the error message needs to point to the repo's Rscript and the dependent R packages it installs. As of this writing, here is what the error message should say:. > Install R package dependencies using `Rscript install_R_packages.R` with the script from https://github.com/broadinstitute/gatk/blob/master/scripts/docker/gatkbase/install_R_packages.R. The script lists the packages.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504
https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504:176,Integrability,depend,dependent,176,"User replies the missing element was the Rscript packages and once this was installed they were able to plot. So the error message needs to point to the repo's Rscript and the dependent R packages it installs. As of this writing, here is what the error message should say:. > Install R package dependencies using `Rscript install_R_packages.R` with the script from https://github.com/broadinstitute/gatk/blob/master/scripts/docker/gatkbase/install_R_packages.R. The script lists the packages.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504
https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504:253,Integrability,message,message,253,"User replies the missing element was the Rscript packages and once this was installed they were able to plot. So the error message needs to point to the repo's Rscript and the dependent R packages it installs. As of this writing, here is what the error message should say:. > Install R package dependencies using `Rscript install_R_packages.R` with the script from https://github.com/broadinstitute/gatk/blob/master/scripts/docker/gatkbase/install_R_packages.R. The script lists the packages.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504
https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504:294,Integrability,depend,dependencies,294,"User replies the missing element was the Rscript packages and once this was installed they were able to plot. So the error message needs to point to the repo's Rscript and the dependent R packages it installs. As of this writing, here is what the error message should say:. > Install R package dependencies using `Rscript install_R_packages.R` with the script from https://github.com/broadinstitute/gatk/blob/master/scripts/docker/gatkbase/install_R_packages.R. The script lists the packages.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3301#issuecomment-316425504
https://github.com/broadinstitute/gatk/issues/3301#issuecomment-356690983:158,Availability,Error,Error,158,"Deleted in #3935, but I tried to replicate with the new versions of the CNV plotting tools. I get a sensible warning if a package is missing, e.g.:. `Stderr: Error in library(data.table) : there is no package called data.table`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3301#issuecomment-356690983
https://github.com/broadinstitute/gatk/pull/3304#issuecomment-321154425:166,Performance,perform,performance,166,"Thank you for the kind explanation, *@davidbenjamin*. I understand your; rationale. BTW, in my test with a PoN of ~100 sample, this set of changes; makes significant performance improvement regardless of the value of; --genotypePonSites. Could you advise how many samples you used to create; the PoN you test? Thanks!. On Tue, Aug 8, 2017 at 9:28 PM, David Benjamin <notifications@github.com>; wrote:. > *@davidbenjamin* commented on this pull request.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/; > Mutect2Engine.java; > <https://github.com/broadinstitute/gatk/pull/3304#discussion_r132078537>:; >; > > }; >; > - if (hasNormal() && normalContext != null && countNonRef(refBase, normalContext) > normalContext.getBasePileup().size() * MTAC.minNormalVariantFraction) {; > + if (!MTAC.genotypePonSites && !featureContext.getValues(MTAC.pon, new SimpleInterval(context.getContig(), (int) context.getPosition(), (int) context.getPosition())).isEmpty()) {; >; > I deliberately made --genotypePonSites false by default because running; > local assembly and realignment of PoN sites is very expensive, especially; > so because PoN sites are frequently in regions that yield very messy; > assembly graphs, hence many haplotypes. It's true that explicit results can; > be useful, and we frequently want them in the course of development, but a; > tenet of the GATK is to make the tools work as well as possible with; > default settings.; >; > ; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/3304#discussion_r132078537>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABD6FgXbu1QybkQOkGpGBtjNQINUx13rks5sWRk3gaJpZM4OcvPO>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3304#issuecomment-321154425
https://github.com/broadinstitute/gatk/pull/3304#issuecomment-321154425:95,Testability,test,test,95,"Thank you for the kind explanation, *@davidbenjamin*. I understand your; rationale. BTW, in my test with a PoN of ~100 sample, this set of changes; makes significant performance improvement regardless of the value of; --genotypePonSites. Could you advise how many samples you used to create; the PoN you test? Thanks!. On Tue, Aug 8, 2017 at 9:28 PM, David Benjamin <notifications@github.com>; wrote:. > *@davidbenjamin* commented on this pull request.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/; > Mutect2Engine.java; > <https://github.com/broadinstitute/gatk/pull/3304#discussion_r132078537>:; >; > > }; >; > - if (hasNormal() && normalContext != null && countNonRef(refBase, normalContext) > normalContext.getBasePileup().size() * MTAC.minNormalVariantFraction) {; > + if (!MTAC.genotypePonSites && !featureContext.getValues(MTAC.pon, new SimpleInterval(context.getContig(), (int) context.getPosition(), (int) context.getPosition())).isEmpty()) {; >; > I deliberately made --genotypePonSites false by default because running; > local assembly and realignment of PoN sites is very expensive, especially; > so because PoN sites are frequently in regions that yield very messy; > assembly graphs, hence many haplotypes. It's true that explicit results can; > be useful, and we frequently want them in the course of development, but a; > tenet of the GATK is to make the tools work as well as possible with; > default settings.; >; > ; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/3304#discussion_r132078537>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABD6FgXbu1QybkQOkGpGBtjNQINUx13rks5sWRk3gaJpZM4OcvPO>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3304#issuecomment-321154425
https://github.com/broadinstitute/gatk/pull/3304#issuecomment-321154425:304,Testability,test,test,304,"Thank you for the kind explanation, *@davidbenjamin*. I understand your; rationale. BTW, in my test with a PoN of ~100 sample, this set of changes; makes significant performance improvement regardless of the value of; --genotypePonSites. Could you advise how many samples you used to create; the PoN you test? Thanks!. On Tue, Aug 8, 2017 at 9:28 PM, David Benjamin <notifications@github.com>; wrote:. > *@davidbenjamin* commented on this pull request.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/; > Mutect2Engine.java; > <https://github.com/broadinstitute/gatk/pull/3304#discussion_r132078537>:; >; > > }; >; > - if (hasNormal() && normalContext != null && countNonRef(refBase, normalContext) > normalContext.getBasePileup().size() * MTAC.minNormalVariantFraction) {; > + if (!MTAC.genotypePonSites && !featureContext.getValues(MTAC.pon, new SimpleInterval(context.getContig(), (int) context.getPosition(), (int) context.getPosition())).isEmpty()) {; >; > I deliberately made --genotypePonSites false by default because running; > local assembly and realignment of PoN sites is very expensive, especially; > so because PoN sites are frequently in regions that yield very messy; > assembly graphs, hence many haplotypes. It's true that explicit results can; > be useful, and we frequently want them in the course of development, but a; > tenet of the GATK is to make the tools work as well as possible with; > default settings.; >; > ; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/3304#discussion_r132078537>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABD6FgXbu1QybkQOkGpGBtjNQINUx13rks5sWRk3gaJpZM4OcvPO>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3304#issuecomment-321154425
https://github.com/broadinstitute/gatk/pull/3304#issuecomment-321154425:908,Usability,Simpl,SimpleInterval,908,"Thank you for the kind explanation, *@davidbenjamin*. I understand your; rationale. BTW, in my test with a PoN of ~100 sample, this set of changes; makes significant performance improvement regardless of the value of; --genotypePonSites. Could you advise how many samples you used to create; the PoN you test? Thanks!. On Tue, Aug 8, 2017 at 9:28 PM, David Benjamin <notifications@github.com>; wrote:. > *@davidbenjamin* commented on this pull request.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/; > Mutect2Engine.java; > <https://github.com/broadinstitute/gatk/pull/3304#discussion_r132078537>:; >; > > }; >; > - if (hasNormal() && normalContext != null && countNonRef(refBase, normalContext) > normalContext.getBasePileup().size() * MTAC.minNormalVariantFraction) {; > + if (!MTAC.genotypePonSites && !featureContext.getValues(MTAC.pon, new SimpleInterval(context.getContig(), (int) context.getPosition(), (int) context.getPosition())).isEmpty()) {; >; > I deliberately made --genotypePonSites false by default because running; > local assembly and realignment of PoN sites is very expensive, especially; > so because PoN sites are frequently in regions that yield very messy; > assembly graphs, hence many haplotypes. It's true that explicit results can; > be useful, and we frequently want them in the course of development, but a; > tenet of the GATK is to make the tools work as well as possible with; > default settings.; >; > ; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/3304#discussion_r132078537>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ABD6FgXbu1QybkQOkGpGBtjNQINUx13rks5sWRk3gaJpZM4OcvPO>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3304#issuecomment-321154425
https://github.com/broadinstitute/gatk/pull/3305#issuecomment-316490330:137,Availability,down,down,137,"@LeeTL1220 A few minor remaining comments. Do what you will. How much of a performance impact does the change have? You said it slows it down, is it significant? It might be faster if you make it a long instead of an atomic long which should be safe it it's single threaded and you don't use parallel streams anywhere.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3305#issuecomment-316490330
https://github.com/broadinstitute/gatk/pull/3305#issuecomment-316490330:75,Performance,perform,performance,75,"@LeeTL1220 A few minor remaining comments. Do what you will. How much of a performance impact does the change have? You said it slows it down, is it significant? It might be faster if you make it a long instead of an atomic long which should be safe it it's single threaded and you don't use parallel streams anywhere.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3305#issuecomment-316490330
https://github.com/broadinstitute/gatk/pull/3305#issuecomment-316490330:245,Safety,safe,safe,245,"@LeeTL1220 A few minor remaining comments. Do what you will. How much of a performance impact does the change have? You said it slows it down, is it significant? It might be faster if you make it a long instead of an atomic long which should be safe it it's single threaded and you don't use parallel streams anywhere.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3305#issuecomment-316490330
https://github.com/broadinstitute/gatk/pull/3305#issuecomment-316495018:12,Performance,Perform,Performance,12,@lbergelson Performance hit is not enough to worry about.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3305#issuecomment-316495018
https://github.com/broadinstitute/gatk/pull/3305#issuecomment-316507748:43,Availability,error,error,43,I have notified the user who reported this error of the fix.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3305#issuecomment-316507748
https://github.com/broadinstitute/gatk/pull/3307#issuecomment-316440155:71,Availability,down,downstream,71,"Please, @lbergelson, take into account that this will be confusing for downstream projects before accepting this PR. Thanks in advance!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3307#issuecomment-316440155
https://github.com/broadinstitute/gatk/issues/3312#issuecomment-316637378:108,Availability,down,downstream,108,"First and second lines in are printed by the wrapper script, no? In that case, it shouldn't be a problem to downstream projects unless the use the same wrapper script. Regarding the last one, I think that it is already customizable by overriding the method that you pointed out (I'm using it in my toolkit, and I guess that it works.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3312#issuecomment-316637378
https://github.com/broadinstitute/gatk/issues/3312#issuecomment-316637378:45,Integrability,wrap,wrapper,45,"First and second lines in are printed by the wrapper script, no? In that case, it shouldn't be a problem to downstream projects unless the use the same wrapper script. Regarding the last one, I think that it is already customizable by overriding the method that you pointed out (I'm using it in my toolkit, and I guess that it works.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3312#issuecomment-316637378
https://github.com/broadinstitute/gatk/issues/3312#issuecomment-316637378:152,Integrability,wrap,wrapper,152,"First and second lines in are printed by the wrapper script, no? In that case, it shouldn't be a problem to downstream projects unless the use the same wrapper script. Regarding the last one, I think that it is already customizable by overriding the method that you pointed out (I'm using it in my toolkit, and I guess that it works.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3312#issuecomment-316637378
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317000181:39,Availability,error,errors,39,Also when I validated the bam I got no errors. . I'll try rerunning this BQSR step a bunch of times to see if I can get the error again and see if it happens on the same shard.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317000181
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317000181:124,Availability,error,error,124,Also when I validated the bam I got no errors. . I'll try rerunning this BQSR step a bunch of times to see if I can get the error again and see if it happens on the same shard.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317000181
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317000181:12,Security,validat,validated,12,Also when I validated the bam I got no errors. . I'll try rerunning this BQSR step a bunch of times to see if I can get the error again and see if it happens on the same shard.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317000181
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317001093:33,Availability,error,error,33,"@pshapiro4broad FYI, this is the error that I showed you yesterday.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317001093
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955:139,Availability,error,error,139,"I reran the BQSR step 5 times using the exact same input bam as before. One has succeeded, 3 are still running and I got a new yet similar error message on a different shard this time:. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr12:1+ -L chr13:1+; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.KnjoXJ; [July 21, 2017 2:50:20 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr12:1+ --intervals chr13:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --reference /cromwell_root/broad-r",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955:4081,Availability,avail,available,4081,"c346ca6d on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_111-8u111-b14-2~bpo8+1-b14; Version: 4.beta.1; [July 21, 2017 3:05:58 PM UTC] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 15.64 minutes.; Runtime.totalMemory()=4191682560; htsjdk.samtools.util.RuntimeIOException: /PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam has invalid uncompressedLength: -305336571; 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:530); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:519); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:455); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:445); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:194); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:326); 	at java.io.DataInputStream.read(DataInputStream.java:149); 	at htsjdk.samtools.util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:404); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955:145,Integrability,message,message,145,"I reran the BQSR step 5 times using the exact same input bam as before. One has succeeded, 3 are still running and I got a new yet similar error message on a different shard this time:. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr12:1+ -L chr13:1+; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.KnjoXJ; [July 21, 2017 2:50:20 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr12:1+ --intervals chr13:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --reference /cromwell_root/broad-r",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955:6269,Integrability,wrap,wrapAndCopyInto,6269,ools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955:5494,Performance,load,loadNextRecord,5494,mtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:1024); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:988); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractP,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955:591,Testability,log,log,591,"I reran the BQSR step 5 times using the exact same input bam as before. One has succeeded, 3 are still running and I got a new yet similar error message on a different shard this time:. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr12:1+ -L chr13:1+; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.KnjoXJ; [July 21, 2017 2:50:20 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr12:1+ --intervals chr13:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --reference /cromwell_root/broad-r",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955:5300,Testability,Assert,AssertingIterator,5300,util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:404); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:1024); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:988); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.ja,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955:5374,Testability,Assert,AssertingIterator,5374,ls.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:1024); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:988); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForE,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317028955
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317029371:227,Availability,error,error,227,"Oh, I just realized I also changed from copying in whole dbsnp vcf to streaming it with NIO. Could this be from uncompressing a vcf.gz file rather than the bam? If so I can easily switch back to copying in dbsnp. Although that error message leads me to believe the problem is still with the BAM.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317029371
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317029371:233,Integrability,message,message,233,"Oh, I just realized I also changed from copying in whole dbsnp vcf to streaming it with NIO. Could this be from uncompressing a vcf.gz file rather than the bam? If so I can easily switch back to copying in dbsnp. Although that error message leads me to believe the problem is still with the BAM.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317029371
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317032724:320,Availability,error,errors,320,"@meganshand The stack trace shows that it's happening in the bam reading, not the vcf reading. Did you examine `gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam` to see if there are any errors? Can you do `samtools view` on this file and GATK `PrintReads` without complaint?. Since the problem is non-deterministic, `samjdk.use_async_io_write_samtools` is another possible culprit. . I suggest doing 5 runs for *each* of the following combinations of settings (should be added to *every* GATK4 command in the WDL):. 1. `--javaOptions ""-Dsamjdk.use_async_io_write_samtools=false""` (will need to add this to the existing `javaOptions` string for gatk-launch in your WDL). 2. `--cloudPrefetchBuffer 0 --cloudIndexPrefetchBuffer 0`. 3. `--use_jdk_deflater --use_jdk_inflater`. This will help narrow down whether the problem lies in the asynchronous writer, the asynchronous NIO prefetcher, or the Intel deflater/inflater itself (or none of the above!)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317032724
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317032724:929,Availability,down,down,929,"@meganshand The stack trace shows that it's happening in the bam reading, not the vcf reading. Did you examine `gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam` to see if there are any errors? Can you do `samtools view` on this file and GATK `PrintReads` without complaint?. Since the problem is non-deterministic, `samjdk.use_async_io_write_samtools` is another possible culprit. . I suggest doing 5 runs for *each* of the following combinations of settings (should be added to *every* GATK4 command in the WDL):. 1. `--javaOptions ""-Dsamjdk.use_async_io_write_samtools=false""` (will need to add this to the existing `javaOptions` string for gatk-launch in your WDL). 2. `--cloudPrefetchBuffer 0 --cloudIndexPrefetchBuffer 0`. 3. `--use_jdk_deflater --use_jdk_inflater`. This will help narrow down whether the problem lies in the asynchronous writer, the asynchronous NIO prefetcher, or the Intel deflater/inflater itself (or none of the above!)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317032724
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317037304:54,Testability,test,test,54,"I'll add, as a supplement to the above: for the first test case, `samjdk.use_async_io_write_samtools` should be disabled in every GATK/Picard tool in the WDL. The syntax for disabling it in GATK4 with gatk-launch is given above, for Picard and GATK3 it's just -Dsamjdk.use_async_io_write_samtools=false",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317037304
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317047601:20,Security,validat,validate,20,@droazen Didn't she validate the input bam though?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317047601
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317048503:134,Availability,error,error,134,"@lbergelson You may recall that we've encountered things like malformed block-compressed input that validates and can be read without error, and yet appears to have fewer records than it should.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317048503
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317048503:100,Security,validat,validates,100,"@lbergelson You may recall that we've encountered things like malformed block-compressed input that validates and can be read without error, and yet appears to have fewer records than it should.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317048503
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564:193,Availability,error,error,193,"@danxmoran This is the bug you're seeing too. I haven't gotten a chance to try any of the suggestions above yet, but I'm hoping to start this afternoon. Also, just for completeness I saw a new error message today that I think Dan saw too (this time from PrintReads):. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -Xms2g -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar PrintReads -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-GatherBamFiles/CHMI_CHMI3_WGS2.bam --interval_padding 500 -L /cromwell_root/broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/1scattered.interval_list -O local.sharded.bam; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.l7eTB5; [July 21, 2017 6:20:54 PM UTC] PrintReads --output local.sharded.bam --intervals /cromwell_root/broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/1scattered.interval_list --interval_padding 500 --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-GatherBamFiles/CHMI_CHMI3_WGS2.bam --interval_set_rule UNION --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564:3447,Availability,avail,available,3447,")=2088763392; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-830472192]; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:554); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:543); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:512); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:455); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:445); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:194); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:326); 	at java.io.DataInputStream.read(DataInputStream.java:149); 	at htsjdk.samtools.util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:404); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564:199,Integrability,message,message,199,"@danxmoran This is the bug you're seeing too. I haven't gotten a chance to try any of the suggestions above yet, but I'm hoping to start this afternoon. Also, just for completeness I saw a new error message today that I think Dan saw too (this time from PrintReads):. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -Xms2g -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar PrintReads -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-GatherBamFiles/CHMI_CHMI3_WGS2.bam --interval_padding 500 -L /cromwell_root/broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/1scattered.interval_list -O local.sharded.bam; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.l7eTB5; [July 21, 2017 6:20:54 PM UTC] PrintReads --output local.sharded.bam --intervals /cromwell_root/broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/1scattered.interval_list --interval_padding 500 --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/a4b1f3b8-9530-491e-8d87-749495f526c8/call-GatherBamFiles/CHMI_CHMI3_WGS2.bam --interval_set_rule UNION --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564:5635,Integrability,wrap,wrapAndCopyInto,5635,ools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564:2517,Performance,concurren,concurrent,2517,"_WGS2.bam --interval_set_rule UNION --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --use_jdk_deflater false --use_jdk_inflater false --disableToolDefaultReadFilters false; [July 21, 2017 6:20:54 PM UTC] Executing as root@9b75c21b7620 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_111-8u111-b14-2~bpo8+1-b14; Version: 4.beta.1; [July 21, 2017 6:29:58 PM UTC] org.broadinstitute.hellbender.tools.PrintReads done. Elapsed time: 9.06 minutes.; Runtime.totalMemory()=2088763392; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-830472192]; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:554); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:543); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:512); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:455); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:445); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:194); 	at htsjdk.samtools.util.Blo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564:4860,Performance,load,loadNextRecord,4860,mtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:1024); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:988); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractP,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564:6704,Performance,concurren,concurrent,6704,"s$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); Caused by: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-830472192]; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 44 more; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-830472192]; 	at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:139); 	at com.google.clou",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564:6881,Performance,concurren,concurrent,6881,"ne.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); Caused by: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-830472192]; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 44 more; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-830472192]; 	at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:139); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(See",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564:6946,Performance,concurren,concurrent,6946,"rencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); Caused by: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-830472192]; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 44 more; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-830472192]; 	at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:139); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hell",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564:8068,Performance,concurren,concurrent,8068,"kableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 44 more; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-830472192]; 	at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:139); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-830472192]; 	at shaded.cloud_nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:487); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	... 7 more; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564:8130,Performance,concurren,concurrent,8130,"kableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 44 more; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-830472192]; 	at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:139); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-830472192]; 	at shaded.cloud_nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:487); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	... 7 more; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564:8215,Performance,concurren,concurrent,8215,"kableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 44 more; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-830472192]; 	at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:139); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-830472192]; 	at shaded.cloud_nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:487); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	... 7 more; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564:4666,Testability,Assert,AssertingIterator,4666,util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:404); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:1024); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:988); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.ja,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564:4740,Testability,Assert,AssertingIterator,4740,ls.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:1024); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:988); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForE,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317442564
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317443294:16,Availability,error,error,16,"Yup, that's the error (we hit it in ApplyBQSR).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317443294
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824:147,Availability,error,error,147,"Ok, I know @danxmoran also kicked off jobs trying those three options @droazen mentioned above, but I at least tried the first option and got this error message:. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -Dsamjdk.use_async_io_write_samtools=false -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr5:1+; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.pDg1Ou; [July 24, 2017 5:46:04 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr5:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --reference /cromwell_root/broad-references/hg38/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824:4066,Availability,avail,available,4066,"08d8af33 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_111-8u111-b14-2~bpo8+1-b14; Version: 4.beta.1; [July 24, 2017 5:56:53 PM UTC] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 10.81 minutes.; Runtime.totalMemory()=4191682560; htsjdk.samtools.util.RuntimeIOException: /PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam has invalid uncompressedLength: -966754216; 	at htsjdk.samtools.util.BlockCompressedInputStream.inflateBlock(BlockCompressedInputStream.java:530); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:519); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:455); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:445); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:194); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:326); 	at java.io.DataInputStream.read(DataInputStream.java:149); 	at htsjdk.samtools.util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:404); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824:153,Integrability,message,message,153,"Ok, I know @danxmoran also kicked off jobs trying those three options @droazen mentioned above, but I at least tried the first option and got this error message:. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -Dsamjdk.use_async_io_write_samtools=false -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr5:1+; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.pDg1Ou; [July 24, 2017 5:46:04 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr5:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --reference /cromwell_root/broad-references/hg38/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824:6254,Integrability,wrap,wrapAndCopyInto,6254,ools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824:5479,Performance,load,loadNextRecord,5479,mtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:1024); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:988); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractP,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824:568,Testability,log,log,568,"Ok, I know @danxmoran also kicked off jobs trying those three options @droazen mentioned above, but I at least tried the first option and got this error message:. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -Dsamjdk.use_async_io_write_samtools=false -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr5:1+; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.pDg1Ou; [July 24, 2017 5:46:04 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr5:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --reference /cromwell_root/broad-references/hg38/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824:5285,Testability,Assert,AssertingIterator,5285,util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:404); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:1024); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:988); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.ja,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824:5359,Testability,Assert,AssertingIterator,5359,ls.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:1024); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:988); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForE,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317520824
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:42,Availability,error,error,42,"For the second option I get the following error message (cloud prefetch buffer = 0):. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr1:1+ --cloudPrefetchBuffer 0 --cloudIndexPrefetchBuffer 0; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.AtXpRI; [July 24, 2017 5:46:26 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr1:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --reference /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta --cloudPrefetchBuffer 0 --cloudInd",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:8723,Availability,avail,available,8723,.SocketException: Connection reset; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:515); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 49 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSock,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:8790,Availability,avail,available,8790,1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:515); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 49 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocket,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:8861,Availability,avail,available,8861,cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:515); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 49 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:9414,Availability,down,download,9414,d(CloudStorageReadChannel.java:113); 	... 49 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpI,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:8847,Energy Efficiency,Meter,MeteredStream,8847,9); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:515); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 49 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketIm,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:8871,Energy Efficiency,Meter,MeteredStream,8871,cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:515); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 49 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:10264,Energy Efficiency,Meter,MeteredStream,10264,); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 58 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:209); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readData,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:10283,Energy Efficiency,Meter,MeteredStream,10283,oud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 58 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:209); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketI,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:48,Integrability,message,message,48,"For the second option I get the following error message (cloud prefetch buffer = 0):. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr1:1+ --cloudPrefetchBuffer 0 --cloudIndexPrefetchBuffer 0; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.AtXpRI; [July 24, 2017 5:46:26 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr1:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --reference /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta --cloudPrefetchBuffer 0 --cloudInd",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:6567,Integrability,wrap,wrapAndCopyInto,6567,es(FeatureContext.java:163); 	at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:115); 	at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:253); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:180); 	at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:9046,Integrability,protocol,protocol,9046,obReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 49 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:10388,Integrability,protocol,protocol,10388,ent.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 58 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:209); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 68 more; ```. Also,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:8625,Security,secur,security,8625,.google.cloud.storage.StorageException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:515); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 49 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:8695,Security,secur,security,8695,javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:515); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	... 49 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.secu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:9634,Security,secur,security,9634,SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(Fil,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:9696,Security,secur,security,9696,ity.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:9763,Security,secur,security,9763,io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:9830,Security,secur,security,9830, sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:9907,Security,secur,security,9907,.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 58 more; Caused by: java.net.SocketException: Connection reset; 	at java.net,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:9984,Security,secur,security,9984,Stream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:97); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:63); 	at shaded.cloud_nio.com.google.api.client.http.HttpResponse.download(HttpResponse.java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 58 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:209); 	at java.net.SocketInput,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:11038,Security,secur,security,11038,java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 58 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:209); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 68 more; ```. Also anecdotally it seems to happen less often.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:11104,Security,secur,security,11104,java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 58 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:209); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 68 more; ```. Also anecdotally it seems to happen less often.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:11165,Security,secur,security,11165,java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 58 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:209); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 68 more; ```. Also anecdotally it seems to happen less often.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:11236,Security,secur,security,11236,java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 58 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:209); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 68 more; ```. Also anecdotally it seems to happen less often.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:11311,Security,secur,security,11311,java:421); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:510); 	... 55 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:169); 	at java.io.FilterInputStream.read(FilterInputStream.java:107); 	at shaded.cloud_nio.com.google.api.client.util.ByteStreams.copy(ByteStreams.java:51); 	at shaded.cloud_nio.com.google.api.client.util.IOUtils.copy(IOUtils.java:94); 	... 58 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:209); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 68 more; ```. Also anecdotally it seems to happen less often.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138:491,Testability,log,log,491,"For the second option I get the following error message (cloud prefetch buffer = 0):. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr1:1+ --cloudPrefetchBuffer 0 --cloudIndexPrefetchBuffer 0; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.AtXpRI; [July 24, 2017 5:46:26 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr1:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --reference /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta --cloudPrefetchBuffer 0 --cloudInd",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549138
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881:66,Availability,error,error,66,"And with the third option (using jdk inflater/deflator) the first error I found is:. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr11:1+ --use_jdk_deflater --use_jdk_inflater; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.hlHVlU; [July 24, 2017 5:49:13 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr11:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --reference /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta --use_jdk_deflater true --use_jdk_inflater true ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881:4259,Availability,avail,available,4259,")=4191682560; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-134217728]; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:554); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:543); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:512); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:455); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:445); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:194); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:326); 	at java.io.DataInputStream.read(DataInputStream.java:149); 	at htsjdk.samtools.util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:404); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881:6447,Integrability,wrap,wrapAndCopyInto,6447,ools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881:3329,Performance,concurren,concurrent,3329,"ltBaseQualities -1 --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --disableToolDefaultReadFilters false; [July 24, 2017 5:49:13 PM UTC] Executing as root@bc900e525fef on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_111-8u111-b14-2~bpo8+1-b14; Version: 4.beta.1; [July 24, 2017 6:18:40 PM UTC] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 29.45 minutes.; Runtime.totalMemory()=4191682560; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-134217728]; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:554); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:543); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:512); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:455); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:445); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:194); 	at htsjdk.samtools.util.Blo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881:5672,Performance,load,loadNextRecord,5672,mtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:1024); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:988); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractP,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881:7516,Performance,concurren,concurrent,7516,"s$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); Caused by: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-134217728]; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 44 more; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-134217728]; 	at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:139); 	at com.google.clou",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881:7693,Performance,concurren,concurrent,7693,"ne.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); Caused by: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-134217728]; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 44 more; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-134217728]; 	at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:139); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(See",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881:7758,Performance,concurren,concurrent,7758,"rencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); Caused by: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-134217728]; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 44 more; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-134217728]; 	at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:139); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hell",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881:8880,Performance,concurren,concurrent,8880,"kableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 44 more; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-134217728]; 	at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:139); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-134217728]; 	at shaded.cloud_nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:487); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	... 7 more; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881:8942,Performance,concurren,concurrent,8942,"kableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 44 more; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-134217728]; 	at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:139); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-134217728]; 	at shaded.cloud_nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:487); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	... 7 more; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881:9027,Performance,concurren,concurrent,9027,"kableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 44 more; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-134217728]; 	at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:139); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-134217728]; 	at shaded.cloud_nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:487); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	... 7 more; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881:490,Testability,log,log,490,"And with the third option (using jdk inflater/deflator) the first error I found is:. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr11:1+ --use_jdk_deflater --use_jdk_inflater; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.hlHVlU; [July 24, 2017 5:49:13 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr11:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --reference /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta --use_jdk_deflater true --use_jdk_inflater true ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881:5478,Testability,Assert,AssertingIterator,5478,util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:404); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:1024); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:988); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.ja,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881:5552,Testability,Assert,AssertingIterator,5552,ls.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:1024); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:988); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForE,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317549881
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317550713:113,Availability,error,error,113,"@meganshand I think we need to re-run option 2 with latest gatk4/master to be sure that the ""all reopens failed"" error is not masking other errors. I really hope option 2 (the NIO prefetcher) is the culprit, though, as it would be by far the easiest to fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317550713
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317550713:126,Availability,mask,masking,126,"@meganshand I think we need to re-run option 2 with latest gatk4/master to be sure that the ""all reopens failed"" error is not masking other errors. I really hope option 2 (the NIO prefetcher) is the culprit, though, as it would be by far the easiest to fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317550713
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317550713:140,Availability,error,errors,140,"@meganshand I think we need to re-run option 2 with latest gatk4/master to be sure that the ""all reopens failed"" error is not masking other errors. I really hope option 2 (the NIO prefetcher) is the culprit, though, as it would be by far the easiest to fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317550713
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:165,Availability,error,error,165,"I reran option 2 with latest gatk4/master. I ran the BaseRecalibrator step (scattered about 20 ways) 10 times each. All 10 runs failed. I haven't checked all of the error messages yet, but I did see a couple with a new error message about the dbsnp vcf, which I was also streaming with NIO. I'm going to change that back to localizing the dbsnp vcf to see if those go away. Here's that message:. ```; Using GATK jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr8:1+ --cloudPrefetchBuffer 0 --cloudIndexPrefetchBuffer 0; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.DoXBYr; [July 24, 2017 9:31:25 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.re",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:219,Availability,error,error,219,"I reran option 2 with latest gatk4/master. I ran the BaseRecalibrator step (scattered about 20 ways) 10 times each. All 10 runs failed. I haven't checked all of the error messages yet, but I did see a couple with a new error message about the dbsnp vcf, which I was also streaming with NIO. I'm going to change that back to localizing the dbsnp vcf to see if those go away. Here's that message:. ```; Using GATK jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr8:1+ --cloudPrefetchBuffer 0 --cloudIndexPrefetchBuffer 0; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.DoXBYr; [July 24, 2017 9:31:25 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.re",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:7031,Availability,error,error,7031,"EachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); ```. Then another run I happened to click on had a similar error to what we've seen before, but I'm now wondering if this message means something different from the other inflator style error messages:. ```; Using GATK jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.v",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:7158,Availability,error,error,7158,"EachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); ```. Then another run I happened to click on had a similar error to what we've seen before, but I'm now wondering if this message means something different from the other inflator style error messages:. ```; Using GATK jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.v",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:15790,Availability,error,error,15790,"tPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); Caused by: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-890235307]; 	at shaded.cloud_nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:179); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:487); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	... 50 more; ```. I'll rerun without using NIO for the dbsnp vcf and I'll try to look through the other 7 error messages to see if anything is different from those above.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:171,Integrability,message,messages,171,"I reran option 2 with latest gatk4/master. I ran the BaseRecalibrator step (scattered about 20 ways) 10 times each. All 10 runs failed. I haven't checked all of the error messages yet, but I did see a couple with a new error message about the dbsnp vcf, which I was also streaming with NIO. I'm going to change that back to localizing the dbsnp vcf to see if those go away. Here's that message:. ```; Using GATK jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr8:1+ --cloudPrefetchBuffer 0 --cloudIndexPrefetchBuffer 0; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.DoXBYr; [July 24, 2017 9:31:25 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.re",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:225,Integrability,message,message,225,"I reran option 2 with latest gatk4/master. I ran the BaseRecalibrator step (scattered about 20 ways) 10 times each. All 10 runs failed. I haven't checked all of the error messages yet, but I did see a couple with a new error message about the dbsnp vcf, which I was also streaming with NIO. I'm going to change that back to localizing the dbsnp vcf to see if those go away. Here's that message:. ```; Using GATK jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr8:1+ --cloudPrefetchBuffer 0 --cloudIndexPrefetchBuffer 0; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.DoXBYr; [July 24, 2017 9:31:25 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.re",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:386,Integrability,message,message,386,"I reran option 2 with latest gatk4/master. I ran the BaseRecalibrator step (scattered about 20 ways) 10 times each. All 10 runs failed. I haven't checked all of the error messages yet, but I did see a couple with a new error message about the dbsnp vcf, which I was also streaming with NIO. I'm going to change that back to localizing the dbsnp vcf to see if those go away. Here's that message:. ```; Using GATK jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr8:1+ --cloudPrefetchBuffer 0 --cloudIndexPrefetchBuffer 0; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.DoXBYr; [July 24, 2017 9:31:25 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.re",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:5924,Integrability,wrap,wrapAndCopyInto,5924,es(FeatureContext.java:163); 	at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:115); 	at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:253); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:180); 	at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:7094,Integrability,message,message,7094,"EachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); ```. Then another run I happened to click on had a similar error to what we've seen before, but I'm now wondering if this message means something different from the other inflator style error messages:. ```; Using GATK jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.v",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:7164,Integrability,message,messages,7164,"EachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); ```. Then another run I happened to click on had a similar error to what we've seen before, but I'm now wondering if this message means something different from the other inflator style error messages:. ```; Using GATK jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.v",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:13939,Integrability,wrap,wrapAndCopyInto,13939,es(FeatureContext.java:163); 	at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:115); 	at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:253); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:180); 	at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:15796,Integrability,message,messages,15796,"tPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:116); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); Caused by: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-890235307]; 	at shaded.cloud_nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:179); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:487); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	... 50 more; ```. I'll rerun without using NIO for the dbsnp vcf and I'll try to look through the other 7 error messages to see if anything is different from those above.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:816,Testability,log,log,816,"I reran option 2 with latest gatk4/master. I ran the BaseRecalibrator step (scattered about 20 ways) 10 times each. All 10 runs failed. I haven't checked all of the error messages yet, but I did see a couple with a new error message about the dbsnp vcf, which I was also streaming with NIO. I'm going to change that back to localizing the dbsnp vcf to see if those go away. Here's that message:. ```; Using GATK jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr8:1+ --cloudPrefetchBuffer 0 --cloudIndexPrefetchBuffer 0; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.DoXBYr; [July 24, 2017 9:31:25 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.re",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963:7595,Testability,log,log,7595,"eMainPostParseArgs(CommandLineProgram.java:173); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); ```. Then another run I happened to click on had a similar error to what we've seen before, but I'm now wondering if this message means something different from the other inflator style error messages:. ```; Using GATK jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk-package-4.beta.2-11-g1b884aa-SNAPSHOT-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr5:1+ --cloudPrefetchBuffer 0 --cloudIndexPrefetchBuffer 0; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.shnAZY; [July 24, 2017 9:31:47 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317736963
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317743568:116,Availability,error,error,116,"I kicked off the runs now localizing the dbsnp file. Of the 10 runs that had failed before, 5 of them had the dbsnp error and the other 5 had that expected non-negative error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317743568
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317743568:169,Availability,error,error,169,"I kicked off the runs now localizing the dbsnp file. Of the 10 runs that had failed before, 5 of them had the dbsnp error and the other 5 had that expected non-negative error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317743568
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:107,Availability,failure,failures,107,"Yes, I ran option 3, 5 times (using the older version not latest master). Of those 5, 3 failed. One of the failures was: `java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: All reopens failed`. The other two were both the non-negative error message:. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr6:1+ --use_jdk_deflater --use_jdk_inflater; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.4ZS1WV; [July 24, 2017 5:48:10 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr6:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:296,Availability,error,error,296,"Yes, I ran option 3, 5 times (using the older version not latest master). Of those 5, 3 failed. One of the failures was: `java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: All reopens failed`. The other two were both the non-negative error message:. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr6:1+ --use_jdk_deflater --use_jdk_inflater; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.4ZS1WV; [July 24, 2017 5:48:10 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr6:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:4485,Availability,avail,available,4485,"=4191682560; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-1056964608]; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:554); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:543); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:512); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:455); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:445); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:194); 	at htsjdk.samtools.util.BlockCompressedInputStream.read(BlockCompressedInputStream.java:326); 	at java.io.DataInputStream.read(DataInputStream.java:149); 	at htsjdk.samtools.util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:404); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:302,Integrability,message,message,302,"Yes, I ran option 3, 5 times (using the older version not latest master). Of those 5, 3 failed. One of the failures was: `java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: All reopens failed`. The other two were both the non-negative error message:. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr6:1+ --use_jdk_deflater --use_jdk_inflater; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.4ZS1WV; [July 24, 2017 5:48:10 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr6:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:6673,Integrability,wrap,wrapAndCopyInto,6673,ools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:160,Performance,concurren,concurrent,160,"Yes, I ran option 3, 5 times (using the older version not latest master). Of those 5, 3 failed. One of the failures was: `java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: All reopens failed`. The other two were both the non-negative error message:. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr6:1+ --use_jdk_deflater --use_jdk_inflater; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.4ZS1WV; [July 24, 2017 5:48:10 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr6:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:3554,Performance,concurren,concurrent,3554,"ltBaseQualities -1 --interval_set_rule UNION --interval_padding 0 --interval_exclusion_padding 0 --readValidationStringency SILENT --secondsBetweenProgressUpdates 10.0 --disableSequenceDictionaryValidation false --createOutputBamIndex true --createOutputBamMD5 false --createOutputVariantIndex true --createOutputVariantMD5 false --lenient false --addOutputSAMProgramRecord true --addOutputVCFCommandLine true --cloudPrefetchBuffer 40 --cloudIndexPrefetchBuffer -1 --disableBamIndexCaching false --help false --version false --showHidden false --verbosity INFO --QUIET false --disableToolDefaultReadFilters false; [July 24, 2017 5:48:10 PM UTC] Executing as root@57972df58207 on Linux 4.9.0-0.bpo.3-amd64 amd64; OpenJDK 64-Bit Server VM 1.8.0_111-8u111-b14-2~bpo8+1-b14; Version: 4.beta.1; [July 24, 2017 6:04:42 PM UTC] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 16.54 minutes.; Runtime.totalMemory()=4191682560; java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-1056964608]; 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:309); 	at htsjdk.samtools.seekablestream.SeekablePathStream.read(SeekablePathStream.java:86); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:554); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBytes(BlockCompressedInputStream.java:543); 	at htsjdk.samtools.util.BlockCompressedInputStream.processNextBlock(BlockCompressedInputStream.java:512); 	at htsjdk.samtools.util.BlockCompressedInputStream.nextBlock(BlockCompressedInputStream.java:455); 	at htsjdk.samtools.util.BlockCompressedInputStream.readBlock(BlockCompressedInputStream.java:445); 	at htsjdk.samtools.util.BlockCompressedInputStream.available(BlockCompressedInputStream.java:194); 	at htsjdk.samtools.util.Bl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:5898,Performance,load,loadNextRecord,5898,mtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:1024); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:988); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractP,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:7742,Performance,concurren,concurrent,7742,"s$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); Caused by: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-1056964608]; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 44 more; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-1056964608]; 	at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:139); 	at com.google.cl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:7920,Performance,concurren,concurrent,7920,"e.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); Caused by: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-1056964608]; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 44 more; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-1056964608]; 	at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:139); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(Se",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:7985,Performance,concurren,concurrent,7985,"encePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:838); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:115); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:170); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:189); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:230); Caused by: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-1056964608]; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 44 more; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-1056964608]; 	at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:139); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:9108,Performance,concurren,concurrent,9108,"bleByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 44 more; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-1056964608]; 	at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:139); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-1056964608]; 	at shaded.cloud_nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:487); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	... 7 more; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:9170,Performance,concurren,concurrent,9170,"bleByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 44 more; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-1056964608]; 	at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:139); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-1056964608]; 	at shaded.cloud_nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:487); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	... 7 more; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:9255,Performance,concurren,concurrent,9255,"bleByteChannelPrefetcher$WorkUnit.getBuf(SeekableByteChannelPrefetcher.java:136); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.fetch(SeekableByteChannelPrefetcher.java:255); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher.read(SeekableByteChannelPrefetcher.java:300); 	... 44 more; Caused by: com.google.cloud.storage.StorageException: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-1056964608]; 	at com.google.cloud.storage.StorageException.translateAndThrow(StorageException.java:71); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:139); 	at com.google.cloud.storage.contrib.nio.CloudStorageReadChannel.read(CloudStorageReadChannel.java:113); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:131); 	at org.broadinstitute.hellbender.utils.nio.SeekableByteChannelPrefetcher$WorkUnit.call(SeekableByteChannelPrefetcher.java:104); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.IllegalArgumentException: Position should be non-negative, is %d [-1056964608]; 	at shaded.cloud_nio.com.google.common.base.Preconditions.checkArgument(Preconditions.java:146); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.read(HttpStorageRpc.java:487); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:127); 	at com.google.cloud.storage.BlobReadChannel$1.call(BlobReadChannel.java:124); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:93); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:49); 	at com.google.cloud.storage.BlobReadChannel.read(BlobReadChannel.java:124); 	... 7 more; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:717,Testability,log,log,717,"Yes, I ran option 3, 5 times (using the older version not latest master). Of those 5, 3 failed. One of the failures was: `java.lang.RuntimeException: java.util.concurrent.ExecutionException: com.google.cloud.storage.StorageException: All reopens failed`. The other two were both the non-negative error message:. ```; Using GATK jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -Dsnappy.disable=true -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:+PrintFlagsFinal -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:gc_log.log -Xms4000m -jar /usr/gitc/gatk4/gatk-package-4.beta.1-local.jar BaseRecalibrator -R /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -I gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-960e-17578f6b382c/call-SortAndFixSampleBam/CHMI_CHMI3_WGS2.aligned.duplicate_marked.sorted.bam --useOriginalQualities -O CHIM.recal_data.csv -knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf -knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz -knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz -L chr6:1+ --use_jdk_deflater --use_jdk_inflater; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.4ZS1WV; [July 24, 2017 5:48:10 PM UTC] BaseRecalibrator --useOriginalQualities true --knownSites gs://broad-references/hg38/v0/Homo_sapiens_assembly38.dbsnp138.vcf --knownSites /cromwell_root/broad-references/hg38/v0/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz --knownSites /cromwell_root/broad-references/hg38/v0/Homo_sapiens_assembly38.known_indels.vcf.gz --output CHIM.recal_data.csv --intervals chr6:1+ --input gs://broad-gotc-dev-cromwell-execution/PairedEndSingleSampleWorkflow/66442def-ad3f-4c6c-",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:5704,Testability,Assert,AssertingIterator,5704,util.BinaryCodec.readBytesOrFewer(BinaryCodec.java:404); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:1024); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:988); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.ja,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472:5778,Testability,Assert,AssertingIterator,5778,ls.util.BinaryCodec.readBytes(BinaryCodec.java:380); 	at htsjdk.samtools.util.BinaryCodec.readBytes(BinaryCodec.java:366); 	at htsjdk.samtools.BAMRecordCodec.decode(BAMRecordCodec.java:209); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.getNextRecord(BAMFileReader.java:829); 	at htsjdk.samtools.BAMFileReader$BAMFileIndexIterator.getNextRecord(BAMFileReader.java:981); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.advance(BAMFileReader.java:803); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:797); 	at htsjdk.samtools.BAMFileReader$BAMFileIterator.next(BAMFileReader.java:765); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.advance(BAMFileReader.java:1034); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:1024); 	at htsjdk.samtools.BAMFileReader$BAMQueryFilteringIterator.next(BAMFileReader.java:988); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:576); 	at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:548); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); 	at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:29); 	at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:15); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForE,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-317782472
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-318419738:195,Availability,error,errors,195,@meganshand We think we may have identified the underlying problem -- a single typecast from long -> int in the `google-cloud-java` library. We are testing now to see if it actually resolves the errors.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-318419738
https://github.com/broadinstitute/gatk/issues/3316#issuecomment-318419738:148,Testability,test,testing,148,@meganshand We think we may have identified the underlying problem -- a single typecast from long -> int in the `google-cloud-java` library. We are testing now to see if it actually resolves the errors.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3316#issuecomment-318419738
https://github.com/broadinstitute/gatk/issues/3318#issuecomment-316889711:154,Availability,reliab,reliable,154,"I suggest making composite quadratures by stacking multiple copies of low-order quadratures. Also, note that high-order Gaussian quadratures only provide reliable error guarantees for smooth integrands. Composite quadratures with the same number of grid points often give better estimates than a high-order quadrature with the same number of points.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3318#issuecomment-316889711
https://github.com/broadinstitute/gatk/issues/3318#issuecomment-316889711:163,Availability,error,error,163,"I suggest making composite quadratures by stacking multiple copies of low-order quadratures. Also, note that high-order Gaussian quadratures only provide reliable error guarantees for smooth integrands. Composite quadratures with the same number of grid points often give better estimates than a high-order quadrature with the same number of points.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3318#issuecomment-316889711
https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323:149,Availability,down,downstream,149,"A couple of months ago I made an attempt to factor SATagBuilder out to a; public place and change its API to be a little more friendly to different; downstream uses, but I found some unexpected behavior in how it was parsing; SA tags that made me give up for fear of breaking the tools that already; rely on it. Within the SV tools, I'm currently working on a branch in which; I've written some code to parse SA tags. Perhaps we can work out what we; both need from a shared API and implement that. On Fri, Jul 21, 2017 at 12:56 PM, Valentin Ruano Rubio <; notifications@github.com> wrote:. > I have to deal with this component recently and I found the design rather; > awkward.... In general between GATK and htsjdk we don't seem to have a; > proper support for managing and querying Supplementary alignment; > information from read alignment records:; >; > Some of the things that I think smell:; >; > 1.; >; > Querying: implemented in htsjdk consists in forging artificial; > SAMRecords that contain only the alignment info in the SA tag element... It; > seems to me that it makes more sense to create class to hold this; > information alone (e.g. ReadAlignmentInfo or ReadAlignment); SATagBuilder; > already has defined a private inner class with that in mind ""SARead"" so why; > not flesh it out and make it public.; > 2.; >; > Writing: currently SATagBuilder gets attached to a read, parsing its; > current SA attribute content into SARead instances. It provides the; > possibility adding additional SAM record one by one or clearing the list.; > ... then it actually updates the SA attribute on the original read when a; > method (setTag) is explicitly called.; >; > I don't see the need to attach the SATag Builder to a read... it could; > perfectly be free standing; the same builder could be re-apply to several; > reads for that matter and I don't see any gain in hiding the read SA tag; > setting process,... even if typically this builder output would go to the; > ""SA"" tag, perhaps at som",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323
https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323:2109,Availability,error,error,2109,"naging and querying Supplementary alignment; > information from read alignment records:; >; > Some of the things that I think smell:; >; > 1.; >; > Querying: implemented in htsjdk consists in forging artificial; > SAMRecords that contain only the alignment info in the SA tag element... It; > seems to me that it makes more sense to create class to hold this; > information alone (e.g. ReadAlignmentInfo or ReadAlignment); SATagBuilder; > already has defined a private inner class with that in mind ""SARead"" so why; > not flesh it out and make it public.; > 2.; >; > Writing: currently SATagBuilder gets attached to a read, parsing its; > current SA attribute content into SARead instances. It provides the; > possibility adding additional SAM record one by one or clearing the list.; > ... then it actually updates the SA attribute on the original read when a; > method (setTag) is explicitly called.; >; > I don't see the need to attach the SATag Builder to a read... it could; > perfectly be free standing; the same builder could be re-apply to several; > reads for that matter and I don't see any gain in hiding the read SA tag; > setting process,... even if typically this builder output would go to the; > ""SA"" tag, perhaps at some point we would like to also write SA coordinate; > list somewhere else, some other tag name or perhaps an error message... why; > impose this single purpose limitation?; >; > I suggest to drop the notion of a builder for a more general custom; > ReadAlignmentInfo (or whatever name) list. Such list could be making; > reference to a dictionary to validate its elements, prevent duplicates,; > keep the primary SA in the first position... etc.; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3324>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AArTZft11VTCtCHT_xr89kPL7hMFYQyhks5sQNghgaJpZM4Ofpkb>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323
https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323:1573,Deployability,update,updates,1573,"th this component recently and I found the design rather; > awkward.... In general between GATK and htsjdk we don't seem to have a; > proper support for managing and querying Supplementary alignment; > information from read alignment records:; >; > Some of the things that I think smell:; >; > 1.; >; > Querying: implemented in htsjdk consists in forging artificial; > SAMRecords that contain only the alignment info in the SA tag element... It; > seems to me that it makes more sense to create class to hold this; > information alone (e.g. ReadAlignmentInfo or ReadAlignment); SATagBuilder; > already has defined a private inner class with that in mind ""SARead"" so why; > not flesh it out and make it public.; > 2.; >; > Writing: currently SATagBuilder gets attached to a read, parsing its; > current SA attribute content into SARead instances. It provides the; > possibility adding additional SAM record one by one or clearing the list.; > ... then it actually updates the SA attribute on the original read when a; > method (setTag) is explicitly called.; >; > I don't see the need to attach the SATag Builder to a read... it could; > perfectly be free standing; the same builder could be re-apply to several; > reads for that matter and I don't see any gain in hiding the read SA tag; > setting process,... even if typically this builder output would go to the; > ""SA"" tag, perhaps at some point we would like to also write SA coordinate; > list somewhere else, some other tag name or perhaps an error message... why; > impose this single purpose limitation?; >; > I suggest to drop the notion of a builder for a more general custom; > ReadAlignmentInfo (or whatever name) list. Such list could be making; > reference to a dictionary to validate its elements, prevent duplicates,; > keep the primary SA in the first position... etc.; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323
https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323:2115,Integrability,message,message,2115,"naging and querying Supplementary alignment; > information from read alignment records:; >; > Some of the things that I think smell:; >; > 1.; >; > Querying: implemented in htsjdk consists in forging artificial; > SAMRecords that contain only the alignment info in the SA tag element... It; > seems to me that it makes more sense to create class to hold this; > information alone (e.g. ReadAlignmentInfo or ReadAlignment); SATagBuilder; > already has defined a private inner class with that in mind ""SARead"" so why; > not flesh it out and make it public.; > 2.; >; > Writing: currently SATagBuilder gets attached to a read, parsing its; > current SA attribute content into SARead instances. It provides the; > possibility adding additional SAM record one by one or clearing the list.; > ... then it actually updates the SA attribute on the original read when a; > method (setTag) is explicitly called.; >; > I don't see the need to attach the SATag Builder to a read... it could; > perfectly be free standing; the same builder could be re-apply to several; > reads for that matter and I don't see any gain in hiding the read SA tag; > setting process,... even if typically this builder output would go to the; > ""SA"" tag, perhaps at some point we would like to also write SA coordinate; > list somewhere else, some other tag name or perhaps an error message... why; > impose this single purpose limitation?; >; > I suggest to drop the notion of a builder for a more general custom; > ReadAlignmentInfo (or whatever name) list. Such list could be making; > reference to a dictionary to validate its elements, prevent duplicates,; > keep the primary SA in the first position... etc.; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3324>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AArTZft11VTCtCHT_xr89kPL7hMFYQyhks5sQNghgaJpZM4Ofpkb>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323
https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323:2350,Security,validat,validate,2350,"naging and querying Supplementary alignment; > information from read alignment records:; >; > Some of the things that I think smell:; >; > 1.; >; > Querying: implemented in htsjdk consists in forging artificial; > SAMRecords that contain only the alignment info in the SA tag element... It; > seems to me that it makes more sense to create class to hold this; > information alone (e.g. ReadAlignmentInfo or ReadAlignment); SATagBuilder; > already has defined a private inner class with that in mind ""SARead"" so why; > not flesh it out and make it public.; > 2.; >; > Writing: currently SATagBuilder gets attached to a read, parsing its; > current SA attribute content into SARead instances. It provides the; > possibility adding additional SAM record one by one or clearing the list.; > ... then it actually updates the SA attribute on the original read when a; > method (setTag) is explicitly called.; >; > I don't see the need to attach the SATag Builder to a read... it could; > perfectly be free standing; the same builder could be re-apply to several; > reads for that matter and I don't see any gain in hiding the read SA tag; > setting process,... even if typically this builder output would go to the; > ""SA"" tag, perhaps at some point we would like to also write SA coordinate; > list somewhere else, some other tag name or perhaps an error message... why; > impose this single purpose limitation?; >; > I suggest to drop the notion of a builder for a more general custom; > ReadAlignmentInfo (or whatever name) list. Such list could be making; > reference to a dictionary to validate its elements, prevent duplicates,; > keep the primary SA in the first position... etc.; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3324>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AArTZft11VTCtCHT_xr89kPL7hMFYQyhks5sQNghgaJpZM4Ofpkb>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323
https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323:1530,Usability,clear,clearing,1530," Fri, Jul 21, 2017 at 12:56 PM, Valentin Ruano Rubio <; notifications@github.com> wrote:. > I have to deal with this component recently and I found the design rather; > awkward.... In general between GATK and htsjdk we don't seem to have a; > proper support for managing and querying Supplementary alignment; > information from read alignment records:; >; > Some of the things that I think smell:; >; > 1.; >; > Querying: implemented in htsjdk consists in forging artificial; > SAMRecords that contain only the alignment info in the SA tag element... It; > seems to me that it makes more sense to create class to hold this; > information alone (e.g. ReadAlignmentInfo or ReadAlignment); SATagBuilder; > already has defined a private inner class with that in mind ""SARead"" so why; > not flesh it out and make it public.; > 2.; >; > Writing: currently SATagBuilder gets attached to a read, parsing its; > current SA attribute content into SARead instances. It provides the; > possibility adding additional SAM record one by one or clearing the list.; > ... then it actually updates the SA attribute on the original read when a; > method (setTag) is explicitly called.; >; > I don't see the need to attach the SATag Builder to a read... it could; > perfectly be free standing; the same builder could be re-apply to several; > reads for that matter and I don't see any gain in hiding the read SA tag; > setting process,... even if typically this builder output would go to the; > ""SA"" tag, perhaps at some point we would like to also write SA coordinate; > list somewhere else, some other tag name or perhaps an error message... why; > impose this single purpose limitation?; >; > I suggest to drop the notion of a builder for a more general custom; > ReadAlignmentInfo (or whatever name) list. Such list could be making; > reference to a dictionary to validate its elements, prevent duplicates,; > keep the primary SA in the first position... etc.; >; > ; > You are receiving this because you are subscr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3324#issuecomment-317065323
https://github.com/broadinstitute/gatk/pull/3327#issuecomment-317091130:43,Testability,test,test,43,@droazen Please review. I'll also launch a test of this tonight to make sure the changes didn't introduce any stupid bugs.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3327#issuecomment-317091130
https://github.com/broadinstitute/gatk/pull/3329#issuecomment-318642013:0,Availability,Ping,Ping,0,Ping @vdauwera,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3329#issuecomment-318642013
https://github.com/broadinstitute/gatk/pull/3330#issuecomment-317188169:327,Deployability,integrat,integrated,327,"Anders Peterson: apete@optimatika.se. I think I made a very small contribution. There is absolutely no need to list me among the contributors. > On 21 Jul 2017, at 23:14, Louis Bergelson <notifications@github.com> wrote:; > ; > Updating the AUTHORS file to include authors who contributed to gatk-protected who's work has been integrated into GATK by the merger.; > ; > I need to find out the preferred emails for the newly listed authors.; > ; > Anders Peterson; > Ayman Abdel Ghany aymana.ghany@devfactory.com; > Kenji Kaneda; > Nils Homer; > ; > @apete @AymanDF @kkaneda @nh13 Would you like to be included here and if so, what email address would you like listed? Have I spelled your name correctly?; > ; > Resolves #3048; > ; > You can view, comment on, or merge this pull request online at:; > ; > https://github.com/broadinstitute/gatk/pull/3330; > ; > Commit Summary; > ; > 	 updating authors to include gatk-protected authors; > File Changes; > ; > 	 M AUTHORS (4); > Patch Links:; > ; > 	 https://github.com/broadinstitute/gatk/pull/3330.patch; > 	 https://github.com/broadinstitute/gatk/pull/3330.diff; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3330#issuecomment-317188169
https://github.com/broadinstitute/gatk/pull/3330#issuecomment-317188169:979,Deployability,Patch,Patch,979,"Anders Peterson: apete@optimatika.se. I think I made a very small contribution. There is absolutely no need to list me among the contributors. > On 21 Jul 2017, at 23:14, Louis Bergelson <notifications@github.com> wrote:; > ; > Updating the AUTHORS file to include authors who contributed to gatk-protected who's work has been integrated into GATK by the merger.; > ; > I need to find out the preferred emails for the newly listed authors.; > ; > Anders Peterson; > Ayman Abdel Ghany aymana.ghany@devfactory.com; > Kenji Kaneda; > Nils Homer; > ; > @apete @AymanDF @kkaneda @nh13 Would you like to be included here and if so, what email address would you like listed? Have I spelled your name correctly?; > ; > Resolves #3048; > ; > You can view, comment on, or merge this pull request online at:; > ; > https://github.com/broadinstitute/gatk/pull/3330; > ; > Commit Summary; > ; > 	 updating authors to include gatk-protected authors; > File Changes; > ; > 	 M AUTHORS (4); > Patch Links:; > ; > 	 https://github.com/broadinstitute/gatk/pull/3330.patch; > 	 https://github.com/broadinstitute/gatk/pull/3330.diff; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3330#issuecomment-317188169
https://github.com/broadinstitute/gatk/pull/3330#issuecomment-317188169:1051,Deployability,patch,patch,1051,"Anders Peterson: apete@optimatika.se. I think I made a very small contribution. There is absolutely no need to list me among the contributors. > On 21 Jul 2017, at 23:14, Louis Bergelson <notifications@github.com> wrote:; > ; > Updating the AUTHORS file to include authors who contributed to gatk-protected who's work has been integrated into GATK by the merger.; > ; > I need to find out the preferred emails for the newly listed authors.; > ; > Anders Peterson; > Ayman Abdel Ghany aymana.ghany@devfactory.com; > Kenji Kaneda; > Nils Homer; > ; > @apete @AymanDF @kkaneda @nh13 Would you like to be included here and if so, what email address would you like listed? Have I spelled your name correctly?; > ; > Resolves #3048; > ; > You can view, comment on, or merge this pull request online at:; > ; > https://github.com/broadinstitute/gatk/pull/3330; > ; > Commit Summary; > ; > 	 updating authors to include gatk-protected authors; > File Changes; > ; > 	 M AUTHORS (4); > Patch Links:; > ; > 	 https://github.com/broadinstitute/gatk/pull/3330.patch; > 	 https://github.com/broadinstitute/gatk/pull/3330.diff; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3330#issuecomment-317188169
https://github.com/broadinstitute/gatk/pull/3330#issuecomment-317188169:327,Integrability,integrat,integrated,327,"Anders Peterson: apete@optimatika.se. I think I made a very small contribution. There is absolutely no need to list me among the contributors. > On 21 Jul 2017, at 23:14, Louis Bergelson <notifications@github.com> wrote:; > ; > Updating the AUTHORS file to include authors who contributed to gatk-protected who's work has been integrated into GATK by the merger.; > ; > I need to find out the preferred emails for the newly listed authors.; > ; > Anders Peterson; > Ayman Abdel Ghany aymana.ghany@devfactory.com; > Kenji Kaneda; > Nils Homer; > ; > @apete @AymanDF @kkaneda @nh13 Would you like to be included here and if so, what email address would you like listed? Have I spelled your name correctly?; > ; > Resolves #3048; > ; > You can view, comment on, or merge this pull request online at:; > ; > https://github.com/broadinstitute/gatk/pull/3330; > ; > Commit Summary; > ; > 	 updating authors to include gatk-protected authors; > File Changes; > ; > 	 M AUTHORS (4); > Patch Links:; > ; > 	 https://github.com/broadinstitute/gatk/pull/3330.patch; > 	 https://github.com/broadinstitute/gatk/pull/3330.diff; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3330#issuecomment-317188169
https://github.com/broadinstitute/gatk/pull/3331#issuecomment-317128040:1530,Security,Validat,ValidateVariants,1530, 18607 +1212 ; ===============================================; Files 1168 1225 +57 ; Lines 62907 68654 +5747 ; Branches 9800 10837 +1037 ; ===============================================; + Hits 50604 55189 +4585 ; - Misses 8376 9267 +891 ; - Partials 3927 4198 +271; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3331?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...titute/hellbender/tools/walkers/GenotypeGVCFs.java](https://codecov.io/gh/broadinstitute/gatk/pull/3331?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnMuamF2YQ==) | `90% <> ()` | `47 <0> ()` | :arrow_down: |; | [...org/broadinstitute/hellbender/utils/GenomeLoc.java](https://codecov.io/gh/broadinstitute/gatk/pull/3331?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vbWVMb2MuamF2YQ==) | `68.362% <> ()` | `85 <0> ()` | :arrow_down: |; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/3331?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYWxpZGF0ZVZhcmlhbnRzLmphdmE=) | `80% <81.25%> (-0.597%)` | `28 <17> (+10)` | |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3331?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `85% <0%> (-15%)` | `3% <0%> (+2%)` | |; | [...lbender/tools/spark/pathseq/PathSeqScoreSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3331?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFTY29yZVNwYXJrLmphdmE=) | `72.84% <0%> (-7.16%)` | `13% <0%> (+5%)` | |; | [.../hellbender/tools/walkers/vqsr/TrancheManager.java](https://codecov.io/gh/broadinstitute/gatk/pull/3331?src=pr&el=tre,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3331#issuecomment-317128040
https://github.com/broadinstitute/gatk/pull/3333#issuecomment-317149978:2148,Testability,test,test,2148,mlsdGVyaW5nRW5naW5lLmphdmE=) | `76.033% <100%> ()` | `35 <0> ()` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3333?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3333?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3333?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3333?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3333?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3333?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `53.947% <0%> (-18.421%)` | `29% <0%> (-7%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3333?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGV,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3333#issuecomment-317149978
https://github.com/broadinstitute/gatk/pull/3333#issuecomment-317149978:3598,Testability,test,test,3598,aW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3333?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3333?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3333?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `53.947% <0%> (-18.421%)` | `29% <0%> (-7%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3333?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3333?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `70.37% <0%> (-11.111%)` | `10% <0%> ()` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3333?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/3333?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3333#issuecomment-317149978
https://github.com/broadinstitute/gatk/issues/3334#issuecomment-317457895:10,Safety,risk,risk,10,"So at the risk of sounding thick, what exact path do I use in my command when I'm calling the docker? Imagine I'm a six year old who doesn't understand what is the internal structure of the GATK docker image or what ""gatk-launch is in the standard docker image in /gatk"" means. Note that right now to call the jar I use /root/gatk.jar",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3334#issuecomment-317457895
https://github.com/broadinstitute/gatk/issues/3334#issuecomment-353612077:10,Usability,guid,guidance,10,Requested guidance (in a different ticket) on how this works when running locally.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3334#issuecomment-353612077
https://github.com/broadinstitute/gatk/issues/3338#issuecomment-318448675:160,Integrability,depend,depends,160,"@ronlevine I haven't started, but start to PR would be a few days to a week. However, if you're doing the same thing my efforts might be totally extraneous. It depends what exactly you're doing but Pair-HMM is the same for HC and M2.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3338#issuecomment-318448675
https://github.com/broadinstitute/gatk/issues/3342#issuecomment-317577301:379,Testability,test,testing,379,"@kgururaj and @kdatta Here's some GVCF data for a trio of samples, each called to haploid (ploidy 1) and tetraploid (4) genotypes. I included the reference (just chromosome 20) and the intervals list. This is data from one of our workshop tutorials so many of the intervals in the list I used don't have any data (so lots of no-calls) but there should be enough usable calls for testing purposes. Let me know if this isn't sufficient to get you started. . Thanks for looking into this, it's very important for a non-trivial subset of our users. . [genomicsdb.zip](https://github.com/broadinstitute/gatk/files/1171416/genomicsdb.zip)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3342#issuecomment-317577301
https://github.com/broadinstitute/gatk/issues/3342#issuecomment-317577301:362,Usability,usab,usable,362,"@kgururaj and @kdatta Here's some GVCF data for a trio of samples, each called to haploid (ploidy 1) and tetraploid (4) genotypes. I included the reference (just chromosome 20) and the intervals list. This is data from one of our workshop tutorials so many of the intervals in the list I used don't have any data (so lots of no-calls) but there should be enough usable calls for testing purposes. Let me know if this isn't sufficient to get you started. . Thanks for looking into this, it's very important for a non-trivial subset of our users. . [genomicsdb.zip](https://github.com/broadinstitute/gatk/files/1171416/genomicsdb.zip)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3342#issuecomment-317577301
https://github.com/broadinstitute/gatk/issues/3342#issuecomment-317582817:77,Availability,down,download,77,"@vdauwera, awesome, thank you. No problem with the attachment, I was able to download it fine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3342#issuecomment-317582817
https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317523846:228,Energy Efficiency,efficient,efficient,228,"Thanks for taking care of this. Be sure to take a look at the HDF5RandomizedSVDReadCountPanelOfNormals.IntervalHelper class in my sl_create_pon branch. I changed the way intervals are written to HDF5 to be faster and more space efficient by using a double matrix. Still a little hacky IMO, but since we can't write integer matrices it'll do for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317523846
https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317545909:87,Integrability,wrap,wrapper,87,@samuelklee Why can't we right integer matrices? Is that a missing feature in the hdf5 wrapper we built or is it fundamental to hdf5?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317545909
https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317617223:30,Integrability,wrap,wrapper,30,"I believe it's missing in the wrapper, although I'm not sure why?. If we revisit the wrapper code, there is some chunking functionality I've introduced in my branch for #2858 that we should perhaps also add. The writing of string matrices is also a bit awkward and could be improved.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317617223
https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317617223:85,Integrability,wrap,wrapper,85,"I believe it's missing in the wrapper, although I'm not sure why?. If we revisit the wrapper code, there is some chunking functionality I've introduced in my branch for #2858 that we should perhaps also add. The writing of string matrices is also a bit awkward and could be improved.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317617223
https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317834727:128,Integrability,wrap,wrapper,128,@LeeTL1220 reminds me that there is also some code for reading/writing intervals that I introduced that probably belongs in the wrapper as well.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-317834727
https://github.com/broadinstitute/gatk/issues/3349#issuecomment-318184455:43,Deployability,update,update,43,@samuelklee Should we make some tickets to update the wrapper?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-318184455
https://github.com/broadinstitute/gatk/issues/3349#issuecomment-318184455:54,Integrability,wrap,wrapper,54,@samuelklee Should we make some tickets to update the wrapper?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-318184455
https://github.com/broadinstitute/gatk/issues/3349#issuecomment-318243071:55,Integrability,wrap,wrapper,55,"Yes, let me know if they should go in this repo or the wrapper repo.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-318243071
https://github.com/broadinstitute/gatk/issues/3349#issuecomment-324933789:111,Availability,error,errors,111,"I've noticed that HDFUtils.writeIntervals seems a bit more memory intensive than it should be. I'm getting OOM errors for bin sizes of 250bp with -Xmx12G, which seems like it should be more than enough. Let's remember to investigate before merging.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3349#issuecomment-324933789
https://github.com/broadinstitute/gatk/pull/3350#issuecomment-317537842:77,Integrability,message,message,77,"@jamesemery You should include a `Resolves #issuenumber` line in your commit message, so that the linked issue will be auto-closed on merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3350#issuecomment-317537842
https://github.com/broadinstitute/gatk/pull/3352#issuecomment-317572507:1830,Testability,test,test,1830,e/gatk/pull/3352?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `53.947% <0%> (-20.395%)` | `29% <0%> (-7%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGV,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3352#issuecomment-317572507
https://github.com/broadinstitute/gatk/pull/3352#issuecomment-317572507:3280,Testability,test,test,3280,=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `53.947% <0%> (-20.395%)` | `29% <0%> (-7%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `70.37% <0%> (-11.111%)` | `10% <0%> ()` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `78.519% <0%> (-5.185%)` | `31% <0%> (-5%)` | |; | ... and [5 more](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3352#issuecomment-317572507
https://github.com/broadinstitute/gatk/pull/3352#issuecomment-317572507:3575,Testability,test,test,3575,=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `53.947% <0%> (-20.395%)` | `29% <0%> (-7%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `70.37% <0%> (-11.111%)` | `10% <0%> ()` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `78.519% <0%> (-5.185%)` | `31% <0%> (-5%)` | |; | ... and [5 more](https://codecov.io/gh/broadinstitute/gatk/pull/3352?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3352#issuecomment-317572507
https://github.com/broadinstitute/gatk/pull/3352#issuecomment-319185047:67,Integrability,depend,dependency,67,Closing this because it turns out it requires adding an additional dependency on devtools which adds more complication. It lets us specify versions of our existing dependencies but we end up with an unversioned dependency on devtools instead. Doesn't really seem worth it since devtools is a fairly heavy thing with lots of it's own dependencies.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3352#issuecomment-319185047
https://github.com/broadinstitute/gatk/pull/3352#issuecomment-319185047:164,Integrability,depend,dependencies,164,Closing this because it turns out it requires adding an additional dependency on devtools which adds more complication. It lets us specify versions of our existing dependencies but we end up with an unversioned dependency on devtools instead. Doesn't really seem worth it since devtools is a fairly heavy thing with lots of it's own dependencies.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3352#issuecomment-319185047
https://github.com/broadinstitute/gatk/pull/3352#issuecomment-319185047:211,Integrability,depend,dependency,211,Closing this because it turns out it requires adding an additional dependency on devtools which adds more complication. It lets us specify versions of our existing dependencies but we end up with an unversioned dependency on devtools instead. Doesn't really seem worth it since devtools is a fairly heavy thing with lots of it's own dependencies.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3352#issuecomment-319185047
https://github.com/broadinstitute/gatk/pull/3352#issuecomment-319185047:333,Integrability,depend,dependencies,333,Closing this because it turns out it requires adding an additional dependency on devtools which adds more complication. It lets us specify versions of our existing dependencies but we end up with an unversioned dependency on devtools instead. Doesn't really seem worth it since devtools is a fairly heavy thing with lots of it's own dependencies.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3352#issuecomment-319185047
https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310:1867,Energy Efficiency,Adapt,AdapterTrimTransformer,1867,ree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...bender/tools/spark/pathseq/PathSeqFilterSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFGaWx0ZXJTcGFyay5qYXZh) | `70.968% <> ()` | `7 <0> ()` | :arrow_down: |; | [...itute/hellbender/tools/spark/pathseq/PSFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyLmphdmE=) | `92.617% <100%> (+0.531%)` | `33 <1> (+1)` | :arrow_up: |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `80% <100%> (+1.429%)` | `2 <0> ()` | :arrow_down: |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <92.857%> ()` | `12 <12> (?)` | |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <94.286%> ()` | `11 <11> (?)` | |; | [...nstitute/hellbender/utils/clipping/ClippingOp.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jbGlwcGluZy9DbGlwcGluZ09wLmphdmE=) | `84.365% <0%> (+1.629%)` | `91% <0%> (+2%)` | :arrow_up: |; | [...stitute/hellbender/utils/clipping/ReadClipper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310
https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310:1867,Integrability,Adapter,AdapterTrimTransformer,1867,ree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...bender/tools/spark/pathseq/PathSeqFilterSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFGaWx0ZXJTcGFyay5qYXZh) | `70.968% <> ()` | `7 <0> ()` | :arrow_down: |; | [...itute/hellbender/tools/spark/pathseq/PSFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyLmphdmE=) | `92.617% <100%> (+0.531%)` | `33 <1> (+1)` | :arrow_up: |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `80% <100%> (+1.429%)` | `2 <0> ()` | :arrow_down: |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <92.857%> ()` | `12 <12> (?)` | |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <94.286%> ()` | `11 <11> (?)` | |; | [...nstitute/hellbender/utils/clipping/ClippingOp.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jbGlwcGluZy9DbGlwcGluZ09wLmphdmE=) | `84.365% <0%> (+1.629%)` | `91% <0%> (+2%)` | :arrow_up: |; | [...stitute/hellbender/utils/clipping/ReadClipper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310
https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310:1867,Modifiability,Adapt,AdapterTrimTransformer,1867,ree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...bender/tools/spark/pathseq/PathSeqFilterSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFGaWx0ZXJTcGFyay5qYXZh) | `70.968% <> ()` | `7 <0> ()` | :arrow_down: |; | [...itute/hellbender/tools/spark/pathseq/PSFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyLmphdmE=) | `92.617% <100%> (+0.531%)` | `33 <1> (+1)` | :arrow_up: |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `80% <100%> (+1.429%)` | `2 <0> ()` | :arrow_down: |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <92.857%> ()` | `12 <12> (?)` | |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <94.286%> ()` | `11 <11> (?)` | |; | [...nstitute/hellbender/utils/clipping/ClippingOp.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jbGlwcGluZy9DbGlwcGluZ09wLmphdmE=) | `84.365% <0%> (+1.629%)` | `91% <0%> (+2%)` | :arrow_up: |; | [...stitute/hellbender/utils/clipping/ReadClipper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310
https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310:2153,Usability,Simpl,SimpleRepeatMaskTransformer,2153,tute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFGaWx0ZXJTcGFyay5qYXZh) | `70.968% <> ()` | `7 <0> ()` | :arrow_down: |; | [...itute/hellbender/tools/spark/pathseq/PSFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyLmphdmE=) | `92.617% <100%> (+0.531%)` | `33 <1> (+1)` | :arrow_up: |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `80% <100%> (+1.429%)` | `2 <0> ()` | :arrow_down: |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <92.857%> ()` | `12 <12> (?)` | |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <94.286%> ()` | `11 <11> (?)` | |; | [...nstitute/hellbender/utils/clipping/ClippingOp.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jbGlwcGluZy9DbGlwcGluZ09wLmphdmE=) | `84.365% <0%> (+1.629%)` | `91% <0%> (+2%)` | :arrow_up: |; | [...stitute/hellbender/utils/clipping/ReadClipper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3354?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jbGlwcGluZy9SZWFkQ2xpcHBlci5qYXZh) | `71.038% <0%> (+1.639%)` | `75% <0%> (+2%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3354#issuecomment-317586310
https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317808987:149,Security,Hash,HashSet,149,"SparkGenomeReadCounts has some code to get rid of some of the non-autosomal chromosomes:. private static final Set<String> NONAUTOSOMALCONTIGS = new HashSet<>(Arrays.asList(""X"", ""Y"", ""MT"", ""M"", ""x"", ""y"",; ""m"", ""chrX"", ""chrY"", ""chrMT"", ""chrM"", ""chrm""));. protected static final String DROP_NON_AUTOSOMES_SHORT_NAME = ""keepxy"";; protected static final String DROP_NON_AUTOSOMES_LONG_NAME = ""keepXYMT"";. @Argument(doc = ""Keep X, Y, GL*, NC_*, and MT regions. If this option is not specified, these regions will be dropped, regardless of intervals specified. Use -L (or -XL) and enable this option for exact specification of intervals. This option may be removed in the future."",; fullName = DROP_NON_AUTOSOMES_LONG_NAME,; shortName = DROP_NON_AUTOSOMES_SHORT_NAME,; optional = true; ); protected boolean keepNonAutosomes = false;. This is a bit hacky, but we could expand the list to account for GRCh38 non-autosomes. (Also note that the choice of the short name for the parameter is not great...we should fix that.) @asmirnov239 the final version of your new tool should be able to handle this sort of thing more elegantly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317808987
https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317817540:32,Availability,error,error,32,"Looking at the stack trace, the error takes place in a low-level BAM input reading component in a dependency library.... It seems that is trying to read as a number portions of the contig name for a read record in the input... which makes very little sense.... . My guess is that either it is a bug entirely contained in that library (is the name seqdoop?), say it does not tolerate those contig names, or that the user managed to input a bam file that isn't formatted correctly on those records.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317817540
https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317817540:374,Availability,toler,tolerate,374,"Looking at the stack trace, the error takes place in a low-level BAM input reading component in a dependency library.... It seems that is trying to read as a number portions of the contig name for a read record in the input... which makes very little sense.... . My guess is that either it is a bug entirely contained in that library (is the name seqdoop?), say it does not tolerate those contig names, or that the user managed to input a bam file that isn't formatted correctly on those records.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317817540
https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317817540:98,Integrability,depend,dependency,98,"Looking at the stack trace, the error takes place in a low-level BAM input reading component in a dependency library.... It seems that is trying to read as a number portions of the contig name for a read record in the input... which makes very little sense.... . My guess is that either it is a bug entirely contained in that library (is the name seqdoop?), say it does not tolerate those contig names, or that the user managed to input a bam file that isn't formatted correctly on those records.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317817540
https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317819766:686,Availability,error,error,686,"@samuelklee, that is very hackish indeed, and very reference version/species dependent. Tools should not discard hard-wired contig names or intervals like that but rather the user must provide the appropriate -L or -XL list. A half-way possibility here is to provide a default set of excluded chromosomes depending on what reference is being used which must be verified on run-time as supposed to make the assumption is the one/ones the developer cared about at the time of writing the code. . Lack of a reference version/species match, lack of explicity -L or -XL lists and lack of non-autosome exclusing flag in the argument list should result in a warning message or perhaps even an error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317819766
https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317819766:77,Integrability,depend,dependent,77,"@samuelklee, that is very hackish indeed, and very reference version/species dependent. Tools should not discard hard-wired contig names or intervals like that but rather the user must provide the appropriate -L or -XL list. A half-way possibility here is to provide a default set of excluded chromosomes depending on what reference is being used which must be verified on run-time as supposed to make the assumption is the one/ones the developer cared about at the time of writing the code. . Lack of a reference version/species match, lack of explicity -L or -XL lists and lack of non-autosome exclusing flag in the argument list should result in a warning message or perhaps even an error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317819766
https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317819766:305,Integrability,depend,depending,305,"@samuelklee, that is very hackish indeed, and very reference version/species dependent. Tools should not discard hard-wired contig names or intervals like that but rather the user must provide the appropriate -L or -XL list. A half-way possibility here is to provide a default set of excluded chromosomes depending on what reference is being used which must be verified on run-time as supposed to make the assumption is the one/ones the developer cared about at the time of writing the code. . Lack of a reference version/species match, lack of explicity -L or -XL lists and lack of non-autosome exclusing flag in the argument list should result in a warning message or perhaps even an error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317819766
https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317819766:659,Integrability,message,message,659,"@samuelklee, that is very hackish indeed, and very reference version/species dependent. Tools should not discard hard-wired contig names or intervals like that but rather the user must provide the appropriate -L or -XL list. A half-way possibility here is to provide a default set of excluded chromosomes depending on what reference is being used which must be verified on run-time as supposed to make the assumption is the one/ones the developer cared about at the time of writing the code. . Lack of a reference version/species match, lack of explicity -L or -XL lists and lack of non-autosome exclusing flag in the argument list should result in a warning message or perhaps even an error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317819766
https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317820781:70,Integrability,message,messages,70,"In contrast, I think excluded chromosomes should be announced in INFO messages (perhaps WARN messages).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317820781
https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317820781:93,Integrability,message,messages,93,"In contrast, I think excluded chromosomes should be announced in INFO messages (perhaps WARN messages).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317820781
https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317823673:85,Deployability,patch,patched,85,"Ah, yes, the garbage contig names strike again! It looks like hadoop-bam hasn't been patched to know about the horrors of hg38 contig names. #3360",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3357#issuecomment-317823673
https://github.com/broadinstitute/gatk/pull/3358#issuecomment-317862466:151,Testability,test,tests,151,@vdauwera It shouldn't. It looks like production uses a different docker build script. Only the mutect2 and cnv wdls should have been affected and the tests for each of those tools still worked.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3358#issuecomment-317862466
https://github.com/broadinstitute/gatk/issues/3360#issuecomment-317978761:165,Availability,error,error,165,@lbergelson is there a spec for the names somewhere? I'm wondering if there is some kind of escape sequence that is used. Can you also upload a file that causes the error?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-317978761
https://github.com/broadinstitute/gatk/issues/3360#issuecomment-318062922:749,Availability,down,down,749,"@tomwhite Sorry! I wasn't thinking, we keep hitting this issue in different places and I was assuming you had seen it before. The issue is that there was no spec for contig names, and when they made hg38 they allowed contig names like `HLA:1-3:52-*:6+` which are terrible because they are ambiguous with the format for specifying intervals. Everyone in the world who wrote software that parses contig names and intervals was using the implicit assumption that `:` and `-` didn't appear in the contig names and write intervals as `contig:start-stop`. So we had to modify all the code that parses intervals to first try to understand it as a complete contig name and if that matches a contig in the sequence dictionary stop parsing it. . I will track down a file that triggers the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-318062922
https://github.com/broadinstitute/gatk/issues/3360#issuecomment-322730591:153,Testability,test,tests,153,"@SHuang-Broad thanks for the regex. Where have you been using the regex? I couldn't find it in htsjdk or GATK, and in fact neither of these seem to have tests for hg38-style contig/chromosome names. Ideally htsjdk would have code for this so that both Hadoop-BAM and GATK could call it directly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-322730591
https://github.com/broadinstitute/gatk/issues/3360#issuecomment-322907595:20,Testability,test,tested,20,"@tomwhite I haven't tested them because I am using them for looking at some structural variant VCF files generated from BAM files aligned to GRCh38. The regex is from eyeballing those 3000 lines of headers :tired_face:. If you would like such tests, I can provide one quickly, just tell me the preferred format, and preferably where to in htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-322907595
https://github.com/broadinstitute/gatk/issues/3360#issuecomment-322907595:243,Testability,test,tests,243,"@tomwhite I haven't tested them because I am using them for looking at some structural variant VCF files generated from BAM files aligned to GRCh38. The regex is from eyeballing those 3000 lines of headers :tired_face:. If you would like such tests, I can provide one quickly, just tell me the preferred format, and preferably where to in htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-322907595
https://github.com/broadinstitute/gatk/issues/3360#issuecomment-323534663:166,Deployability,update,updated,166,"@tomwhite , since this is becoming used by others, I went back and checked the regex, turns out that it is no catching all the contigs in the headers, so here is the updated one:; ```; (chr([0-9]{1,2}|X|Y|M|Un|EBV)(_[A-Z]+[0-9]{6,8}v[0-9](_random|_alt|_decoy)?)?|HLA-[A-Z]{1,3}([0-9])?\*[0-9]{2,2}:[0-9]{2,3}(N|Q|(:[0-9]{2,2}){0,}(N|L|S|Q)?)); ```; There are 3366 different contigs in the bam/vcf files I ""tested"" this with, and this catches all of them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-323534663
https://github.com/broadinstitute/gatk/issues/3360#issuecomment-323534663:406,Testability,test,tested,406,"@tomwhite , since this is becoming used by others, I went back and checked the regex, turns out that it is no catching all the contigs in the headers, so here is the updated one:; ```; (chr([0-9]{1,2}|X|Y|M|Un|EBV)(_[A-Z]+[0-9]{6,8}v[0-9](_random|_alt|_decoy)?)?|HLA-[A-Z]{1,3}([0-9])?\*[0-9]{2,2}:[0-9]{2,3}(N|Q|(:[0-9]{2,2}){0,}(N|L|S|Q)?)); ```; There are 3366 different contigs in the bam/vcf files I ""tested"" this with, and this catches all of them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-323534663
https://github.com/broadinstitute/gatk/issues/3360#issuecomment-324732655:88,Availability,ping,ping,88,"If anyone wants to learn more about the horrors of HLA (and MHC more generally) naming, ping me elsewhere, probably best at https://github.com/nmdp-bioinformatics/genotype-list.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-324732655
https://github.com/broadinstitute/gatk/issues/3360#issuecomment-324732655:19,Usability,learn,learn,19,"If anyone wants to learn more about the horrors of HLA (and MHC more generally) naming, ping me elsewhere, probably best at https://github.com/nmdp-bioinformatics/genotype-list.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-324732655
https://github.com/broadinstitute/gatk/issues/3360#issuecomment-331202249:362,Integrability,depend,dependants,362,"Looking at the existing code in Hadoop_BAM it makes the assumption that coordinates are always of the form ```chr:start-stop``` never things like ```chr```, ```chr:pos```, ```char:star+```... I've just generalized a bit more so that it can handle ':' and '-' inside the ```chr``` in a PR. I guess is not ideal but In any case this addresses the current fire and dependants have a clear work around which is to provide their intervals in the expected ```chr:start-stop``` format.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-331202249
https://github.com/broadinstitute/gatk/issues/3360#issuecomment-331202249:380,Usability,clear,clear,380,"Looking at the existing code in Hadoop_BAM it makes the assumption that coordinates are always of the form ```chr:start-stop``` never things like ```chr```, ```chr:pos```, ```char:star+```... I've just generalized a bit more so that it can handle ':' and '-' inside the ```chr``` in a PR. I guess is not ideal but In any case this addresses the current fire and dependants have a clear work around which is to provide their intervals in the expected ```chr:start-stop``` format.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3360#issuecomment-331202249
https://github.com/broadinstitute/gatk/issues/3367#issuecomment-324935273:264,Availability,error,errors,264,"@mbabadi I know for the hg38 runs you are using CalculateTargetCoverage, but in case you used SparkGenomeReadCounts for any other WGS runs you're looking at, here's another thing to be aware of when considering the duplicates issue. I'm also running into frequent errors when running SparkGenomeReadCounts for the WGS CNV validation that seem to be related to hadoop bam or binning errors. Let's move to @asmirnov239's new tool ASAP.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3367#issuecomment-324935273
https://github.com/broadinstitute/gatk/issues/3367#issuecomment-324935273:382,Availability,error,errors,382,"@mbabadi I know for the hg38 runs you are using CalculateTargetCoverage, but in case you used SparkGenomeReadCounts for any other WGS runs you're looking at, here's another thing to be aware of when considering the duplicates issue. I'm also running into frequent errors when running SparkGenomeReadCounts for the WGS CNV validation that seem to be related to hadoop bam or binning errors. Let's move to @asmirnov239's new tool ASAP.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3367#issuecomment-324935273
https://github.com/broadinstitute/gatk/issues/3367#issuecomment-324935273:322,Security,validat,validation,322,"@mbabadi I know for the hg38 runs you are using CalculateTargetCoverage, but in case you used SparkGenomeReadCounts for any other WGS runs you're looking at, here's another thing to be aware of when considering the duplicates issue. I'm also running into frequent errors when running SparkGenomeReadCounts for the WGS CNV validation that seem to be related to hadoop bam or binning errors. Let's move to @asmirnov239's new tool ASAP.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3367#issuecomment-324935273
https://github.com/broadinstitute/gatk/issues/3368#issuecomment-482307485:16,Deployability,update,updates,16,@ldgauthier any updates on a solution? We have an example for clinically reportable variant that matches #5824.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3368#issuecomment-482307485
https://github.com/broadinstitute/gatk/issues/3368#issuecomment-483654829:468,Deployability,update,updates,468,"Our long term solution is a rather large modification to the graph assembly; code: https://github.com/broadinstitute/gatk/issues/5828. That will likely take a couple months, but we fully expect a dramatic; improvement in phasing. Since we're working on that, spending time in a; quick fix is just going to make the long term fix take longer. On Thu, Apr 11, 2019, 4:46 PM Nils Homer <notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> any updates on a solution? We; > have an example for clinically reportable variant that matches #5824; > <https://github.com/broadinstitute/gatk/issues/5824>.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3368#issuecomment-482307485>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdBhIYIXwi9yIHobr45Nil-8yzNgTks5vf58ygaJpZM4Olg1H>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3368#issuecomment-483654829
https://github.com/broadinstitute/gatk/pull/3369#issuecomment-322515672:132,Deployability,release,release,132,Thanks for the review @lbergelson. I've addressed all your comments. (Note the tests will still fail until there's a new Hadoop-BAM release.),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3369#issuecomment-322515672
https://github.com/broadinstitute/gatk/pull/3369#issuecomment-322515672:79,Testability,test,tests,79,Thanks for the review @lbergelson. I've addressed all your comments. (Note the tests will still fail until there's a new Hadoop-BAM release.),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3369#issuecomment-322515672
https://github.com/broadinstitute/gatk/pull/3369#issuecomment-325704254:56,Integrability,depend,dependency,56,"@lbergelson, @droazen are you OK with adding a SNAPSHOT dependency for Hadoop-BAM so we can commit this (and also the GVCF PR)?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3369#issuecomment-325704254
https://github.com/broadinstitute/gatk/pull/3369#issuecomment-325704642:927,Security,validat,validation,927,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3369?src=pr&el=h1) Report; > Merging [#3369](https://codecov.io/gh/broadinstitute/gatk/pull/3369?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/28c3b7d48a5b3c219a1057e96b1f728ab2f06b37?src=pr&el=desc) will **increase** coverage by `0.017%`.; > The diff coverage is `75%`. ```diff; @@ Coverage Diff @@; ## master #3369 +/- ##; ==============================================; + Coverage 79.923% 79.94% +0.017% ; - Complexity 17884 17897 +13 ; ==============================================; Files 1198 1198 ; Lines 64966 64980 +14 ; Branches 10114 10120 +6 ; ==============================================; + Hits 51923 51945 +22 ; + Misses 9010 9002 -8 ; Partials 4033 4033; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3369?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...tools/spark/validation/CompareDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3369?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay92YWxpZGF0aW9uL0NvbXBhcmVEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `82.927% <50%> (-1.883%)` | `24 <0> ()` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3369?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `80.198% <76.923%> (+10.724%)` | `38 <10> (+10)` | :arrow_up: |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/3369?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `85% <85.714%> (+0.789%)` | `55 <5> (+2)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3369?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGU,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3369#issuecomment-325704642
https://github.com/broadinstitute/gatk/pull/3370#issuecomment-318746083:97,Modifiability,variab,variable,97,"Turns out a typo prevents running the ""manage_sv_pipeline"" script, saying GATK_DIR is an unbound variable. Please fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3370#issuecomment-318746083
https://github.com/broadinstitute/gatk/pull/3370#issuecomment-318751586:8,Modifiability,variab,variable,8,Unbound variable bug fixed.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3370#issuecomment-318751586
https://github.com/broadinstitute/gatk/pull/3370#issuecomment-318919090:36,Deployability,pipeline,pipeline,36,"I cannot seem to be able to run the pipeline with the following way of running it:. ```bash; ./manage_sv_pipeline.sh \; /Users/shuang/GATK \; broad-dsde-methods \; gs://broad-dsde-methods/sv/samples/G94797_CHM_MIX/WGS1/G94794.CHMI_CHMI3_WGS1.cram.bam \; gs://broad-dsde-methods/sv/reference/GRCh38/Homo_sapiens_assembly38.fasta \; gs://broad-dsde-methods/shuang/tmp/gatk-jars/default_init.sh; ```. And if I run with the following way (only adding a user name). ```bash; ./manage_sv_pipeline.sh \; /Users/shuang/GATK \; broad-dsde-methods \; gs://broad-dsde-methods/sv/samples/G94797_CHM_MIX/WGS1/G94794.CHMI_CHMI3_WGS1.cram.bam \; gs://broad-dsde-methods/sv/reference/GRCh38/Homo_sapiens_assembly38.fasta \; gs://broad-dsde-methods/shuang/tmp/gatk-jars/default_init.sh \; shuang; ```; The script runs as expected. I believe line 47 is the culprit:; ```bash; SV_ARGS=${*:-${SV_ARGS:-""""}} && SV_ARGS=${SV_ARGS:+"" ${SV_ARGS}""}; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3370#issuecomment-318919090
https://github.com/broadinstitute/gatk/pull/3370#issuecomment-318925727:184,Deployability,update,update,184,"My test run has successfully finished. Awesome, @TedBrookings !. Two suggestions that you could decide when to address them:; 1. This script requires a lot of user interaction (gcloud update, whether to create a cluster, whether to copy results, whether to delete cluster), I could imagine this being inconvenient for some, so we could have some upfront arguments specifying answers to these questions when the script is launched.; 2. The bucket to which the results are copied is not overridable by caller of script. A user might want to copy the results to a specific location.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3370#issuecomment-318925727
https://github.com/broadinstitute/gatk/pull/3370#issuecomment-318925727:3,Testability,test,test,3,"My test run has successfully finished. Awesome, @TedBrookings !. Two suggestions that you could decide when to address them:; 1. This script requires a lot of user interaction (gcloud update, whether to create a cluster, whether to copy results, whether to delete cluster), I could imagine this being inconvenient for some, so we could have some upfront arguments specifying answers to these questions when the script is launched.; 2. The bucket to which the results are copied is not overridable by caller of script. A user might want to copy the results to a specific location.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3370#issuecomment-318925727
https://github.com/broadinstitute/gatk/pull/3370#issuecomment-319452179:90,Availability,error,error,90,"I addressed the crash (caused by calling shift with too large a number and set-ing strict error checks in bash). I also added the requested options. Due to the larger number of options I decided that using only positional arguments would be impractical (requiring counting the number of empty """" default arguments) so I added a unix-like option parsing scheme to manage_sv_pipeline.sh; --quiet or -q will cause the script to run without any user prompting; --save [bucket/path] or -s [bucket/path] will save results and initialization scripts within the specified bucket/path",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3370#issuecomment-319452179
https://github.com/broadinstitute/gatk/pull/3370#issuecomment-319705622:0,Testability,Test,Tested,0,Tested to be working. Thanks!; Please merge when you are ready.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3370#issuecomment-319705622
https://github.com/broadinstitute/gatk/pull/3373#issuecomment-318466514:16,Testability,test,tests,16,"Will merge once tests pass, then build a new docker image with this fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3373#issuecomment-318466514
https://github.com/broadinstitute/gatk/pull/3377#issuecomment-318705714:20,Deployability,update,update,20,@tomwhite Could you update the part of the readme that lists the test type options to include the new one? It's near the top of the test section. Aren't you on vacation?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3377#issuecomment-318705714
https://github.com/broadinstitute/gatk/pull/3377#issuecomment-318705714:65,Testability,test,test,65,@tomwhite Could you update the part of the readme that lists the test type options to include the new one? It's near the top of the test section. Aren't you on vacation?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3377#issuecomment-318705714
https://github.com/broadinstitute/gatk/pull/3377#issuecomment-318705714:132,Testability,test,test,132,@tomwhite Could you update the part of the readme that lists the test type options to include the new one? It's near the top of the test section. Aren't you on vacation?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3377#issuecomment-318705714
https://github.com/broadinstitute/gatk/pull/3383#issuecomment-318741849:59,Testability,test,tests,59,"@droazen Here's the fix, but I'm only about 99.6% sure the tests will pass, so don't merge yet.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3383#issuecomment-318741849
https://github.com/broadinstitute/gatk/pull/3386#issuecomment-319074608:58,Deployability,update,update,58,@LeeTL1220 I will merge now and open a separate ticket to update the multi sample wdl and all wdls that depend on it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3386#issuecomment-319074608
https://github.com/broadinstitute/gatk/pull/3386#issuecomment-319074608:104,Integrability,depend,depend,104,@LeeTL1220 I will merge now and open a separate ticket to update the multi sample wdl and all wdls that depend on it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3386#issuecomment-319074608
https://github.com/broadinstitute/gatk/pull/3388#issuecomment-319175054:3054,Energy Efficiency,Adapt,AdapterTrimTransformer,3054,3Zxc3IvVHJhbmNoZS5qYXZh) | `62.921% <0%> (-7.349%)` | `18% <0%> ()` | |; | [.../hellbender/tools/walkers/vqsr/TrancheManager.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVHJhbmNoZU1hbmFnZXIuamF2YQ==) | `67.347% <0%> (-2.983%)` | `18% <0%> (+3%)` | |; | [...ols/walkers/contamination/ContaminationRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vQ29udGFtaW5hdGlvblJlY29yZC5qYXZh) | `87.302% <0%> (-2.698%)` | `9% <0%> (+4%)` | |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <0%> ()` | `11% <0%> (?)` | |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <0%> ()` | `12% <0%> (?)` | |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `80% <0%> (+1.429%)` | `2% <0%> ()` | :arrow_down: |; | [...s/spark/pathseq/PSBuildReferenceTaxonomyUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTQnVpbGRSZWZlcmVuY2VUYXhvbm9teVV0aWxzLmphdmE=) | `90.541% <0%> (+1.579%)` | `80% <0%> (+41%)` | :arrow_up: |; | ... and [7 more](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3388#issuecomment-319175054
https://github.com/broadinstitute/gatk/pull/3388#issuecomment-319175054:3054,Integrability,Adapter,AdapterTrimTransformer,3054,3Zxc3IvVHJhbmNoZS5qYXZh) | `62.921% <0%> (-7.349%)` | `18% <0%> ()` | |; | [.../hellbender/tools/walkers/vqsr/TrancheManager.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVHJhbmNoZU1hbmFnZXIuamF2YQ==) | `67.347% <0%> (-2.983%)` | `18% <0%> (+3%)` | |; | [...ols/walkers/contamination/ContaminationRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vQ29udGFtaW5hdGlvblJlY29yZC5qYXZh) | `87.302% <0%> (-2.698%)` | `9% <0%> (+4%)` | |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <0%> ()` | `11% <0%> (?)` | |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <0%> ()` | `12% <0%> (?)` | |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `80% <0%> (+1.429%)` | `2% <0%> ()` | :arrow_down: |; | [...s/spark/pathseq/PSBuildReferenceTaxonomyUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTQnVpbGRSZWZlcmVuY2VUYXhvbm9teVV0aWxzLmphdmE=) | `90.541% <0%> (+1.579%)` | `80% <0%> (+41%)` | :arrow_up: |; | ... and [7 more](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3388#issuecomment-319175054
https://github.com/broadinstitute/gatk/pull/3388#issuecomment-319175054:3054,Modifiability,Adapt,AdapterTrimTransformer,3054,3Zxc3IvVHJhbmNoZS5qYXZh) | `62.921% <0%> (-7.349%)` | `18% <0%> ()` | |; | [.../hellbender/tools/walkers/vqsr/TrancheManager.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVHJhbmNoZU1hbmFnZXIuamF2YQ==) | `67.347% <0%> (-2.983%)` | `18% <0%> (+3%)` | |; | [...ols/walkers/contamination/ContaminationRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vQ29udGFtaW5hdGlvblJlY29yZC5qYXZh) | `87.302% <0%> (-2.698%)` | `9% <0%> (+4%)` | |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <0%> ()` | `11% <0%> (?)` | |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <0%> ()` | `12% <0%> (?)` | |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `80% <0%> (+1.429%)` | `2% <0%> ()` | :arrow_down: |; | [...s/spark/pathseq/PSBuildReferenceTaxonomyUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTQnVpbGRSZWZlcmVuY2VUYXhvbm9teVV0aWxzLmphdmE=) | `90.541% <0%> (+1.579%)` | `80% <0%> (+41%)` | :arrow_up: |; | ... and [7 more](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3388#issuecomment-319175054
https://github.com/broadinstitute/gatk/pull/3388#issuecomment-319175054:2754,Usability,Simpl,SimpleRepeatMaskTransformer,2754,ZlcmVuY2VUYXhvblByb3BlcnRpZXMuamF2YQ==) | `90% <0%> (-10%)` | `13% <0%> (+12%)` | |; | [...stitute/hellbender/tools/walkers/vqsr/Tranche.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVHJhbmNoZS5qYXZh) | `62.921% <0%> (-7.349%)` | `18% <0%> ()` | |; | [.../hellbender/tools/walkers/vqsr/TrancheManager.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVHJhbmNoZU1hbmFnZXIuamF2YQ==) | `67.347% <0%> (-2.983%)` | `18% <0%> (+3%)` | |; | [...ols/walkers/contamination/ContaminationRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vQ29udGFtaW5hdGlvblJlY29yZC5qYXZh) | `87.302% <0%> (-2.698%)` | `9% <0%> (+4%)` | |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <0%> ()` | `11% <0%> (?)` | |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <0%> ()` | `12% <0%> (?)` | |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `80% <0%> (+1.429%)` | `2% <0%> ()` | :arrow_down: |; | [...s/spark/pathseq/PSBuildReferenceTaxonomyUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3388?src=pr&el=tree#diff-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3388#issuecomment-319175054
https://github.com/broadinstitute/gatk/issues/3393#issuecomment-319408334:113,Testability,Benchmark,Benchmark,113,@lbergelson Main goals of this epic:. * Hook up `BWASpark` and `HaplotypeCallerSpark` to `ReadsPipelineSpark`; * Benchmark `ReadsPipelineSpark` against running the spark tools individually; * Better/more consistent GCS support (either via the gcs-connector or NIO); * Better/more visible cluster-based testing for Spark (possibly on travis); * Fix the most serious/embarrassing Spark bugs,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3393#issuecomment-319408334
https://github.com/broadinstitute/gatk/issues/3393#issuecomment-319408334:302,Testability,test,testing,302,@lbergelson Main goals of this epic:. * Hook up `BWASpark` and `HaplotypeCallerSpark` to `ReadsPipelineSpark`; * Benchmark `ReadsPipelineSpark` against running the spark tools individually; * Better/more consistent GCS support (either via the gcs-connector or NIO); * Better/more visible cluster-based testing for Spark (possibly on travis); * Fix the most serious/embarrassing Spark bugs,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3393#issuecomment-319408334
https://github.com/broadinstitute/gatk/issues/3395#issuecomment-341788281:65,Deployability,pipeline,pipeline,65,These initial results suggest that the savings from a pure-Spark pipeline are in the 15-30% range. @tomwhite Do you attribute these savings mostly to avoiding writing/reading intermediate outputs?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3395#issuecomment-341788281
https://github.com/broadinstitute/gatk/issues/3395#issuecomment-341788281:150,Safety,avoid,avoiding,150,These initial results suggest that the savings from a pure-Spark pipeline are in the 15-30% range. @tomwhite Do you attribute these savings mostly to avoiding writing/reading intermediate outputs?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3395#issuecomment-341788281
https://github.com/broadinstitute/gatk/issues/3395#issuecomment-341789732:98,Deployability,pipeline,pipeline,98,"Also, once we've confirmed these results, we'll want to compare the total core hours of the Spark pipeline against the core hours of an equivalent non-Spark pipeline, to see if the savings provided by a pure-Spark pipeline actually make it cheaper than a non-Spark pipeline.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3395#issuecomment-341789732
https://github.com/broadinstitute/gatk/issues/3395#issuecomment-341789732:157,Deployability,pipeline,pipeline,157,"Also, once we've confirmed these results, we'll want to compare the total core hours of the Spark pipeline against the core hours of an equivalent non-Spark pipeline, to see if the savings provided by a pure-Spark pipeline actually make it cheaper than a non-Spark pipeline.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3395#issuecomment-341789732
https://github.com/broadinstitute/gatk/issues/3395#issuecomment-341789732:214,Deployability,pipeline,pipeline,214,"Also, once we've confirmed these results, we'll want to compare the total core hours of the Spark pipeline against the core hours of an equivalent non-Spark pipeline, to see if the savings provided by a pure-Spark pipeline actually make it cheaper than a non-Spark pipeline.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3395#issuecomment-341789732
https://github.com/broadinstitute/gatk/issues/3395#issuecomment-341789732:265,Deployability,pipeline,pipeline,265,"Also, once we've confirmed these results, we'll want to compare the total core hours of the Spark pipeline against the core hours of an equivalent non-Spark pipeline, to see if the savings provided by a pure-Spark pipeline actually make it cheaper than a non-Spark pipeline.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3395#issuecomment-341789732
https://github.com/broadinstitute/gatk/issues/3396#issuecomment-319721849:173,Testability,test,tests,173,Because there is currently no way in travis to prevent the build stages from being triggered in every pull request it was decided to simply upload the nightly build without tests instead. An example of how to use build stages can be seen in this branch for future reference: https://github.com/broadinstitute/gatk/tree/je_travisBuildStages,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3396#issuecomment-319721849
https://github.com/broadinstitute/gatk/issues/3396#issuecomment-319721849:133,Usability,simpl,simply,133,Because there is currently no way in travis to prevent the build stages from being triggered in every pull request it was decided to simply upload the nightly build without tests instead. An example of how to use build stages can be seen in this branch for future reference: https://github.com/broadinstitute/gatk/tree/je_travisBuildStages,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3396#issuecomment-319721849
https://github.com/broadinstitute/gatk/pull/3398#issuecomment-319512377:3668,Energy Efficiency,Adapt,AdapterTrimTransformer,3668,93YWxrZXJzL3Zxc3IvVHJhbmNoZU1hbmFnZXIuamF2YQ==) | `67.347% <0%> (-2.983%)` | `18% <0%> (+3%)` | |; | [...hellbender/utils/haplotype/HaplotypeBAMWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oYXBsb3R5cGUvSGFwbG90eXBlQkFNV3JpdGVyLmphdmE=) | `97.531% <0%> (-0.546%)` | `15% <0%> (+5%)` | |; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `68.595% <0%> (-0.092%)` | `29% <0%> (+5%)` | |; | [...r/transformers/BaseQualityClipReadTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQmFzZVF1YWxpdHlDbGlwUmVhZFRyYW5zZm9ybWVyLmphdmE=) | `100% <0%> ()` | `19% <0%> (+5%)` | :arrow_up: |; | [...hellbender/utils/haplotype/SAMFileDestination.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oYXBsb3R5cGUvU0FNRmlsZURlc3RpbmF0aW9uLmphdmE=) | `100% <0%> ()` | `6% <0%> (+3%)` | :arrow_up: |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <0%> ()` | `11% <0%> (?)` | |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <0%> ()` | `12% <0%> (?)` | |; | ... and [14 more](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3398#issuecomment-319512377
https://github.com/broadinstitute/gatk/pull/3398#issuecomment-319512377:3668,Integrability,Adapter,AdapterTrimTransformer,3668,93YWxrZXJzL3Zxc3IvVHJhbmNoZU1hbmFnZXIuamF2YQ==) | `67.347% <0%> (-2.983%)` | `18% <0%> (+3%)` | |; | [...hellbender/utils/haplotype/HaplotypeBAMWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oYXBsb3R5cGUvSGFwbG90eXBlQkFNV3JpdGVyLmphdmE=) | `97.531% <0%> (-0.546%)` | `15% <0%> (+5%)` | |; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `68.595% <0%> (-0.092%)` | `29% <0%> (+5%)` | |; | [...r/transformers/BaseQualityClipReadTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQmFzZVF1YWxpdHlDbGlwUmVhZFRyYW5zZm9ybWVyLmphdmE=) | `100% <0%> ()` | `19% <0%> (+5%)` | :arrow_up: |; | [...hellbender/utils/haplotype/SAMFileDestination.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oYXBsb3R5cGUvU0FNRmlsZURlc3RpbmF0aW9uLmphdmE=) | `100% <0%> ()` | `6% <0%> (+3%)` | :arrow_up: |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <0%> ()` | `11% <0%> (?)` | |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <0%> ()` | `12% <0%> (?)` | |; | ... and [14 more](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3398#issuecomment-319512377
https://github.com/broadinstitute/gatk/pull/3398#issuecomment-319512377:3668,Modifiability,Adapt,AdapterTrimTransformer,3668,93YWxrZXJzL3Zxc3IvVHJhbmNoZU1hbmFnZXIuamF2YQ==) | `67.347% <0%> (-2.983%)` | `18% <0%> (+3%)` | |; | [...hellbender/utils/haplotype/HaplotypeBAMWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oYXBsb3R5cGUvSGFwbG90eXBlQkFNV3JpdGVyLmphdmE=) | `97.531% <0%> (-0.546%)` | `15% <0%> (+5%)` | |; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `68.595% <0%> (-0.092%)` | `29% <0%> (+5%)` | |; | [...r/transformers/BaseQualityClipReadTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQmFzZVF1YWxpdHlDbGlwUmVhZFRyYW5zZm9ybWVyLmphdmE=) | `100% <0%> ()` | `19% <0%> (+5%)` | :arrow_up: |; | [...hellbender/utils/haplotype/SAMFileDestination.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oYXBsb3R5cGUvU0FNRmlsZURlc3RpbmF0aW9uLmphdmE=) | `100% <0%> ()` | `6% <0%> (+3%)` | :arrow_up: |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <0%> ()` | `11% <0%> (?)` | |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <0%> ()` | `12% <0%> (?)` | |; | ... and [14 more](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3398#issuecomment-319512377
https://github.com/broadinstitute/gatk/pull/3398#issuecomment-319512377:3368,Usability,Simpl,SimpleRepeatMaskTransformer,3368,93YWxrZXJzL3Zxc3IvVHJhbmNoZU1hbmFnZXIuamF2YQ==) | `67.347% <0%> (-2.983%)` | `18% <0%> (+3%)` | |; | [...hellbender/utils/haplotype/HaplotypeBAMWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oYXBsb3R5cGUvSGFwbG90eXBlQkFNV3JpdGVyLmphdmE=) | `97.531% <0%> (-0.546%)` | `15% <0%> (+5%)` | |; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `68.595% <0%> (-0.092%)` | `29% <0%> (+5%)` | |; | [...r/transformers/BaseQualityClipReadTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQmFzZVF1YWxpdHlDbGlwUmVhZFRyYW5zZm9ybWVyLmphdmE=) | `100% <0%> ()` | `19% <0%> (+5%)` | :arrow_up: |; | [...hellbender/utils/haplotype/SAMFileDestination.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oYXBsb3R5cGUvU0FNRmlsZURlc3RpbmF0aW9uLmphdmE=) | `100% <0%> ()` | `6% <0%> (+3%)` | :arrow_up: |; | [...nder/transformers/SimpleRepeatMaskTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvU2ltcGxlUmVwZWF0TWFza1RyYW5zZm9ybWVyLmphdmE=) | `94.286% <0%> ()` | `11% <0%> (?)` | |; | [...ellbender/transformers/AdapterTrimTransformer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90cmFuc2Zvcm1lcnMvQWRhcHRlclRyaW1UcmFuc2Zvcm1lci5qYXZh) | `92.857% <0%> ()` | `12% <0%> (?)` | |; | ... and [14 more](https://codecov.io/gh/broadinstitute/gatk/pull/3398?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3398#issuecomment-319512377
https://github.com/broadinstitute/gatk/pull/3398#issuecomment-320052914:9,Testability,Test,Test,9,@droazen Test enabled.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3398#issuecomment-320052914
https://github.com/broadinstitute/gatk/pull/3399#issuecomment-319685863:129,Deployability,release,releases,129,"@droazen Should we stick this as a versioned document into git instead of using the wiki? Also, should we recommend signing tags releases?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3399#issuecomment-319685863
https://github.com/broadinstitute/gatk/pull/3400#issuecomment-319705302:34,Testability,test,test,34,@lbergelson Is there a way we can test this fix?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3400#issuecomment-319705302
https://github.com/broadinstitute/gatk/pull/3400#issuecomment-319778125:362,Deployability,configurat,configuration,362,"@david-wb @popboy126 I'm having trouble reproducing the shutdown issue on our own cluster, I sometimes get the message `Shutdown hook called before final status was reported.` but the job status is SUCCEEDED. This happens if I run with the System.exit(0) or not. Could one of you test with this branch and let me know if it solves your issue? I think my cluster configuration must be different then yours in some way.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3400#issuecomment-319778125
https://github.com/broadinstitute/gatk/pull/3400#issuecomment-319778125:111,Integrability,message,message,111,"@david-wb @popboy126 I'm having trouble reproducing the shutdown issue on our own cluster, I sometimes get the message `Shutdown hook called before final status was reported.` but the job status is SUCCEEDED. This happens if I run with the System.exit(0) or not. Could one of you test with this branch and let me know if it solves your issue? I think my cluster configuration must be different then yours in some way.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3400#issuecomment-319778125
https://github.com/broadinstitute/gatk/pull/3400#issuecomment-319778125:362,Modifiability,config,configuration,362,"@david-wb @popboy126 I'm having trouble reproducing the shutdown issue on our own cluster, I sometimes get the message `Shutdown hook called before final status was reported.` but the job status is SUCCEEDED. This happens if I run with the System.exit(0) or not. Could one of you test with this branch and let me know if it solves your issue? I think my cluster configuration must be different then yours in some way.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3400#issuecomment-319778125
https://github.com/broadinstitute/gatk/pull/3400#issuecomment-319778125:280,Testability,test,test,280,"@david-wb @popboy126 I'm having trouble reproducing the shutdown issue on our own cluster, I sometimes get the message `Shutdown hook called before final status was reported.` but the job status is SUCCEEDED. This happens if I run with the System.exit(0) or not. Could one of you test with this branch and let me know if it solves your issue? I think my cluster configuration must be different then yours in some way.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3400#issuecomment-319778125
https://github.com/broadinstitute/gatk/pull/3403#issuecomment-322255289:91,Deployability,upgrade,upgrade,91,"@lbergelson Not sure if you're finished reviewing this one or not. This one has the htsjdk upgrade needed to re-enable IndexFeatureFile, so this one needs to go in first.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3403#issuecomment-322255289
https://github.com/broadinstitute/gatk/issues/3407#issuecomment-580901710:94,Deployability,integrat,integration,94,Let's be honest -- this is never going to happen. The goal is to move towards non-exact-match integration tests anyway.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3407#issuecomment-580901710
https://github.com/broadinstitute/gatk/issues/3407#issuecomment-580901710:94,Integrability,integrat,integration,94,Let's be honest -- this is never going to happen. The goal is to move towards non-exact-match integration tests anyway.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3407#issuecomment-580901710
https://github.com/broadinstitute/gatk/issues/3407#issuecomment-580901710:106,Testability,test,tests,106,Let's be honest -- this is never going to happen. The goal is to move towards non-exact-match integration tests anyway.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3407#issuecomment-580901710
https://github.com/broadinstitute/gatk/pull/3408#issuecomment-320987933:49,Testability,test,tested,49,Adding runtime blocks and having the CNV WDL get tested in a local+docker backend.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3408#issuecomment-320987933
https://github.com/broadinstitute/gatk/pull/3408#issuecomment-322549071:140,Testability,test,tests,140,"@samuelklee I did not do everything, but if you want me to, I can. Otherwise, I'll squash and merge (assuming I did not inadvertently break tests)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3408#issuecomment-322549071
https://github.com/broadinstitute/gatk/pull/3408#issuecomment-322550439:35,Integrability,message,message,35,@samuelklee I've reworded the hack message,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3408#issuecomment-322550439
https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320262613:56,Usability,guid,guidance,56,Maybe @lbergelson would be willing to review or provide guidance for a new engine team member?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320262613
https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320273200:2874,Deployability,Integrat,IntegrationTestSpec,2874,p: |; | [...er/tools/picard/analysis/CollectGcBiasMetrics.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9waWNhcmQvYW5hbHlzaXMvQ29sbGVjdEdjQmlhc01ldHJpY3MuamF2YQ==) | `0.794% <0%> (+0.794%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...utils/test/ReadsPreprocessingPipelineTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1JlYWRzUHJlcHJvY2Vzc2luZ1BpcGVsaW5lVGVzdERhdGEuamF2YQ==) | `0.847% <0%> (+0.847%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...spark/sv/evidence/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `67.347% <0%> (+1.02%)` | `34% <0%> (+1%)` | :arrow_up: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `73.118% <0%> (+1.075%)` | `25% <0%> ()` | :arrow_down: |; | [...e/conversion/allelicbalancecaller/CNLOHCaller.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9jb252ZXJzaW9uL2FsbGVsaWNiYWxhbmNlY2FsbGVyL0NOTE9IQ2FsbGVyLmphdmE=) | `96.283% <0%> (+1.115%)` | `95% <0%> (+3%)` | :arrow_up: |; | [...kers/haplotypecaller/ReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWwuamF2YQ==) | `92.737% <0%> (+1.117%)` | `61% <0%> (+2%)` | :arrow_up: |; | [...itute/hellbender/tools/picard/vcf/LiftOverVcf.java](h,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320273200
https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320273200:2874,Integrability,Integrat,IntegrationTestSpec,2874,p: |; | [...er/tools/picard/analysis/CollectGcBiasMetrics.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9waWNhcmQvYW5hbHlzaXMvQ29sbGVjdEdjQmlhc01ldHJpY3MuamF2YQ==) | `0.794% <0%> (+0.794%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...utils/test/ReadsPreprocessingPipelineTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1JlYWRzUHJlcHJvY2Vzc2luZ1BpcGVsaW5lVGVzdERhdGEuamF2YQ==) | `0.847% <0%> (+0.847%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...spark/sv/evidence/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `67.347% <0%> (+1.02%)` | `34% <0%> (+1%)` | :arrow_up: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `73.118% <0%> (+1.075%)` | `25% <0%> ()` | :arrow_down: |; | [...e/conversion/allelicbalancecaller/CNLOHCaller.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9jb252ZXJzaW9uL2FsbGVsaWNiYWxhbmNlY2FsbGVyL0NOTE9IQ2FsbGVyLmphdmE=) | `96.283% <0%> (+1.115%)` | `95% <0%> (+3%)` | :arrow_up: |; | [...kers/haplotypecaller/ReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWwuamF2YQ==) | `92.737% <0%> (+1.117%)` | `61% <0%> (+2%)` | :arrow_up: |; | [...itute/hellbender/tools/picard/vcf/LiftOverVcf.java](h,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320273200
https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320273200:2205,Testability,test,test,2205, `43 <0> (+8)` | :arrow_up: |; | [...itute/hellbender/tools/spark/pathseq/PSScorer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTU2NvcmVyLmphdmE=) | `89.595% <0%> (+0.578%)` | `54% <0%> (+1%)` | :arrow_up: |; | [.../exome/pulldown/BayesianHetPulldownCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9wdWxsZG93bi9CYXllc2lhbkhldFB1bGxkb3duQ2FsY3VsYXRvci5qYXZh) | `86.624% <0%> (+0.637%)` | `35% <0%> (+1%)` | :arrow_up: |; | [...er/tools/picard/analysis/CollectGcBiasMetrics.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9waWNhcmQvYW5hbHlzaXMvQ29sbGVjdEdjQmlhc01ldHJpY3MuamF2YQ==) | `0.794% <0%> (+0.794%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...utils/test/ReadsPreprocessingPipelineTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1JlYWRzUHJlcHJvY2Vzc2luZ1BpcGVsaW5lVGVzdERhdGEuamF2YQ==) | `0.847% <0%> (+0.847%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...spark/sv/evidence/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `67.347% <0%> (+1.02%)` | `34% <0%> (+1%)` | :arrow_up: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `73.118% <0%> (+1.075%)` | `25% <0%> ()` | :arrow_down: |; | [...e/conversion/allelicbalancecaller/CNLOHCaller.java](https://codecov.io/g,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320273200
https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320273200:2869,Testability,test,test,2869,p: |; | [...er/tools/picard/analysis/CollectGcBiasMetrics.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9waWNhcmQvYW5hbHlzaXMvQ29sbGVjdEdjQmlhc01ldHJpY3MuamF2YQ==) | `0.794% <0%> (+0.794%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...utils/test/ReadsPreprocessingPipelineTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1JlYWRzUHJlcHJvY2Vzc2luZ1BpcGVsaW5lVGVzdERhdGEuamF2YQ==) | `0.847% <0%> (+0.847%)` | `1% <0%> (+1%)` | :arrow_up: |; | [...spark/sv/evidence/FindBreakpointEvidenceSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmsuamF2YQ==) | `67.347% <0%> (+1.02%)` | `34% <0%> (+1%)` | :arrow_up: |; | [...ute/hellbender/utils/test/IntegrationTestSpec.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0ludGVncmF0aW9uVGVzdFNwZWMuamF2YQ==) | `73.118% <0%> (+1.075%)` | `25% <0%> ()` | :arrow_down: |; | [...e/conversion/allelicbalancecaller/CNLOHCaller.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9jb252ZXJzaW9uL2FsbGVsaWNiYWxhbmNlY2FsbGVyL0NOTE9IQ2FsbGVyLmphdmE=) | `96.283% <0%> (+1.115%)` | `95% <0%> (+3%)` | :arrow_up: |; | [...kers/haplotypecaller/ReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/3409?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWwuamF2YQ==) | `92.737% <0%> (+1.117%)` | `61% <0%> (+2%)` | :arrow_up: |; | [...itute/hellbender/tools/picard/vcf/LiftOverVcf.java](h,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320273200
https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124:85,Deployability,integrat,integration,85,"@ldgauthier This looks good, its a pretty simple change and there are unit tests and integration tests that enforce the new behavior. I would squash the two commits and give them an informative commit message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124
https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124:85,Integrability,integrat,integration,85,"@ldgauthier This looks good, its a pretty simple change and there are unit tests and integration tests that enforce the new behavior. I would squash the two commits and give them an informative commit message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124
https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124:201,Integrability,message,message,201,"@ldgauthier This looks good, its a pretty simple change and there are unit tests and integration tests that enforce the new behavior. I would squash the two commits and give them an informative commit message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124
https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124:75,Testability,test,tests,75,"@ldgauthier This looks good, its a pretty simple change and there are unit tests and integration tests that enforce the new behavior. I would squash the two commits and give them an informative commit message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124
https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124:97,Testability,test,tests,97,"@ldgauthier This looks good, its a pretty simple change and there are unit tests and integration tests that enforce the new behavior. I would squash the two commits and give them an informative commit message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124
https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124:42,Usability,simpl,simple,42,"@ldgauthier This looks good, its a pretty simple change and there are unit tests and integration tests that enforce the new behavior. I would squash the two commits and give them an informative commit message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3409#issuecomment-320707124
https://github.com/broadinstitute/gatk/pull/3410#issuecomment-320329698:38,Availability,failure,failures,38,@jonn-smith There are a bunch of test failures on this branch in travis -- could you fix these before we review? Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3410#issuecomment-320329698
https://github.com/broadinstitute/gatk/pull/3410#issuecomment-320329698:33,Testability,test,test,33,@jonn-smith There are a bunch of test failures on this branch in travis -- could you fix these before we review? Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3410#issuecomment-320329698
https://github.com/broadinstitute/gatk/pull/3410#issuecomment-321247532:52,Availability,down,down,52,"@magicDGS The plan is to eventually push this codec down into htsjdk for wider use by the community, but we want to develop it here first for the sake of fast iteration. Since the GATK project that depends on this branch has a looming deadline, we're unable to generalize this code further at this time, but we can revisit this when the codec is moved into htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3410#issuecomment-321247532
https://github.com/broadinstitute/gatk/pull/3410#issuecomment-321247532:198,Integrability,depend,depends,198,"@magicDGS The plan is to eventually push this codec down into htsjdk for wider use by the community, but we want to develop it here first for the sake of fast iteration. Since the GATK project that depends on this branch has a looming deadline, we're unable to generalize this code further at this time, but we can revisit this when the codec is moved into htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3410#issuecomment-321247532
https://github.com/broadinstitute/gatk/issues/3411#issuecomment-320304844:219,Security,expose,expose,219,We had already planned to remove this limitation. The limitation comes from using an older version of TileDB in GenomicsDB. The latest version of TileDB has an API called array_move() to do this correctly which we will expose in GenomicsDB.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3411#issuecomment-320304844
https://github.com/broadinstitute/gatk/issues/3411#issuecomment-320324927:261,Deployability,update,update,261,"@droazen the reason for hardcoding the full path is to handle grouping of arrays. TileDB manages arrays hierarchically. A workspace can contain arrays or groups of arrays. Groups can have different arrays with same name. When you read from an existing array or update it with a given workspace path, you need to figure out which array in the the group you are referring to, hence the full path. More information [here](http://istc-bigdata.org/tiledb/tutorials/index.html#workspaces_groups). The real issue here is to figure out a way to package TileDB arrays to ship it to some other location. The problem is the data and fragments inside the array directory is self-contained. If we replace the full path in the schema it will break other conventions for groups and workspaces. I will discuss more on this with @kgururaj and come up with a solution.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3411#issuecomment-320324927
https://github.com/broadinstitute/gatk/issues/3411#issuecomment-320325990:116,Security,hash,hash,116,@kdatta Why not use some kind of globally-unique identifier for the arrays if name collision is an issue (such as a hash or UUID)? Would that solve the problem?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3411#issuecomment-320325990
https://github.com/broadinstitute/gatk/issues/3411#issuecomment-320326745:182,Deployability,update,updates,182,"@lbergelson actually many databases do such hardcoded directory management and provide tools to migrate data to other locations. The reason is they want to maintain writeahead logs, updates and other temporary files per database or table or array. We also followed the method in TileDB. Other storage formats like HDF5 are completely self-contained and stores everything in one file. Each method comes with its set of challenges :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3411#issuecomment-320326745
https://github.com/broadinstitute/gatk/issues/3411#issuecomment-320326745:176,Testability,log,logs,176,"@lbergelson actually many databases do such hardcoded directory management and provide tools to migrate data to other locations. The reason is they want to maintain writeahead logs, updates and other temporary files per database or table or array. We also followed the method in TileDB. Other storage formats like HDF5 are completely self-contained and stores everything in one file. Each method comes with its set of challenges :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3411#issuecomment-320326745
https://github.com/broadinstitute/gatk/issues/3411#issuecomment-356024968:274,Deployability,update,update,274,@lbergelson I see that 7298392 closed this issue. Does this mean that the `genomicsdb` artifact version `0.8.1-proto-3.0.0-beta-1` in maven central supports reading of genomics db instances stored at paths arbitrarily different form their creation location?. Thanks for the update!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3411#issuecomment-356024968
https://github.com/broadinstitute/gatk/issues/3411#issuecomment-356033474:99,Testability,test,tests,99,@danking That's the idea. I may have closed this prematurely because I didn't wait for the pr with tests (#4000). You're supposed to be able to pick up the workspace directory and move it around no problem now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3411#issuecomment-356033474
https://github.com/broadinstitute/gatk/issues/3412#issuecomment-361985215:128,Deployability,pipeline,pipeline,128,@kgururaj I think so. We've been unable to reproduce it and haven't seen it again since we fixed the memory requirements in our pipeline. If it reoccurs we'll reopen.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3412#issuecomment-361985215
https://github.com/broadinstitute/gatk/issues/3412#issuecomment-446736619:16,Availability,error,error,16,"I hit this same error attempting a 156K callset. I'm rerunning with more memory and also downloading the GDB for debugging, which is 46GB. :-/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3412#issuecomment-446736619
https://github.com/broadinstitute/gatk/issues/3412#issuecomment-446736619:89,Availability,down,downloading,89,"I hit this same error attempting a 156K callset. I'm rerunning with more memory and also downloading the GDB for debugging, which is 46GB. :-/",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3412#issuecomment-446736619
https://github.com/broadinstitute/gatk/issues/3413#issuecomment-320341028:276,Testability,test,test,276,"@droazen It occurs to me that one other axis that might be worth looking at is quality score quantization. I think the BAMs I was looking at were ones that had [unrecalibrated] full range quality scores, not ones that had been quantized to ~8 or fewer values. I wonder if the test files used above were all HiSeq-X whether that could have made a difference.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-320341028
https://github.com/broadinstitute/gatk/issues/3413#issuecomment-323812606:23,Testability,test,testing,23,"@tfenne Did you do any testing with compression level 2 + the Intel Deflater? @jsotobroad 's latest results suggest that it may offer the best speed/size tradeoff, with the current version of the GKL at least.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-323812606
https://github.com/broadinstitute/gatk/issues/3413#issuecomment-323840661:496,Performance,perform,perform,496,"@droazen I didn't really look at runtime scientifically, so I can't comment on that. I pasted this table and explanation into the picard issue, but I think it had already been closed at that point, so I'm not sure how many people saw it:. > I have some _small_ test BAMs that are constructed by extracting reads overlapping a few hundred kb of genome from WGS samples. I made the table below using such a BAM made from the 1KG PCR-free WGS data from NA19625. Not ideal, but I would _think_ would perform fairly similar to a full WGS bam for compression purposes. What I see is that at compression level 1 the intel deflator produces a significantly larger BAM that the JDK deflator at level=1. . Compression Level | Intel Deflater File Size | Intel Deflater % of JDK l=5 | JDK Deflater File Size | JDK Delfater % of JDK l=5; ---|------------|----------|---------------|---------; 1 | 54,840,445 | 175.23% | 38,543,684 | 123.16%; 2 | 35,782,642 | 114.33% | 36,745,494 | 117.41%; 3 | 34,989,899 | 111.80% | 35,262,326 | 112.67%; 4 | 31,815,698 | 101.66% | 32,549,560 | 104.00%; 5 | 31,240,892 | 99.82% | 31,296,433 | 100.00%; 6 | 30,675,174 | 98.01% | 30,577,906 | 97.70%; 7 | 30,379,699 | 97.07% | 30,380,325 | 97.07%; 8 | 30,124,200 | 96.25% | 30,124,375 | 96.25%; 9 | 30,064,322 | 96.06% | 30,064,325 | 96.06%. That does seem to suggest that the intel deflator at `level=2` produces a BAM that is smaller than the JDK deflator at either level 2 or 1, and if it is also faster in your testing, that sounds pretty good for intermediate files. It's still ~15% bigger than a `level=5` BAM though, so unless the vast majority of users are switching over to CRAM for storage, I'd hesitate to change the default compression level in any of the toolkits.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-323840661
https://github.com/broadinstitute/gatk/issues/3413#issuecomment-323840661:261,Testability,test,test,261,"@droazen I didn't really look at runtime scientifically, so I can't comment on that. I pasted this table and explanation into the picard issue, but I think it had already been closed at that point, so I'm not sure how many people saw it:. > I have some _small_ test BAMs that are constructed by extracting reads overlapping a few hundred kb of genome from WGS samples. I made the table below using such a BAM made from the 1KG PCR-free WGS data from NA19625. Not ideal, but I would _think_ would perform fairly similar to a full WGS bam for compression purposes. What I see is that at compression level 1 the intel deflator produces a significantly larger BAM that the JDK deflator at level=1. . Compression Level | Intel Deflater File Size | Intel Deflater % of JDK l=5 | JDK Deflater File Size | JDK Delfater % of JDK l=5; ---|------------|----------|---------------|---------; 1 | 54,840,445 | 175.23% | 38,543,684 | 123.16%; 2 | 35,782,642 | 114.33% | 36,745,494 | 117.41%; 3 | 34,989,899 | 111.80% | 35,262,326 | 112.67%; 4 | 31,815,698 | 101.66% | 32,549,560 | 104.00%; 5 | 31,240,892 | 99.82% | 31,296,433 | 100.00%; 6 | 30,675,174 | 98.01% | 30,577,906 | 97.70%; 7 | 30,379,699 | 97.07% | 30,380,325 | 97.07%; 8 | 30,124,200 | 96.25% | 30,124,375 | 96.25%; 9 | 30,064,322 | 96.06% | 30,064,325 | 96.06%. That does seem to suggest that the intel deflator at `level=2` produces a BAM that is smaller than the JDK deflator at either level 2 or 1, and if it is also faster in your testing, that sounds pretty good for intermediate files. It's still ~15% bigger than a `level=5` BAM though, so unless the vast majority of users are switching over to CRAM for storage, I'd hesitate to change the default compression level in any of the toolkits.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-323840661
https://github.com/broadinstitute/gatk/issues/3413#issuecomment-323840661:1485,Testability,test,testing,1485,"@droazen I didn't really look at runtime scientifically, so I can't comment on that. I pasted this table and explanation into the picard issue, but I think it had already been closed at that point, so I'm not sure how many people saw it:. > I have some _small_ test BAMs that are constructed by extracting reads overlapping a few hundred kb of genome from WGS samples. I made the table below using such a BAM made from the 1KG PCR-free WGS data from NA19625. Not ideal, but I would _think_ would perform fairly similar to a full WGS bam for compression purposes. What I see is that at compression level 1 the intel deflator produces a significantly larger BAM that the JDK deflator at level=1. . Compression Level | Intel Deflater File Size | Intel Deflater % of JDK l=5 | JDK Deflater File Size | JDK Delfater % of JDK l=5; ---|------------|----------|---------------|---------; 1 | 54,840,445 | 175.23% | 38,543,684 | 123.16%; 2 | 35,782,642 | 114.33% | 36,745,494 | 117.41%; 3 | 34,989,899 | 111.80% | 35,262,326 | 112.67%; 4 | 31,815,698 | 101.66% | 32,549,560 | 104.00%; 5 | 31,240,892 | 99.82% | 31,296,433 | 100.00%; 6 | 30,675,174 | 98.01% | 30,577,906 | 97.70%; 7 | 30,379,699 | 97.07% | 30,380,325 | 97.07%; 8 | 30,124,200 | 96.25% | 30,124,375 | 96.25%; 9 | 30,064,322 | 96.06% | 30,064,325 | 96.06%. That does seem to suggest that the intel deflator at `level=2` produces a BAM that is smaller than the JDK deflator at either level 2 or 1, and if it is also faster in your testing, that sounds pretty good for intermediate files. It's still ~15% bigger than a `level=5` BAM though, so unless the vast majority of users are switching over to CRAM for storage, I'd hesitate to change the default compression level in any of the toolkits.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-323840661
https://github.com/broadinstitute/gatk/issues/3413#issuecomment-340501007:8,Deployability,update,updated,8,We have updated to a newer version of compression engine in GKL. Could you test with the latest GATK/GKL? and report if the problem still exists.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-340501007
https://github.com/broadinstitute/gatk/issues/3413#issuecomment-340501007:75,Testability,test,test,75,We have updated to a newer version of compression engine in GKL. Could you test with the latest GATK/GKL? and report if the problem still exists.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-340501007
https://github.com/broadinstitute/gatk/issues/3413#issuecomment-360179673:1109,Energy Efficiency,reduce,reduced,1109,"anies:; ![grafik](https://user-images.githubusercontent.com/1612006/35342524-94fcab50-0128-11e8-800e-840d891058ef.png). 1. How to convince people:; I agree. I think it is most effective to make people ""feel"" the difference, i.e. output like ""you have been waiting 1324s or 60% of additional processing time on this step due to compression"".; Or ""Processing still hasn't started due to compression/decompression."". GATK4, especially on Spark hides that pretty well.; For example, turning off Spark lz4 and relying on ZFS lz4 for the writing of temporary data was instructive about how much CPU was used for it (not that much). 2. Compression differences:; I might help to look at the used dictionary size for the differences and also the possible method of compression parallelization. Multi-core compression mostly cuts files into pieces and can greatly decrease compression if the data is highly repetitive. Because another core starts anew on data that the previous one might have reduced to almost nothing (zstd allows some sharing of the dictionary between cores, but most do not I think). Example about the dictionary difference: For long distance repetitive files, compression with; xz --lzma2=preset=1,dict=1500M can bringe a huge gain in compression, but still be much faster than level 9 (which has normally only a dictionary of 64MB). Compression levels are correlated with dict size for most compressors to ensure monotonically increasing memory usage, but that doesn't have to be so.; zstd, for example, allows many parameters to change this. Even more than xz. I suspect due to my experiments that quality values gain more from increased dictionary size, because they are more repetitive than the DNA data. And shorter BAMs would be different because they are less repetitive (usually less coverage), so their compression relies more on CPU-expensive crunching of the ""2bit nature"" of the DNA.; So they might logically suffer more from a lower compression level.; It might be instructive ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-360179673
https://github.com/broadinstitute/gatk/issues/3413#issuecomment-360179673:2700,Performance,optimiz,optimized,2700," increased dictionary size, because they are more repetitive than the DNA data. And shorter BAMs would be different because they are less repetitive (usually less coverage), so their compression relies more on CPU-expensive crunching of the ""2bit nature"" of the DNA.; So they might logically suffer more from a lower compression level.; It might be instructive to compare compression sizes of raw sequence data of two BAM files with output of faToTwoBit / 2.bit files.; 2bit files are compressed by a factor of around four, which gzip often does not reach (because it doesn't know ahead of time that DNA has only four letters).; Use reference genome fasta as proxy for nearly no repetition at all. It doesn't compress much beyond 2bit. Tweaking of the Huffmann coding etc. might have influenced the compression level much in this case, by ""giving the compressor a subtle hint about the four letters"".; Paradoxically, Intel might have optimized for average data and thus brought a disadvantage for the four letter nature of DNA (and also the few letters used in quality data encoding compared to text). 3. BQSR:; When I did interleaving compression experiments, I noticed that the BQSR step decreases compressiblity considerably.; In this example I had the same BAM file in different versions that were aligned to hs38DH, hs38, hs37d5 and could compress them to nearly the size of one, by putting similar pieces of the files after one another.; Adding the same BAM with BQSR increased final file size more than several pre-BQSR versions together.; Note: This piece-meal packing might be useful for different BAMs mostly only with many BAMs where similar regions accumulate. 4. Even faster:; In my experience, level 0 (no compression) (with samtools view -u) increases speed even more, if files are on a lz4 encrypted disk (such as with ZFS).; The speed-up of lz4 over even level 1 of any gzip-like compression is substantial.; With data on SSDs or similarly fast storage, that can make a huge differenc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-360179673
https://github.com/broadinstitute/gatk/issues/3413#issuecomment-360179673:3932,Performance,load,load,3932,"factor of around four, which gzip often does not reach (because it doesn't know ahead of time that DNA has only four letters).; Use reference genome fasta as proxy for nearly no repetition at all. It doesn't compress much beyond 2bit. Tweaking of the Huffmann coding etc. might have influenced the compression level much in this case, by ""giving the compressor a subtle hint about the four letters"".; Paradoxically, Intel might have optimized for average data and thus brought a disadvantage for the four letter nature of DNA (and also the few letters used in quality data encoding compared to text). 3. BQSR:; When I did interleaving compression experiments, I noticed that the BQSR step decreases compressiblity considerably.; In this example I had the same BAM file in different versions that were aligned to hs38DH, hs38, hs37d5 and could compress them to nearly the size of one, by putting similar pieces of the files after one another.; Adding the same BAM with BQSR increased final file size more than several pre-BQSR versions together.; Note: This piece-meal packing might be useful for different BAMs mostly only with many BAMs where similar regions accumulate. 4. Even faster:; In my experience, level 0 (no compression) (with samtools view -u) increases speed even more, if files are on a lz4 encrypted disk (such as with ZFS).; The speed-up of lz4 over even level 1 of any gzip-like compression is substantial.; With data on SSDs or similarly fast storage, that can make a huge difference. Another factor 6 six faster than level 1 on compression and a factor 9 on decompression. The then possible decompression speed of 3GB/s makes it possible to e.g. load a 180GB bam into a RAM disk in 60 seconds on a sufficiently fast SSD array (e.g. as on an aws ec2 i3.8xlarge instance).; Still 600MB/s if the RAM is also lz4 compressed. See image from https://github.com/lz4/lz4 below.; ![grafik](https://user-images.githubusercontent.com/1612006/35339046-d84b8b78-011f-11e8-99ec-a36cde725bb3.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-360179673
https://github.com/broadinstitute/gatk/issues/3413#issuecomment-360179673:3572,Security,encrypt,encrypted,3572,"factor of around four, which gzip often does not reach (because it doesn't know ahead of time that DNA has only four letters).; Use reference genome fasta as proxy for nearly no repetition at all. It doesn't compress much beyond 2bit. Tweaking of the Huffmann coding etc. might have influenced the compression level much in this case, by ""giving the compressor a subtle hint about the four letters"".; Paradoxically, Intel might have optimized for average data and thus brought a disadvantage for the four letter nature of DNA (and also the few letters used in quality data encoding compared to text). 3. BQSR:; When I did interleaving compression experiments, I noticed that the BQSR step decreases compressiblity considerably.; In this example I had the same BAM file in different versions that were aligned to hs38DH, hs38, hs37d5 and could compress them to nearly the size of one, by putting similar pieces of the files after one another.; Adding the same BAM with BQSR increased final file size more than several pre-BQSR versions together.; Note: This piece-meal packing might be useful for different BAMs mostly only with many BAMs where similar regions accumulate. 4. Even faster:; In my experience, level 0 (no compression) (with samtools view -u) increases speed even more, if files are on a lz4 encrypted disk (such as with ZFS).; The speed-up of lz4 over even level 1 of any gzip-like compression is substantial.; With data on SSDs or similarly fast storage, that can make a huge difference. Another factor 6 six faster than level 1 on compression and a factor 9 on decompression. The then possible decompression speed of 3GB/s makes it possible to e.g. load a 180GB bam into a RAM disk in 60 seconds on a sufficiently fast SSD array (e.g. as on an aws ec2 i3.8xlarge instance).; Still 600MB/s if the RAM is also lz4 compressed. See image from https://github.com/lz4/lz4 below.; ![grafik](https://user-images.githubusercontent.com/1612006/35339046-d84b8b78-011f-11e8-99ec-a36cde725bb3.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-360179673
https://github.com/broadinstitute/gatk/issues/3413#issuecomment-360179673:2048,Testability,log,logically,2048,"w on data that the previous one might have reduced to almost nothing (zstd allows some sharing of the dictionary between cores, but most do not I think). Example about the dictionary difference: For long distance repetitive files, compression with; xz --lzma2=preset=1,dict=1500M can bringe a huge gain in compression, but still be much faster than level 9 (which has normally only a dictionary of 64MB). Compression levels are correlated with dict size for most compressors to ensure monotonically increasing memory usage, but that doesn't have to be so.; zstd, for example, allows many parameters to change this. Even more than xz. I suspect due to my experiments that quality values gain more from increased dictionary size, because they are more repetitive than the DNA data. And shorter BAMs would be different because they are less repetitive (usually less coverage), so their compression relies more on CPU-expensive crunching of the ""2bit nature"" of the DNA.; So they might logically suffer more from a lower compression level.; It might be instructive to compare compression sizes of raw sequence data of two BAM files with output of faToTwoBit / 2.bit files.; 2bit files are compressed by a factor of around four, which gzip often does not reach (because it doesn't know ahead of time that DNA has only four letters).; Use reference genome fasta as proxy for nearly no repetition at all. It doesn't compress much beyond 2bit. Tweaking of the Huffmann coding etc. might have influenced the compression level much in this case, by ""giving the compressor a subtle hint about the four letters"".; Paradoxically, Intel might have optimized for average data and thus brought a disadvantage for the four letter nature of DNA (and also the few letters used in quality data encoding compared to text). 3. BQSR:; When I did interleaving compression experiments, I noticed that the BQSR step decreases compressiblity considerably.; In this example I had the same BAM file in different versions that were",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-360179673
https://github.com/broadinstitute/gatk/issues/3413#issuecomment-379290482:1240,Performance,tune,tune,1240,"The original reason for this issue was to investigate why BAM files compressed with GKL level 1 DEFLATE compression are larger than BAM files compressed with JDK level 5 DEFLATE compression. Stating the obvious, level 1 compressed files are expected to be larger file than level 5 compressed files. However, GKL level 1 and 2 trade compression ratio for compression speed, so we ran some experiments on data from #4249 to investigate. The chart below shows compression speed vs. compression ratio for 11 files compressed using GKL (use-jdk-deflater = False) and JDK (use-jdk-deflater = True) for compression levels 1 through 9. The chart shows BAM files with binned quality scores can be compressed more given more CPU effort (i.e. higher compression level). The effect is the same for GKL compression and JDK compression, but the compression ratio difference is higher for GKL due to the ratio vs. speed trade off. ![compression study](https://user-images.githubusercontent.com/10476709/38428795-a5f11e4c-398a-11e8-8cfb-800b0423a95a.png). My conclusion is GATK default compression settings work well for some use models (i.e. minimizing cloud compute cost). The default settings may not be optimal for all use models, so users are free to tune the compression options to minimize their own cost function.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3413#issuecomment-379290482
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320696279:135,Availability,error,errors,135,@erniebrau I don't think we can exclude log4j 1.x. A lot of our dependencies use it. This branch is failing with various ClassNotFound errors. ex: https://storage.googleapis.com/hellbender/test/build_reports/11489.3/tests/test/classes/org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSourceUnitTest.html#testReadFromFileAndHDFS,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320696279
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320696279:64,Integrability,depend,dependencies,64,@erniebrau I don't think we can exclude log4j 1.x. A lot of our dependencies use it. This branch is failing with various ClassNotFound errors. ex: https://storage.googleapis.com/hellbender/test/build_reports/11489.3/tests/test/classes/org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSourceUnitTest.html#testReadFromFileAndHDFS,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320696279
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320696279:189,Testability,test,test,189,@erniebrau I don't think we can exclude log4j 1.x. A lot of our dependencies use it. This branch is failing with various ClassNotFound errors. ex: https://storage.googleapis.com/hellbender/test/build_reports/11489.3/tests/test/classes/org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSourceUnitTest.html#testReadFromFileAndHDFS,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320696279
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320696279:216,Testability,test,tests,216,@erniebrau I don't think we can exclude log4j 1.x. A lot of our dependencies use it. This branch is failing with various ClassNotFound errors. ex: https://storage.googleapis.com/hellbender/test/build_reports/11489.3/tests/test/classes/org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSourceUnitTest.html#testReadFromFileAndHDFS,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320696279
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320696279:222,Testability,test,test,222,@erniebrau I don't think we can exclude log4j 1.x. A lot of our dependencies use it. This branch is failing with various ClassNotFound errors. ex: https://storage.googleapis.com/hellbender/test/build_reports/11489.3/tests/test/classes/org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSourceUnitTest.html#testReadFromFileAndHDFS,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320696279
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320696279:320,Testability,test,testReadFromFileAndHDFS,320,@erniebrau I don't think we can exclude log4j 1.x. A lot of our dependencies use it. This branch is failing with various ClassNotFound errors. ex: https://storage.googleapis.com/hellbender/test/build_reports/11489.3/tests/test/classes/org.broadinstitute.hellbender.engine.spark.datasources.ReadsSparkSourceUnitTest.html#testReadFromFileAndHDFS,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320696279
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320745313:154,Integrability,rout,route,154,"@lbergelson You are correct. Let us do a bit more research to see if we can get GKL to log properly to both GATK 3 and 4. If not, we might have to go the route of having a GKL specific to GATK 3. Can we leave this PR open for now?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320745313
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320745313:87,Testability,log,log,87,"@lbergelson You are correct. Let us do a bit more research to see if we can get GKL to log properly to both GATK 3 and 4. If not, we might have to go the route of having a GKL specific to GATK 3. Can we leave this PR open for now?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320745313
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320779413:89,Integrability,depend,dependencies,89,"OK. I found a potential solution. For this solution, we do not need to add or remove any dependencies. The only change is to the `log4j.properties` file (which configures log4j 1.x) to match the config specified in `log4j2.xml` (which configures log4j2). Now, GKL will use log4j 1.x to log, but the format will match the rest of GATK, which uses log4j2. This means that we have only one GKL for both GATK 3 and 4, at the expense of having to keep to config files, `log4j.properties` and `log4j2.xml`, in sync (which they probably should have been anyway, thought they weren't).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320779413
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320779413:160,Modifiability,config,configures,160,"OK. I found a potential solution. For this solution, we do not need to add or remove any dependencies. The only change is to the `log4j.properties` file (which configures log4j 1.x) to match the config specified in `log4j2.xml` (which configures log4j2). Now, GKL will use log4j 1.x to log, but the format will match the rest of GATK, which uses log4j2. This means that we have only one GKL for both GATK 3 and 4, at the expense of having to keep to config files, `log4j.properties` and `log4j2.xml`, in sync (which they probably should have been anyway, thought they weren't).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320779413
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320779413:195,Modifiability,config,config,195,"OK. I found a potential solution. For this solution, we do not need to add or remove any dependencies. The only change is to the `log4j.properties` file (which configures log4j 1.x) to match the config specified in `log4j2.xml` (which configures log4j2). Now, GKL will use log4j 1.x to log, but the format will match the rest of GATK, which uses log4j2. This means that we have only one GKL for both GATK 3 and 4, at the expense of having to keep to config files, `log4j.properties` and `log4j2.xml`, in sync (which they probably should have been anyway, thought they weren't).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320779413
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320779413:235,Modifiability,config,configures,235,"OK. I found a potential solution. For this solution, we do not need to add or remove any dependencies. The only change is to the `log4j.properties` file (which configures log4j 1.x) to match the config specified in `log4j2.xml` (which configures log4j2). Now, GKL will use log4j 1.x to log, but the format will match the rest of GATK, which uses log4j2. This means that we have only one GKL for both GATK 3 and 4, at the expense of having to keep to config files, `log4j.properties` and `log4j2.xml`, in sync (which they probably should have been anyway, thought they weren't).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320779413
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320779413:450,Modifiability,config,config,450,"OK. I found a potential solution. For this solution, we do not need to add or remove any dependencies. The only change is to the `log4j.properties` file (which configures log4j 1.x) to match the config specified in `log4j2.xml` (which configures log4j2). Now, GKL will use log4j 1.x to log, but the format will match the rest of GATK, which uses log4j2. This means that we have only one GKL for both GATK 3 and 4, at the expense of having to keep to config files, `log4j.properties` and `log4j2.xml`, in sync (which they probably should have been anyway, thought they weren't).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320779413
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320779413:286,Testability,log,log,286,"OK. I found a potential solution. For this solution, we do not need to add or remove any dependencies. The only change is to the `log4j.properties` file (which configures log4j 1.x) to match the config specified in `log4j2.xml` (which configures log4j2). Now, GKL will use log4j 1.x to log, but the format will match the rest of GATK, which uses log4j2. This means that we have only one GKL for both GATK 3 and 4, at the expense of having to keep to config files, `log4j.properties` and `log4j2.xml`, in sync (which they probably should have been anyway, thought they weren't).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320779413
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320787794:292,Deployability,update,update,292,So we typically override the config files on the command line. We'll have to make sure we wire the log4j 1.x logger to respect our command line overrides if it doesn't already. You can check that by testing if you can control the log output with the --verbosity command. If not we'll have to update `LoggingUtils.setLoggingLevel()`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320787794
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320787794:29,Modifiability,config,config,29,So we typically override the config files on the command line. We'll have to make sure we wire the log4j 1.x logger to respect our command line overrides if it doesn't already. You can check that by testing if you can control the log output with the --verbosity command. If not we'll have to update `LoggingUtils.setLoggingLevel()`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320787794
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320787794:109,Testability,log,logger,109,So we typically override the config files on the command line. We'll have to make sure we wire the log4j 1.x logger to respect our command line overrides if it doesn't already. You can check that by testing if you can control the log output with the --verbosity command. If not we'll have to update `LoggingUtils.setLoggingLevel()`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320787794
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320787794:199,Testability,test,testing,199,So we typically override the config files on the command line. We'll have to make sure we wire the log4j 1.x logger to respect our command line overrides if it doesn't already. You can check that by testing if you can control the log output with the --verbosity command. If not we'll have to update `LoggingUtils.setLoggingLevel()`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320787794
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320787794:230,Testability,log,log,230,So we typically override the config files on the command line. We'll have to make sure we wire the log4j 1.x logger to respect our command line overrides if it doesn't already. You can check that by testing if you can control the log output with the --verbosity command. If not we'll have to update `LoggingUtils.setLoggingLevel()`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320787794
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320787794:300,Testability,Log,LoggingUtils,300,So we typically override the config files on the command line. We'll have to make sure we wire the log4j 1.x logger to respect our command line overrides if it doesn't already. You can check that by testing if you can control the log output with the --verbosity command. If not we'll have to update `LoggingUtils.setLoggingLevel()`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320787794
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320788037:28,Testability,log,logger,28,"I have to say, I loathe the logger ecosystem... So much complexity for such boring results.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-320788037
https://github.com/broadinstitute/gatk/pull/3416#issuecomment-321051156:272,Deployability,release,release,272,"@lbergelson As you foreshadowed, the `--versbosity` option does not affect log4j 1.x code, which means that, with the changes in 0.5.6, GKL will not listen to this option. I think it is time to close this PR, since any fix to this issue, if one exists, will require a new release of GKL. Thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3416#issuecomment-321051156
https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321078016:56,Availability,failure,failures,56,@cmnbroad please review (assuming there aren't any test failures that I missed in my local testing),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321078016
https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321078016:51,Testability,test,test,51,@cmnbroad please review (assuming there aren't any test failures that I missed in my local testing),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321078016
https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321078016:91,Testability,test,testing,91,@cmnbroad please review (assuming there aren't any test failures that I missed in my local testing),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321078016
https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321351249:112,Availability,failure,failures,112,"@cmnbroad I was going to actually fix the test data, but when I made the test data valid I started getting test failures. @droazen seemed like he preferred the quick and dirty solution, but maybe I communicated the state poorly to him.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321351249
https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321351249:42,Testability,test,test,42,"@cmnbroad I was going to actually fix the test data, but when I made the test data valid I started getting test failures. @droazen seemed like he preferred the quick and dirty solution, but maybe I communicated the state poorly to him.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321351249
https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321351249:73,Testability,test,test,73,"@cmnbroad I was going to actually fix the test data, but when I made the test data valid I started getting test failures. @droazen seemed like he preferred the quick and dirty solution, but maybe I communicated the state poorly to him.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321351249
https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321351249:107,Testability,test,test,107,"@cmnbroad I was going to actually fix the test data, but when I made the test data valid I started getting test failures. @droazen seemed like he preferred the quick and dirty solution, but maybe I communicated the state poorly to him.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321351249
https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321351743:167,Testability,test,test,167,"@cmnbroad Someone once actually fixed all the bam files so they were valid and we rejected it because people were afraid that the fixes were not going to maintain the test conditions properly. So my guess is no, we will never do #569.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321351743
https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321356740:926,Testability,test,test,926,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3421?src=pr&el=h1) Report; > Merging [#3421](https://codecov.io/gh/broadinstitute/gatk/pull/3421?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/0565ee66812e9d0dc09ce704bc06f5da4b56b95c?src=pr&el=desc) will **increase** coverage by `0.082%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #3421 +/- ##; ==============================================; + Coverage 80.51% 80.591% +0.082% ; - Complexity 17555 17654 +99 ; ==============================================; Files 1175 1175 ; Lines 63499 63776 +277 ; Branches 9896 9956 +60 ; ==============================================; + Hits 51123 51398 +275 ; - Misses 8425 8426 +1 ; - Partials 3951 3952 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3421?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ils/test/testers/AbstractMarkDuplicatesTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3421?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvQWJzdHJhY3RNYXJrRHVwbGljYXRlc1Rlc3Rlci5qYXZh) | `79.487% <100%> ()` | `17 <0> ()` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3421?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.233% <0%> (-2.74%)` | `11% <0%> ()` | |; | [...tionbiasvariantfilter/OrientationBiasFilterer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3421?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9vcmllbnRhdGlvbmJpYXN2YXJpYW50ZmlsdGVyL09yaWVudGF0aW9uQmlhc0ZpbHRlcmVyLmphdmE=) | `95.492% <0%> (-0.064%)` | `80% <0%> (+24%)` | |; | [...bender/tools/walkers/annotator/FragmentLength.java](https://codecov.io/gh/broadinstitute/gatk/pull/3421?src=pr&el=tree#diff-c3JjL21haW4vamF,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321356740
https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321356740:931,Testability,test,testers,931,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3421?src=pr&el=h1) Report; > Merging [#3421](https://codecov.io/gh/broadinstitute/gatk/pull/3421?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/0565ee66812e9d0dc09ce704bc06f5da4b56b95c?src=pr&el=desc) will **increase** coverage by `0.082%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #3421 +/- ##; ==============================================; + Coverage 80.51% 80.591% +0.082% ; - Complexity 17555 17654 +99 ; ==============================================; Files 1175 1175 ; Lines 63499 63776 +277 ; Branches 9896 9956 +60 ; ==============================================; + Hits 51123 51398 +275 ; - Misses 8425 8426 +1 ; - Partials 3951 3952 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3421?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ils/test/testers/AbstractMarkDuplicatesTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3421?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvQWJzdHJhY3RNYXJrRHVwbGljYXRlc1Rlc3Rlci5qYXZh) | `79.487% <100%> ()` | `17 <0> ()` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3421?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.233% <0%> (-2.74%)` | `11% <0%> ()` | |; | [...tionbiasvariantfilter/OrientationBiasFilterer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3421?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9vcmllbnRhdGlvbmJpYXN2YXJpYW50ZmlsdGVyL09yaWVudGF0aW9uQmlhc0ZpbHRlcmVyLmphdmE=) | `95.492% <0%> (-0.064%)` | `80% <0%> (+24%)` | |; | [...bender/tools/walkers/annotator/FragmentLength.java](https://codecov.io/gh/broadinstitute/gatk/pull/3421?src=pr&el=tree#diff-c3JjL21haW4vamF,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3421#issuecomment-321356740
https://github.com/broadinstitute/gatk/pull/3422#issuecomment-321093756:2127,Testability,test,test,2127,VEtWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `99.286% <100%> ()` | `7 <0> ()` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3422?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3422?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3422?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3422?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3422?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3422?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `53.947% <0%> (-20.395%)` | `29% <0%> (-8%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3422?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGV,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3422#issuecomment-321093756
https://github.com/broadinstitute/gatk/pull/3422#issuecomment-321093756:3577,Testability,test,test,3577,aW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3422?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3422?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3422?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `53.947% <0%> (-20.395%)` | `29% <0%> (-8%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3422?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3422?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `70.37% <0%> (-11.111%)` | `10% <0%> ()` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3422?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | ... and [8 more](https://codecov.io/gh/broadinstitute/gatk/pull/3422?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3422#issuecomment-321093756
https://github.com/broadinstitute/gatk/pull/3427#issuecomment-322529717:9,Deployability,update,updated,9,@cwhelan updated by removing 3 commits that have the unused classes and functions. Also did the changes as you suggested. PR test cluster is failing but doesn't seem to be related to this PR and engine team is aware of this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3427#issuecomment-322529717
https://github.com/broadinstitute/gatk/pull/3427#issuecomment-322529717:125,Testability,test,test,125,@cwhelan updated by removing 3 commits that have the unused classes and functions. Also did the changes as you suggested. PR test cluster is failing but doesn't seem to be related to this PR and engine team is aware of this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3427#issuecomment-322529717
https://github.com/broadinstitute/gatk/issues/3428#issuecomment-321579805:115,Availability,down,down,115,"We'll get you an answer in the forum, please don't cross-post to github as that just generates noise that slows us down.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3428#issuecomment-321579805
https://github.com/broadinstitute/gatk/issues/3429#issuecomment-321870350:54,Testability,test,test,54,"Also, @vdauwera thank Brad Chapman for this excellent test case. No one ever sends us such complete data to reproduce. It even has a run script that demonstrates the problem!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-321870350
https://github.com/broadinstitute/gatk/issues/3429#issuecomment-324390105:88,Performance,load,load,88,Thanks everyone for working this out. Is there any chance we can detect this problem on load and fail rather than silently giving bad output?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-324390105
https://github.com/broadinstitute/gatk/issues/3429#issuecomment-324390105:65,Safety,detect,detect,65,Thanks everyone for working this out. Is there any chance we can detect this problem on load and fail rather than silently giving bad output?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-324390105
https://github.com/broadinstitute/gatk/issues/3429#issuecomment-325024708:242,Availability,error,error,242,"The GATK VCF header issue causing the underlying problem was fixed in #3351, so a new release of GATK4 should work correctly and avoid losing variants during GenomicsDB import/output for joint calling. I agree with Louis that failing with an error would be better than the current silent failures in case of any future issues. Thank you all again for the help debugging this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-325024708
https://github.com/broadinstitute/gatk/issues/3429#issuecomment-325024708:288,Availability,failure,failures,288,"The GATK VCF header issue causing the underlying problem was fixed in #3351, so a new release of GATK4 should work correctly and avoid losing variants during GenomicsDB import/output for joint calling. I agree with Louis that failing with an error would be better than the current silent failures in case of any future issues. Thank you all again for the help debugging this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-325024708
https://github.com/broadinstitute/gatk/issues/3429#issuecomment-325024708:86,Deployability,release,release,86,"The GATK VCF header issue causing the underlying problem was fixed in #3351, so a new release of GATK4 should work correctly and avoid losing variants during GenomicsDB import/output for joint calling. I agree with Louis that failing with an error would be better than the current silent failures in case of any future issues. Thank you all again for the help debugging this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-325024708
https://github.com/broadinstitute/gatk/issues/3429#issuecomment-325024708:129,Safety,avoid,avoid,129,"The GATK VCF header issue causing the underlying problem was fixed in #3351, so a new release of GATK4 should work correctly and avoid losing variants during GenomicsDB import/output for joint calling. I agree with Louis that failing with an error would be better than the current silent failures in case of any future issues. Thank you all again for the help debugging this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-325024708
https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059:46,Availability,error,error,46,"I'm using GATK 4.1.8.1. And I found a similar error when trying to use GenotypeGVCFs to consolidate genotyping variants on chrX. It does not give any error message. It silently fails. BTW, I'm dealing with WES data. This is the code I used:; # For GenomicDBImport, I randomly select 50 samples from our history samples(using the same probe set) along with the current batch.; time ${gatk} --java-options ""-Xmx8g -Xms2g"" GenomicsDBImport \; --tmp-dir /paedyl01/disk1/yangyxt/test_tmp \; --genomicsdb-update-workspace-path ${vcf_dir}/genomicdbimport_chr${1} \; -R ${ref_gen}/ucsc.hg19.fasta \; --batch-size 0 \; --sample-name-map ${gvcf}/batch_cohort.sample_map \; --reader-threads 5; check_return_code. # For GenotypeGVCFs; time ${gatk} --java-options ""-Xmx8g -Xms2g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" GenotypeGVCFs \; -R ${ref_gen}/ucsc.hg19.fasta \; -V gendb://${vcf_dir}/genomicdbimport_chr${1} \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -L chr${1} \; -O ${bgvcf}/all_${seq_type}_samples_plus_${sample_batch}.chr${1}.HC.vcf. # These are log records:; 02:07:51.286 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 02:07:51.321 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl; Nov 06, 2020 2:07:56 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 02:07:56.529 INFO GenotypeGVCFs - ------------------------------------------------------------; 02:07:56.529 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 02:07:56.530 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 02:08:01.543 INFO GenotypeGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 02:08:01.543 INFO Ge",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059
https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059:150,Availability,error,error,150,"I'm using GATK 4.1.8.1. And I found a similar error when trying to use GenotypeGVCFs to consolidate genotyping variants on chrX. It does not give any error message. It silently fails. BTW, I'm dealing with WES data. This is the code I used:; # For GenomicDBImport, I randomly select 50 samples from our history samples(using the same probe set) along with the current batch.; time ${gatk} --java-options ""-Xmx8g -Xms2g"" GenomicsDBImport \; --tmp-dir /paedyl01/disk1/yangyxt/test_tmp \; --genomicsdb-update-workspace-path ${vcf_dir}/genomicdbimport_chr${1} \; -R ${ref_gen}/ucsc.hg19.fasta \; --batch-size 0 \; --sample-name-map ${gvcf}/batch_cohort.sample_map \; --reader-threads 5; check_return_code. # For GenotypeGVCFs; time ${gatk} --java-options ""-Xmx8g -Xms2g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" GenotypeGVCFs \; -R ${ref_gen}/ucsc.hg19.fasta \; -V gendb://${vcf_dir}/genomicdbimport_chr${1} \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -L chr${1} \; -O ${bgvcf}/all_${seq_type}_samples_plus_${sample_batch}.chr${1}.HC.vcf. # These are log records:; 02:07:51.286 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 02:07:51.321 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl; Nov 06, 2020 2:07:56 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 02:07:56.529 INFO GenotypeGVCFs - ------------------------------------------------------------; 02:07:56.529 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 02:07:56.530 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 02:08:01.543 INFO GenotypeGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 02:08:01.543 INFO Ge",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059
https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059:1124,Availability,Redundant,Redundant,1124,"r message. It silently fails. BTW, I'm dealing with WES data. This is the code I used:; # For GenomicDBImport, I randomly select 50 samples from our history samples(using the same probe set) along with the current batch.; time ${gatk} --java-options ""-Xmx8g -Xms2g"" GenomicsDBImport \; --tmp-dir /paedyl01/disk1/yangyxt/test_tmp \; --genomicsdb-update-workspace-path ${vcf_dir}/genomicdbimport_chr${1} \; -R ${ref_gen}/ucsc.hg19.fasta \; --batch-size 0 \; --sample-name-map ${gvcf}/batch_cohort.sample_map \; --reader-threads 5; check_return_code. # For GenotypeGVCFs; time ${gatk} --java-options ""-Xmx8g -Xms2g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" GenotypeGVCFs \; -R ${ref_gen}/ucsc.hg19.fasta \; -V gendb://${vcf_dir}/genomicdbimport_chr${1} \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -L chr${1} \; -O ${bgvcf}/all_${seq_type}_samples_plus_${sample_batch}.chr${1}.HC.vcf. # These are log records:; 02:07:51.286 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 02:07:51.321 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl; Nov 06, 2020 2:07:56 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 02:07:56.529 INFO GenotypeGVCFs - ------------------------------------------------------------; 02:07:56.529 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 02:07:56.530 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 02:08:01.543 INFO GenotypeGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 02:08:01.543 INFO GenotypeGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_161-b12; 02:08:01.543 INFO GenotypeGVCFs - Start Date/Time: November 6, 2020 2:07:51",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059
https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059:4504,Availability,down,down,4504,"e field will NOT be part of INFO fields in the; 02:08:02.331 info NativeGenomicsDB - pid=161923 tid=161924 No valid combination operation found for INFO field MLEAC - the field will NOT be part of INFO fields in the generated; 02:08:02.331 info NativeGenomicsDB - pid=161923 tid=161924 No valid combination operation found for INFO field MLEAF - the field will NOT be part of INFO fields in the generated; 02:08:02.380 INFO IntervalArgumentCollection - Processing 155270560 bp from intervals; 02:08:02.385 INFO GenotypeGVCFs - Done initializing engine; 02:08:02.426 INFO ProgressMeter - Starting traversal; 02:08:02.426 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.0,Cpu time(s),0.0; 02:08:02.685 INFO ProgressMeter - unmapped 0.0 0 0.0; 02:08:02.685 INFO ProgressMeter - Traversal complete. Processed 0 total variants in 0.0 minutes.; 02:08:02.688 INFO GenotypeGVCFs - Shutting down engine; [November 6, 2020 2:08:02 AM HKT] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.19 minutes.; Runtime.totalMemory()=2190999552; Using GATK jar /home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8g -Xms2g -D. real 0m18.775s; user 0m8.039s; sys 0m1.440s. According to the log, it seems the traversal never started. But I checked the gvcf file on chrX of the current batch and I'm pretty sure there are lot's of variant records (for a single sample, around 25000 variant records on chrX) looking like these:; chrX 2699968 . A G,<NON_REF> 894.06 . AS_RAW_BaseQRankSum=||;AS_RAW_MQ=0.00|75600.00|0.00;AS_RAW_MQRankSum=||;AS_RAW_ReadPosRankSum=||;AS_SB_TABLE=0,0|21,; chrX 2700027 . T C,<NON_REF> 1681.06 . AS_RAW_BaseQRankSum=||;AS_RAW_MQ=0.00|165600.00|0.00;AS_RAW_MQRankSum=|",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059
https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059:499,Deployability,update,update-workspace-path,499,"I'm using GATK 4.1.8.1. And I found a similar error when trying to use GenotypeGVCFs to consolidate genotyping variants on chrX. It does not give any error message. It silently fails. BTW, I'm dealing with WES data. This is the code I used:; # For GenomicDBImport, I randomly select 50 samples from our history samples(using the same probe set) along with the current batch.; time ${gatk} --java-options ""-Xmx8g -Xms2g"" GenomicsDBImport \; --tmp-dir /paedyl01/disk1/yangyxt/test_tmp \; --genomicsdb-update-workspace-path ${vcf_dir}/genomicdbimport_chr${1} \; -R ${ref_gen}/ucsc.hg19.fasta \; --batch-size 0 \; --sample-name-map ${gvcf}/batch_cohort.sample_map \; --reader-threads 5; check_return_code. # For GenotypeGVCFs; time ${gatk} --java-options ""-Xmx8g -Xms2g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" GenotypeGVCFs \; -R ${ref_gen}/ucsc.hg19.fasta \; -V gendb://${vcf_dir}/genomicdbimport_chr${1} \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -L chr${1} \; -O ${bgvcf}/all_${seq_type}_samples_plus_${sample_batch}.chr${1}.HC.vcf. # These are log records:; 02:07:51.286 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 02:07:51.321 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl; Nov 06, 2020 2:07:56 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 02:07:56.529 INFO GenotypeGVCFs - ------------------------------------------------------------; 02:07:56.529 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 02:07:56.530 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 02:08:01.543 INFO GenotypeGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 02:08:01.543 INFO Ge",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059
https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059:156,Integrability,message,message,156,"I'm using GATK 4.1.8.1. And I found a similar error when trying to use GenotypeGVCFs to consolidate genotyping variants on chrX. It does not give any error message. It silently fails. BTW, I'm dealing with WES data. This is the code I used:; # For GenomicDBImport, I randomly select 50 samples from our history samples(using the same probe set) along with the current batch.; time ${gatk} --java-options ""-Xmx8g -Xms2g"" GenomicsDBImport \; --tmp-dir /paedyl01/disk1/yangyxt/test_tmp \; --genomicsdb-update-workspace-path ${vcf_dir}/genomicdbimport_chr${1} \; -R ${ref_gen}/ucsc.hg19.fasta \; --batch-size 0 \; --sample-name-map ${gvcf}/batch_cohort.sample_map \; --reader-threads 5; check_return_code. # For GenotypeGVCFs; time ${gatk} --java-options ""-Xmx8g -Xms2g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" GenotypeGVCFs \; -R ${ref_gen}/ucsc.hg19.fasta \; -V gendb://${vcf_dir}/genomicdbimport_chr${1} \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -L chr${1} \; -O ${bgvcf}/all_${seq_type}_samples_plus_${sample_batch}.chr${1}.HC.vcf. # These are log records:; 02:07:51.286 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 02:07:51.321 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl; Nov 06, 2020 2:07:56 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 02:07:56.529 INFO GenotypeGVCFs - ------------------------------------------------------------; 02:07:56.529 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 02:07:56.530 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 02:08:01.543 INFO GenotypeGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 02:08:01.543 INFO Ge",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059
https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059:1257,Performance,Load,Loading,1257,"DBImport, I randomly select 50 samples from our history samples(using the same probe set) along with the current batch.; time ${gatk} --java-options ""-Xmx8g -Xms2g"" GenomicsDBImport \; --tmp-dir /paedyl01/disk1/yangyxt/test_tmp \; --genomicsdb-update-workspace-path ${vcf_dir}/genomicdbimport_chr${1} \; -R ${ref_gen}/ucsc.hg19.fasta \; --batch-size 0 \; --sample-name-map ${gvcf}/batch_cohort.sample_map \; --reader-threads 5; check_return_code. # For GenotypeGVCFs; time ${gatk} --java-options ""-Xmx8g -Xms2g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" GenotypeGVCFs \; -R ${ref_gen}/ucsc.hg19.fasta \; -V gendb://${vcf_dir}/genomicdbimport_chr${1} \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -L chr${1} \; -O ${bgvcf}/all_${seq_type}_samples_plus_${sample_batch}.chr${1}.HC.vcf. # These are log records:; 02:07:51.286 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 02:07:51.321 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl; Nov 06, 2020 2:07:56 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 02:07:56.529 INFO GenotypeGVCFs - ------------------------------------------------------------; 02:07:56.529 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 02:07:56.530 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 02:08:01.543 INFO GenotypeGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 02:08:01.543 INFO GenotypeGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_161-b12; 02:08:01.543 INFO GenotypeGVCFs - Start Date/Time: November 6, 2020 2:07:51 AM HKT; 02:08:01.543 INFO GenotypeGVCFs - ----------------------------------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059
https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059:1124,Safety,Redund,Redundant,1124,"r message. It silently fails. BTW, I'm dealing with WES data. This is the code I used:; # For GenomicDBImport, I randomly select 50 samples from our history samples(using the same probe set) along with the current batch.; time ${gatk} --java-options ""-Xmx8g -Xms2g"" GenomicsDBImport \; --tmp-dir /paedyl01/disk1/yangyxt/test_tmp \; --genomicsdb-update-workspace-path ${vcf_dir}/genomicdbimport_chr${1} \; -R ${ref_gen}/ucsc.hg19.fasta \; --batch-size 0 \; --sample-name-map ${gvcf}/batch_cohort.sample_map \; --reader-threads 5; check_return_code. # For GenotypeGVCFs; time ${gatk} --java-options ""-Xmx8g -Xms2g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" GenotypeGVCFs \; -R ${ref_gen}/ucsc.hg19.fasta \; -V gendb://${vcf_dir}/genomicdbimport_chr${1} \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -L chr${1} \; -O ${bgvcf}/all_${seq_type}_samples_plus_${sample_batch}.chr${1}.HC.vcf. # These are log records:; 02:07:51.286 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 02:07:51.321 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl; Nov 06, 2020 2:07:56 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 02:07:56.529 INFO GenotypeGVCFs - ------------------------------------------------------------; 02:07:56.529 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 02:07:56.530 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 02:08:01.543 INFO GenotypeGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 02:08:01.543 INFO GenotypeGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_161-b12; 02:08:01.543 INFO GenotypeGVCFs - Start Date/Time: November 6, 2020 2:07:51",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059
https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059:1527,Safety,detect,detect,1527,"{vcf_dir}/genomicdbimport_chr${1} \; -R ${ref_gen}/ucsc.hg19.fasta \; --batch-size 0 \; --sample-name-map ${gvcf}/batch_cohort.sample_map \; --reader-threads 5; check_return_code. # For GenotypeGVCFs; time ${gatk} --java-options ""-Xmx8g -Xms2g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" GenotypeGVCFs \; -R ${ref_gen}/ucsc.hg19.fasta \; -V gendb://${vcf_dir}/genomicdbimport_chr${1} \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -L chr${1} \; -O ${bgvcf}/all_${seq_type}_samples_plus_${sample_batch}.chr${1}.HC.vcf. # These are log records:; 02:07:51.286 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 02:07:51.321 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl; Nov 06, 2020 2:07:56 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 02:07:56.529 INFO GenotypeGVCFs - ------------------------------------------------------------; 02:07:56.529 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 02:07:56.530 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 02:08:01.543 INFO GenotypeGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 02:08:01.543 INFO GenotypeGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_161-b12; 02:08:01.543 INFO GenotypeGVCFs - Start Date/Time: November 6, 2020 2:07:51 AM HKT; 02:08:01.543 INFO GenotypeGVCFs - ------------------------------------------------------------; 02:08:01.544 INFO GenotypeGVCFs - ------------------------------------------------------------; 02:08:01.544 INFO GenotypeGVCFs - HTSJDK Version: 2.23.0; 02:08:01.545 INFO GenotypeGVCFs - Picard Version: 2.22.8; 02:08:01.545 INFO GenotypeGVCFs - HTSJDK Defaults.C",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059
https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059:1059,Testability,log,log,1059,"to use GenotypeGVCFs to consolidate genotyping variants on chrX. It does not give any error message. It silently fails. BTW, I'm dealing with WES data. This is the code I used:; # For GenomicDBImport, I randomly select 50 samples from our history samples(using the same probe set) along with the current batch.; time ${gatk} --java-options ""-Xmx8g -Xms2g"" GenomicsDBImport \; --tmp-dir /paedyl01/disk1/yangyxt/test_tmp \; --genomicsdb-update-workspace-path ${vcf_dir}/genomicdbimport_chr${1} \; -R ${ref_gen}/ucsc.hg19.fasta \; --batch-size 0 \; --sample-name-map ${gvcf}/batch_cohort.sample_map \; --reader-threads 5; check_return_code. # For GenotypeGVCFs; time ${gatk} --java-options ""-Xmx8g -Xms2g -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" GenotypeGVCFs \; -R ${ref_gen}/ucsc.hg19.fasta \; -V gendb://${vcf_dir}/genomicdbimport_chr${1} \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -L chr${1} \; -O ${bgvcf}/all_${seq_type}_samples_plus_${sample_batch}.chr${1}.HC.vcf. # These are log records:; 02:07:51.286 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 02:07:51.321 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl; Nov 06, 2020 2:07:56 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 02:07:56.529 INFO GenotypeGVCFs - ------------------------------------------------------------; 02:07:56.529 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 02:07:56.530 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 02:08:01.543 INFO GenotypeGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 02:08:01.543 INFO GenotypeGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059
https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059:5011,Testability,log,log,5011,"GenotypeGVCFs - Done initializing engine; 02:08:02.426 INFO ProgressMeter - Starting traversal; 02:08:02.426 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),0.0,Cpu time(s),0.0; 02:08:02.685 INFO ProgressMeter - unmapped 0.0 0 0.0; 02:08:02.685 INFO ProgressMeter - Traversal complete. Processed 0 total variants in 0.0 minutes.; 02:08:02.688 INFO GenotypeGVCFs - Shutting down engine; [November 6, 2020 2:08:02 AM HKT] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.19 minutes.; Runtime.totalMemory()=2190999552; Using GATK jar /home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx8g -Xms2g -D. real 0m18.775s; user 0m8.039s; sys 0m1.440s. According to the log, it seems the traversal never started. But I checked the gvcf file on chrX of the current batch and I'm pretty sure there are lot's of variant records (for a single sample, around 25000 variant records on chrX) looking like these:; chrX 2699968 . A G,<NON_REF> 894.06 . AS_RAW_BaseQRankSum=||;AS_RAW_MQ=0.00|75600.00|0.00;AS_RAW_MQRankSum=||;AS_RAW_ReadPosRankSum=||;AS_SB_TABLE=0,0|21,; chrX 2700027 . T C,<NON_REF> 1681.06 . AS_RAW_BaseQRankSum=||;AS_RAW_MQ=0.00|165600.00|0.00;AS_RAW_MQRankSum=||;AS_RAW_ReadPosRankSum=||;AS_SB_TABLE=0,0|34; chrX 2704469 . T C,<NON_REF> 70.64 . AS_RAW_BaseQRankSum=|-0.8,1|NaN;AS_RAW_MQ=10800.00|14400.00|0.00;AS_RAW_MQRankSum=|0.0,1|NaN;AS_RAW_ReadPosRankSum=|; chrX 2704556 . A G,<NON_REF> 105.64 . AS_RAW_BaseQRankSum=|-0.6,1|NaN;AS_RAW_MQ=7200.00|14400.00|0.00;AS_RAW_MQRankSum=|0.0,1|NaN;AS_RAW_ReadPosRankSum=|1; chrX 2706896 . T TA,<NON_REF> 44.27 . AS_RAW_BaseQRankSum=||;AS_RAW_MQ=0.00|7200.00|0.00;AS_RAW_MQRankSum=||;AS_RAW_ReadPosRankSum=||;AS_SB_TABLE=0,0|0,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3429#issuecomment-722764059
https://github.com/broadinstitute/gatk/pull/3430#issuecomment-333562036:5,Testability,test,tested,5,I've tested my scenario and made notes in <https://github.com/broadinstitute/gatk/issues/3154>. I used `gatk-4.beta.5` to test. The issue is solved. Thank you for the fix.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3430#issuecomment-333562036
https://github.com/broadinstitute/gatk/pull/3430#issuecomment-333562036:122,Testability,test,test,122,I've tested my scenario and made notes in <https://github.com/broadinstitute/gatk/issues/3154>. I used `gatk-4.beta.5` to test. The issue is solved. Thank you for the fix.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3430#issuecomment-333562036
https://github.com/broadinstitute/gatk/issues/3431#issuecomment-343286070:51,Testability,test,tests,51,now that tool is up and running. ; Need to provide tests for stability and this needs to be DONE BEFORE the prototyping tool hooked up into master,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3431#issuecomment-343286070
https://github.com/broadinstitute/gatk/issues/3437#issuecomment-322485170:909,Energy Efficiency,reduce,reducers,909,"I can confirm this too. When I reverted https://github.com/broadinstitute/gatk/commit/4c697e06ea33c9179840c81c843658442c82a951 the problem disappeared, so that seems to be the culprit. This is definitely a GCS issue, as I don't see the problem when running with HDFS inputs. More details: for ReadsPipelineSpark, the first job has the following stages when running OK:; * Stage ID 0, mapToPair at MarkDuplicatesSparkUtils.java:56, 147 partitions; * Stage ID 1, flatMapToPair at MarkDuplicatesSparkUtils.java:60, 1880 partitions. And the following when there's only a single partition:; * Stage ID 0, mapToPair at MarkDuplicatesSparkUtils.java:56, 294 partitions; * Stage ID 1, flatMapToPair at MarkDuplicatesSparkUtils.java:60, **_1 partition_**. I wonder if the GCS code called by `BucketUtils.dirSize` has changed somehow, since it's used by `GATKSparkTool.getRecommendedNumReducers()` to get the number of reducers.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3437#issuecomment-322485170
https://github.com/broadinstitute/gatk/issues/3437#issuecomment-326617327:72,Testability,test,test-spark-markeddupe,72,@lbergelson do any of the Jenkins jobs need reenabling? I see gatk-perf-test-spark-markeddupe and gatk-perf-test-spark-readpipeline are disabled - or were they disabled for another reason?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3437#issuecomment-326617327
https://github.com/broadinstitute/gatk/issues/3437#issuecomment-326617327:108,Testability,test,test-spark-readpipeline,108,@lbergelson do any of the Jenkins jobs need reenabling? I see gatk-perf-test-spark-markeddupe and gatk-perf-test-spark-readpipeline are disabled - or were they disabled for another reason?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3437#issuecomment-326617327
https://github.com/broadinstitute/gatk/issues/3437#issuecomment-327116293:15,Testability,test,test-spark-markeddupe,15,"Both gatk-perf-test-spark-markeddupe and gatk-perf-test-spark-readpipeline have been passing for the last few days, so I'll close this now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3437#issuecomment-327116293
https://github.com/broadinstitute/gatk/issues/3437#issuecomment-327116293:51,Testability,test,test-spark-readpipeline,51,"Both gatk-perf-test-spark-markeddupe and gatk-perf-test-spark-readpipeline have been passing for the last few days, so I'll close this now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3437#issuecomment-327116293
https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322318791:40,Availability,failure,failures,40,@cmnbroad This should hopefully fix the failures...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322318791
https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322588809:278,Deployability,install,installed,278,"Seems still failing, what about multiple tries. ```r; dependencies = c(""naturalsort"",""ggplot2"",""gplots"",""reshape"",""gsalib""); repos <- c(""http://cran.cnr.Berkeley.edu"", ; ""https://cran.mtu.edu"", ; ""http://lib.stat.cmu.edu/R/CRAN/""); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- 1; while(length(missing)!=0 & try <= length(repos)) {; install.packages(dependencies[missing], repos = repos[try]); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- try + 1; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322588809
https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322588809:365,Deployability,install,install,365,"Seems still failing, what about multiple tries. ```r; dependencies = c(""naturalsort"",""ggplot2"",""gplots"",""reshape"",""gsalib""); repos <- c(""http://cran.cnr.Berkeley.edu"", ; ""https://cran.mtu.edu"", ; ""http://lib.stat.cmu.edu/R/CRAN/""); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- 1; while(length(missing)!=0 & try <= length(repos)) {; install.packages(dependencies[missing], repos = repos[try]); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- try + 1; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322588809
https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322588809:472,Deployability,install,installed,472,"Seems still failing, what about multiple tries. ```r; dependencies = c(""naturalsort"",""ggplot2"",""gplots"",""reshape"",""gsalib""); repos <- c(""http://cran.cnr.Berkeley.edu"", ; ""https://cran.mtu.edu"", ; ""http://lib.stat.cmu.edu/R/CRAN/""); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- 1; while(length(missing)!=0 & try <= length(repos)) {; install.packages(dependencies[missing], repos = repos[try]); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- try + 1; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322588809
https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322588809:54,Integrability,depend,dependencies,54,"Seems still failing, what about multiple tries. ```r; dependencies = c(""naturalsort"",""ggplot2"",""gplots"",""reshape"",""gsalib""); repos <- c(""http://cran.cnr.Berkeley.edu"", ; ""https://cran.mtu.edu"", ; ""http://lib.stat.cmu.edu/R/CRAN/""); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- 1; while(length(missing)!=0 & try <= length(repos)) {; install.packages(dependencies[missing], repos = repos[try]); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- try + 1; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322588809
https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322588809:251,Integrability,depend,dependencies,251,"Seems still failing, what about multiple tries. ```r; dependencies = c(""naturalsort"",""ggplot2"",""gplots"",""reshape"",""gsalib""); repos <- c(""http://cran.cnr.Berkeley.edu"", ; ""https://cran.mtu.edu"", ; ""http://lib.stat.cmu.edu/R/CRAN/""); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- 1; while(length(missing)!=0 & try <= length(repos)) {; install.packages(dependencies[missing], repos = repos[try]); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- try + 1; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322588809
https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322588809:382,Integrability,depend,dependencies,382,"Seems still failing, what about multiple tries. ```r; dependencies = c(""naturalsort"",""ggplot2"",""gplots"",""reshape"",""gsalib""); repos <- c(""http://cran.cnr.Berkeley.edu"", ; ""https://cran.mtu.edu"", ; ""http://lib.stat.cmu.edu/R/CRAN/""); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- 1; while(length(missing)!=0 & try <= length(repos)) {; install.packages(dependencies[missing], repos = repos[try]); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- try + 1; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322588809
https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322588809:445,Integrability,depend,dependencies,445,"Seems still failing, what about multiple tries. ```r; dependencies = c(""naturalsort"",""ggplot2"",""gplots"",""reshape"",""gsalib""); repos <- c(""http://cran.cnr.Berkeley.edu"", ; ""https://cran.mtu.edu"", ; ""http://lib.stat.cmu.edu/R/CRAN/""); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- 1; while(length(missing)!=0 & try <= length(repos)) {; install.packages(dependencies[missing], repos = repos[try]); missing <- which(!(dependencies %in% rownames(installed.packages()))); try <- try + 1; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322588809
https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322820092:78,Availability,robust,robust,78,closing this because https://github.com/broadinstitute/gatk/pull/3451 is more robust,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3443#issuecomment-322820092
https://github.com/broadinstitute/gatk/pull/3445#issuecomment-322886799:951,Security,Validat,ValidateVariants,951,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3445?src=pr&el=h1) Report; > Merging [#3445](https://codecov.io/gh/broadinstitute/gatk/pull/3445?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/69fd3791cf5dd975ce1cc820226fc4a4c8904b65?src=pr&el=desc) will **increase** coverage by `0.023%`.; > The diff coverage is `91.667%`. ```diff; @@ Coverage Diff @@; ## master #3445 +/- ##; ==============================================; + Coverage 80.287% 80.31% +0.023% ; - Complexity 17633 17647 +14 ; ==============================================; Files 1178 1178 ; Lines 63847 63854 +7 ; Branches 9928 9930 +2 ; ==============================================; + Hits 51261 51281 +20 ; + Misses 8631 8628 -3 ; + Partials 3955 3945 -10; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3445?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/3445?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYWxpZGF0ZVZhcmlhbnRzLmphdmE=) | `82.353% <91.667%> (+2.353%)` | `32 <0> (+4)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3445?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `74.342% <0%> (-1.974%)` | `38% <0%> ()` | |; | [...bender/tools/spark/sv/evidence/ReadClassifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/3445?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9SZWFkQ2xhc3NpZmllci5qYXZh) | `86.667% <0%> (+1.333%)` | `33% <0%> (+1%)` | :arrow_up: |; | [...er/tools/spark/sv/evidence/BreakpointEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/3445?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVs,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3445#issuecomment-322886799
https://github.com/broadinstitute/gatk/pull/3445#issuecomment-323204475:27,Performance,optimiz,optimization,27,@yfarjoun this is a memory optimization but I have confirmed it uses less memory and runs at the same speed,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3445#issuecomment-323204475
https://github.com/broadinstitute/gatk/pull/3447#issuecomment-323474032:1818,Modifiability,config,config,1818,odecov.io/gh/broadinstitute/gatk/pull/3447?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [.../broadinstitute/hellbender/utils/LoggingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9Mb2dnaW5nVXRpbHMuamF2YQ==) | `82.222% <> ()` | `11 <0> ()` | :arrow_down: |; | [...ellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1N0YW5kYXJkQXJndW1lbnREZWZpbml0aW9ucy5qYXZh) | `0% <> ()` | `0 <0> ()` | :arrow_down: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `65.926% <> ()` | `35 <0> ()` | :arrow_down: |; | [...ellbender/utils/config/CustomBooleanConverter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb25maWcvQ3VzdG9tQm9vbGVhbkNvbnZlcnRlci5qYXZh) | `100% <100%> ()` | `2 <2> (?)` | |; | [...rg/broadinstitute/hellbender/utils/io/IOUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9JT1V0aWxzLmphdmE=) | `60.104% <100%> (+0.418%)` | `50 <2> (+1)` | :arrow_up: |; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `86.408% <100%> (+0.408%)` | `29 <0> ()` | :arrow_down: |; | [...oadinstitute/hellbender/engine/FeatureManager.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447#issuecomment-323474032
https://github.com/broadinstitute/gatk/pull/3447#issuecomment-323474032:975,Testability,Log,LoggingUtils,975,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3447?src=pr&el=h1) Report; > Merging [#3447](https://codecov.io/gh/broadinstitute/gatk/pull/3447?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/054f7481b5fff4b781de7aa74433f7fd685ea2eb?src=pr&el=desc) will **increase** coverage by `0.265%`.; > The diff coverage is `75.275%`. ```diff; @@ Coverage Diff @@; ## master #3447 +/- ##; ===============================================; + Coverage 79.183% 79.448% +0.265% ; - Complexity 16844 18136 +1292 ; ===============================================; Files 1119 1189 +70 ; Lines 60168 65580 +5412 ; Branches 9498 9959 +461 ; ===============================================; + Hits 47643 52102 +4459 ; - Misses 8822 9487 +665 ; - Partials 3703 3991 +288; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3447?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [.../broadinstitute/hellbender/utils/LoggingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9Mb2dnaW5nVXRpbHMuamF2YQ==) | `82.222% <> ()` | `11 <0> ()` | :arrow_down: |; | [...ellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1N0YW5kYXJkQXJndW1lbnREZWZpbml0aW9ucy5qYXZh) | `0% <> ()` | `0 <0> ()` | :arrow_down: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `65.926% <> ()` | `35 <0> ()` | :arrow_down: |; | [...ellbender/utils/config/CustomBooleanConverter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447#issuecomment-323474032
https://github.com/broadinstitute/gatk/pull/3447#issuecomment-323474032:1552,Testability,test,test,1552,============================================; Files 1119 1189 +70 ; Lines 60168 65580 +5412 ; Branches 9498 9959 +461 ; ===============================================; + Hits 47643 52102 +4459 ; - Misses 8822 9487 +665 ; - Partials 3703 3991 +288; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3447?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [.../broadinstitute/hellbender/utils/LoggingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9Mb2dnaW5nVXRpbHMuamF2YQ==) | `82.222% <> ()` | `11 <0> ()` | :arrow_down: |; | [...ellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1N0YW5kYXJkQXJndW1lbnREZWZpbml0aW9ucy5qYXZh) | `0% <> ()` | `0 <0> ()` | :arrow_down: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `65.926% <> ()` | `35 <0> ()` | :arrow_down: |; | [...ellbender/utils/config/CustomBooleanConverter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb25maWcvQ3VzdG9tQm9vbGVhbkNvbnZlcnRlci5qYXZh) | `100% <100%> ()` | `2 <2> (?)` | |; | [...rg/broadinstitute/hellbender/utils/io/IOUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9JT1V0aWxzLmphdmE=) | `60.104% <100%> (+0.418%)` | `50 <2> (+1)` | :arrow_up: |; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3447/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aX,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447#issuecomment-323474032
https://github.com/broadinstitute/gatk/pull/3447#issuecomment-347911605:43,Availability,down,downstream,43,"@magicDGS Understood about the changes for downstream projects. When this goes in, I can make a new issue for better downstream compatibility (thinking specifically about the argument collection, though there may be others).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447#issuecomment-347911605
https://github.com/broadinstitute/gatk/pull/3447#issuecomment-347911605:117,Availability,down,downstream,117,"@magicDGS Understood about the changes for downstream projects. When this goes in, I can make a new issue for better downstream compatibility (thinking specifically about the argument collection, though there may be others).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3447#issuecomment-347911605
https://github.com/broadinstitute/gatk/issues/3448#issuecomment-322799380:111,Safety,sanity check,sanity check,111,@drozen htsjdk PR is [here](https://github.com/samtools/htsjdk/pull/968/). I'm running gatk tests locally as a sanity check.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3448#issuecomment-322799380
https://github.com/broadinstitute/gatk/issues/3448#issuecomment-322799380:92,Testability,test,tests,92,@drozen htsjdk PR is [here](https://github.com/samtools/htsjdk/pull/968/). I'm running gatk tests locally as a sanity check.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3448#issuecomment-322799380
https://github.com/broadinstitute/gatk/issues/3448#issuecomment-322901996:0,Testability,Test,Tests,0,"Tests passed, PR is reviewed and merged into htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3448#issuecomment-322901996
https://github.com/broadinstitute/gatk/pull/3450#issuecomment-324005527:270,Deployability,pipeline,pipeline,270,"@lbergelson thanks for the review! I've addressed your comments in this PR, but also in #3452, which this is based on. The PRs should be merged in this order, since they are all related and each builds on the previous: #3106 (whole genome fixes), #3452 (add HC to reads pipeline), #3450 (gVCF support) - although #3450 needs a Hadoop-BAM release first.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3450#issuecomment-324005527
https://github.com/broadinstitute/gatk/pull/3450#issuecomment-324005527:338,Deployability,release,release,338,"@lbergelson thanks for the review! I've addressed your comments in this PR, but also in #3452, which this is based on. The PRs should be merged in this order, since they are all related and each builds on the previous: #3106 (whole genome fixes), #3452 (add HC to reads pipeline), #3450 (gVCF support) - although #3450 needs a Hadoop-BAM release first.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3450#issuecomment-324005527
https://github.com/broadinstitute/gatk/pull/3452#issuecomment-323129083:942,Deployability,pipeline,pipelines,942,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3452?src=pr&el=h1) Report; > Merging [#3452](https://codecov.io/gh/broadinstitute/gatk/pull/3452?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/1edf1b6455708fa7974896ec792e64bb24c7307c?src=pr&el=desc) will **increase** coverage by `0.001%`.; > The diff coverage is `90.909%`. ```diff; @@ Coverage Diff @@; ## master #3452 +/- ##; ===============================================; + Coverage 80.092% 80.092% +0.001% ; - Complexity 17763 17766 +3 ; ===============================================; Files 1188 1188 ; Lines 64415 64417 +2 ; Branches 10006 10007 +1 ; ===============================================; + Hits 51591 51593 +2 ; + Misses 8838 8837 -1 ; - Partials 3986 3987 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3452?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3452?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `91.429% <90%> (-1.675%)` | `10 <1> (+2)` | |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3452?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `83.168% <91.667%> (+4.121%)` | `25 <5> (+1)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3452?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.233% <0%> (-2.74%)` | `11% <0%> ()` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3452?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3452#issuecomment-323129083
https://github.com/broadinstitute/gatk/pull/3452#issuecomment-325607019:40,Testability,test,tests,40,I've addressed all the feedback and all tests are passing so I'm going to squash and merge this now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3452#issuecomment-325607019
https://github.com/broadinstitute/gatk/pull/3452#issuecomment-325607019:23,Usability,feedback,feedback,23,I've addressed all the feedback and all tests are passing so I'm going to squash and merge this now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3452#issuecomment-325607019
https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323698699:400,Integrability,depend,depending,400,"For reporting the number of reads that fails each of the filters, the composed filter could be changed by a `CountingReadFilter`; using the `getSummaryLine()` method will provide the number of reads failing each of the components. Developers could have in their tools a field with the `WellFormedReadFilter` and call a new method for reporting the summary, to log a warning/debug line. For exploding depending on the tool, maybe an advance/hidden argument can be added to the filter (something like `--failOnMalformed`) to throw an exception if true; developers might add a default filter with this value equals to true if they want to enforce by default this behaviour. I think that this a simpler idea for allow the developer to choose, and give some flexibility to the user to change the behaviour as its own risk (they can disable all filters anyway, which is also risky).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323698699
https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323698699:812,Safety,risk,risk,812,"For reporting the number of reads that fails each of the filters, the composed filter could be changed by a `CountingReadFilter`; using the `getSummaryLine()` method will provide the number of reads failing each of the components. Developers could have in their tools a field with the `WellFormedReadFilter` and call a new method for reporting the summary, to log a warning/debug line. For exploding depending on the tool, maybe an advance/hidden argument can be added to the filter (something like `--failOnMalformed`) to throw an exception if true; developers might add a default filter with this value equals to true if they want to enforce by default this behaviour. I think that this a simpler idea for allow the developer to choose, and give some flexibility to the user to change the behaviour as its own risk (they can disable all filters anyway, which is also risky).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323698699
https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323698699:869,Safety,risk,risky,869,"For reporting the number of reads that fails each of the filters, the composed filter could be changed by a `CountingReadFilter`; using the `getSummaryLine()` method will provide the number of reads failing each of the components. Developers could have in their tools a field with the `WellFormedReadFilter` and call a new method for reporting the summary, to log a warning/debug line. For exploding depending on the tool, maybe an advance/hidden argument can be added to the filter (something like `--failOnMalformed`) to throw an exception if true; developers might add a default filter with this value equals to true if they want to enforce by default this behaviour. I think that this a simpler idea for allow the developer to choose, and give some flexibility to the user to change the behaviour as its own risk (they can disable all filters anyway, which is also risky).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323698699
https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323698699:360,Testability,log,log,360,"For reporting the number of reads that fails each of the filters, the composed filter could be changed by a `CountingReadFilter`; using the `getSummaryLine()` method will provide the number of reads failing each of the components. Developers could have in their tools a field with the `WellFormedReadFilter` and call a new method for reporting the summary, to log a warning/debug line. For exploding depending on the tool, maybe an advance/hidden argument can be added to the filter (something like `--failOnMalformed`) to throw an exception if true; developers might add a default filter with this value equals to true if they want to enforce by default this behaviour. I think that this a simpler idea for allow the developer to choose, and give some flexibility to the user to change the behaviour as its own risk (they can disable all filters anyway, which is also risky).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323698699
https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323698699:691,Usability,simpl,simpler,691,"For reporting the number of reads that fails each of the filters, the composed filter could be changed by a `CountingReadFilter`; using the `getSummaryLine()` method will provide the number of reads failing each of the components. Developers could have in their tools a field with the `WellFormedReadFilter` and call a new method for reporting the summary, to log a warning/debug line. For exploding depending on the tool, maybe an advance/hidden argument can be added to the filter (something like `--failOnMalformed`) to throw an exception if true; developers might add a default filter with this value equals to true if they want to enforce by default this behaviour. I think that this a simpler idea for allow the developer to choose, and give some flexibility to the user to change the behaviour as its own risk (they can disable all filters anyway, which is also risky).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323698699
https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323738847:409,Integrability,wrap,wrapping,409,"@magicDGS I think the context for this issue is the Pathogen sequence detection tools, which are Spark tools. `CountingReadFilter` isn't inherently reducible, and shouldn't be used in a Spark tool. Also, I can't say love the idea of using a filter as a control flow mechanism; but I don't have a better idea (maybe a separate tool as @mwalker174 mentioned above ?). One other note. As things currently stand, wrapping a WellFormedReadFilter in a counting filter (which we currently do for walkers) wouldn't give summary counts at the granular level, because WellFormedReadFilter is composed from non-CountingRead filters. Wrapping it yields a single, outer level summary/count. It would be easy enough to create one though that provided detailed summary/counts though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323738847
https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323738847:622,Integrability,Wrap,Wrapping,622,"@magicDGS I think the context for this issue is the Pathogen sequence detection tools, which are Spark tools. `CountingReadFilter` isn't inherently reducible, and shouldn't be used in a Spark tool. Also, I can't say love the idea of using a filter as a control flow mechanism; but I don't have a better idea (maybe a separate tool as @mwalker174 mentioned above ?). One other note. As things currently stand, wrapping a WellFormedReadFilter in a counting filter (which we currently do for walkers) wouldn't give summary counts at the granular level, because WellFormedReadFilter is composed from non-CountingRead filters. Wrapping it yields a single, outer level summary/count. It would be easy enough to create one though that provided detailed summary/counts though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323738847
https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323738847:70,Safety,detect,detection,70,"@magicDGS I think the context for this issue is the Pathogen sequence detection tools, which are Spark tools. `CountingReadFilter` isn't inherently reducible, and shouldn't be used in a Spark tool. Also, I can't say love the idea of using a filter as a control flow mechanism; but I don't have a better idea (maybe a separate tool as @mwalker174 mentioned above ?). One other note. As things currently stand, wrapping a WellFormedReadFilter in a counting filter (which we currently do for walkers) wouldn't give summary counts at the granular level, because WellFormedReadFilter is composed from non-CountingRead filters. Wrapping it yields a single, outer level summary/count. It would be easy enough to create one though that provided detailed summary/counts though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3454#issuecomment-323738847
https://github.com/broadinstitute/gatk/pull/3457#issuecomment-327257527:0,Availability,ping,ping,0,ping @cwhelan .,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3457#issuecomment-327257527
https://github.com/broadinstitute/gatk/issues/3459#issuecomment-323218384:103,Performance,perform,perform,103,"How to reproduce:. Modify the code in ```AlignmentIntervalUnitTest.testConstructionFromSAMRecord``` to perform a validation of the read returned by ```applyAlignment```:. ```; final SAMRecord samRecord = BwaMemAlignmentUtils.applyAlignment(""whatever"", SVDiscoveryTestDataProvider.makeDummySequence(expectedContigLength, (byte)'A'), null, null, bwaMemAlignment, refNames, hg19Header, false, false);; if (samRecord.isValid() != null) {; throw new IllegalStateException(samRecord.isValid().stream().map(s -> s.getMessage()).collect(Collectors.joining("", "")));; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459#issuecomment-323218384
https://github.com/broadinstitute/gatk/issues/3459#issuecomment-323218384:113,Security,validat,validation,113,"How to reproduce:. Modify the code in ```AlignmentIntervalUnitTest.testConstructionFromSAMRecord``` to perform a validation of the read returned by ```applyAlignment```:. ```; final SAMRecord samRecord = BwaMemAlignmentUtils.applyAlignment(""whatever"", SVDiscoveryTestDataProvider.makeDummySequence(expectedContigLength, (byte)'A'), null, null, bwaMemAlignment, refNames, hg19Header, false, false);; if (samRecord.isValid() != null) {; throw new IllegalStateException(samRecord.isValid().stream().map(s -> s.getMessage()).collect(Collectors.joining("", "")));; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459#issuecomment-323218384
https://github.com/broadinstitute/gatk/issues/3459#issuecomment-323218384:67,Testability,test,testConstructionFromSAMRecord,67,"How to reproduce:. Modify the code in ```AlignmentIntervalUnitTest.testConstructionFromSAMRecord``` to perform a validation of the read returned by ```applyAlignment```:. ```; final SAMRecord samRecord = BwaMemAlignmentUtils.applyAlignment(""whatever"", SVDiscoveryTestDataProvider.makeDummySequence(expectedContigLength, (byte)'A'), null, null, bwaMemAlignment, refNames, hg19Header, false, false);; if (samRecord.isValid() != null) {; throw new IllegalStateException(samRecord.isValid().stream().map(s -> s.getMessage()).collect(Collectors.joining("", "")));; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459#issuecomment-323218384
https://github.com/broadinstitute/gatk/issues/3459#issuecomment-453575941:173,Deployability,patch,patch,173,"Closing this ancient issue, since as @tedsharpe mentioned it appears to fix a problem that can't occur in practice. Feel free to re-open if someone feels strongly that this patch should go in.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3459#issuecomment-453575941
https://github.com/broadinstitute/gatk/issues/3460#issuecomment-351526174:50,Testability,test,testing,50,This will be done after Cromwell 30 and Firecloud testing is complete. We'll incorporate whatever changes were necessary to get those to pass as well as make the changes listed in #3940.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3460#issuecomment-351526174
https://github.com/broadinstitute/gatk/pull/3461#issuecomment-323443004:1242,Security,Validat,ValidateVariants,1242,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3461?src=pr&el=h1) Report; > Merging [#3461](https://codecov.io/gh/broadinstitute/gatk/pull/3461?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/a1292eecb05bc4c61abc33d7b01c81b29383a150?src=pr&el=desc) will **increase** coverage by `0.001%`.; > The diff coverage is `75%`. ```diff; @@ Coverage Diff @@; ## master #3461 +/- ##; ===============================================; + Coverage 80.307% 80.307% +0.001% ; - Complexity 17645 17666 +21 ; ===============================================; Files 1178 1178 ; Lines 63854 63907 +53 ; Branches 9930 9947 +17 ; ===============================================; + Hits 51279 51322 +43 ; - Misses 8627 8632 +5 ; - Partials 3948 3953 +5; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3461?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ute/hellbender/utils/bwa/BwaMemAlignmentUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3461?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9id2EvQndhTWVtQWxpZ25tZW50VXRpbHMuamF2YQ==) | `88.889% <75%> (-4.532%)` | `36 <26> (+5)` | |; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/3461?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYWxpZGF0ZVZhcmlhbnRzLmphdmE=) | `83.688% <0%> (+1.335%)` | `48% <0%> (+16%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3461#issuecomment-323443004
https://github.com/broadinstitute/gatk/pull/3461#issuecomment-323450988:30,Availability,toler,tolerant,30,"The change is fine: It's more tolerant of bogus input, and the cost is nearly 0.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3461#issuecomment-323450988
https://github.com/broadinstitute/gatk/pull/3461#issuecomment-453575860:170,Deployability,patch,patch,170,"Closing this ancient PR, since as @tedsharpe mentioned it appears to fix a problem that can't occur in practice. Feel free to re-open if someone feels strongly that this patch should go in.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3461#issuecomment-453575860
https://github.com/broadinstitute/gatk/pull/3464#issuecomment-323622997:2461,Usability,Simpl,SimpleStrandSwitchVariantDetector,2461,amF2YQ==) | `95% <> ()` | `18 <0> ()` | :arrow_down: |; | [.../hellbender/tools/spark/sv/utils/SVFastqUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3464?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVkZhc3RxVXRpbHMuamF2YQ==) | `65.152% <> (+1.849%)` | `5 <0> ()` | :arrow_down: |; | [.../sv/StructuralVariationDiscoveryPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3464?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5UGlwZWxpbmVTcGFyay5qYXZh) | `94.872% <> (-0.065%)` | `6 <0> ()` | |; | [...e/hellbender/tools/spark/sv/utils/SVVCFWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3464?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVlZDRldyaXRlci5qYXZh) | `86.047% <> ()` | `10 <0> ()` | :arrow_down: |; | [...y/prototype/SimpleStrandSwitchVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3464?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1NpbXBsZVN0cmFuZFN3aXRjaFZhcmlhbnREZXRlY3Rvci5qYXZh) | `27.848% <0%> (-4.744%)` | `13 <0> ()` | |; | [.../sv/discovery/prototype/InsDelVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3464?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL0luc0RlbFZhcmlhbnREZXRlY3Rvci5qYXZh) | `0% <0%> ()` | `0 <0> ()` | :arrow_down: |; | [...tools/spark/sv/sga/AlignAssembledContigsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3464?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9zZ2EvQWxpZ25Bc3NlbWJsZWRDb250aWdzU3BhcmsuamF2YQ==) | `100% <100%> (+2.222%)` | `12 <0> ()` | :arrow_down: |; | [.../DiscoverVariantsFromContigAlignmentsSAMSpark.jav,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3464#issuecomment-323622997
https://github.com/broadinstitute/gatk/pull/3464#issuecomment-327882765:147,Usability,simpl,simple,147,"This brings to us approximately 60 variants (without any filter applied). @cwhelan Please take time to review, another PR (supposedly dealing with simple ""translocation""s) is going to line up after this. Then the major graph-based one, but expected to take sometime to codeup. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3464#issuecomment-327882765
https://github.com/broadinstitute/gatk/pull/3464#issuecomment-331931810:94,Availability,down,downstream,94,"@cwhelan , after our offline discussion about how to make the insertion annotation easier for downstream analysis, I went back and did a check on how insertion annotation are extracted, and here's a summary:. Keys: NARL&mdash;NovelAdjacencyReferenceLocations, CA&mdash;ChimericAlignment, BC&mdash;BreakpointComplications. * NARL contains {mate breakpoint locations, orientation change between the breakpoints, complications around the breakpoint}, where the complication is mainly used for two purposes: 1) adjusting the exact locations of the breakpoints, and 2) useful for downstream annotations for the associated VCF records.; * NARL is constructed from an input CA, which in turn has two ways of being constructed: 1) deliberate construction with two neighboring alignments on the contig, 2) construction from an input contig whose alignments are scanned through in a semi pair-wise fashion. The second way is the master version currently in use in out pipeline, and is planned to be phased out eventually. Note that the second way extracts neighboring alignments that it considers good quality and send the information to the first version for actual construction. ; * The ctor for CA that takes two neighboring alignments also takes in a string representation of mapping locations of suspected insertions. In master version, this information is extracted from the alignments that are considered not strong enough, e.g. lower MQ, shorter alignment length, but the actual inserted sequence is not extracted in CA, but rather in BC.; * The BC field in NARL, holding inserted sequence, micro-homology and other information (e.g. for duplication), does not contain where the inserted sequence, if any, is mapped, and the inserted sequence is extracted from the distance on the contig between two neighboring alignments stored in the input CA.; * The variant, after its NARL locations are pinned down, is annotated by information stored in both CA and BC, where the information for BC is critical for",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3464#issuecomment-331931810
https://github.com/broadinstitute/gatk/pull/3464#issuecomment-331931810:575,Availability,down,downstream,575,"@cwhelan , after our offline discussion about how to make the insertion annotation easier for downstream analysis, I went back and did a check on how insertion annotation are extracted, and here's a summary:. Keys: NARL&mdash;NovelAdjacencyReferenceLocations, CA&mdash;ChimericAlignment, BC&mdash;BreakpointComplications. * NARL contains {mate breakpoint locations, orientation change between the breakpoints, complications around the breakpoint}, where the complication is mainly used for two purposes: 1) adjusting the exact locations of the breakpoints, and 2) useful for downstream annotations for the associated VCF records.; * NARL is constructed from an input CA, which in turn has two ways of being constructed: 1) deliberate construction with two neighboring alignments on the contig, 2) construction from an input contig whose alignments are scanned through in a semi pair-wise fashion. The second way is the master version currently in use in out pipeline, and is planned to be phased out eventually. Note that the second way extracts neighboring alignments that it considers good quality and send the information to the first version for actual construction. ; * The ctor for CA that takes two neighboring alignments also takes in a string representation of mapping locations of suspected insertions. In master version, this information is extracted from the alignments that are considered not strong enough, e.g. lower MQ, shorter alignment length, but the actual inserted sequence is not extracted in CA, but rather in BC.; * The BC field in NARL, holding inserted sequence, micro-homology and other information (e.g. for duplication), does not contain where the inserted sequence, if any, is mapped, and the inserted sequence is extracted from the distance on the contig between two neighboring alignments stored in the input CA.; * The variant, after its NARL locations are pinned down, is annotated by information stored in both CA and BC, where the information for BC is critical for",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3464#issuecomment-331931810
https://github.com/broadinstitute/gatk/pull/3464#issuecomment-331931810:1897,Availability,down,down,1897,"breakpoint}, where the complication is mainly used for two purposes: 1) adjusting the exact locations of the breakpoints, and 2) useful for downstream annotations for the associated VCF records.; * NARL is constructed from an input CA, which in turn has two ways of being constructed: 1) deliberate construction with two neighboring alignments on the contig, 2) construction from an input contig whose alignments are scanned through in a semi pair-wise fashion. The second way is the master version currently in use in out pipeline, and is planned to be phased out eventually. Note that the second way extracts neighboring alignments that it considers good quality and send the information to the first version for actual construction. ; * The ctor for CA that takes two neighboring alignments also takes in a string representation of mapping locations of suspected insertions. In master version, this information is extracted from the alignments that are considered not strong enough, e.g. lower MQ, shorter alignment length, but the actual inserted sequence is not extracted in CA, but rather in BC.; * The BC field in NARL, holding inserted sequence, micro-homology and other information (e.g. for duplication), does not contain where the inserted sequence, if any, is mapped, and the inserted sequence is extracted from the distance on the contig between two neighboring alignments stored in the input CA.; * The variant, after its NARL locations are pinned down, is annotated by information stored in both CA and BC, where the information for BC is critical for reconstructing the alt haplotype and those in CA mainly for evaluating evidence strength. . Hence we should put the suspected inserted sequence and mapping in the same class, proposed to be in BC. But I think this PR is getting bigger than it should be, and the cigar operation is what I now need for the graph-based cpx sv detection. So I am thinking of creating a ticket for this issue, and follow up in a month. What you do think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3464#issuecomment-331931810
https://github.com/broadinstitute/gatk/pull/3464#issuecomment-331931810:958,Deployability,pipeline,pipeline,958,"@cwhelan , after our offline discussion about how to make the insertion annotation easier for downstream analysis, I went back and did a check on how insertion annotation are extracted, and here's a summary:. Keys: NARL&mdash;NovelAdjacencyReferenceLocations, CA&mdash;ChimericAlignment, BC&mdash;BreakpointComplications. * NARL contains {mate breakpoint locations, orientation change between the breakpoints, complications around the breakpoint}, where the complication is mainly used for two purposes: 1) adjusting the exact locations of the breakpoints, and 2) useful for downstream annotations for the associated VCF records.; * NARL is constructed from an input CA, which in turn has two ways of being constructed: 1) deliberate construction with two neighboring alignments on the contig, 2) construction from an input contig whose alignments are scanned through in a semi pair-wise fashion. The second way is the master version currently in use in out pipeline, and is planned to be phased out eventually. Note that the second way extracts neighboring alignments that it considers good quality and send the information to the first version for actual construction. ; * The ctor for CA that takes two neighboring alignments also takes in a string representation of mapping locations of suspected insertions. In master version, this information is extracted from the alignments that are considered not strong enough, e.g. lower MQ, shorter alignment length, but the actual inserted sequence is not extracted in CA, but rather in BC.; * The BC field in NARL, holding inserted sequence, micro-homology and other information (e.g. for duplication), does not contain where the inserted sequence, if any, is mapped, and the inserted sequence is extracted from the distance on the contig between two neighboring alignments stored in the input CA.; * The variant, after its NARL locations are pinned down, is annotated by information stored in both CA and BC, where the information for BC is critical for",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3464#issuecomment-331931810
https://github.com/broadinstitute/gatk/pull/3464#issuecomment-331931810:2326,Safety,detect,detection,2326,"breakpoint}, where the complication is mainly used for two purposes: 1) adjusting the exact locations of the breakpoints, and 2) useful for downstream annotations for the associated VCF records.; * NARL is constructed from an input CA, which in turn has two ways of being constructed: 1) deliberate construction with two neighboring alignments on the contig, 2) construction from an input contig whose alignments are scanned through in a semi pair-wise fashion. The second way is the master version currently in use in out pipeline, and is planned to be phased out eventually. Note that the second way extracts neighboring alignments that it considers good quality and send the information to the first version for actual construction. ; * The ctor for CA that takes two neighboring alignments also takes in a string representation of mapping locations of suspected insertions. In master version, this information is extracted from the alignments that are considered not strong enough, e.g. lower MQ, shorter alignment length, but the actual inserted sequence is not extracted in CA, but rather in BC.; * The BC field in NARL, holding inserted sequence, micro-homology and other information (e.g. for duplication), does not contain where the inserted sequence, if any, is mapped, and the inserted sequence is extracted from the distance on the contig between two neighboring alignments stored in the input CA.; * The variant, after its NARL locations are pinned down, is annotated by information stored in both CA and BC, where the information for BC is critical for reconstructing the alt haplotype and those in CA mainly for evaluating evidence strength. . Hence we should put the suspected inserted sequence and mapping in the same class, proposed to be in BC. But I think this PR is getting bigger than it should be, and the cigar operation is what I now need for the graph-based cpx sv detection. So I am thinking of creating a ticket for this issue, and follow up in a month. What you do think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3464#issuecomment-331931810
https://github.com/broadinstitute/gatk/issues/3465#issuecomment-324064738:52,Integrability,depend,depend,52,"Hi @hh1985 . Memory tuning is pretty tricky and can depend on a lot of things. How is your cluster configured? ; Are you using YARN? Are you running in client or cluster mode? . I'm assuming you're running with YARN. Mesos should also work but I don't have any experience configuring it. . BQSR should run safely with 4g of memory per core. (It should really work with much less I think, but 4 should definitely be sufficient.) There are a few different parameters that can help you adjust the memory ratios.; A good tuning might be something like; ; ```; --num-executors 5 ; --executor-cores 8 ; --executor-memory 32g ; ```. if you're not running with gatk-launch you'll need to set; ```; --conf spark.yarn.executor.memoryOverhead=600; ```; Without setting a higher than default yarn memory overhead like this we see consistent crashes, it's included in the settings gatk-launch applies already. That should run 5 separate executors with 8 cores each and give each one 32g, so 4g / core. . If you're running in cluster mode you'll have to carve out some memory and cores for the driver. You can set the driver settings with ; ```; --driver-cores 2; --driver-memory 4g; ``` ; or something along those lines. The driver doesn't need much memory or computer for BQSR. In general we've had better luck using the entire cluster for one job and running jobs in sequence rather than trying to run two jobs simultaneously using a subset of the cluster.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3465#issuecomment-324064738
https://github.com/broadinstitute/gatk/issues/3465#issuecomment-324064738:99,Modifiability,config,configured,99,"Hi @hh1985 . Memory tuning is pretty tricky and can depend on a lot of things. How is your cluster configured? ; Are you using YARN? Are you running in client or cluster mode? . I'm assuming you're running with YARN. Mesos should also work but I don't have any experience configuring it. . BQSR should run safely with 4g of memory per core. (It should really work with much less I think, but 4 should definitely be sufficient.) There are a few different parameters that can help you adjust the memory ratios.; A good tuning might be something like; ; ```; --num-executors 5 ; --executor-cores 8 ; --executor-memory 32g ; ```. if you're not running with gatk-launch you'll need to set; ```; --conf spark.yarn.executor.memoryOverhead=600; ```; Without setting a higher than default yarn memory overhead like this we see consistent crashes, it's included in the settings gatk-launch applies already. That should run 5 separate executors with 8 cores each and give each one 32g, so 4g / core. . If you're running in cluster mode you'll have to carve out some memory and cores for the driver. You can set the driver settings with ; ```; --driver-cores 2; --driver-memory 4g; ``` ; or something along those lines. The driver doesn't need much memory or computer for BQSR. In general we've had better luck using the entire cluster for one job and running jobs in sequence rather than trying to run two jobs simultaneously using a subset of the cluster.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3465#issuecomment-324064738
https://github.com/broadinstitute/gatk/issues/3465#issuecomment-324064738:272,Modifiability,config,configuring,272,"Hi @hh1985 . Memory tuning is pretty tricky and can depend on a lot of things. How is your cluster configured? ; Are you using YARN? Are you running in client or cluster mode? . I'm assuming you're running with YARN. Mesos should also work but I don't have any experience configuring it. . BQSR should run safely with 4g of memory per core. (It should really work with much less I think, but 4 should definitely be sufficient.) There are a few different parameters that can help you adjust the memory ratios.; A good tuning might be something like; ; ```; --num-executors 5 ; --executor-cores 8 ; --executor-memory 32g ; ```. if you're not running with gatk-launch you'll need to set; ```; --conf spark.yarn.executor.memoryOverhead=600; ```; Without setting a higher than default yarn memory overhead like this we see consistent crashes, it's included in the settings gatk-launch applies already. That should run 5 separate executors with 8 cores each and give each one 32g, so 4g / core. . If you're running in cluster mode you'll have to carve out some memory and cores for the driver. You can set the driver settings with ; ```; --driver-cores 2; --driver-memory 4g; ``` ; or something along those lines. The driver doesn't need much memory or computer for BQSR. In general we've had better luck using the entire cluster for one job and running jobs in sequence rather than trying to run two jobs simultaneously using a subset of the cluster.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3465#issuecomment-324064738
https://github.com/broadinstitute/gatk/issues/3465#issuecomment-324064738:306,Safety,safe,safely,306,"Hi @hh1985 . Memory tuning is pretty tricky and can depend on a lot of things. How is your cluster configured? ; Are you using YARN? Are you running in client or cluster mode? . I'm assuming you're running with YARN. Mesos should also work but I don't have any experience configuring it. . BQSR should run safely with 4g of memory per core. (It should really work with much less I think, but 4 should definitely be sufficient.) There are a few different parameters that can help you adjust the memory ratios.; A good tuning might be something like; ; ```; --num-executors 5 ; --executor-cores 8 ; --executor-memory 32g ; ```. if you're not running with gatk-launch you'll need to set; ```; --conf spark.yarn.executor.memoryOverhead=600; ```; Without setting a higher than default yarn memory overhead like this we see consistent crashes, it's included in the settings gatk-launch applies already. That should run 5 separate executors with 8 cores each and give each one 32g, so 4g / core. . If you're running in cluster mode you'll have to carve out some memory and cores for the driver. You can set the driver settings with ; ```; --driver-cores 2; --driver-memory 4g; ``` ; or something along those lines. The driver doesn't need much memory or computer for BQSR. In general we've had better luck using the entire cluster for one job and running jobs in sequence rather than trying to run two jobs simultaneously using a subset of the cluster.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3465#issuecomment-324064738
https://github.com/broadinstitute/gatk/issues/3465#issuecomment-324066954:295,Deployability,install,installing,295,"It just occured to me that you probably meant you were running with `--sparkMaster local[4]` not, on a local cluster (vs a cluster in the cloud). In that case disregard my previous advice. Running a single process spark isn't going to scale well to 40 cores whatever you do, you'd be better off installing spark locally on your machine and running it as a single node cluster than running in the local mode. . If you want to run with master local, the biggest thing is probably to set -Xmx high enough, I'd set it as all of your memory - some overhead for the OS. Maybe try something like:; `-Xmx 140G -XX:ParallelGCThreads=6 --sparkMasterLocal[40]",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3465#issuecomment-324066954
https://github.com/broadinstitute/gatk/issues/3466#issuecomment-352183647:133,Testability,test,test,133,@droazen @vdauwera -- sorry to bump this but I'm hitting this problem with additional unrelated samples and could provide additional test cases if this isn't enough to debug. Thanks much.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3466#issuecomment-352183647
https://github.com/broadinstitute/gatk/issues/3466#issuecomment-355649619:38,Deployability,release,release,38,We hope to have this fixed by the 4.0 release on tuesday.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3466#issuecomment-355649619
https://github.com/broadinstitute/gatk/issues/3468#issuecomment-324932250:18,Testability,test,tested,18,I've created (and tested) a fix in jsr203-hadoop: https://github.com/damiencarol/jsr203-hadoop/pull/32,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3468#issuecomment-324932250
https://github.com/broadinstitute/gatk/pull/3469#issuecomment-324204507:725,Availability,error,errors,725,"Re: strandedness, while it would be much easier not to have to track strand (and would probably save me from writing a lot of bugs), I think that we do need to do so if we ever want these data elements to be used for calling more complicated events like inversions or translocations. For example, for inversions we need to record whether we saw evidence linking +/+ strands or -/- strands, since the breakpoints might appear different at the two junctions due to insertions or deletions. For translocations, you definitely need to know which strands were involved so that you can extrapolate the rest of the event from the breakpoint. Agreed that it's a pain to keep track of it, though, and I find myself introducing strand errors all the time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-324204507
https://github.com/broadinstitute/gatk/pull/3469#issuecomment-324467678:125,Integrability,depend,dependency,125,"Sorry. I get your thinking, but I think it would be cleaner to pass the param to each of those two classes. It cleans up the dependency tree -- those two classes don't depend on any of the ReadMetadata state but for that one param -- and avoids having to have the SVReadFilter be both Java and Kryo serializable. I'd prefer it, but won't insist upon it.; Adding the filter values to the read metadata output file makes sense, though. Doesn't need to be done now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-324467678
https://github.com/broadinstitute/gatk/pull/3469#issuecomment-324467678:168,Integrability,depend,depend,168,"Sorry. I get your thinking, but I think it would be cleaner to pass the param to each of those two classes. It cleans up the dependency tree -- those two classes don't depend on any of the ReadMetadata state but for that one param -- and avoids having to have the SVReadFilter be both Java and Kryo serializable. I'd prefer it, but won't insist upon it.; Adding the filter values to the read metadata output file makes sense, though. Doesn't need to be done now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-324467678
https://github.com/broadinstitute/gatk/pull/3469#issuecomment-324467678:238,Safety,avoid,avoids,238,"Sorry. I get your thinking, but I think it would be cleaner to pass the param to each of those two classes. It cleans up the dependency tree -- those two classes don't depend on any of the ReadMetadata state but for that one param -- and avoids having to have the SVReadFilter be both Java and Kryo serializable. I'd prefer it, but won't insist upon it.; Adding the filter values to the read metadata output file makes sense, though. Doesn't need to be done now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-324467678
https://github.com/broadinstitute/gatk/pull/3469#issuecomment-326088993:601,Testability,test,test,601,"I've tried to study the code that turns a split read into a stranded interval pair so that it can be compared directly to the disparate read pair info, and I can't convince myself that it's correct. There seem to be a bunch of cases that aren't covered. For example, it seems to me that the first step would have to be reversing the cigars on negative strand SA's, so that you can see which pairs of SA's are genuinely supplemental to -- and potentially partially overlapping -- each other, and the actual order of the aligned sequences. (I'm sure this is unclear, too. We can talk.). Is there a unit test that mocks the reads we'd expect to get from an inversion breakpoint, both discordant and split. And that demonstrates that the stranded interval pairs generated from the reads are consistent with each other and with that breakpoint?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-326088993
https://github.com/broadinstitute/gatk/pull/3469#issuecomment-326088993:611,Testability,mock,mocks,611,"I've tried to study the code that turns a split read into a stranded interval pair so that it can be compared directly to the disparate read pair info, and I can't convince myself that it's correct. There seem to be a bunch of cases that aren't covered. For example, it seems to me that the first step would have to be reversing the cigars on negative strand SA's, so that you can see which pairs of SA's are genuinely supplemental to -- and potentially partially overlapping -- each other, and the actual order of the aligned sequences. (I'm sure this is unclear, too. We can talk.). Is there a unit test that mocks the reads we'd expect to get from an inversion breakpoint, both discordant and split. And that demonstrates that the stranded interval pairs generated from the reads are consistent with each other and with that breakpoint?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-326088993
https://github.com/broadinstitute/gatk/pull/3469#issuecomment-328300806:881,Performance,optimiz,optimizations,881,"@tedsharpe I've addressed some of your comments here -- all the simpler stuff plus:. - I now only make distal targets for split reads with one supplementary alignment. We can make a ticket to handle more complex cases at some point.; - I renamed the concept of strand in the `EvidenceTargetLink` and related classes -- I'm now calling it `evidenceUpstreamOfBreakpoint`.; - I canonicalize `EvidenceTargetLinks` and only create them when the source is upstream of the target. This allowed me to get rid of the de-duplication code, so thanks for the suggestion. It seemed tricky to me to try to cluster these links during the initial pass over the reads while at the same time keeping track of coherent evidence. In my testing it doesn't seem like it is slow to run over the `EvidenceRDD` again to do this, but we could think about trying to change this sometime if we're looking for optimizations. . Want to take another look?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-328300806
https://github.com/broadinstitute/gatk/pull/3469#issuecomment-328300806:716,Testability,test,testing,716,"@tedsharpe I've addressed some of your comments here -- all the simpler stuff plus:. - I now only make distal targets for split reads with one supplementary alignment. We can make a ticket to handle more complex cases at some point.; - I renamed the concept of strand in the `EvidenceTargetLink` and related classes -- I'm now calling it `evidenceUpstreamOfBreakpoint`.; - I canonicalize `EvidenceTargetLinks` and only create them when the source is upstream of the target. This allowed me to get rid of the de-duplication code, so thanks for the suggestion. It seemed tricky to me to try to cluster these links during the initial pass over the reads while at the same time keeping track of coherent evidence. In my testing it doesn't seem like it is slow to run over the `EvidenceRDD` again to do this, but we could think about trying to change this sometime if we're looking for optimizations. . Want to take another look?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-328300806
https://github.com/broadinstitute/gatk/pull/3469#issuecomment-328300806:64,Usability,simpl,simpler,64,"@tedsharpe I've addressed some of your comments here -- all the simpler stuff plus:. - I now only make distal targets for split reads with one supplementary alignment. We can make a ticket to handle more complex cases at some point.; - I renamed the concept of strand in the `EvidenceTargetLink` and related classes -- I'm now calling it `evidenceUpstreamOfBreakpoint`.; - I canonicalize `EvidenceTargetLinks` and only create them when the source is upstream of the target. This allowed me to get rid of the de-duplication code, so thanks for the suggestion. It seemed tricky to me to try to cluster these links during the initial pass over the reads while at the same time keeping track of coherent evidence. In my testing it doesn't seem like it is slow to run over the `EvidenceRDD` again to do this, but we could think about trying to change this sometime if we're looking for optimizations. . Want to take another look?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-328300806
https://github.com/broadinstitute/gatk/pull/3469#issuecomment-328935711:519,Security,validat,validate,519,"It would be nice to have a StrandedInterval class, and then the distal targets could be stored as one of these in the various BreakpointEvidence subclasses that have distal targets, and the PairedStrandedIntervals class could just have two of them. This would also let you eliminate the methods hasDistalTargets and getDistalTargetsUpstreamOfBreakpoints -- getDistalTargets would do the job of all three.; I assume that PairedStrandedIntervals shouldn't ever have null intervals for source or target, so you could just validate in the constructor and then you wouldn't have to test nullness in equals and hashCode.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-328935711
https://github.com/broadinstitute/gatk/pull/3469#issuecomment-328935711:605,Security,hash,hashCode,605,"It would be nice to have a StrandedInterval class, and then the distal targets could be stored as one of these in the various BreakpointEvidence subclasses that have distal targets, and the PairedStrandedIntervals class could just have two of them. This would also let you eliminate the methods hasDistalTargets and getDistalTargetsUpstreamOfBreakpoints -- getDistalTargets would do the job of all three.; I assume that PairedStrandedIntervals shouldn't ever have null intervals for source or target, so you could just validate in the constructor and then you wouldn't have to test nullness in equals and hashCode.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-328935711
https://github.com/broadinstitute/gatk/pull/3469#issuecomment-328935711:577,Testability,test,test,577,"It would be nice to have a StrandedInterval class, and then the distal targets could be stored as one of these in the various BreakpointEvidence subclasses that have distal targets, and the PairedStrandedIntervals class could just have two of them. This would also let you eliminate the methods hasDistalTargets and getDistalTargetsUpstreamOfBreakpoints -- getDistalTargets would do the job of all three.; I assume that PairedStrandedIntervals shouldn't ever have null intervals for source or target, so you could just validate in the constructor and then you wouldn't have to test nullness in equals and hashCode.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3469#issuecomment-328935711
https://github.com/broadinstitute/gatk/issues/3471#issuecomment-324070716:50,Deployability,configurat,configuration,50,Agreed! And also with default value stored in the configuration file.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3471#issuecomment-324070716
https://github.com/broadinstitute/gatk/issues/3471#issuecomment-324070716:50,Modifiability,config,configuration,50,Agreed! And also with default value stored in the configuration file.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3471#issuecomment-324070716
https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324062155:118,Deployability,integrat,integration,118,@DonFreed Both of these changes look more correct than what we were doing before. But as louis pointed out two of the integration tests failed on parsing the header. You should fix these tests.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324062155
https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324062155:118,Integrability,integrat,integration,118,@DonFreed Both of these changes look more correct than what we were doing before. But as louis pointed out two of the integration tests failed on parsing the header. You should fix these tests.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324062155
https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324062155:130,Testability,test,tests,130,@DonFreed Both of these changes look more correct than what we were doing before. But as louis pointed out two of the integration tests failed on parsing the header. You should fix these tests.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324062155
https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324062155:187,Testability,test,tests,187,@DonFreed Both of these changes look more correct than what we were doing before. But as louis pointed out two of the integration tests failed on parsing the header. You should fix these tests.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324062155
https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324067644:152,Testability,test,tests,152,"I don't want the palantir evaluation to be any more complicated than it needs to be, and I'm also in the process of ripping apart the `HaplotypeCaller` tests in another branch -- let's put this PR on hold until after that's done.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324067644
https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324413672:2142,Testability,test,test,2142,VEtWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `99.265% <100%> ()` | `7 <0> ()` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3472?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3472?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3472?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3472?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3472?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3472?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `55.263% <0%> (-19.079%)` | `30% <0%> (-8%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3472?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGV,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324413672
https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324413672:3592,Testability,test,test,3592,W4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3472?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3472?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3472?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `55.263% <0%> (-19.079%)` | `30% <0%> (-8%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3472?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3472?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `70.37% <0%> (-11.111%)` | `10% <0%> ()` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3472?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | ... and [20 more](https://codecov.io/gh/broadinstitute/gatk/pull/3472?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324413672
https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324430072:32,Deployability,update,updated,32,Sorry I missed the test case. I updated the header of the test case so the pull request passes the integration tests. Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324430072
https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324430072:99,Deployability,integrat,integration,99,Sorry I missed the test case. I updated the header of the test case so the pull request passes the integration tests. Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324430072
https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324430072:99,Integrability,integrat,integration,99,Sorry I missed the test case. I updated the header of the test case so the pull request passes the integration tests. Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324430072
https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324430072:19,Testability,test,test,19,Sorry I missed the test case. I updated the header of the test case so the pull request passes the integration tests. Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324430072
https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324430072:58,Testability,test,test,58,Sorry I missed the test case. I updated the header of the test case so the pull request passes the integration tests. Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324430072
https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324430072:111,Testability,test,tests,111,Sorry I missed the test case. I updated the header of the test case so the pull request passes the integration tests. Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324430072
https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324446155:165,Deployability,update,updated,165,"@DonFreed Thanks for the fix, though unfortunately as @droazen says the branch is going to have to be on hold for a little while until the Haplotype Caller has been updated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3472#issuecomment-324446155
https://github.com/broadinstitute/gatk/pull/3474#issuecomment-325007520:927,Deployability,pipeline,pipelines,927,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3474?src=pr&el=h1) Report; > Merging [#3474](https://codecov.io/gh/broadinstitute/gatk/pull/3474?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/bfa9af462f484c77597a9fdbdc46f66393afaff1?src=pr&el=desc) will **increase** coverage by `0.008%`.; > The diff coverage is `84.615%`. ```diff; @@ Coverage Diff @@; ## master #3474 +/- ##; ===============================================; + Coverage 80.079% 80.087% +0.008% ; - Complexity 17760 17762 +2 ; ===============================================; Files 1188 1188 ; Lines 64410 64415 +5 ; Branches 10004 10006 +2 ; ===============================================; + Hits 51579 51588 +9 ; + Misses 8845 8840 -5 ; - Partials 3986 3987 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3474?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3474?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `76.471% <100%> ()` | `4 <0> ()` | :arrow_down: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3474?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `69.231% <100%> (+2.564%)` | `5 <0> (+1)` | :arrow_up: |; | [...tute/hellbender/tools/BwaMemIndexImageCreator.java](https://codecov.io/gh/broadinstitute/gatk/pull/3474?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Cd2FNZW1JbmRleEltYWdlQ3JlYXRvci5qYXZh) | `71.429% <50%> ()` | `2 <0> ()` | :arrow_down: |; | [...ute/hellbender/tools/spark/bwa/BwaSparkEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/3474?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGU,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3474#issuecomment-325007520
https://github.com/broadinstitute/gatk/pull/3474#issuecomment-325028831:20,Testability,Test,Tests,20,Addressed comments. Tests pass. Notice that now src/test/java/org/broadinstitute/hellbender/BwaMemIntegrationTest.java takes longer to run (3+ minutes) due to the change from creating the image from the index file to using the fasta file. Just giving you the heads-up. @tedsharpe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3474#issuecomment-325028831
https://github.com/broadinstitute/gatk/pull/3474#issuecomment-325028831:52,Testability,test,test,52,Addressed comments. Tests pass. Notice that now src/test/java/org/broadinstitute/hellbender/BwaMemIntegrationTest.java takes longer to run (3+ minutes) due to the change from creating the image from the index file to using the fasta file. Just giving you the heads-up. @tedsharpe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3474#issuecomment-325028831
https://github.com/broadinstitute/gatk/pull/3474#issuecomment-325029200:12,Deployability,update,update,12,"I forgot to update the docs about the no need for index files... will do that before merging, anything else that needs to be changed?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3474#issuecomment-325029200
https://github.com/broadinstitute/gatk/pull/3474#issuecomment-325512779:33,Testability,test,test,33,"Addresses the last comment, once test pass this can be merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3474#issuecomment-325512779
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324065340:49,Testability,test,test,49,Here is a new PR for the issues related with the test code. Back to you @droazen.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324065340
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324295384:12,Deployability,update,updated,12,"@droazen, I updated the PR message to describe the changes, because I tried to get all the code referring to test resources packaged in src/test. Now it should pass the tests too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324295384
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324295384:27,Integrability,message,message,27,"@droazen, I updated the PR message to describe the changes, because I tried to get all the code referring to test resources packaged in src/test. Now it should pass the tests too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324295384
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324295384:109,Testability,test,test,109,"@droazen, I updated the PR message to describe the changes, because I tried to get all the code referring to test resources packaged in src/test. Now it should pass the tests too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324295384
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324295384:140,Testability,test,test,140,"@droazen, I updated the PR message to describe the changes, because I tried to get all the code referring to test resources packaged in src/test. Now it should pass the tests too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324295384
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324295384:169,Testability,test,tests,169,"@droazen, I updated the PR message to describe the changes, because I tried to get all the code referring to test resources packaged in src/test. Now it should pass the tests too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324295384
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700:3005,Deployability,pipeline,pipelines,3005,GUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `100% <100%> ()` | `5 <2> (?)` | |; | [...ute/hellbender/utils/test/GenomicsDBTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0dlbm9taWNzREJUZXN0VXRpbHMuamF2YQ==) | `91.667% <100%> (-0.641%)` | `3 <0> ()` | |; | [...ils/test/testers/AbstractMarkDuplicatesTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvQWJzdHJhY3RNYXJrRHVwbGljYXRlc1Rlc3Rlci5qYXZh) | `79.487% <100%> ()` | `17 <1> ()` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | ... and [16 more](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700:962,Testability,test,test,962,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=h1) Report; > Merging [#3475](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/c798c8489d4f04687396ec3e1405b854e5360ce1?src=pr&el=desc) will **decrease** coverage by `0.54%`.; > The diff coverage is `85.714%`. ```diff; @@ Coverage Diff @@; ## master #3475 +/- ##; ==============================================; - Coverage 79.554% 79.014% -0.54% ; + Complexity 17738 17588 -150 ; ==============================================; Files 1154 1151 -3 ; Lines 64092 63666 -426 ; Branches 9757 9748 -9 ; ==============================================; - Hits 50988 50305 -683 ; - Misses 9214 9486 +272 ; + Partials 3890 3875 -15; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `70.707% <> (-13.116%)` | `27 <0> (-9)` | |; | [...e/hellbender/utils/test/testers/SamFileTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvU2FtRmlsZVRlc3Rlci5qYXZh) | `90.217% <> ()` | `30 <0> ()` | :arrow_down: |; | [.../hellbender/utils/test/testers/CleanSamTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvQ2xlYW5TYW1UZXN0ZXIuamF2YQ==) | `0% <0%> ()` | `0 <0> ()` | :arrow_down: |; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydm,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700:1221,Testability,test,test,1221,tk/commit/c798c8489d4f04687396ec3e1405b854e5360ce1?src=pr&el=desc) will **decrease** coverage by `0.54%`.; > The diff coverage is `85.714%`. ```diff; @@ Coverage Diff @@; ## master #3475 +/- ##; ==============================================; - Coverage 79.554% 79.014% -0.54% ; + Complexity 17738 17588 -150 ; ==============================================; Files 1154 1151 -3 ; Lines 64092 63666 -426 ; Branches 9757 9748 -9 ; ==============================================; - Hits 50988 50305 -683 ; - Misses 9214 9486 +272 ; + Partials 3890 3875 -15; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `70.707% <> (-13.116%)` | `27 <0> (-9)` | |; | [...e/hellbender/utils/test/testers/SamFileTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvU2FtRmlsZVRlc3Rlci5qYXZh) | `90.217% <> ()` | `30 <0> ()` | :arrow_down: |; | [.../hellbender/utils/test/testers/CleanSamTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvQ2xlYW5TYW1UZXN0ZXIuamF2YQ==) | `0% <0%> ()` | `0 <0> ()` | :arrow_down: |; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `100% <100%> ()` | `5 <2> (?)` | |; | [...ute/hellbender/utils/test/GenomicsDBTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700:1226,Testability,test,testers,1226,tk/commit/c798c8489d4f04687396ec3e1405b854e5360ce1?src=pr&el=desc) will **decrease** coverage by `0.54%`.; > The diff coverage is `85.714%`. ```diff; @@ Coverage Diff @@; ## master #3475 +/- ##; ==============================================; - Coverage 79.554% 79.014% -0.54% ; + Complexity 17738 17588 -150 ; ==============================================; Files 1154 1151 -3 ; Lines 64092 63666 -426 ; Branches 9757 9748 -9 ; ==============================================; - Hits 50988 50305 -683 ; - Misses 9214 9486 +272 ; + Partials 3890 3875 -15; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `70.707% <> (-13.116%)` | `27 <0> (-9)` | |; | [...e/hellbender/utils/test/testers/SamFileTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvU2FtRmlsZVRlc3Rlci5qYXZh) | `90.217% <> ()` | `30 <0> ()` | :arrow_down: |; | [.../hellbender/utils/test/testers/CleanSamTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvQ2xlYW5TYW1UZXN0ZXIuamF2YQ==) | `0% <0%> ()` | `0 <0> ()` | :arrow_down: |; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `100% <100%> ()` | `5 <2> (?)` | |; | [...ute/hellbender/utils/test/GenomicsDBTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700:1513,Testability,test,test,1513,7738 17588 -150 ; ==============================================; Files 1154 1151 -3 ; Lines 64092 63666 -426 ; Branches 9757 9748 -9 ; ==============================================; - Hits 50988 50305 -683 ; - Misses 9214 9486 +272 ; + Partials 3890 3875 -15; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `70.707% <> (-13.116%)` | `27 <0> (-9)` | |; | [...e/hellbender/utils/test/testers/SamFileTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvU2FtRmlsZVRlc3Rlci5qYXZh) | `90.217% <> ()` | `30 <0> ()` | :arrow_down: |; | [.../hellbender/utils/test/testers/CleanSamTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvQ2xlYW5TYW1UZXN0ZXIuamF2YQ==) | `0% <0%> ()` | `0 <0> ()` | :arrow_down: |; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `100% <100%> ()` | `5 <2> (?)` | |; | [...ute/hellbender/utils/test/GenomicsDBTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0dlbm9taWNzREJUZXN0VXRpbHMuamF2YQ==) | `91.667% <100%> (-0.641%)` | `3 <0> ()` | |; | [...ils/test/testers/AbstractMarkDuplicatesTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRp,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700:1518,Testability,test,testers,1518,7738 17588 -150 ; ==============================================; Files 1154 1151 -3 ; Lines 64092 63666 -426 ; Branches 9757 9748 -9 ; ==============================================; - Hits 50988 50305 -683 ; - Misses 9214 9486 +272 ; + Partials 3890 3875 -15; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `70.707% <> (-13.116%)` | `27 <0> (-9)` | |; | [...e/hellbender/utils/test/testers/SamFileTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvU2FtRmlsZVRlc3Rlci5qYXZh) | `90.217% <> ()` | `30 <0> ()` | :arrow_down: |; | [.../hellbender/utils/test/testers/CleanSamTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvQ2xlYW5TYW1UZXN0ZXIuamF2YQ==) | `0% <0%> ()` | `0 <0> ()` | :arrow_down: |; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `100% <100%> ()` | `5 <2> (?)` | |; | [...ute/hellbender/utils/test/GenomicsDBTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0dlbm9taWNzREJUZXN0VXRpbHMuamF2YQ==) | `91.667% <100%> (-0.641%)` | `3 <0> ()` | |; | [...ils/test/testers/AbstractMarkDuplicatesTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRp,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700:1802,Testability,test,test,1802,//codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `70.707% <> (-13.116%)` | `27 <0> (-9)` | |; | [...e/hellbender/utils/test/testers/SamFileTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvU2FtRmlsZVRlc3Rlci5qYXZh) | `90.217% <> ()` | `30 <0> ()` | :arrow_down: |; | [.../hellbender/utils/test/testers/CleanSamTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvQ2xlYW5TYW1UZXN0ZXIuamF2YQ==) | `0% <0%> ()` | `0 <0> ()` | :arrow_down: |; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `100% <100%> ()` | `5 <2> (?)` | |; | [...ute/hellbender/utils/test/GenomicsDBTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0dlbm9taWNzREJUZXN0VXRpbHMuamF2YQ==) | `91.667% <100%> (-0.641%)` | `3 <0> ()` | |; | [...ils/test/testers/AbstractMarkDuplicatesTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvQWJzdHJhY3RNYXJrRHVwbGljYXRlc1Rlc3Rlci5qYXZh) | `79.487% <100%> ()` | `17 <1> ()` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21h,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700:2095,Testability,test,test,2095,vaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `70.707% <> (-13.116%)` | `27 <0> (-9)` | |; | [...e/hellbender/utils/test/testers/SamFileTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvU2FtRmlsZVRlc3Rlci5qYXZh) | `90.217% <> ()` | `30 <0> ()` | :arrow_down: |; | [.../hellbender/utils/test/testers/CleanSamTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvQ2xlYW5TYW1UZXN0ZXIuamF2YQ==) | `0% <0%> ()` | `0 <0> ()` | :arrow_down: |; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `100% <100%> ()` | `5 <2> (?)` | |; | [...ute/hellbender/utils/test/GenomicsDBTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0dlbm9taWNzREJUZXN0VXRpbHMuamF2YQ==) | `91.667% <100%> (-0.641%)` | `3 <0> ()` | |; | [...ils/test/testers/AbstractMarkDuplicatesTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvQWJzdHJhY3RNYXJrRHVwbGljYXRlc1Rlc3Rlci5qYXZh) | `79.487% <100%> ()` | `17 <1> ()` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=p,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700:2366,Testability,test,test,2366,1dGlscy90ZXN0L3Rlc3RlcnMvU2FtRmlsZVRlc3Rlci5qYXZh) | `90.217% <> ()` | `30 <0> ()` | :arrow_down: |; | [.../hellbender/utils/test/testers/CleanSamTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvQ2xlYW5TYW1UZXN0ZXIuamF2YQ==) | `0% <0%> ()` | `0 <0> ()` | :arrow_down: |; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `100% <100%> ()` | `5 <2> (?)` | |; | [...ute/hellbender/utils/test/GenomicsDBTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0dlbm9taWNzREJUZXN0VXRpbHMuamF2YQ==) | `91.667% <100%> (-0.641%)` | `3 <0> ()` | |; | [...ils/test/testers/AbstractMarkDuplicatesTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvQWJzdHJhY3RNYXJrRHVwbGljYXRlc1Rlc3Rlci5qYXZh) | `79.487% <100%> ()` | `17 <1> ()` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700:2371,Testability,test,testers,2371,1dGlscy90ZXN0L3Rlc3RlcnMvU2FtRmlsZVRlc3Rlci5qYXZh) | `90.217% <> ()` | `30 <0> ()` | :arrow_down: |; | [.../hellbender/utils/test/testers/CleanSamTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvQ2xlYW5TYW1UZXN0ZXIuamF2YQ==) | `0% <0%> ()` | `0 <0> ()` | :arrow_down: |; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `100% <100%> ()` | `5 <2> (?)` | |; | [...ute/hellbender/utils/test/GenomicsDBTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0dlbm9taWNzREJUZXN0VXRpbHMuamF2YQ==) | `91.667% <100%> (-0.641%)` | `3 <0> ()` | |; | [...ils/test/testers/AbstractMarkDuplicatesTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvQWJzdHJhY3RNYXJrRHVwbGljYXRlc1Rlc3Rlci5qYXZh) | `79.487% <100%> ()` | `17 <1> ()` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700:1807,Usability,Simpl,SimpleIntervalTestFactory,1807,//codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `70.707% <> (-13.116%)` | `27 <0> (-9)` | |; | [...e/hellbender/utils/test/testers/SamFileTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvU2FtRmlsZVRlc3Rlci5qYXZh) | `90.217% <> ()` | `30 <0> ()` | :arrow_down: |; | [.../hellbender/utils/test/testers/CleanSamTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvQ2xlYW5TYW1UZXN0ZXIuamF2YQ==) | `0% <0%> ()` | `0 <0> ()` | :arrow_down: |; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `100% <100%> ()` | `5 <2> (?)` | |; | [...ute/hellbender/utils/test/GenomicsDBTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0dlbm9taWNzREJUZXN0VXRpbHMuamF2YQ==) | `91.667% <100%> (-0.641%)` | `3 <0> ()` | |; | [...ils/test/testers/AbstractMarkDuplicatesTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L3Rlc3RlcnMvQWJzdHJhY3RNYXJrRHVwbGljYXRlc1Rlc3Rlci5qYXZh) | `79.487% <100%> ()` | `17 <1> ()` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3475?src=pr&el=tree#diff-c3JjL21h,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-324298700
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-338697388:36,Deployability,update,update,36,@magicDGS Could you rebase this and update newer references to baseTest that have been added since you created this branch?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-338697388
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-338990541:150,Modifiability,refactor,refactoring,150,"@jamesemery - I think that the rebase is done. I'd like to have this in as soon as it can be, to avoid the extra-work of rebasing due to new tests or refactoring of them.... Thank you in advance!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-338990541
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-338990541:97,Safety,avoid,avoid,97,"@jamesemery - I think that the rebase is done. I'd like to have this in as soon as it can be, to avoid the extra-work of rebasing due to new tests or refactoring of them.... Thank you in advance!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-338990541
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-338990541:141,Testability,test,tests,141,"@jamesemery - I think that the rebase is done. I'd like to have this in as soon as it can be, to avoid the extra-work of rebasing due to new tests or refactoring of them.... Thank you in advance!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-338990541
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-340724214:240,Modifiability,extend,extend,240,"@jamesemery - we should get this merge as soon as possible to avoid conflicts that pop up in every round of comments. Once this is in, I can go to the open PRs to point out the conflicts and the new structure (e.g., change the new tests to extend `GATKBaseTest`). I added a new commit addressing the issues and I will rebase to resolve conflicts again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-340724214
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-340724214:62,Safety,avoid,avoid,62,"@jamesemery - we should get this merge as soon as possible to avoid conflicts that pop up in every round of comments. Once this is in, I can go to the open PRs to point out the conflicts and the new structure (e.g., change the new tests to extend `GATKBaseTest`). I added a new commit addressing the issues and I will rebase to resolve conflicts again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-340724214
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-340724214:231,Testability,test,tests,231,"@jamesemery - we should get this merge as soon as possible to avoid conflicts that pop up in every round of comments. Once this is in, I can go to the open PRs to point out the conflicts and the new structure (e.g., change the new tests to extend `GATKBaseTest`). I added a new commit addressing the issues and I will rebase to resolve conflicts again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-340724214
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-340836437:100,Usability,Simpl,SimpleIntervalTestFactory,100,@magicDGS You need to resolve the conflicts yet again and respond to the comments I made about the `SimpleIntervalTestFactory` then this could probably be merged,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-340836437
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341093236:190,Testability,test,testing,190,"@jamesemery - I rebased to solve the conflict and I open an issue regarding the `SimpleIntervalTestFactory` to do not block this work any longer, because this is already a big change in the testing framework. . Because the changes are big and we are working in different timezones, conflicts pop up everyday when another PR is accepted before this if they modify any of the test files (which is often the case). If we continue delaying this, it would never be possible to merge...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341093236
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341093236:374,Testability,test,test,374,"@jamesemery - I rebased to solve the conflict and I open an issue regarding the `SimpleIntervalTestFactory` to do not block this work any longer, because this is already a big change in the testing framework. . Because the changes are big and we are working in different timezones, conflicts pop up everyday when another PR is accepted before this if they modify any of the test files (which is often the case). If we continue delaying this, it would never be possible to merge...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341093236
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341093236:81,Usability,Simpl,SimpleIntervalTestFactory,81,"@jamesemery - I rebased to solve the conflict and I open an issue regarding the `SimpleIntervalTestFactory` to do not block this work any longer, because this is already a big change in the testing framework. . Because the changes are big and we are working in different timezones, conflicts pop up everyday when another PR is accepted before this if they modify any of the test files (which is often the case). If we continue delaying this, it would never be possible to merge...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341093236
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259:62,Availability,error,errors,62,"@magicDGS It looks like you have triggered a few new compiler errors in the last branch, namely in the following places:. ```; /gatk/src/test/java/org/broadinstitute/hellbender/tools/spark/sv/discovery/SVDiscoveryTestDataProvider.java:33: error: cannot find symbol; BaseTest.b38_reference_20_21, ReferenceWindowFunctions.IDENTITY_FUNCTION);; ^; symbol: variable BaseTest; location: class SVDiscoveryTestDataProvider; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/formats/SampleLocatableCollectionUnitTest.java:30: error: cannot find symbol; private static final String TEST_SUB_DIR = toolsTestDir + ""copynumber/formats"";; ^; symbol: variable toolsTestDir; location: class SampleLocatableCollectionUnitTest; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/utils/annotatedregion/SimpleAnnotatedGenomicRegionUnitTest.java:18: error: cannot find symbol; private static final String TEST_FILE = publicTestDir + ""org/broadinstitute/hellbender/tools/copynumber/utils/combine-segment-breakpoints-with-legacy-header-learning-combined-copy-number.tsv"";; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259:239,Availability,error,error,239,"@magicDGS It looks like you have triggered a few new compiler errors in the last branch, namely in the following places:. ```; /gatk/src/test/java/org/broadinstitute/hellbender/tools/spark/sv/discovery/SVDiscoveryTestDataProvider.java:33: error: cannot find symbol; BaseTest.b38_reference_20_21, ReferenceWindowFunctions.IDENTITY_FUNCTION);; ^; symbol: variable BaseTest; location: class SVDiscoveryTestDataProvider; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/formats/SampleLocatableCollectionUnitTest.java:30: error: cannot find symbol; private static final String TEST_SUB_DIR = toolsTestDir + ""copynumber/formats"";; ^; symbol: variable toolsTestDir; location: class SampleLocatableCollectionUnitTest; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/utils/annotatedregion/SimpleAnnotatedGenomicRegionUnitTest.java:18: error: cannot find symbol; private static final String TEST_FILE = publicTestDir + ""org/broadinstitute/hellbender/tools/copynumber/utils/combine-segment-breakpoints-with-legacy-header-learning-combined-copy-number.tsv"";; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259:535,Availability,error,error,535,"@magicDGS It looks like you have triggered a few new compiler errors in the last branch, namely in the following places:. ```; /gatk/src/test/java/org/broadinstitute/hellbender/tools/spark/sv/discovery/SVDiscoveryTestDataProvider.java:33: error: cannot find symbol; BaseTest.b38_reference_20_21, ReferenceWindowFunctions.IDENTITY_FUNCTION);; ^; symbol: variable BaseTest; location: class SVDiscoveryTestDataProvider; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/formats/SampleLocatableCollectionUnitTest.java:30: error: cannot find symbol; private static final String TEST_SUB_DIR = toolsTestDir + ""copynumber/formats"";; ^; symbol: variable toolsTestDir; location: class SampleLocatableCollectionUnitTest; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/utils/annotatedregion/SimpleAnnotatedGenomicRegionUnitTest.java:18: error: cannot find symbol; private static final String TEST_FILE = publicTestDir + ""org/broadinstitute/hellbender/tools/copynumber/utils/combine-segment-breakpoints-with-legacy-header-learning-combined-copy-number.tsv"";; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259:863,Availability,error,error,863,"@magicDGS It looks like you have triggered a few new compiler errors in the last branch, namely in the following places:. ```; /gatk/src/test/java/org/broadinstitute/hellbender/tools/spark/sv/discovery/SVDiscoveryTestDataProvider.java:33: error: cannot find symbol; BaseTest.b38_reference_20_21, ReferenceWindowFunctions.IDENTITY_FUNCTION);; ^; symbol: variable BaseTest; location: class SVDiscoveryTestDataProvider; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/formats/SampleLocatableCollectionUnitTest.java:30: error: cannot find symbol; private static final String TEST_SUB_DIR = toolsTestDir + ""copynumber/formats"";; ^; symbol: variable toolsTestDir; location: class SampleLocatableCollectionUnitTest; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/utils/annotatedregion/SimpleAnnotatedGenomicRegionUnitTest.java:18: error: cannot find symbol; private static final String TEST_FILE = publicTestDir + ""org/broadinstitute/hellbender/tools/copynumber/utils/combine-segment-breakpoints-with-legacy-header-learning-combined-copy-number.tsv"";; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259:353,Modifiability,variab,variable,353,"@magicDGS It looks like you have triggered a few new compiler errors in the last branch, namely in the following places:. ```; /gatk/src/test/java/org/broadinstitute/hellbender/tools/spark/sv/discovery/SVDiscoveryTestDataProvider.java:33: error: cannot find symbol; BaseTest.b38_reference_20_21, ReferenceWindowFunctions.IDENTITY_FUNCTION);; ^; symbol: variable BaseTest; location: class SVDiscoveryTestDataProvider; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/formats/SampleLocatableCollectionUnitTest.java:30: error: cannot find symbol; private static final String TEST_SUB_DIR = toolsTestDir + ""copynumber/formats"";; ^; symbol: variable toolsTestDir; location: class SampleLocatableCollectionUnitTest; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/utils/annotatedregion/SimpleAnnotatedGenomicRegionUnitTest.java:18: error: cannot find symbol; private static final String TEST_FILE = publicTestDir + ""org/broadinstitute/hellbender/tools/copynumber/utils/combine-segment-breakpoints-with-legacy-header-learning-combined-copy-number.tsv"";; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259:654,Modifiability,variab,variable,654,"@magicDGS It looks like you have triggered a few new compiler errors in the last branch, namely in the following places:. ```; /gatk/src/test/java/org/broadinstitute/hellbender/tools/spark/sv/discovery/SVDiscoveryTestDataProvider.java:33: error: cannot find symbol; BaseTest.b38_reference_20_21, ReferenceWindowFunctions.IDENTITY_FUNCTION);; ^; symbol: variable BaseTest; location: class SVDiscoveryTestDataProvider; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/formats/SampleLocatableCollectionUnitTest.java:30: error: cannot find symbol; private static final String TEST_SUB_DIR = toolsTestDir + ""copynumber/formats"";; ^; symbol: variable toolsTestDir; location: class SampleLocatableCollectionUnitTest; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/utils/annotatedregion/SimpleAnnotatedGenomicRegionUnitTest.java:18: error: cannot find symbol; private static final String TEST_FILE = publicTestDir + ""org/broadinstitute/hellbender/tools/copynumber/utils/combine-segment-breakpoints-with-legacy-header-learning-combined-copy-number.tsv"";; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259:137,Testability,test,test,137,"@magicDGS It looks like you have triggered a few new compiler errors in the last branch, namely in the following places:. ```; /gatk/src/test/java/org/broadinstitute/hellbender/tools/spark/sv/discovery/SVDiscoveryTestDataProvider.java:33: error: cannot find symbol; BaseTest.b38_reference_20_21, ReferenceWindowFunctions.IDENTITY_FUNCTION);; ^; symbol: variable BaseTest; location: class SVDiscoveryTestDataProvider; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/formats/SampleLocatableCollectionUnitTest.java:30: error: cannot find symbol; private static final String TEST_SUB_DIR = toolsTestDir + ""copynumber/formats"";; ^; symbol: variable toolsTestDir; location: class SampleLocatableCollectionUnitTest; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/utils/annotatedregion/SimpleAnnotatedGenomicRegionUnitTest.java:18: error: cannot find symbol; private static final String TEST_FILE = publicTestDir + ""org/broadinstitute/hellbender/tools/copynumber/utils/combine-segment-breakpoints-with-legacy-header-learning-combined-copy-number.tsv"";; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259:427,Testability,test,test,427,"@magicDGS It looks like you have triggered a few new compiler errors in the last branch, namely in the following places:. ```; /gatk/src/test/java/org/broadinstitute/hellbender/tools/spark/sv/discovery/SVDiscoveryTestDataProvider.java:33: error: cannot find symbol; BaseTest.b38_reference_20_21, ReferenceWindowFunctions.IDENTITY_FUNCTION);; ^; symbol: variable BaseTest; location: class SVDiscoveryTestDataProvider; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/formats/SampleLocatableCollectionUnitTest.java:30: error: cannot find symbol; private static final String TEST_SUB_DIR = toolsTestDir + ""copynumber/formats"";; ^; symbol: variable toolsTestDir; location: class SampleLocatableCollectionUnitTest; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/utils/annotatedregion/SimpleAnnotatedGenomicRegionUnitTest.java:18: error: cannot find symbol; private static final String TEST_FILE = publicTestDir + ""org/broadinstitute/hellbender/tools/copynumber/utils/combine-segment-breakpoints-with-legacy-header-learning-combined-copy-number.tsv"";; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259:738,Testability,test,test,738,"@magicDGS It looks like you have triggered a few new compiler errors in the last branch, namely in the following places:. ```; /gatk/src/test/java/org/broadinstitute/hellbender/tools/spark/sv/discovery/SVDiscoveryTestDataProvider.java:33: error: cannot find symbol; BaseTest.b38_reference_20_21, ReferenceWindowFunctions.IDENTITY_FUNCTION);; ^; symbol: variable BaseTest; location: class SVDiscoveryTestDataProvider; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/formats/SampleLocatableCollectionUnitTest.java:30: error: cannot find symbol; private static final String TEST_SUB_DIR = toolsTestDir + ""copynumber/formats"";; ^; symbol: variable toolsTestDir; location: class SampleLocatableCollectionUnitTest; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/utils/annotatedregion/SimpleAnnotatedGenomicRegionUnitTest.java:18: error: cannot find symbol; private static final String TEST_FILE = publicTestDir + ""org/broadinstitute/hellbender/tools/copynumber/utils/combine-segment-breakpoints-with-legacy-header-learning-combined-copy-number.tsv"";; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259:817,Usability,Simpl,SimpleAnnotatedGenomicRegionUnitTest,817,"@magicDGS It looks like you have triggered a few new compiler errors in the last branch, namely in the following places:. ```; /gatk/src/test/java/org/broadinstitute/hellbender/tools/spark/sv/discovery/SVDiscoveryTestDataProvider.java:33: error: cannot find symbol; BaseTest.b38_reference_20_21, ReferenceWindowFunctions.IDENTITY_FUNCTION);; ^; symbol: variable BaseTest; location: class SVDiscoveryTestDataProvider; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/formats/SampleLocatableCollectionUnitTest.java:30: error: cannot find symbol; private static final String TEST_SUB_DIR = toolsTestDir + ""copynumber/formats"";; ^; symbol: variable toolsTestDir; location: class SampleLocatableCollectionUnitTest; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/utils/annotatedregion/SimpleAnnotatedGenomicRegionUnitTest.java:18: error: cannot find symbol; private static final String TEST_FILE = publicTestDir + ""org/broadinstitute/hellbender/tools/copynumber/utils/combine-segment-breakpoints-with-legacy-header-learning-combined-copy-number.tsv"";; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259:1047,Usability,learn,learning-combined-copy-number,1047,"@magicDGS It looks like you have triggered a few new compiler errors in the last branch, namely in the following places:. ```; /gatk/src/test/java/org/broadinstitute/hellbender/tools/spark/sv/discovery/SVDiscoveryTestDataProvider.java:33: error: cannot find symbol; BaseTest.b38_reference_20_21, ReferenceWindowFunctions.IDENTITY_FUNCTION);; ^; symbol: variable BaseTest; location: class SVDiscoveryTestDataProvider; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/formats/SampleLocatableCollectionUnitTest.java:30: error: cannot find symbol; private static final String TEST_SUB_DIR = toolsTestDir + ""copynumber/formats"";; ^; symbol: variable toolsTestDir; location: class SampleLocatableCollectionUnitTest; /gatk/src/test/java/org/broadinstitute/hellbender/tools/copynumber/utils/annotatedregion/SimpleAnnotatedGenomicRegionUnitTest.java:18: error: cannot find symbol; private static final String TEST_FILE = publicTestDir + ""org/broadinstitute/hellbender/tools/copynumber/utils/combine-segment-breakpoints-with-legacy-header-learning-combined-copy-number.tsv"";; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341143259
https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341155668:77,Testability,test,tests,77,Thanks @jamesemery - that's the complication of this big PR. I hope that the tests pass after my last commit and that we can get this in before another PR gets in. Thanks a lot for reviewing!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3475#issuecomment-341155668
https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325025262:48,Availability,down,down,48,"No problem adding hasEnd()... but can you break down what SV types have it which don't .... . *BUT* I think is important to consider here what ""end"" means in reality.. I think that ""end"" here should be the last position continuously overlapped by the variant from its start position. So for insertions, translocations and bnds, typically it would be set equal to start. . Think about ""start"" itself.... it does not make reference to the first overlapped based but the ones before it. If a BND would not have an ""end"" why should it have an ""start""?. I think start-end is just defined to what is practical for the sake of working with VCFs. What do you think? @SHuang-Broad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325025262
https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325025262:220,Deployability,continuous,continuously,220,"No problem adding hasEnd()... but can you break down what SV types have it which don't .... . *BUT* I think is important to consider here what ""end"" means in reality.. I think that ""end"" here should be the last position continuously overlapped by the variant from its start position. So for insertions, translocations and bnds, typically it would be set equal to start. . Think about ""start"" itself.... it does not make reference to the first overlapped based but the ones before it. If a BND would not have an ""end"" why should it have an ""start""?. I think start-end is just defined to what is practical for the sake of working with VCFs. What do you think? @SHuang-Broad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325025262
https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325025607:22,Deployability,Pipeline,PipelineOptions,22,@SHuang-Broad what is PipelineOptions needed for ... does one need it to access the reference if it stored in something that is not a ordinary file? (e.g. GS bucket?),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325025607
https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325025607:73,Security,access,access,73,@SHuang-Broad what is PipelineOptions needed for ... does one need it to access the reference if it stored in something that is not a ordinary file? (e.g. GS bucket?),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325025607
https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325030125:7,Deployability,Pipeline,PipelineOptions,7,"* For `PipelineOptions`, my understanding is that it is used for Google genomics API, and we seem to use it very infrequently in GATK (and never in SV), so it is safe to use null whenever engine level or other utility functions API needs it; * For the `END` and `START` annotation, there is NO`START` in VCF spec, but `POS`, so I don't know where the `start` comes from. And yes, I agree that BND records don't have a `start` either, it is merely a novel adjacency between two genomic locations, none of which is a start or end.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325030125
https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325030125:162,Safety,safe,safe,162,"* For `PipelineOptions`, my understanding is that it is used for Google genomics API, and we seem to use it very infrequently in GATK (and never in SV), so it is safe to use null whenever engine level or other utility functions API needs it; * For the `END` and `START` annotation, there is NO`START` in VCF spec, but `POS`, so I don't know where the `start` comes from. And yes, I agree that BND records don't have a `start` either, it is merely a novel adjacency between two genomic locations, none of which is a start or end.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3476#issuecomment-325030125
https://github.com/broadinstitute/gatk/pull/3479#issuecomment-324144199:48,Usability,simpl,simple,48,@jonn-smith Could you take a look at this super simple PR when you get a chance?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3479#issuecomment-324144199
https://github.com/broadinstitute/gatk/pull/3480#issuecomment-417360848:58,Deployability,update,updated,58,"I rebased this, and responded to code review comments:. - updated comments; - reverted GenotypeGVCFs change; - reverted changing the default lookahead for VariantWalker side inputs. I think changing the default lookahead for VariantWalker side inputs to the new, smaller value will hurt performance for tools like VQSR. I did some crude timing tests using the FeatureDataSource default (1000 bases) proposed in this branch, and the current default (100,000 bases). The following are total times as reported by Gradle for serial runs of the VQSR integration tests:. With 1000 base lookahead:; 1m40s; 1m29s; 1m29s; 1m25s. With 100,000 base lookahead:; 1m29s; 1m17s; 1m16s; 1m18s. Back to 1000 base lookahead again:; 1m36s; 1m26s; 1m26s; 1m29s. It seems pretty consistently slower with the smaller lookahead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3480#issuecomment-417360848
https://github.com/broadinstitute/gatk/pull/3480#issuecomment-417360848:545,Deployability,integrat,integration,545,"I rebased this, and responded to code review comments:. - updated comments; - reverted GenotypeGVCFs change; - reverted changing the default lookahead for VariantWalker side inputs. I think changing the default lookahead for VariantWalker side inputs to the new, smaller value will hurt performance for tools like VQSR. I did some crude timing tests using the FeatureDataSource default (1000 bases) proposed in this branch, and the current default (100,000 bases). The following are total times as reported by Gradle for serial runs of the VQSR integration tests:. With 1000 base lookahead:; 1m40s; 1m29s; 1m29s; 1m25s. With 100,000 base lookahead:; 1m29s; 1m17s; 1m16s; 1m18s. Back to 1000 base lookahead again:; 1m36s; 1m26s; 1m26s; 1m29s. It seems pretty consistently slower with the smaller lookahead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3480#issuecomment-417360848
https://github.com/broadinstitute/gatk/pull/3480#issuecomment-417360848:545,Integrability,integrat,integration,545,"I rebased this, and responded to code review comments:. - updated comments; - reverted GenotypeGVCFs change; - reverted changing the default lookahead for VariantWalker side inputs. I think changing the default lookahead for VariantWalker side inputs to the new, smaller value will hurt performance for tools like VQSR. I did some crude timing tests using the FeatureDataSource default (1000 bases) proposed in this branch, and the current default (100,000 bases). The following are total times as reported by Gradle for serial runs of the VQSR integration tests:. With 1000 base lookahead:; 1m40s; 1m29s; 1m29s; 1m25s. With 100,000 base lookahead:; 1m29s; 1m17s; 1m16s; 1m18s. Back to 1000 base lookahead again:; 1m36s; 1m26s; 1m26s; 1m29s. It seems pretty consistently slower with the smaller lookahead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3480#issuecomment-417360848
https://github.com/broadinstitute/gatk/pull/3480#issuecomment-417360848:287,Performance,perform,performance,287,"I rebased this, and responded to code review comments:. - updated comments; - reverted GenotypeGVCFs change; - reverted changing the default lookahead for VariantWalker side inputs. I think changing the default lookahead for VariantWalker side inputs to the new, smaller value will hurt performance for tools like VQSR. I did some crude timing tests using the FeatureDataSource default (1000 bases) proposed in this branch, and the current default (100,000 bases). The following are total times as reported by Gradle for serial runs of the VQSR integration tests:. With 1000 base lookahead:; 1m40s; 1m29s; 1m29s; 1m25s. With 100,000 base lookahead:; 1m29s; 1m17s; 1m16s; 1m18s. Back to 1000 base lookahead again:; 1m36s; 1m26s; 1m26s; 1m29s. It seems pretty consistently slower with the smaller lookahead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3480#issuecomment-417360848
https://github.com/broadinstitute/gatk/pull/3480#issuecomment-417360848:344,Testability,test,tests,344,"I rebased this, and responded to code review comments:. - updated comments; - reverted GenotypeGVCFs change; - reverted changing the default lookahead for VariantWalker side inputs. I think changing the default lookahead for VariantWalker side inputs to the new, smaller value will hurt performance for tools like VQSR. I did some crude timing tests using the FeatureDataSource default (1000 bases) proposed in this branch, and the current default (100,000 bases). The following are total times as reported by Gradle for serial runs of the VQSR integration tests:. With 1000 base lookahead:; 1m40s; 1m29s; 1m29s; 1m25s. With 100,000 base lookahead:; 1m29s; 1m17s; 1m16s; 1m18s. Back to 1000 base lookahead again:; 1m36s; 1m26s; 1m26s; 1m29s. It seems pretty consistently slower with the smaller lookahead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3480#issuecomment-417360848
https://github.com/broadinstitute/gatk/pull/3480#issuecomment-417360848:557,Testability,test,tests,557,"I rebased this, and responded to code review comments:. - updated comments; - reverted GenotypeGVCFs change; - reverted changing the default lookahead for VariantWalker side inputs. I think changing the default lookahead for VariantWalker side inputs to the new, smaller value will hurt performance for tools like VQSR. I did some crude timing tests using the FeatureDataSource default (1000 bases) proposed in this branch, and the current default (100,000 bases). The following are total times as reported by Gradle for serial runs of the VQSR integration tests:. With 1000 base lookahead:; 1m40s; 1m29s; 1m29s; 1m25s. With 100,000 base lookahead:; 1m29s; 1m17s; 1m16s; 1m18s. Back to 1000 base lookahead again:; 1m36s; 1m26s; 1m26s; 1m29s. It seems pretty consistently slower with the smaller lookahead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3480#issuecomment-417360848
https://github.com/broadinstitute/gatk/pull/3480#issuecomment-453645733:124,Testability,test,tests,124,I did a final rebase on this branch to account for the `VariantLocusWalker` and to make a few minor tweaks. Will merge once tests pass.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3480#issuecomment-453645733
https://github.com/broadinstitute/gatk/issues/3481#issuecomment-324686603:217,Testability,log,logging,217,"It looks like something went wrong with an earlier step (either a bug or some other condition), causing this step to see a truncated file. This will need some investigation. The first thing I'd suggest is to add more logging so we can visually make sure that each step finished correctly, and perhaps log the output file size every time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3481#issuecomment-324686603
https://github.com/broadinstitute/gatk/issues/3481#issuecomment-324686603:301,Testability,log,log,301,"It looks like something went wrong with an earlier step (either a bug or some other condition), causing this step to see a truncated file. This will need some investigation. The first thing I'd suggest is to add more logging so we can visually make sure that each step finished correctly, and perhaps log the output file size every time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3481#issuecomment-324686603
https://github.com/broadinstitute/gatk/issues/3483#issuecomment-324388854:66,Performance,load,loaded,66,@magicDGS Doesn't the static block run when a subclass of Main is loaded as well?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3483#issuecomment-324388854
https://github.com/broadinstitute/gatk/issues/3483#issuecomment-324566619:10,Testability,test,test,10,"I haven't test it by myself (all my computers have the default locale to US-En), but regarding https://github.com/broadinstitute/gatk/pull/3447#discussion_r134548399, it looks like it won't work.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3483#issuecomment-324566619
https://github.com/broadinstitute/gatk/issues/3483#issuecomment-324622945:55,Availability,down,downstream,55,"@magicDGS I'm still missing why this wouldn't work for downstream projects (as long as they load Main or some Main-derived class). I think the owner config issue is different; for locale, we need to always force US. Can you verify this, or maybe provide more details about what case doesn't work ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3483#issuecomment-324622945
https://github.com/broadinstitute/gatk/issues/3483#issuecomment-324622945:149,Modifiability,config,config,149,"@magicDGS I'm still missing why this wouldn't work for downstream projects (as long as they load Main or some Main-derived class). I think the owner config issue is different; for locale, we need to always force US. Can you verify this, or maybe provide more details about what case doesn't work ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3483#issuecomment-324622945
https://github.com/broadinstitute/gatk/issues/3483#issuecomment-324622945:92,Performance,load,load,92,"@magicDGS I'm still missing why this wouldn't work for downstream projects (as long as they load Main or some Main-derived class). I think the owner config issue is different; for locale, we need to always force US. Can you verify this, or maybe provide more details about what case doesn't work ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3483#issuecomment-324622945
https://github.com/broadinstitute/gatk/issues/3483#issuecomment-324627658:79,Modifiability,config,config,79,"I'm always confused with static-block initializers, and I just wondered in the config PR if the static block in `Main` it is correctly setting everything in sub-classes. I understood that this won't work in Main-derived classes; if that's not the case, feel free to close this PR...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3483#issuecomment-324627658
https://github.com/broadinstitute/gatk/pull/3485#issuecomment-324300515:1241,Deployability,pipeline,pipelines,1241,32e31dc2105a4edcecc4131a6e1e?src=pr&el=desc) will **increase** coverage by `<.001%`.; > The diff coverage is `71.429%`. ```diff; @@ Coverage Diff @@; ## master #3485 +/- ##; =============================================; + Coverage 79.94% 79.94% +<.001% ; Complexity 17897 17897 ; =============================================; Files 1198 1199 +1 ; Lines 64980 64986 +6 ; Branches 10120 10120 ; =============================================; + Hits 51945 51950 +5 ; + Misses 9002 9001 -1 ; - Partials 4033 4035 +2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3485?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...er/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/3485?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmsuamF2YQ==) | `83.019% <100%> ()` | `11 <0> ()` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3485?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <66.667%> ()` | `2 <2> (?)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/3485?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `87.963% <0%> (-0.926%)` | `50% <0%> (-2%)` | |; | [...te/hellbender/engine/spark/VariantWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3485?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvVmFyaWFudFdhbGtlclNwYXJrLmphdmE=) | `74.468% <0%> (+2.128%)` | `14% <0%> ()` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3485?src=pr&el=tre,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3485#issuecomment-324300515
https://github.com/broadinstitute/gatk/pull/3486#issuecomment-324341197:3243,Testability,test,test,3243,ff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oZWxwL0dBVEtIZWxwRG9jV29ya1VuaXRIYW5kbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | [...institute/hellbender/utils/help/HelpConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/3486?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oZWxwL0hlbHBDb25zdGFudHMuamF2YQ==) | `3.704% <0%> (-92.593%)` | `1% <0%> (-7%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3486?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3486?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3486?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3486?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3486?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | ... and [64 more](https://codecov.io/gh/broadinstitute/gatk/pull/3486?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3486#issuecomment-324341197
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324361091:1924,Availability,Down,Downsampling,1924,"_64 ; INFO 10:49:20,811 HelpFormatter - Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14 ; INFO 10:49:20,813 HelpFormatter - Program Args: -T LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V zeta_snippet.vcf.gz -o zeta_snippet_leftalign.vcf.gz ; INFO 10:49:20,819 HelpFormatter - Executing as shlee@WMCF9-CB5 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14. ; INFO 10:49:20,819 HelpFormatter - Date/Time: 2017/08/23 10:49:20 ; INFO 10:49:20,819 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 10:49:20,819 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 10:49:20,830 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:49:21,846 GenomeAnalysisEngine - Downsampling Settings: Method: BY_SAMPLE, Target Coverage: 1000 ; WARN 10:49:22,065 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; INFO 10:49:22,989 GenomeAnalysisEngine - Preparing for traversal ; INFO 10:49:22,994 GenomeAnalysisEngine - Done preparing for traversal ; INFO 10:49:22,995 ProgressMeter - [INITIALIZATION COMPLETE; STARTING PROCESSING] ; INFO 10:49:22,995 ProgressMeter - | processed | time | per 1M | | total | remaining ; INFO 10:49:22,995 ProgressMeter - Location | sites | elapsed | sites | completed | runtime | runtime ; INFO 10:49:23,191 LeftAlignAndTrimVariants - Reference allele is too long (245) at position chr1:10146; skipping that record. Set --reference_window_stop >= 245 ; INFO 10:49:23,197 LeftAlignAndTrimVariants - Reference allele is too long (225) at position chr1:10178; skipping that record. Set --reference_window_stop >= 225 ; INFO 10:49:23,200 LeftAlignAndTrimVariants - Reference allele is too long (221) at position chr1:10213; skipping that record. Set --reference_window_stop >= 221 ; INFO 10:49:23,201 LeftAlignAndTrimVariants - Reference allele is",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324361091
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324361091:4464,Integrability,message,messages,4464,"too long (225) at position chr1:10178; skipping that record. Set --reference_window_stop >= 225 ; INFO 10:49:23,200 LeftAlignAndTrimVariants - Reference allele is too long (221) at position chr1:10213; skipping that record. Set --reference_window_stop >= 221 ; INFO 10:49:23,201 LeftAlignAndTrimVariants - Reference allele is too long (223) at position chr1:10218; skipping that record. Set --reference_window_stop >= 223 ; INFO 10:49:23,203 LeftAlignAndTrimVariants - Reference allele is too long (212) at position chr1:10229; skipping that record. Set --reference_window_stop >= 212 ; INFO 10:49:23,203 LeftAlignAndTrimVariants - Reference allele is too long (216) at position chr1:10231; skipping that record. Set --reference_window_stop >= 216 ; INFO 10:49:23,205 LeftAlignAndTrimVariants - Reference allele is too long (204) at position chr1:10237; skipping that record. Set --reference_window_stop >= 204 ; INFO 10:49:23,205 LeftAlignAndTrimVariants - Reference allele is too long (209) at position chr1:10238; skipping that record. Set --reference_window_stop >= 209 ; INFO 10:49:23,208 LeftAlignAndTrimVariants - Reference allele is too long (204) at position chr1:10254; skipping that record. Set --reference_window_stop >= 204 ; INFO 10:49:23,214 LeftAlignAndTrimVariants - Reference allele is too long (207) at position chr1:10276; skipping that record. Set --reference_window_stop >= 207 ; 0 variants were aligned; INFO 10:49:23,402 ProgressMeter - done 638.0 0.0 s 10.6 m 0.0% 0.0 s 0.0 s ; INFO 10:49:23,402 ProgressMeter - Total runtime 0.41 secs, 0.01 min, 0.00 hours ; ------------------------------------------------------------------------------------------; Done. There were 1 WARN messages, the first 1 are repeated below.; WARN 10:49:22,065 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324361091
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324361091:2110,Security,validat,validation,2110,"_64 ; INFO 10:49:20,811 HelpFormatter - Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14 ; INFO 10:49:20,813 HelpFormatter - Program Args: -T LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V zeta_snippet.vcf.gz -o zeta_snippet_leftalign.vcf.gz ; INFO 10:49:20,819 HelpFormatter - Executing as shlee@WMCF9-CB5 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14. ; INFO 10:49:20,819 HelpFormatter - Date/Time: 2017/08/23 10:49:20 ; INFO 10:49:20,819 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 10:49:20,819 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 10:49:20,830 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:49:21,846 GenomeAnalysisEngine - Downsampling Settings: Method: BY_SAMPLE, Target Coverage: 1000 ; WARN 10:49:22,065 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; INFO 10:49:22,989 GenomeAnalysisEngine - Preparing for traversal ; INFO 10:49:22,994 GenomeAnalysisEngine - Done preparing for traversal ; INFO 10:49:22,995 ProgressMeter - [INITIALIZATION COMPLETE; STARTING PROCESSING] ; INFO 10:49:22,995 ProgressMeter - | processed | time | per 1M | | total | remaining ; INFO 10:49:22,995 ProgressMeter - Location | sites | elapsed | sites | completed | runtime | runtime ; INFO 10:49:23,191 LeftAlignAndTrimVariants - Reference allele is too long (245) at position chr1:10146; skipping that record. Set --reference_window_stop >= 245 ; INFO 10:49:23,197 LeftAlignAndTrimVariants - Reference allele is too long (225) at position chr1:10178; skipping that record. Set --reference_window_stop >= 225 ; INFO 10:49:23,200 LeftAlignAndTrimVariants - Reference allele is too long (221) at position chr1:10213; skipping that record. Set --reference_window_stop >= 221 ; INFO 10:49:23,201 LeftAlignAndTrimVariants - Reference allele is",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324361091
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324361091:4627,Security,validat,validation,4627,"too long (225) at position chr1:10178; skipping that record. Set --reference_window_stop >= 225 ; INFO 10:49:23,200 LeftAlignAndTrimVariants - Reference allele is too long (221) at position chr1:10213; skipping that record. Set --reference_window_stop >= 221 ; INFO 10:49:23,201 LeftAlignAndTrimVariants - Reference allele is too long (223) at position chr1:10218; skipping that record. Set --reference_window_stop >= 223 ; INFO 10:49:23,203 LeftAlignAndTrimVariants - Reference allele is too long (212) at position chr1:10229; skipping that record. Set --reference_window_stop >= 212 ; INFO 10:49:23,203 LeftAlignAndTrimVariants - Reference allele is too long (216) at position chr1:10231; skipping that record. Set --reference_window_stop >= 216 ; INFO 10:49:23,205 LeftAlignAndTrimVariants - Reference allele is too long (204) at position chr1:10237; skipping that record. Set --reference_window_stop >= 204 ; INFO 10:49:23,205 LeftAlignAndTrimVariants - Reference allele is too long (209) at position chr1:10238; skipping that record. Set --reference_window_stop >= 209 ; INFO 10:49:23,208 LeftAlignAndTrimVariants - Reference allele is too long (204) at position chr1:10254; skipping that record. Set --reference_window_stop >= 204 ; INFO 10:49:23,214 LeftAlignAndTrimVariants - Reference allele is too long (207) at position chr1:10276; skipping that record. Set --reference_window_stop >= 207 ; 0 variants were aligned; INFO 10:49:23,402 ProgressMeter - done 638.0 0.0 s 10.6 m 0.0% 0.0 s 0.0 s ; INFO 10:49:23,402 ProgressMeter - Total runtime 0.41 secs, 0.01 min, 0.00 hours ; ------------------------------------------------------------------------------------------; Done. There were 1 WARN messages, the first 1 are repeated below.; WARN 10:49:22,065 IndexDictionaryUtils - Track variant doesn't have a sequence dictionary built in, skipping dictionary validation ; ------------------------------------------------------------------------------------------; WMCF9-CB5:Mutect2 shlee$ ; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324361091
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324361091:3,Testability,Test,Test,3,"## Test data. I've created a snippet of my `zeta` and also generated the output of the following command. The data are derived from gnomAD and so it can be used for a test case. Again, zeta is the output of a Picard LiftoverVcf command and requires GRCh38 as the reference. [zeta_snippet_shlee.zip](https://github.com/broadinstitute/gatk/files/1245839/zeta_snippet_shlee.zip). ```; WMCF9-CB5:Mutect2 shlee$ java -jar $GATK -T LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V zeta_snippet.vcf.gz -o zeta_snippet_leftalign.vcf.gz; INFO 10:49:20,809 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 10:49:20,810 HelpFormatter - The Genome Analysis Toolkit (GATK) v3.7-0-gcfedb67, Compiled 2016/12/12 11:21:18 ; INFO 10:49:20,810 HelpFormatter - Copyright (c) 2010-2016 The Broad Institute ; INFO 10:49:20,811 HelpFormatter - For support and documentation go to https://software.broadinstitute.org/gatk ; INFO 10:49:20,811 HelpFormatter - [Wed Aug 23 10:49:20 EDT 2017] Executing on Mac OS X 10.11.6 x86_64 ; INFO 10:49:20,811 HelpFormatter - Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14 ; INFO 10:49:20,813 HelpFormatter - Program Args: -T LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V zeta_snippet.vcf.gz -o zeta_snippet_leftalign.vcf.gz ; INFO 10:49:20,819 HelpFormatter - Executing as shlee@WMCF9-CB5 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14. ; INFO 10:49:20,819 HelpFormatter - Date/Time: 2017/08/23 10:49:20 ; INFO 10:49:20,819 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 10:49:20,819 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 10:49:20,830 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:49:21,846 GenomeAnalysisEngine - Downsampling Settings: Method: BY_SAMPLE, Target Coverage: 1000 ; WARN 10:49:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324361091
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324361091:167,Testability,test,test,167,"## Test data. I've created a snippet of my `zeta` and also generated the output of the following command. The data are derived from gnomAD and so it can be used for a test case. Again, zeta is the output of a Picard LiftoverVcf command and requires GRCh38 as the reference. [zeta_snippet_shlee.zip](https://github.com/broadinstitute/gatk/files/1245839/zeta_snippet_shlee.zip). ```; WMCF9-CB5:Mutect2 shlee$ java -jar $GATK -T LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V zeta_snippet.vcf.gz -o zeta_snippet_leftalign.vcf.gz; INFO 10:49:20,809 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 10:49:20,810 HelpFormatter - The Genome Analysis Toolkit (GATK) v3.7-0-gcfedb67, Compiled 2016/12/12 11:21:18 ; INFO 10:49:20,810 HelpFormatter - Copyright (c) 2010-2016 The Broad Institute ; INFO 10:49:20,811 HelpFormatter - For support and documentation go to https://software.broadinstitute.org/gatk ; INFO 10:49:20,811 HelpFormatter - [Wed Aug 23 10:49:20 EDT 2017] Executing on Mac OS X 10.11.6 x86_64 ; INFO 10:49:20,811 HelpFormatter - Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14 ; INFO 10:49:20,813 HelpFormatter - Program Args: -T LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V zeta_snippet.vcf.gz -o zeta_snippet_leftalign.vcf.gz ; INFO 10:49:20,819 HelpFormatter - Executing as shlee@WMCF9-CB5 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_111-b14. ; INFO 10:49:20,819 HelpFormatter - Date/Time: 2017/08/23 10:49:20 ; INFO 10:49:20,819 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 10:49:20,819 HelpFormatter - -------------------------------------------------------------------------------- ; INFO 10:49:20,830 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:49:21,846 GenomeAnalysisEngine - Downsampling Settings: Method: BY_SAMPLE, Target Coverage: 1000 ; WARN 10:49:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324361091
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324402304:593,Availability,avail,available,593,"@lbergelson I was just adding a third point to the list. I didn't realize these were different tools so thanks for the clarification. . I think since Picard LiftoverVcf doesn't leftalign/trim, and GATK4-Mutect2 requires exactly identical allele representations in the resource to use the allele frequency in its calculations, and we are trying to nudge people to switch to GRCh38 over b37, we should provide a means for folks to correctly format their REF/ALT alleles after liftover or after calling using a non-GATK caller (to enable using Mutect2). I just think this functionality should be available somewhere--either in Picard or GATK. Since GATK already has such a tool, my vote would be to port to GATK4.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-324402304
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:239,Availability,Down,Downloads,239,"Testing branch `ck_3487_port_LeftAlignAndTrimVariants`, which ports LeftAlignAndTrimVariants from GATK3 to GATK4. ### stdout; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; 16:34:35.251 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 4:34:35 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 16:34:35.413 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 16:34:35.414 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:34:35.414 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 16:34:35.414 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 16:34:35.414 IN",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:607,Availability,Down,Downloads,607,"Testing branch `ck_3487_port_LeftAlignAndTrimVariants`, which ports LeftAlignAndTrimVariants from GATK3 to GATK4. ### stdout; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; 16:34:35.251 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 4:34:35 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 16:34:35.413 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 16:34:35.414 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:34:35.414 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 16:34:35.414 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 16:34:35.414 IN",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:1328,Availability,error,error,1328,"lee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; 16:34:35.251 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 4:34:35 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 16:34:35.413 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 16:34:35.414 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:34:35.414 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 16:34:35.414 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 16:34:35.414 INFO LeftAlignAndTrimVariants - Start Date/Time: September 5, 2018 4:34:35 PM EDT; 16:34:35.414 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - -------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:3190,Availability,Down,Downloads,3190,----------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.415 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 16:34:35.415 INFO LeftAlignAndTrimVariants - Picard Version: 2.18.7; 16:34:35.415 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:34:35.415 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:34:35.415 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:34:35.415 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:34:35.415 INFO LeftAlignAndTrimVariants - Deflater: IntelDeflater; 16:34:35.415 INFO LeftAlignAndTrimVariants - Inflater: IntelInflater; 16:34:35.415 INFO LeftAlignAndTrimVariants - GCS max retries/reopens: 20; 16:34:35.415 INFO LeftAlignAndTrimVariants - Initializing engine; 16:34:35.646 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz; 16:34:35.732 INFO LeftAlignAndTrimVariants - Done initializing engine; 16:34:35.809 INFO ProgressMeter - Starting traversal; 16:34:35.809 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 16:34:35.866 INFO LeftAlignAndTrimVariants - Reference allele is too long (245) at position chr1:10146; skipping that record. Set --maxIndelSize >= 245; 16:34:35.872 INFO LeftAlignAndTrimVariants - Reference allele is too long (225) at position chr1:10178; skipping that record. Set --maxIndelSize >= 225; 16:34:35.874 INFO LeftAlignAndTrimVariants - Reference allele is too long (221) at position chr1:10213; skipping that record. Set --maxIndelSize >= 221; 16:34:35.874 INFO LeftAlignAndTrimVariants - Reference allele is too long (223) at position chr1:10218; skipping that record. Set --maxIndelSize >= 223; 16:34:35.875 INFO LeftAlignAndTrimVariants - Reference allele is too long (212) at position ch,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:5210,Availability,down,down,5210,"ndelSize >= 212; 16:34:35.876 INFO LeftAlignAndTrimVariants - Reference allele is too long (216) at position chr1:10231; skipping that record. Set --maxIndelSize >= 216; 16:34:35.877 INFO LeftAlignAndTrimVariants - Reference allele is too long (204) at position chr1:10237; skipping that record. Set --maxIndelSize >= 204; 16:34:35.877 INFO LeftAlignAndTrimVariants - Reference allele is too long (209) at position chr1:10238; skipping that record. Set --maxIndelSize >= 209; 16:34:35.879 INFO LeftAlignAndTrimVariants - Reference allele is too long (204) at position chr1:10254; skipping that record. Set --maxIndelSize >= 204; 16:34:35.881 INFO LeftAlignAndTrimVariants - Reference allele is too long (207) at position chr1:10276; skipping that record. Set --maxIndelSize >= 207; 16:34:35.914 INFO ProgressMeter - unmapped 0.0 295 168571.4; 16:34:35.914 INFO ProgressMeter - Traversal complete. Processed 295 total variants in 0.0 minutes.; 16:34:35.920 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 5, 2018 4:34:35 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=249036800; Tool returned:; 0 variants left aligned; ```. md5 of input; ```; WMCF9-CB5:shlee$ md5 zeta_headless.txt ; MD5 (zeta_headless.txt) = 9569730f636c1c27353ab122a3792a14; ```; md5 of GATK3-leftalign; ```; WMCF9-CB5:shlee$ md5 zeta_leftalign_headless.txt ; MD5 (zeta_leftalign_headless.txt) = a9a07f5049188d2e57fc0b653a131887; ```; md5 of GATK4-port-leftalign; ```; WMCF9-CB5:shlee$ md5 zeta_leftalign_ck_3487_headless.txt ; MD5 (zeta_leftalign_ck_3487_headless.txt) = 61a5526841d465b14f5a4f7582d5ae55; ```. The GATK4-port-leftalign retains the same number of records as the input, whereas GATK3-leftalign drops ten. The test data variants run into and overlap each other. Combining the variant calls is a functionality in another tool, CombineVariants. Here, first let's make sure variant representations are le",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:397,Deployability,install,install,397,"Testing branch `ck_3487_port_LeftAlignAndTrimVariants`, which ports LeftAlignAndTrimVariants from GATK3 to GATK4. ### stdout; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; 16:34:35.251 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 4:34:35 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 16:34:35.413 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 16:34:35.414 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:34:35.414 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 16:34:35.414 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 16:34:35.414 IN",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:479,Deployability,install,install,479,"Testing branch `ck_3487_port_LeftAlignAndTrimVariants`, which ports LeftAlignAndTrimVariants from GATK3 to GATK4. ### stdout; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; 16:34:35.251 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 4:34:35 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 16:34:35.413 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 16:34:35.414 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:34:35.414 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 16:34:35.414 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 16:34:35.414 IN",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:826,Deployability,install,install,826,"Testing branch `ck_3487_port_LeftAlignAndTrimVariants`, which ports LeftAlignAndTrimVariants from GATK3 to GATK4. ### stdout; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; 16:34:35.251 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 4:34:35 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 16:34:35.413 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 16:34:35.414 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:34:35.414 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 16:34:35.414 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 16:34:35.414 IN",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:333,Integrability,wrap,wrapper,333,"Testing branch `ck_3487_port_LeftAlignAndTrimVariants`, which ports LeftAlignAndTrimVariants from GATK3 to GATK4. ### stdout; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; 16:34:35.251 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 4:34:35 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 16:34:35.413 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 16:34:35.414 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:34:35.414 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 16:34:35.414 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 16:34:35.414 IN",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:730,Performance,Load,Loading,730,"Testing branch `ck_3487_port_LeftAlignAndTrimVariants`, which ports LeftAlignAndTrimVariants from GATK3 to GATK4. ### stdout; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; 16:34:35.251 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 4:34:35 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 16:34:35.413 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 16:34:35.414 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:34:35.414 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 16:34:35.414 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 16:34:35.414 IN",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:1059,Security,authenticat,authenticated,1059,"Variants`, which ports LeftAlignAndTrimVariants from GATK3 to GATK4. ### stdout; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; 16:34:35.251 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 4:34:35 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 16:34:35.413 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 16:34:35.414 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:34:35.414 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 16:34:35.414 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 16:34:35.414 INFO LeftAlignAndTrimVariants - Start Date/Time",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:1414,Security,authenticat,authentication,1414,"k; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; 16:34:35.251 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 4:34:35 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 16:34:35.413 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 16:34:35.414 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:34:35.414 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 16:34:35.414 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 16:34:35.414 INFO LeftAlignAndTrimVariants - Start Date/Time: September 5, 2018 4:34:35 PM EDT; 16:34:35.414 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.415 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 16:34:35.415 INFO LeftAlignAndTrimVariants - Picard V",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:0,Testability,Test,Testing,0,"Testing branch `ck_3487_port_LeftAlignAndTrimVariants`, which ports LeftAlignAndTrimVariants from GATK3 to GATK4. ### stdout; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign.vcf.gz; 16:34:35.251 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 4:34:35 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 16:34:35.413 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 16:34:35.414 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 16:34:35.414 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:34:35.414 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 16:34:35.414 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 16:34:35.414 IN",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494:6023,Testability,test,test,6023,"168571.4; 16:34:35.914 INFO ProgressMeter - Traversal complete. Processed 295 total variants in 0.0 minutes.; 16:34:35.920 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 5, 2018 4:34:35 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=249036800; Tool returned:; 0 variants left aligned; ```. md5 of input; ```; WMCF9-CB5:shlee$ md5 zeta_headless.txt ; MD5 (zeta_headless.txt) = 9569730f636c1c27353ab122a3792a14; ```; md5 of GATK3-leftalign; ```; WMCF9-CB5:shlee$ md5 zeta_leftalign_headless.txt ; MD5 (zeta_leftalign_headless.txt) = a9a07f5049188d2e57fc0b653a131887; ```; md5 of GATK4-port-leftalign; ```; WMCF9-CB5:shlee$ md5 zeta_leftalign_ck_3487_headless.txt ; MD5 (zeta_leftalign_ck_3487_headless.txt) = 61a5526841d465b14f5a4f7582d5ae55; ```. The GATK4-port-leftalign retains the same number of records as the input, whereas GATK3-leftalign drops ten. The test data variants run into and overlap each other. Combining the variant calls is a functionality in another tool, CombineVariants. Here, first let's make sure variant representations are left-aligned and not think about their overlap. ---; ### Look inside each.; input; ```; chr1 10144 . TAACCCCTAACCCTAACCCTAACCC CAACCCCTAACCCTAACCCTAACCC,TACCCCTAACCCTAACCCTAACCC,TTAACCCTAACCCTAACCC 82960.90 PASS AC=13,16,9;AF=0.0003364,0.0004141,0.0002329; chr1 10145 . AACCCCT TACCCCT,ACCCT 51129.90 PASS AC=6,17;AF=0.0001555,0.0004407; chr1 10146 . ACCCCTAACCCTAACCCTAACCCTAACCCTAACCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCCTAACCCTAACCCTAAACCCTAAACCCTAACCCTAACCCTAACCCTAACCCTAACCCCAACCCCAACCCCAACCCCAACCCCAACCCCAACCCTAACCCCTAACCCTAACCCTAACCCTACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAAC ACCCTAACCCTAACCCTAACCCTAACCCTAACCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCCTAACCCTAACCCTAAACCCTAAACCCTAACCCTAACCCTAACCCTAACCCTAACCCCAACCCCAACCCCAACCCCAACCCCAACCCCAACCCTAACCCCTAACCCTAACCCTAACCCTACCCTAACCCTAACCCTAACCCTAACCCTAA",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418875494
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543:149,Availability,Down,Downloads,149,"Now run with `--maxIndelSize 250`.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; 17:24:16.345 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:24:16 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:24:16.502 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:24:16.502 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:24:16.502 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:24:16.502 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:24:16.502 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 17:24:16.503 INFO LeftAlignAndTrimV",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543:552,Availability,Down,Downloads,552,"Now run with `--maxIndelSize 250`.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; 17:24:16.345 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:24:16 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:24:16.502 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:24:16.502 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:24:16.502 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:24:16.502 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:24:16.502 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 17:24:16.503 INFO LeftAlignAndTrimV",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543:1308,Availability,error,error,1308,"axindelsize250.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; 17:24:16.345 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:24:16 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:24:16.502 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:24:16.502 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:24:16.502 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:24:16.502 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:24:16.502 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 17:24:16.503 INFO LeftAlignAndTrimVariants - Start Date/Time: September 5, 2018 5:24:16 PM EDT; 17:24:16.503 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:24:16.503 INFO LeftAlignAndTrimVariants - -------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543:3170,Availability,Down,Downloads,3170,"----------------; 17:24:16.503 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:24:16.503 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 17:24:16.503 INFO LeftAlignAndTrimVariants - Picard Version: 2.18.7; 17:24:16.503 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:24:16.503 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:24:16.503 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:24:16.503 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:24:16.503 INFO LeftAlignAndTrimVariants - Deflater: IntelDeflater; 17:24:16.503 INFO LeftAlignAndTrimVariants - Inflater: IntelInflater; 17:24:16.503 INFO LeftAlignAndTrimVariants - GCS max retries/reopens: 20; 17:24:16.503 INFO LeftAlignAndTrimVariants - Initializing engine; 17:24:16.738 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz; 17:24:16.829 INFO LeftAlignAndTrimVariants - Done initializing engine; 17:24:16.909 INFO ProgressMeter - Starting traversal; 17:24:16.910 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 17:24:17.021 INFO ProgressMeter - unmapped 0.0 295 160909.1; 17:24:17.021 INFO ProgressMeter - Traversal complete. Processed 295 total variants in 0.0 minutes.; 17:24:17.027 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 5, 2018 5:24:17 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=246939648; Tool returned:; 0 variants left aligned; ```. md5; ```; WMCF9-CB5:shlee$ md5 zeta_snippet_leftalign_maxindelsize250_headless.txt; MD5 (zeta_snippet_leftalign_maxindelsize250_headless.txt) = 46f5fbb0613094c2ad489edb4e050f74; ```; Retains same number of records as original.; ```; chr1 10144 . T",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543:3660,Availability,down,down,3660,"_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:24:16.503 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:24:16.503 INFO LeftAlignAndTrimVariants - Deflater: IntelDeflater; 17:24:16.503 INFO LeftAlignAndTrimVariants - Inflater: IntelInflater; 17:24:16.503 INFO LeftAlignAndTrimVariants - GCS max retries/reopens: 20; 17:24:16.503 INFO LeftAlignAndTrimVariants - Initializing engine; 17:24:16.738 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz; 17:24:16.829 INFO LeftAlignAndTrimVariants - Done initializing engine; 17:24:16.909 INFO ProgressMeter - Starting traversal; 17:24:16.910 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 17:24:17.021 INFO ProgressMeter - unmapped 0.0 295 160909.1; 17:24:17.021 INFO ProgressMeter - Traversal complete. Processed 295 total variants in 0.0 minutes.; 17:24:17.027 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 5, 2018 5:24:17 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=246939648; Tool returned:; 0 variants left aligned; ```. md5; ```; WMCF9-CB5:shlee$ md5 zeta_snippet_leftalign_maxindelsize250_headless.txt; MD5 (zeta_snippet_leftalign_maxindelsize250_headless.txt) = 46f5fbb0613094c2ad489edb4e050f74; ```; Retains same number of records as original.; ```; chr1 10144 . TAACCCC CAACCCC,TACCCC,T 82960.90 PASS AC=13,16,9;AF=0.0003364,0.0004141,0.0002329; chr1 10145 . AAC TAC,A 51129.90 PASS AC=6,17;AF=0.0001555,0.0004407; chr1 10146 . ACC AC,A 985368 PASS AC=5380,12;AF=0.141,0.0003145; chr1 10147 . C CCCTAA,A,G 987696 PASS AC=6,22,7;AF=0.0001577,0.0005784,0.000184; chr1 10149 . CCT C 2664.59 PASS AC=21;AF=0.0005601; chr1 10150 . CT C,TT 82702.60 PASS AC=37,21;AF=0.0009911,0.0005625; ```. The variant at 10146 is now correctly left-aligned and trimmed. It is interesting to note ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543:342,Deployability,install,install,342,"Now run with `--maxIndelSize 250`.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; 17:24:16.345 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:24:16 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:24:16.502 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:24:16.502 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:24:16.502 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:24:16.502 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:24:16.502 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 17:24:16.503 INFO LeftAlignAndTrimV",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543:424,Deployability,install,install,424,"Now run with `--maxIndelSize 250`.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; 17:24:16.345 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:24:16 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:24:16.502 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:24:16.502 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:24:16.502 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:24:16.502 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:24:16.502 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 17:24:16.503 INFO LeftAlignAndTrimV",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543:806,Deployability,install,install,806,"Now run with `--maxIndelSize 250`.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; 17:24:16.345 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:24:16 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:24:16.502 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:24:16.502 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:24:16.502 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:24:16.502 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:24:16.502 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 17:24:16.503 INFO LeftAlignAndTrimV",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543:278,Integrability,wrap,wrapper,278,"Now run with `--maxIndelSize 250`.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; 17:24:16.345 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:24:16 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:24:16.502 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:24:16.502 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:24:16.502 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:24:16.502 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:24:16.502 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 17:24:16.503 INFO LeftAlignAndTrimV",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543:710,Performance,Load,Loading,710,"Now run with `--maxIndelSize 250`.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; 17:24:16.345 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:24:16 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:24:16.502 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:24:16.502 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:24:16.502 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:24:16.502 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:24:16.502 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 17:24:16.503 INFO LeftAlignAndTrimV",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543:1039,Security,authenticat,authenticated,1039,"ize 250`.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; 17:24:16.345 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:24:16 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:24:16.502 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:24:16.502 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:24:16.502 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:24:16.502 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:24:16.502 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 17:24:16.503 INFO LeftAlignAndTrimVariants - Start Date/Time",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543:1394,Security,authenticat,authentication,1394,"/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250.vcf.gz; 17:24:16.345 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:24:16 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:24:16.502 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:24:16.502 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:24:16.502 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:24:16.502 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:24:16.502 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 17:24:16.503 INFO LeftAlignAndTrimVariants - Start Date/Time: September 5, 2018 5:24:16 PM EDT; 17:24:16.503 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:24:16.503 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:24:16.503 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 17:24:16.503 INFO LeftAlignAndTrimVariants - Picard V",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418887543
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971:170,Availability,Down,Downloads,170,"Just a quick test of `--splitMultiallelics` looks good:; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; 17:52:19.004 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:52:19 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:52:19.130 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:52:19.131 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:52:19.131 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:52:19.131 INFO LeftAlignAndTrimVariants ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971:613,Availability,Down,Downloads,613,"Just a quick test of `--splitMultiallelics` looks good:; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; 17:52:19.004 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:52:19 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:52:19.130 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:52:19.131 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:52:19.131 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:52:19.131 INFO LeftAlignAndTrimVariants ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971:1409,Availability,error,error,1409,"r script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; 17:52:19.004 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:52:19 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:52:19.130 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:52:19.131 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:52:19.131 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:52:19.131 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 17:52:19.131 INFO LeftAlignAndTrimVariants - Start Date/Time: September 5, 2018 5:52:18 PM EDT; 17:52:19.131 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - -------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971:3271,Availability,Down,Downloads,3271,"----------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 17:52:19.132 INFO LeftAlignAndTrimVariants - Picard Version: 2.18.7; 17:52:19.132 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:52:19.132 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:52:19.132 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:52:19.132 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:52:19.132 INFO LeftAlignAndTrimVariants - Deflater: IntelDeflater; 17:52:19.132 INFO LeftAlignAndTrimVariants - Inflater: IntelInflater; 17:52:19.132 INFO LeftAlignAndTrimVariants - GCS max retries/reopens: 20; 17:52:19.132 INFO LeftAlignAndTrimVariants - Initializing engine; 17:52:19.351 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz; 17:52:19.434 INFO LeftAlignAndTrimVariants - Done initializing engine; 17:52:19.514 INFO ProgressMeter - Starting traversal; 17:52:19.514 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 17:52:19.654 INFO ProgressMeter - unmapped 0.0 295 126428.6; 17:52:19.655 INFO ProgressMeter - Traversal complete. Processed 295 total variants in 0.0 minutes.; 17:52:19.661 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 5, 2018 5:52:19 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=247463936; Tool returned:; 0 variants left aligned; WMCF9-CB5:shlee$ gzcat zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz | grep -v '##' | less; WMCF9-CB5:shlee$ gzcat zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz | grep -v '##' | wc -l; 448; WMCF9-CB5:shlee$ gzcat z",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971:3761,Availability,down,down,3761,"_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:52:19.132 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 17:52:19.132 INFO LeftAlignAndTrimVariants - Deflater: IntelDeflater; 17:52:19.132 INFO LeftAlignAndTrimVariants - Inflater: IntelInflater; 17:52:19.132 INFO LeftAlignAndTrimVariants - GCS max retries/reopens: 20; 17:52:19.132 INFO LeftAlignAndTrimVariants - Initializing engine; 17:52:19.351 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz; 17:52:19.434 INFO LeftAlignAndTrimVariants - Done initializing engine; 17:52:19.514 INFO ProgressMeter - Starting traversal; 17:52:19.514 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 17:52:19.654 INFO ProgressMeter - unmapped 0.0 295 126428.6; 17:52:19.655 INFO ProgressMeter - Traversal complete. Processed 295 total variants in 0.0 minutes.; 17:52:19.661 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 5, 2018 5:52:19 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=247463936; Tool returned:; 0 variants left aligned; WMCF9-CB5:shlee$ gzcat zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz | grep -v '##' | less; WMCF9-CB5:shlee$ gzcat zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz | grep -v '##' | wc -l; 448; WMCF9-CB5:shlee$ gzcat zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz | grep -v '##' | head; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO; chr1	10067	.	T	TAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCC	30.35	PASS	AC=3;AF=7.384e-05; chr1	10108	.	CAACCCT	C	46514.30	PASS	AC=6;AF=0.0001525; chr1	10109	.	AACCCT	A	89837.30	PASS	AC=48;AF=0.001223; chr1	10114	.	T	C	36729	PASS	.; chr1	10114	.	TAACCCTAACCCTAACCCTAACCCTAACCCTAACCCCTAACCCTAACCCTAACCCTAACCCTAACCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCCTAACCCTAACCCTAAACCCTA	",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971:403,Deployability,install,install,403,"Just a quick test of `--splitMultiallelics` looks good:; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; 17:52:19.004 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:52:19 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:52:19.130 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:52:19.131 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:52:19.131 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:52:19.131 INFO LeftAlignAndTrimVariants ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971:485,Deployability,install,install,485,"Just a quick test of `--splitMultiallelics` looks good:; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; 17:52:19.004 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:52:19 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:52:19.130 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:52:19.131 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:52:19.131 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:52:19.131 INFO LeftAlignAndTrimVariants ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971:907,Deployability,install,install,907,"Just a quick test of `--splitMultiallelics` looks good:; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; 17:52:19.004 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:52:19 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:52:19.130 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:52:19.131 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:52:19.131 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:52:19.131 INFO LeftAlignAndTrimVariants ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971:339,Integrability,wrap,wrapper,339,"Just a quick test of `--splitMultiallelics` looks good:; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; 17:52:19.004 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:52:19 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:52:19.130 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:52:19.131 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:52:19.131 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:52:19.131 INFO LeftAlignAndTrimVariants ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971:811,Performance,Load,Loading,811,"Just a quick test of `--splitMultiallelics` looks good:; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; 17:52:19.004 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:52:19 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:52:19.130 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:52:19.131 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:52:19.131 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:52:19.131 INFO LeftAlignAndTrimVariants ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971:1140,Security,authenticat,authenticated,1140,"ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; 17:52:19.004 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:52:19 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:52:19.130 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:52:19.131 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:52:19.131 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:52:19.131 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 17:52:19.131 INFO LeftAlignAndTrimVariants - Start Date/Time",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971:1495,Security,authenticat,authentication,1495,"bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; 17:52:19.004 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:52:19 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:52:19.130 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:52:19.131 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:52:19.131 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:52:19.131 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 17:52:19.131 INFO LeftAlignAndTrimVariants - Start Date/Time: September 5, 2018 5:52:18 PM EDT; 17:52:19.131 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 17:52:19.132 INFO LeftAlignAndTrimVariants - Picard V",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971:13,Testability,test,test,13,"Just a quick test of `--splitMultiallelics` looks good:; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --maxIndelSize 250 -O zeta_snippet_leftalign_maxindelsize250_splitmultiallelics.vcf.gz --splitMultiallelics; 17:52:19.004 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 05, 2018 5:52:19 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 17:52:19.130 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 17:52:19.131 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-24-gb43bc27-SNAPSHOT; 17:52:19.131 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:52:19.131 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 17:52:19.131 INFO LeftAlignAndTrimVariants ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-418893971
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:162,Availability,Down,Downloads,162,"Testing updated branch with improved messaging.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; 12:55:31.964 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 12:55:32 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.083 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 12:55:32.083 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:55:32.083 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:55:32.083 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:55:32.083 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:539,Availability,Down,Downloads,539,"Testing updated branch with improved messaging.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; 12:55:31.964 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 12:55:32 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.083 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 12:55:32.083 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:55:32.083 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:55:32.083 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:55:32.083 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:1270,Availability,error,error,1270,"f.gz -O zeta_snippet_leftalign_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; 12:55:31.964 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 12:55:32 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.083 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 12:55:32.083 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:55:32.083 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:55:32.083 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:55:32.083 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6, 2018 12:55:31 PM EDT; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.084 INFO LeftAlignAndTrimVariants - ------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:3133,Availability,Down,Downloads,3133,----------------; 12:55:32.084 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.084 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 12:55:32.084 INFO LeftAlignAndTrimVariants - Picard Version: 2.18.7; 12:55:32.084 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:55:32.084 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:55:32.084 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:55:32.084 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:55:32.084 INFO LeftAlignAndTrimVariants - Deflater: IntelDeflater; 12:55:32.084 INFO LeftAlignAndTrimVariants - Inflater: IntelInflater; 12:55:32.084 INFO LeftAlignAndTrimVariants - GCS max retries/reopens: 20; 12:55:32.084 INFO LeftAlignAndTrimVariants - Initializing engine; 12:55:32.275 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz; 12:55:32.361 INFO LeftAlignAndTrimVariants - Done initializing engine; 12:55:32.435 INFO ProgressMeter - Starting traversal; 12:55:32.436 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 12:55:32.488 INFO LeftAlignAndTrimVariants - Reference allele is too long (245) at position chr1:10146; skipping that record. Set --max-indel-length >= 245; 12:55:32.493 INFO LeftAlignAndTrimVariants - Reference allele is too long (225) at position chr1:10178; skipping that record. Set --max-indel-length >= 225; 12:55:32.495 INFO LeftAlignAndTrimVariants - Reference allele is too long (221) at position chr1:10213; skipping that record. Set --max-indel-length >= 221; 12:55:32.496 INFO LeftAlignAndTrimVariants - Reference allele is too long (223) at position chr1:10218; skipping that record. Set --max-indel-length >= 223; 12:55:32.497 INFO LeftAlignAndTrimVariants - Reference allele is too long (212,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:5546,Availability,down,down,5546,"- Reference allele is too long (209) at position chr1:10238; skipping that record. Set --max-indel-length >= 209; 12:55:32.500 INFO LeftAlignAndTrimVariants - Reference allele is too long (204) at position chr1:10254; skipping that record. Set --max-indel-length >= 204; 12:55:32.502 INFO LeftAlignAndTrimVariants - Reference allele is too long (207) at position chr1:10276; skipping that record. Set --max-indel-length >= 207; 12:55:32.536 INFO ProgressMeter - unmapped 0.0 295 178787.9; 12:55:32.536 INFO ProgressMeter - Traversal complete. Processed 295 total variants in 0.0 minutes.; 12:55:32.536 INFO LeftAlignAndTrimVariants - 133 variants trimmed; 12:55:32.536 INFO LeftAlignAndTrimVariants - 10 variants skipped because the reference allele was too long. The longest had a reference allele length of 245. To not skip these variants set --max-indel-length >= 245; 12:55:32.536 INFO LeftAlignAndTrimVariants - 0 variants left aligned; 12:55:32.542 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 6, 2018 12:55:32 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=249036800; ```; Multiple changes to messages in stdout. Includes # total records, number of records that were trimmed, # variant records skipped due to ref allele being too long and finally the max-indel-length value that needs to be set to include these in the leftalignandtrim. This is an improvement to previous stdout messaging. Upping max-indel-length; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Docume",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:6205,Availability,Down,Downloads,6205,"NFO LeftAlignAndTrimVariants - 10 variants skipped because the reference allele was too long. The longest had a reference allele length of 245. To not skip these variants set --max-indel-length >= 245; 12:55:32.536 INFO LeftAlignAndTrimVariants - 0 variants left aligned; 12:55:32.542 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 6, 2018 12:55:32 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=249036800; ```; Multiple changes to messages in stdout. Includes # total records, number of records that were trimmed, # variant records skipped due to ref allele being too long and finally the max-indel-length value that needs to be set to include these in the leftalignandtrim. This is an improvement to previous stdout messaging. Upping max-indel-length; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; 14:03:44.243 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 2:03:44 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accou",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:6609,Availability,Down,Downloads,6609,"ender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=249036800; ```; Multiple changes to messages in stdout. Includes # total records, number of records that were trimmed, # variant records skipped due to ref allele being too long and finally the max-indel-length value that needs to be set to include these in the leftalignandtrim. This is an improvement to previous stdout messaging. Upping max-indel-length; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; 14:03:44.243 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 2:03:44 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 14:03:44.358 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 14:03:44.358 INFO LeftAlignAndTrimVariants",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:7366,Availability,error,error,7366,"_250_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; 14:03:44.243 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 2:03:44 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 14:03:44.358 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 14:03:44.358 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 14:03:44.359 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:03:44.359 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 14:03:44.359 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 14:03:44.359 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6, 2018 2:03:44 PM EDT; 14:03:44.359 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 14:03:44.359 INFO LeftAlignAndTrimVariants - -------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:9228,Availability,Down,Downloads,9228,"e: September 6, 2018 2:03:44 PM EDT; 14:03:44.359 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 14:03:44.359 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 14:03:44.359 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 14:03:44.359 INFO LeftAlignAndTrimVariants - Picard Version: 2.18.7; 14:03:44.359 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:03:44.359 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:03:44.360 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:03:44.360 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:03:44.360 INFO LeftAlignAndTrimVariants - Deflater: IntelDeflater; 14:03:44.360 INFO LeftAlignAndTrimVariants - Inflater: IntelInflater; 14:03:44.360 INFO LeftAlignAndTrimVariants - GCS max retries/reopens: 20; 14:03:44.360 INFO LeftAlignAndTrimVariants - Initializing engine; 14:03:44.549 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz; 14:03:44.631 INFO LeftAlignAndTrimVariants - Done initializing engine; 14:03:44.716 INFO ProgressMeter - Starting traversal; 14:03:44.716 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 14:03:44.808 INFO ProgressMeter - unmapped 0.0 295 192391.3; 14:03:44.808 INFO ProgressMeter - Traversal complete. Processed 295 total variants in 0.0 minutes.; 14:03:44.808 INFO LeftAlignAndTrimVariants - 142 variants trimmed; 14:03:44.808 INFO LeftAlignAndTrimVariants - 0 variants left aligned; 14:03:44.813 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 6, 2018 2:03:44 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=251133952; ```; Messaging is as expected.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:9855,Availability,down,down,9855,"e: September 6, 2018 2:03:44 PM EDT; 14:03:44.359 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 14:03:44.359 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 14:03:44.359 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 14:03:44.359 INFO LeftAlignAndTrimVariants - Picard Version: 2.18.7; 14:03:44.359 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:03:44.359 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:03:44.360 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:03:44.360 INFO LeftAlignAndTrimVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:03:44.360 INFO LeftAlignAndTrimVariants - Deflater: IntelDeflater; 14:03:44.360 INFO LeftAlignAndTrimVariants - Inflater: IntelInflater; 14:03:44.360 INFO LeftAlignAndTrimVariants - GCS max retries/reopens: 20; 14:03:44.360 INFO LeftAlignAndTrimVariants - Initializing engine; 14:03:44.549 INFO FeatureManager - Using codec VCFCodec to read file file:///Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz; 14:03:44.631 INFO LeftAlignAndTrimVariants - Done initializing engine; 14:03:44.716 INFO ProgressMeter - Starting traversal; 14:03:44.716 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 14:03:44.808 INFO ProgressMeter - unmapped 0.0 295 192391.3; 14:03:44.808 INFO ProgressMeter - Traversal complete. Processed 295 total variants in 0.0 minutes.; 14:03:44.808 INFO LeftAlignAndTrimVariants - 142 variants trimmed; 14:03:44.808 INFO LeftAlignAndTrimVariants - 0 variants left aligned; 14:03:44.813 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 6, 2018 2:03:44 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=251133952; ```; Messaging is as expected.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:8,Deployability,update,updated,8,"Testing updated branch with improved messaging.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; 12:55:31.964 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 12:55:32 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.083 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 12:55:32.083 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:55:32.083 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:55:32.083 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:55:32.083 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:329,Deployability,install,install,329,"Testing updated branch with improved messaging.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; 12:55:31.964 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 12:55:32 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.083 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 12:55:32.083 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:55:32.083 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:55:32.083 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:55:32.083 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:411,Deployability,install,install,411,"Testing updated branch with improved messaging.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; 12:55:31.964 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 12:55:32 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.083 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 12:55:32.083 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:55:32.083 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:55:32.083 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:55:32.083 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:767,Deployability,install,install,767,"Testing updated branch with improved messaging.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; 12:55:31.964 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 12:55:32 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.083 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 12:55:32.083 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:55:32.083 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:55:32.083 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:55:32.083 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:6399,Deployability,install,install,6399,"rimVariants - 0 variants left aligned; 12:55:32.542 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 6, 2018 12:55:32 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=249036800; ```; Multiple changes to messages in stdout. Includes # total records, number of records that were trimmed, # variant records skipped due to ref allele being too long and finally the max-indel-length value that needs to be set to include these in the leftalignandtrim. This is an improvement to previous stdout messaging. Upping max-indel-length; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; 14:03:44.243 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 2:03:44 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/au",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:6481,Deployability,install,install,6481,"rimVariants - 0 variants left aligned; 12:55:32.542 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 6, 2018 12:55:32 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=249036800; ```; Multiple changes to messages in stdout. Includes # total records, number of records that were trimmed, # variant records skipped due to ref allele being too long and finally the max-indel-length value that needs to be set to include these in the leftalignandtrim. This is an improvement to previous stdout messaging. Upping max-indel-length; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; 14:03:44.243 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 2:03:44 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/au",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:6864,Deployability,install,install,6864,"re trimmed, # variant records skipped due to ref allele being too long and finally the max-indel-length value that needs to be set to include these in the leftalignandtrim. This is an improvement to previous stdout messaging. Upping max-indel-length; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; 14:03:44.243 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 2:03:44 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 14:03:44.358 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 14:03:44.358 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 14:03:44.359 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:03:44.359 INFO LeftAlignAn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:265,Integrability,wrap,wrapper,265,"Testing updated branch with improved messaging.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; 12:55:31.964 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 12:55:32 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.083 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 12:55:32.083 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:55:32.083 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:55:32.083 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:55:32.083 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:5770,Integrability,message,messages,5770,"n chr1:10254; skipping that record. Set --max-indel-length >= 204; 12:55:32.502 INFO LeftAlignAndTrimVariants - Reference allele is too long (207) at position chr1:10276; skipping that record. Set --max-indel-length >= 207; 12:55:32.536 INFO ProgressMeter - unmapped 0.0 295 178787.9; 12:55:32.536 INFO ProgressMeter - Traversal complete. Processed 295 total variants in 0.0 minutes.; 12:55:32.536 INFO LeftAlignAndTrimVariants - 133 variants trimmed; 12:55:32.536 INFO LeftAlignAndTrimVariants - 10 variants skipped because the reference allele was too long. The longest had a reference allele length of 245. To not skip these variants set --max-indel-length >= 245; 12:55:32.536 INFO LeftAlignAndTrimVariants - 0 variants left aligned; 12:55:32.542 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 6, 2018 12:55:32 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=249036800; ```; Multiple changes to messages in stdout. Includes # total records, number of records that were trimmed, # variant records skipped due to ref allele being too long and finally the max-indel-length value that needs to be set to include these in the leftalignandtrim. This is an improvement to previous stdout messaging. Upping max-indel-length; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; 14:03:44.243 INFO NativeLib",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:6335,Integrability,wrap,wrapper,6335,"rimVariants - 0 variants left aligned; 12:55:32.542 INFO LeftAlignAndTrimVariants - Shutting down engine; [September 6, 2018 12:55:32 PM EDT] org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=249036800; ```; Multiple changes to messages in stdout. Includes # total records, number of records that were trimmed, # variant records skipped due to ref allele being too long and finally the max-indel-length value that needs to be set to include these in the leftalignandtrim. This is an improvement to previous stdout messaging. Upping max-indel-length; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; 14:03:44.243 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 2:03:44 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/au",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:671,Performance,Load,Loading,671,"Testing updated branch with improved messaging.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; 12:55:31.964 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 12:55:32 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.083 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 12:55:32.083 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:55:32.083 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:55:32.083 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:55:32.083 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:6768,Performance,Load,Loading,6768," to messages in stdout. Includes # total records, number of records that were trimmed, # variant records skipped due to ref allele being too long and finally the max-indel-length value that needs to be set to include these in the leftalignandtrim. This is an improvement to previous stdout messaging. Upping max-indel-length; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; 14:03:44.243 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 2:03:44 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 14:03:44.358 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 14:03:44.358 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 14:03:44.359 INFO LeftAlignAndTrimVariants - For support and documentation go ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:1001,Security,authenticat,authenticated,1001,"Testing updated branch with improved messaging.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; 12:55:31.964 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 12:55:32 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.083 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 12:55:32.083 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:55:32.083 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:55:32.083 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:55:32.083 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:1356,Security,authenticat,authentication,1356,":; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; 12:55:31.964 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 12:55:32 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.083 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 12:55:32.083 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:55:32.083 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:55:32.083 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:55:32.083 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6, 2018 12:55:31 PM EDT; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.084 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.084 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 12:55:32.084 INFO LeftAlignAndTrimVariants - Picard ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:7097,Security,authenticat,authenticated,7097,"-length; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; 14:03:44.243 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 2:03:44 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 14:03:44.358 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 14:03:44.358 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 14:03:44.359 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:03:44.359 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 14:03:44.359 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 14:03:44.359 INFO LeftAlignAndTrimVariants - Start Date/Time",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:7452,Security,authenticat,authentication,7452,"branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz --max-indel-length 250 -O zeta_snippet_leftalign_250_96branch.vcf.gz; 14:03:44.243 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 2:03:44 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 14:03:44.358 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 14:03:44.358 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 14:03:44.359 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:03:44.359 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 14:03:44.359 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 14:03:44.359 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6, 2018 2:03:44 PM EDT; 14:03:44.359 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 14:03:44.359 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 14:03:44.359 INFO LeftAlignAndTrimVariants - HTSJDK Version: 2.16.0; 14:03:44.359 INFO LeftAlignAndTrimVariants - Picard V",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326:0,Testability,Test,Testing,0,"Testing updated branch with improved messaging.; ```; WMCF9-CB5:shlee$ ./gatk LeftAlignAndTrimVariants -R ~/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V ~/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; Using GATK wrapper script /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk; Running:; /Users/shlee/Documents/branches/hellbender/build/install/gatk/bin/gatk LeftAlignAndTrimVariants -R /Users/shlee/Documents/ref/hg38/Homo_sapiens_assembly38.fasta -V /Users/shlee/Downloads/zeta_snippet_shlee/zeta_snippet.vcf.gz -O zeta_snippet_leftalign_96branch.vcf.gz; 12:55:31.964 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/shlee/Documents/branches/hellbender/build/install/gatk/lib/gkl-0.8.5.jar!/com/intel/gkl/native/libgkl_compression.dylib; Sep 06, 2018 12:55:32 PM shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 12:55:32.083 INFO LeftAlignAndTrimVariants - ------------------------------------------------------------; 12:55:32.083 INFO LeftAlignAndTrimVariants - The Genome Analysis Toolkit (GATK) v4.0.8.1-25-g0c6f06f-SNAPSHOT; 12:55:32.083 INFO LeftAlignAndTrimVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:55:32.083 INFO LeftAlignAndTrimVariants - Executing as shlee@WMCF9-CB5 on Mac OS X v10.13.6 x86_64; 12:55:32.083 INFO LeftAlignAndTrimVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_111-b14; 12:55:32.083 INFO LeftAlignAndTrimVariants - Start Date/Time: September 6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3487#issuecomment-419190326
https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324388148:173,Availability,error,error,173,"@mwalker174 Many gatk tools require our bams to have readgroups. We should probably update our bwa tools to add readgroups, although fixing hadoop-bam to give a more useful error message would be good as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324388148
https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324388148:84,Deployability,update,update,84,"@mwalker174 Many gatk tools require our bams to have readgroups. We should probably update our bwa tools to add readgroups, although fixing hadoop-bam to give a more useful error message would be good as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324388148
https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324388148:179,Integrability,message,message,179,"@mwalker174 Many gatk tools require our bams to have readgroups. We should probably update our bwa tools to add readgroups, although fixing hadoop-bam to give a more useful error message would be good as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324388148
https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324579749:15,Availability,error,error,15,Looking at the error it seems to be failing because the file doesn't have a BGZF magic number. Can you post the first few bytes of the file (via hexdump or similar)?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324579749
https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324959378:22,Availability,fault,fault,22,"Looks like this is my fault... I didn't realize BWA produces SAM output and the non-spark tool was correcting my mistake automatically (by checking for a magic number). Can we make the error message more informative like: ""BAM file must start with BGZF magic number""? . It would be great to detect whether it's SAM or BAM by checking the file contents, as in non-spark tools that use htsjdk, rather than the extension. Is this easily done?. @lbergelson To clarify I was using the regular BWA binaries not the GATK BWA tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324959378
https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324959378:185,Availability,error,error,185,"Looks like this is my fault... I didn't realize BWA produces SAM output and the non-spark tool was correcting my mistake automatically (by checking for a magic number). Can we make the error message more informative like: ""BAM file must start with BGZF magic number""? . It would be great to detect whether it's SAM or BAM by checking the file contents, as in non-spark tools that use htsjdk, rather than the extension. Is this easily done?. @lbergelson To clarify I was using the regular BWA binaries not the GATK BWA tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324959378
https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324959378:191,Integrability,message,message,191,"Looks like this is my fault... I didn't realize BWA produces SAM output and the non-spark tool was correcting my mistake automatically (by checking for a magic number). Can we make the error message more informative like: ""BAM file must start with BGZF magic number""? . It would be great to detect whether it's SAM or BAM by checking the file contents, as in non-spark tools that use htsjdk, rather than the extension. Is this easily done?. @lbergelson To clarify I was using the regular BWA binaries not the GATK BWA tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324959378
https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324959378:291,Safety,detect,detect,291,"Looks like this is my fault... I didn't realize BWA produces SAM output and the non-spark tool was correcting my mistake automatically (by checking for a magic number). Can we make the error message more informative like: ""BAM file must start with BGZF magic number""? . It would be great to detect whether it's SAM or BAM by checking the file contents, as in non-spark tools that use htsjdk, rather than the extension. Is this easily done?. @lbergelson To clarify I was using the regular BWA binaries not the GATK BWA tool.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3488#issuecomment-324959378
https://github.com/broadinstitute/gatk/pull/3490#issuecomment-324591544:121,Deployability,update,updated,121,"Apologies, I'd missed the unit test before. We expect these to change since we now include REF alleles in the outputs. I updated the tests and rebased so hopefully checks will now finish cleanly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3490#issuecomment-324591544
https://github.com/broadinstitute/gatk/pull/3490#issuecomment-324591544:31,Testability,test,test,31,"Apologies, I'd missed the unit test before. We expect these to change since we now include REF alleles in the outputs. I updated the tests and rebased so hopefully checks will now finish cleanly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3490#issuecomment-324591544
https://github.com/broadinstitute/gatk/pull/3490#issuecomment-324591544:133,Testability,test,tests,133,"Apologies, I'd missed the unit test before. We expect these to change since we now include REF alleles in the outputs. I updated the tests and rebased so hopefully checks will now finish cleanly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3490#issuecomment-324591544
https://github.com/broadinstitute/gatk/pull/3490#issuecomment-324600057:2727,Testability,test,test,2727,bm90YXRvci9CYXNlUXVhbGl0eS5qYXZh) | `100% <100%> ()` | `9 <1> (+1)` | :arrow_up: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3490?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3490?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3490?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3490?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3490?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3490?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `55.263% <0%> (-19.079%)` | `30% <0%> (-8%)` | |; | [...r/tools/walkers/annotator/PerAlleleAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/3490?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGV,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3490#issuecomment-324600057
https://github.com/broadinstitute/gatk/pull/3490#issuecomment-325024282:219,Deployability,patch,patch,219,"David -- thanks again for the review. I tested the latest head and your annotation fixes in #3351 do resolve the issue with incompatible headers, resulting in correct behavior with GenomicsDB. There is no need for this patch so closing -- a new release should fix with your improvements should fix that issue. Thanks again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3490#issuecomment-325024282
https://github.com/broadinstitute/gatk/pull/3490#issuecomment-325024282:245,Deployability,release,release,245,"David -- thanks again for the review. I tested the latest head and your annotation fixes in #3351 do resolve the issue with incompatible headers, resulting in correct behavior with GenomicsDB. There is no need for this patch so closing -- a new release should fix with your improvements should fix that issue. Thanks again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3490#issuecomment-325024282
https://github.com/broadinstitute/gatk/pull/3490#issuecomment-325024282:40,Testability,test,tested,40,"David -- thanks again for the review. I tested the latest head and your annotation fixes in #3351 do resolve the issue with incompatible headers, resulting in correct behavior with GenomicsDB. There is no need for this patch so closing -- a new release should fix with your improvements should fix that issue. Thanks again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3490#issuecomment-325024282
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-324452717:287,Testability,test,test,287,"A quick run off between 4.beta.2 BaseRecalibrator and 4.beta.3 doesn't show any difference to me. It must be either some difference in the user's command line, their data, or possibly a change in their environment over time. I'm going to request that they upload example commandline and test files that reproduce the problem.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-324452717
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-324453449:25,Modifiability,variab,variability,25,"It could just be natural variability in the user's runtime environment, but it's worth doing some longer-running tests to be sure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-324453449
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-324453449:113,Testability,test,tests,113,"It could just be natural variability in the user's runtime environment, but it's worth doing some longer-running tests to be sure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-324453449
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-325211756:926,Deployability,patch,patch,926,"User is reporting a nearly exact 2 minute pause at tool startup. Seems very suspicious, possibly some sort of gcs operation trying and timing out?. ```; 14:33:39.416 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/gatk-package-4.beta.3-local.jar!/com/intel/gkl/native/libgkl_compression.so; 14:35:46.843 INFO BaseRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 5; 14:35:46.843 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:35:46.843 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 14:35:46.844 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:35:46.844 INFO BaseRecalibrator - Deflater: IntelDeflater; 14:35:46.844 INFO BaseRecalibrator - Inflater: IntelInflater; 14:35:46.844 INFO BaseRecalibrator - GCS max retries/reopens: 20; 14:35:46.844 INFO BaseRecalibrator - Using google-cloud-java patch 317951be3c2e898e3916a4b1abf5a9c220d84df8; 14:35:46.844 INFO BaseRecalibrator - Initializing engine; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-325211756
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-325211756:193,Performance,Load,Loading,193,"User is reporting a nearly exact 2 minute pause at tool startup. Seems very suspicious, possibly some sort of gcs operation trying and timing out?. ```; 14:33:39.416 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/gatk-package-4.beta.3-local.jar!/com/intel/gkl/native/libgkl_compression.so; 14:35:46.843 INFO BaseRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 5; 14:35:46.843 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:35:46.843 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 14:35:46.844 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:35:46.844 INFO BaseRecalibrator - Deflater: IntelDeflater; 14:35:46.844 INFO BaseRecalibrator - Inflater: IntelInflater; 14:35:46.844 INFO BaseRecalibrator - GCS max retries/reopens: 20; 14:35:46.844 INFO BaseRecalibrator - Using google-cloud-java patch 317951be3c2e898e3916a4b1abf5a9c220d84df8; 14:35:46.844 INFO BaseRecalibrator - Initializing engine; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-325211756
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-325211756:42,Usability,pause,pause,42,"User is reporting a nearly exact 2 minute pause at tool startup. Seems very suspicious, possibly some sort of gcs operation trying and timing out?. ```; 14:33:39.416 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/gatk-package-4.beta.3-local.jar!/com/intel/gkl/native/libgkl_compression.so; 14:35:46.843 INFO BaseRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 5; 14:35:46.843 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:35:46.843 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 14:35:46.844 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:35:46.844 INFO BaseRecalibrator - Deflater: IntelDeflater; 14:35:46.844 INFO BaseRecalibrator - Inflater: IntelInflater; 14:35:46.844 INFO BaseRecalibrator - GCS max retries/reopens: 20; 14:35:46.844 INFO BaseRecalibrator - Using google-cloud-java patch 317951be3c2e898e3916a4b1abf5a9c220d84df8; 14:35:46.844 INFO BaseRecalibrator - Initializing engine; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-325211756
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1190,Integrability,protocol,protocol,1190,ead.State: RUNNABLE; 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	- locked <0x0000000584a63348> (a java.net.SocksSocketImpl); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at java.net.Socket.connect(Socket.java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:3,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1285,Integrability,protocol,protocol,1285,stractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	- locked <0x0000000584a63348> (a java.net.SocksSocketImpl); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at java.net.Socket.connect(Socket.java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.go,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1377,Integrability,protocol,protocol,1377,3348> (a java.net.SocksSocketImpl); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at java.net.Socket.connect(Socket.java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:238); 	at com.google.cloud.storage.Stor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1468,Integrability,protocol,protocol,1468,bstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at java.net.Socket.connect(Socket.java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:238); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<ini,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1553,Integrability,protocol,protocol,1553,ctPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at java.net.Socket.connect(Socket.java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:238); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:30); 	at com.google.cloud.storage.StorageOptions$Builder.build,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1677,Integrability,protocol,protocol,1677,ket.java:589); 	at java.net.Socket.connect(Socket.java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:238); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:30); 	at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:77); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.jav,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1727,Integrability,protocol,protocol,1727,java:538); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:180); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:238); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:30); 	at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:77); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:361); 	at org.broadinstitute.hellbender.cmdline.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670:1850,Integrability,protocol,protocol,1850,nt.java:432); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:527); 	- locked <0x0000000584a62640> (a sun.net.www.http.HttpClient); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:211); 	at sun.net.www.http.HttpClient.New(HttpClient.java:308); 	at sun.net.www.http.HttpClient.New(HttpClient.java:326); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1546); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	- locked <0x0000000584a60148> (a sun.net.www.protocol.http.HttpURLConnection); 	at com.google.cloud.MetadataConfig.getAttribute(MetadataConfig.java:65); 	at com.google.cloud.MetadataConfig.getProjectId(MetadataConfig.java:41); 	at com.google.cloud.ServiceOptions.getGoogleCloudProjectId(ServiceOptions.java:376); 	at com.google.cloud.ServiceOptions.getDefaultProjectId(ServiceOptions.java:311); 	at com.google.cloud.ServiceOptions.getDefaultProject(ServiceOptions.java:284); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:238); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:30); 	at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:77); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:361); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); 	at org.broadinstitute.hellbender.cmdline.Comman,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-328629670
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427371743:90,Usability,pause,pause,90,"Also renamed this ticket to be less scary and more precise, since we know it's a 2-minute pause in the NIO library. It clearly doesn't always happen, though, as I don't think I've ever seen it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427371743
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427371743:119,Usability,clear,clearly,119,"Also renamed this ticket to be less scary and more precise, since we know it's a 2-minute pause in the NIO library. It clearly doesn't always happen, though, as I don't think I've ever seen it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427371743
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427413074:39,Modifiability,layers,layers,39,"This seems to happen in the cloud auth layers, which I don't control. . One potential workaround would be to add a command-line option to disable GCS support. This would only help the original reporter if they don't use GCS paths, of course. Is this something we think may be worth doing at all?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427413074
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427415516:31,Usability,clear,clear,31,"@jean-philippe-martin It's not clear to me how widespread this issue is, or what conditions trigger it -- @lbergelson care to comment?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427415516
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141:175,Availability,error,error,175,"I think it triggers in certain situations where a firewall is blocking the connection. If the internet is simply unreachable it doesn't happen, so I don't know what the exact error case is. It happened consistently for people inside Intel's firewall or vpn. . An option to disable gcs support isn't a bad idea, it's kind of a hack though, it would be better if we could understand and avoid triggering the problem. If we could only initialize GCS support when we are sure that we actually are accessing files from google that could be a useful, but it doesn't seem like there's any single point we can plug into to detect that, it would have to be spread over everything that uses paths.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141:385,Safety,avoid,avoid,385,"I think it triggers in certain situations where a firewall is blocking the connection. If the internet is simply unreachable it doesn't happen, so I don't know what the exact error case is. It happened consistently for people inside Intel's firewall or vpn. . An option to disable gcs support isn't a bad idea, it's kind of a hack though, it would be better if we could understand and avoid triggering the problem. If we could only initialize GCS support when we are sure that we actually are accessing files from google that could be a useful, but it doesn't seem like there's any single point we can plug into to detect that, it would have to be spread over everything that uses paths.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141:615,Safety,detect,detect,615,"I think it triggers in certain situations where a firewall is blocking the connection. If the internet is simply unreachable it doesn't happen, so I don't know what the exact error case is. It happened consistently for people inside Intel's firewall or vpn. . An option to disable gcs support isn't a bad idea, it's kind of a hack though, it would be better if we could understand and avoid triggering the problem. If we could only initialize GCS support when we are sure that we actually are accessing files from google that could be a useful, but it doesn't seem like there's any single point we can plug into to detect that, it would have to be spread over everything that uses paths.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141:50,Security,firewall,firewall,50,"I think it triggers in certain situations where a firewall is blocking the connection. If the internet is simply unreachable it doesn't happen, so I don't know what the exact error case is. It happened consistently for people inside Intel's firewall or vpn. . An option to disable gcs support isn't a bad idea, it's kind of a hack though, it would be better if we could understand and avoid triggering the problem. If we could only initialize GCS support when we are sure that we actually are accessing files from google that could be a useful, but it doesn't seem like there's any single point we can plug into to detect that, it would have to be spread over everything that uses paths.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141:241,Security,firewall,firewall,241,"I think it triggers in certain situations where a firewall is blocking the connection. If the internet is simply unreachable it doesn't happen, so I don't know what the exact error case is. It happened consistently for people inside Intel's firewall or vpn. . An option to disable gcs support isn't a bad idea, it's kind of a hack though, it would be better if we could understand and avoid triggering the problem. If we could only initialize GCS support when we are sure that we actually are accessing files from google that could be a useful, but it doesn't seem like there's any single point we can plug into to detect that, it would have to be spread over everything that uses paths.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141:493,Security,access,accessing,493,"I think it triggers in certain situations where a firewall is blocking the connection. If the internet is simply unreachable it doesn't happen, so I don't know what the exact error case is. It happened consistently for people inside Intel's firewall or vpn. . An option to disable gcs support isn't a bad idea, it's kind of a hack though, it would be better if we could understand and avoid triggering the problem. If we could only initialize GCS support when we are sure that we actually are accessing files from google that could be a useful, but it doesn't seem like there's any single point we can plug into to detect that, it would have to be spread over everything that uses paths.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141:106,Usability,simpl,simply,106,"I think it triggers in certain situations where a firewall is blocking the connection. If the internet is simply unreachable it doesn't happen, so I don't know what the exact error case is. It happened consistently for people inside Intel's firewall or vpn. . An option to disable gcs support isn't a bad idea, it's kind of a hack though, it would be better if we could understand and avoid triggering the problem. If we could only initialize GCS support when we are sure that we actually are accessing files from google that could be a useful, but it doesn't seem like there's any single point we can plug into to detect that, it would have to be spread over everything that uses paths.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-427432141
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:3948,Availability,Down,Downloads,3948,"s(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:100); at com.google.cloud.ServiceOptions.defaultCredentials(ServiceOptions.java:304); at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:278); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:83); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:31); at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:78); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:382); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:183); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. Produced by pulling the docker image, **shutting off the internet connection**, mounting [helloHaplotypeCaller](https://drive.google.com/file/d/0B7akc6CTmxIHdy11R1M3ZjJJdUU/view), and running:. ```shell; docker run \; --rm \; -v /Users/kshakir/Downloads/helloHaplotypeCaller:/data \; broadinstitute/gatk:4.0.11.0 \; gatk \; HaplotypeCaller \; -R /data/ref/human_g1k_b37_20.fasta \; -I /data/inputs/NA12878_wgs_20.bam \; -O test.vcf; ```. Adding in a `GOOGLE_APPLICATION_CREDENTIALS` environment variable short circuits the above stack trace. ```shell; docker run \; -e GOOGLE_APPLICATION_CREDENTIALS=whatever; --rm \; -v /Users/kshakir/Downloads/helloHaplotypeCaller:/data \; broadinstitute/gatk:4.0.11.0 \; gatk \; HaplotypeCaller \; -R /data/ref/human_g1k_b37_20.fasta \; -I /data/inputs/NA12878_wgs_20.bam \; -O test.vcf; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:4340,Availability,Down,Downloads,4340,"s(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:100); at com.google.cloud.ServiceOptions.defaultCredentials(ServiceOptions.java:304); at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:278); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:83); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:31); at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:78); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:382); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:183); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. Produced by pulling the docker image, **shutting off the internet connection**, mounting [helloHaplotypeCaller](https://drive.google.com/file/d/0B7akc6CTmxIHdy11R1M3ZjJJdUU/view), and running:. ```shell; docker run \; --rm \; -v /Users/kshakir/Downloads/helloHaplotypeCaller:/data \; broadinstitute/gatk:4.0.11.0 \; gatk \; HaplotypeCaller \; -R /data/ref/human_g1k_b37_20.fasta \; -I /data/inputs/NA12878_wgs_20.bam \; -O test.vcf; ```. Adding in a `GOOGLE_APPLICATION_CREDENTIALS` environment variable short circuits the above stack trace. ```shell; docker run \; -e GOOGLE_APPLICATION_CREDENTIALS=whatever; --rm \; -v /Users/kshakir/Downloads/helloHaplotypeCaller:/data \; broadinstitute/gatk:4.0.11.0 \; gatk \; HaplotypeCaller \; -R /data/ref/human_g1k_b37_20.fasta \; -I /data/inputs/NA12878_wgs_20.bam \; -O test.vcf; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:1500,Integrability,protocol,protocol,1500,auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Connection refused (Connection refused); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsPr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:1594,Integrability,protocol,protocol,1594, we are running on Google Compute Engine.; java.net.ConnectException: Connection refused (Connection refused); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.goo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:1685,Integrability,protocol,protocol,1685,onnection refused); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); at sha,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:1775,Integrability,protocol,protocol,1775,AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:210); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:290); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:207); at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredent,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:4199,Modifiability,variab,variable,4199,"s(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:100); at com.google.cloud.ServiceOptions.defaultCredentials(ServiceOptions.java:304); at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:278); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:83); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:31); at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:78); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:382); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:183); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. Produced by pulling the docker image, **shutting off the internet connection**, mounting [helloHaplotypeCaller](https://drive.google.com/file/d/0B7akc6CTmxIHdy11R1M3ZjJJdUU/view), and running:. ```shell; docker run \; --rm \; -v /Users/kshakir/Downloads/helloHaplotypeCaller:/data \; broadinstitute/gatk:4.0.11.0 \; gatk \; HaplotypeCaller \; -R /data/ref/human_g1k_b37_20.fasta \; -I /data/inputs/NA12878_wgs_20.bam \; -O test.vcf; ```. Adding in a `GOOGLE_APPLICATION_CREDENTIALS` environment variable short circuits the above stack trace. ```shell; docker run \; -e GOOGLE_APPLICATION_CREDENTIALS=whatever; --rm \; -v /Users/kshakir/Downloads/helloHaplotypeCaller:/data \; broadinstitute/gatk:4.0.11.0 \; gatk \; HaplotypeCaller \; -R /data/ref/human_g1k_b37_20.fasta \; -I /data/inputs/NA12878_wgs_20.bam \; -O test.vcf; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:584,Safety,detect,detect,584,"Here's a stack trace of the area I think the two minute wait may be occurring. The below example fails-fast and prints out stack trace when there is no internet. I suspect that the slow-and-quiet alternative occurs when the connection to [google](https://github.com/googleapis/google-cloud-java/blob/v0.72.0/google-cloud-clients/google-cloud-core/src/main/java/com/google/cloud/ServiceOptions.java#L450) is blocked vs. completely unavailable. ```java; Dec 02, 2018 7:50:25 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Connection refused (Connection refused); at java.net.PlainSocketImpl.socketConnect(Native Method); at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); at java.net.Socket.connect(Socket.java:589); at sun.net.NetworkClient.doConnect(NetworkClient.java:175); at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); at sun.net.www.http.HttpClient.New(HttpClient.java:339); at sun.net.www.http.HttpClient.New(HttpClient.java:357); at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1220); at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1156); at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1050); at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:984); at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:104); at shaded.cloud_nio.com.google.api.client.http.HttpRe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:4127,Testability,test,test,4127,"s(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:100); at com.google.cloud.ServiceOptions.defaultCredentials(ServiceOptions.java:304); at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:278); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:83); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:31); at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:78); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:382); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:183); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. Produced by pulling the docker image, **shutting off the internet connection**, mounting [helloHaplotypeCaller](https://drive.google.com/file/d/0B7akc6CTmxIHdy11R1M3ZjJJdUU/view), and running:. ```shell; docker run \; --rm \; -v /Users/kshakir/Downloads/helloHaplotypeCaller:/data \; broadinstitute/gatk:4.0.11.0 \; gatk \; HaplotypeCaller \; -R /data/ref/human_g1k_b37_20.fasta \; -I /data/inputs/NA12878_wgs_20.bam \; -O test.vcf; ```. Adding in a `GOOGLE_APPLICATION_CREDENTIALS` environment variable short circuits the above stack trace. ```shell; docker run \; -e GOOGLE_APPLICATION_CREDENTIALS=whatever; --rm \; -v /Users/kshakir/Downloads/helloHaplotypeCaller:/data \; broadinstitute/gatk:4.0.11.0 \; gatk \; HaplotypeCaller \; -R /data/ref/human_g1k_b37_20.fasta \; -I /data/inputs/NA12878_wgs_20.bam \; -O test.vcf; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843:4519,Testability,test,test,4519,"s(DefaultCredentialsProvider.java:124); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:127); at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:100); at com.google.cloud.ServiceOptions.defaultCredentials(ServiceOptions.java:304); at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:278); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:83); at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:31); at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:78); at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:382); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:183); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); ```. Produced by pulling the docker image, **shutting off the internet connection**, mounting [helloHaplotypeCaller](https://drive.google.com/file/d/0B7akc6CTmxIHdy11R1M3ZjJJdUU/view), and running:. ```shell; docker run \; --rm \; -v /Users/kshakir/Downloads/helloHaplotypeCaller:/data \; broadinstitute/gatk:4.0.11.0 \; gatk \; HaplotypeCaller \; -R /data/ref/human_g1k_b37_20.fasta \; -I /data/inputs/NA12878_wgs_20.bam \; -O test.vcf; ```. Adding in a `GOOGLE_APPLICATION_CREDENTIALS` environment variable short circuits the above stack trace. ```shell; docker run \; -e GOOGLE_APPLICATION_CREDENTIALS=whatever; --rm \; -v /Users/kshakir/Downloads/helloHaplotypeCaller:/data \; broadinstitute/gatk:4.0.11.0 \; gatk \; HaplotypeCaller \; -R /data/ref/human_g1k_b37_20.fasta \; -I /data/inputs/NA12878_wgs_20.bam \; -O test.vcf; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443830843
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504:1105,Deployability,configurat,configuration,1105,"Thank you @kshakir. What I see there is that the code sets the default NIO option, and as part of this is creates a google cloud `StorageOptions` object. Sadly for us, when this object is created it determines which Google credentials to use, and if nothing was specified by the user it will send some network messages to try to figure out whether it's running on a Google Compute Engine machine. When we wrote the default-setting code we didn't realize that setting the number of retries was going to cause a network message to be sent, with the associated potential retries and delays. We can't change the way Google Compute Engine works, or how the Google authentication works either. Ideally we'd want some way to only search for credentials when we know NIO is going to be used. The point of these defaults is that they're used for anything that uses NIO, including third-party library code. We can't fully replicate this behavior in a different way from the outside. So I think the ""correct"" fix would be to go deep inside the Google NIO library and change it so that instead of providing a default configuration (that the user would have to put together, causing the problem you've seen), we can provide a *callback* that sets the configuration when the Google Cloud NIO provider is loaded. This is harder for future developers to wrap their heads around, but at least it would prevent this delay if NIO is not used. I'd like to think about this some more before doing something quite this drastic, though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504:1238,Deployability,configurat,configuration,1238,"Thank you @kshakir. What I see there is that the code sets the default NIO option, and as part of this is creates a google cloud `StorageOptions` object. Sadly for us, when this object is created it determines which Google credentials to use, and if nothing was specified by the user it will send some network messages to try to figure out whether it's running on a Google Compute Engine machine. When we wrote the default-setting code we didn't realize that setting the number of retries was going to cause a network message to be sent, with the associated potential retries and delays. We can't change the way Google Compute Engine works, or how the Google authentication works either. Ideally we'd want some way to only search for credentials when we know NIO is going to be used. The point of these defaults is that they're used for anything that uses NIO, including third-party library code. We can't fully replicate this behavior in a different way from the outside. So I think the ""correct"" fix would be to go deep inside the Google NIO library and change it so that instead of providing a default configuration (that the user would have to put together, causing the problem you've seen), we can provide a *callback* that sets the configuration when the Google Cloud NIO provider is loaded. This is harder for future developers to wrap their heads around, but at least it would prevent this delay if NIO is not used. I'd like to think about this some more before doing something quite this drastic, though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504:310,Integrability,message,messages,310,"Thank you @kshakir. What I see there is that the code sets the default NIO option, and as part of this is creates a google cloud `StorageOptions` object. Sadly for us, when this object is created it determines which Google credentials to use, and if nothing was specified by the user it will send some network messages to try to figure out whether it's running on a Google Compute Engine machine. When we wrote the default-setting code we didn't realize that setting the number of retries was going to cause a network message to be sent, with the associated potential retries and delays. We can't change the way Google Compute Engine works, or how the Google authentication works either. Ideally we'd want some way to only search for credentials when we know NIO is going to be used. The point of these defaults is that they're used for anything that uses NIO, including third-party library code. We can't fully replicate this behavior in a different way from the outside. So I think the ""correct"" fix would be to go deep inside the Google NIO library and change it so that instead of providing a default configuration (that the user would have to put together, causing the problem you've seen), we can provide a *callback* that sets the configuration when the Google Cloud NIO provider is loaded. This is harder for future developers to wrap their heads around, but at least it would prevent this delay if NIO is not used. I'd like to think about this some more before doing something quite this drastic, though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504:518,Integrability,message,message,518,"Thank you @kshakir. What I see there is that the code sets the default NIO option, and as part of this is creates a google cloud `StorageOptions` object. Sadly for us, when this object is created it determines which Google credentials to use, and if nothing was specified by the user it will send some network messages to try to figure out whether it's running on a Google Compute Engine machine. When we wrote the default-setting code we didn't realize that setting the number of retries was going to cause a network message to be sent, with the associated potential retries and delays. We can't change the way Google Compute Engine works, or how the Google authentication works either. Ideally we'd want some way to only search for credentials when we know NIO is going to be used. The point of these defaults is that they're used for anything that uses NIO, including third-party library code. We can't fully replicate this behavior in a different way from the outside. So I think the ""correct"" fix would be to go deep inside the Google NIO library and change it so that instead of providing a default configuration (that the user would have to put together, causing the problem you've seen), we can provide a *callback* that sets the configuration when the Google Cloud NIO provider is loaded. This is harder for future developers to wrap their heads around, but at least it would prevent this delay if NIO is not used. I'd like to think about this some more before doing something quite this drastic, though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504:1338,Integrability,wrap,wrap,1338,"Thank you @kshakir. What I see there is that the code sets the default NIO option, and as part of this is creates a google cloud `StorageOptions` object. Sadly for us, when this object is created it determines which Google credentials to use, and if nothing was specified by the user it will send some network messages to try to figure out whether it's running on a Google Compute Engine machine. When we wrote the default-setting code we didn't realize that setting the number of retries was going to cause a network message to be sent, with the associated potential retries and delays. We can't change the way Google Compute Engine works, or how the Google authentication works either. Ideally we'd want some way to only search for credentials when we know NIO is going to be used. The point of these defaults is that they're used for anything that uses NIO, including third-party library code. We can't fully replicate this behavior in a different way from the outside. So I think the ""correct"" fix would be to go deep inside the Google NIO library and change it so that instead of providing a default configuration (that the user would have to put together, causing the problem you've seen), we can provide a *callback* that sets the configuration when the Google Cloud NIO provider is loaded. This is harder for future developers to wrap their heads around, but at least it would prevent this delay if NIO is not used. I'd like to think about this some more before doing something quite this drastic, though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504:1105,Modifiability,config,configuration,1105,"Thank you @kshakir. What I see there is that the code sets the default NIO option, and as part of this is creates a google cloud `StorageOptions` object. Sadly for us, when this object is created it determines which Google credentials to use, and if nothing was specified by the user it will send some network messages to try to figure out whether it's running on a Google Compute Engine machine. When we wrote the default-setting code we didn't realize that setting the number of retries was going to cause a network message to be sent, with the associated potential retries and delays. We can't change the way Google Compute Engine works, or how the Google authentication works either. Ideally we'd want some way to only search for credentials when we know NIO is going to be used. The point of these defaults is that they're used for anything that uses NIO, including third-party library code. We can't fully replicate this behavior in a different way from the outside. So I think the ""correct"" fix would be to go deep inside the Google NIO library and change it so that instead of providing a default configuration (that the user would have to put together, causing the problem you've seen), we can provide a *callback* that sets the configuration when the Google Cloud NIO provider is loaded. This is harder for future developers to wrap their heads around, but at least it would prevent this delay if NIO is not used. I'd like to think about this some more before doing something quite this drastic, though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504:1238,Modifiability,config,configuration,1238,"Thank you @kshakir. What I see there is that the code sets the default NIO option, and as part of this is creates a google cloud `StorageOptions` object. Sadly for us, when this object is created it determines which Google credentials to use, and if nothing was specified by the user it will send some network messages to try to figure out whether it's running on a Google Compute Engine machine. When we wrote the default-setting code we didn't realize that setting the number of retries was going to cause a network message to be sent, with the associated potential retries and delays. We can't change the way Google Compute Engine works, or how the Google authentication works either. Ideally we'd want some way to only search for credentials when we know NIO is going to be used. The point of these defaults is that they're used for anything that uses NIO, including third-party library code. We can't fully replicate this behavior in a different way from the outside. So I think the ""correct"" fix would be to go deep inside the Google NIO library and change it so that instead of providing a default configuration (that the user would have to put together, causing the problem you've seen), we can provide a *callback* that sets the configuration when the Google Cloud NIO provider is loaded. This is harder for future developers to wrap their heads around, but at least it would prevent this delay if NIO is not used. I'd like to think about this some more before doing something quite this drastic, though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504:1290,Performance,load,loaded,1290,"Thank you @kshakir. What I see there is that the code sets the default NIO option, and as part of this is creates a google cloud `StorageOptions` object. Sadly for us, when this object is created it determines which Google credentials to use, and if nothing was specified by the user it will send some network messages to try to figure out whether it's running on a Google Compute Engine machine. When we wrote the default-setting code we didn't realize that setting the number of retries was going to cause a network message to be sent, with the associated potential retries and delays. We can't change the way Google Compute Engine works, or how the Google authentication works either. Ideally we'd want some way to only search for credentials when we know NIO is going to be used. The point of these defaults is that they're used for anything that uses NIO, including third-party library code. We can't fully replicate this behavior in a different way from the outside. So I think the ""correct"" fix would be to go deep inside the Google NIO library and change it so that instead of providing a default configuration (that the user would have to put together, causing the problem you've seen), we can provide a *callback* that sets the configuration when the Google Cloud NIO provider is loaded. This is harder for future developers to wrap their heads around, but at least it would prevent this delay if NIO is not used. I'd like to think about this some more before doing something quite this drastic, though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504
https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504:659,Security,authenticat,authentication,659,"Thank you @kshakir. What I see there is that the code sets the default NIO option, and as part of this is creates a google cloud `StorageOptions` object. Sadly for us, when this object is created it determines which Google credentials to use, and if nothing was specified by the user it will send some network messages to try to figure out whether it's running on a Google Compute Engine machine. When we wrote the default-setting code we didn't realize that setting the number of retries was going to cause a network message to be sent, with the associated potential retries and delays. We can't change the way Google Compute Engine works, or how the Google authentication works either. Ideally we'd want some way to only search for credentials when we know NIO is going to be used. The point of these defaults is that they're used for anything that uses NIO, including third-party library code. We can't fully replicate this behavior in a different way from the outside. So I think the ""correct"" fix would be to go deep inside the Google NIO library and change it so that instead of providing a default configuration (that the user would have to put together, causing the problem you've seen), we can provide a *callback* that sets the configuration when the Google Cloud NIO provider is loaded. This is harder for future developers to wrap their heads around, but at least it would prevent this delay if NIO is not used. I'd like to think about this some more before doing something quite this drastic, though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3491#issuecomment-443837504
https://github.com/broadinstitute/gatk/pull/3494#issuecomment-324476830:2964,Deployability,pipeline,pipelines,2964,l=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9tY21jL1BhcmFtZXRlcldyaXRlci5qYXZh) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | [...roadinstitute/hellbender/utils/svd/SVDFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zdmQvU1ZERmFjdG9yeS5qYXZh) | `0% <0%> (-85.714%)` | `0% <0%> (-3%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...broadinstitute/hellbender/utils/read/GATKRead.java](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL0dBVEtSZWFkLmphdmE=) | `31.25% <0%> (-68.75%)` | `7% <0%> (-6%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...titute/hellbender/engine/spark/JsonSerializer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvSnNvblNlcmlhbGl6ZXIuamF2YQ==) | `0% <0%> (-63.636%)` | `0% <0%> (-4%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | ... and [890 more](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3494#issuecomment-324476830
https://github.com/broadinstitute/gatk/pull/3494#issuecomment-324476830:3567,Testability,test,test,3567,l=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9tY21jL1BhcmFtZXRlcldyaXRlci5qYXZh) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | [...roadinstitute/hellbender/utils/svd/SVDFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zdmQvU1ZERmFjdG9yeS5qYXZh) | `0% <0%> (-85.714%)` | `0% <0%> (-3%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...broadinstitute/hellbender/utils/read/GATKRead.java](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL0dBVEtSZWFkLmphdmE=) | `31.25% <0%> (-68.75%)` | `7% <0%> (-6%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...titute/hellbender/engine/spark/JsonSerializer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvSnNvblNlcmlhbGl6ZXIuamF2YQ==) | `0% <0%> (-63.636%)` | `0% <0%> (-4%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | ... and [890 more](https://codecov.io/gh/broadinstitute/gatk/pull/3494/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3494#issuecomment-324476830
https://github.com/broadinstitute/gatk/pull/3494#issuecomment-331990229:64,Testability,test,test,64,Added a few comments requesting clarification about some of the test cases. The branch also needs to be rebased onto the latest master before we can proceed.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3494#issuecomment-331990229
https://github.com/broadinstitute/gatk/pull/3494#issuecomment-418464574:78,Deployability,patch,patch,78,"@davidbenjamin The merge conflict here is potentially a little tricky, as the patch conflicts with some code you added recently. Would you mind taking a look? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3494#issuecomment-418464574
https://github.com/broadinstitute/gatk/pull/3494#issuecomment-418471397:230,Safety,safe,safe,230,"@droazen I believe @DonFreed's new code can be inserted before my new code with no change to either. His code deals with the non-hard-clipped part of the read, and all my code does is add the hard clips to the cigar. I think it's safe to add naively.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3494#issuecomment-418471397
https://github.com/broadinstitute/gatk/pull/3495#issuecomment-324605546:1835,Testability,test,test,1835,e/gatk/pull/3495?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `55.263% <0%> (-19.079%)` | `30% <0%> (-8%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGV,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3495#issuecomment-324605546
https://github.com/broadinstitute/gatk/pull/3495#issuecomment-324605546:3285,Testability,test,test,3285,=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `55.263% <0%> (-19.079%)` | `30% <0%> (-8%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `70.37% <0%> (-11.111%)` | `10% <0%> ()` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `78.519% <0%> (-5.185%)` | `31% <0%> (-5%)` | |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3495#issuecomment-324605546
https://github.com/broadinstitute/gatk/pull/3495#issuecomment-324605546:3580,Testability,test,test,3580,=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `55.263% <0%> (-19.079%)` | `30% <0%> (-8%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `10.169% <0%> (-13.559%)` | `1% <0%> (-1%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `70.37% <0%> (-11.111%)` | `10% <0%> ()` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `78.519% <0%> (-5.185%)` | `31% <0%> (-5%)` | |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/3495?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3495#issuecomment-324605546
https://github.com/broadinstitute/gatk/issues/3497#issuecomment-354784074:89,Deployability,continuous,continuous,89,This immediate task is effectively closed by PR #4020 . In the long-run this is really a continuous improvement task.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3497#issuecomment-354784074
https://github.com/broadinstitute/gatk/issues/3501#issuecomment-324724782:296,Availability,down,down,296,"@cmnbroad has volunteered to implement `PythonScriptExecutor` (should be quick), plus an example tool. Then he'll turn things over to @samuelklee and the CNV team to implement a prototype ML tool, after which we'll do the evaluation outlined above and decide whether this is the right path to go down.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501#issuecomment-324724782
https://github.com/broadinstitute/gatk/issues/3501#issuecomment-325040324:103,Availability,alive,alive,103,"@droazen ideally, the executor must be able to fire up one (or more) python kernels and keep it (them) alive as long as the user decides to keep it (or the GATK session terminates). Here's an example why this is desirable: the compilation of a complicated theano computational graph can take a significant portion of the total computation time. The compiled graph is a function of data dimensions, which in my use case, varies from loci to loci. My current solution to this is to pre-compile and cache a number of theano computational graphs with different sizes, pad the data to fit it to the closest matching computational graph, and re-use the same compiled graph(s) as required. To this end, one needs to keep the python kernel w/ the compiled graphs alive.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501#issuecomment-325040324
https://github.com/broadinstitute/gatk/issues/3501#issuecomment-325040324:755,Availability,alive,alive,755,"@droazen ideally, the executor must be able to fire up one (or more) python kernels and keep it (them) alive as long as the user decides to keep it (or the GATK session terminates). Here's an example why this is desirable: the compilation of a complicated theano computational graph can take a significant portion of the total computation time. The compiled graph is a function of data dimensions, which in my use case, varies from loci to loci. My current solution to this is to pre-compile and cache a number of theano computational graphs with different sizes, pad the data to fit it to the closest matching computational graph, and re-use the same compiled graph(s) as required. To this end, one needs to keep the python kernel w/ the compiled graphs alive.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501#issuecomment-325040324
https://github.com/broadinstitute/gatk/issues/3501#issuecomment-325040324:496,Performance,cache,cache,496,"@droazen ideally, the executor must be able to fire up one (or more) python kernels and keep it (them) alive as long as the user decides to keep it (or the GATK session terminates). Here's an example why this is desirable: the compilation of a complicated theano computational graph can take a significant portion of the total computation time. The compiled graph is a function of data dimensions, which in my use case, varies from loci to loci. My current solution to this is to pre-compile and cache a number of theano computational graphs with different sizes, pad the data to fit it to the closest matching computational graph, and re-use the same compiled graph(s) as required. To this end, one needs to keep the python kernel w/ the compiled graphs alive.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3501#issuecomment-325040324
https://github.com/broadinstitute/gatk/issues/3510#issuecomment-353631513:239,Deployability,release,release,239,@sooheelee I fixed the javadoc and added a logger warning letting users know that they must input a .args file for their vcfs list. When I copy your .list file to a .args file everything works. I'm going to address the other stuff for the release as well.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3510#issuecomment-353631513
https://github.com/broadinstitute/gatk/issues/3510#issuecomment-353631513:43,Testability,log,logger,43,@sooheelee I fixed the javadoc and added a logger warning letting users know that they must input a .args file for their vcfs list. When I copy your .list file to a .args file everything works. I'm going to address the other stuff for the release as well.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3510#issuecomment-353631513
https://github.com/broadinstitute/gatk/issues/3510#issuecomment-355053317:34,Usability,learn,learning,34,"Thanks, @davidbenjamin. I started learning Java over the break as planned. I'm a quarter in to my intro to Java class. So at this point, I think it best to leave the review to those who are more versed in the language.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3510#issuecomment-355053317
https://github.com/broadinstitute/gatk/pull/3515#issuecomment-325021094:944,Performance,optimiz,optimization,944,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3515?src=pr&el=h1) Report; > Merging [#3515](https://codecov.io/gh/broadinstitute/gatk/pull/3515?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/a218b6bbf6b3f243bce34a30f2458308319aadf3?src=pr&el=desc) will **increase** coverage by `0.012%`.; > The diff coverage is `84.946%`. ```diff; @@ Coverage Diff @@; ## master #3515 +/- ##; ===============================================; + Coverage 79.905% 79.917% +0.012% ; - Complexity 17918 17945 +27 ; ===============================================; Files 1199 1200 +1 ; Lines 65102 65195 +93 ; Branches 10142 10160 +18 ; ===============================================; + Hits 52020 52102 +82 ; - Misses 9042 9049 +7 ; - Partials 4040 4044 +4; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3515?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...umber/utils/optimization/PersistenceOptimizer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3515?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL29wdGltaXphdGlvbi9QZXJzaXN0ZW5jZU9wdGltaXplci5qYXZh) | `84.946% <84.946%> ()` | `27 <27> (?)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3515?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `78.571% <0%> (+0.649%)` | `39% <0%> ()` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3515?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `73.973% <0%> (+2.74%)` | `11% <0%> ()` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3515#issuecomment-325021094
https://github.com/broadinstitute/gatk/pull/3515#issuecomment-329054563:62,Testability,test,test,62,"Addressed review comments, expanded documentation, added some test cases, and did some minor renaming/cleanup. Thanks, back to you @asmirnov239!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3515#issuecomment-329054563
https://github.com/broadinstitute/gatk/pull/3519#issuecomment-325039173:43,Testability,test,tests,43,All comments addressed -- will merge after tests pass.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3519#issuecomment-325039173
https://github.com/broadinstitute/gatk/issues/3520#issuecomment-367072562:23,Safety,detect,detect,23,"@cmnbroad How about we detect the common case of filters composed using only AND, and use simplified output in that case, and revert back to the complex output when filters are composed in more complex ways? That would resolve the problem in practice, since (as far as I know) all of the filters we actually use are composed using only AND.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3520#issuecomment-367072562
https://github.com/broadinstitute/gatk/issues/3520#issuecomment-367072562:90,Usability,simpl,simplified,90,"@cmnbroad How about we detect the common case of filters composed using only AND, and use simplified output in that case, and revert back to the complex output when filters are composed in more complex ways? That would resolve the problem in practice, since (as far as I know) all of the filters we actually use are composed using only AND.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3520#issuecomment-367072562
https://github.com/broadinstitute/gatk/issues/3521#issuecomment-325505585:210,Deployability,update,updated,210,After talking to @SHuang-Broad seems that this might be kind of expected. The exception thrown however shows lack of checking the assumptions made by the method. Lets put this **on hold** as this code might be updated in the near future.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3521#issuecomment-325505585
https://github.com/broadinstitute/gatk/pull/3525#issuecomment-325343138:1839,Deployability,pipeline,pipelines,1839,5?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `86.4% <> ()` | `50 <0> ()` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3525#issuecomment-325343138
https://github.com/broadinstitute/gatk/pull/3525#issuecomment-325343138:2450,Testability,test,test,2450,lbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...institute/hellbender/utils/gcs/GATKGCSOptions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvR0FUS0dDU09wdGlvbnMuamF2YQ==) | `0% <0%> (-66.667%)` | `0% <0%> ()` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `22.013% <0%> (-62.264%)` | `8% <0%> (-26%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...llbender/engine/spark/SparkCommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb21tYW5kTGluZVByb2dyYW0uamF2YQ==) | `68.75% <0%> (-25%)` | `6% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.545% <0%> (-24.026%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/3525?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGV,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3525#issuecomment-325343138
https://github.com/broadinstitute/gatk/pull/3526#issuecomment-345816099:34,Availability,error,error,34,Travis failed with some sort of R error:; ```; Stderr: Error in library(optparse) : there is no package called optparse; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3526#issuecomment-345816099
https://github.com/broadinstitute/gatk/pull/3526#issuecomment-345816099:55,Availability,Error,Error,55,Travis failed with some sort of R error:; ```; Stderr: Error in library(optparse) : there is no package called optparse; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3526#issuecomment-345816099
https://github.com/broadinstitute/gatk/pull/3526#issuecomment-346370425:40,Availability,error,error,40,"@jean-philippe-martin There was another error in one build job in the travis matrix, but it looks transient, and unrelated. I restarted that build.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3526#issuecomment-346370425
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-325462858:4,Deployability,integrat,integration,4,"The integration tests I had for the allele-specific annotations admittedly had very small VCFs, but they were very, very gross variants. :) At the very least, the rank sums need test data that have a 0/1 sample and a 0/2 sample.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-325462858
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-325462858:4,Integrability,integrat,integration,4,"The integration tests I had for the allele-specific annotations admittedly had very small VCFs, but they were very, very gross variants. :) At the very least, the rank sums need test data that have a 0/1 sample and a 0/2 sample.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-325462858
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-325462858:16,Testability,test,tests,16,"The integration tests I had for the allele-specific annotations admittedly had very small VCFs, but they were very, very gross variants. :) At the very least, the rank sums need test data that have a 0/1 sample and a 0/2 sample.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-325462858
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-325462858:178,Testability,test,test,178,"The integration tests I had for the allele-specific annotations admittedly had very small VCFs, but they were very, very gross variants. :) At the very least, the rank sums need test data that have a 0/1 sample and a 0/2 sample.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-325462858
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:30,Testability,test,tests,30,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:60,Testability,test,testBaseQualRawAnnotate,60,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:102,Testability,Assert,AssertionError,102,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:177,Testability,test,testng,177,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:184,Testability,Assert,Assert,184,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:196,Testability,Assert,Assert,196,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:220,Testability,test,testng,220,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:227,Testability,Assert,Assert,227,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:248,Testability,Assert,Assert,248,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:273,Testability,test,testng,273,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:280,Testability,Assert,Assert,280,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:287,Testability,assert,assertEqualsImpl,287,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:304,Testability,Assert,Assert,304,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:329,Testability,test,testng,329,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:336,Testability,Assert,Assert,336,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:343,Testability,assert,assertEquals,343,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:356,Testability,Assert,Assert,356,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:381,Testability,test,testng,381,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:388,Testability,Assert,Assert,388,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:395,Testability,assert,assertEquals,395,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:408,Testability,Assert,Assert,408,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631:514,Testability,test,testBaseQualRawAnnotate,514,"@jamesemery It looks like the tests are failing with:. ```; testBaseQualRawAnnotate FAILED; java.lang.AssertionError: expected [50,1,60,1|10,1,20,1] but found [|-1.4,1]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:115); at org.testng.Assert.assertEquals(Assert.java:178); at org.broadinstitute.hellbender.tools.walkers.annotator.BaseQualityRankSumTestUnitTest.testBaseQualRawAnnotate(BaseQualityRankSumTestUnitTest.java:97); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326647631
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326651102:55,Testability,test,test,55,@lbergelson Looks like i accidentally reactivated that test. The forward port of https://github.com/broadinstitute/gsa-unstable/pull/1541 broke that test as its now actually calculating something different entirely. I'll change it to properly reflect the new output.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326651102
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326651102:149,Testability,test,test,149,@lbergelson Looks like i accidentally reactivated that test. The forward port of https://github.com/broadinstitute/gsa-unstable/pull/1541 broke that test as its now actually calculating something different entirely. I'll change it to properly reflect the new output.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-326651102
https://github.com/broadinstitute/gatk/pull/3527#issuecomment-333551290:40,Deployability,update,updated,40,"@droazen @ldgauthier just a heads up, I updated the commit and pulled in a bunch of fixes I made to get the finalizeRawAnnotation code working, so this is in a much better state now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3527#issuecomment-333551290
https://github.com/broadinstitute/gatk/issues/3528#issuecomment-331237941:209,Deployability,release,release,209,@lbergelson Hey Louis. The user just asked about this. Is this something you guys are willing to look into? I guess it would be nice to let the user know if this is something that will be fixed in the general release or the next beta release or never.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3528#issuecomment-331237941
https://github.com/broadinstitute/gatk/issues/3528#issuecomment-331237941:234,Deployability,release,release,234,@lbergelson Hey Louis. The user just asked about this. Is this something you guys are willing to look into? I guess it would be nice to let the user know if this is something that will be fixed in the general release or the next beta release or never.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3528#issuecomment-331237941
https://github.com/broadinstitute/gatk/issues/3528#issuecomment-332942323:229,Deployability,release,release,229,"I am pretty sure GATK3 HC did not call this. But, I am checking now. I put this in GATK4 because I know it will not be fixed in GATK3. I can let the user know this is not high priority for now? We will get to bugs after the main release?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3528#issuecomment-332942323
https://github.com/broadinstitute/gatk/issues/3528#issuecomment-332945722:132,Deployability,release,release,132,"Yeah, we'd obviously like to fix any bugs, and having the test case will be really useful. We might be able to get to it before the release, but it won't be for a little bit.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3528#issuecomment-332945722
https://github.com/broadinstitute/gatk/issues/3528#issuecomment-332945722:58,Testability,test,test,58,"Yeah, we'd obviously like to fix any bugs, and having the test case will be really useful. We might be able to get to it before the release, but it won't be for a little bit.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3528#issuecomment-332945722
https://github.com/broadinstitute/gatk/issues/3528#issuecomment-358781536:85,Deployability,release,release,85,"The user is really eager for this fix to go in, so I told him it will be in the next release (4.1). I hope this is alright.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3528#issuecomment-358781536
https://github.com/broadinstitute/gatk/issues/3529#issuecomment-383723121:182,Availability,reliab,reliably,182,"obsolete now as we switched to a different strategy: contigs that used to trigger InvDup calls are now classified as ""incomplete"" because the duplicated region could not be inferred reliably from the contig's alignments alone",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3529#issuecomment-383723121
https://github.com/broadinstitute/gatk/pull/3530#issuecomment-325497752:1559,Deployability,pipeline,pipelines,1559,=============; Files 1188 1188 ; Lines 64410 64543 +133 ; Branches 10004 10022 +18 ; ==============================================; + Hits 51579 51705 +126 ; Misses 8845 8845 ; - Partials 3986 3993 +7; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYWxpZGF0ZVZhcmlhbnRzLmphdmE=) | `82.857% <100%> (+0.504%)` | `34 <0> (+2)` | :arrow_up: |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `89.831% <0%> (-0.847%)` | `23% <0%> (-1%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `92.857% <0%> (-0.246%)` | `16% <0%> (+8%)` | |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaC5qYXZh) | `88.101% <0%> (+0.253%)` | `142% <0%> (+1%)` | :arrow_up: |; | [...institute/hellbender/utils/GenomeLocSortedSet.java](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vbWVMb2NTb3J0ZWRTZXQuamF2YQ==) | `93.793% <0%> (+0.69%)` | `59% <0%> ()` | :arrow_down: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinsti,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3530#issuecomment-325497752
https://github.com/broadinstitute/gatk/pull/3530#issuecomment-325497752:947,Security,Validat,ValidateVariants,947,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=h1) Report; > Merging [#3530](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/bfa9af462f484c77597a9fdbdc46f66393afaff1?src=pr&el=desc) will **increase** coverage by `0.03%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #3530 +/- ##; ==============================================; + Coverage 80.079% 80.109% +0.03% ; - Complexity 17760 17791 +31 ; ==============================================; Files 1188 1188 ; Lines 64410 64543 +133 ; Branches 10004 10022 +18 ; ==============================================; + Hits 51579 51705 +126 ; Misses 8845 8845 ; - Partials 3986 3993 +7; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYWxpZGF0ZVZhcmlhbnRzLmphdmE=) | `82.857% <100%> (+0.504%)` | `34 <0> (+2)` | :arrow_up: |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `89.831% <0%> (-0.847%)` | `23% <0%> (-1%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `92.857% <0%> (-0.246%)` | `16% <0%> (+8%)` | |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/3530?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRp,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3530#issuecomment-325497752
https://github.com/broadinstitute/gatk/pull/3531#issuecomment-325502243:81,Testability,test,testing-code,81,@SHuang-Broad sorry that is just over 1000 lines... that said alot of it is just testing-code; I don't know what you do with testing c. I normally don't care much about its form.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3531#issuecomment-325502243
https://github.com/broadinstitute/gatk/pull/3531#issuecomment-325502243:125,Testability,test,testing,125,@SHuang-Broad sorry that is just over 1000 lines... that said alot of it is just testing-code; I don't know what you do with testing c. I normally don't care much about its form.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3531#issuecomment-325502243
https://github.com/broadinstitute/gatk/pull/3531#issuecomment-325508326:66,Testability,test,testing,66,"@vruano , I try to look at them if the main purpose of this PR is testing, which I totally understand for Cigar related acrobatics.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3531#issuecomment-325508326
https://github.com/broadinstitute/gatk/pull/3531#issuecomment-325509985:35,Testability,test,testing,35,"The main propose of this PR is not testing but to add those utilities that I'm using as part of some of the PR coming after this one. In theory testing must always be exhaustive (provide a good coverage). . What I wanted to say is that I don't think that one should worried much whether the testing code looks good or not. I know some people are as stringent with testing code as with production code, if you are one of them, then sorry for the extra work.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3531#issuecomment-325509985
https://github.com/broadinstitute/gatk/pull/3531#issuecomment-325509985:144,Testability,test,testing,144,"The main propose of this PR is not testing but to add those utilities that I'm using as part of some of the PR coming after this one. In theory testing must always be exhaustive (provide a good coverage). . What I wanted to say is that I don't think that one should worried much whether the testing code looks good or not. I know some people are as stringent with testing code as with production code, if you are one of them, then sorry for the extra work.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3531#issuecomment-325509985
https://github.com/broadinstitute/gatk/pull/3531#issuecomment-325509985:291,Testability,test,testing,291,"The main propose of this PR is not testing but to add those utilities that I'm using as part of some of the PR coming after this one. In theory testing must always be exhaustive (provide a good coverage). . What I wanted to say is that I don't think that one should worried much whether the testing code looks good or not. I know some people are as stringent with testing code as with production code, if you are one of them, then sorry for the extra work.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3531#issuecomment-325509985
https://github.com/broadinstitute/gatk/pull/3531#issuecomment-325509985:364,Testability,test,testing,364,"The main propose of this PR is not testing but to add those utilities that I'm using as part of some of the PR coming after this one. In theory testing must always be exhaustive (provide a good coverage). . What I wanted to say is that I don't think that one should worried much whether the testing code looks good or not. I know some people are as stringent with testing code as with production code, if you are one of them, then sorry for the extra work.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3531#issuecomment-325509985
https://github.com/broadinstitute/gatk/pull/3531#issuecomment-326697886:180,Testability,test,testing,180,"@SHuang-Broad please take a look at changes. I have moved soft/hardReclip code output of CigarUtils into AlignmentInterval where it is used. Is ""package"" protected for the sake of testing otherwise it would be private. Thanks, V.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3531#issuecomment-326697886
https://github.com/broadinstitute/gatk/pull/3531#issuecomment-327613819:55,Testability,test,tests,55,"I have addressed @mwalker174 comments, Will merge once tests pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3531#issuecomment-327613819
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152:104,Availability,error,error,104,"@erniebrau, the mesage and log file corresponds to the latest master (GKL 0.5.8); for the GKL 0.5.3 the error message is the following:. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011dc557f4, pid=20586, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression1417468606951982528.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid20586.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. And the log file: [hs_err_pid20586.log.txt](https://github.com/broadinstitute/gatk/files/1264191/hs_err_pid20586.log.txt). Let me know if you need more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152:155,Availability,error,error,155,"@erniebrau, the mesage and log file corresponds to the latest master (GKL 0.5.8); for the GKL 0.5.3 the error message is the following:. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011dc557f4, pid=20586, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression1417468606951982528.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid20586.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. And the log file: [hs_err_pid20586.log.txt](https://github.com/broadinstitute/gatk/files/1264191/hs_err_pid20586.log.txt). Let me know if you need more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152:751,Availability,error,error,751,"@erniebrau, the mesage and log file corresponds to the latest master (GKL 0.5.8); for the GKL 0.5.3 the error message is the following:. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011dc557f4, pid=20586, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression1417468606951982528.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid20586.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. And the log file: [hs_err_pid20586.log.txt](https://github.com/broadinstitute/gatk/files/1264191/hs_err_pid20586.log.txt). Let me know if you need more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152:110,Integrability,message,message,110,"@erniebrau, the mesage and log file corresponds to the latest master (GKL 0.5.8); for the GKL 0.5.3 the error message is the following:. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011dc557f4, pid=20586, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression1417468606951982528.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid20586.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. And the log file: [hs_err_pid20586.log.txt](https://github.com/broadinstitute/gatk/files/1264191/hs_err_pid20586.log.txt). Let me know if you need more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152:170,Safety,detect,detected,170,"@erniebrau, the mesage and log file corresponds to the latest master (GKL 0.5.8); for the GKL 0.5.3 the error message is the following:. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011dc557f4, pid=20586, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression1417468606951982528.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid20586.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. And the log file: [hs_err_pid20586.log.txt](https://github.com/broadinstitute/gatk/files/1264191/hs_err_pid20586.log.txt). Let me know if you need more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152:27,Testability,log,log,27,"@erniebrau, the mesage and log file corresponds to the latest master (GKL 0.5.8); for the GKL 0.5.3 the error message is the following:. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011dc557f4, pid=20586, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression1417468606951982528.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid20586.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. And the log file: [hs_err_pid20586.log.txt](https://github.com/broadinstitute/gatk/files/1264191/hs_err_pid20586.log.txt). Let me know if you need more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152:858,Testability,log,log,858,"@erniebrau, the mesage and log file corresponds to the latest master (GKL 0.5.8); for the GKL 0.5.3 the error message is the following:. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011dc557f4, pid=20586, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression1417468606951982528.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid20586.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. And the log file: [hs_err_pid20586.log.txt](https://github.com/broadinstitute/gatk/files/1264191/hs_err_pid20586.log.txt). Let me know if you need more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152:1115,Testability,log,log,1115,"@erniebrau, the mesage and log file corresponds to the latest master (GKL 0.5.8); for the GKL 0.5.3 the error message is the following:. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011dc557f4, pid=20586, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression1417468606951982528.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid20586.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. And the log file: [hs_err_pid20586.log.txt](https://github.com/broadinstitute/gatk/files/1264191/hs_err_pid20586.log.txt). Let me know if you need more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152:1142,Testability,log,log,1142,"@erniebrau, the mesage and log file corresponds to the latest master (GKL 0.5.8); for the GKL 0.5.3 the error message is the following:. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011dc557f4, pid=20586, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression1417468606951982528.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid20586.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. And the log file: [hs_err_pid20586.log.txt](https://github.com/broadinstitute/gatk/files/1264191/hs_err_pid20586.log.txt). Let me know if you need more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152:1220,Testability,log,log,1220,"@erniebrau, the mesage and log file corresponds to the latest master (GKL 0.5.8); for the GKL 0.5.3 the error message is the following:. ```; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGILL (0x4) at pc=0x000000011dc557f4, pid=20586, tid=20739; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression1417468606951982528.dylib+0x17f4] Java_com_intel_gkl_compression_IntelDeflater_resetNative+0x164; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/daniel/workspaces/ReadTools/hs_err_pid20586.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```. And the log file: [hs_err_pid20586.log.txt](https://github.com/broadinstitute/gatk/files/1264191/hs_err_pid20586.log.txt). Let me know if you need more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-326031152
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-328778797:81,Availability,down,downstream,81,"Any progress on this, @erniebrau? I would like to update to the latest master my downstream project... Thanks in advance!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-328778797
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-328778797:50,Deployability,update,update,50,"Any progress on this, @erniebrau? I would like to update to the latest master my downstream project... Thanks in advance!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-328778797
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-329198004:15,Deployability,update,update,15,"Thanks for the update, @erniebrau - I would answer every question as soon as I read it. Thank you for doing this!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-329198004
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-330240343:41,Usability,simpl,simple,41,@magicDGS Can you please compile (with a simple `g++ avx-all.cpp`) and run the short program below on the affected Mac and report back the output? This is basically the code being executed by GKL to determine if AVX is supported. Code to compile and run (zipped): [code.zip](https://github.com/broadinstitute/gatk/files/1310975/code.zip),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-330240343
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-330636186:99,Deployability,release,release,99,"@magicDGS We have an idea of what the problem is. If we're right, it will be fixed in the next GKL release, which should happen sometime tomorrow. I will then create a GATK branch that uses the new GKL release for you to test (and to ultimately merge into master). If we're wrong about what is causing the problem, we will have to continue to debug. Sorry about the slowness of this process. Like I said before, it's mostly due to us not having a system where we can reproduce the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-330636186
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-330636186:202,Deployability,release,release,202,"@magicDGS We have an idea of what the problem is. If we're right, it will be fixed in the next GKL release, which should happen sometime tomorrow. I will then create a GATK branch that uses the new GKL release for you to test (and to ultimately merge into master). If we're wrong about what is causing the problem, we will have to continue to debug. Sorry about the slowness of this process. Like I said before, it's mostly due to us not having a system where we can reproduce the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-330636186
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-330636186:221,Testability,test,test,221,"@magicDGS We have an idea of what the problem is. If we're right, it will be fixed in the next GKL release, which should happen sometime tomorrow. I will then create a GATK branch that uses the new GKL release for you to test (and to ultimately merge into master). If we're wrong about what is causing the problem, we will have to continue to debug. Sorry about the slowness of this process. Like I said before, it's mostly due to us not having a system where we can reproduce the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-330636186
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-330808237:52,Deployability,release,release,52,Thanks @erniebrau! Looking forward to test the next release of GKL.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-330808237
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-330808237:38,Testability,test,test,38,Thanks @erniebrau! Looking forward to test the next release of GKL.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-330808237
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-331930379:48,Deployability,release,release,48,@magicDGS Just want to keep you up-to-date. The release is taking a bit longer than expected. I'll let you know when it's out so you can test it out.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-331930379
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-331930379:137,Testability,test,test,137,@magicDGS Just want to keep you up-to-date. The release is taking a bit longer than expected. I'll let you know when it's out so you can test it out.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-331930379
https://github.com/broadinstitute/gatk/issues/3532#issuecomment-332446347:57,Availability,failure,failure,57,Thanks @erniebrau - with GKL 0.7 I do not experience any failure anymore!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3532#issuecomment-332446347
https://github.com/broadinstitute/gatk/pull/3533#issuecomment-325981458:1786,Availability,Down,DownsampleableSparkReadShard,1786,](https://codecov.io/gh/broadinstitute/gatk/pull/3533?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...oadinstitute/hellbender/engine/AssemblyRegion.java](https://codecov.io/gh/broadinstitute/gatk/pull/3533?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXNzZW1ibHlSZWdpb24uamF2YQ==) | `82.946% <> (-1.412%)` | `45 <0> (-14)` | |; | [...bender/engine/spark/AssemblyRegionWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3533?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvQXNzZW1ibHlSZWdpb25XYWxrZXJTcGFyay5qYXZh) | `0% <0%> ()` | `0 <0> ()` | :arrow_down: |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3533?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `83% <100%> (-0.168%)` | `25 <1> ()` | |; | [...hellbender/tools/DownsampleableSparkReadShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/3533?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Eb3duc2FtcGxlYWJsZVNwYXJrUmVhZFNoYXJkLmphdmE=) | `81.818% <0%> (-9.091%)` | `3% <0%> (-1%)` | |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/3533?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaC5qYXZh) | `87.848% <0%> (-0.253%)` | `141% <0%> (-1%)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/3533?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `90.678% <0%> ()` | `24% <0%> ()` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstit,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3533#issuecomment-325981458
https://github.com/broadinstitute/gatk/pull/3533#issuecomment-326366040:21,Performance,perform,performance,21,"This change degrades performance on Spark, so should not be merged.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3533#issuecomment-326366040
https://github.com/broadinstitute/gatk/pull/3533#issuecomment-330905564:31,Performance,perform,performance,31,"@tomwhite I'm looking into the performance issues now with the new code path -- it brings the output much closer to GATK3, but clearly needs some profiling work. Can you tell me what kind of difference you saw in the runtime on Spark? Eg., was it on the order of 20-30%, or was it worse than that?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3533#issuecomment-330905564
https://github.com/broadinstitute/gatk/pull/3533#issuecomment-330905564:127,Usability,clear,clearly,127,"@tomwhite I'm looking into the performance issues now with the new code path -- it brings the output much closer to GATK3, but clearly needs some profiling work. Can you tell me what kind of difference you saw in the runtime on Spark? Eg., was it on the order of 20-30%, or was it worse than that?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3533#issuecomment-330905564
https://github.com/broadinstitute/gatk/pull/3533#issuecomment-330907379:54,Deployability,pipeline,pipeline,54,@droazen it was a lot worse - running the whole reads pipeline on an exome went from ~50 min to ~180 min.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3533#issuecomment-330907379
https://github.com/broadinstitute/gatk/issues/3534#issuecomment-333964173:121,Availability,error,errors,121,"But the good news is IndexFeatureFile works now ? We have not had any users report this, but I just tried it, and got no errors :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3534#issuecomment-333964173
https://github.com/broadinstitute/gatk/pull/3537#issuecomment-329907772:113,Deployability,integrat,integration,113,"Thank you for your review, @vruano ! I addressed each of your comments. In the process, I discovered a bug in an integration test that needed fixing, which is added as another commit.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3537#issuecomment-329907772
https://github.com/broadinstitute/gatk/pull/3537#issuecomment-329907772:113,Integrability,integrat,integration,113,"Thank you for your review, @vruano ! I addressed each of your comments. In the process, I discovered a bug in an integration test that needed fixing, which is added as another commit.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3537#issuecomment-329907772
https://github.com/broadinstitute/gatk/pull/3537#issuecomment-329907772:125,Testability,test,test,125,"Thank you for your review, @vruano ! I addressed each of your comments. In the process, I discovered a bug in an integration test that needed fixing, which is added as another commit.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3537#issuecomment-329907772
https://github.com/broadinstitute/gatk/pull/3538#issuecomment-326306087:103,Integrability,message,message,103,"@davidbenjamin Just added an additional automated test thanks to @sooheelee , but please ignore commit message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3538#issuecomment-326306087
https://github.com/broadinstitute/gatk/pull/3538#issuecomment-326306087:50,Testability,test,test,50,"@davidbenjamin Just added an additional automated test thanks to @sooheelee , but please ignore commit message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3538#issuecomment-326306087
https://github.com/broadinstitute/gatk/pull/3539#issuecomment-326609538:24,Testability,test,test,24,@tomwhite  The fix and test look good to me.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3539#issuecomment-326609538
https://github.com/broadinstitute/gatk/issues/3541#issuecomment-331950525:68,Performance,perform,performance,68,I think we discovered at some point that IntervalSkipList has worse performance than htsjdk `OverlapDetector`. We should probably be deprecating and removing it. #3608,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3541#issuecomment-331950525
https://github.com/broadinstitute/gatk/pull/3542#issuecomment-327489556:68,Integrability,Depend,Depending,68,"A quick high-level comment: what if the CNV interval is very large? Depending on the algorithm it could be 10s or 100s of kb. I'm worried that that could create a too-large assembly. One possible solution is that we might want to only create evidence intervals around the proposed breakpoints of the interval, based on adding some amount of slop around each breakpoint (since these inputs are from read-depth based CNV callers that won't be able to identify the breakpoint with single-nucleotide precision). It might take some analysis of the input parameters to figure out the right parameters for this type of approach, which we could do in a subsequent task if you want. Another option would be to offload that type of processing into a different tool depending on the CNV caller being used (ie a GenomeSTRipCNVCallPreprocessor or gCNVCallPreprocessor) if we think that the right approach might vary with the algorithm being used.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3542#issuecomment-327489556
https://github.com/broadinstitute/gatk/pull/3542#issuecomment-327489556:755,Integrability,depend,depending,755,"A quick high-level comment: what if the CNV interval is very large? Depending on the algorithm it could be 10s or 100s of kb. I'm worried that that could create a too-large assembly. One possible solution is that we might want to only create evidence intervals around the proposed breakpoints of the interval, based on adding some amount of slop around each breakpoint (since these inputs are from read-depth based CNV callers that won't be able to identify the breakpoint with single-nucleotide precision). It might take some analysis of the input parameters to figure out the right parameters for this type of approach, which we could do in a subsequent task if you want. Another option would be to offload that type of processing into a different tool depending on the CNV caller being used (ie a GenomeSTRipCNVCallPreprocessor or gCNVCallPreprocessor) if we think that the right approach might vary with the algorithm being used.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3542#issuecomment-327489556
https://github.com/broadinstitute/gatk/pull/3542#issuecomment-327499474:11,Integrability,depend,depends,11,"I guess it depends on how general we want to keep this input path. I think most purely read-depth based callers won't really be able to discover events smaller than 800bp or so (maybe 500bp at the lower limit) with any accuracy. I also don't know of any tools that we're considering that will describe individual breakpoints. . What about this for a rule: create two intervals for the start and end of the CNV interval + or - 151 bases (allowing a read length of slop). If the two intervals overlap, merge them together into a single evidence interval. . We could also make the slop amount parameterizable per input file, since different tools might have different characteristics, although that would be a feature we could just make a ticket for until we need it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3542#issuecomment-327499474
https://github.com/broadinstitute/gatk/pull/3542#issuecomment-327499474:590,Modifiability,parameteriz,parameterizable,590,"I guess it depends on how general we want to keep this input path. I think most purely read-depth based callers won't really be able to discover events smaller than 800bp or so (maybe 500bp at the lower limit) with any accuracy. I also don't know of any tools that we're considering that will describe individual breakpoints. . What about this for a rule: create two intervals for the start and end of the CNV interval + or - 151 bases (allowing a read length of slop). If the two intervals overlap, merge them together into a single evidence interval. . We could also make the slop amount parameterizable per input file, since different tools might have different characteristics, although that would be a feature we could just make a ticket for until we need it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3542#issuecomment-327499474
https://github.com/broadinstitute/gatk/pull/3546#issuecomment-327496420:3349,Testability,test,test,3349,Rlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `78.313% <0%> (+1.205%)` | `27% <0%> (+2%)` | :arrow_up: |; | [...adinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `90.909% <0%> (+1.515%)` | `63% <0%> (+2%)` | :arrow_up: |; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `74.803% <0%> (+1.575%)` | `40% <0%> (+2%)` | :arrow_up: |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `69.474% <0%> (+3.158%)` | `28% <0%> ()` | :arrow_down: |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/3546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `68.033% <0%> (+3.279%)` | `3% <0%> ()` | :arrow_down: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `83.704% <0%> (+5.185%)` | `36% <0%> (+5%)` | :arrow_up: |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `89.474% <0%> (+10.526%)` | `7% <0%> (+1%)` | :arrow_up: |; | ... and [8 more](https://codecov.io/gh/broadinstitute/gatk/pull/3546?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3546#issuecomment-327496420
https://github.com/broadinstitute/gatk/pull/3546#issuecomment-327496420:3627,Testability,test,test,3627,Rlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `78.313% <0%> (+1.205%)` | `27% <0%> (+2%)` | :arrow_up: |; | [...adinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `90.909% <0%> (+1.515%)` | `63% <0%> (+2%)` | :arrow_up: |; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `74.803% <0%> (+1.575%)` | `40% <0%> (+2%)` | :arrow_up: |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `69.474% <0%> (+3.158%)` | `28% <0%> ()` | :arrow_down: |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/3546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `68.033% <0%> (+3.279%)` | `3% <0%> ()` | :arrow_down: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `83.704% <0%> (+5.185%)` | `36% <0%> (+5%)` | :arrow_up: |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3546?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `89.474% <0%> (+10.526%)` | `7% <0%> (+1%)` | :arrow_up: |; | ... and [8 more](https://codecov.io/gh/broadinstitute/gatk/pull/3546?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3546#issuecomment-327496420
https://github.com/broadinstitute/gatk/pull/3547#issuecomment-327537230:3046,Testability,test,test,3046,lci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `90.909% <0%> (+1.515%)` | `63% <0%> (+2%)` | :arrow_up: |; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3547?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `74.803% <0%> (+1.575%)` | `40% <0%> (+2%)` | :arrow_up: |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3547?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `69.474% <0%> (+3.158%)` | `28% <0%> ()` | :arrow_down: |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/3547?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `68.033% <0%> (+3.279%)` | `3% <0%> ()` | :arrow_down: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3547?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `83.704% <0%> (+5.185%)` | `36% <0%> (+5%)` | :arrow_up: |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3547?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `89.474% <0%> (+10.526%)` | `7% <0%> (+1%)` | :arrow_up: |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3547?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `81.481% <0%> (+11.111%)` | `10% <0%> ()` | :arrow_down: |; | ... and [7 more](https://codecov.io/gh/broadinstitute/gatk/pull/3547?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3547#issuecomment-327537230
https://github.com/broadinstitute/gatk/pull/3547#issuecomment-327537230:3324,Testability,test,test,3324,lci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `90.909% <0%> (+1.515%)` | `63% <0%> (+2%)` | :arrow_up: |; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3547?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `74.803% <0%> (+1.575%)` | `40% <0%> (+2%)` | :arrow_up: |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3547?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `69.474% <0%> (+3.158%)` | `28% <0%> ()` | :arrow_down: |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/3547?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `68.033% <0%> (+3.279%)` | `3% <0%> ()` | :arrow_down: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/3547?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `83.704% <0%> (+5.185%)` | `36% <0%> (+5%)` | :arrow_up: |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3547?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `89.474% <0%> (+10.526%)` | `7% <0%> (+1%)` | :arrow_up: |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/3547?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `81.481% <0%> (+11.111%)` | `10% <0%> ()` | :arrow_down: |; | ... and [7 more](https://codecov.io/gh/broadinstitute/gatk/pull/3547?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3547#issuecomment-327537230
https://github.com/broadinstitute/gatk/pull/3550#issuecomment-327585487:227,Testability,test,tests,227,@samuelklee Code cov reports are usually off for one of two reasons: ; 1. something went horribly wrong and codecov reported coverage before all the travis jobs finished. ; 2. something went horribly wrong and a large chunk of tests are silently failing to execute. . Good to check that it's 1 and not 2. Usually rerunning should fix case 1.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3550#issuecomment-327585487
https://github.com/broadinstitute/gatk/pull/3550#issuecomment-331029649:91,Security,validat,validation,91,@samuelklee Feel free to merge regardless of your decision. This PR is actually blocking a validation.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3550#issuecomment-331029649
https://github.com/broadinstitute/gatk/issues/3552#issuecomment-327582630:129,Testability,test,tests,129,@mbabadi Can you take a look - I know the tool is beta but as it stands its a bit painful to figure out whats happening when the tests fail.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3552#issuecomment-327582630
https://github.com/broadinstitute/gatk/issues/3552#issuecomment-327585040:49,Modifiability,config,config,49,seems like a good candidate to be moved into the config files...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3552#issuecomment-327585040
https://github.com/broadinstitute/gatk/issues/3554#issuecomment-327793286:119,Deployability,pipeline,pipeline,119,"PlotSegmentedCopyRatio for 250bp bins takes ~15 minutes. (However, with #2858, plotting is now the slowest step in the pipeline!)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3554#issuecomment-327793286
https://github.com/broadinstitute/gatk/issues/3554#issuecomment-329195610:118,Energy Efficiency,efficient,efficient,118,"Actually, just ran a WGS sample with 250bp bins that took ~4 hours to plot...pretty ridiculous! The R code is neither efficient nor well written, so I'm inclined to completely rewrite plotting in python (for ACNV, as well).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3554#issuecomment-329195610
https://github.com/broadinstitute/gatk/issues/3554#issuecomment-329195610:176,Modifiability,rewrite,rewrite,176,"Actually, just ran a WGS sample with 250bp bins that took ~4 hours to plot...pretty ridiculous! The R code is neither efficient nor well written, so I'm inclined to completely rewrite plotting in python (for ACNV, as well).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3554#issuecomment-329195610
https://github.com/broadinstitute/gatk/issues/3555#issuecomment-327843256:162,Availability,down,downstream,162,"I've already suggested in https://github.com/broadinstitute/barclay/pull/28#discussion_r98629000), when the feature was implemented, that this can be an issue in downstream projects. Maybe it is still not late to change the extension to "".arg_list"" to be sure that it is what the user requested.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3555#issuecomment-327843256
https://github.com/broadinstitute/gatk/issues/3555#issuecomment-331451475:170,Availability,error,errors,170,"I added a PR to Barclay (https://github.com/broadinstitute/barclay/pull/95) to both change the extension and to switch off the behaviour if need it. That may solve other errors in the future too, if other downstream project want to use the extension for other purposes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3555#issuecomment-331451475
https://github.com/broadinstitute/gatk/issues/3555#issuecomment-331451475:205,Availability,down,downstream,205,"I added a PR to Barclay (https://github.com/broadinstitute/barclay/pull/95) to both change the extension and to switch off the behaviour if need it. That may solve other errors in the future too, if other downstream project want to use the extension for other purposes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3555#issuecomment-331451475
https://github.com/broadinstitute/gatk/issues/3555#issuecomment-344267691:29,Deployability,upgrade,upgrade,29,"This is fixed by the Barclay upgrade in https://github.com/broadinstitute/gatk/pull/3804, but we really should add an explicit test that uses a Picard interval list with a .list extension that includes a header (i.e., src/test/resources/small_unmerged_picard_intervals.list, but this is only used in a unit test).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3555#issuecomment-344267691
https://github.com/broadinstitute/gatk/issues/3555#issuecomment-344267691:127,Testability,test,test,127,"This is fixed by the Barclay upgrade in https://github.com/broadinstitute/gatk/pull/3804, but we really should add an explicit test that uses a Picard interval list with a .list extension that includes a header (i.e., src/test/resources/small_unmerged_picard_intervals.list, but this is only used in a unit test).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3555#issuecomment-344267691
https://github.com/broadinstitute/gatk/issues/3555#issuecomment-344267691:222,Testability,test,test,222,"This is fixed by the Barclay upgrade in https://github.com/broadinstitute/gatk/pull/3804, but we really should add an explicit test that uses a Picard interval list with a .list extension that includes a header (i.e., src/test/resources/small_unmerged_picard_intervals.list, but this is only used in a unit test).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3555#issuecomment-344267691
https://github.com/broadinstitute/gatk/issues/3555#issuecomment-344267691:307,Testability,test,test,307,"This is fixed by the Barclay upgrade in https://github.com/broadinstitute/gatk/pull/3804, but we really should add an explicit test that uses a Picard interval list with a .list extension that includes a header (i.e., src/test/resources/small_unmerged_picard_intervals.list, but this is only used in a unit test).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3555#issuecomment-344267691
https://github.com/broadinstitute/gatk/pull/3556#issuecomment-328135262:1591,Usability,Simpl,SimpleStrandSwitchVariantDetector,1591,s 65015 65015 ; Branches 10124 10124 ; ===============================================; + Hits 51965 51970 +5 ; + Misses 9016 9012 -4 ; + Partials 4034 4033 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3556?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...v/evidence/experimental/FindSmallIndelRegions.java](https://codecov.io/gh/broadinstitute/gatk/pull/3556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9leHBlcmltZW50YWwvRmluZFNtYWxsSW5kZWxSZWdpb25zLmphdmE=) | `0% <> ()` | `0 <0> ()` | :arrow_down: |; | [...iscoverFromLocalAssemblyContigAlignmentsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1N2RGlzY292ZXJGcm9tTG9jYWxBc3NlbWJseUNvbnRpZ0FsaWdubWVudHNTcGFyay5qYXZh) | `0% <0%> ()` | `0 <0> (?)` | |; | [...y/prototype/SimpleStrandSwitchVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1NpbXBsZVN0cmFuZFN3aXRjaFZhcmlhbnREZXRlY3Rvci5qYXZh) | `33.588% <0%> ()` | `13 <0> ()` | :arrow_down: |; | [...ry/prototype/FilterLongReadAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL0ZpbHRlckxvbmdSZWFkQWxpZ25tZW50c1NBTVNwYXJrLmphdmE=) | `55.652% <16.667%> ()` | `29 <0> (?)` | |; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/3556?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `54.857% <0%> (-1.143%)` | `28% <0%> (-1%)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gat,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3556#issuecomment-328135262
https://github.com/broadinstitute/gatk/pull/3557#issuecomment-327940272:60,Deployability,update,updates,60,Based on https://blog.travis-ci.com/2017-08-29-trusty-image-updates. Also see https://github.com/travis-ci/travis-ci/issues/8315.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3557#issuecomment-327940272
https://github.com/broadinstitute/gatk/pull/3557#issuecomment-328089242:147,Availability,outage,outage,147,"Travis support confirms that the new image we're using as of yesterday seems to have less space, and this wasn't being picked up due to the github outage, which is now fixed, and this branch seems to have passed. Once its merged, the builds should APPEAR to be passing again, but then we'll still need to fix the underlying failures in the WDL tests. I'm going to rerun this one more time to verify, since last night I was getting inconsistent results.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3557#issuecomment-328089242
https://github.com/broadinstitute/gatk/pull/3557#issuecomment-328089242:324,Availability,failure,failures,324,"Travis support confirms that the new image we're using as of yesterday seems to have less space, and this wasn't being picked up due to the github outage, which is now fixed, and this branch seems to have passed. Once its merged, the builds should APPEAR to be passing again, but then we'll still need to fix the underlying failures in the WDL tests. I'm going to rerun this one more time to verify, since last night I was getting inconsistent results.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3557#issuecomment-328089242
https://github.com/broadinstitute/gatk/pull/3557#issuecomment-328089242:344,Testability,test,tests,344,"Travis support confirms that the new image we're using as of yesterday seems to have less space, and this wasn't being picked up due to the github outage, which is now fixed, and this branch seems to have passed. Once its merged, the builds should APPEAR to be passing again, but then we'll still need to fix the underlying failures in the WDL tests. I'm going to rerun this one more time to verify, since last night I was getting inconsistent results.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3557#issuecomment-328089242
https://github.com/broadinstitute/gatk/pull/3557#issuecomment-328102781:116,Testability,test,tests,116,"@lbergelson Please take a look if you can. This gets the builds passing again, so I'm planning to merge it once the tests pass for a final time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3557#issuecomment-328102781
https://github.com/broadinstitute/gatk/issues/3558#issuecomment-328093511:94,Testability,test,tests,94,"Also, we should find out why the travis builds have been appearing to succeed even when these tests fail.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3558#issuecomment-328093511
https://github.com/broadinstitute/gatk/issues/3558#issuecomment-328559733:57,Testability,test,tests,57,@LeeTL1220 Can you look into this. It seems like the wdl tests may be failing to run and saying they passed anyway.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3558#issuecomment-328559733
https://github.com/broadinstitute/gatk/issues/3558#issuecomment-328623422:408,Availability,failure,failure,408,After discussion with @LeeTL1220 this seems to be a known issue with Cromwell returning an exception (https://github.com/broadinstitute/cromwell/issues/2538). It has been confirmed that the tests are indeed succeeding despite returning a stack trace upon failing to find the docker image uploaded to Dockerhub because Cromwell is succeeding in a check to the local installation for the requested image after failure.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3558#issuecomment-328623422
https://github.com/broadinstitute/gatk/issues/3558#issuecomment-328623422:365,Deployability,install,installation,365,After discussion with @LeeTL1220 this seems to be a known issue with Cromwell returning an exception (https://github.com/broadinstitute/cromwell/issues/2538). It has been confirmed that the tests are indeed succeeding despite returning a stack trace upon failing to find the docker image uploaded to Dockerhub because Cromwell is succeeding in a check to the local installation for the requested image after failure.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3558#issuecomment-328623422
https://github.com/broadinstitute/gatk/issues/3558#issuecomment-328623422:190,Testability,test,tests,190,After discussion with @LeeTL1220 this seems to be a known issue with Cromwell returning an exception (https://github.com/broadinstitute/cromwell/issues/2538). It has been confirmed that the tests are indeed succeeding despite returning a stack trace upon failing to find the docker image uploaded to Dockerhub because Cromwell is succeeding in a check to the local installation for the requested image after failure.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3558#issuecomment-328623422
https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328169271:64,Integrability,rout,route,64,"Dijkstra origina algorithm is about finding the single shortest route (or one of the in case of a tie), here we need the one that finds the K-shortest routes which is described [here](https://en.wikipedia.org/wiki/K_shortest_path_routing). Is this one implanted in Jgraph? In that case, yes we could.... . Otherwise if we have to implement the it from scratch... then there is no guaranteed the code is going to be simpler.... it could simpler just because I didn't bother to make the current one as simple as it could be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328169271
https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328169271:151,Integrability,rout,routes,151,"Dijkstra origina algorithm is about finding the single shortest route (or one of the in case of a tie), here we need the one that finds the K-shortest routes which is described [here](https://en.wikipedia.org/wiki/K_shortest_path_routing). Is this one implanted in Jgraph? In that case, yes we could.... . Otherwise if we have to implement the it from scratch... then there is no guaranteed the code is going to be simpler.... it could simpler just because I didn't bother to make the current one as simple as it could be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328169271
https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328169271:415,Usability,simpl,simpler,415,"Dijkstra origina algorithm is about finding the single shortest route (or one of the in case of a tie), here we need the one that finds the K-shortest routes which is described [here](https://en.wikipedia.org/wiki/K_shortest_path_routing). Is this one implanted in Jgraph? In that case, yes we could.... . Otherwise if we have to implement the it from scratch... then there is no guaranteed the code is going to be simpler.... it could simpler just because I didn't bother to make the current one as simple as it could be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328169271
https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328169271:436,Usability,simpl,simpler,436,"Dijkstra origina algorithm is about finding the single shortest route (or one of the in case of a tie), here we need the one that finds the K-shortest routes which is described [here](https://en.wikipedia.org/wiki/K_shortest_path_routing). Is this one implanted in Jgraph? In that case, yes we could.... . Otherwise if we have to implement the it from scratch... then there is no guaranteed the code is going to be simpler.... it could simpler just because I didn't bother to make the current one as simple as it could be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328169271
https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328169271:500,Usability,simpl,simple,500,"Dijkstra origina algorithm is about finding the single shortest route (or one of the in case of a tie), here we need the one that finds the K-shortest routes which is described [here](https://en.wikipedia.org/wiki/K_shortest_path_routing). Is this one implanted in Jgraph? In that case, yes we could.... . Otherwise if we have to implement the it from scratch... then there is no guaranteed the code is going to be simpler.... it could simpler just because I didn't bother to make the current one as simple as it could be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328169271
https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328171212:378,Usability,simpl,simple,378,"However, the current algorithm and the k-dijkstra still would show the same problems in terms of doing a suboptimal selection of haplotypes in terms of their coverage of plausible variation. . I had implemented an alternative that fixed that issue... but I couldn't find the code ... perhaps just in my local machine (backups) need to find it. ; . In any case the idea is quite simple.... we simply simulate haplotypes based on those same furcation likelihoods and we stop when we have not discovered anything new for a while... the problem of such an approach is to make it deterministic. I guess we could fix a seed based on information on the current active region.... anyway,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328171212
https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328171212:392,Usability,simpl,simply,392,"However, the current algorithm and the k-dijkstra still would show the same problems in terms of doing a suboptimal selection of haplotypes in terms of their coverage of plausible variation. . I had implemented an alternative that fixed that issue... but I couldn't find the code ... perhaps just in my local machine (backups) need to find it. ; . In any case the idea is quite simple.... we simply simulate haplotypes based on those same furcation likelihoods and we stop when we have not discovered anything new for a while... the problem of such an approach is to make it deterministic. I guess we could fix a seed based on information on the current active region.... anyway,",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3561#issuecomment-328171212
https://github.com/broadinstitute/gatk/issues/3564#issuecomment-328853019:335,Availability,down,downstream,335,"Thanks much for the help with this. That's a good question as representing multiple low frequency somatic variants at the same position doesn't have a great fit with VCF. You're right, these are essentially a pool so could have an arbitrarily large number of calls, but reflecting that as ploidy ends up being a little problematic for downstream processing. If I got to pick, I'd suggest normalizing these so each variant has it's own line. This also has the advantage of applying filters to individual variants instead of needing to treat all possibilities together. Running `bcftools norm -m '-any` gets it almost right, except for retaining the triploid calls:; ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT control_downsample tumor_downsample; 1 725556 . A G . . DP=460;ECNT=3;NLOD=54.98;N_ART_LOD=2.72;POP_AF=0.001;P_GERMLINE=-51.85;TLOD=6.33 GT:AD:AF:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:SA_MAP_AF:SA_POST_PROB 0/0:205,6:0.02:101,4:104,2:34:415,467:40:4:.:. 0/1/0:209,9:0.035:108,7:101,2:34:404,485:28:2:0.03,0.03,0.035:0.003983,0.005306,0.991; 1 725556 . A AGAATAGAATGGAATAGAAAGGAATG . . DP=460;ECNT=3;NLOD=46.06;N_ART_LOD=8;POP_AF=0.001;P_GERMLINE=-42.76;TLOD=19.76 GT:AD:AF:F1R2:F2R1:MBQ:MFRL:MMQ:MPOS:SA_MAP_AF:SA_POST_PROB 0/0:205,4:0.044:101,0:104,4:0:415,130:25:0:.:. 0/0/1:209,8:0.047:108,4:101,4:0:404,137:42:0:0.03,0.03,0.035:0.003983,0.005306,0.991; ```; Is this something worth adjusting in the MuTect2 output, or do you prefer if we normalize and re-fix ploidy as a post-processing step? Thanks again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3564#issuecomment-328853019
https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330401348:84,Modifiability,inherit,inherited,84,"@chandrans @chapmanb @ldgauthier The `-ploidy` argument is one of several arguments inherited from `AssemblyRegionWalker` that apply only to `HaplotypeCaller` and do nothing in `Mutect2`. (We should refactor this once the engine team's workload lightens enough to review lower-priority things like this.) The `GT` field emitted by Mutect is just the concatenation of all called alleles -- 0/1, 0/1/2, 0/1/2/3 etc -- and doesn't imply anything about the ploidy. Maybe we should get rid of it entirely since `AF` is so much more informative. I like the idea of splitting multiallelics into multiple lines. It would make filtering a lot easier. @LeeTL1220 do you have an opinion?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330401348
https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330401348:199,Modifiability,refactor,refactor,199,"@chandrans @chapmanb @ldgauthier The `-ploidy` argument is one of several arguments inherited from `AssemblyRegionWalker` that apply only to `HaplotypeCaller` and do nothing in `Mutect2`. (We should refactor this once the engine team's workload lightens enough to review lower-priority things like this.) The `GT` field emitted by Mutect is just the concatenation of all called alleles -- 0/1, 0/1/2, 0/1/2/3 etc -- and doesn't imply anything about the ploidy. Maybe we should get rid of it entirely since `AF` is so much more informative. I like the idea of splitting multiallelics into multiple lines. It would make filtering a lot easier. @LeeTL1220 do you have an opinion?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330401348
https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330527699:455,Modifiability,inherit,inherited,455,"I don't think that M2 should be spewing out a concatenation of all alleles,; since that does imply ploidy via the VCF spec. Multiallelics on multiple; lines violates the spec too, right?. On Mon, Sep 18, 2017 at 9:28 PM, David Benjamin <notifications@github.com>; wrote:. > @chandrans <https://github.com/chandrans> @chapmanb; > <https://github.com/chapmanb> @ldgauthier <https://github.com/ldgauthier>; > The -ploidy argument is one of several arguments inherited from; > AssemblyRegionWalker that apply only to HaplotypeCaller and do nothing in; > Mutect2. (We should refactor this once the engine team's workload; > lightens enough to review lower-priority things like this.) The GT field; > emitted by Mutect is just the concatenation of all called alleles -- 0/1,; > 0/1/2, 0/1/2/3 etc -- and doesn't imply anything about the ploidy. Maybe we; > should get rid of it entirely since AF is so much more informative.; >; > I like the idea of splitting multiallelics into multiple lines. It would; > make filtering a lot easier. @LeeTL1220 <https://github.com/leetl1220> do; > you have an opinion?; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330401348>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk2Bmhl2i8xOPd4zC_WqQ9GtNbRKNks5sjxi1gaJpZM4PTWbd>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330527699
https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330527699:570,Modifiability,refactor,refactor,570,"I don't think that M2 should be spewing out a concatenation of all alleles,; since that does imply ploidy via the VCF spec. Multiallelics on multiple; lines violates the spec too, right?. On Mon, Sep 18, 2017 at 9:28 PM, David Benjamin <notifications@github.com>; wrote:. > @chandrans <https://github.com/chandrans> @chapmanb; > <https://github.com/chapmanb> @ldgauthier <https://github.com/ldgauthier>; > The -ploidy argument is one of several arguments inherited from; > AssemblyRegionWalker that apply only to HaplotypeCaller and do nothing in; > Mutect2. (We should refactor this once the engine team's workload; > lightens enough to review lower-priority things like this.) The GT field; > emitted by Mutect is just the concatenation of all called alleles -- 0/1,; > 0/1/2, 0/1/2/3 etc -- and doesn't imply anything about the ploidy. Maybe we; > should get rid of it entirely since AF is so much more informative.; >; > I like the idea of splitting multiallelics into multiple lines. It would; > make filtering a lot easier. @LeeTL1220 <https://github.com/leetl1220> do; > you have an opinion?; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330401348>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk2Bmhl2i8xOPd4zC_WqQ9GtNbRKNks5sjxi1gaJpZM4PTWbd>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330527699
https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330549263:254,Availability,down,downstream,254,"David and Lee;; Thanks for the thoughts and heads up on ploidy. I normally only set this for mitochondrial and chrX/Y but it's not a big deal to have diploid calls throughout. Avoiding representing minor variants in the ploidy field would be helpful for downstream processing. Having multiple alleles on a single line per allele is within spec (1.6.1 in the 4.3 spec: ""It is permitted to have multiple records with the same POS."") and a lot of downstream tools deal with them this way. bcftools and vt normalization produces these and I know GEMINI does this to correctly handle multi-alleles.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330549263
https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330549263:444,Availability,down,downstream,444,"David and Lee;; Thanks for the thoughts and heads up on ploidy. I normally only set this for mitochondrial and chrX/Y but it's not a big deal to have diploid calls throughout. Avoiding representing minor variants in the ploidy field would be helpful for downstream processing. Having multiple alleles on a single line per allele is within spec (1.6.1 in the 4.3 spec: ""It is permitted to have multiple records with the same POS."") and a lot of downstream tools deal with them this way. bcftools and vt normalization produces these and I know GEMINI does this to correctly handle multi-alleles.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330549263
https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330549263:176,Safety,Avoid,Avoiding,176,"David and Lee;; Thanks for the thoughts and heads up on ploidy. I normally only set this for mitochondrial and chrX/Y but it's not a big deal to have diploid calls throughout. Avoiding representing minor variants in the ploidy field would be helpful for downstream processing. Having multiple alleles on a single line per allele is within spec (1.6.1 in the 4.3 spec: ""It is permitted to have multiple records with the same POS."") and a lot of downstream tools deal with them this way. bcftools and vt normalization produces these and I know GEMINI does this to correctly handle multi-alleles.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3564#issuecomment-330549263
https://github.com/broadinstitute/gatk/issues/3564#issuecomment-570229469:104,Modifiability,refactor,refactoring,104,"@srikarchamala We haven't heard from enough people to make this a priority. However, we are doing a big refactoring to make all of the Mutect2 annotations and filters inherently multiallelic so that splitting with external tools before or after FilterMutectCalls ought not to cause problems.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3564#issuecomment-570229469
https://github.com/broadinstitute/gatk/issues/3569#issuecomment-328993020:428,Modifiability,plugin,plugin,428,"BucketUtils was a solution before we had Filesystem providers. It's stuck around as a parallel set of code because we couldn't trust the providers at first. In the long run it should be removed and replaced entirely by `Files` operations. We need to test that all the functionality exists / works as expected though, and it hasn't been a high priority to do so. Particularly, I'm not sure we have a lot of faith in the HDFS NIO plugin, so we may need to keep around special cases for that. It could definitely at least be simplified a lot though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3569#issuecomment-328993020
https://github.com/broadinstitute/gatk/issues/3569#issuecomment-328993020:250,Testability,test,test,250,"BucketUtils was a solution before we had Filesystem providers. It's stuck around as a parallel set of code because we couldn't trust the providers at first. In the long run it should be removed and replaced entirely by `Files` operations. We need to test that all the functionality exists / works as expected though, and it hasn't been a high priority to do so. Particularly, I'm not sure we have a lot of faith in the HDFS NIO plugin, so we may need to keep around special cases for that. It could definitely at least be simplified a lot though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3569#issuecomment-328993020
https://github.com/broadinstitute/gatk/issues/3569#issuecomment-328993020:522,Usability,simpl,simplified,522,"BucketUtils was a solution before we had Filesystem providers. It's stuck around as a parallel set of code because we couldn't trust the providers at first. In the long run it should be removed and replaced entirely by `Files` operations. We need to test that all the functionality exists / works as expected though, and it hasn't been a high priority to do so. Particularly, I'm not sure we have a lot of faith in the HDFS NIO plugin, so we may need to keep around special cases for that. It could definitely at least be simplified a lot though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3569#issuecomment-328993020
https://github.com/broadinstitute/gatk/pull/3571#issuecomment-329034255:1568,Usability,Simpl,SimpleSVType,1568,========================; Files 1133 1141 +8 ; Lines 63042 62843 -199 ; Branches 9613 9562 -51 ; ==============================================; - Hits 50151 49803 -348 ; - Misses 9062 9230 +168 ; + Partials 3829 3810 -19; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...tute/hellbender/tools/spark/sv/utils/RDDUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9SRERVdGlscy5qYXZh) | `0% <> ()` | `0 <0> ()` | :arrow_down: |; | [...s/spark/sv/discovery/AnnotatedVariantProducer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQW5ub3RhdGVkVmFyaWFudFByb2R1Y2VyLmphdmE=) | `78.07% <> (+3.28%)` | `23 <0> ()` | :arrow_down: |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `86.567% <> ()` | `2 <0> ()` | :arrow_down: |; | [...e/hellbender/tools/spark/sv/utils/SVVCFWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9TVlZDRldyaXRlci5qYXZh) | `86.047% <> ()` | `10 <0> ()` | :arrow_down: |; | [...tructuralVariationDiscoveryArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5QXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `96.667% <> ()` | `0 <0> ()` | :arrow_down: |; | [...ls/spark/sv/discovery/GappedAlignmentSplitter.java](https://codecov.io/gh/broadinstitute/gatk/pull,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3571#issuecomment-329034255
https://github.com/broadinstitute/gatk/pull/3571#issuecomment-329034255:3760,Usability,Simpl,SimpleStrandSwitchVariantDetector,3760,ion.java](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5QXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `96.667% <> ()` | `0 <0> ()` | :arrow_down: |; | [...ls/spark/sv/discovery/GappedAlignmentSplitter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvR2FwcGVkQWxpZ25tZW50U3BsaXR0ZXIuamF2YQ==) | `95% <> ()` | `18 <0> ()` | :arrow_down: |; | [...iscoverFromLocalAssemblyContigAlignmentsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1N2RGlzY292ZXJGcm9tTG9jYWxBc3NlbWJseUNvbnRpZ0FsaWdubWVudHNTcGFyay5qYXZh) | `0% <0%> ()` | `0 <0> ()` | :arrow_down: |; | [...discovery/prototype/SuspectedTransLocDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1N1c3BlY3RlZFRyYW5zTG9jRGV0ZWN0b3IuamF2YQ==) | `0% <0%> ()` | `0 <0> (?)` | |; | [.../tools/spark/sv/discovery/BreakEndVariantType.java](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQnJlYWtFbmRWYXJpYW50VHlwZS5qYXZh) | `0% <0%> ()` | `0 <0> ()` | :arrow_down: |; | [...y/prototype/SimpleStrandSwitchVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL1NpbXBsZVN0cmFuZFN3aXRjaFZhcmlhbnREZXRlY3Rvci5qYXZh) | `0% <0%> (-28.387%)` | `0 <0> (-13)` | |; | ... and [87 more](https://codecov.io/gh/broadinstitute/gatk/pull/3571?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3571#issuecomment-329034255
https://github.com/broadinstitute/gatk/pull/3571#issuecomment-338003549:33,Modifiability,refactor,refactoring,33,@cwhelan I've made the suggested refactoring for breakpoint adjustment code.; Do you want to take a look again?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3571#issuecomment-338003549
https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329210063:106,Testability,test,test-spark-readpipeline,106,@davidbernick I was going to tackle this by cloning https://gatk-jenkins.broadinstitute.org/job/gatk-perf-test-spark-readpipeline and adjusting some of the parameters. Are there any issues or gotchas I should know about? /cc @lbergelson,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329210063
https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329283305:236,Availability,down,downstream,236,That's fine -- just make sure it launches with : ; Build after other projects are built - to gatk-perf test. That's the one that sets up the environment and builds latests dockers. So that needs to happen first then all the other tests downstream after. A clone should capture that but just double check.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329283305
https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329283305:103,Testability,test,test,103,That's fine -- just make sure it launches with : ; Build after other projects are built - to gatk-perf test. That's the one that sets up the environment and builds latests dockers. So that needs to happen first then all the other tests downstream after. A clone should capture that but just double check.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329283305
https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329283305:230,Testability,test,tests,230,That's fine -- just make sure it launches with : ; Build after other projects are built - to gatk-perf test. That's the one that sets up the environment and builds latests dockers. So that needs to happen first then all the other tests downstream after. A clone should capture that but just double check.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329283305
https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329446325:83,Availability,error,error,83,"@davidbernick thanks!. I noticed that the existing jobs are now failing with a GCS error (see https://gatk-jenkins.broadinstitute.org/job/gatk-perf-test-spark-markeddupe/436/console):. ```; Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```. There has been a change to the GCS library (https://github.com/broadinstitute/gatk/commit/b47838c9a5fa172ed6669ed4872b04d91c962a85), but when I ran a GCS pipeline manually on my machine it worked fine, even with this change. Any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329446325
https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329446325:190,Availability,Error,Error,190,"@davidbernick thanks!. I noticed that the existing jobs are now failing with a GCS error (see https://gatk-jenkins.broadinstitute.org/job/gatk-perf-test-spark-markeddupe/436/console):. ```; Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```. There has been a change to the GCS library (https://github.com/broadinstitute/gatk/commit/b47838c9a5fa172ed6669ed4872b04d91c962a85), but when I ran a GCS pipeline manually on my machine it worked fine, even with this change. Any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329446325
https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329446325:555,Deployability,pipeline,pipeline,555,"@davidbernick thanks!. I noticed that the existing jobs are now failing with a GCS error (see https://gatk-jenkins.broadinstitute.org/job/gatk-perf-test-spark-markeddupe/436/console):. ```; Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```. There has been a change to the GCS library (https://github.com/broadinstitute/gatk/commit/b47838c9a5fa172ed6669ed4872b04d91c962a85), but when I ran a GCS pipeline manually on my machine it worked fine, even with this change. Any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329446325
https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329446325:219,Security,secur,security,219,"@davidbernick thanks!. I noticed that the existing jobs are now failing with a GCS error (see https://gatk-jenkins.broadinstitute.org/job/gatk-perf-test-spark-markeddupe/436/console):. ```; Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```. There has been a change to the GCS library (https://github.com/broadinstitute/gatk/commit/b47838c9a5fa172ed6669ed4872b04d91c962a85), but when I ran a GCS pipeline manually on my machine it worked fine, even with this change. Any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329446325
https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329446325:228,Security,access,access,228,"@davidbernick thanks!. I noticed that the existing jobs are now failing with a GCS error (see https://gatk-jenkins.broadinstitute.org/job/gatk-perf-test-spark-markeddupe/436/console):. ```; Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```. There has been a change to the GCS library (https://github.com/broadinstitute/gatk/commit/b47838c9a5fa172ed6669ed4872b04d91c962a85), but when I ran a GCS pipeline manually on my machine it worked fine, even with this change. Any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329446325
https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329446325:148,Testability,test,test-spark-markeddupe,148,"@davidbernick thanks!. I noticed that the existing jobs are now failing with a GCS error (see https://gatk-jenkins.broadinstitute.org/job/gatk-perf-test-spark-markeddupe/436/console):. ```; Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```. There has been a change to the GCS library (https://github.com/broadinstitute/gatk/commit/b47838c9a5fa172ed6669ed4872b04d91c962a85), but when I ran a GCS pipeline manually on my machine it worked fine, even with this change. Any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3573#issuecomment-329446325
https://github.com/broadinstitute/gatk/issues/3573#issuecomment-331913059:78,Testability,test,tests,78,"This is related to a known issue with GCS. #3591 When that's fixed, the spark tests will work again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3573#issuecomment-331913059
https://github.com/broadinstitute/gatk/issues/3573#issuecomment-331917095:31,Testability,test,tests,31,Thanks @davidbernick. When the tests are working again I'll create a new job for this issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3573#issuecomment-331917095
https://github.com/broadinstitute/gatk/issues/3573#issuecomment-332574260:58,Testability,test,test-spark-readpipeline-exome,58,See https://gatk-jenkins.broadinstitute.org/job/gatk-perf-test-spark-readpipeline-exome/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3573#issuecomment-332574260
https://github.com/broadinstitute/gatk/issues/3578#issuecomment-329269545:133,Usability,clear,clear,133,It looks like it shouldn't be to difficult but it would necessitate either moving the bucket they are located in or asking people to clear out the hellbender bucket of other things because it appears the lifecycle features can only be applied on a per-bucket basis.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3578#issuecomment-329269545
https://github.com/broadinstitute/gatk/issues/3578#issuecomment-329271288:31,Testability,log,logs,31,"definitely easiest to move the logs I think, the hellbender bucket unfortunately has become hardcoded into a bunch of tests and might be a pain to move",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3578#issuecomment-329271288
https://github.com/broadinstitute/gatk/issues/3578#issuecomment-329271288:118,Testability,test,tests,118,"definitely easiest to move the logs I think, the hellbender bucket unfortunately has become hardcoded into a bunch of tests and might be a pain to move",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3578#issuecomment-329271288
https://github.com/broadinstitute/gatk/issues/3578#issuecomment-330225659:133,Testability,test,test-logs,133,Resolved by this commit: https://github.com/broadinstitute/gatk/commit/c063348274cce3da724a06d789cd1b8edcd9f893; See gs://hellbender-test-logs/ for the new source of test logs.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3578#issuecomment-330225659
https://github.com/broadinstitute/gatk/issues/3578#issuecomment-330225659:166,Testability,test,test,166,Resolved by this commit: https://github.com/broadinstitute/gatk/commit/c063348274cce3da724a06d789cd1b8edcd9f893; See gs://hellbender-test-logs/ for the new source of test logs.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3578#issuecomment-330225659
https://github.com/broadinstitute/gatk/issues/3578#issuecomment-330225659:171,Testability,log,logs,171,Resolved by this commit: https://github.com/broadinstitute/gatk/commit/c063348274cce3da724a06d789cd1b8edcd9f893; See gs://hellbender-test-logs/ for the new source of test logs.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3578#issuecomment-330225659
https://github.com/broadinstitute/gatk/pull/3579#issuecomment-329802505:62,Testability,test,test,62,"Thanks @TedBrookings !. I did a creation and self-termination test run (without actually running the analysis to save time), and it worked as expected. Also implemented the suggested changes:; 1. documentation in help; 2. upfront def instead of in the creation block",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3579#issuecomment-329802505
https://github.com/broadinstitute/gatk/pull/3581#issuecomment-329793309:41,Performance,Concurren,ConcurrentModificationException,41,Note: it looks like this doesn't fix the ConcurrentModificationException during serialization while running the unit tests on my Picard branch.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3581#issuecomment-329793309
https://github.com/broadinstitute/gatk/pull/3581#issuecomment-329793309:117,Testability,test,tests,117,Note: it looks like this doesn't fix the ConcurrentModificationException during serialization while running the unit tests on my Picard branch.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3581#issuecomment-329793309
https://github.com/broadinstitute/gatk/issues/3583#issuecomment-335602331:26,Deployability,pipeline,pipeline,26,"Let's discuss. In the new pipeline, I currently have median absolute deviation after standardization and denoising output as text files during the plotting step, as before. But I think it actually makes more sense to output them after DenoiseReadCounts. We also can't output the number of segments until after the ModelSegments step. However, I would rather not bake this sort of thing into the jar if a simple `wc -l` would suffice.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3583#issuecomment-335602331
https://github.com/broadinstitute/gatk/issues/3583#issuecomment-335602331:404,Usability,simpl,simple,404,"Let's discuss. In the new pipeline, I currently have median absolute deviation after standardization and denoising output as text files during the plotting step, as before. But I think it actually makes more sense to output them after DenoiseReadCounts. We also can't output the number of segments until after the ModelSegments step. However, I would rather not bake this sort of thing into the jar if a simple `wc -l` would suffice.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3583#issuecomment-335602331
https://github.com/broadinstitute/gatk/pull/3585#issuecomment-330360241:37,Testability,test,test,37,"@jsotobroad I'm running a full sized test, but my plumbing test succeeded. I added a GenerateOutputMap step. Back to you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3585#issuecomment-330360241
https://github.com/broadinstitute/gatk/pull/3585#issuecomment-330360241:59,Testability,test,test,59,"@jsotobroad I'm running a full sized test, but my plumbing test succeeded. I added a GenerateOutputMap step. Back to you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3585#issuecomment-330360241
https://github.com/broadinstitute/gatk/pull/3588#issuecomment-330357192:44,Availability,error,errors,44,@jean-philippe-martin We're seeing the same errors here as in yours pr. So it's something in the htsjdk update...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3588#issuecomment-330357192
https://github.com/broadinstitute/gatk/pull/3588#issuecomment-330357192:104,Deployability,update,update,104,@jean-philippe-martin We're seeing the same errors here as in yours pr. So it's something in the htsjdk update...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3588#issuecomment-330357192
https://github.com/broadinstitute/gatk/pull/3588#issuecomment-330558205:812,Availability,failure,failure,812,"@lbergelson @jean-philippe-martin I looked into this it a bit - it can be readily reproduced if the failing test is run through gradle, but not from IntelliJ, which is because when it runs through gradle, its using asyncIO for BAM writing, but when run from IntelliJ its using sync io. I'm not sure why this issue is showing up now, but in the cases that fail, the async writer thread is being interrupted by [this code](https://github.com/samtools/htsjdk/blob/912c28bec415c430b43515652ccaf13222b07e7b/src/main/java/htsjdk/samtools/util/AbstractAsyncWriter.java#L75) which is called from the main thread when the PrintReads closeTool method closes the writer (I added a trace statement to verify this). When I run in IntelliJ and force async io to be used, the interrupt call still happens, but there is no test failure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3588#issuecomment-330558205
https://github.com/broadinstitute/gatk/pull/3588#issuecomment-330558205:108,Testability,test,test,108,"@lbergelson @jean-philippe-martin I looked into this it a bit - it can be readily reproduced if the failing test is run through gradle, but not from IntelliJ, which is because when it runs through gradle, its using asyncIO for BAM writing, but when run from IntelliJ its using sync io. I'm not sure why this issue is showing up now, but in the cases that fail, the async writer thread is being interrupted by [this code](https://github.com/samtools/htsjdk/blob/912c28bec415c430b43515652ccaf13222b07e7b/src/main/java/htsjdk/samtools/util/AbstractAsyncWriter.java#L75) which is called from the main thread when the PrintReads closeTool method closes the writer (I added a trace statement to verify this). When I run in IntelliJ and force async io to be used, the interrupt call still happens, but there is no test failure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3588#issuecomment-330558205
https://github.com/broadinstitute/gatk/pull/3588#issuecomment-330558205:807,Testability,test,test,807,"@lbergelson @jean-philippe-martin I looked into this it a bit - it can be readily reproduced if the failing test is run through gradle, but not from IntelliJ, which is because when it runs through gradle, its using asyncIO for BAM writing, but when run from IntelliJ its using sync io. I'm not sure why this issue is showing up now, but in the cases that fail, the async writer thread is being interrupted by [this code](https://github.com/samtools/htsjdk/blob/912c28bec415c430b43515652ccaf13222b07e7b/src/main/java/htsjdk/samtools/util/AbstractAsyncWriter.java#L75) which is called from the main thread when the PrintReads closeTool method closes the writer (I added a trace statement to verify this). When I run in IntelliJ and force async io to be used, the interrupt call still happens, but there is no test failure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3588#issuecomment-330558205
https://github.com/broadinstitute/gatk/pull/3588#issuecomment-331951965:27,Deployability,update,updated,27,"@jean-philippe-martin I've updated the htsjdk snapshot, you should be unblocked after a rebase.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3588#issuecomment-331951965
https://github.com/broadinstitute/gatk/pull/3590#issuecomment-330888925:34,Testability,test,tests,34,"Whoops, just realized I broke the tests with some changes in a previous PR. Will fix and address @davidbenjamin's comments, thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3590#issuecomment-330888925
https://github.com/broadinstitute/gatk/pull/3590#issuecomment-330916077:954,Performance,optimiz,optimization,954,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3590?src=pr&el=h1) Report; > Merging [#3590](https://codecov.io/gh/broadinstitute/gatk/pull/3590?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/58108d0f3f1a760884201a62469105bc55c09a29?src=pr&el=desc) will **increase** coverage by `0.358%`.; > The diff coverage is `93.939%`. ```diff; @@ Coverage Diff @@; ## master #3590 +/- ##; ===============================================; + Coverage 79.736% 80.094% +0.358% ; - Complexity 18148 18799 +651 ; ===============================================; Files 1217 1226 +9 ; Lines 66602 69015 +2413 ; Branches 10429 11073 +644 ; ===============================================; + Hits 53106 55277 +2171 ; - Misses 9289 9415 +126 ; - Partials 4207 4323 +116; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3590?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...umber/utils/optimization/PersistenceOptimizer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3590?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL29wdGltaXphdGlvbi9QZXJzaXN0ZW5jZU9wdGltaXplci5qYXZh) | `84.946% <> ()` | `27 <0> ()` | :arrow_down: |; | [...copynumber/utils/segmentation/KernelSegmenter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3590?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL3NlZ21lbnRhdGlvbi9LZXJuZWxTZWdtZW50ZXIuamF2YQ==) | `93.939% <93.939%> ()` | `44 <44> (?)` | |; | [.../tools/spark/sv/evidence/QNamesForKmersFinder.java](https://codecov.io/gh/broadinstitute/gatk/pull/3590?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9RTmFtZXNGb3JLbWVyc0ZpbmRlci5qYXZh) | `83.333% <0%> (-16.667%)` | `7% <0%> ()` | |; | [...nder/tools/spark/pathseq/PSPathogenTaxonScore.java](https://codecov.io/gh/broadinstitute/gatk/pull/3590?src=pr&el=,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3590#issuecomment-330916077
https://github.com/broadinstitute/gatk/pull/3590#issuecomment-332307777:77,Testability,test,tests,77,"Thanks! Fixed up some inadvertent missed changes. Will squash and merge once tests pass, if @davidbenjamin gives the go ahead!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3590#issuecomment-332307777
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330650894:221,Integrability,message,message,221,"@mwalker174 Is encountering the same problem in the wild. He's reporting that it goes away if you specify the environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY. he's seeing the warning message:; ```; 16:55:09.480 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; ```; which *should* only appear during tests, so something is strange.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330650894
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330650894:122,Modifiability,variab,variables,122,"@mwalker174 Is encountering the same problem in the wild. He's reporting that it goes away if you specify the environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY. he's seeing the warning message:; ```; 16:55:09.480 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; ```; which *should* only appear during tests, so something is strange.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330650894
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330650894:288,Modifiability,variab,variables,288,"@mwalker174 Is encountering the same problem in the wild. He's reporting that it goes away if you specify the environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY. he's seeing the warning message:; ```; 16:55:09.480 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; ```; which *should* only appear during tests, so something is strange.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330650894
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330650894:414,Modifiability,config,configured,414,"@mwalker174 Is encountering the same problem in the wild. He's reporting that it goes away if you specify the environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY. he's seeing the warning message:; ```; 16:55:09.480 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; ```; which *should* only appear during tests, so something is strange.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330650894
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330650894:474,Testability,test,tests,474,"@mwalker174 Is encountering the same problem in the wild. He's reporting that it goes away if you specify the environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY. he's seeing the warning message:; ```; 16:55:09.480 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; ```; which *should* only appear during tests, so something is strange.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330650894
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330658299:35,Availability,error,error,35,"As far as I can tell, getting that error message means that BaseTest is being loaded at runtime, and running it's static initializer block which calls `SparkContextFactory.enableTestSparkContext();`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330658299
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330658299:41,Integrability,message,message,41,"As far as I can tell, getting that error message means that BaseTest is being loaded at runtime, and running it's static initializer block which calls `SparkContextFactory.enableTestSparkContext();`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330658299
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330658299:78,Performance,load,loaded,78,"As far as I can tell, getting that error message means that BaseTest is being loaded at runtime, and running it's static initializer block which calls `SparkContextFactory.enableTestSparkContext();`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330658299
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330894140:725,Deployability,pipeline,pipelines,725,"I think the message isn't coming from BaseTest, its coming from a static block in SparkContextFactory:. 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getGcsHadoopAdapterTestProperties(SparkContextFactory.java:68); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.<clinit>(SparkContextFactory.java:59); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineArgumentCollection.<init>(SparkCommandLineArgumentCollection.java:20); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.<init>(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.<init>(GATKSparkTool.java:64); 	at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.<init>(PrintReadsSpark.java:19); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at java.lang.Class.newInstance(Class.java:442); 	at org.broadinstitute.hellbender.Main.extractCommandLineProgram(Main.java:285); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:150); 	at org.broadinstitute.hellbender.Main.main(Main.java:233)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330894140
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330894140:12,Integrability,message,message,12,"I think the message isn't coming from BaseTest, its coming from a static block in SparkContextFactory:. 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.getGcsHadoopAdapterTestProperties(SparkContextFactory.java:68); 	at org.broadinstitute.hellbender.engine.spark.SparkContextFactory.<clinit>(SparkContextFactory.java:59); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineArgumentCollection.<init>(SparkCommandLineArgumentCollection.java:20); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.<init>(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.<init>(GATKSparkTool.java:64); 	at org.broadinstitute.hellbender.tools.spark.pipelines.PrintReadsSpark.<init>(PrintReadsSpark.java:19); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method); 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62); 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45); 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423); 	at java.lang.Class.newInstance(Class.java:442); 	at org.broadinstitute.hellbender.Main.extractCommandLineProgram(Main.java:285); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:150); 	at org.broadinstitute.hellbender.Main.main(Main.java:233)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330894140
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330902481:124,Performance,load,loading,124,"@cmnbroad @lbergelson Looks like `SparkContextFactory.DEFAULT_TEST_PROPERTIES` is currently initialized statically at class-loading time, resulting in a call to `getGcsHadoopAdapterTestProperties()` even when we're not running the test suite.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330902481
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330902481:231,Testability,test,test,231,"@cmnbroad @lbergelson Looks like `SparkContextFactory.DEFAULT_TEST_PROPERTIES` is currently initialized statically at class-loading time, resulting in a call to `getGcsHadoopAdapterTestProperties()` even when we're not running the test suite.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330902481
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001:382,Availability,error,error,382,"@jean-philippe-martin Can you comment on this one? It looks like `google-cloud-java` recently bumped their `google-auth-library-credentials` and `google-auth-library-oauth2-http` dependencies to `0.8.0` -- was there some change that would require us to modify our authentication-related code in GATK, and/or the permissions setup in our Google Cloud project, that could explain the error:. ```; Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001:395,Availability,Error,Error,395,"@jean-philippe-martin Can you comment on this one? It looks like `google-cloud-java` recently bumped their `google-auth-library-credentials` and `google-auth-library-oauth2-http` dependencies to `0.8.0` -- was there some change that would require us to modify our authentication-related code in GATK, and/or the permissions setup in our Google Cloud project, that could explain the error:. ```; Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001:179,Integrability,depend,dependencies,179,"@jean-philippe-martin Can you comment on this one? It looks like `google-cloud-java` recently bumped their `google-auth-library-credentials` and `google-auth-library-oauth2-http` dependencies to `0.8.0` -- was there some change that would require us to modify our authentication-related code in GATK, and/or the permissions setup in our Google Cloud project, that could explain the error:. ```; Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001:264,Security,authenticat,authentication-related,264,"@jean-philippe-martin Can you comment on this one? It looks like `google-cloud-java` recently bumped their `google-auth-library-credentials` and `google-auth-library-oauth2-http` dependencies to `0.8.0` -- was there some change that would require us to modify our authentication-related code in GATK, and/or the permissions setup in our Google Cloud project, that could explain the error:. ```; Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001:424,Security,secur,security,424,"@jean-philippe-martin Can you comment on this one? It looks like `google-cloud-java` recently bumped their `google-auth-library-credentials` and `google-auth-library-oauth2-http` dependencies to `0.8.0` -- was there some change that would require us to modify our authentication-related code in GATK, and/or the permissions setup in our Google Cloud project, that could explain the error:. ```; Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001:433,Security,access,access,433,"@jean-philippe-martin Can you comment on this one? It looks like `google-cloud-java` recently bumped their `google-auth-library-credentials` and `google-auth-library-oauth2-http` dependencies to `0.8.0` -- was there some change that would require us to modify our authentication-related code in GATK, and/or the permissions setup in our Google Cloud project, that could explain the error:. ```; Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330936001
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330939236:37,Availability,error,error,37,I was just talking with @vruano. The error might come from improper permissions/roles being set up on the cluster by default.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330939236
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940018:140,Deployability,upgrade,upgrade,140,It's weird that it worked before though if roles aren't set up right. It seems like security issues shouldn't be solved by asking people to upgrade their client software so that it can deny them permission.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940018
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940018:84,Security,secur,security,84,It's weird that it worked before though if roles aren't set up right. It seems like security issues shouldn't be solved by asking people to upgrade their client software so that it can deny them permission.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940018
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940762:77,Deployability,patch,patched,77,"It seems plausible to me, though, that the Google auth library may have been patched to perform checks that it wasn't performing previously. Maybe our project permissions have always been mis-configured :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940762
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940762:192,Modifiability,config,configured,192,"It seems plausible to me, though, that the Google auth library may have been patched to perform checks that it wasn't performing previously. Maybe our project permissions have always been mis-configured :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940762
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940762:88,Performance,perform,perform,88,"It seems plausible to me, though, that the Google auth library may have been patched to perform checks that it wasn't performing previously. Maybe our project permissions have always been mis-configured :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940762
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940762:118,Performance,perform,performing,118,"It seems plausible to me, though, that the Google auth library may have been patched to perform checks that it wasn't performing previously. Maybe our project permissions have always been mis-configured :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-330940762
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331002437:122,Availability,error,error,122,"So this seems to only happen when trying to access a bucket from a job on dataproc. For example, the following throws the error:. ./gatk-launch PathSeqFilterSpark -I gs://bucket/in.bam -O gs://bucket/out.bam -- --sparkRunner GCS --cluster my-cluster. but the following does not:; ./gatk-launch PathSeqFilterSpark -I hdfs://bams/in.bam -O hdfs://bams/out.bam -- --sparkRunner GCS --cluster my-cluster. This happens even if I launch the cluster ""gcloud dataproc clusters create ... --scope cloud-platform"", which is supposed to grant full storage permissions. I believe this is equivalent to checking the ""Allow API access to all Google Cloud Services"" box if you launch a cluster through the web console. . Also explicitly adding the service account as a ""storage legacy bucket owner"" does not seem to help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331002437
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331002437:44,Security,access,access,44,"So this seems to only happen when trying to access a bucket from a job on dataproc. For example, the following throws the error:. ./gatk-launch PathSeqFilterSpark -I gs://bucket/in.bam -O gs://bucket/out.bam -- --sparkRunner GCS --cluster my-cluster. but the following does not:; ./gatk-launch PathSeqFilterSpark -I hdfs://bams/in.bam -O hdfs://bams/out.bam -- --sparkRunner GCS --cluster my-cluster. This happens even if I launch the cluster ""gcloud dataproc clusters create ... --scope cloud-platform"", which is supposed to grant full storage permissions. I believe this is equivalent to checking the ""Allow API access to all Google Cloud Services"" box if you launch a cluster through the web console. . Also explicitly adding the service account as a ""storage legacy bucket owner"" does not seem to help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331002437
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331002437:614,Security,access,access,614,"So this seems to only happen when trying to access a bucket from a job on dataproc. For example, the following throws the error:. ./gatk-launch PathSeqFilterSpark -I gs://bucket/in.bam -O gs://bucket/out.bam -- --sparkRunner GCS --cluster my-cluster. but the following does not:; ./gatk-launch PathSeqFilterSpark -I hdfs://bams/in.bam -O hdfs://bams/out.bam -- --sparkRunner GCS --cluster my-cluster. This happens even if I launch the cluster ""gcloud dataproc clusters create ... --scope cloud-platform"", which is supposed to grant full storage permissions. I believe this is equivalent to checking the ""Allow API access to all Google Cloud Services"" box if you launch a cluster through the web console. . Also explicitly adding the service account as a ""storage legacy bucket owner"" does not seem to help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331002437
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331047616:102,Deployability,configurat,configuration,102,"OK so just following along; the problem appears related to the Google Cloud Storage Connector and its configuration. When running on Cloud we need to ask for the `https://www.googleapis.com/auth/devstorage.read_write` scope, as described in [the install docs](https://github.com/GoogleCloudPlatform/bigdata-interop/blob/master/gcs/INSTALL.md). But you're right that `https://www.googleapis.com/auth/cloud-platform` should imply that so it should work... The command line argument is `--scopes` (plural) and not `--scope` but that's probably not the issue, the tool would have complained if you actually typed `scope` in there. . Perhaps the code is trying to do the non-cloud setup and that's what's making it not work on cloud?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331047616
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331047616:246,Deployability,install,install,246,"OK so just following along; the problem appears related to the Google Cloud Storage Connector and its configuration. When running on Cloud we need to ask for the `https://www.googleapis.com/auth/devstorage.read_write` scope, as described in [the install docs](https://github.com/GoogleCloudPlatform/bigdata-interop/blob/master/gcs/INSTALL.md). But you're right that `https://www.googleapis.com/auth/cloud-platform` should imply that so it should work... The command line argument is `--scopes` (plural) and not `--scope` but that's probably not the issue, the tool would have complained if you actually typed `scope` in there. . Perhaps the code is trying to do the non-cloud setup and that's what's making it not work on cloud?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331047616
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331047616:331,Deployability,INSTALL,INSTALL,331,"OK so just following along; the problem appears related to the Google Cloud Storage Connector and its configuration. When running on Cloud we need to ask for the `https://www.googleapis.com/auth/devstorage.read_write` scope, as described in [the install docs](https://github.com/GoogleCloudPlatform/bigdata-interop/blob/master/gcs/INSTALL.md). But you're right that `https://www.googleapis.com/auth/cloud-platform` should imply that so it should work... The command line argument is `--scopes` (plural) and not `--scope` but that's probably not the issue, the tool would have complained if you actually typed `scope` in there. . Perhaps the code is trying to do the non-cloud setup and that's what's making it not work on cloud?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331047616
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331047616:102,Modifiability,config,configuration,102,"OK so just following along; the problem appears related to the Google Cloud Storage Connector and its configuration. When running on Cloud we need to ask for the `https://www.googleapis.com/auth/devstorage.read_write` scope, as described in [the install docs](https://github.com/GoogleCloudPlatform/bigdata-interop/blob/master/gcs/INSTALL.md). But you're right that `https://www.googleapis.com/auth/cloud-platform` should imply that so it should work... The command line argument is `--scopes` (plural) and not `--scope` but that's probably not the issue, the tool would have complained if you actually typed `scope` in there. . Perhaps the code is trying to do the non-cloud setup and that's what's making it not work on cloud?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331047616
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:327,Availability,down,down,327,"Apparently related, just running IndexFeatureFile on my machine results in several stack traces:; ```; Sep 21, 2017 4:10:53 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Host is down (connect failed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:3500,Availability,down,down,3500,redentials(ServiceOptions.java:277); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:252); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:30); 	at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:77); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:361); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); ```; and ; ```; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Host is down (connect failed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:1154,Integrability,protocol,protocol,1154,h.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Host is down (connect failed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCrede,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:1249,Integrability,protocol,protocol,1249,are running on Google Compute Engine.; java.net.ConnectException: Host is down (connect failed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:112); 	at shaded.cloud_nio,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:1341,Integrability,protocol,protocol,1341,ed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:112); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:113);,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:1432,Integrability,protocol,protocol,1432,ocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:112); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:113); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(Google,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:4327,Integrability,protocol,protocol,4327,tute.hellbender.Main.main(Main.java:233); ```; and ; ```; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Host is down (connect failed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCrede,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:4422,Integrability,protocol,protocol,4422,are running on Google Compute Engine.; java.net.ConnectException: Host is down (connect failed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:112); 	at shaded.cloud_nio,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:4514,Integrability,protocol,protocol,4514,ed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:112); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:113);,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:4605,Integrability,protocol,protocol,4605,ocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:112); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:113); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(Google,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:6606,Modifiability,variab,variable,6606,onnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentialsUnsynchronized(DefaultCredentialsProvider.java:194); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.getDefaultCredentials(DefaultCredentialsProvider.java:112); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:113); 	at shaded.cloud_nio.com.google.auth.oauth2.GoogleCredentials.getApplicationDefault(GoogleCredentials.java:86); 	at com.google.cloud.ServiceOptions.defaultCredentials(ServiceOptions.java:277); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:252); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:30); 	at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:77); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:361); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); ```; I was able to fix the issue by setting the environment variable `NO_GCE_CHECK=true` in my shell though,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:235,Safety,detect,detect,235,"Apparently related, just running IndexFeatureFile on my machine results in several stack traces:; ```; Sep 21, 2017 4:10:53 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Host is down (connect failed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1138); 	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1032); 	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:966); 	at shaded.cloud_nio.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials.runningOnComputeEngine(ComputeEngineCredentials.java:176); 	at shaded.cloud_nio.com.google.auth.oauth2.DefaultCredentialsProvider.tryGetComputeCredentials(DefaultCredentialsProvider.java:270); 	at shaded.cloud_nio.com.google.auth.oauth2",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235:3408,Safety,detect,detect,3408,ApplicationDefault(GoogleCredentials.java:86); 	at com.google.cloud.ServiceOptions.defaultCredentials(ServiceOptions.java:277); 	at com.google.cloud.ServiceOptions.<init>(ServiceOptions.java:252); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:82); 	at com.google.cloud.storage.StorageOptions.<init>(StorageOptions.java:30); 	at com.google.cloud.storage.StorageOptions$Builder.build(StorageOptions.java:77); 	at org.broadinstitute.hellbender.utils.gcs.BucketUtils.setGlobalNIODefaultOptions(BucketUtils.java:361); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:155); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:195); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:131); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:152); 	at org.broadinstitute.hellbender.Main.main(Main.java:233); ```; and ; ```; WARNING: Failed to detect whether we are running on Google Compute Engine.; java.net.ConnectException: Host is down (connect failed); 	at java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350); 	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206); 	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188); 	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392); 	at java.net.Socket.connect(Socket.java:589); 	at sun.net.NetworkClient.doConnect(NetworkClient.java:175); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463); 	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558); 	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at sun.net.www.http.HttpClient.New(HttpClient.java:339); 	at sun.net.www.http.HttpClient.New(HttpClient.java:357); 	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1202); 	at sun,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331269235
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331275667:72,Availability,error,error,72,"@mwalker174 @lbergelson @jean-philippe-martin I was able to fix the 404 error by building a custom version of the lastest master of `google-cloud-java` with the following patch:. ```; diff --git a/pom.xml b/pom.xml; index 0a77a625b0..e0884bbf2d 100644; --- a/pom.xml; +++ b/pom.xml; @@ -131,10 +131,10 @@; <api-client.version>1.22.0</api-client.version>; ; <api-common.version>1.1.0</api-common.version>; - <gax.version>1.8.1</gax.version>; - <gax-grpc.version>0.25.1</gax-grpc.version>; + <gax.version>1.8.0</gax.version>; + <gax-grpc.version>0.25.0</gax-grpc.version>; <generatedProto.version>0.1.19</generatedProto.version>; - <google.auth.version>0.8.0</google.auth.version>; + <google.auth.version>0.7.0</google.auth.version>; <grpc.version>1.6.1</grpc.version>; <guava.version>20.0</guava.version>; <http-client.version>1.22.0</http-client.version>; ```. So it's likely the `google.auth.version` bump that introduced the error -- in particular, the change described in https://github.com/google/google-auth-library-java/releases/tag/v0.7.1 and implemented in https://github.com/google/google-auth-library-java/pull/110",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331275667
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331275667:927,Availability,error,error,927,"@mwalker174 @lbergelson @jean-philippe-martin I was able to fix the 404 error by building a custom version of the lastest master of `google-cloud-java` with the following patch:. ```; diff --git a/pom.xml b/pom.xml; index 0a77a625b0..e0884bbf2d 100644; --- a/pom.xml; +++ b/pom.xml; @@ -131,10 +131,10 @@; <api-client.version>1.22.0</api-client.version>; ; <api-common.version>1.1.0</api-common.version>; - <gax.version>1.8.1</gax.version>; - <gax-grpc.version>0.25.1</gax-grpc.version>; + <gax.version>1.8.0</gax.version>; + <gax-grpc.version>0.25.0</gax-grpc.version>; <generatedProto.version>0.1.19</generatedProto.version>; - <google.auth.version>0.8.0</google.auth.version>; + <google.auth.version>0.7.0</google.auth.version>; <grpc.version>1.6.1</grpc.version>; <guava.version>20.0</guava.version>; <http-client.version>1.22.0</http-client.version>; ```. So it's likely the `google.auth.version` bump that introduced the error -- in particular, the change described in https://github.com/google/google-auth-library-java/releases/tag/v0.7.1 and implemented in https://github.com/google/google-auth-library-java/pull/110",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331275667
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331275667:171,Deployability,patch,patch,171,"@mwalker174 @lbergelson @jean-philippe-martin I was able to fix the 404 error by building a custom version of the lastest master of `google-cloud-java` with the following patch:. ```; diff --git a/pom.xml b/pom.xml; index 0a77a625b0..e0884bbf2d 100644; --- a/pom.xml; +++ b/pom.xml; @@ -131,10 +131,10 @@; <api-client.version>1.22.0</api-client.version>; ; <api-common.version>1.1.0</api-common.version>; - <gax.version>1.8.1</gax.version>; - <gax-grpc.version>0.25.1</gax-grpc.version>; + <gax.version>1.8.0</gax.version>; + <gax-grpc.version>0.25.0</gax-grpc.version>; <generatedProto.version>0.1.19</generatedProto.version>; - <google.auth.version>0.8.0</google.auth.version>; + <google.auth.version>0.7.0</google.auth.version>; <grpc.version>1.6.1</grpc.version>; <guava.version>20.0</guava.version>; <http-client.version>1.22.0</http-client.version>; ```. So it's likely the `google.auth.version` bump that introduced the error -- in particular, the change described in https://github.com/google/google-auth-library-java/releases/tag/v0.7.1 and implemented in https://github.com/google/google-auth-library-java/pull/110",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331275667
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331275667:1026,Deployability,release,releases,1026,"@mwalker174 @lbergelson @jean-philippe-martin I was able to fix the 404 error by building a custom version of the lastest master of `google-cloud-java` with the following patch:. ```; diff --git a/pom.xml b/pom.xml; index 0a77a625b0..e0884bbf2d 100644; --- a/pom.xml; +++ b/pom.xml; @@ -131,10 +131,10 @@; <api-client.version>1.22.0</api-client.version>; ; <api-common.version>1.1.0</api-common.version>; - <gax.version>1.8.1</gax.version>; - <gax-grpc.version>0.25.1</gax-grpc.version>; + <gax.version>1.8.0</gax.version>; + <gax-grpc.version>0.25.0</gax-grpc.version>; <generatedProto.version>0.1.19</generatedProto.version>; - <google.auth.version>0.8.0</google.auth.version>; + <google.auth.version>0.7.0</google.auth.version>; <grpc.version>1.6.1</grpc.version>; <guava.version>20.0</guava.version>; <http-client.version>1.22.0</http-client.version>; ```. So it's likely the `google.auth.version` bump that introduced the error -- in particular, the change described in https://github.com/google/google-auth-library-java/releases/tag/v0.7.1 and implemented in https://github.com/google/google-auth-library-java/pull/110",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331275667
https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331281442:5,Deployability,update,updated,5,I've updated https://github.com/GoogleCloudPlatform/google-cloud-java/issues/2453 with this result -- we'll see what they say.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3591#issuecomment-331281442
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330691059:2375,Deployability,update,update,2375,"3592?src=pr&el=tree). ```diff; @@ Coverage Diff @@; ## master #3592 +/- ##; ============================================; - Coverage 79.73% 79.73% -0.01% ; - Complexity 18148 18149 +1 ; ============================================; Files 1217 1217 ; Lines 66602 66602 ; Branches 10429 10429 ; ============================================; - Hits 53106 53104 -2 ; - Misses 9289 9292 +3 ; + Partials 4207 4206 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `91% <100%> ()` | `30 <0> ()` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `76.62% <0%> (-1.95%)` | `39% <0%> ()` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `88.88% <0%> (+0.46%)` | `52% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > ` = absolute <relative> (impact)`, ` = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=footer). Last update [58108d0...c374339](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330691059
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330691059:2278,Energy Efficiency,Power,Powered,2278,"3592?src=pr&el=tree). ```diff; @@ Coverage Diff @@; ## master #3592 +/- ##; ============================================; - Coverage 79.73% 79.73% -0.01% ; - Complexity 18148 18149 +1 ; ============================================; Files 1217 1217 ; Lines 66602 66602 ; Branches 10429 10429 ; ============================================; - Hits 53106 53104 -2 ; - Misses 9289 9292 +3 ; + Partials 4207 4206 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `91% <100%> ()` | `30 <0> ()` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `76.62% <0%> (-1.95%)` | `39% <0%> ()` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `88.88% <0%> (+0.46%)` | `52% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > ` = absolute <relative> (impact)`, ` = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=footer). Last update [58108d0...c374339](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330691059
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330691059:2141,Usability,learn,learn,2141,"3592?src=pr&el=tree). ```diff; @@ Coverage Diff @@; ## master #3592 +/- ##; ============================================; - Coverage 79.73% 79.73% -0.01% ; - Complexity 18148 18149 +1 ; ============================================; Files 1217 1217 ; Lines 66602 66602 ; Branches 10429 10429 ; ============================================; - Hits 53106 53104 -2 ; - Misses 9289 9292 +3 ; + Partials 4207 4206 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `91% <100%> ()` | `30 <0> ()` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `76.62% <0%> (-1.95%)` | `39% <0%> ()` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `88.88% <0%> (+0.46%)` | `52% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > ` = absolute <relative> (impact)`, ` = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=footer). Last update [58108d0...c374339](https://codecov.io/gh/broadinstitute/gatk/pull/3592?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330691059
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330874487:56,Deployability,release,release,56,@lbergelson We really need to stay on the newest gcloud release -- it contains the official release of our NIO fixes! We should try to work through any issues rather than reverting to the previous (unreleased) snapshot.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330874487
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330874487:92,Deployability,release,release,92,@lbergelson We really need to stay on the newest gcloud release -- it contains the official release of our NIO fixes! We should try to work through any issues rather than reverting to the previous (unreleased) snapshot.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330874487
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330886791:49,Deployability,release,release,49,PR is #3594 if we want to try moving forward one release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330886791
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330888023:138,Modifiability,refactor,refactor,138,"@cmnbroad Worth a try. Do we understand the underlying issue, though? If it's just the static initializer in `BaseTest`, perhaps we could refactor that into a `@BeforeSuite`?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330888023
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330894575:26,Integrability,message,message,26,"I don't think the warning message is coming from BaseTest, its coming directly from SparkContextFactory, which is executing static code that I think it shouldn't (see the stack I just added to #3591). Its unclear to me if that is actually CAUSING #3591, or just causing the message to display.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330894575
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330894575:274,Integrability,message,message,274,"I don't think the warning message is coming from BaseTest, its coming directly from SparkContextFactory, which is executing static code that I think it shouldn't (see the stack I just added to #3591). Its unclear to me if that is actually CAUSING #3591, or just causing the message to display.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330894575
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330896419:93,Availability,error,error,93,"It turns out I was mistaken that setting the environment variables fixes the problem (stupid error on my part). It's possible the BaseTest message is unrelated. I haven't tested this branch out yet, but building from the commit immediately before the update works. I am going to try the next version to see if it helps. Edit: #3594 does not fix the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330896419
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330896419:251,Deployability,update,update,251,"It turns out I was mistaken that setting the environment variables fixes the problem (stupid error on my part). It's possible the BaseTest message is unrelated. I haven't tested this branch out yet, but building from the commit immediately before the update works. I am going to try the next version to see if it helps. Edit: #3594 does not fix the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330896419
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330896419:139,Integrability,message,message,139,"It turns out I was mistaken that setting the environment variables fixes the problem (stupid error on my part). It's possible the BaseTest message is unrelated. I haven't tested this branch out yet, but building from the commit immediately before the update works. I am going to try the next version to see if it helps. Edit: #3594 does not fix the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330896419
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330896419:57,Modifiability,variab,variables,57,"It turns out I was mistaken that setting the environment variables fixes the problem (stupid error on my part). It's possible the BaseTest message is unrelated. I haven't tested this branch out yet, but building from the commit immediately before the update works. I am going to try the next version to see if it helps. Edit: #3594 does not fix the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330896419
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330896419:171,Testability,test,tested,171,"It turns out I was mistaken that setting the environment variables fixes the problem (stupid error on my part). It's possible the BaseTest message is unrelated. I haven't tested this branch out yet, but building from the commit immediately before the update works. I am going to try the next version to see if it helps. Edit: #3594 does not fix the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330896419
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330906450:45,Deployability,patch,patch,45,"@mwalker174 Can you try another run with the patch in https://github.com/broadinstitute/gatk/pull/3594, but this time comment out the call to `getGcsHadoopAdapterTestProperties()` in `SparkContextFactory` line 59?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330906450
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330918132:22,Availability,error,error,22,@droazen still giving error:. com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330918132
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330918132:73,Availability,Error,Error,73,@droazen still giving error:. com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330918132
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330918132:102,Security,secur,security,102,@droazen still giving error:. com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330918132
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330918132:111,Security,access,access,111,@droazen still giving error:. com.google.cloud.storage.StorageException: Error code 404 trying to get security access token from Compute Engine metadata for the default service account. This may be because the virtual machine instance does not have permission scopes specified.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330918132
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330937174:252,Availability,error,error,252,"@mwalker174 Ok, I've asked our Google collaborator @jean-philippe-martin to comment on https://github.com/broadinstitute/gatk/issues/3591. It looks like there were some authentication-related changes in the newer gcloud releases that could explain the error. It may be that we just need to update our client code and/or project IAM settings.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330937174
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330937174:220,Deployability,release,releases,220,"@mwalker174 Ok, I've asked our Google collaborator @jean-philippe-martin to comment on https://github.com/broadinstitute/gatk/issues/3591. It looks like there were some authentication-related changes in the newer gcloud releases that could explain the error. It may be that we just need to update our client code and/or project IAM settings.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330937174
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330937174:290,Deployability,update,update,290,"@mwalker174 Ok, I've asked our Google collaborator @jean-philippe-martin to comment on https://github.com/broadinstitute/gatk/issues/3591. It looks like there were some authentication-related changes in the newer gcloud releases that could explain the error. It may be that we just need to update our client code and/or project IAM settings.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330937174
https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330937174:169,Security,authenticat,authentication-related,169,"@mwalker174 Ok, I've asked our Google collaborator @jean-philippe-martin to comment on https://github.com/broadinstitute/gatk/issues/3591. It looks like there were some authentication-related changes in the newer gcloud releases that could explain the error. It may be that we just need to update our client code and/or project IAM settings.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3592#issuecomment-330937174
https://github.com/broadinstitute/gatk/issues/3593#issuecomment-330818394:192,Availability,error,error,192,"The git hash refers to the commit of GATK you have checked out in your branch as opposed to the commit of GATK that has been built in Java (and will be run on the cluster). I will clarify the error message: it means that you need to rebuild GATK to match your changes to the repository. The malformed object name is a different story, and seems like a bug. I will try to figure that out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3593#issuecomment-330818394
https://github.com/broadinstitute/gatk/issues/3593#issuecomment-330818394:198,Integrability,message,message,198,"The git hash refers to the commit of GATK you have checked out in your branch as opposed to the commit of GATK that has been built in Java (and will be run on the cluster). I will clarify the error message: it means that you need to rebuild GATK to match your changes to the repository. The malformed object name is a different story, and seems like a bug. I will try to figure that out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3593#issuecomment-330818394
https://github.com/broadinstitute/gatk/issues/3593#issuecomment-330818394:8,Security,hash,hash,8,"The git hash refers to the commit of GATK you have checked out in your branch as opposed to the commit of GATK that has been built in Java (and will be run on the cluster). I will clarify the error message: it means that you need to rebuild GATK to match your changes to the repository. The malformed object name is a different story, and seems like a bug. I will try to figure that out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3593#issuecomment-330818394
https://github.com/broadinstitute/gatk/pull/3594#issuecomment-330903924:42,Availability,error,error,42,Unfortunately I am still getting the same error #3591,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3594#issuecomment-330903924
https://github.com/broadinstitute/gatk/issues/3596#issuecomment-330936329:124,Integrability,depend,depend,124,"If a tool exists and is runnable, but is not documented, it should be accessible via tab-completion. Otherwise people can't depend on tab-completion to give a complete list of all tools that can be run.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-330936329
https://github.com/broadinstitute/gatk/issues/3596#issuecomment-330936329:70,Security,access,accessible,70,"If a tool exists and is runnable, but is not documented, it should be accessible via tab-completion. Otherwise people can't depend on tab-completion to give a complete list of all tools that can be run.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-330936329
https://github.com/broadinstitute/gatk/issues/3596#issuecomment-330941066:105,Usability,simpl,simple,105,"If it's a difficult/non-trivial change, though, then it may not be worth fixing. I thought it would be a simple change.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-330941066
https://github.com/broadinstitute/gatk/issues/3596#issuecomment-331112758:1101,Integrability,interface,interface,1101,"Apart of the amount of work in both Barclay and GATK, I think that this shouldn't be implemented for 2 reasons:. * After #3486, some tools are hidden from the command line (and they will be most likely undocumented too). If the bash-completion works with undocumented tools that are hidden from the command line, there will appear anyway after pressing tab-tab. If that tools are treated in a different way, then it requires even more work - Barclay does not use the omitFromCommandLine at all, and that means that GATK should extend the bash-completion to take it into account.; * If a tool can bash-complete but it does not show in the online help pages (the main source for help, taking into account that in the CLI is a bit messy when the parameter space grows), then it will be really difficult to really understand how the tool work. Even if it shows the parameters with tab-tab, the only way of checking what the meaning of each of them is look at the CLI help. Because the bash-completion is a sub-type of help-doclet, it should require the `@DocumentedFeature` annotation: that is the marker interface in Barclay for mark classes as parsed/added to the ""help"" generated by doclets....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-331112758
https://github.com/broadinstitute/gatk/issues/3596#issuecomment-331112758:527,Modifiability,extend,extend,527,"Apart of the amount of work in both Barclay and GATK, I think that this shouldn't be implemented for 2 reasons:. * After #3486, some tools are hidden from the command line (and they will be most likely undocumented too). If the bash-completion works with undocumented tools that are hidden from the command line, there will appear anyway after pressing tab-tab. If that tools are treated in a different way, then it requires even more work - Barclay does not use the omitFromCommandLine at all, and that means that GATK should extend the bash-completion to take it into account.; * If a tool can bash-complete but it does not show in the online help pages (the main source for help, taking into account that in the CLI is a bit messy when the parameter space grows), then it will be really difficult to really understand how the tool work. Even if it shows the parameters with tab-tab, the only way of checking what the meaning of each of them is look at the CLI help. Because the bash-completion is a sub-type of help-doclet, it should require the `@DocumentedFeature` annotation: that is the marker interface in Barclay for mark classes as parsed/added to the ""help"" generated by doclets....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-331112758
https://github.com/broadinstitute/gatk/issues/3596#issuecomment-331112758:202,Usability,undo,undocumented,202,"Apart of the amount of work in both Barclay and GATK, I think that this shouldn't be implemented for 2 reasons:. * After #3486, some tools are hidden from the command line (and they will be most likely undocumented too). If the bash-completion works with undocumented tools that are hidden from the command line, there will appear anyway after pressing tab-tab. If that tools are treated in a different way, then it requires even more work - Barclay does not use the omitFromCommandLine at all, and that means that GATK should extend the bash-completion to take it into account.; * If a tool can bash-complete but it does not show in the online help pages (the main source for help, taking into account that in the CLI is a bit messy when the parameter space grows), then it will be really difficult to really understand how the tool work. Even if it shows the parameters with tab-tab, the only way of checking what the meaning of each of them is look at the CLI help. Because the bash-completion is a sub-type of help-doclet, it should require the `@DocumentedFeature` annotation: that is the marker interface in Barclay for mark classes as parsed/added to the ""help"" generated by doclets....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-331112758
https://github.com/broadinstitute/gatk/issues/3596#issuecomment-331112758:255,Usability,undo,undocumented,255,"Apart of the amount of work in both Barclay and GATK, I think that this shouldn't be implemented for 2 reasons:. * After #3486, some tools are hidden from the command line (and they will be most likely undocumented too). If the bash-completion works with undocumented tools that are hidden from the command line, there will appear anyway after pressing tab-tab. If that tools are treated in a different way, then it requires even more work - Barclay does not use the omitFromCommandLine at all, and that means that GATK should extend the bash-completion to take it into account.; * If a tool can bash-complete but it does not show in the online help pages (the main source for help, taking into account that in the CLI is a bit messy when the parameter space grows), then it will be really difficult to really understand how the tool work. Even if it shows the parameters with tab-tab, the only way of checking what the meaning of each of them is look at the CLI help. Because the bash-completion is a sub-type of help-doclet, it should require the `@DocumentedFeature` annotation: that is the marker interface in Barclay for mark classes as parsed/added to the ""help"" generated by doclets....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3596#issuecomment-331112758
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:967,Modifiability,extend,extends,967,"Thanks guys!. On Sat, Sep 23, 2017 at 11:38 PM, David Benjamin <notifications@github.com>; wrote:. > *@davidbenjamin* requested changes on this pull request.; >; > Done with my review. Mainly the usual stuff about writing more idiomatic; > Java that all C++ coders go through!; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646010>:; >; > > +import org.broadinstitute.hellbender.utils.IntervalUtils;; > +import org.broadinstitute.hellbender.utils.SimpleInterval;; > +; > +import java.io.File;; > +import java.util.List;; > +; > +; > +; > +@CommandLineProgramProperties(; > + summary = ""Split intervals into sub-interval files."",; > + oneLineSummary = ""Split intervals into sub-interval files."",; > + programGroup = VariantProgramGroup.class; > +); > +@DocumentedFeature; > +public class CreateBinningIntervals extends GATKTool {; > + public static final String WIDTH_OF_BINS_SHORT_NAME = ""bw"";; >; > @samuelklee <https://github.com/samuelklee> is the boss of the copy; > number code, but personally I don't see the need to be extremely concise; > with short names and would prefer width.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646054>:; >; > > +@DocumentedFeature; > +public class CreateBinningIntervals extends GATKTool {; > + public static final String WIDTH_OF_BINS_SHORT_NAME = ""bw"";; > + public static final String WIDTH_OF_BINS_LONG_NAME = ""binwidths"";; > +; > + public static final String PADDING_SHORT_NAME = ""pad"";; > + public static final String PADDING_LONG_NAME = ""padding"";; > +; > + @Argument(; > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + pri",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:1526,Modifiability,extend,extends,1526,"= ""Split intervals into sub-interval files."",; > + oneLineSummary = ""Split intervals into sub-interval files."",; > + programGroup = VariantProgramGroup.class; > +); > +@DocumentedFeature; > +public class CreateBinningIntervals extends GATKTool {; > + public static final String WIDTH_OF_BINS_SHORT_NAME = ""bw"";; >; > @samuelklee <https://github.com/samuelklee> is the boss of the copy; > number code, but personally I don't see the need to be extremely concise; > with short names and would prefer width.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646054>:; >; > > +@DocumentedFeature; > +public class CreateBinningIntervals extends GATKTool {; > + public static final String WIDTH_OF_BINS_SHORT_NAME = ""bw"";; > + public static final String WIDTH_OF_BINS_LONG_NAME = ""binwidths"";; > +; > + public static final String PADDING_SHORT_NAME = ""pad"";; > + public static final String PADDING_LONG_NAME = ""padding"";; > +; > + @Argument(; > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; >; > binWidth would be a more readable variable name. There's nothing wrong; > with the command line argument and the variable being identical.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646097>:; >; > > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; > +; > + @Argument(; > + doc = ""width of the padding regions"",; > + fullName = PADDING_LONG_NAME,; > + shortName = PADDING_SHORT_NAME,; > + optional = tr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:2067,Modifiability,variab,variable,2067,"= ""Split intervals into sub-interval files."",; > + oneLineSummary = ""Split intervals into sub-interval files."",; > + programGroup = VariantProgramGroup.class; > +); > +@DocumentedFeature; > +public class CreateBinningIntervals extends GATKTool {; > + public static final String WIDTH_OF_BINS_SHORT_NAME = ""bw"";; >; > @samuelklee <https://github.com/samuelklee> is the boss of the copy; > number code, but personally I don't see the need to be extremely concise; > with short names and would prefer width.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646054>:; >; > > +@DocumentedFeature; > +public class CreateBinningIntervals extends GATKTool {; > + public static final String WIDTH_OF_BINS_SHORT_NAME = ""bw"";; > + public static final String WIDTH_OF_BINS_LONG_NAME = ""binwidths"";; > +; > + public static final String PADDING_SHORT_NAME = ""pad"";; > + public static final String PADDING_LONG_NAME = ""padding"";; > +; > + @Argument(; > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; >; > binWidth would be a more readable variable name. There's nothing wrong; > with the command line argument and the variable being identical.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646097>:; >; > > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; > +; > + @Argument(; > + doc = ""width of the padding regions"",; > + fullName = PADDING_LONG_NAME,; > + shortName = PADDING_SHORT_NAME,; > + optional = tr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:2146,Modifiability,variab,variable,2146,"> number code, but personally I don't see the need to be extremely concise; > with short names and would prefer width.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646054>:; >; > > +@DocumentedFeature; > +public class CreateBinningIntervals extends GATKTool {; > + public static final String WIDTH_OF_BINS_SHORT_NAME = ""bw"";; > + public static final String WIDTH_OF_BINS_LONG_NAME = ""binwidths"";; > +; > + public static final String PADDING_SHORT_NAME = ""pad"";; > + public static final String PADDING_LONG_NAME = ""padding"";; > +; > + @Argument(; > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; >; > binWidth would be a more readable variable name. There's nothing wrong; > with the command line argument and the variable being identical.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646097>:; >; > > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; > +; > + @Argument(; > + doc = ""width of the padding regions"",; > + fullName = PADDING_LONG_NAME,; > + shortName = PADDING_SHORT_NAME,; > + optional = true,; > + minValue = 0; > + ); > + private int padding = 0;; >; > This tool extends GATKTool, which means that it inherits an; > IntervalArgumentCollection that already includes a padding argument. A; > new one is not needed. BTW @samuelklee <https://github.com/samuelklee>; > does this come up elsewhere in the CNV code? It could be a holdover from; > the days of porting ReCapSeg when",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:2816,Modifiability,extend,extends,2816,"al String WIDTH_OF_BINS_LONG_NAME = ""binwidths"";; > +; > + public static final String PADDING_SHORT_NAME = ""pad"";; > + public static final String PADDING_LONG_NAME = ""padding"";; > +; > + @Argument(; > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; >; > binWidth would be a more readable variable name. There's nothing wrong; > with the command line argument and the variable being identical.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646097>:; >; > > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; > +; > + @Argument(; > + doc = ""width of the padding regions"",; > + fullName = PADDING_LONG_NAME,; > + shortName = PADDING_SHORT_NAME,; > + optional = true,; > + minValue = 0; > + ); > + private int padding = 0;; >; > This tool extends GATKTool, which means that it inherits an; > IntervalArgumentCollection that already includes a padding argument. A; > new one is not needed. BTW @samuelklee <https://github.com/samuelklee>; > does this come up elsewhere in the CNV code? It could be a holdover from; > the days of porting ReCapSeg when I feel we used to write more; > CommandLinePrograms.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646119>:; >; > > + createBins();; > + }; > +; > + /**; > + * Generates binning coverage in the intervals given by the user.; > + * The width of bins, the intervals and the output file's path are given by the user.; > + */; > + public void createBin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:2854,Modifiability,inherit,inherits,2854,"al String WIDTH_OF_BINS_LONG_NAME = ""binwidths"";; > +; > + public static final String PADDING_SHORT_NAME = ""pad"";; > + public static final String PADDING_LONG_NAME = ""padding"";; > +; > + @Argument(; > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; >; > binWidth would be a more readable variable name. There's nothing wrong; > with the command line argument and the variable being identical.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646097>:; >; > > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; > +; > + @Argument(; > + doc = ""width of the padding regions"",; > + fullName = PADDING_LONG_NAME,; > + shortName = PADDING_SHORT_NAME,; > + optional = true,; > + minValue = 0; > + ); > + private int padding = 0;; >; > This tool extends GATKTool, which means that it inherits an; > IntervalArgumentCollection that already includes a padding argument. A; > new one is not needed. BTW @samuelklee <https://github.com/samuelklee>; > does this come up elsewhere in the CNV code? It could be a holdover from; > the days of porting ReCapSeg when I feel we used to write more; > CommandLinePrograms.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646119>:; >; > > + createBins();; > + }; > +; > + /**; > + * Generates binning coverage in the intervals given by the user.; > + * The width of bins, the intervals and the output file's path are given by the user.; > + */; > + public void createBin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:4993,Modifiability,inherit,inherited,4993,"OfBins) + "" should be >= 0."");; >; > @asmirnov <https://github.com/asmirnov> and @samuelklee; > <https://github.com/samuelklee> are both correct, but for the future in; > cases where you *would* want an IllegalArgumentException you should use; > Utils.validateArg to render this sort of thing a one-liner.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646132>:; >; > > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; > +; > + @Argument(; > + doc = ""width of the padding regions"",; > + fullName = PADDING_LONG_NAME,; > + shortName = PADDING_SHORT_NAME,; > + optional = true,; > + minValue = 0; > + ); > + private int padding = 0;; >; > . . . and if this padding is different from the inherited padding then; > this demands a comment to avoid confusion.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646146>:; >; > > +; > + // check if the bin widths are set appropriately; > + if(widthOfBins <= 0) {; > + throw new IllegalArgumentException(""Width of bins "" + Integer.toString(widthOfBins) + "" should be >= 0."");; > + }; > +; > + // get the sequence dictionary; > + final SAMSequenceDictionary sequenceDictionary = getBestAvailableSequenceDictionary();; > + final List<SimpleInterval> intervals = hasIntervals() ? intervalArgumentCollection.getIntervals(sequenceDictionary); > + : IntervalUtils.getAllIntervalsForReference(sequenceDictionary);; > +; > + // create an IntervalList by copying all elements of 'intervals' into it; > + IntervalList intervalList = new IntervalList(sequenceDictionary);; > + intervals.stream().map(si -> new Inte",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:9676,Modifiability,variab,variables,9676,".java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646204>:; >; > > + IntervalList intervalList = new IntervalList(sequenceDictionary);; > + intervals.stream().map(si -> new Interval(si.getContig(), si.getStart(), si.getEnd())).forEach(intervalList::add);; > +; > + // sort intervals according to their coordinates and unique them (i.e. delete duplicates); > + intervalList.uniqued();; > +; > + // pad all elements of intervalList; > + intervalList = intervalList.padded(padding,padding);; > +; > + // merge those that intersect after padding; > + intervalList = IntervalList.intersection(intervalList, intervalList);; > +; > + // break the intervals up to bins -- the last bin in each interval can be shorter than the others; > + IntervalList bins = new IntervalList(sequenceDictionary);; > + int bin_start, bin_end;; > + Interval new_bin;; >; > Agreed, but *if* you didn't inline it, you would want to declare it; > inside the loop. In Java you pretty much always try to give variables the; > most local scope possible.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646252>:; >; > > +; > + // merge those that intersect after padding; > + intervalList = IntervalList.intersection(intervalList, intervalList);; > +; > + // break the intervals up to bins -- the last bin in each interval can be shorter than the others; > + IntervalList bins = new IntervalList(sequenceDictionary);; > + int bin_start, bin_end;; > + Interval new_bin;; > + for(Interval in : intervalList) {; > + bin_start = in.getStart();; > + bin_end = Math.min(bin_start + widthOfBins - 1, in.getEnd());; > + while(bin_start < in.getEnd()) {; > + new_bin = new Interval(in.getContig(), bin_start, bin_end);; > + bins.add(new_bin);; > + bin_start += widthOfBins;; > + bin_end = Math.min(bin_start + widthOfBins - 1, in.getEnd());; >; > If you move bin_e",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:5045,Safety,avoid,avoid,5045,"OfBins) + "" should be >= 0."");; >; > @asmirnov <https://github.com/asmirnov> and @samuelklee; > <https://github.com/samuelklee> are both correct, but for the future in; > cases where you *would* want an IllegalArgumentException you should use; > Utils.validateArg to render this sort of thing a one-liner.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646132>:; >; > > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; > +; > + @Argument(; > + doc = ""width of the padding regions"",; > + fullName = PADDING_LONG_NAME,; > + shortName = PADDING_SHORT_NAME,; > + optional = true,; > + minValue = 0; > + ); > + private int padding = 0;; >; > . . . and if this padding is different from the inherited padding then; > this demands a comment to avoid confusion.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646146>:; >; > > +; > + // check if the bin widths are set appropriately; > + if(widthOfBins <= 0) {; > + throw new IllegalArgumentException(""Width of bins "" + Integer.toString(widthOfBins) + "" should be >= 0."");; > + }; > +; > + // get the sequence dictionary; > + final SAMSequenceDictionary sequenceDictionary = getBestAvailableSequenceDictionary();; > + final List<SimpleInterval> intervals = hasIntervals() ? intervalArgumentCollection.getIntervals(sequenceDictionary); > + : IntervalUtils.getAllIntervalsForReference(sequenceDictionary);; > +; > + // create an IntervalList by copying all elements of 'intervals' into it; > + IntervalList intervalList = new IntervalList(sequenceDictionary);; > + intervals.stream().map(si -> new Inte",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:4257,Security,validat,validateArg,4257,"/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646119>:; >; > > + createBins();; > + }; > +; > + /**; > + * Generates binning coverage in the intervals given by the user.; > + * The width of bins, the intervals and the output file's path are given by the user.; > + */; > + public void createBins() {; > + // check if the output directory exists; > + if (!outputFile.exists() && !outputFile.mkdir()) {; > + throw new RuntimeException(""Unable to create file: "" + outputFile.getAbsolutePath());; > + }; > +; > + // check if the bin widths are set appropriately; > + if(widthOfBins <= 0) {; > + throw new IllegalArgumentException(""Width of bins "" + Integer.toString(widthOfBins) + "" should be >= 0."");; >; > @asmirnov <https://github.com/asmirnov> and @samuelklee; > <https://github.com/samuelklee> are both correct, but for the future in; > cases where you *would* want an IllegalArgumentException you should use; > Utils.validateArg to render this sort of thing a one-liner.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646132>:; >; > > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; > +; > + @Argument(; > + doc = ""width of the padding regions"",; > + fullName = PADDING_LONG_NAME,; > + shortName = PADDING_SHORT_NAME,; > + optional = true,; > + minValue = 0; > + ); > + private int padding = 0;; >; > . . . and if this padding is different from the inherited padding then; > this demands a comment to avoid confusion.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646146>:; >; > > +",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:12840,Testability,test,test,12840,".getContig(), bin_start, bin_end));; > }; >; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646304>:; >; > > + // break the intervals up to bins -- the last bin in each interval can be shorter than the others; > + IntervalList bins = new IntervalList(sequenceDictionary);; > + int bin_start, bin_end;; > + Interval new_bin;; > + for(Interval in : intervalList) {; > + bin_start = in.getStart();; > + bin_end = Math.min(bin_start + widthOfBins - 1, in.getEnd());; > + while(bin_start < in.getEnd()) {; > + new_bin = new Interval(in.getContig(), bin_start, bin_end);; > + bins.add(new_bin);; > + bin_start += widthOfBins;; > + bin_end = Math.min(bin_start + widthOfBins - 1, in.getEnd());; > + }; > + }; > +; > + // write the bins into file; >; > I would skip this comment.; > ------------------------------; >; > In src/test/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervalsIntegrationTest.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646311>:; >; > > + // printOutputFile(outputFile);; > +; > + // read the bins from the output file; > + IntervalList binsFromFile = IntervalList.fromFile(outputFile);; > +; > + // we expect the following result; > + IntervalList binsExpected = new IntervalList(binsFromFile.getHeader().getSequenceDictionary());; > + String contig = binsFromFile.iterator().next().getContig();; > + binsExpected.add(new Interval(contig, 1, 10000));; > + binsExpected.add(new Interval(contig, 10001, 20000));; > + binsExpected.add(new Interval(contig, 20001, 20500));; > +; > + // compare the file contents to the expected result; > + Assert.assertEquals(binsFromFile, binsExpected);; > + }; > +; >; > extra whitespace line; > ------------------------------; >; > In src/test/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervalsIntegrationTest.ja",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:13629,Testability,Assert,Assert,13629,"n_end);; > + bins.add(new_bin);; > + bin_start += widthOfBins;; > + bin_end = Math.min(bin_start + widthOfBins - 1, in.getEnd());; > + }; > + }; > +; > + // write the bins into file; >; > I would skip this comment.; > ------------------------------; >; > In src/test/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervalsIntegrationTest.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646311>:; >; > > + // printOutputFile(outputFile);; > +; > + // read the bins from the output file; > + IntervalList binsFromFile = IntervalList.fromFile(outputFile);; > +; > + // we expect the following result; > + IntervalList binsExpected = new IntervalList(binsFromFile.getHeader().getSequenceDictionary());; > + String contig = binsFromFile.iterator().next().getContig();; > + binsExpected.add(new Interval(contig, 1, 10000));; > + binsExpected.add(new Interval(contig, 10001, 20000));; > + binsExpected.add(new Interval(contig, 20001, 20500));; > +; > + // compare the file contents to the expected result; > + Assert.assertEquals(binsFromFile, binsExpected);; > + }; > +; >; > extra whitespace line; > ------------------------------; >; > In src/test/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervalsIntegrationTest.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646314>:; >; > > + runCommandLine(args);; > +; > + // read the contents of the output file and print them out; > + // printOutputFile(outputFile);; > +; > + // read the bins from the output file; > + IntervalList binsFromFile = IntervalList.fromFile(outputFile);; > +; > + // we expect the following result; > + IntervalList binsExpected = new IntervalList(binsFromFile.getHeader().getSequenceDictionary());; > + String contig = binsFromFile.iterator().next().getContig();; > + binsExpected.add(new Interval(contig, 1, 10000));; > + binsExpected.add(new Interval(contig, 10001, 20000));; > + binsExpected.add(new Interval(contig, 20001, 20500",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:13636,Testability,assert,assertEquals,13636,"into file; >; > I would skip this comment.; > ------------------------------; >; > In src/test/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervalsIntegrationTest.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646311>:; >; > > + // printOutputFile(outputFile);; > +; > + // read the bins from the output file; > + IntervalList binsFromFile = IntervalList.fromFile(outputFile);; > +; > + // we expect the following result; > + IntervalList binsExpected = new IntervalList(binsFromFile.getHeader().getSequenceDictionary());; > + String contig = binsFromFile.iterator().next().getContig();; > + binsExpected.add(new Interval(contig, 1, 10000));; > + binsExpected.add(new Interval(contig, 10001, 20000));; > + binsExpected.add(new Interval(contig, 20001, 20500));; > +; > + // compare the file contents to the expected result; > + Assert.assertEquals(binsFromFile, binsExpected);; > + }; > +; >; > extra whitespace line; > ------------------------------; >; > In src/test/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervalsIntegrationTest.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646314>:; >; > > + runCommandLine(args);; > +; > + // read the contents of the output file and print them out; > + // printOutputFile(outputFile);; > +; > + // read the bins from the output file; > + IntervalList binsFromFile = IntervalList.fromFile(outputFile);; > +; > + // we expect the following result; > + IntervalList binsExpected = new IntervalList(binsFromFile.getHeader().getSequenceDictionary());; > + String contig = binsFromFile.iterator().next().getContig();; > + binsExpected.add(new Interval(contig, 1, 10000));; > + binsExpected.add(new Interval(contig, 10001, 20000));; > + binsExpected.add(new Interval(contig, 20001, 20500));; > +; > + // compare the file contents to the expected result; >; > Unnecessary comment; > ------------------------------; >; > In src/test/java/org/broadinstitute/hel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:13765,Testability,test,test,13765,"into file; >; > I would skip this comment.; > ------------------------------; >; > In src/test/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervalsIntegrationTest.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646311>:; >; > > + // printOutputFile(outputFile);; > +; > + // read the bins from the output file; > + IntervalList binsFromFile = IntervalList.fromFile(outputFile);; > +; > + // we expect the following result; > + IntervalList binsExpected = new IntervalList(binsFromFile.getHeader().getSequenceDictionary());; > + String contig = binsFromFile.iterator().next().getContig();; > + binsExpected.add(new Interval(contig, 1, 10000));; > + binsExpected.add(new Interval(contig, 10001, 20000));; > + binsExpected.add(new Interval(contig, 20001, 20500));; > +; > + // compare the file contents to the expected result; > + Assert.assertEquals(binsFromFile, binsExpected);; > + }; > +; >; > extra whitespace line; > ------------------------------; >; > In src/test/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervalsIntegrationTest.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646314>:; >; > > + runCommandLine(args);; > +; > + // read the contents of the output file and print them out; > + // printOutputFile(outputFile);; > +; > + // read the bins from the output file; > + IntervalList binsFromFile = IntervalList.fromFile(outputFile);; > +; > + // we expect the following result; > + IntervalList binsExpected = new IntervalList(binsFromFile.getHeader().getSequenceDictionary());; > + String contig = binsFromFile.iterator().next().getContig();; > + binsExpected.add(new Interval(contig, 1, 10000));; > + binsExpected.add(new Interval(contig, 10001, 20000));; > + binsExpected.add(new Interval(contig, 20001, 20500));; > +; > + // compare the file contents to the expected result; >; > Unnecessary comment; > ------------------------------; >; > In src/test/java/org/broadinstitute/hel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:14718,Testability,test,test,14718,"> + }; > +; >; > extra whitespace line; > ------------------------------; >; > In src/test/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervalsIntegrationTest.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646314>:; >; > > + runCommandLine(args);; > +; > + // read the contents of the output file and print them out; > + // printOutputFile(outputFile);; > +; > + // read the bins from the output file; > + IntervalList binsFromFile = IntervalList.fromFile(outputFile);; > +; > + // we expect the following result; > + IntervalList binsExpected = new IntervalList(binsFromFile.getHeader().getSequenceDictionary());; > + String contig = binsFromFile.iterator().next().getContig();; > + binsExpected.add(new Interval(contig, 1, 10000));; > + binsExpected.add(new Interval(contig, 10001, 20000));; > + binsExpected.add(new Interval(contig, 20001, 20500));; > +; > + // compare the file contents to the expected result; >; > Unnecessary comment; > ------------------------------; >; > In src/test/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervalsIntegrationTest.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646351>:; >; > > + ""-"" + CreateBinningIntervals.WIDTH_OF_BINS_SHORT_NAME, Integer.toString(widthOfBins),; > + ""-"" + CreateBinningIntervals.PADDING_SHORT_NAME, Integer.toString(padding),; > + ""-O"", outputFile.getAbsolutePath(); > + };; > + runCommandLine(args);; > +; > + // read the contents of the output file and print them out; > + // printOutputFile(outputFile);; > +; > + // read the bins from the output file; > + IntervalList binsFromFile = IntervalList.fromFile(outputFile);; > +; > + // we expect the following result; > + IntervalList binsExpected = new IntervalList(binsFromFile.getHeader().getSequenceDictionary());; > + String contig = binsFromFile.iterator().next().getContig();; > + binsExpected.add(new Interval(contig, 1, 10000000));; >; > I think how you have it is fine, ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:16000,Testability,test,test,16000,"teBinningIntervals.PADDING_SHORT_NAME, Integer.toString(padding),; > + ""-O"", outputFile.getAbsolutePath(); > + };; > + runCommandLine(args);; > +; > + // read the contents of the output file and print them out; > + // printOutputFile(outputFile);; > +; > + // read the bins from the output file; > + IntervalList binsFromFile = IntervalList.fromFile(outputFile);; > +; > + // we expect the following result; > + IntervalList binsExpected = new IntervalList(binsFromFile.getHeader().getSequenceDictionary());; > + String contig = binsFromFile.iterator().next().getContig();; > + binsExpected.add(new Interval(contig, 1, 10000000));; >; > I think how you have it is fine, but if this chromosome were a bit longer; > you could render this concise with:; >; > final int width = 10_000_000;IntStream.rangeClosed(0, 6); > .mapToObj(n -> new Interval(contig, n * width + 1, Math.min( (n + 1) * width, contigSize))); > .forEach(binsExpected::add);; >; > ------------------------------; >; > In src/test/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervalsIntegrationTest.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646381>:; >; > > + IntervalList binsExpected = new IntervalList(binsFromFile.getHeader().getSequenceDictionary());; > + String contig = binsFromFile.iterator().next().getContig();; > + binsExpected.add(new Interval(contig, 1, 10000000));; > + binsExpected.add(new Interval(contig, 10000001, 20000000));; > + binsExpected.add(new Interval(contig, 20000001, 30000000));; > + binsExpected.add(new Interval(contig, 30000001, 40000000));; > + binsExpected.add(new Interval(contig, 40000001, 50000000));; > + binsExpected.add(new Interval(contig, 50000001, 60000000));; > + binsExpected.add(new Interval(contig, 60000001, 63025520));; > +; > + // compare the file contents to the expected result; > + Assert.assertEquals(binsFromFile, binsExpected);; > + }; > +; > +; > + // Test for reading intervals from a file; >; > Personally, and this is v",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:16867,Testability,Assert,Assert,16867,"sed(0, 6); > .mapToObj(n -> new Interval(contig, n * width + 1, Math.min( (n + 1) * width, contigSize))); > .forEach(binsExpected::add);; >; > ------------------------------; >; > In src/test/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervalsIntegrationTest.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646381>:; >; > > + IntervalList binsExpected = new IntervalList(binsFromFile.getHeader().getSequenceDictionary());; > + String contig = binsFromFile.iterator().next().getContig();; > + binsExpected.add(new Interval(contig, 1, 10000000));; > + binsExpected.add(new Interval(contig, 10000001, 20000000));; > + binsExpected.add(new Interval(contig, 20000001, 30000000));; > + binsExpected.add(new Interval(contig, 30000001, 40000000));; > + binsExpected.add(new Interval(contig, 40000001, 50000000));; > + binsExpected.add(new Interval(contig, 50000001, 60000000));; > + binsExpected.add(new Interval(contig, 60000001, 63025520));; > +; > + // compare the file contents to the expected result; > + Assert.assertEquals(binsFromFile, binsExpected);; > + }; > +; > +; > + // Test for reading intervals from a file; >; > Personally, and this is very subjective, I feel that once you're fully; > exploiting IntervalArgumentCollection you can get rid of tests that just; > vary how we pass the intervals via -L, because it's not our job here to; > verify the correctness of IntervalArgumentCollection. I would be curious; > to hear @samuelklee <https://github.com/samuelklee>'s opinion.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/3597#pullrequestreview-64752317>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGPkHhuk2NAMl5M4g7BYDg3AXGor3-VOks5slc7DgaJpZM4PeOtF>; > .; >. -- ; Marton Kanasz-Nagy; Physics Department, Harvard University; 17 Oxford Street, Cambridge, MA 02138; kanasz@physics.harvard.edu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:16874,Testability,assert,assertEquals,16874,"ed(0, 6); > .mapToObj(n -> new Interval(contig, n * width + 1, Math.min( (n + 1) * width, contigSize))); > .forEach(binsExpected::add);; >; > ------------------------------; >; > In src/test/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervalsIntegrationTest.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646381>:; >; > > + IntervalList binsExpected = new IntervalList(binsFromFile.getHeader().getSequenceDictionary());; > + String contig = binsFromFile.iterator().next().getContig();; > + binsExpected.add(new Interval(contig, 1, 10000000));; > + binsExpected.add(new Interval(contig, 10000001, 20000000));; > + binsExpected.add(new Interval(contig, 20000001, 30000000));; > + binsExpected.add(new Interval(contig, 30000001, 40000000));; > + binsExpected.add(new Interval(contig, 40000001, 50000000));; > + binsExpected.add(new Interval(contig, 50000001, 60000000));; > + binsExpected.add(new Interval(contig, 60000001, 63025520));; > +; > + // compare the file contents to the expected result; > + Assert.assertEquals(binsFromFile, binsExpected);; > + }; > +; > +; > + // Test for reading intervals from a file; >; > Personally, and this is very subjective, I feel that once you're fully; > exploiting IntervalArgumentCollection you can get rid of tests that just; > vary how we pass the intervals via -L, because it's not our job here to; > verify the correctness of IntervalArgumentCollection. I would be curious; > to hear @samuelklee <https://github.com/samuelklee>'s opinion.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/3597#pullrequestreview-64752317>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGPkHhuk2NAMl5M4g7BYDg3AXGor3-VOks5slc7DgaJpZM4PeOtF>; > .; >. -- ; Marton Kanasz-Nagy; Physics Department, Harvard University; 17 Oxford Street, Cambridge, MA 02138; kanasz@physics.harvard.edu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:16941,Testability,Test,Test,16941,"ed(0, 6); > .mapToObj(n -> new Interval(contig, n * width + 1, Math.min( (n + 1) * width, contigSize))); > .forEach(binsExpected::add);; >; > ------------------------------; >; > In src/test/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervalsIntegrationTest.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646381>:; >; > > + IntervalList binsExpected = new IntervalList(binsFromFile.getHeader().getSequenceDictionary());; > + String contig = binsFromFile.iterator().next().getContig();; > + binsExpected.add(new Interval(contig, 1, 10000000));; > + binsExpected.add(new Interval(contig, 10000001, 20000000));; > + binsExpected.add(new Interval(contig, 20000001, 30000000));; > + binsExpected.add(new Interval(contig, 30000001, 40000000));; > + binsExpected.add(new Interval(contig, 40000001, 50000000));; > + binsExpected.add(new Interval(contig, 50000001, 60000000));; > + binsExpected.add(new Interval(contig, 60000001, 63025520));; > +; > + // compare the file contents to the expected result; > + Assert.assertEquals(binsFromFile, binsExpected);; > + }; > +; > +; > + // Test for reading intervals from a file; >; > Personally, and this is very subjective, I feel that once you're fully; > exploiting IntervalArgumentCollection you can get rid of tests that just; > vary how we pass the intervals via -L, because it's not our job here to; > verify the correctness of IntervalArgumentCollection. I would be curious; > to hear @samuelklee <https://github.com/samuelklee>'s opinion.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/3597#pullrequestreview-64752317>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGPkHhuk2NAMl5M4g7BYDg3AXGor3-VOks5slc7DgaJpZM4PeOtF>; > .; >. -- ; Marton Kanasz-Nagy; Physics Department, Harvard University; 17 Oxford Street, Cambridge, MA 02138; kanasz@physics.harvard.edu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:17117,Testability,test,tests,17117,"ed(0, 6); > .mapToObj(n -> new Interval(contig, n * width + 1, Math.min( (n + 1) * width, contigSize))); > .forEach(binsExpected::add);; >; > ------------------------------; >; > In src/test/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervalsIntegrationTest.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646381>:; >; > > + IntervalList binsExpected = new IntervalList(binsFromFile.getHeader().getSequenceDictionary());; > + String contig = binsFromFile.iterator().next().getContig();; > + binsExpected.add(new Interval(contig, 1, 10000000));; > + binsExpected.add(new Interval(contig, 10000001, 20000000));; > + binsExpected.add(new Interval(contig, 20000001, 30000000));; > + binsExpected.add(new Interval(contig, 30000001, 40000000));; > + binsExpected.add(new Interval(contig, 40000001, 50000000));; > + binsExpected.add(new Interval(contig, 50000001, 60000000));; > + binsExpected.add(new Interval(contig, 60000001, 63025520));; > +; > + // compare the file contents to the expected result; > + Assert.assertEquals(binsFromFile, binsExpected);; > + }; > +; > +; > + // Test for reading intervals from a file; >; > Personally, and this is very subjective, I feel that once you're fully; > exploiting IntervalArgumentCollection you can get rid of tests that just; > vary how we pass the intervals via -L, because it's not our job here to; > verify the correctness of IntervalArgumentCollection. I would be curious; > to hear @samuelklee <https://github.com/samuelklee>'s opinion.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/3597#pullrequestreview-64752317>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGPkHhuk2NAMl5M4g7BYDg3AXGor3-VOks5slc7DgaJpZM4PeOtF>; > .; >. -- ; Marton Kanasz-Nagy; Physics Department, Harvard University; 17 Oxford Street, Cambridge, MA 02138; kanasz@physics.harvard.edu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:604,Usability,Simpl,SimpleInterval,604,"Thanks guys!. On Sat, Sep 23, 2017 at 11:38 PM, David Benjamin <notifications@github.com>; wrote:. > *@davidbenjamin* requested changes on this pull request.; >; > Done with my review. Mainly the usual stuff about writing more idiomatic; > Java that all C++ coders go through!; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646010>:; >; > > +import org.broadinstitute.hellbender.utils.IntervalUtils;; > +import org.broadinstitute.hellbender.utils.SimpleInterval;; > +; > +import java.io.File;; > +import java.util.List;; > +; > +; > +; > +@CommandLineProgramProperties(; > + summary = ""Split intervals into sub-interval files."",; > + oneLineSummary = ""Split intervals into sub-interval files."",; > + programGroup = VariantProgramGroup.class; > +); > +@DocumentedFeature; > +public class CreateBinningIntervals extends GATKTool {; > + public static final String WIDTH_OF_BINS_SHORT_NAME = ""bw"";; >; > @samuelklee <https://github.com/samuelklee> is the boss of the copy; > number code, but personally I don't see the need to be extremely concise; > with short names and would prefer width.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646054>:; >; > > +@DocumentedFeature; > +public class CreateBinningIntervals extends GATKTool {; > + public static final String WIDTH_OF_BINS_SHORT_NAME = ""bw"";; > + public static final String WIDTH_OF_BINS_LONG_NAME = ""binwidths"";; > +; > + public static final String PADDING_SHORT_NAME = ""pad"";; > + public static final String PADDING_LONG_NAME = ""padding"";; > +; > + @Argument(; > + doc = ""width of the bins"",; > + fullName = WIDTH_OF_BINS_LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + pri",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:5635,Usability,Simpl,SimpleInterval,5635,"LONG_NAME,; > + shortName = WIDTH_OF_BINS_SHORT_NAME,; > + optional = true,; > + minValue = 1; > + ); > + private int widthOfBins = 1;; > +; > + @Argument(; > + doc = ""width of the padding regions"",; > + fullName = PADDING_LONG_NAME,; > + shortName = PADDING_SHORT_NAME,; > + optional = true,; > + minValue = 0; > + ); > + private int padding = 0;; >; > . . . and if this padding is different from the inherited padding then; > this demands a comment to avoid confusion.; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646146>:; >; > > +; > + // check if the bin widths are set appropriately; > + if(widthOfBins <= 0) {; > + throw new IllegalArgumentException(""Width of bins "" + Integer.toString(widthOfBins) + "" should be >= 0."");; > + }; > +; > + // get the sequence dictionary; > + final SAMSequenceDictionary sequenceDictionary = getBestAvailableSequenceDictionary();; > + final List<SimpleInterval> intervals = hasIntervals() ? intervalArgumentCollection.getIntervals(sequenceDictionary); > + : IntervalUtils.getAllIntervalsForReference(sequenceDictionary);; > +; > + // create an IntervalList by copying all elements of 'intervals' into it; > + IntervalList intervalList = new IntervalList(sequenceDictionary);; > + intervals.stream().map(si -> new Interval(si.getContig(), si.getStart(), si.getEnd())).forEach(intervalList::add);; > +; > + // sort intervals according to their coordinates and unique them (i.e. delete duplicates); >; > I think the right word is uniquify; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646179>:; >; > > + : IntervalUtils.getAllIntervalsForReference(sequenceDictionary);; > +; > + // create an IntervalList by copying all elements of 'intervals' int",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211:7624,Usability,Simpl,SimpleInterval,7624,"f 'intervals' into it; > + IntervalList intervalList = new IntervalList(sequenceDictionary);; > + intervals.stream().map(si -> new Interval(si.getContig(), si.getStart(), si.getEnd())).forEach(intervalList::add);; > +; > + // sort intervals according to their coordinates and unique them (i.e. delete duplicates); > + intervalList.uniqued();; > +; > + // pad all elements of intervalList; > + intervalList = intervalList.padded(padding,padding);; > +; > + // merge those that intersect after padding; > + intervalList = IntervalList.intersection(intervalList, intervalList);; > +; > + // break the intervals up to bins -- the last bin in each interval can be shorter than the others; >; > ""break the intervals up into bins""; > ------------------------------; >; > In src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > CreateBinningIntervals.java; > <https://github.com/broadinstitute/gatk/pull/3597#discussion_r140646188>:; >; > > + final SAMSequenceDictionary sequenceDictionary = getBestAvailableSequenceDictionary();; > + final List<SimpleInterval> intervals = hasIntervals() ? intervalArgumentCollection.getIntervals(sequenceDictionary); > + : IntervalUtils.getAllIntervalsForReference(sequenceDictionary);; > +; > + // create an IntervalList by copying all elements of 'intervals' into it; > + IntervalList intervalList = new IntervalList(sequenceDictionary);; > + intervals.stream().map(si -> new Interval(si.getContig(), si.getStart(), si.getEnd())).forEach(intervalList::add);; > +; > + // sort intervals according to their coordinates and unique them (i.e. delete duplicates); > + intervalList.uniqued();; > +; > + // pad all elements of intervalList; > + intervalList = intervalList.padded(padding,padding);; > +; > + // merge those that intersect after padding; > + intervalList = IntervalList.intersection(intervalList, intervalList);; >; > As Sam said, some of this stuff can probably be handled automatically by; > IntervalArgumentCollection.; > ---------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-331744211
https://github.com/broadinstitute/gatk/pull/3597#issuecomment-333636280:28,Deployability,update,updated,28,Thanks for your comments! I updated the code.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3597#issuecomment-333636280
https://github.com/broadinstitute/gatk/pull/3598#issuecomment-330959993:1556,Testability,test,test,1556,98 +/- ##; ===============================================; + Coverage 79.721% 79.721% +0.001% ; - Complexity 18162 18189 +27 ; ===============================================; Files 1223 1223 ; Lines 66649 66735 +86 ; Branches 10409 10426 +17 ; ===============================================; + Hits 53133 53202 +69 ; - Misses 9309 9317 +8 ; - Partials 4207 4216 +9; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3598?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...tools/walkers/genotyper/AlleleSubsettingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3598?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9BbGxlbGVTdWJzZXR0aW5nVXRpbHMuamF2YQ==) | `88.596% <> ()` | `43 <0> ()` | :arrow_down: |; | [...e/hellbender/utils/variant/GATKVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/3598?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `99.281% <100%> (+0.016%)` | `10 <3> (+3)` | :arrow_up: |; | [...hellbender/utils/test/VariantContextTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3598?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1ZhcmlhbnRDb250ZXh0VGVzdFV0aWxzLmphdmE=) | `79.602% <79.31%> (-0.906%)` | `49 <24> (+24)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/3598?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.233% <0%> (-2.74%)` | `11% <0%> ()` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/3598?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (+1.948%)` | `39% <0%> ()` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3598#issuecomment-330959993
https://github.com/broadinstitute/gatk/issues/3599#issuecomment-331163651:388,Availability,error,error,388,"Five dollars says someone forgot a backslash at the end of a bash command. On Sep 21, 2017 09:42, ""ldgauthier"" <notifications@github.com> wrote:. > We had a little bit of trouble with AllelicCNV at the Finland workshop; > last week. Apologies that this isn't the most complete bug report, but the; > hands-on portion of the workshop moved pretty fast.; >; > Soo Hee took a picture of the error with her phone:; > [image: image]; > <https://user-images.githubusercontent.com/6578548/30697898-6dff7e24-9eae-11e7-8ec3-d876483fec1a.png>; > The rest of the relevant line is ""undefined symbol: cblas_daxpy""; >; > The version was the GATK4 beta 4 release and the command was:; >; > gatk-launch AllelicCNV \; > --tumorHets tumor_hets.tsv \; > --tangentNormalized tumor_C.tn.tsv \; > --segments tumor_C.seg \; > --outputPrefix acnv \; > --intervalThresholdCopyRatio 5.0; >; > The inputs are in the AllelicCNV workshop bundle in Google Drive:; > https://drive.google.com/drive/folders/0BzI1CyccGsZiU1dkcndQMkRmTTQ; >; > I think the host institution was running Red Hat, but it might have been; > Ubuntu. Like I said, sorry this is a pretty sad bug report. I haven't tried; > to reproduce the error since it seems platform-specific, but maybe some; > weirdo who doesn't use a Mac (@LeeTL1220 <https://github.com/leetl1220>); > would give it a shot?; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3599>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk2jo8d7ryQQY_DZoSMvpPR7VANRrks5skmeogaJpZM4PfVmS>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3599#issuecomment-331163651
https://github.com/broadinstitute/gatk/issues/3599#issuecomment-331163651:1182,Availability,error,error,1182,"Five dollars says someone forgot a backslash at the end of a bash command. On Sep 21, 2017 09:42, ""ldgauthier"" <notifications@github.com> wrote:. > We had a little bit of trouble with AllelicCNV at the Finland workshop; > last week. Apologies that this isn't the most complete bug report, but the; > hands-on portion of the workshop moved pretty fast.; >; > Soo Hee took a picture of the error with her phone:; > [image: image]; > <https://user-images.githubusercontent.com/6578548/30697898-6dff7e24-9eae-11e7-8ec3-d876483fec1a.png>; > The rest of the relevant line is ""undefined symbol: cblas_daxpy""; >; > The version was the GATK4 beta 4 release and the command was:; >; > gatk-launch AllelicCNV \; > --tumorHets tumor_hets.tsv \; > --tangentNormalized tumor_C.tn.tsv \; > --segments tumor_C.seg \; > --outputPrefix acnv \; > --intervalThresholdCopyRatio 5.0; >; > The inputs are in the AllelicCNV workshop bundle in Google Drive:; > https://drive.google.com/drive/folders/0BzI1CyccGsZiU1dkcndQMkRmTTQ; >; > I think the host institution was running Red Hat, but it might have been; > Ubuntu. Like I said, sorry this is a pretty sad bug report. I haven't tried; > to reproduce the error since it seems platform-specific, but maybe some; > weirdo who doesn't use a Mac (@LeeTL1220 <https://github.com/leetl1220>); > would give it a shot?; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3599>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk2jo8d7ryQQY_DZoSMvpPR7VANRrks5skmeogaJpZM4PfVmS>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3599#issuecomment-331163651
https://github.com/broadinstitute/gatk/issues/3599#issuecomment-331163651:640,Deployability,release,release,640,"Five dollars says someone forgot a backslash at the end of a bash command. On Sep 21, 2017 09:42, ""ldgauthier"" <notifications@github.com> wrote:. > We had a little bit of trouble with AllelicCNV at the Finland workshop; > last week. Apologies that this isn't the most complete bug report, but the; > hands-on portion of the workshop moved pretty fast.; >; > Soo Hee took a picture of the error with her phone:; > [image: image]; > <https://user-images.githubusercontent.com/6578548/30697898-6dff7e24-9eae-11e7-8ec3-d876483fec1a.png>; > The rest of the relevant line is ""undefined symbol: cblas_daxpy""; >; > The version was the GATK4 beta 4 release and the command was:; >; > gatk-launch AllelicCNV \; > --tumorHets tumor_hets.tsv \; > --tangentNormalized tumor_C.tn.tsv \; > --segments tumor_C.seg \; > --outputPrefix acnv \; > --intervalThresholdCopyRatio 5.0; >; > The inputs are in the AllelicCNV workshop bundle in Google Drive:; > https://drive.google.com/drive/folders/0BzI1CyccGsZiU1dkcndQMkRmTTQ; >; > I think the host institution was running Red Hat, but it might have been; > Ubuntu. Like I said, sorry this is a pretty sad bug report. I haven't tried; > to reproduce the error since it seems platform-specific, but maybe some; > weirdo who doesn't use a Mac (@LeeTL1220 <https://github.com/leetl1220>); > would give it a shot?; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/3599>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk2jo8d7ryQQY_DZoSMvpPR7VANRrks5skmeogaJpZM4PfVmS>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3599#issuecomment-331163651
https://github.com/broadinstitute/gatk/issues/3599#issuecomment-331165780:123,Integrability,depend,dependency,123,ACNV uses Spark MLlib's kernel density estimation to find the posterior mode from MCMC samples. I'm guessing the offending dependency comes from this import statement in `org.apache.spark.mllib.stat.KernelDensity`: `import com.github.fommil.netlib.BLAS.{getInstance => blas}` @lbergelson Any ideas?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3599#issuecomment-331165780
https://github.com/broadinstitute/gatk/issues/3599#issuecomment-356744585:141,Integrability,depend,dependency,141,"Deleted AllelicCNV in #3935. I don't think `org.apache.spark.mllib.stat.KernelDensity` is used any longer, but we may still run into similar dependency issues in the future. Going to close this for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3599#issuecomment-356744585
https://github.com/broadinstitute/gatk/pull/3600#issuecomment-331546971:96,Modifiability,refactor,refactor,96,"@cmnbroad I responded to your comments, what do you want to about names? Do you think we should refactor the haplotype caller tests to run with all the types of I also bumped to a more stable looking version of native bindings while I was at it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3600#issuecomment-331546971
https://github.com/broadinstitute/gatk/pull/3600#issuecomment-331546971:126,Testability,test,tests,126,"@cmnbroad I responded to your comments, what do you want to about names? Do you think we should refactor the haplotype caller tests to run with all the types of I also bumped to a more stable looking version of native bindings while I was at it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3600#issuecomment-331546971
https://github.com/broadinstitute/gatk/issues/3601#issuecomment-331469899:16,Availability,fault,fault,16,"Oops, that's my fault.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3601#issuecomment-331469899
https://github.com/broadinstitute/gatk/issues/3605#issuecomment-332370070:38,Availability,failure,failure,38,"@chapmanb We were able to reproduce a failure with your command line. This looks like an issue related to JNI and garbage collection that is exposed by setting `-Xmx46965m` and `-XX:+UseSerialGC`, but it needs further debugging. To confirm, can you please try running without specifying these javaOptions? Something like this:; ```; ./gatk-launch --javaOptions '-Djava.io.tmpdir=$TEMP_DIR' \; ApplyBQSRSpark \; --sparkMaster local[16] \; --input $BAM_IN \; --output $BAM_OUT \; --bqsr_recal_file $BQSR_RECAL \; -- \; --conf spark.local.dir=$SPARK_LOCAL_DIR; ```. FYI, we see better performance from Spark when using an SSD for spark.local.dir. The `--conf ` option above shows how to set the spark.local.dir.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3605#issuecomment-332370070
https://github.com/broadinstitute/gatk/issues/3605#issuecomment-332370070:582,Performance,perform,performance,582,"@chapmanb We were able to reproduce a failure with your command line. This looks like an issue related to JNI and garbage collection that is exposed by setting `-Xmx46965m` and `-XX:+UseSerialGC`, but it needs further debugging. To confirm, can you please try running without specifying these javaOptions? Something like this:; ```; ./gatk-launch --javaOptions '-Djava.io.tmpdir=$TEMP_DIR' \; ApplyBQSRSpark \; --sparkMaster local[16] \; --input $BAM_IN \; --output $BAM_OUT \; --bqsr_recal_file $BQSR_RECAL \; -- \; --conf spark.local.dir=$SPARK_LOCAL_DIR; ```. FYI, we see better performance from Spark when using an SSD for spark.local.dir. The `--conf ` option above shows how to set the spark.local.dir.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3605#issuecomment-332370070
https://github.com/broadinstitute/gatk/issues/3605#issuecomment-332370070:141,Security,expose,exposed,141,"@chapmanb We were able to reproduce a failure with your command line. This looks like an issue related to JNI and garbage collection that is exposed by setting `-Xmx46965m` and `-XX:+UseSerialGC`, but it needs further debugging. To confirm, can you please try running without specifying these javaOptions? Something like this:; ```; ./gatk-launch --javaOptions '-Djava.io.tmpdir=$TEMP_DIR' \; ApplyBQSRSpark \; --sparkMaster local[16] \; --input $BAM_IN \; --output $BAM_OUT \; --bqsr_recal_file $BQSR_RECAL \; -- \; --conf spark.local.dir=$SPARK_LOCAL_DIR; ```. FYI, we see better performance from Spark when using an SSD for spark.local.dir. The `--conf ` option above shows how to set the spark.local.dir.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3605#issuecomment-332370070
https://github.com/broadinstitute/gatk/issues/3605#issuecomment-333837665:119,Availability,error,error,119,George -- thanks much for debugging and identifying the underlying problem. I can confirm that we're able to avoid the error by removing `-XX:+UseSerialGC` and moving back to parallel GC. We'd initially introduced the serial GC usage to avoid problems when running multiple HaplotypeCaller commands simultaneously on a single machine but by letting the Spark implementation take care of parallelizing we should no longer need to worry about that. Thanks again for the workaround and the tip on using `spark.local.dir`. Much appreciated.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3605#issuecomment-333837665
https://github.com/broadinstitute/gatk/issues/3605#issuecomment-333837665:109,Safety,avoid,avoid,109,George -- thanks much for debugging and identifying the underlying problem. I can confirm that we're able to avoid the error by removing `-XX:+UseSerialGC` and moving back to parallel GC. We'd initially introduced the serial GC usage to avoid problems when running multiple HaplotypeCaller commands simultaneously on a single machine but by letting the Spark implementation take care of parallelizing we should no longer need to worry about that. Thanks again for the workaround and the tip on using `spark.local.dir`. Much appreciated.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3605#issuecomment-333837665
https://github.com/broadinstitute/gatk/issues/3605#issuecomment-333837665:237,Safety,avoid,avoid,237,George -- thanks much for debugging and identifying the underlying problem. I can confirm that we're able to avoid the error by removing `-XX:+UseSerialGC` and moving back to parallel GC. We'd initially introduced the serial GC usage to avoid problems when running multiple HaplotypeCaller commands simultaneously on a single machine but by letting the Spark implementation take care of parallelizing we should no longer need to worry about that. Thanks again for the workaround and the tip on using `spark.local.dir`. Much appreciated.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3605#issuecomment-333837665
https://github.com/broadinstitute/gatk/issues/3605#issuecomment-338723352:15,Usability,feedback,feedback,15,Thanks for the feedback Brad. We'll continue to look into the core dump to make sure it doesn't cause issues in the future.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3605#issuecomment-338723352
https://github.com/broadinstitute/gatk/issues/3605#issuecomment-349721014:33,Deployability,update,update,33,"I'm assuming that the recent GKL update addresses this, so am closing based on the girl scout principle (find it broken? fix it), but feel free to reopen. https://github.com/broadinstitute/gatk/pull/3865",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3605#issuecomment-349721014
https://github.com/broadinstitute/gatk/issues/3609#issuecomment-349667094:22,Testability,test,tests,22,"In implementing these tests, I have run into https://github.com/samtools/htsjdk/issues/1044, which is waiting on to unblock https://github.com/samtools/htsjdk/pull/1048.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3609#issuecomment-349667094
https://github.com/broadinstitute/gatk/issues/3610#issuecomment-331978713:85,Deployability,configurat,configuration,85,"Co-assigning to @jonn-smith, since it's likely to be implemented using the new OWNER configuration facility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3610#issuecomment-331978713
https://github.com/broadinstitute/gatk/issues/3610#issuecomment-331978713:85,Modifiability,config,configuration,85,"Co-assigning to @jonn-smith, since it's likely to be implemented using the new OWNER configuration facility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3610#issuecomment-331978713
https://github.com/broadinstitute/gatk/pull/3611#issuecomment-332025444:1251,Testability,log,loggers,1251,f39ae35a0604d3b3eca?src=pr&el=desc) will **decrease** coverage by `0.016%`.; > The diff coverage is `81%`. ```diff; @@ Coverage Diff @@; ## master #3611 +/- ##; ===============================================; - Coverage 79.487% 79.472% -0.016% ; - Complexity 18094 18099 +5 ; ===============================================; Files 1187 1192 +5 ; Lines 65403 65446 +43 ; Branches 9932 9939 +7 ; ===============================================; + Hits 51987 52011 +24 ; - Misses 9429 9437 +8 ; - Partials 3987 3998 +11; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3611?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `79.31% <> (-0.69%)` | `2 <0> ()` | |; | [...ols/spark/pathseq/loggers/PSFilterEmptyLogger.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL2xvZ2dlcnMvUFNGaWx0ZXJFbXB0eUxvZ2dlci5qYXZh) | `0% <0%> ()` | `0 <0> (?)` | |; | [...ools/spark/pathseq/loggers/PSFilterFileLogger.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL2xvZ2dlcnMvUFNGaWx0ZXJGaWxlTG9nZ2VyLmphdmE=) | `100% <100%> ()` | `8 <8> (?)` | |; | [...itute/hellbender/tools/spark/pathseq/PSFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyLmphdmE=) | `94.828% <100%> (+2.775%)` | `28 <6> (-5)` | :arrow_down: |; | [...er/tools/spark/pathseq/loggers/PSScoreMetrics.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-332025444
https://github.com/broadinstitute/gatk/pull/3611#issuecomment-332025444:1552,Testability,log,loggers,1552,========================; Files 1187 1192 +5 ; Lines 65403 65446 +43 ; Branches 9932 9939 +7 ; ===============================================; + Hits 51987 52011 +24 ; - Misses 9429 9437 +8 ; - Partials 3987 3998 +11; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/3611?src=pr&el=tree) | Coverage  | Complexity  | |; |---|---|---|---|; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `79.31% <> (-0.69%)` | `2 <0> ()` | |; | [...ols/spark/pathseq/loggers/PSFilterEmptyLogger.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL2xvZ2dlcnMvUFNGaWx0ZXJFbXB0eUxvZ2dlci5qYXZh) | `0% <0%> ()` | `0 <0> (?)` | |; | [...ools/spark/pathseq/loggers/PSFilterFileLogger.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL2xvZ2dlcnMvUFNGaWx0ZXJGaWxlTG9nZ2VyLmphdmE=) | `100% <100%> ()` | `8 <8> (?)` | |; | [...itute/hellbender/tools/spark/pathseq/PSFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyLmphdmE=) | `94.828% <100%> (+2.775%)` | `28 <6> (-5)` | :arrow_down: |; | [...er/tools/spark/pathseq/loggers/PSScoreMetrics.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL2xvZ2dlcnMvUFNTY29yZU1ldHJpY3MuamF2YQ==) | `100% <100%> ()` | `1 <1> (?)` | |; | [...tools/spark/pathseq/loggers/PSScoreFileLogger.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-332025444
https://github.com/broadinstitute/gatk/pull/3611#issuecomment-332025444:2164,Testability,log,loggers,2164,xsZWN0aW9uLmphdmE=) | `79.31% <> (-0.69%)` | `2 <0> ()` | |; | [...ols/spark/pathseq/loggers/PSFilterEmptyLogger.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL2xvZ2dlcnMvUFNGaWx0ZXJFbXB0eUxvZ2dlci5qYXZh) | `0% <0%> ()` | `0 <0> (?)` | |; | [...ools/spark/pathseq/loggers/PSFilterFileLogger.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL2xvZ2dlcnMvUFNGaWx0ZXJGaWxlTG9nZ2VyLmphdmE=) | `100% <100%> ()` | `8 <8> (?)` | |; | [...itute/hellbender/tools/spark/pathseq/PSFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyLmphdmE=) | `94.828% <100%> (+2.775%)` | `28 <6> (-5)` | :arrow_down: |; | [...er/tools/spark/pathseq/loggers/PSScoreMetrics.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL2xvZ2dlcnMvUFNTY29yZU1ldHJpY3MuamF2YQ==) | `100% <100%> ()` | `1 <1> (?)` | |; | [...tools/spark/pathseq/loggers/PSScoreFileLogger.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL2xvZ2dlcnMvUFNTY29yZUZpbGVMb2dnZXIuamF2YQ==) | `100% <100%> ()` | `4 <4> (?)` | |; | [...lbender/tools/spark/pathseq/PathSeqScoreSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFTY29yZVNwYXJrLmphdmE=) | `58.182% <60%> (-1.818%)` | `7 <0> (-1)` | |; | [...itute/hellbender/tools/spark/pathseq/PSScorer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-332025444
https://github.com/broadinstitute/gatk/pull/3611#issuecomment-332025444:2461,Testability,log,loggers,2461,x0ZXJFbXB0eUxvZ2dlci5qYXZh) | `0% <0%> ()` | `0 <0> (?)` | |; | [...ools/spark/pathseq/loggers/PSFilterFileLogger.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL2xvZ2dlcnMvUFNGaWx0ZXJGaWxlTG9nZ2VyLmphdmE=) | `100% <100%> ()` | `8 <8> (?)` | |; | [...itute/hellbender/tools/spark/pathseq/PSFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyLmphdmE=) | `94.828% <100%> (+2.775%)` | `28 <6> (-5)` | :arrow_down: |; | [...er/tools/spark/pathseq/loggers/PSScoreMetrics.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL2xvZ2dlcnMvUFNTY29yZU1ldHJpY3MuamF2YQ==) | `100% <100%> ()` | `1 <1> (?)` | |; | [...tools/spark/pathseq/loggers/PSScoreFileLogger.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL2xvZ2dlcnMvUFNTY29yZUZpbGVMb2dnZXIuamF2YQ==) | `100% <100%> ()` | `4 <4> (?)` | |; | [...lbender/tools/spark/pathseq/PathSeqScoreSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFTY29yZVNwYXJrLmphdmE=) | `58.182% <60%> (-1.818%)` | `7 <0> (-1)` | |; | [...itute/hellbender/tools/spark/pathseq/PSScorer.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTU2NvcmVyLmphdmE=) | `90.61% <66.667%> (-0.939%)` | `63 <0> (-1)` | |; | [...nder/tools/spark/pathseq/PathSeqPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/3611/diff?src=pr&el=tree#d,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-332025444
https://github.com/broadinstitute/gatk/pull/3611#issuecomment-333258346:97,Availability,down,down,97,@mwalker174 I'm asking of a bit of a re-haul of the specialized logging so perhaps you wanna sit down next week and go thru the code in tandem if you want.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-333258346
https://github.com/broadinstitute/gatk/pull/3611#issuecomment-333258346:64,Testability,log,logging,64,@mwalker174 I'm asking of a bit of a re-haul of the specialized logging so perhaps you wanna sit down next week and go thru the code in tandem if you want.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-333258346
https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160:368,Integrability,interface,interface,368,"Thank you @vruano for your diligent review. I've implemented logger classes to encapsulate the metrics classes. Unfortunately the metrics classes must remain public in order to write output using `MetricsUtils.saveMetrics()`, but at least the tools aren't using them directly. There are two logging class groups - one for Filter and one Score. For Filter, there is an interface `PSFilterLogger` that is implemented by a file-logging class `PSFilterFileLogger` and a dummy class `PSFilterEmptyLogger` that does nothing. There are analogous classes for Score, but there is no Empty logger because it's not actually necessary. This adds a lot of new classes (maybe you can think of a better way) but usage has been greatly simplified. As we discussed in person, I don't think there is a faster way to count the reads in Spark. If you wanted to count the reads as they pass through, you would have to use some kind of atomic type that would be slow. Also it may be impossible to account for cases when tasks fail and restart. @lbergelson @droazen In this PR, I wanted to use htsjdk's MetricsFile and MetricBase classes for writing metrics to a file. I notice that these classes are mostly used for picard-related things. Is this the preferred way to do things? They do force you to expose public variables and also use an upper-case naming convention. On the other hand, they are somewhat convenient.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160
https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160:1292,Modifiability,variab,variables,1292,"Thank you @vruano for your diligent review. I've implemented logger classes to encapsulate the metrics classes. Unfortunately the metrics classes must remain public in order to write output using `MetricsUtils.saveMetrics()`, but at least the tools aren't using them directly. There are two logging class groups - one for Filter and one Score. For Filter, there is an interface `PSFilterLogger` that is implemented by a file-logging class `PSFilterFileLogger` and a dummy class `PSFilterEmptyLogger` that does nothing. There are analogous classes for Score, but there is no Empty logger because it's not actually necessary. This adds a lot of new classes (maybe you can think of a better way) but usage has been greatly simplified. As we discussed in person, I don't think there is a faster way to count the reads in Spark. If you wanted to count the reads as they pass through, you would have to use some kind of atomic type that would be slow. Also it may be impossible to account for cases when tasks fail and restart. @lbergelson @droazen In this PR, I wanted to use htsjdk's MetricsFile and MetricBase classes for writing metrics to a file. I notice that these classes are mostly used for picard-related things. Is this the preferred way to do things? They do force you to expose public variables and also use an upper-case naming convention. On the other hand, they are somewhat convenient.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160
https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160:1278,Security,expose,expose,1278,"Thank you @vruano for your diligent review. I've implemented logger classes to encapsulate the metrics classes. Unfortunately the metrics classes must remain public in order to write output using `MetricsUtils.saveMetrics()`, but at least the tools aren't using them directly. There are two logging class groups - one for Filter and one Score. For Filter, there is an interface `PSFilterLogger` that is implemented by a file-logging class `PSFilterFileLogger` and a dummy class `PSFilterEmptyLogger` that does nothing. There are analogous classes for Score, but there is no Empty logger because it's not actually necessary. This adds a lot of new classes (maybe you can think of a better way) but usage has been greatly simplified. As we discussed in person, I don't think there is a faster way to count the reads in Spark. If you wanted to count the reads as they pass through, you would have to use some kind of atomic type that would be slow. Also it may be impossible to account for cases when tasks fail and restart. @lbergelson @droazen In this PR, I wanted to use htsjdk's MetricsFile and MetricBase classes for writing metrics to a file. I notice that these classes are mostly used for picard-related things. Is this the preferred way to do things? They do force you to expose public variables and also use an upper-case naming convention. On the other hand, they are somewhat convenient.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160
https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160:61,Testability,log,logger,61,"Thank you @vruano for your diligent review. I've implemented logger classes to encapsulate the metrics classes. Unfortunately the metrics classes must remain public in order to write output using `MetricsUtils.saveMetrics()`, but at least the tools aren't using them directly. There are two logging class groups - one for Filter and one Score. For Filter, there is an interface `PSFilterLogger` that is implemented by a file-logging class `PSFilterFileLogger` and a dummy class `PSFilterEmptyLogger` that does nothing. There are analogous classes for Score, but there is no Empty logger because it's not actually necessary. This adds a lot of new classes (maybe you can think of a better way) but usage has been greatly simplified. As we discussed in person, I don't think there is a faster way to count the reads in Spark. If you wanted to count the reads as they pass through, you would have to use some kind of atomic type that would be slow. Also it may be impossible to account for cases when tasks fail and restart. @lbergelson @droazen In this PR, I wanted to use htsjdk's MetricsFile and MetricBase classes for writing metrics to a file. I notice that these classes are mostly used for picard-related things. Is this the preferred way to do things? They do force you to expose public variables and also use an upper-case naming convention. On the other hand, they are somewhat convenient.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160
https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160:291,Testability,log,logging,291,"Thank you @vruano for your diligent review. I've implemented logger classes to encapsulate the metrics classes. Unfortunately the metrics classes must remain public in order to write output using `MetricsUtils.saveMetrics()`, but at least the tools aren't using them directly. There are two logging class groups - one for Filter and one Score. For Filter, there is an interface `PSFilterLogger` that is implemented by a file-logging class `PSFilterFileLogger` and a dummy class `PSFilterEmptyLogger` that does nothing. There are analogous classes for Score, but there is no Empty logger because it's not actually necessary. This adds a lot of new classes (maybe you can think of a better way) but usage has been greatly simplified. As we discussed in person, I don't think there is a faster way to count the reads in Spark. If you wanted to count the reads as they pass through, you would have to use some kind of atomic type that would be slow. Also it may be impossible to account for cases when tasks fail and restart. @lbergelson @droazen In this PR, I wanted to use htsjdk's MetricsFile and MetricBase classes for writing metrics to a file. I notice that these classes are mostly used for picard-related things. Is this the preferred way to do things? They do force you to expose public variables and also use an upper-case naming convention. On the other hand, they are somewhat convenient.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160
https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160:425,Testability,log,logging,425,"Thank you @vruano for your diligent review. I've implemented logger classes to encapsulate the metrics classes. Unfortunately the metrics classes must remain public in order to write output using `MetricsUtils.saveMetrics()`, but at least the tools aren't using them directly. There are two logging class groups - one for Filter and one Score. For Filter, there is an interface `PSFilterLogger` that is implemented by a file-logging class `PSFilterFileLogger` and a dummy class `PSFilterEmptyLogger` that does nothing. There are analogous classes for Score, but there is no Empty logger because it's not actually necessary. This adds a lot of new classes (maybe you can think of a better way) but usage has been greatly simplified. As we discussed in person, I don't think there is a faster way to count the reads in Spark. If you wanted to count the reads as they pass through, you would have to use some kind of atomic type that would be slow. Also it may be impossible to account for cases when tasks fail and restart. @lbergelson @droazen In this PR, I wanted to use htsjdk's MetricsFile and MetricBase classes for writing metrics to a file. I notice that these classes are mostly used for picard-related things. Is this the preferred way to do things? They do force you to expose public variables and also use an upper-case naming convention. On the other hand, they are somewhat convenient.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160
https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160:580,Testability,log,logger,580,"Thank you @vruano for your diligent review. I've implemented logger classes to encapsulate the metrics classes. Unfortunately the metrics classes must remain public in order to write output using `MetricsUtils.saveMetrics()`, but at least the tools aren't using them directly. There are two logging class groups - one for Filter and one Score. For Filter, there is an interface `PSFilterLogger` that is implemented by a file-logging class `PSFilterFileLogger` and a dummy class `PSFilterEmptyLogger` that does nothing. There are analogous classes for Score, but there is no Empty logger because it's not actually necessary. This adds a lot of new classes (maybe you can think of a better way) but usage has been greatly simplified. As we discussed in person, I don't think there is a faster way to count the reads in Spark. If you wanted to count the reads as they pass through, you would have to use some kind of atomic type that would be slow. Also it may be impossible to account for cases when tasks fail and restart. @lbergelson @droazen In this PR, I wanted to use htsjdk's MetricsFile and MetricBase classes for writing metrics to a file. I notice that these classes are mostly used for picard-related things. Is this the preferred way to do things? They do force you to expose public variables and also use an upper-case naming convention. On the other hand, they are somewhat convenient.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160
https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160:720,Usability,simpl,simplified,720,"Thank you @vruano for your diligent review. I've implemented logger classes to encapsulate the metrics classes. Unfortunately the metrics classes must remain public in order to write output using `MetricsUtils.saveMetrics()`, but at least the tools aren't using them directly. There are two logging class groups - one for Filter and one Score. For Filter, there is an interface `PSFilterLogger` that is implemented by a file-logging class `PSFilterFileLogger` and a dummy class `PSFilterEmptyLogger` that does nothing. There are analogous classes for Score, but there is no Empty logger because it's not actually necessary. This adds a lot of new classes (maybe you can think of a better way) but usage has been greatly simplified. As we discussed in person, I don't think there is a faster way to count the reads in Spark. If you wanted to count the reads as they pass through, you would have to use some kind of atomic type that would be slow. Also it may be impossible to account for cases when tasks fail and restart. @lbergelson @droazen In this PR, I wanted to use htsjdk's MetricsFile and MetricBase classes for writing metrics to a file. I notice that these classes are mostly used for picard-related things. Is this the preferred way to do things? They do force you to expose public variables and also use an upper-case naming convention. On the other hand, they are somewhat convenient.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-334308160
https://github.com/broadinstitute/gatk/pull/3611#issuecomment-336521031:131,Modifiability,refactor,refactoring,131,"Looking at MetricFile and with it heavy use of Reflexion looks a bit nasty, if there is a better alternative the better. I guess a refactoring of MetricFile would use annotations to allow one to customize output variable name... force one to have those not-so-good looking CAPITAL_FIELD_NAMES for the sake of it is harsh. Don't understand why One has to commit to ; particular type for all histograms either. . Anyway, only if the use of MetricFile is an overkill I would ask you to do your custom one (i.e if it can be done in a few lines of code).... probably not the case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-336521031
https://github.com/broadinstitute/gatk/pull/3611#issuecomment-336521031:212,Modifiability,variab,variable,212,"Looking at MetricFile and with it heavy use of Reflexion looks a bit nasty, if there is a better alternative the better. I guess a refactoring of MetricFile would use annotations to allow one to customize output variable name... force one to have those not-so-good looking CAPITAL_FIELD_NAMES for the sake of it is harsh. Don't understand why One has to commit to ; particular type for all histograms either. . Anyway, only if the use of MetricFile is an overkill I would ask you to do your custom one (i.e if it can be done in a few lines of code).... probably not the case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-336521031
https://github.com/broadinstitute/gatk/pull/3611#issuecomment-344761211:82,Testability,log,loggers,82,Thank you @vruano. I've addressed your comments to implement AutoCloseable in the loggers and use try-with-resources. I also moved the hg19mini BWA image file to the base resources directory.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/3611#issuecomment-344761211
https://github.com/broadinstitute/gatk/issues/3612#issuecomment-332053448:36,Deployability,pipeline,pipeline,36,"I am OK with removing it, since our pipeline seems to have been stabilized without it for almost 6 months now. What do you think @cwhelan @tedsharpe ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3612#issuecomment-332053448
https://github.com/broadinstitute/gatk/issues/3612#issuecomment-332170554:209,Deployability,pipeline,pipeline,209,"I'm fine with it.; If the skipped tests are the primary irritant let's just delete them. > On Sep 25, 2017, at 8:47 PM, Steve Huang <notifications@github.com> wrote:; > ; > I am OK with removing it, since our pipeline seems to have been stabilized without it for almost 6 months now. What do you think @cwhelan @tedsharpe ?; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3612#issuecomment-332170554
https://github.com/broadinstitute/gatk/issues/3612#issuecomment-332170554:34,Testability,test,tests,34,"I'm fine with it.; If the skipped tests are the primary irritant let's just delete them. > On Sep 25, 2017, at 8:47 PM, Steve Huang <notifications@github.com> wrote:; > ; > I am OK with removing it, since our pipeline seems to have been stabilized without it for almost 6 months now. What do you think @cwhelan @tedsharpe ?; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3612#issuecomment-332170554
https://github.com/broadinstitute/gatk/issues/3612#issuecomment-332184271:341,Deployability,pipeline,pipeline,341,"Yes I think we can get rid of these. > On Sep 26, 2017, at 7:34 AM, tedsharpe <notifications@github.com> wrote:; > ; > I'm fine with it.; > If the skipped tests are the primary irritant let's just delete them.; > ; > > On Sep 25, 2017, at 8:47 PM, Steve Huang <notifications@github.com> wrote:; > > ; > > I am OK with removing it, since our pipeline seems to have been stabilized without it for almost 6 months now. What do you think @cwhelan @tedsharpe ?; > > ; > > ; > > You are receiving this because you were mentioned.; > > Reply to this email directly, view it on GitHub, or mute the thread.; > > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3612#issuecomment-332184271
https://github.com/broadinstitute/gatk/issues/3612#issuecomment-332184271:155,Testability,test,tests,155,"Yes I think we can get rid of these. > On Sep 26, 2017, at 7:34 AM, tedsharpe <notifications@github.com> wrote:; > ; > I'm fine with it.; > If the skipped tests are the primary irritant let's just delete them.; > ; > > On Sep 25, 2017, at 8:47 PM, Steve Huang <notifications@github.com> wrote:; > > ; > > I am OK with removing it, since our pipeline seems to have been stabilized without it for almost 6 months now. What do you think @cwhelan @tedsharpe ?; > > ; > > ; > > You are receiving this because you were mentioned.; > > Reply to this email directly, view it on GitHub, or mute the thread.; > > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or mute the thread.; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/3612#issuecomment-332184271
