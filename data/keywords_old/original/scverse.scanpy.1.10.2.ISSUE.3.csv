id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/2158:88,Testability,test,tests,88,"https://github.com/theislab/scanpy/blob/0fde3f6cf93806bb1be1ac5fa4449da8a670fcf3/scanpy/tests/test_plotting.py#L1504. should it be moved in tests externals? if not, then `flit install -s --deps=develop` doesn't install scrublet whereas it should imho otherwise test fails for fail import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2158
https://github.com/scverse/scanpy/issues/2158:140,Testability,test,tests,140,"https://github.com/theislab/scanpy/blob/0fde3f6cf93806bb1be1ac5fa4449da8a670fcf3/scanpy/tests/test_plotting.py#L1504. should it be moved in tests externals? if not, then `flit install -s --deps=develop` doesn't install scrublet whereas it should imho otherwise test fails for fail import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2158
https://github.com/scverse/scanpy/issues/2158:261,Testability,test,test,261,"https://github.com/theislab/scanpy/blob/0fde3f6cf93806bb1be1ac5fa4449da8a670fcf3/scanpy/tests/test_plotting.py#L1504. should it be moved in tests externals? if not, then `flit install -s --deps=develop` doesn't install scrublet whereas it should imho otherwise test fails for fail import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2158
https://github.com/scverse/scanpy/pull/2159:41,Availability,error,error,41,Backport PR #2120: Fix colorbar mappable error for older matplotlib,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2159
https://github.com/scverse/scanpy/issues/2160:468,Availability,error,error,468,"> Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. ; ### Minimal code sample. ```python. import scanpy; import numpy; > ; tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'); sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>; <summary> traceback </summary>. ```pytb; > The error I get:; > ---------------------------------------------------------------------------; > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context; yield; File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block; self.lower_inst(inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst; val = self.lower_assign(ty, inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign; return self.lower_expr(ty, value); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr; res = self.lower_call(resty, expr); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call; res = self._lower_call_normal(fnty, expr, signature); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal; res = impl(self.builder, argvals, self.loc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__; res = self._imp(self._context, builder, self._sig, args, loc=loc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:652,Availability,error,errors,652,"> Hi, I am working with a big dataset and I run into a problem when computing the neigbours. Find below an small example:. ; ### Minimal code sample. ```python. import scanpy; import numpy; > ; tab = scvi.data.read_csv(""C:/Users/RUTBO/AML-029-01-1E.gene.expression.matrix.tsv"", delimiter='\t', first_column_names=True). sc.tl.pca(tab, svd_solver='arpack'); sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40). ```. <details>; <summary> traceback </summary>. ```pytb; > The error I get:; > ---------------------------------------------------------------------------; > File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 823, in new_error_context; yield; File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block; self.lower_inst(inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 438, in lower_inst; val = self.lower_assign(ty, inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign; return self.lower_expr(ty, value); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr; res = self.lower_call(resty, expr); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call; res = self._lower_call_normal(fnty, expr, signature); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal; res = impl(self.builder, argvals, self.loc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__; res = self._imp(self._context, builder, self._sig, args, loc=loc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7470,Availability,error,errors,7470,"_pass, internal_state); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check; mangled = func(compiler_state); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass; lower.lower(); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower; self.lower_normal_function(self.fndesc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function; entry_block_tail = self.lower_function_body(); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body; self.lower_block(block); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block; self.lower_inst(inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__; self.gen.throw(type, value, traceback); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context; raise newerr.with_traceback(tb); numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53); ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7558,Availability,error,errors,7558,"_pass, internal_state); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check; mangled = func(compiler_state); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass; lower.lower(); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower; self.lower_normal_function(self.fndesc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function; entry_block_tail = self.lower_function_body(); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body; self.lower_block(block); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block; self.lower_inst(inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__; self.gen.throw(type, value, traceback); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context; raise newerr.with_traceback(tb); numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53); ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4933,Deployability,pipeline,pipeline,4933,"sers\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper; disp.compile(sig); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile; cres = self._compiler.compile(args, return_type); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile; status, retval = self._compile_cached(args, return_type); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached; retval = self._compile_core(args, return_type); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core; cres = compiler.compile_extra(self.targetdescr.typing_context,; File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra; return pipeline.compile_extra(func); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 429, in compile_extra; return self._compile_bytecode(); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 497, in _compile_bytecode; return self._compile_core(); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 476, in _compile_core; raise e; File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 463, in _compile_core; pm.run(self.state); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 353, in run; raise patched_exception; File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 341, in run; self._runPass(idx, pass_inst, state); File ""C:\Us",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:7604,Deployability,pipeline,pipeline,7604,"_pass, internal_state); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler_machinery.py"", line 269, in check; mangled = func(compiler_state); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\typed_passes.py"", line 394, in run_pass; lower.lower(); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 196, in lower; self.lower_normal_function(self.fndesc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 250, in lower_normal_function; entry_block_tail = self.lower_function_body(); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 279, in lower_function_body; self.lower_block(block); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 293, in lower_block; self.lower_inst(inst); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\contextlib.py"", line 135, in __exit__; self.gen.throw(type, value, traceback); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\errors.py"", line 837, in new_error_context; raise newerr.with_traceback(tb); numba.core.errors.LoweringError: Failed in nopython mode pipeline (step: native lowering); Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). File ""..\..\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 53:; def rdist(x, y):; <source elided>; dim = x.shape[0]; for i in range(dim):; ^. During: lowering ""$20call_function.7 = call $16load_global.5(dim, func=$16load_global.5, args=[Var(dim, layouts.py:52)], kws=(), vararg=None, target=None)"" at C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py (53); ```. </details>. I am running scanpy using python v3.9 with numba v0.55.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:2015,Integrability,wrap,wrapper,2015,"n39\lib\site-packages\numba\core\lowering.py"", line 624, in lower_assign; return self.lower_expr(ty, value); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1159, in lower_expr; res = self.lower_call(resty, expr); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 889, in lower_call; res = self._lower_call_normal(fnty, expr, signature); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\lowering.py"", line 1130, in _lower_call_normal; res = impl(self.builder, argvals, self.loc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1201, in __call__; res = self._imp(self._context, builder, self._sig, args, loc=loc); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\base.py"", line 1231, in wrapper; return fn(*args, **kwargs); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\cpython\rangeobj.py"", line 40, in range1_impl; state.stop = stop; File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 164, in __setattr__; self[self._datamodel.get_field_position(field)] = value; File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\cgutils.py"", line 188, in __setitem__; raise TypeError(""Invalid store of {value.type} to ""; TypeError: Invalid store of i64 to i32 in <numba.core.datamodel.models.RangeModel object at 0x0000015592499520> (trying to write member #1). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""C:\Users\RUTBO\PycharmProjects\pvalue\single cell analysis.py"", line 44, in <module>; sc.pp.neighbors(tab, n_neighbors=10, n_pcs=40); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 139, in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2160:4025,Integrability,wrap,wrapper,4025,"packages\scanpy\neighbors\__init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\neighbors\__init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\__init__.py"", line 2, in <module>; from .umap_ import UMAP; File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\umap_.py"", line 41, in <module>; from umap.layouts import (; File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\umap\layouts.py"", line 39, in <module>; def rdist(x, y):; File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\decorators.py"", line 219, in wrapper; disp.compile(sig); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 965, in compile; cres = self._compiler.compile(args, return_type); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 125, in compile; status, retval = self._compile_cached(args, return_type); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 139, in _compile_cached; retval = self._compile_core(args, return_type); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\dispatcher.py"", line 152, in _compile_core; cres = compiler.compile_extra(self.targetdescr.typing_context,; File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\lib\site-packages\numba\core\compiler.py"", line 693, in compile_extra; return pipeline.compile_extra(func); File ""C:\Users\RUTBO\AppData\Local\Programs\Python\Python39\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2160
https://github.com/scverse/scanpy/issues/2161:246,Availability,down,download,246,"Hello,. I will analyze data from the GEO dataset [GSE161529](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE161529). There is one folder containing the files *-barcodes.tsv.gz and *-matrix.mtx.gz from multiple samples. Separately, one can download one single _features.tsv.gz file. I plan to read each sample through a loop but I do not manage since read_10x_mtx allows a single prefix, but the prefixes are not the same for barcodes and matrix on the one side and features on the other side.; Here is an example of file names for one sample:. > GSM4909253_N-PM0092-Total-barcodes.tsv.gz; > GSM4909253_N-PM0092-Total-matrix.mtx.gz. while the feature file is:. > GSE161529_features. My idea is to rename the feature file in my for loop with the corresponding prefix... I would like to know if there is something more appropriate to do, maybe another function or parameters that I miss... Thank you in advance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2161
https://github.com/scverse/scanpy/issues/2162:52,Deployability,integrat,integrating,52,"Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers; Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:381,Deployability,integrat,integration,381,"Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers; Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:52,Integrability,integrat,integrating,52,"Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers; Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:381,Integrability,integrat,integration,381,"Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers; Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:307,Testability,test,test,307,"Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers; Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:353,Testability,test,test,353,"Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers; Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2162:457,Testability,test,test,457,"Hi. I have a question. I am using the scanorama for integrating multiple datasets. In my use-case, I will have a new dataset again. The question is, is there any way to transfer the results of scanorama to the new dataset? Or should I retrain everything again. This is also important if one has a train and test set. Ideally, you do not want to use the test set to use in the data integration training and only use the already trained transformation on the test data. . I am wondering if there is a solution for these use-cases? Would you please help us with that. Cheers; Ali",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2162
https://github.com/scverse/scanpy/issues/2163:205,Availability,error,error,205,"scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python ; B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(); sc.pp.scale(B); sc.tl.pca(B, svd_solver='arpack'); ```. Yet I encounter an error:; `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2163:332,Availability,error,error,332,"scanpy==1.8.2. Hi,. I'm attempting to cluster subset of B-cells:. ```python ; B=ad[ad.obs['clusters'].isin(['B-cell']),:].copy(); sc.pp.scale(B); sc.tl.pca(B, svd_solver='arpack'); ```. Yet I encounter an error:; `ValueError: Input contains NaN, infinity or a value too large for dtype('float32').`. When I don't scale the data the error doe not occur.. any suggestions? I supposed that after taking a subset rescaling is needed for these cells. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2163
https://github.com/scverse/scanpy/issues/2164:144,Deployability,integrat,integrating-data-using-ingest,144,"Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2164:144,Integrability,integrat,integrating-data-using-ingest,144,"Hi,. I found that in some tutorial documents, they does not use sc.pp.scale before sc.tl.pca. https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html. But for some documents, they used. https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. This thing also happened in several tools' analysis codes. https://docs.scvi-tools.org/en/stable/tutorials/notebooks/api_overview.html. Therefore, I wonder if the scale function is a key step for PCA analysis or not. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2164
https://github.com/scverse/scanpy/issues/2165:58,Availability,error,error,58,"Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`; `>>> import sklearn`; `>>> import scanpy`; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>; from . import tools as tl; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>; from ..preprocessing import pca; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>; from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>; from ._normalization import normalize_total; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>; from sklearn.utils import sparsefuncs; ImportError: cannot import name 'sparsefuncs'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:209,Availability,error,error,209,"Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`; `>>> import sklearn`; `>>> import scanpy`; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>; from . import tools as tl; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>; from ..preprocessing import pca; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>; from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>; from ._normalization import normalize_total; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>; from sklearn.utils import sparsefuncs; ImportError: cannot import name 'sparsefuncs'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:368,Availability,error,error,368,"Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`; `>>> import sklearn`; `>>> import scanpy`; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>; from . import tools as tl; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>; from ..preprocessing import pca; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>; from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>; from ._normalization import normalize_total; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>; from sklearn.utils import sparsefuncs; ImportError: cannot import name 'sparsefuncs'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/issues/2165:142,Deployability,install,installed,142,"Hi, thanks for developing Scanpy. Here, I encountered the error, `ImportError: cannot import name 'sparsefuncs'`. To solve this problem, I re-installed ""sklearn.utils"" and ""sklearn"". However, I still get this error when importing Scanpy. The Scanpy runs correctly in my linux system, but it cannot be imported corrected in my windows 10 system. **Here is the code and error information:**. `>>> import sklearn.utils`; `>>> import sklearn`; `>>> import scanpy`; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\__init__.py"", line 15, in <module>; from . import tools as tl; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\tools\__init__.py"", line 1, in <module>; from ..preprocessing import pca; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\__init__.py"", line 1, in <module>; from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_recipes.py"", line 11, in <module>; from ._normalization import normalize_total; File ""D:\system_software\Miniconda3\envs\PAGA\lib\site-packages\scanpy\preprocessing\_normalization.py"", line 6, in <module>; from sklearn.utils import sparsefuncs; ImportError: cannot import name 'sparsefuncs'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2165
https://github.com/scverse/scanpy/pull/2167:19,Deployability,Update,Update,19,Backport PR #2166: Update intersphinx links,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2167
https://github.com/scverse/scanpy/issues/2169:4381,Availability,error,error,4381,"""""""; 341 if isinstance(moduleOrReq, Requirement):; --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]; 343 try:; 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements); 884 included, even if they were already activated in this working set.; 885 """"""; --> 886 needed = self.resolve(parse_requirements(requirements)); 887 ; 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras); 770 if dist is None:; 771 requirers = required_by.get(req, None); --> 772 raise DistributionNotFound(req, requirers); 773 to_activate.append(dist); 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application; ```. #### Versions; latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>; ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file); 167 try:; 168 buf = sys.stdout = io.StringIO(); --> 169 sinfo(; 170 dependencies=True,; 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 208 for mod_name in clean_modules:; 209 mod_names.append(mod_name); --> 210 mod = sys.modules[mod_name]; 211 # Since modules use different attribute names to store version info,; 212 # try the most common ones. KeyError: 'umap'; ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:1946,Deployability,install,installed,1946,"_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 806 # we need self._distances also for method == 'gauss' if we didn't; 807 # use dense distances; --> 808 self._distances, self._connectivities = _compute_connectivities_umap(; 809 knn_indices,; 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 385 # umap 0.5.0; 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""); --> 387 from umap.umap_ import fuzzy_simplicial_set; 388 ; 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>; 1 from warnings import warn, catch_warnings, simplefilter; ----> 2 from .umap_ import UMAP; 3 ; 4 try:; 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>; 45 ); 46 ; ---> 47 from pynndescent import NNDescent; 48 from pynndescent.distances import named_distances as pynn_named_distances; 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>; 13 numba.config.THREADING_LAYER = ""workqueue""; 14 ; ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:3936,Deployability,install,installer,3936," get_distribution(dist); 464 dist = Requirement.parse(dist); 465 if isinstance(dist, Requirement):; --> 466 dist = get_provider(dist); 467 if not isinstance(dist, Distribution):; 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq); 340 """"""Return an IResourceProvider for the named module or requirement""""""; 341 if isinstance(moduleOrReq, Requirement):; --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]; 343 try:; 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements); 884 included, even if they were already activated in this working set.; 885 """"""; --> 886 needed = self.resolve(parse_requirements(requirements)); 887 ; 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras); 770 if dist is None:; 771 requirers = required_by.get(req, None); --> 772 raise DistributionNotFound(req, requirers); 773 to_activate.append(dist); 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application; ```. #### Versions; latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>; ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file); 167 try:; 168 buf = sys.stdout = io.StringIO(); --> 169 sinfo(; 170 dependencies=True,; 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:1921,Integrability,message,message,1921,"_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 806 # we need self._distances also for method == 'gauss' if we didn't; 807 # use dense distances; --> 808 self._distances, self._connectivities = _compute_connectivities_umap(; 809 knn_indices,; 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 385 # umap 0.5.0; 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""); --> 387 from umap.umap_ import fuzzy_simplicial_set; 388 ; 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>; 1 from warnings import warn, catch_warnings, simplefilter; ----> 2 from .umap_ import UMAP; 3 ; 4 try:; 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>; 45 ); 46 ; ---> 47 from pynndescent import NNDescent; 48 from pynndescent.distances import named_distances as pynn_named_distances; 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>; 13 numba.config.THREADING_LAYER = ""workqueue""; 14 ; ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4822,Integrability,depend,dependencies,4822,"""""""; 341 if isinstance(moduleOrReq, Requirement):; --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]; 343 try:; 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements); 884 included, even if they were already activated in this working set.; 885 """"""; --> 886 needed = self.resolve(parse_requirements(requirements)); 887 ; 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras); 770 if dist is None:; 771 requirers = required_by.get(req, None); --> 772 raise DistributionNotFound(req, requirers); 773 to_activate.append(dist); 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application; ```. #### Versions; latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>; ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file); 167 try:; 168 buf = sys.stdout = io.StringIO(); --> 169 sinfo(; 170 dependencies=True,; 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 208 for mod_name in clean_modules:; 209 mod_names.append(mod_name); --> 210 mod = sys.modules[mod_name]; 211 # Since modules use different attribute names to store version info,; 212 # try the most common ones. KeyError: 'umap'; ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4986,Integrability,depend,dependencies,4986,"""""""; 341 if isinstance(moduleOrReq, Requirement):; --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]; 343 try:; 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements); 884 included, even if they were already activated in this working set.; 885 """"""; --> 886 needed = self.resolve(parse_requirements(requirements)); 887 ; 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras); 770 if dist is None:; 771 requirers = required_by.get(req, None); --> 772 raise DistributionNotFound(req, requirers); 773 to_activate.append(dist); 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application; ```. #### Versions; latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>; ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file); 167 try:; 168 buf = sys.stdout = io.StringIO(); --> 169 sinfo(; 170 dependencies=True,; 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 208 for mod_name in clean_modules:; 209 mod_names.append(mod_name); --> 210 mod = sys.modules[mod_name]; 211 # Since modules use different attribute names to store version info,; 212 # try the most common ones. KeyError: 'umap'; ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2775,Modifiability,config,config,2775,"map(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 385 # umap 0.5.0; 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""); --> 387 from umap.umap_ import fuzzy_simplicial_set; 388 ; 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>; 1 from warnings import warn, catch_warnings, simplefilter; ----> 2 from .umap_ import UMAP; 3 ; 4 try:; 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>; 45 ); 46 ; ---> 47 from pynndescent import NNDescent; 48 from pynndescent.distances import named_distances as pynn_named_distances; 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>; 13 numba.config.THREADING_LAYER = ""workqueue""; 14 ; ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist); 464 dist = Requirement.parse(dist); 465 if isinstance(dist, Requirement):; --> 466 dist = get_provider(dist); 467 if not isinstance(dist, Distribution):; 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist). /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_provider(moduleOrReq); 340 """"""Return an IResourceProvider for the named module or requirement""""""; 341 if isinstance(moduleOrReq, Requirement):; --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]; 343 try:; 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements); 884 included, even if they were already activated in this working set.; 885 """"""; --> 886 needed = self.resolve(parse_requ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4601,Testability,log,logging,4601,"""""""; 341 if isinstance(moduleOrReq, Requirement):; --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]; 343 try:; 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements); 884 included, even if they were already activated in this working set.; 885 """"""; --> 886 needed = self.resolve(parse_requirements(requirements)); 887 ; 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras); 770 if dist is None:; 771 requirers = required_by.get(req, None); --> 772 raise DistributionNotFound(req, requirers); 773 to_activate.append(dist); 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application; ```. #### Versions; latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>; ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file); 167 try:; 168 buf = sys.stdout = io.StringIO(); --> 169 sinfo(; 170 dependencies=True,; 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 208 for mod_name in clean_modules:; 209 mod_names.append(mod_name); --> 210 mod = sys.modules[mod_name]; 211 # Since modules use different attribute names to store version info,; 212 # try the most common ones. KeyError: 'umap'; ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:4718,Testability,log,logging,4718,"""""""; 341 if isinstance(moduleOrReq, Requirement):; --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]; 343 try:; 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements); 884 included, even if they were already activated in this working set.; 885 """"""; --> 886 needed = self.resolve(parse_requirements(requirements)); 887 ; 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras); 770 if dist is None:; 771 requirers = required_by.get(req, None); --> 772 raise DistributionNotFound(req, requirers); 773 to_activate.append(dist); 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application; ```. #### Versions; latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>; ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file); 167 try:; 168 buf = sys.stdout = io.StringIO(); --> 169 sinfo(; 170 dependencies=True,; 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 208 for mod_name in clean_modules:; 209 mod_names.append(mod_name); --> 210 mod = sys.modules[mod_name]; 211 # Since modules use different attribute names to store version info,; 212 # try the most common ones. KeyError: 'umap'; ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:2230,Usability,simpl,simplefilter,2230,"ctive/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 806 # we need self._distances also for method == 'gauss' if we didn't; 807 # use dense distances; --> 808 self._distances, self._connectivities = _compute_connectivities_umap(; 809 knn_indices,; 810 knn_distances,. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 385 # umap 0.5.0; 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""); --> 387 from umap.umap_ import fuzzy_simplicial_set; 388 ; 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/__init__.py in <module>; 1 from warnings import warn, catch_warnings, simplefilter; ----> 2 from .umap_ import UMAP; 3 ; 4 try:; 5 with catch_warnings():. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/umap/umap_.py in <module>; 45 ); 46 ; ---> 47 from pynndescent import NNDescent; 48 from pynndescent.distances import named_distances as pynn_named_distances; 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/pynndescent/__init__.py in <module>; 13 numba.config.THREADING_LAYER = ""workqueue""; 14 ; ---> 15 __version__ = pkg_resources.get_distribution(""pynndescent"").version. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in get_distribution(dist); 464 dist = Requirement.parse(dist); 465 if isinstance(dist, Requirement):; --> 466 dist = get_provider(dist); 467 if not isinstance(dist, Distribution):; 468 raise TypeError(""Expected string, Requirement, or Distribution"", dist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/issues/2169:5376,Usability,learn,learn,5376,"""""""; 341 if isinstance(moduleOrReq, Requirement):; --> 342 return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]; 343 try:; 344 module = sys.modules[moduleOrReq]. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in require(self, *requirements); 884 included, even if they were already activated in this working set.; 885 """"""; --> 886 needed = self.resolve(parse_requirements(requirements)); 887 ; 888 for dist in needed:. /opt/conda/lib/python3.9/site-packages/pkg_resources/__init__.py in resolve(self, requirements, env, installer, replace_conflicting, extras); 770 if dist is None:; 771 requirers = required_by.get(req, None); --> 772 raise DistributionNotFound(req, requirers); 773 to_activate.append(dist); 774 if dist not in req:. DistributionNotFound: The 'pynndescent' distribution was not found and is required by the application; ```. #### Versions; latest version of scipy as well as pynndescent. strangely enough, if I try to print the versions I get this error as well:; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/955352.tmpdir/ipykernel_5496/3375110566.py in <module>; ----> 1 print(sc.logging.print_versions()). /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/scanpy/logging.py in print_versions(file); 167 try:; 168 buf = sys.stdout = io.StringIO(); --> 169 sinfo(; 170 dependencies=True,; 171 excludes=[. /storage1/fs1/leyao.wang/Active/conda/envs/velocyto3.9/lib/python3.9/site-packages/sinfo/main.py in sinfo(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 208 for mod_name in clean_modules:; 209 mod_names.append(mod_name); --> 210 mod = sys.modules[mod_name]; 211 # Since modules use different attribute names to store version info,; 212 # try the most common ones. KeyError: 'umap'; ```. I should note that I uninstalled and reinstalled the latest version of umap-learn.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2169
https://github.com/scverse/scanpy/pull/2170:302,Testability,test,test,302,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Here I changed the `test_read_visium_counts()` function to actually test `read_visium()` function instead of `read_10x_h5()`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170
https://github.com/scverse/scanpy/pull/2170:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Here I changed the `test_read_visium_counts()` function to actually test `read_visium()` function instead of `read_10x_h5()`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170
https://github.com/scverse/scanpy/pull/2170:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Here I changed the `test_read_visium_counts()` function to actually test `read_visium()` function instead of `read_10x_h5()`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2170
https://github.com/scverse/scanpy/issues/2171:643,Availability,error,error,643,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy.; How can I export umap location csv fileBarcodesX,Yfrom AnnData object after sc.tl.umap; thanks; ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:749,Testability,log,logging,749,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy.; How can I export umap location csv fileBarcodesX,Yfrom AnnData object after sc.tl.umap; thanks; ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2171:358,Usability,guid,guide,358,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy.; How can I export umap location csv fileBarcodesX,Yfrom AnnData object after sc.tl.umap; thanks; ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2171
https://github.com/scverse/scanpy/issues/2172:376,Deployability,install,install,376,"- [x] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; ### Minimal code sample (that we can copy&paste without having any data). ```bash; conda create -n Scanpy python=3.7; conda activate Scanpy; conda install -c bioconda scanpy; conda install -c bioconda anndata2ri; ```; ```; import scanpy as sc; ```. ```pytb; Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>; import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>; from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>; from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>; from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>; from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct; ```; Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions; After fixing the issue.; <details>; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 9.0.1; PyQt5 NA; annd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:410,Deployability,install,install,410,"- [x] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; ### Minimal code sample (that we can copy&paste without having any data). ```bash; conda create -n Scanpy python=3.7; conda activate Scanpy; conda install -c bioconda scanpy; conda install -c bioconda anndata2ri; ```; ```; import scanpy as sc; ```. ```pytb; Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>; import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>; from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>; from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>; from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>; from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct; ```; Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions; After fixing the issue.; <details>; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 9.0.1; PyQt5 NA; annd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1743,Deployability,Install,Installing,1743,"iniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>; from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>; from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>; from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct; ```; Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions; After fixing the issue.; <details>; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 9.0.1; PyQt5 NA; anndata 0.7.8; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.10.0; fsspec 2022.01.0; get_version 3.5.4; h5py 2.10.0; igraph 0.9.9; ipykernel 6.4.1; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.3.2; legacy_api_wrap 0.0.0; leidenalg 0.8.9; llvmlite 0.37.0; markupsafe 1.1.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; numba 0.54.1; numexpr 2.8.1; numpy 1.20.3; packaging 21.3; pandas 1.3.4; parso 0.8.3; pexpect 4.8.0; picklesha",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1764,Deployability,install,install,1764,"iniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>; from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>; from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>; from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct; ```; Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions; After fixing the issue.; <details>; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 9.0.1; PyQt5 NA; anndata 0.7.8; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.10.0; fsspec 2022.01.0; get_version 3.5.4; h5py 2.10.0; igraph 0.9.9; ipykernel 6.4.1; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.3.2; legacy_api_wrap 0.0.0; leidenalg 0.8.9; llvmlite 0.37.0; markupsafe 1.1.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; numba 0.54.1; numexpr 2.8.1; numpy 1.20.3; packaging 21.3; pandas 1.3.4; parso 0.8.3; pexpect 4.8.0; picklesha",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:3667,Deployability,update,updated,3667," remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions; After fixing the issue.; <details>; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 9.0.1; PyQt5 NA; anndata 0.7.8; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.10.0; fsspec 2022.01.0; get_version 3.5.4; h5py 2.10.0; igraph 0.9.9; ipykernel 6.4.1; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.3.2; legacy_api_wrap 0.0.0; leidenalg 0.8.9; llvmlite 0.37.0; markupsafe 1.1.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; numba 0.54.1; numexpr 2.8.1; numpy 1.20.3; packaging 21.3; pandas 1.3.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.20; psutil 5.8.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.4; pytz 2021.3; scanpy 1.7.2; scipy 1.7.3; setuptools_scm NA; sinfo 0.3.1; sip NA; six 1.16.0; sklearn 1.0.2; sphinxcontrib NA; spyder 5.1.5; spyder_kernels 2.1.3; spydercustomize NA; storemagic NA; tables 3.6.1; texttable 1.6.4; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; wurlitzer 3.0.2; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 7.31.1; jupyter_client 6.1.12; jupyter_core 4.9.1; -----; Python 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]; Linux-5.4.0-104-generic-x86_64-with-debian-bullseye-sid; 16 logical CPU cores, x86_64; -----; Session information updated at 2022-03-09 15:40. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:2094,Performance,bottleneck,bottleneck,2094,"r/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>; from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>; from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct; ```; Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions; After fixing the issue.; <details>; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 9.0.1; PyQt5 NA; anndata 0.7.8; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.10.0; fsspec 2022.01.0; get_version 3.5.4; h5py 2.10.0; igraph 0.9.9; ipykernel 6.4.1; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.3.2; legacy_api_wrap 0.0.0; leidenalg 0.8.9; llvmlite 0.37.0; markupsafe 1.1.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; numba 0.54.1; numexpr 2.8.1; numpy 1.20.3; packaging 21.3; pandas 1.3.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.20; psutil 5.8.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.4; pytz 2021.3; scanpy 1.7.2; scipy 1.7.3; setuptools_sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1046,Testability,log,logging,1046," not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; ### Minimal code sample (that we can copy&paste without having any data). ```bash; conda create -n Scanpy python=3.7; conda activate Scanpy; conda install -c bioconda scanpy; conda install -c bioconda anndata2ri; ```; ```; import scanpy as sc; ```. ```pytb; Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>; import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>; from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>; from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>; from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>; from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct; ```; Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions; After fixing the issue.; <details>; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 9.0.1; PyQt5 NA; anndata 0.7.8; atomicwrites 1.4.0; autoreloa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:1057,Testability,log,logg,1057," not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; ### Minimal code sample (that we can copy&paste without having any data). ```bash; conda create -n Scanpy python=3.7; conda activate Scanpy; conda install -c bioconda scanpy; conda install -c bioconda anndata2ri; ```; ```; import scanpy as sc; ```. ```pytb; Traceback (most recent call last):. File ""/tmp/ipykernel_2478/912249142.py"", line 1, in <module>; import scanpy as sc. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/__init__.py"", line 15, in <module>; from . import tools as tl. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 17, in <module>; from ._sim import sim. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/tools/_sim.py"", line 23, in <module>; from .. import _utils, readwrite, logging as logg. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/readwrite.py"", line 10, in <module>; import tables. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/__init__.py"", line 62, in <module>; from .file import File, open_file, copy_file. File ""/home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/file.py"", line 33, in <module>; from . import hdf5extension. ImportError: /home/augustoer/miniconda3/envs/Scanpy/lib/python3.7/site-packages/tables/hdf5extension.cpython-37m-x86_64-linux-gnu.so: undefined symbol: H5Pset_fapl_direct; ```; Removing anndata2ri with `conda remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions; After fixing the issue.; <details>; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 9.0.1; PyQt5 NA; anndata 0.7.8; atomicwrites 1.4.0; autoreloa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2172:3613,Testability,log,logical,3613," remove anndata2ri` fixes the issue. Installing with `pip install anndata2ri` prevents the issue. #### Versions; After fixing the issue.; <details>; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 9.0.1; PyQt5 NA; anndata 0.7.8; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.10.0; fsspec 2022.01.0; get_version 3.5.4; h5py 2.10.0; igraph 0.9.9; ipykernel 6.4.1; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.3.2; legacy_api_wrap 0.0.0; leidenalg 0.8.9; llvmlite 0.37.0; markupsafe 1.1.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; numba 0.54.1; numexpr 2.8.1; numpy 1.20.3; packaging 21.3; pandas 1.3.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.20; psutil 5.8.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.4; pytz 2021.3; scanpy 1.7.2; scipy 1.7.3; setuptools_scm NA; sinfo 0.3.1; sip NA; six 1.16.0; sklearn 1.0.2; sphinxcontrib NA; spyder 5.1.5; spyder_kernels 2.1.3; spydercustomize NA; storemagic NA; tables 3.6.1; texttable 1.6.4; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; wurlitzer 3.0.2; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 7.31.1; jupyter_client 6.1.12; jupyter_core 4.9.1; -----; Python 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]; Linux-5.4.0-104-generic-x86_64-with-debian-bullseye-sid; 16 logical CPU cores, x86_64; -----; Session information updated at 2022-03-09 15:40. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2172
https://github.com/scverse/scanpy/issues/2173:1656,Performance,load,load,1656,"```python; import scanpy as sc; ```. ```pytb; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>; ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>; 13 Verbosity,; 14 ) # start with settings as several tools are using it; ---> 15 from . import tools as tl; 16 from . import preprocessing as pp; 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>; 40 # Import the user classes from the proper modules; 41 from .exceptions import *; ---> 42 from .file import File, open_file, copy_file; 43 from .node import Node; 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>; 21 import numpy as np; 22 ; ---> 23 from . import hdf5extension; 24 from . import utilsextension; 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:917,Testability,log,logging,917,"```python; import scanpy as sc; ```. ```pytb; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>; ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>; 13 Verbosity,; 14 ) # start with settings as several tools are using it; ---> 15 from . import tools as tl; 16 from . import preprocessing as pp; 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>; 40 # Import the user classes from the proper modules; 41 from .exceptions import *; ---> 42 from .file import File, open_file, copy_file; 43 from .node import Node; 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>; 21 import numpy as np; 22 ; ---> 23 from . import hdf5extension; 24 from . import utilsextension; 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/issues/2173:928,Testability,log,logg,928,"```python; import scanpy as sc; ```. ```pytb; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_22924/912249142.py in <module>; ----> 1 import scanpy as sc. ~\Anaconda3\lib\site-packages\scanpy\__init__.py in <module>; 13 Verbosity,; 14 ) # start with settings as several tools are using it; ---> 15 from . import tools as tl; 16 from . import preprocessing as pp; 17 from . import plotting as pl. ~\Anaconda3\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\Anaconda3\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\Anaconda3\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ~\Anaconda3\lib\site-packages\tables\__init__.py in <module>; 40 # Import the user classes from the proper modules; 41 from .exceptions import *; ---> 42 from .file import File, open_file, copy_file; 43 from .node import Node; 44 from .group import Group. ~\Anaconda3\lib\site-packages\tables\file.py in <module>; 21 import numpy as np; 22 ; ---> 23 from . import hdf5extension; 24 from . import utilsextension; 25 from . import parameters. ImportError: DLL load failed: The specified procedure could not be found.; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2173
https://github.com/scverse/scanpy/pull/2176:190,Integrability,wrap,wraps,190,"Hi @giovp @ivirshup, (also CCing @dkobak). as we discussed at #1715 and in https://github.com/theislab/scanpy-tutorials/pull/43, I prepared a function `pearson_residuals_hvg_scatter()` that wraps `sc.pl.scatter()` to reproduce the ""gene selection plot"" from the tutorial. It can be used as a sanity check for both the HVG selection and the appropriateness of the used Pearson residual null model (as explained also in the tutorial notebook). I also added a feature to show known marker genes on the plot, change plot aesthetics and which fields are used for plotting. Looking forward to your thoughts on this one :); Best,; Jan. PS: I prepared this PR on an independent branch from #1715 - hope that is the correct way in this situation!; ```; import scanpy as sc; sc.settings.set_figure_params(dpi=80, facecolor=""white""). #run pearson residuals gene selection; adata=sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_cells=1); sc.experimental.pp.highly_variable_genes(adata, flavor=""pearson_residuals"", n_top_genes=2000). #basic plot; sc.experimental.pl.pearson_residuals_hvg_scatter(adata); ```; ![image](https://user-images.githubusercontent.com/34481813/158408471-5d661d60-11f3-482d-981b-da3a507b64b4.png). ```; #modify some aesthetics; sc.experimental.pl.pearson_residuals_hvg_scatter(adata,kwargs_sc_pl_scatter=dict(size=30)); ```. ![image](https://user-images.githubusercontent.com/34481813/158408564-9ca8b476-c0e6-4159-8c4e-cc4b542f43c4.png). ```; #highlight some marker genes; markers = [""IL7R"", ""LYZ"", ""CD14"", ""MS4A1"", ""CD8A"", ""GNLY""]; sc.experimental.pl.pearson_residuals_hvg_scatter(adata,marker_names=markers,kwargs_sc_pl_scatter=dict(size=30)); ```; ![image](https://user-images.githubusercontent.com/34481813/158408630-f973cb16-0165-42ee-95e6-55e9e6de676e.png). ```; #use custom fields in `adata` for x and y; #(there is also a similar option to use a different field for where HVG flag is stored); sc.experimental.pl.pearson_residuals_hvg_scatter(adata,x='means',y='variances',return",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2176
https://github.com/scverse/scanpy/pull/2176:292,Safety,sanity check,sanity check,292,"Hi @giovp @ivirshup, (also CCing @dkobak). as we discussed at #1715 and in https://github.com/theislab/scanpy-tutorials/pull/43, I prepared a function `pearson_residuals_hvg_scatter()` that wraps `sc.pl.scatter()` to reproduce the ""gene selection plot"" from the tutorial. It can be used as a sanity check for both the HVG selection and the appropriateness of the used Pearson residual null model (as explained also in the tutorial notebook). I also added a feature to show known marker genes on the plot, change plot aesthetics and which fields are used for plotting. Looking forward to your thoughts on this one :); Best,; Jan. PS: I prepared this PR on an independent branch from #1715 - hope that is the correct way in this situation!; ```; import scanpy as sc; sc.settings.set_figure_params(dpi=80, facecolor=""white""). #run pearson residuals gene selection; adata=sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_cells=1); sc.experimental.pp.highly_variable_genes(adata, flavor=""pearson_residuals"", n_top_genes=2000). #basic plot; sc.experimental.pl.pearson_residuals_hvg_scatter(adata); ```; ![image](https://user-images.githubusercontent.com/34481813/158408471-5d661d60-11f3-482d-981b-da3a507b64b4.png). ```; #modify some aesthetics; sc.experimental.pl.pearson_residuals_hvg_scatter(adata,kwargs_sc_pl_scatter=dict(size=30)); ```. ![image](https://user-images.githubusercontent.com/34481813/158408564-9ca8b476-c0e6-4159-8c4e-cc4b542f43c4.png). ```; #highlight some marker genes; markers = [""IL7R"", ""LYZ"", ""CD14"", ""MS4A1"", ""CD8A"", ""GNLY""]; sc.experimental.pl.pearson_residuals_hvg_scatter(adata,marker_names=markers,kwargs_sc_pl_scatter=dict(size=30)); ```; ![image](https://user-images.githubusercontent.com/34481813/158408630-f973cb16-0165-42ee-95e6-55e9e6de676e.png). ```; #use custom fields in `adata` for x and y; #(there is also a similar option to use a different field for where HVG flag is stored); sc.experimental.pl.pearson_residuals_hvg_scatter(adata,x='means',y='variances',return",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2176
https://github.com/scverse/scanpy/pull/2177:53,Availability,Ping,Ping,53,Updating scanpy discourse links to point at scverse. Ping @adamgayoso,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2177
https://github.com/scverse/scanpy/issues/2178:598,Availability,down,downloaded,598,"- [ x] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results.; ```python; import numpy as np; import pandas as pd; import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_header(); sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(; 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],; jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]; adata = adata[adat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:835,Availability,error,errors,835,"- [ x] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results.; ```python; import numpy as np; import pandas as pd; import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_header(); sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(; 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],; jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]; adata = adata[adat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:3202,Deployability,install,installed,3202,"ata[:, adata.var.highly_variable]. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:; ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:; ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:; ```sh; conda install -c bioconda scanpy; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 9.0.1; anndata 0.7.8; annoy NA; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; deepMNN NA; defusedxml 0.7.1; dunamai 1.10.0; entrypoints 0.4; executing 0.8.3; fbpca NA; get_version 3.5.4; h5py 3.6.0; hypergeom_ufunc NA; intervaltree NA; ipykernel 6.9.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.3.2; legacy_api_wrap 0.0.0; llvmlite 0.38.0; matplotlib 3.3.2; matplotlib_inline NA; metrics NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.0; numpy 1.21.5; packaging 21.3; pandas 1.4.1; parso 0.8.3; patsy 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.27; psutil 5.9.0; ptyprocess 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:3250,Deployability,install,install,3250,"ata[:, adata.var.highly_variable]. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:; ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:; ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:; ```sh; conda install -c bioconda scanpy; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 9.0.1; anndata 0.7.8; annoy NA; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; deepMNN NA; defusedxml 0.7.1; dunamai 1.10.0; entrypoints 0.4; executing 0.8.3; fbpca NA; get_version 3.5.4; h5py 3.6.0; hypergeom_ufunc NA; intervaltree NA; ipykernel 6.9.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.3.2; legacy_api_wrap 0.0.0; llvmlite 0.38.0; matplotlib 3.3.2; matplotlib_inline NA; metrics NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.0; numpy 1.21.5; packaging 21.3; pandas 1.4.1; parso 0.8.3; patsy 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.27; psutil 5.9.0; ptyprocess 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:5108,Deployability,update,updated,5108,"erefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:; ```sh; conda install -c bioconda scanpy; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 9.0.1; anndata 0.7.8; annoy NA; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; deepMNN NA; defusedxml 0.7.1; dunamai 1.10.0; entrypoints 0.4; executing 0.8.3; fbpca NA; get_version 3.5.4; h5py 3.6.0; hypergeom_ufunc NA; intervaltree NA; ipykernel 6.9.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.3.2; legacy_api_wrap 0.0.0; llvmlite 0.38.0; matplotlib 3.3.2; matplotlib_inline NA; metrics NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.0; numpy 1.21.5; packaging 21.3; pandas 1.4.1; parso 0.8.3; patsy 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.27; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2021.3; scanpy 1.7.2; scipy 1.8.0; seaborn 0.11.2; setuptools 60.9.3; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 0.23.2; sortedcontainers 2.4.0; sphinxcontrib NA; stack_data 0.2.0; statsmodels 0.13.2; tables 3.7.0; torch 1.11.0; tornado 6.1; tqdm 4.63.0; traitlets 5.1.1; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; zipp NA; zmq 22.3.0; -----; IPython 8.1.1; jupyter_client 7.1.2; jupyter_core 4.9.2; notebook 6.4.9; -----; Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]; Linux-5.4.0-104-generic-x86_64-with-glibc2.10; 24 logical CPU cores, x86_64; -----; Session information updated at 2022-03-15 16:53. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:1208,Modifiability,variab,variable,1208,"aster branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results.; ```python; import numpy as np; import pandas as pd; import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_header(); sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(; 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],; jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]; adata = adata[adata.obs.pct_counts_mt < 5, :]. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:1224,Modifiability,variab,variables-axis,1224,"aster branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results.; ```python; import numpy as np; import pandas as pd; import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_header(); sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(; 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],; jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]; adata = adata[adata.obs.pct_counts_mt < 5, :]. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:1247,Performance,cache,cache,1247,"aster branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results.; ```python; import numpy as np; import pandas as pd; import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_header(); sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(; 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],; jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]; adata = adata[adata.obs.pct_counts_mt < 5, :]. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:885,Testability,log,logging,885,"- [ x] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results.; ```python; import numpy as np; import pandas as pd; import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_header(); sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(; 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],; jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]; adata = adata[adat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:2473,Testability,log,log,2473,"r_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],; jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]; adata = adata[adata.obs.pct_counts_mt < 5, :]. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.highly_variable_genes(adata). adata.raw = adata. adata = adata[:, adata.var.highly_variable]. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']). sc.pp.scale(adata, max_value=10). sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='CST3'). sc.pl.pca_variance_ratio(adata, log=True). adata.write(results_file). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.tsne(adata). sc.pl.tsne(adata, color=['CST3', 'NKG7', 'PPBP']). ```. ![image](https://user-images.githubusercontent.com/5612966/158490622-dae4e20c-1e60-4f27-a844-9235fd77c0ea.png). I would expect a umap like the sample on the website:; ![image](https://user-images.githubusercontent.com/5612966/158491669-e4e256c9-edfd-4cd5-9390-3c09cac540bc.png). I was having this problem with my own SC data:; ![image](https://user-images.githubusercontent.com/5612966/158490800-bd710bb1-4fba-4e4f-be2d-d878ebb76d4a.png). Therefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:; ```sh; conda install -c bioconda scanpy; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 9.0.1; anndata 0.7.8; annoy NA;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:5054,Testability,log,logical,5054,"erefore I reproduced the problem using the tutorial. I installed scanpy yesterday using:; ```sh; conda install -c bioconda scanpy; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 9.0.1; anndata 0.7.8; annoy NA; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; deepMNN NA; defusedxml 0.7.1; dunamai 1.10.0; entrypoints 0.4; executing 0.8.3; fbpca NA; get_version 3.5.4; h5py 3.6.0; hypergeom_ufunc NA; intervaltree NA; ipykernel 6.9.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.3.2; legacy_api_wrap 0.0.0; llvmlite 0.38.0; matplotlib 3.3.2; matplotlib_inline NA; metrics NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.0; numpy 1.21.5; packaging 21.3; pandas 1.4.1; parso 0.8.3; patsy 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.27; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2021.3; scanpy 1.7.2; scipy 1.8.0; seaborn 0.11.2; setuptools 60.9.3; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 0.23.2; sortedcontainers 2.4.0; sphinxcontrib NA; stack_data 0.2.0; statsmodels 0.13.2; tables 3.7.0; torch 1.11.0; tornado 6.1; tqdm 4.63.0; traitlets 5.1.1; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; zipp NA; zmq 22.3.0; -----; IPython 8.1.1; jupyter_client 7.1.2; jupyter_core 4.9.2; notebook 6.4.9; -----; Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]; Linux-5.4.0-104-generic-x86_64-with-glibc2.10; 24 logical CPU cores, x86_64; -----; Session information updated at 2022-03-15 16:53. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/issues/2178:259,Usability,guid,guide,259,"- [ x] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This is exactly the code on https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html using the dataset downloaded per the instructions. The umap step does not produce the correct result. tsne however produces sensible results.; ```python; import numpy as np; import pandas as pd; import scanpy as sc. sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_header(); sc.settings.set_figure_params(dpi=80, facecolor='white'). results_file = 'write/pbmc3k.h5ad' # the file that will store the analysis results. adata = sc.read_10x_mtx(; 'data/filtered_gene_bc_matrices/hg19/', # the directory with the `.mtx` file; var_names='gene_symbols', # use gene symbols for the variable names (variables-axis index); cache=True) . adata.var_names_make_unique() # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`. sc.pl.highest_expr_genes(adata, n_top=20, ). sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3). adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],; jitter=0.4, multi_panel=True). sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'). adata = adata[adata.obs.n_genes_by_counts < 2500, :]; adata = adata[adat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2178
https://github.com/scverse/scanpy/pull/2179:814,Energy Efficiency,adapt,adapt,814,"Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:814,Modifiability,adapt,adapt,814,"Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:106,Usability,guid,guidelines,106,"Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:931,Usability,guid,guidelines,931,"Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/pull/2179:962,Usability,guid,guide,962,"Hello scanpy team,. this is my first pull request, I hope I at least vaguely adhered to your contribution guidelines. I did not find an issue tackling this exact situation, but if I overlooked it, feel free to point that out. This PR changes few lines of code involved in getting dimensionality reductions like X_pca. The current code skips subsetting the respective array to the n_pcs requested, if the representation name is not X_pca. I do not think this is optimal. This change allows to only take the dimensions needed also for non X_pca representations. This can be useful when using harmony for example or storing different PCA embeddings in the same object. Then it is not needed to first store them as X_pca to be able to properly use the n_pcs parameter in e.g. pp.neighbors. It might make sense then to adapt the documentation respectively as well. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. ----------. Fixes #1846",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2179
https://github.com/scverse/scanpy/issues/2180:372,Testability,log,log,372,"Dear scanpy Team,; I am a little bit confused regarding the counts, that are used for computing marker genes for clusters for example. In your publication :Current best practices in single-cell RNA-seq analysis: a tutorial, in Table 1 you recommend to use raw data for this instance but in the implementation of rank_gene_groups and in your notebooks for the publication, log normalized counts were used for this purpose if I'm not mistaken. Could you maybe clarify what the best practice would be? ; Thank you so much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2180
https://github.com/scverse/scanpy/issues/2181:966,Availability,down,downstream,966,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I noticed an issue when trying to run `tl.rank_genes_groups`, which was the result of `adata.uns['log1p']` being blank (i.e., an empty dictionary, `{}`). I have gone through my workflow and confirmed that `adata.uns['log1p']` is the expected `{'base': None}` after each preprocessing step, so I don't think the issue is with any of preprocessing code. However, when I save my adata object to a .h5ad file using the `.write()` function and then read my .h5ad file using the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice!. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:1747,Availability,error,error,1747,"the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice!. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python; adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_cells = 1). # scran normalization; adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6); sc.pp.log1p(adata_pp); sc.pp.pca(adata_pp, n_comps = 15); sc.pp.neighbors(adata_pp); sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5); input_groups = adata_pp.obs['groups']; data_mat = adata.X.T; ```; ```python; %%R -i data_mat -i input_groups -o size_factors; size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), ; clusters = input_groups, ; min.mean = 0.1)); ```; ```python; del adata_pp; adata.obs['size_factors'] = size_factors; adata.layers['counts']",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:3379,Availability,error,error,3379,"ut_groups = adata_pp.obs['groups']; data_mat = adata.X.T; ```; ```python; %%R -i data_mat -i input_groups -o size_factors; size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), ; clusters = input_groups, ; min.mean = 0.1)); ```; ```python; del adata_pp; adata.obs['size_factors'] = size_factors; adata.layers['counts'] = adata.X.copy(); adata.X /= adata.obs['size_factors'].values[:,None]; sc.pp.log1p(adata); adata.X = sp.sparse.csr_matrix(adata.X); adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000); sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'); sc.pp.neighbors(adata); sc.tl.umap(adata); adata.uns['log1p'] # this produces: {'base': None}; adata.write('test.h5ad'). adata = sc.read('test.h5ad'); adata.uns['log1p'] # the now produces: {}; sc.tl.leiden(adata, key_added='leiden_r1.0'); sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error; ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Input In [13], in <cell line: 2>(); 1 # Calculate marker genes; ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the ra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:6633,Deployability,update,updated,6633,"p_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. #### Versions. <details>. -----; anndata 0.8.0rc1; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 9.0.1; anndata2ri 1.0.6; annoy NA; asttokens NA; backcall 0.2.0; backports NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.11.0; entrypoints 0.4; executing 0.8.3; get_version 3.5.4; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.9; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; jupyter_server 1.13.5; kiwisolver 1.4.0; leidenalg 0.8.9; llvmlite 0.38.0; markupsafe 2.1.1; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.0; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.28; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2021.3; pytz_deprecation_shim NA; rpy2 3.4.2; scipy 1.8.0; scrublet NA; seaborn 0.11.2; sitecustomize NA; six 1.14.0; skimage 0.19.2; sklearn 1.0.2; stack_data 0.2.0; statsmodels 0.13.2; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.1; tqdm 4.63.0; traitlets 5.1.1; typing_extensions NA; tzlocal NA; umap 0.5.2; wcwidth 0.2.5; zmq 22.3.0; -----; IPython 8.1.1; jupyter_client 7.1.2; jupyter_core 4.9.2; jupyterlab 3.3.1; notebook 6.4.8; -----; Python 3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]; Linux-5.10.76-linuxkit-x86_64-with-glibc2.29; 8 logical CPU cores, x86_64; -----; Session information updated at 2022-03-17 17:22. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:2690,Modifiability,layers,layers,2690,"y on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python; adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_cells = 1). # scran normalization; adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6); sc.pp.log1p(adata_pp); sc.pp.pca(adata_pp, n_comps = 15); sc.pp.neighbors(adata_pp); sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5); input_groups = adata_pp.obs['groups']; data_mat = adata.X.T; ```; ```python; %%R -i data_mat -i input_groups -o size_factors; size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), ; clusters = input_groups, ; min.mean = 0.1)); ```; ```python; del adata_pp; adata.obs['size_factors'] = size_factors; adata.layers['counts'] = adata.X.copy(); adata.X /= adata.obs['size_factors'].values[:,None]; sc.pp.log1p(adata); adata.X = sp.sparse.csr_matrix(adata.X); adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000); sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'); sc.pp.neighbors(adata); sc.tl.umap(adata); adata.uns['log1p'] # this produces: {'base': None}; adata.write('test.h5ad'). adata = sc.read('test.h5ad'); adata.uns['log1p'] # the now produces: {}; sc.tl.leiden(adata, key_added='leiden_r1.0'); sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error; ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Input In [13], in <cell line: 2>(); 1 # Calculate marker genes; ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:1801,Testability,test,test,1801,"the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice!. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python; adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_cells = 1). # scran normalization; adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6); sc.pp.log1p(adata_pp); sc.pp.pca(adata_pp, n_comps = 15); sc.pp.neighbors(adata_pp); sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5); input_groups = adata_pp.obs['groups']; data_mat = adata.X.T; ```; ```python; %%R -i data_mat -i input_groups -o size_factors; size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), ; clusters = input_groups, ; min.mean = 0.1)); ```; ```python; del adata_pp; adata.obs['size_factors'] = size_factors; adata.layers['counts']",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:3129,Testability,test,test,3129,"y(); sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6); sc.pp.log1p(adata_pp); sc.pp.pca(adata_pp, n_comps = 15); sc.pp.neighbors(adata_pp); sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5); input_groups = adata_pp.obs['groups']; data_mat = adata.X.T; ```; ```python; %%R -i data_mat -i input_groups -o size_factors; size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), ; clusters = input_groups, ; min.mean = 0.1)); ```; ```python; del adata_pp; adata.obs['size_factors'] = size_factors; adata.layers['counts'] = adata.X.copy(); adata.X /= adata.obs['size_factors'].values[:,None]; sc.pp.log1p(adata); adata.X = sp.sparse.csr_matrix(adata.X); adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000); sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'); sc.pp.neighbors(adata); sc.tl.umap(adata); adata.uns['log1p'] # this produces: {'base': None}; adata.write('test.h5ad'). adata = sc.read('test.h5ad'); adata.uns['log1p'] # the now produces: {}; sc.tl.leiden(adata, key_added='leiden_r1.0'); sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error; ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Input In [13], in <cell line: 2>(); 1 # Calculate marker genes; ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:3159,Testability,test,test,3159,"adata_pp, counts_per_cell_after = 1e6); sc.pp.log1p(adata_pp); sc.pp.pca(adata_pp, n_comps = 15); sc.pp.neighbors(adata_pp); sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5); input_groups = adata_pp.obs['groups']; data_mat = adata.X.T; ```; ```python; %%R -i data_mat -i input_groups -o size_factors; size_factors = sizeFactors(computeSumFactors(SingleCellExperiment(list(counts = data_mat)), ; clusters = input_groups, ; min.mean = 0.1)); ```; ```python; del adata_pp; adata.obs['size_factors'] = size_factors; adata.layers['counts'] = adata.X.copy(); adata.X /= adata.obs['size_factors'].values[:,None]; sc.pp.log1p(adata); adata.X = sp.sparse.csr_matrix(adata.X); adata.raw = adata. sc.pp.highly_variable_genes(adata, flavor = 'cell_ranger', n_top_genes = 2000); sc.pp.pca(adata, n_comps = 50, use_highly_variable = True, svd_solver = 'arpack'); sc.pp.neighbors(adata); sc.tl.umap(adata); adata.uns['log1p'] # this produces: {'base': None}; adata.write('test.h5ad'). adata = sc.read('test.h5ad'); adata.uns['log1p'] # the now produces: {}; sc.tl.leiden(adata, key_added='leiden_r1.0'); sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error; ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Input In [13], in <cell line: 2>(); 1 # Calculate marker genes; ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, gro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4273,Testability,log,logreg,4273,"enes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error; ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Input In [13], in <cell line: 2>(); 1 # Calculate marker genes; ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. #### Versions. <details>. -----; anndata 0.8.0rc1; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 9.0.1; anndata2ri 1.0.6; annoy NA; asttokens NA; backcall 0.2.0; backports NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.11.0; entrypoints 0.4; executing 0.8.3; get_version 3.5.4; h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4287,Testability,log,logg,4287,"enes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon') # this causes an error; ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Input In [13], in <cell line: 2>(); 1 # Calculate marker genes; ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. #### Versions. <details>. -----; anndata 0.8.0rc1; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 9.0.1; anndata2ri 1.0.6; annoy NA; asttokens NA; backcall 0.2.0; backports NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.11.0; entrypoints 0.4; executing 0.8.3; get_version 3.5.4; h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4380,Testability,log,logarithmize,4380,"---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Input In [13], in <cell line: 2>(); 1 # Calculate marker genes; ----> 2 sc.tl.rank_genes_groups(adata, groupby='leiden_r1.0', key_added='rank_genes_all', method='wilcoxon', use_raw=False). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. #### Versions. <details>. -----; anndata 0.8.0rc1; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 9.0.1; anndata2ri 1.0.6; annoy NA; asttokens NA; backcall 0.2.0; backports NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.11.0; entrypoints 0.4; executing 0.8.3; get_version 3.5.4; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.9; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:4824,Testability,log,log,4824,", use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File /usr/local/lib/python3.8/dist-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. #### Versions. <details>. -----; anndata 0.8.0rc1; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 9.0.1; anndata2ri 1.0.6; annoy NA; asttokens NA; backcall 0.2.0; backports NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.11.0; entrypoints 0.4; executing 0.8.3; get_version 3.5.4; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.9; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; jupyter_server 1.13.5; kiwisolver 1.4.0; leidenalg 0.8.9; llvmlite 0.38.0; markupsafe 2.1.1; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.0; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.28; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:6579,Testability,log,logical,6579,"p_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. #### Versions. <details>. -----; anndata 0.8.0rc1; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 9.0.1; anndata2ri 1.0.6; annoy NA; asttokens NA; backcall 0.2.0; backports NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dunamai 1.11.0; entrypoints 0.4; executing 0.8.3; get_version 3.5.4; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.9; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; jupyter_server 1.13.5; kiwisolver 1.4.0; leidenalg 0.8.9; llvmlite 0.38.0; markupsafe 2.1.1; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.0; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.28; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2021.3; pytz_deprecation_shim NA; rpy2 3.4.2; scipy 1.8.0; scrublet NA; seaborn 0.11.2; sitecustomize NA; six 1.14.0; skimage 0.19.2; sklearn 1.0.2; stack_data 0.2.0; statsmodels 0.13.2; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.1; tqdm 4.63.0; traitlets 5.1.1; typing_extensions NA; tzlocal NA; umap 0.5.2; wcwidth 0.2.5; zmq 22.3.0; -----; IPython 8.1.1; jupyter_client 7.1.2; jupyter_core 4.9.2; jupyterlab 3.3.1; notebook 6.4.8; -----; Python 3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]; Linux-5.10.76-linuxkit-x86_64-with-glibc2.29; 8 logical CPU cores, x86_64; -----; Session information updated at 2022-03-17 17:22. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/issues/2181:1365,Usability,guid,guide,1365,"empty dictionary, `{}`). I have gone through my workflow and confirmed that `adata.uns['log1p']` is the expected `{'base': None}` after each preprocessing step, so I don't think the issue is with any of preprocessing code. However, when I save my adata object to a .h5ad file using the `.write()` function and then read my .h5ad file using the `sc.read()` function, when I check `adata.uns['log1p']` it is an empty dictionary - so maybe the issue is either in the writing or reading function? I am able to manually set `adata.uns['log1p']` to `{'base': None}` after reading the file, and can then run downstream functions like `tl.rank_genes_groups` without issue. I have not had this problem previously when reading .h5ad files (into either the same Jupyter notebook or into a new Jupyter notebook). Since I can manually set `adata.uns['log1p']` to `{'base': None}`, I don't think this issue is pressing. It's just a little strange to me. Thank you for any help/advice!. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This can all be run in one Jupyter notebook and should produce the issue (unless it's something exclusively on my end; I've been able to reproduce the error with my own data and one of the scanpy built-in test datasets). Sorry the code chunks are broken up/a little long; I am using the scran normalization approach outlined in the [single cell tutorial](https://github.com/theislab/single-cell-tutorial). ```python; adata = sc.datasets.pbmc3k(); sc.pp.filter_genes(adata, min_cells = 1). # scran normalization; adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after = 1e6); sc.pp.log1p(adata_pp); sc.pp.pca(adata_pp, n_comps = 15); sc.pp.neighbors(adata_pp); sc.tl.leiden(adata_pp, key_added = 'groups', resolution = 0.5); input_groups = adat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2181
https://github.com/scverse/scanpy/pull/2183:72,Modifiability,layers,layers,72,Quite a simple addition meant to fix a bug when one works with specific layers.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2183
https://github.com/scverse/scanpy/pull/2183:8,Usability,simpl,simple,8,Quite a simple addition meant to fix a bug when one works with specific layers.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2183
https://github.com/scverse/scanpy/pull/2184:9,Deployability,release,release,9,Updating release guide to contain current practices.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2184
https://github.com/scverse/scanpy/pull/2184:17,Usability,guid,guide,17,Updating release guide to contain current practices.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2184
https://github.com/scverse/scanpy/pull/2186:203,Deployability,integrat,integrates,203,"The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/pull/2186:203,Integrability,integrat,integrates,203,"The packages dorothea-py and progeny-py are now deprecated, instead one should use decoupler (https://github.com/saezlab/decoupler-py). It contains both prior knowledge resources plus many more since it integrates the meta-resource OmniPath, and it also contains many footprint enrichment methods instead of a fixed one.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2186
https://github.com/scverse/scanpy/issues/2188:1111,Availability,down,downgrade,1111,"[ Yes] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ncont = ncont[ncont.obs.pct_counts_mt < 5, :]; ncont.raw = ncont; ```. ```pytb; [TypeError: cannot unpack non-iterable NoneType object]; ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; kiwisolver 1.3.1; leidenalg 0.8.9; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbclassic NA; nbform",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1090,Deployability,install,installs,1090,"[ Yes] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ncont = ncont[ncont.obs.pct_counts_mt < 5, :]; ncont.raw = ncont; ```. ```pytb; [TypeError: cannot unpack non-iterable NoneType object]; ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; kiwisolver 1.3.1; leidenalg 0.8.9; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbclassic NA; nbform",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1227,Deployability,install,install,1227,"of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ncont = ncont[ncont.obs.pct_counts_mt < 5, :]; ncont.raw = ncont; ```. ```pytb; [TypeError: cannot unpack non-iterable NoneType object]; ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; kiwisolver 1.3.1; leidenalg 0.8.9; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbclassic NA; nbformat 5.1.3; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.5; packaging 21.3; pandas 1.3.2; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:3035,Deployability,update,updated,3035,"d breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; kiwisolver 1.3.1; leidenalg 0.8.9; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbclassic NA; nbformat 5.1.3; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.5; packaging 21.3; pandas 1.3.2; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.19; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pyexpat NA; pygments 2.10.0; pynndescent 0.5.6; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.26.0; scipy 1.7.1; seaborn 0.11.2; send2trash NA; six 1.16.0; sklearn 0.24.2; sniffio 1.2.0; statsmodels 0.13.2; storemagic NA; tables 3.7.0; terminado 0.11.1; texttable 1.6.4; tornado 6.1; tqdm 4.63.0; traitlets 5.0.5; umap 0.5.2; urllib3 1.26.6; wcwidth 0.2.5; websocket 1.2.1; zmq 22.2.1; -----; IPython 7.26.0; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.1.7; notebook 6.4.3; -----; Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]; Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17; 36 logical CPU cores, x86_64; -----; Session information updated at 2022-03-21 23:04]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1172,Integrability,message,message,1172,"(optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ncont = ncont[ncont.obs.pct_counts_mt < 5, :]; ncont.raw = ncont; ```. ```pytb; [TypeError: cannot unpack non-iterable NoneType object]; ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; kiwisolver 1.3.1; leidenalg 0.8.9; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbclassic NA; nbformat 5.1.3; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.5; packaging ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:1071,Safety,avoid,avoid,1071,"[ Yes] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ncont = ncont[ncont.obs.pct_counts_mt < 5, :]; ncont.raw = ncont; ```. ```pytb; [TypeError: cannot unpack non-iterable NoneType object]; ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; kiwisolver 1.3.1; leidenalg 0.8.9; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbclassic NA; nbform",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:2981,Testability,log,logical,2981,"d breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; kiwisolver 1.3.1; leidenalg 0.8.9; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbclassic NA; nbformat 5.1.3; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.5; packaging 21.3; pandas 1.3.2; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.19; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pyexpat NA; pygments 2.10.0; pynndescent 0.5.6; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.26.0; scipy 1.7.1; seaborn 0.11.2; send2trash NA; six 1.16.0; sklearn 0.24.2; sniffio 1.2.0; statsmodels 0.13.2; storemagic NA; tables 3.7.0; terminado 0.11.1; texttable 1.6.4; tornado 6.1; tqdm 4.63.0; traitlets 5.0.5; umap 0.5.2; urllib3 1.26.6; wcwidth 0.2.5; websocket 1.2.1; zmq 22.2.1; -----; IPython 7.26.0; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.1.7; notebook 6.4.3; -----; Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]; Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17; 36 logical CPU cores, x86_64; -----; Session information updated at 2022-03-21 23:04]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:263,Usability,guid,guide,263,"- [ Yes] I have checked that this issue has not already been reported.; - [ Yes] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ncont = ncont[ncont.obs.pct_counts_mt < 5, :]; ncont.raw = ncont; ```. ```pytb; [TypeError: cannot unpack non-iterable NoneType object]; ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; kiwisolver 1.3.1; leidenalg 0.8.9; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.4.3; m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2188:751,Usability,learn,learn,751,"- [ Yes] I have checked that this issue has not already been reported.; - [ Yes] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ncont = ncont[ncont.obs.pct_counts_mt < 5, :]; ncont.raw = ncont; ```. ```pytb; [TypeError: cannot unpack non-iterable NoneType object]; ```. #### Versions. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.1 pandas==1.3.2 scikit-learn==0.24.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. <details>. [WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; kiwisolver 1.3.1; leidenalg 0.8.9; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.4.3; m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2188
https://github.com/scverse/scanpy/issues/2189:185,Availability,error,errors,185,"Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html; ```python; adata.var['mt'] = adata.var_names.str.startswith('MT-'); sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); ```. ```pytb; TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/issues/2189:928,Testability,log,logging,928,"Hi, there. I am following the tutorial [here](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html), it works perfectly with Jupyter Notebook, but I do encounter the following errors when running the code in command line or PyCharm. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). from https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html; ```python; adata.var['mt'] = adata.var_names.str.startswith('MT-'); sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); ```. ```pytb; TypeError: calculate_qc_metrics() got an unexpected keyword argument 'log1p'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2189
https://github.com/scverse/scanpy/pull/2190:231,Security,hash,hashsolo,231,"It seems like the last PR #1483 1504a36 by @njbernstein broke the way the `number_of_noise_barcodes` worked. Like in the[ original solo repository ](https://github.com/calico/solo/blob/cd0ec6bd189fafa842af934e3d302715135bc8fc/solo/hashsolo.py#L83-L89) the `number_of_**non**_noise_barcodes` should be `2` as a default OR the `number_of_barcodes` - `number_of_noise_barcodes`. . However, changing the default `number_of_noise_barcodes` from `None` to `2` and changing:; ```python; number_of_non_noise_barcodes = (; num_of_barcodes - number_of_noise_barcodes; if number_of_noise_barcodes is not None; else 2; ); ```. to ; ```python; number_of_non_noise_barcodes = num_of_barcodes - number_of_noise_barcodes; ```. led to the situation, that the used `number_of_non_noise_barcodes` was `number_of_barcodes` - `2` as a default instead of `2`. This leads to problems with demultiplexing, especially with multiple barcodes. Hence, I changed this back. I also modified the check for a valid input to cope for the `None` default. ``` python; if number_of_noise_barcodes >= len(cell_hashing_columns):; ```; changed to; ```python; if (number_of_noise_barcodes is not None) and (; number_of_noise_barcodes >= len(cell_hashing_columns); ):; ```. The rest of changes was introduced by `black` formatting.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2190
https://github.com/scverse/scanpy/issues/2191:311,Availability,Down,Downgrading,311,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb; ---------------------------------------------------------------------------; RecursionError Traceback (most recent call last); Input In [6], in <cell line: 1>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 130 ing.map_embedding(method); 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state); 469 if self._use_pynndescent:; 470 self._nnd_idx.search_rng_state = rng_state; --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon); 474 else:; 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon); 1564 """"""Query the training graph_data for the k nearest neighbors; 1565 ; 1566 Parameters; (...); 1592 training graph_data.; 1593 """"""; 1594 if not hasattr(self, ""_search_graph""):; -> 1595 self._init_search_graph(); 1597 if n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3696,Availability,error,errors,3696,"ent/pynndescent_.py:968, in <listcomp>(.0); 961 self._search_forest = [; 962 convert_tree_format(tree, self._raw_data.shape[0]); 963 for tree in rp_forest; 964 ]; 965 else:; 966 # convert the best trees into a search forest; 967 tree_scores = [; --> 968 score_linked_tree(tree, self._neighbor_graph[0]); 969 for tree in self._rp_forest; 970 ]; 971 if self.verbose:; 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws); 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 486 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 487 raise e; 488 finally:; 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws); 418 return_val = None; 419 try:; --> 420 return_val = self.compile(tuple(argtypes)); 421 except errors.ForceLiteralArg as e:; 422 # Received request for compiler re-entry with the list of arguments; 423 # indicated by e.requested_args.; 424 # First, check if any of these args are already Literal-ized; 425 already_lit_pos = [i for i in e.requested_args; 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type); 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4261,Availability,error,errors,4261,"elf, *args, **kws); 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 486 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 487 raise e; 488 finally:; 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws); 418 return_val = None; 419 try:; --> 420 return_val = self.compile(tuple(argtypes)); 421 except errors.ForceLiteralArg as e:; 422 # Received request for compiler re-entry with the list of arguments; 423 # indicated by e.requested_args.; 424 # First, check if any of these args are already Literal-ized; 425 already_lit_pos = [i for i in e.requested_args; 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type); 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type); 136 pass; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); 149 flags = self._customize_flags(flags); 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4842,Availability,error,errors,4842,"uested_args.; 424 # First, check if any of these args are already Literal-ized; 425 already_lit_pos = [i for i in e.requested_args; 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type); 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type); 136 pass; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); 149 flags = self._customize_flags(flags); 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,; 155 args=args, return_type=return_type,; 156 flags=flags, locals=self.locals,; 157 pipeline_class=self.pipeline_class); 158 # Check typing error if object mode is used; 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, target",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5398,Availability,error,error,5398,"125, in _FunctionCompiler.compile(self, args, return_type); 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type); 136 pass; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); 149 flags = self._customize_flags(flags); 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,; 155 args=args, return_type=return_type,; 156 flags=flags, locals=self.locals,; 157 pipeline_class=self.pipeline_class); 158 # Check typing error if object mode is used; 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6669,Availability,avail,available,6669,"eturn_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self); 461 res = None; 462 try:; --> 463 pm.run(self.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state); 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._patch_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state); 339 pass_inst = _pass_registry.get(pss).pass_inst; 340 if isinstance(pass_inst, CompilerPass):; --> 341 self._runPass(idx, pass_inst, state); 342 else:; 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:402,Deployability,Integrat,Integrating,402,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb; ---------------------------------------------------------------------------; RecursionError Traceback (most recent call last); Input In [6], in <cell line: 1>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 130 ing.map_embedding(method); 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state); 469 if self._use_pynndescent:; 470 self._nnd_idx.search_rng_state = rng_state; --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon); 474 else:; 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon); 1564 """"""Query the training graph_data for the k nearest neighbors; 1565 ; 1566 Parameters; (...); 1592 training graph_data.; 1593 """"""; 1594 if not hasattr(self, ""_search_graph""):; -> 1595 self._init_search_graph(); 1597 if n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:493,Deployability,integrat,integrating-data-using-ingest,493,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb; ---------------------------------------------------------------------------; RecursionError Traceback (most recent call last); Input In [6], in <cell line: 1>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 130 ing.map_embedding(method); 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state); 469 if self._use_pynndescent:; 470 self._nnd_idx.search_rng_state = rng_state; --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon); 474 else:; 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon); 1564 """"""Query the training graph_data for the k nearest neighbors; 1565 ; 1566 Parameters; (...); 1592 training graph_data.; 1593 """"""; 1594 if not hasattr(self, ""_search_graph""):; -> 1595 self._init_search_graph(); 1597 if n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:528,Deployability,Integrat,Integrating-data-using-ingest-and-BBKNN,528,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb; ---------------------------------------------------------------------------; RecursionError Traceback (most recent call last); Input In [6], in <cell line: 1>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 130 ing.map_embedding(method); 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state); 469 if self._use_pynndescent:; 470 self._nnd_idx.search_rng_state = rng_state; --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon); 474 else:; 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon); 1564 """"""Query the training graph_data for the k nearest neighbors; 1565 ; 1566 Parameters; (...); 1592 training graph_data.; 1593 """"""; 1594 if not hasattr(self, ""_search_graph""):; -> 1595 self._init_search_graph(); 1597 if n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5757,Deployability,pipeline,pipeline,5757,"rn_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); 149 flags = self._customize_flags(flags); 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,; 155 args=args, return_type=return_type,; 156 flags=flags, locals=self.locals,; 157 pipeline_class=self.pipeline_class); 158 # Check typing error if object mode is used; 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5780,Deployability,pipeline,pipeline,5780,"rn_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); 149 flags = self._customize_flags(flags); 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,; 155 args=args, return_type=return_type,; 156 flags=flags, locals=self.locals,; 157 pipeline_class=self.pipeline_class); 158 # Check typing error if object mode is used; 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5892,Deployability,pipeline,pipeline,5892,"rn_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); 149 flags = self._customize_flags(flags); 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,; 155 args=args, return_type=return_type,; 156 flags=flags, locals=self.locals,; 157 pipeline_class=self.pipeline_class); 158 # Check typing error if object mode is used; 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6310,Deployability,pipeline,pipeline,6310,"=flags, locals=self.locals,; 157 pipeline_class=self.pipeline_class); 158 # Check typing error if object mode is used; 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self); 461 res = None; 462 try:; --> 463 pm.run(self.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state); 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._patch_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6679,Deployability,pipeline,pipelines,6679,"eturn_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self); 461 res = None; 462 try:; --> 463 pm.run(self.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state); 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._patch_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state); 339 pass_inst = _pass_registry.get(pss).pass_inst; 340 if isinstance(pass_inst, CompilerPass):; --> 341 self._runPass(idx, pass_inst, state); 342 else:; 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7081,Deployability,pipeline,pipeline,7081,"); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self); 461 res = None; 462 try:; --> 463 pm.run(self.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state); 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._patch_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state); 339 pass_inst = _pass_registry.get(pss).pass_inst; 340 if isinstance(pass_inst, CompilerPass):; --> 341 self._runPass(idx, pass_inst, state); 342 else:; 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs); 32 @functools.wraps(func); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self:; ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state); 294 mutated |= check(pss.run_initialization, internal_state); 295 with Sim",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:11846,Deployability,pipeline,pipeline,11846,"10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly); 3624 def lookup(var, varonly=True):; -> 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors); maximum recursion depth exceeded while calling a Python object. ```. #### Versions; <details>. -----; anndata 0.8.0; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.0.1; anndata 0.8.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 0.8.3; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.9; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.0; leidenalg 0.8.9; llvmlite 0.38.0; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.0; numpy 1.21.5; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.27; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pyde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:13585,Deployability,update,updated,13585,"t_reduce_nodes.<locals>.lookup(var, varonly); 3624 def lookup(var, varonly=True):; -> 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors); maximum recursion depth exceeded while calling a Python object. ```. #### Versions; <details>. -----; anndata 0.8.0; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.0.1; anndata 0.8.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 0.8.3; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.9; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.0; leidenalg 0.8.9; llvmlite 0.38.0; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.0; numpy 1.21.5; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.27; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2022.1; scanpy 1.8.2; scipy 1.8.0; seaborn 0.11.2; setuptools 60.10.0; sinfo 0.3.1; six 1.16.0; sklearn 1.0.2; sphinxcontrib NA; stack_data 0.2.0; statsmodels 0.13.2; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.1; tqdm 4.63.1; traitlets 5.1.1; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; zmq 22.3.0; -----; IPython 8.1.1; jupyter_client 7.1.2; jupyter_core 4.9.2; notebook 6.4.10; -----; Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57) [GCC 10.3.0]; Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31; 8 logical CPU cores, x86_64; -----; Session information updated at 2022-03-24 22:07. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:402,Integrability,Integrat,Integrating,402,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb; ---------------------------------------------------------------------------; RecursionError Traceback (most recent call last); Input In [6], in <cell line: 1>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 130 ing.map_embedding(method); 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state); 469 if self._use_pynndescent:; 470 self._nnd_idx.search_rng_state = rng_state; --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon); 474 else:; 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon); 1564 """"""Query the training graph_data for the k nearest neighbors; 1565 ; 1566 Parameters; (...); 1592 training graph_data.; 1593 """"""; 1594 if not hasattr(self, ""_search_graph""):; -> 1595 self._init_search_graph(); 1597 if n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:493,Integrability,integrat,integrating-data-using-ingest,493,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb; ---------------------------------------------------------------------------; RecursionError Traceback (most recent call last); Input In [6], in <cell line: 1>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 130 ing.map_embedding(method); 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state); 469 if self._use_pynndescent:; 470 self._nnd_idx.search_rng_state = rng_state; --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon); 474 else:; 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon); 1564 """"""Query the training graph_data for the k nearest neighbors; 1565 ; 1566 Parameters; (...); 1592 training graph_data.; 1593 """"""; 1594 if not hasattr(self, ""_search_graph""):; -> 1595 self._init_search_graph(); 1597 if n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:528,Integrability,Integrat,Integrating-data-using-ingest-and-BBKNN,528,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb; ---------------------------------------------------------------------------; RecursionError Traceback (most recent call last); Input In [6], in <cell line: 1>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 130 ing.map_embedding(method); 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state); 469 if self._use_pynndescent:; 470 self._nnd_idx.search_rng_state = rng_state; --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon); 474 else:; 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon); 1564 """"""Query the training graph_data for the k nearest neighbors; 1565 ; 1566 Parameters; (...); 1592 training graph_data.; 1593 """"""; 1594 if not hasattr(self, ""_search_graph""):; -> 1595 self._init_search_graph(); 1597 if n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7734,Integrability,wrap,wraps,7734,"CompilerBase._compile_core(self); 461 res = None; 462 try:; --> 463 pm.run(self.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state); 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._patch_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state); 339 pass_inst = _pass_registry.get(pss).pass_inst; 340 if isinstance(pass_inst, CompilerPass):; --> 341 self._runPass(idx, pass_inst, state); 342 else:; 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs); 32 @functools.wraps(func); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self:; ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state); 294 mutated |= check(pss.run_initialization, internal_state); 295 with SimpleTimer() as pass_time:; --> 296 mutated |= check(pss.run_pass, internal_state); 297 with SimpleTimer() as finalize_time:; 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state); 268 def check(func, compiler_state):; --> 269 mangled = func(compiler_state); 270 if mangled not in (True, False):; 271 msg = (""CompilerPass implementations should return True/False. ""; 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state); 295 assert state.fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3359,Modifiability,config,config,3359,"he best trees into a search forest; --> 967 tree_scores = [; 968 score_linked_tree(tree, self._neighbor_graph[0]); 969 for tree in self._rp_forest; 970 ]; 971 if self.verbose:; 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0); 961 self._search_forest = [; 962 convert_tree_format(tree, self._raw_data.shape[0]); 963 for tree in rp_forest; 964 ]; 965 else:; 966 # convert the best trees into a search forest; 967 tree_scores = [; --> 968 score_linked_tree(tree, self._neighbor_graph[0]); 969 for tree in self._rp_forest; 970 ]; 971 if self.verbose:; 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws); 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 486 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 487 raise e; 488 finally:; 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws); 418 return_val = None; 419 try:; --> 420 return_val = self.compile(tuple(argtypes)); 421 except errors.ForceLiteralArg as e:; 422 # Received request for compiler re-entry with the list of arguments; 423 # indicated by e.requested_args.; 424 # First, check if any of these args are already Literal-ized; 425 already_lit_pos = [i for i in e.requested_args; 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9848,Modifiability,variab,variables,9848,"Pass(state.func_ir,; 297 state.typemap,; 298 state.calltypes,; (...); 304 state.metadata,; 305 state.parfor_diagnostics); --> 306 parfor_pass.run(); 308 # check the parfor pass worked and warn if it didn't; 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self); 2924 # Validate reduction in parfors.; 2925 for p in parfors:; -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes); 2928 # Validate parameters:; 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param); 3547 if param_name in used_vars and param_name not in reduce_varnames:; 3548 param_nodes[param].reverse(); -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir); 3550 # Certain kinds of ill-formed Python (like potentially undefined; 3551 # variables) in combination with SSA can make things look like; 3552 # reductions except that they don't have reduction operators.; 3553 # If we get to this point but don't find a reduction operator; 3554 # then assume it is this situation and just don't treat this; 3555 # variable as a reduction.; 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir); 3635 defs[lhs.name] = rhs; 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:; -> 3637 rhs = lookup(rhs); 3638 if isinstance(rhs, ir.Expr):; 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:10120,Modifiability,variab,variable,10120,"File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self); 2924 # Validate reduction in parfors.; 2925 for p in parfors:; -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes); 2928 # Validate parameters:; 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param); 3547 if param_name in used_vars and param_name not in reduce_varnames:; 3548 param_nodes[param].reverse(); -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir); 3550 # Certain kinds of ill-formed Python (like potentially undefined; 3551 # variables) in combination with SSA can make things look like; 3552 # reductions except that they don't have reduction operators.; 3553 # If we get to this point but don't find a reduction operator; 3554 # then assume it is this situation and just don't treat this; 3555 # variable as a reduction.; 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir); 3635 defs[lhs.name] = rhs; 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:; -> 3637 rhs = lookup(rhs); 3638 if isinstance(rhs, ir.Expr):; 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9179,Security,Validat,Validate,9179,"inalize_time:; 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state); 268 def check(func, compiler_state):; --> 269 mangled = func(compiler_state); 270 if mangled not in (True, False):; 271 msg = (""CompilerPass implementations should return True/False. ""; 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state); 295 assert state.func_ir; 296 parfor_pass = _parfor_ParforPass(state.func_ir,; 297 state.typemap,; 298 state.calltypes,; (...); 304 state.metadata,; 305 state.parfor_diagnostics); --> 306 parfor_pass.run(); 308 # check the parfor pass worked and warn if it didn't; 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self); 2924 # Validate reduction in parfors.; 2925 for p in parfors:; -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes); 2928 # Validate parameters:; 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param); 3547 if param_name in used_vars and param_name not in reduce_varnames:; 3548 param_nodes[param].reverse(); -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir); 3550 # Certain kinds of ill-formed Python (like potentially undefined; 3551 # variables) in combination with SSA can make things look like; 3552 # reductions except that they don't have reduction operators.; 3553 # If we get to this point but don't find a reduction operator; 3554 # then assume it is this situation and just don't treat this; 3555 # variable as a reduction.; 3556 if reduce_nodes is not None:. File",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9316,Security,Validat,Validate,9316,"iler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state); 268 def check(func, compiler_state):; --> 269 mangled = func(compiler_state); 270 if mangled not in (True, False):; 271 msg = (""CompilerPass implementations should return True/False. ""; 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state); 295 assert state.func_ir; 296 parfor_pass = _parfor_ParforPass(state.func_ir,; 297 state.typemap,; 298 state.calltypes,; (...); 304 state.metadata,; 305 state.parfor_diagnostics); --> 306 parfor_pass.run(); 308 # check the parfor pass worked and warn if it didn't; 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self); 2924 # Validate reduction in parfors.; 2925 for p in parfors:; -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes); 2928 # Validate parameters:; 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param); 3547 if param_name in used_vars and param_name not in reduce_varnames:; 3548 param_nodes[param].reverse(); -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir); 3550 # Certain kinds of ill-formed Python (like potentially undefined; 3551 # variables) in combination with SSA can make things look like; 3552 # reductions except that they don't have reduction operators.; 3553 # If we get to this point but don't find a reduction operator; 3554 # then assume it is this situation and just don't treat this; 3555 # variable as a reduction.; 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir); 3635 def",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:940,Testability,test,test,940,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. RecursionError when using sc.tl.ingest with Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb; ---------------------------------------------------------------------------; RecursionError Traceback (most recent call last); Input In [6], in <cell line: 1>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 130 ing.map_embedding(method); 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state); 469 if self._use_pynndescent:; 470 self._nnd_idx.search_rng_state = rng_state; --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon); 474 else:; 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon); 1564 """"""Query the training graph_data for the k nearest neighbors; 1565 ; 1566 Parameters; (...); 1592 training graph_data.; 1593 """"""; 1594 if not hasattr(self, ""_search_graph""):; -> 1595 self._init_search_graph(); 1597 if n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:1298,Testability,test,test,1298,"ith Python 3.10. Downgrading to Python 3.8 or 3.9 fixes the issue. . Recreate by just running scanpy's own [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html#Integrating-data-using-ingest-and-BBKNN) tutorial. ![image](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb; ---------------------------------------------------------------------------; RecursionError Traceback (most recent call last); Input In [6], in <cell line: 1>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 130 ing.map_embedding(method); 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state); 469 if self._use_pynndescent:; 470 self._nnd_idx.search_rng_state = rng_state; --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon); 474 else:; 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon); 1564 """"""Query the training graph_data for the k nearest neighbors; 1565 ; 1566 Parameters; (...); 1592 training graph_data.; 1593 """"""; 1594 if not hasattr(self, ""_search_graph""):; -> 1595 self._init_search_graph(); 1597 if not self._is_sparse:; 1598 # Standard case; 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self); 961 self._search_forest = [; 962 convert_tree_format(tree, self._raw_data.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:1566,Testability,test,test,1566,"e](https://user-images.githubusercontent.com/4848896/160018184-7609a89a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb; ---------------------------------------------------------------------------; RecursionError Traceback (most recent call last); Input In [6], in <cell line: 1>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 130 ing.map_embedding(method); 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state); 469 if self._use_pynndescent:; 470 self._nnd_idx.search_rng_state = rng_state; --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon); 474 else:; 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon); 1564 """"""Query the training graph_data for the k nearest neighbors; 1565 ; 1566 Parameters; (...); 1592 training graph_data.; 1593 """"""; 1594 if not hasattr(self, ""_search_graph""):; -> 1595 self._init_search_graph(); 1597 if not self._is_sparse:; 1598 # Standard case; 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self); 961 self._search_forest = [; 962 convert_tree_format(tree, self._raw_data.shape[0]); 963 for tree in rp_forest; 964 ]; 965 else:; 966 # convert the best trees into a search forest; --> 967 tree_scores = [; 968 score_linked_tree(tree, self._neighbor_graph[0]); 969 for tree in self._rp_forest; 970 ]; 971 if self.verbose:; 972 print(ts(), ""Worst tree score: {:.8f}""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:1659,Testability,test,test,1659,"a-adc5-4094-9bc3-7f2d894355f4.png). ```pytb; ---------------------------------------------------------------------------; RecursionError Traceback (most recent call last); Input In [6], in <cell line: 1>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain'). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:133, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 130 ing.map_embedding(method); 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state); 469 if self._use_pynndescent:; 470 self._nnd_idx.search_rng_state = rng_state; --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon); 474 else:; 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon); 1564 """"""Query the training graph_data for the k nearest neighbors; 1565 ; 1566 Parameters; (...); 1592 training graph_data.; 1593 """"""; 1594 if not hasattr(self, ""_search_graph""):; -> 1595 self._init_search_graph(); 1597 if not self._is_sparse:; 1598 # Standard case; 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self); 961 self._search_forest = [; 962 convert_tree_format(tree, self._raw_data.shape[0]); 963 for tree in rp_forest; 964 ]; 965 else:; 966 # convert the best trees into a search forest; --> 967 tree_scores = [; 968 score_linked_tree(tree, self._neighbor_graph[0]); 969 for tree in self._rp_forest; 970 ]; 971 if self.verbose:; 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:2115,Testability,test,test,2115,"ng.map_embedding(method); 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). File ~/miniconda3/envs/test/lib/python3.10/site-packages/scanpy/tools/_ingest.py:472, in Ingest.neighbors(self, k, queue_size, epsilon, random_state); 469 if self._use_pynndescent:; 470 self._nnd_idx.search_rng_state = rng_state; --> 472 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon); 474 else:; 475 from umap.utils import deheap_sort. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon); 1564 """"""Query the training graph_data for the k nearest neighbors; 1565 ; 1566 Parameters; (...); 1592 training graph_data.; 1593 """"""; 1594 if not hasattr(self, ""_search_graph""):; -> 1595 self._init_search_graph(); 1597 if not self._is_sparse:; 1598 # Standard case; 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self); 961 self._search_forest = [; 962 convert_tree_format(tree, self._raw_data.shape[0]); 963 for tree in rp_forest; 964 ]; 965 else:; 966 # convert the best trees into a search forest; --> 967 tree_scores = [; 968 score_linked_tree(tree, self._neighbor_graph[0]); 969 for tree in self._rp_forest; 970 ]; 971 if self.verbose:; 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0); 961 self._search_forest = [; 962 convert_tree_format(tree, self._raw_data.shape[0]); 963 for tree in rp_forest; 964 ]; 965 else:; 966 # convert the best trees into a search forest; 967 tree_scores = [; --> 968 score_linked_tree(tree, self._neighbor_graph[0]); 969 for tree in self._rp_forest; 970 ]; 971 if self.verbose:; 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_sco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:2639,Testability,test,test,2639," File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:1595, in NNDescent.query(self, query_data, k, epsilon); 1564 """"""Query the training graph_data for the k nearest neighbors; 1565 ; 1566 Parameters; (...); 1592 training graph_data.; 1593 """"""; 1594 if not hasattr(self, ""_search_graph""):; -> 1595 self._init_search_graph(); 1597 if not self._is_sparse:; 1598 # Standard case; 1599 if not hasattr(self, ""_search_function""):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self); 961 self._search_forest = [; 962 convert_tree_format(tree, self._raw_data.shape[0]); 963 for tree in rp_forest; 964 ]; 965 else:; 966 # convert the best trees into a search forest; --> 967 tree_scores = [; 968 score_linked_tree(tree, self._neighbor_graph[0]); 969 for tree in self._rp_forest; 970 ]; 971 if self.verbose:; 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0); 961 self._search_forest = [; 962 convert_tree_format(tree, self._raw_data.shape[0]); 963 for tree in rp_forest; 964 ]; 965 else:; 966 # convert the best trees into a search forest; 967 tree_scores = [; --> 968 score_linked_tree(tree, self._neighbor_graph[0]); 969 for tree in self._rp_forest; 970 ]; 971 if self.verbose:; 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws); 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 486 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 487 raise e; 488 finally:; 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws); 418 return_val = None; 419 try:; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3143,Testability,test,test,3143,"-packages/pynndescent/pynndescent_.py:967, in NNDescent._init_search_graph(self); 961 self._search_forest = [; 962 convert_tree_format(tree, self._raw_data.shape[0]); 963 for tree in rp_forest; 964 ]; 965 else:; 966 # convert the best trees into a search forest; --> 967 tree_scores = [; 968 score_linked_tree(tree, self._neighbor_graph[0]); 969 for tree in self._rp_forest; 970 ]; 971 if self.verbose:; 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0); 961 self._search_forest = [; 962 convert_tree_format(tree, self._raw_data.shape[0]); 963 for tree in rp_forest; 964 ]; 965 else:; 966 # convert the best trees into a search forest; 967 tree_scores = [; --> 968 score_linked_tree(tree, self._neighbor_graph[0]); 969 for tree in self._rp_forest; 970 ]; 971 if self.verbose:; 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws); 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 486 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 487 raise e; 488 finally:; 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws); 418 return_val = None; 419 try:; --> 420 return_val = self.compile(tuple(argtypes)); 421 except errors.ForceLiteralArg as e:; 422 # Received request for compiler re-entry with the list of arguments; 423 # indicated by e.requested_args.; 424 # First, check if any of these args are already Literal-ized; 425 already_lit_pos = [i for i in e.requested_args; 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig); 963 with ev.trigger_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:3478,Testability,test,test,3478,"h[0]); 969 for tree in self._rp_forest; 970 ]; 971 if self.verbose:; 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/pynndescent/pynndescent_.py:968, in <listcomp>(.0); 961 self._search_forest = [; 962 convert_tree_format(tree, self._raw_data.shape[0]); 963 for tree in rp_forest; 964 ]; 965 else:; 966 # convert the best trees into a search forest; 967 tree_scores = [; --> 968 score_linked_tree(tree, self._neighbor_graph[0]); 969 for tree in self._rp_forest; 970 ]; 971 if self.verbose:; 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws); 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 486 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 487 raise e; 488 finally:; 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws); 418 return_val = None; 419 try:; --> 420 return_val = self.compile(tuple(argtypes)); 421 except errors.ForceLiteralArg as e:; 422 # Received request for compiler re-entry with the list of arguments; 423 # indicated by e.requested_args.; 424 # First, check if any of these args are already Literal-ized; 425 already_lit_pos = [i for i in e.requested_args; 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type); 124 def compil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4022,Testability,test,test,4022,"970 ]; 971 if self.verbose:; 972 print(ts(), ""Worst tree score: {:.8f}"".format(np.min(tree_scores))). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:487, in _DispatcherBase._compile_for_args(self, *args, **kws); 485 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 486 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 487 raise e; 488 finally:; 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws); 418 return_val = None; 419 try:; --> 420 return_val = self.compile(tuple(argtypes)); 421 except errors.ForceLiteralArg as e:; 422 # Received request for compiler re-entry with the list of arguments; 423 # indicated by e.requested_args.; 424 # First, check if any of these args are already Literal-ized; 425 already_lit_pos = [i for i in e.requested_args; 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type); 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type); 136 pass; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4342,Testability,test,test,4342," the FULL_TRACEBACKS config, this needs reporting!; --> 487 raise e; 488 finally:; 489 self._types_active_call = []. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:420, in _DispatcherBase._compile_for_args(self, *args, **kws); 418 return_val = None; 419 try:; --> 420 return_val = self.compile(tuple(argtypes)); 421 except errors.ForceLiteralArg as e:; 422 # Received request for compiler re-entry with the list of arguments; 423 # indicated by e.requested_args.; 424 # First, check if any of these args are already Literal-ized; 425 already_lit_pos = [i for i in e.requested_args; 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type); 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type); 136 pass; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); 149 flags = self._customize_flags(flags); 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,; 155 args=args, return_type=return_type,; 156 flags=flags, locals=self.locals,; 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4628,Testability,test,test,4628,"19 try:; --> 420 return_val = self.compile(tuple(argtypes)); 421 except errors.ForceLiteralArg as e:; 422 # Received request for compiler re-entry with the list of arguments; 423 # indicated by e.requested_args.; 424 # First, check if any of these args are already Literal-ized; 425 already_lit_pos = [i for i in e.requested_args; 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type); 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type); 136 pass; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); 149 flags = self._customize_flags(flags); 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,; 155 args=args, return_type=return_type,; 156 flags=flags, locals=self.locals,; 157 pipeline_class=self.pipeline_class); 158 # Check typing error if object mode is used; 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:4924,Testability,test,test,4924,"os = [i for i in e.requested_args; 426 if isinstance(args[i], types.Literal)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:965, in Dispatcher.compile(self, sig); 963 with ev.trigger_event(""numba:compile"", data=ev_details):; 964 try:; --> 965 cres = self._compiler.compile(args, return_type); 966 except errors.ForceLiteralArg as e:; 967 def folded(args, kws):. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:125, in _FunctionCompiler.compile(self, args, return_type); 124 def compile(self, args, return_type):; --> 125 status, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type); 136 pass; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); 149 flags = self._customize_flags(flags); 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,; 155 args=args, return_type=return_type,; 156 flags=flags, locals=self.locals,; 157 pipeline_class=self.pipeline_class); 158 # Check typing error if object mode is used; 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5520,Testability,test,test,5520,"us, retval = self._compile_cached(args, return_type); 126 if status:; 127 return retval. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:139, in _FunctionCompiler._compile_cached(self, args, return_type); 136 pass; 138 try:; --> 139 retval = self._compile_core(args, return_type); 140 except errors.TypingError as e:; 141 self._failed_cache[key] = e. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); 149 flags = self._customize_flags(flags); 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,; 155 args=args, return_type=return_type,; 156 flags=flags, locals=self.locals,; 157 pipeline_class=self.pipeline_class); 158 # Check typing error if object mode is used; 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in Compi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:5945,Testability,test,test,5945,"10/site-packages/numba/core/dispatcher.py:152, in _FunctionCompiler._compile_core(self, args, return_type); 149 flags = self._customize_flags(flags); 151 impl = self._get_implementation(args, {}); --> 152 cres = compiler.compile_extra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,; 155 args=args, return_type=return_type,; 156 flags=flags, locals=self.locals,; 157 pipeline_class=self.pipeline_class); 158 # Check typing error if object mode is used; 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self); 461 res = None; 462 try:; --> 463 pm.run(self.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6177,Testability,test,test,6177,"ra(self.targetdescr.typing_context,; 153 self.targetdescr.target_context,; 154 impl,; 155 args=args, return_type=return_type,; 156 flags=flags, locals=self.locals,; 157 pipeline_class=self.pipeline_class); 158 # Check typing error if object mode is used; 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self); 461 res = None; 462 try:; --> 463 pm.run(self.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state); 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6352,Testability,assert,assert,6352,"=flags, locals=self.locals,; 157 pipeline_class=self.pipeline_class); 158 # Check typing error if object mode is used; 159 if cres.typing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self); 461 res = None; 462 try:; --> 463 pm.run(self.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state); 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._patch_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6447,Testability,test,test,6447,"ing_error is not None and not flags.enable_pyobject:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:693, in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 669 """"""Compiler entry point; 670 ; 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self); 461 res = None; 462 try:; --> 463 pm.run(self.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state); 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._patch_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state); 339 pass_inst = _pass_registry.get(pss).pass_inst; 340 if isinstance(pass_inst, Compiler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6725,Testability,test,test,6725," 671 Parameter; (...); 689 compiler pipeline; 690 """"""; 691 pipeline = pipeline_class(typingctx, targetctx, library,; 692 args, return_type, flags, locals); --> 693 return pipeline.compile_extra(func). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self); 461 res = None; 462 try:; --> 463 pm.run(self.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state); 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._patch_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state); 339 pass_inst = _pass_registry.get(pss).pass_inst; 340 if isinstance(pass_inst, CompilerPass):; --> 341 self._runPass(idx, pass_inst, state); 342 else:; 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs); 32",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:6947,Testability,test,test,6947,"s/test/lib/python3.10/site-packages/numba/core/compiler.py:429, in CompilerBase.compile_extra(self, func); 427 self.state.lifted = (); 428 self.state.lifted_from = None; --> 429 return self._compile_bytecode(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:497, in CompilerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self); 461 res = None; 462 try:; --> 463 pm.run(self.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state); 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._patch_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state); 339 pass_inst = _pass_registry.get(pss).pass_inst; 340 if isinstance(pass_inst, CompilerPass):; --> 341 self._runPass(idx, pass_inst, state); 342 else:; 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs); 32 @functools.wraps(func); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self:; ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7251,Testability,test,test,7251,"lerBase._compile_bytecode(self); 493 """"""; 494 Populate and run pipeline for bytecode input; 495 """"""; 496 assert self.state.func_ir is None; --> 497 return self._compile_core(). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:476, in CompilerBase._compile_core(self); 474 self.state.status.fail_reason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self); 461 res = None; 462 try:; --> 463 pm.run(self.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state); 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._patch_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state); 339 pass_inst = _pass_registry.get(pss).pass_inst; 340 if isinstance(pass_inst, CompilerPass):; --> 341 self._runPass(idx, pass_inst, state); 342 else:; 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs); 32 @functools.wraps(func); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self:; ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state); 294 mutated |= check(pss.run_initialization, internal_state); 295 with SimpleTimer() as pass_time:; --> 296 mutated |= check(pss.run_pass, internal_state); 297 with SimpleTimer() as finalize_time:; 298 mutated |= check(pss.run_finalizer, internal",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7579,Testability,test,test,7579,"ason = e; 475 if is_final_pipeline:; --> 476 raise e; 477 else:; 478 raise CompilerError(""All available pipelines exhausted""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler.py:463, in CompilerBase._compile_core(self); 461 res = None; 462 try:; --> 463 pm.run(self.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state); 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._patch_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state); 339 pass_inst = _pass_registry.get(pss).pass_inst; 340 if isinstance(pass_inst, CompilerPass):; --> 341 self._runPass(idx, pass_inst, state); 342 else:; 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs); 32 @functools.wraps(func); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self:; ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state); 294 mutated |= check(pss.run_initialization, internal_state); 295 with SimpleTimer() as pass_time:; --> 296 mutated |= check(pss.run_pass, internal_state); 297 with SimpleTimer() as finalize_time:; 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state); 268 def check(func, compiler_state):; --> 269 mangled = func(compiler_state); 270 if mangled not in (True, False):; 271 msg = (""CompilerPass implementations shoul",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:7871,Testability,test,test,7871,"lf.state); 464 if self.state.cr is not None:; 465 break. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:353, in PassManager.run(self, state); 350 msg = ""Failed in %s mode pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._patch_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state); 339 pass_inst = _pass_registry.get(pss).pass_inst; 340 if isinstance(pass_inst, CompilerPass):; --> 341 self._runPass(idx, pass_inst, state); 342 else:; 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs); 32 @functools.wraps(func); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self:; ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state); 294 mutated |= check(pss.run_initialization, internal_state); 295 with SimpleTimer() as pass_time:; --> 296 mutated |= check(pss.run_pass, internal_state); 297 with SimpleTimer() as finalize_time:; 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state); 268 def check(func, compiler_state):; --> 269 mangled = func(compiler_state); 270 if mangled not in (True, False):; 271 msg = (""CompilerPass implementations should return True/False. ""; 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state); 295 assert state.func_ir; 296 parfor_pass = _parfor_ParforPass(state.func_ir,; 297 state.typemap,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8280,Testability,test,test,8280,"packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state); 339 pass_inst = _pass_registry.get(pss).pass_inst; 340 if isinstance(pass_inst, CompilerPass):; --> 341 self._runPass(idx, pass_inst, state); 342 else:; 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs); 32 @functools.wraps(func); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self:; ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state); 294 mutated |= check(pss.run_initialization, internal_state); 295 with SimpleTimer() as pass_time:; --> 296 mutated |= check(pss.run_pass, internal_state); 297 with SimpleTimer() as finalize_time:; 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state); 268 def check(func, compiler_state):; --> 269 mangled = func(compiler_state); 270 if mangled not in (True, False):; 271 msg = (""CompilerPass implementations should return True/False. ""; 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state); 295 assert state.func_ir; 296 parfor_pass = _parfor_ParforPass(state.func_ir,; 297 state.typemap,; 298 state.calltypes,; (...); 304 state.metadata,; 305 state.parfor_diagnostics); --> 306 parfor_pass.run(); 308 # check the parfor pass worked and warn if it didn't; 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self); 2924 # Validate reduction in parfors.; 2925 for p in parfors:; -> 2926 get_parfor_reductions(self.func_ir",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8668,Testability,test,test,8668,"call__.<locals>._acquire_compile_lock(*args, **kwargs); 32 @functools.wraps(func); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self:; ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state); 294 mutated |= check(pss.run_initialization, internal_state); 295 with SimpleTimer() as pass_time:; --> 296 mutated |= check(pss.run_pass, internal_state); 297 with SimpleTimer() as finalize_time:; 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state); 268 def check(func, compiler_state):; --> 269 mangled = func(compiler_state); 270 if mangled not in (True, False):; 271 msg = (""CompilerPass implementations should return True/False. ""; 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state); 295 assert state.func_ir; 296 parfor_pass = _parfor_ParforPass(state.func_ir,; 297 state.typemap,; 298 state.calltypes,; (...); 304 state.metadata,; 305 state.parfor_diagnostics); --> 306 parfor_pass.run(); 308 # check the parfor pass worked and warn if it didn't; 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self); 2924 # Validate reduction in parfors.; 2925 for p in parfors:; -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes); 2928 # Validate parameters:; 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param); 3547 if param_name in used_vars and param_name not in reduce_varnames:; 3548 pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8775,Testability,assert,assert,8775,"le_lock(*args, **kwargs):; 34 with self:; ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state); 294 mutated |= check(pss.run_initialization, internal_state); 295 with SimpleTimer() as pass_time:; --> 296 mutated |= check(pss.run_pass, internal_state); 297 with SimpleTimer() as finalize_time:; 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state); 268 def check(func, compiler_state):; --> 269 mangled = func(compiler_state); 270 if mangled not in (True, False):; 271 msg = (""CompilerPass implementations should return True/False. ""; 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state); 295 assert state.func_ir; 296 parfor_pass = _parfor_ParforPass(state.func_ir,; 297 state.typemap,; 298 state.calltypes,; (...); 304 state.metadata,; 305 state.parfor_diagnostics); --> 306 parfor_pass.run(); 308 # check the parfor pass worked and warn if it didn't; 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self); 2924 # Validate reduction in parfors.; 2925 for p in parfors:; -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes); 2928 # Validate parameters:; 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param); 3547 if param_name in used_vars and param_name not in reduce_varnames:; 3548 param_nodes[param].reverse(); -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9083,Testability,test,test,9083,"Timer() as pass_time:; --> 296 mutated |= check(pss.run_pass, internal_state); 297 with SimpleTimer() as finalize_time:; 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state); 268 def check(func, compiler_state):; --> 269 mangled = func(compiler_state); 270 if mangled not in (True, False):; 271 msg = (""CompilerPass implementations should return True/False. ""; 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state); 295 assert state.func_ir; 296 parfor_pass = _parfor_ParforPass(state.func_ir,; 297 state.typemap,; 298 state.calltypes,; (...); 304 state.metadata,; 305 state.parfor_diagnostics); --> 306 parfor_pass.run(); 308 # check the parfor pass worked and warn if it didn't; 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self); 2924 # Validate reduction in parfors.; 2925 for p in parfors:; -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes); 2928 # Validate parameters:; 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param); 3547 if param_name in used_vars and param_name not in reduce_varnames:; 3548 param_nodes[param].reverse(); -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir); 3550 # Certain kinds of ill-formed Python (like potentially undefined; 3551 # variables) in combination with SSA can make things look like; 3552 # reductions except that they don't have reduction operators.; 3553 # If we get to this point but don't find a reduction operator; 3554 # then assume it is this situ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:9385,Testability,test,test,9385,"ls>.check(func, compiler_state); 268 def check(func, compiler_state):; --> 269 mangled = func(compiler_state); 270 if mangled not in (True, False):; 271 msg = (""CompilerPass implementations should return True/False. ""; 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state); 295 assert state.func_ir; 296 parfor_pass = _parfor_ParforPass(state.func_ir,; 297 state.typemap,; 298 state.calltypes,; (...); 304 state.metadata,; 305 state.parfor_diagnostics); --> 306 parfor_pass.run(); 308 # check the parfor pass worked and warn if it didn't; 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self); 2924 # Validate reduction in parfors.; 2925 for p in parfors:; -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes); 2928 # Validate parameters:; 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param); 3547 if param_name in used_vars and param_name not in reduce_varnames:; 3548 param_nodes[param].reverse(); -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir); 3550 # Certain kinds of ill-formed Python (like potentially undefined; 3551 # variables) in combination with SSA can make things look like; 3552 # reductions except that they don't have reduction operators.; 3553 # If we get to this point but don't find a reduction operator; 3554 # then assume it is this situation and just don't treat this; 3555 # variable as a reduction.; 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir); 3635 defs[lhs.name] = rhs; 3636 if isinstance(rhs, ir.Var) an",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:10204,Testability,test,test,10204," parfors.; 2925 for p in parfors:; -> 2926 get_parfor_reductions(self.func_ir, p, p.params, self.calltypes); 2928 # Validate parameters:; 2929 for p in parfors:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3549, in get_parfor_reductions(func_ir, parfor, parfor_params, calltypes, reductions, reduce_varnames, param_uses, param_nodes, var_to_param); 3547 if param_name in used_vars and param_name not in reduce_varnames:; 3548 param_nodes[param].reverse(); -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir); 3550 # Certain kinds of ill-formed Python (like potentially undefined; 3551 # variables) in combination with SSA can make things look like; 3552 # reductions except that they don't have reduction operators.; 3553 # If we get to this point but don't find a reduction operator; 3554 # then assume it is this situation and just don't treat this; 3555 # variable as a reduction.; 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir); 3635 defs[lhs.name] = rhs; 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:; -> 3637 rhs = lookup(rhs); 3638 if isinstance(rhs, ir.Expr):; 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:10555,Testability,test,test,10555,"_uses, param_nodes, var_to_param); 3547 if param_name in used_vars and param_name not in reduce_varnames:; 3548 param_nodes[param].reverse(); -> 3549 reduce_nodes = get_reduce_nodes(param, param_nodes[param], func_ir); 3550 # Certain kinds of ill-formed Python (like potentially undefined; 3551 # variables) in combination with SSA can make things look like; 3552 # reductions except that they don't have reduction operators.; 3553 # If we get to this point but don't find a reduction operator; 3554 # then assume it is this situation and just don't treat this; 3555 # variable as a reduction.; 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir); 3635 defs[lhs.name] = rhs; 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:; -> 3637 rhs = lookup(rhs); 3638 if isinstance(rhs, ir.Expr):; 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. File ~/miniconda3/en",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:10858,Testability,test,test,10858,"les) in combination with SSA can make things look like; 3552 # reductions except that they don't have reduction operators.; 3553 # If we get to this point but don't find a reduction operator; 3554 # then assume it is this situation and just don't treat this; 3555 # variable as a reduction.; 3556 if reduce_nodes is not None:. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir); 3635 defs[lhs.name] = rhs; 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:; -> 3637 rhs = lookup(rhs); 3638 if isinstance(rhs, ir.Expr):; 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly); 3624 def lookup(var, varonly=True):; -> 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:11252,Testability,test,test,11252,"ors/parfor.py:3637, in get_reduce_nodes(reduction_node, nodes, func_ir); 3635 defs[lhs.name] = rhs; 3636 if isinstance(rhs, ir.Var) and rhs.name in defs:; -> 3637 rhs = lookup(rhs); 3638 if isinstance(rhs, ir.Expr):; 3639 in_vars = set(lookup(v, True).name for v in rhs.list_vars()). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly); 3624 def lookup(var, varonly=True):; -> 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors); maximum recursion depth exceeded while calling a Python object. ```. #### Versions; <details>. -----; anndata 0.8.0; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.0.1; anndata 0.8.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:11555,Testability,test,test,11555,"nvs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. [... skipping similar frames: get_reduce_nodes.<locals>.lookup at line 3627 (2946 times)]. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3627, in get_reduce_nodes.<locals>.lookup(var, varonly); 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; -> 3627 return lookup(val); 3628 else:; 3629 return var if (varonly or val is None) else val. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:3625, in get_reduce_nodes.<locals>.lookup(var, varonly); 3624 def lookup(var, varonly=True):; -> 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors); maximum recursion depth exceeded while calling a Python object. ```. #### Versions; <details>. -----; anndata 0.8.0; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.0.1; anndata 0.8.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 0.8.3; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.9; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.0; leidenalg 0.8.9; llvmlite 0.38.0; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:13531,Testability,log,logical,13531,"t_reduce_nodes.<locals>.lookup(var, varonly); 3624 def lookup(var, varonly=True):; -> 3625 val = defs.get(var.name, None); 3626 if isinstance(val, ir.Var):; 3627 return lookup(val). RecursionError: Failed in nopython mode pipeline (step: convert to parfors); maximum recursion depth exceeded while calling a Python object. ```. #### Versions; <details>. -----; anndata 0.8.0; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.0.1; anndata 0.8.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 0.8.3; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.9; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.0; leidenalg 0.8.9; llvmlite 0.38.0; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.0; numpy 1.21.5; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.27; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2022.1; scanpy 1.8.2; scipy 1.8.0; seaborn 0.11.2; setuptools 60.10.0; sinfo 0.3.1; six 1.16.0; sklearn 1.0.2; sphinxcontrib NA; stack_data 0.2.0; statsmodels 0.13.2; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.1; tqdm 4.63.1; traitlets 5.1.1; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; zmq 22.3.0; -----; IPython 8.1.1; jupyter_client 7.1.2; jupyter_core 4.9.2; notebook 6.4.10; -----; Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57) [GCC 10.3.0]; Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31; 8 logical CPU cores, x86_64; -----; Session information updated at 2022-03-24 22:07. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8073,Usability,Simpl,SimpleTimer,8073,"e pipeline (step: %s)"" % \; 351 (self.pipeline_name, pass_desc); 352 patched_exception = self._patch_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state); 339 pass_inst = _pass_registry.get(pss).pass_inst; 340 if isinstance(pass_inst, CompilerPass):; --> 341 self._runPass(idx, pass_inst, state); 342 else:; 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs); 32 @functools.wraps(func); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self:; ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state); 294 mutated |= check(pss.run_initialization, internal_state); 295 with SimpleTimer() as pass_time:; --> 296 mutated |= check(pss.run_pass, internal_state); 297 with SimpleTimer() as finalize_time:; 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state); 268 def check(func, compiler_state):; --> 269 mangled = func(compiler_state); 270 if mangled not in (True, False):; 271 msg = (""CompilerPass implementations should return True/False. ""; 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state); 295 assert state.func_ir; 296 parfor_pass = _parfor_ParforPass(state.func_ir,; 297 state.typemap,; 298 state.calltypes,; (...); 304 state.metadata,; 305 state.parfor_diagnostics); --> 306 parfor_pass.run(); 308 # check the parfor pass worked and warn if it didn't; 309 has_parfor = False. File ~/miniconda3/e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/issues/2191:8167,Usability,Simpl,SimpleTimer,8167,"h_error(msg, e); --> 353 raise patched_exception. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:341, in PassManager.run(self, state); 339 pass_inst = _pass_registry.get(pss).pass_inst; 340 if isinstance(pass_inst, CompilerPass):; --> 341 self._runPass(idx, pass_inst, state); 342 else:; 343 raise BaseException(""Legacy pass in use""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_lock.py:35, in _CompilerLock.__call__.<locals>._acquire_compile_lock(*args, **kwargs); 32 @functools.wraps(func); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self:; ---> 35 return func(*args, **kwargs). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:296, in PassManager._runPass(self, index, pss, internal_state); 294 mutated |= check(pss.run_initialization, internal_state); 295 with SimpleTimer() as pass_time:; --> 296 mutated |= check(pss.run_pass, internal_state); 297 with SimpleTimer() as finalize_time:; 298 mutated |= check(pss.run_finalizer, internal_state). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/compiler_machinery.py:269, in PassManager._runPass.<locals>.check(func, compiler_state); 268 def check(func, compiler_state):; --> 269 mangled = func(compiler_state); 270 if mangled not in (True, False):; 271 msg = (""CompilerPass implementations should return True/False. ""; 272 ""CompilerPass with name '%s' did not.""). File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/core/typed_passes.py:306, in ParforPass.run_pass(self, state); 295 assert state.func_ir; 296 parfor_pass = _parfor_ParforPass(state.func_ir,; 297 state.typemap,; 298 state.calltypes,; (...); 304 state.metadata,; 305 state.parfor_diagnostics); --> 306 parfor_pass.run(); 308 # check the parfor pass worked and warn if it didn't; 309 has_parfor = False. File ~/miniconda3/envs/test/lib/python3.10/site-packages/numba/parfors/parfor.py:2926, in ParforPass.run(self); 2924 #",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2191
https://github.com/scverse/scanpy/pull/2192:0,Deployability,Update,Update,0,Update chat link from slack to zulip,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2192
https://github.com/scverse/scanpy/issues/2193:1054,Availability,down,downgrade,1054,"hecked that this issue has not already been reported.; - [ Yes] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pp.highly_variable_genes(; ncase,; n_top_genes=3000,; # subset=True, # to automatically subset to the 4000 genes; layer=""counts"",; flavor=""seurat""; ); ```. ```pytb; ValueError: cannot specify integer `bins` when input data contains infinity; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; anyio NA; astunparse 1.6.3; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; et_xmlfile 1.1.0; flatbuffers 2.0; gast 0.5.3; google NA; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; keras 2.8.0; keras_preprocessing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:1033,Deployability,install,installs,1033,"hecked that this issue has not already been reported.; - [ Yes] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pp.highly_variable_genes(; ncase,; n_top_genes=3000,; # subset=True, # to automatically subset to the 4000 genes; layer=""counts"",; flavor=""seurat""; ); ```. ```pytb; ValueError: cannot specify integer `bins` when input data contains infinity; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; anyio NA; astunparse 1.6.3; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; et_xmlfile 1.1.0; flatbuffers 2.0; gast 0.5.3; google NA; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; keras 2.8.0; keras_preprocessing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:1170,Deployability,install,install,1170,"l) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pp.highly_variable_genes(; ncase,; n_top_genes=3000,; # subset=True, # to automatically subset to the 4000 genes; layer=""counts"",; flavor=""seurat""; ); ```. ```pytb; ValueError: cannot specify integer `bins` when input data contains infinity; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; anyio NA; astunparse 1.6.3; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; et_xmlfile 1.1.0; flatbuffers 2.0; gast 0.5.3; google NA; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; keras 2.8.0; keras_preprocessing 1.1.2; kiwisolver 1.3.1; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:3284,Deployability,update,updated,3284,"n_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; anyio NA; astunparse 1.6.3; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; et_xmlfile 1.1.0; flatbuffers 2.0; gast 0.5.3; google NA; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; keras 2.8.0; keras_preprocessing 1.1.2; kiwisolver 1.3.1; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbclassic NA; nbformat 5.1.3; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.5; openpyxl 3.0.9; opt_einsum v3.3.0; packaging 21.3; pandas 1.3.2; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.19; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pyexpat NA; pygments 2.10.0; pynndescent 0.5.6; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.26.0; scipy 1.7.1; send2trash NA; six 1.16.0; sklearn 0.24.2; sniffio 1.2.0; statsmodels 0.13.2; storemagic NA; tables 3.7.0; tensorboard 2.8.0; tensorflow 2.8.0; termcolor 1.1.0; terminado 0.11.1; texttable 1.6.4; tornado 6.1; tqdm 4.63.0; traitlets 5.0.5; typing_extensions NA; umap 0.5.2; urllib3 1.26.6; wcwidth 0.2.5; websocket 1.2.1; wrapt 1.14.0; xlrd 1.2.0; zmq 22.2.1; -----; IPython 7.26.0; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.1.7; notebook 6.4.3; -----; Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]; Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17; 36 logical CPU cores, x86_64; -----; Session information updated at 2022-03-26 18:52. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:1115,Integrability,message,message,1115," this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pp.highly_variable_genes(; ncase,; n_top_genes=3000,; # subset=True, # to automatically subset to the 4000 genes; layer=""counts"",; flavor=""seurat""; ); ```. ```pytb; ValueError: cannot specify integer `bins` when input data contains infinity; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; anyio NA; astunparse 1.6.3; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; et_xmlfile 1.1.0; flatbuffers 2.0; gast 0.5.3; google NA; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; keras 2.8.0; keras_preprocessing 1.1.2; kiwisolver 1.3.1; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; marku",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:2938,Integrability,wrap,wrapt,2938,"n_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; anyio NA; astunparse 1.6.3; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; et_xmlfile 1.1.0; flatbuffers 2.0; gast 0.5.3; google NA; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; keras 2.8.0; keras_preprocessing 1.1.2; kiwisolver 1.3.1; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbclassic NA; nbformat 5.1.3; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.5; openpyxl 3.0.9; opt_einsum v3.3.0; packaging 21.3; pandas 1.3.2; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.19; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pyexpat NA; pygments 2.10.0; pynndescent 0.5.6; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.26.0; scipy 1.7.1; send2trash NA; six 1.16.0; sklearn 0.24.2; sniffio 1.2.0; statsmodels 0.13.2; storemagic NA; tables 3.7.0; tensorboard 2.8.0; tensorflow 2.8.0; termcolor 1.1.0; terminado 0.11.1; texttable 1.6.4; tornado 6.1; tqdm 4.63.0; traitlets 5.0.5; typing_extensions NA; umap 0.5.2; urllib3 1.26.6; wcwidth 0.2.5; websocket 1.2.1; wrapt 1.14.0; xlrd 1.2.0; zmq 22.2.1; -----; IPython 7.26.0; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.1.7; notebook 6.4.3; -----; Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]; Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17; 36 logical CPU cores, x86_64; -----; Session information updated at 2022-03-26 18:52. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:1014,Safety,avoid,avoid,1014,"hecked that this issue has not already been reported.; - [ Yes] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pp.highly_variable_genes(; ncase,; n_top_genes=3000,; # subset=True, # to automatically subset to the 4000 genes; layer=""counts"",; flavor=""seurat""; ); ```. ```pytb; ValueError: cannot specify integer `bins` when input data contains infinity; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; anyio NA; astunparse 1.6.3; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; et_xmlfile 1.1.0; flatbuffers 2.0; gast 0.5.3; google NA; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; keras 2.8.0; keras_preprocessing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:3230,Testability,log,logical,3230,"n_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; anyio NA; astunparse 1.6.3; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; et_xmlfile 1.1.0; flatbuffers 2.0; gast 0.5.3; google NA; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; keras 2.8.0; keras_preprocessing 1.1.2; kiwisolver 1.3.1; leidenalg 0.8.9; llvmlite 0.38.0; louvain 0.7.1; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbclassic NA; nbformat 5.1.3; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.5; openpyxl 3.0.9; opt_einsum v3.3.0; packaging 21.3; pandas 1.3.2; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.19; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pyexpat NA; pygments 2.10.0; pynndescent 0.5.6; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.26.0; scipy 1.7.1; send2trash NA; six 1.16.0; sklearn 0.24.2; sniffio 1.2.0; statsmodels 0.13.2; storemagic NA; tables 3.7.0; tensorboard 2.8.0; tensorflow 2.8.0; termcolor 1.1.0; terminado 0.11.1; texttable 1.6.4; tornado 6.1; tqdm 4.63.0; traitlets 5.0.5; typing_extensions NA; umap 0.5.2; urllib3 1.26.6; wcwidth 0.2.5; websocket 1.2.1; wrapt 1.14.0; xlrd 1.2.0; zmq 22.2.1; -----; IPython 7.26.0; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.1.7; notebook 6.4.3; -----; Python 3.9.6 (default, Aug 18 2021, 11:08:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]; Linux-3.10.0-1160.41.1.el7.x86_64-x86_64-with-glibc2.17; 36 logical CPU cores, x86_64; -----; Session information updated at 2022-03-26 18:52. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2193:263,Usability,guid,guide,263,"- [ Yes] I have checked that this issue has not already been reported.; - [ Yes] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pp.highly_variable_genes(; ncase,; n_top_genes=3000,; # subset=True, # to automatically subset to the 4000 genes; layer=""counts"",; flavor=""seurat""; ); ```. ```pytb; ValueError: cannot specify integer `bins` when input data contains infinity; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.3.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; anyio NA; astunparse 1.6.3; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; celltypist 0.2.0; certifi 2021.05.30; cffi 1.14.6; charset_normalizer 2.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; et_xmlfile 1.1.0; flatbuffers 2.0; gast 0.5.3; google NA; h5py 3.3.0; idna 3.2; igraph 0.9.9; ipykernel 6.2.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.1; keras 2.8.0; ker",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2193
https://github.com/scverse/scanpy/issues/2194:168,Usability,simpl,simple,168,"<!-- What kind of feature would you like to request? -->; - [ x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Add color annotation to dotplot, e.g. same as row_colors and col_colors in seaborn heatmap.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2194
https://github.com/scverse/scanpy/issues/2195:548,Testability,log,logreg,548,"- [x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.rank_genes_groups(adata, 'leiden', method='logreg'); ```. ```pytb; ~/miniconda3/envs/tangram-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):; STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in:; https://scikit-learn.org/stable/modules/preprocessing.html; Please also refer to the documentation for alternative solver options:; https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression; n_iter_i = _check_optimize_result(; finished (0:07:47). ```. #### Versions. scikit-learn=1.0.2; scanpy=1.8.2. <details>. It seems the result was still not converged when using the maximal iteration parameter (max_iter=100) in LogisticRegression function of sklearn. I'd like to ask are there any possibilities to pass any parameters from scanpy to sklearn to increase the max_iter value?. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2195
https://github.com/scverse/scanpy/issues/2195:1039,Testability,log,logistic-regression,1039,"- [x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.rank_genes_groups(adata, 'leiden', method='logreg'); ```. ```pytb; ~/miniconda3/envs/tangram-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):; STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in:; https://scikit-learn.org/stable/modules/preprocessing.html; Please also refer to the documentation for alternative solver options:; https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression; n_iter_i = _check_optimize_result(; finished (0:07:47). ```. #### Versions. scikit-learn=1.0.2; scanpy=1.8.2. <details>. It seems the result was still not converged when using the maximal iteration parameter (max_iter=100) in LogisticRegression function of sklearn. I'd like to ask are there any possibilities to pass any parameters from scanpy to sklearn to increase the max_iter value?. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2195
https://github.com/scverse/scanpy/issues/2195:1286,Testability,Log,LogisticRegression,1286,"- [x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.rank_genes_groups(adata, 'leiden', method='logreg'); ```. ```pytb; ~/miniconda3/envs/tangram-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):; STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in:; https://scikit-learn.org/stable/modules/preprocessing.html; Please also refer to the documentation for alternative solver options:; https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression; n_iter_i = _check_optimize_result(; finished (0:07:47). ```. #### Versions. scikit-learn=1.0.2; scanpy=1.8.2. <details>. It seems the result was still not converged when using the maximal iteration parameter (max_iter=100) in LogisticRegression function of sklearn. I'd like to ask are there any possibilities to pass any parameters from scanpy to sklearn to increase the max_iter value?. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2195
https://github.com/scverse/scanpy/issues/2195:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.rank_genes_groups(adata, 'leiden', method='logreg'); ```. ```pytb; ~/miniconda3/envs/tangram-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):; STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in:; https://scikit-learn.org/stable/modules/preprocessing.html; Please also refer to the documentation for alternative solver options:; https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression; n_iter_i = _check_optimize_result(; finished (0:07:47). ```. #### Versions. scikit-learn=1.0.2; scanpy=1.8.2. <details>. It seems the result was still not converged when using the maximal iteration parameter (max_iter=100) in LogisticRegression function of sklearn. I'd like to ask are there any possibilities to pass any parameters from scanpy to sklearn to increase the max_iter value?. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2195
https://github.com/scverse/scanpy/issues/2195:864,Usability,learn,learn,864,"- [x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.rank_genes_groups(adata, 'leiden', method='logreg'); ```. ```pytb; ~/miniconda3/envs/tangram-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):; STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in:; https://scikit-learn.org/stable/modules/preprocessing.html; Please also refer to the documentation for alternative solver options:; https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression; n_iter_i = _check_optimize_result(; finished (0:07:47). ```. #### Versions. scikit-learn=1.0.2; scanpy=1.8.2. <details>. It seems the result was still not converged when using the maximal iteration parameter (max_iter=100) in LogisticRegression function of sklearn. I'd like to ask are there any possibilities to pass any parameters from scanpy to sklearn to increase the max_iter value?. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2195
https://github.com/scverse/scanpy/issues/2195:996,Usability,learn,learn,996,"- [x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.rank_genes_groups(adata, 'leiden', method='logreg'); ```. ```pytb; ~/miniconda3/envs/tangram-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):; STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in:; https://scikit-learn.org/stable/modules/preprocessing.html; Please also refer to the documentation for alternative solver options:; https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression; n_iter_i = _check_optimize_result(; finished (0:07:47). ```. #### Versions. scikit-learn=1.0.2; scanpy=1.8.2. <details>. It seems the result was still not converged when using the maximal iteration parameter (max_iter=100) in LogisticRegression function of sklearn. I'd like to ask are there any possibilities to pass any parameters from scanpy to sklearn to increase the max_iter value?. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2195
https://github.com/scverse/scanpy/issues/2195:1143,Usability,learn,learn,1143,"- [x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.rank_genes_groups(adata, 'leiden', method='logreg'); ```. ```pytb; ~/miniconda3/envs/tangram-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):; STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in:; https://scikit-learn.org/stable/modules/preprocessing.html; Please also refer to the documentation for alternative solver options:; https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression; n_iter_i = _check_optimize_result(; finished (0:07:47). ```. #### Versions. scikit-learn=1.0.2; scanpy=1.8.2. <details>. It seems the result was still not converged when using the maximal iteration parameter (max_iter=100) in LogisticRegression function of sklearn. I'd like to ask are there any possibilities to pass any parameters from scanpy to sklearn to increase the max_iter value?. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2195
https://github.com/scverse/scanpy/pull/2196:9,Deployability,release,release,9,Prepping release notes for 1.9.0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2196
https://github.com/scverse/scanpy/pull/2197:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2197
https://github.com/scverse/scanpy/pull/2197:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2197
https://github.com/scverse/scanpy/pull/2198:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2198
https://github.com/scverse/scanpy/pull/2198:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2198
https://github.com/scverse/scanpy/pull/2199:805,Deployability,update,update,805,"Every time I build the docs locally, they do a complete rebuild. This is painfully slow (especially with our examples that run on each build) and really discourages editing the docs. This is happening because the sphinx sees the config being modified. There are two causes of this:. * The version being set dynamically  at each commit the version string changes.; * `scanpydoc.elegant_typehints` sets some properties of the config after it's loaded. E.g.:. ```; updating environment: [config changed ('typehints_formatter')] 317 added, 0 changed, 0 removed; ```. ### Solution. Version being set dynamically does really add that much value for us, so I just removed that part of the version string. `scanpydoc.elegant_typehints` does make the doc-strings nicer, but it is not worth a five minute build to update the docs. Ideally it can be implemented in a way that doesn't make sphinx think the config has changed, but I am disabling it until then.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2199
https://github.com/scverse/scanpy/pull/2199:229,Modifiability,config,config,229,"Every time I build the docs locally, they do a complete rebuild. This is painfully slow (especially with our examples that run on each build) and really discourages editing the docs. This is happening because the sphinx sees the config being modified. There are two causes of this:. * The version being set dynamically  at each commit the version string changes.; * `scanpydoc.elegant_typehints` sets some properties of the config after it's loaded. E.g.:. ```; updating environment: [config changed ('typehints_formatter')] 317 added, 0 changed, 0 removed; ```. ### Solution. Version being set dynamically does really add that much value for us, so I just removed that part of the version string. `scanpydoc.elegant_typehints` does make the doc-strings nicer, but it is not worth a five minute build to update the docs. Ideally it can be implemented in a way that doesn't make sphinx think the config has changed, but I am disabling it until then.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2199
https://github.com/scverse/scanpy/pull/2199:425,Modifiability,config,config,425,"Every time I build the docs locally, they do a complete rebuild. This is painfully slow (especially with our examples that run on each build) and really discourages editing the docs. This is happening because the sphinx sees the config being modified. There are two causes of this:. * The version being set dynamically  at each commit the version string changes.; * `scanpydoc.elegant_typehints` sets some properties of the config after it's loaded. E.g.:. ```; updating environment: [config changed ('typehints_formatter')] 317 added, 0 changed, 0 removed; ```. ### Solution. Version being set dynamically does really add that much value for us, so I just removed that part of the version string. `scanpydoc.elegant_typehints` does make the doc-strings nicer, but it is not worth a five minute build to update the docs. Ideally it can be implemented in a way that doesn't make sphinx think the config has changed, but I am disabling it until then.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2199
https://github.com/scverse/scanpy/pull/2199:486,Modifiability,config,config,486,"Every time I build the docs locally, they do a complete rebuild. This is painfully slow (especially with our examples that run on each build) and really discourages editing the docs. This is happening because the sphinx sees the config being modified. There are two causes of this:. * The version being set dynamically  at each commit the version string changes.; * `scanpydoc.elegant_typehints` sets some properties of the config after it's loaded. E.g.:. ```; updating environment: [config changed ('typehints_formatter')] 317 added, 0 changed, 0 removed; ```. ### Solution. Version being set dynamically does really add that much value for us, so I just removed that part of the version string. `scanpydoc.elegant_typehints` does make the doc-strings nicer, but it is not worth a five minute build to update the docs. Ideally it can be implemented in a way that doesn't make sphinx think the config has changed, but I am disabling it until then.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2199
https://github.com/scverse/scanpy/pull/2199:896,Modifiability,config,config,896,"Every time I build the docs locally, they do a complete rebuild. This is painfully slow (especially with our examples that run on each build) and really discourages editing the docs. This is happening because the sphinx sees the config being modified. There are two causes of this:. * The version being set dynamically  at each commit the version string changes.; * `scanpydoc.elegant_typehints` sets some properties of the config after it's loaded. E.g.:. ```; updating environment: [config changed ('typehints_formatter')] 317 added, 0 changed, 0 removed; ```. ### Solution. Version being set dynamically does really add that much value for us, so I just removed that part of the version string. `scanpydoc.elegant_typehints` does make the doc-strings nicer, but it is not worth a five minute build to update the docs. Ideally it can be implemented in a way that doesn't make sphinx think the config has changed, but I am disabling it until then.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2199
https://github.com/scverse/scanpy/pull/2199:443,Performance,load,loaded,443,"Every time I build the docs locally, they do a complete rebuild. This is painfully slow (especially with our examples that run on each build) and really discourages editing the docs. This is happening because the sphinx sees the config being modified. There are two causes of this:. * The version being set dynamically  at each commit the version string changes.; * `scanpydoc.elegant_typehints` sets some properties of the config after it's loaded. E.g.:. ```; updating environment: [config changed ('typehints_formatter')] 317 added, 0 changed, 0 removed; ```. ### Solution. Version being set dynamically does really add that much value for us, so I just removed that part of the version string. `scanpydoc.elegant_typehints` does make the doc-strings nicer, but it is not worth a five minute build to update the docs. Ideally it can be implemented in a way that doesn't make sphinx think the config has changed, but I am disabling it until then.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2199
https://github.com/scverse/scanpy/issues/2203:187,Availability,error,error,187,"Hi . When attempting so simply read a h5 file with: . ```; Python version - 3.8.8; # results_file = path to 10X h5 file ; # adata = sc.read_10x_h5(results_file); ```. I get the following error which is fixed when rolling back to scanpy=1.8.2; ```pytb; ValueError Traceback (most recent call last); <ipython-input-3-8ddd0a13aab2> in <module>; 8 print(results_file); ----> 9 adata = sc.read_10x_h5(results_file); 10 adata.var_names_make_unique(); 11 adata.obs.index = meta.iloc[idx,2] + '-' + adata.obs.index. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url); 181 v3 = '/matrix' in f; 182 if v3:; --> 183 adata = _read_v3_10x_h5(filename, start=start); 184 if genome:; 185 if genome not in adata.var['genome'].values:. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_h5(filename, start); 266 try:; 267 dsets = {}; --> 268 _collect_datasets(dsets, f[""matrix""]); 269 ; 270 from scipy.sparse import csr_matrix. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in _collect_datasets(dsets, group); 254 for k, v in group.items():; 255 if isinstance(v, h5py.Dataset):; --> 256 dsets[k] = v[:]; 257 else:; 258 _collect_datasets(dsets, v). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). /opt/conda/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args, new_dtype); 767 if self.shape == ():; 768 fspace = self.id.get_space(); --> 769 selection = sel2.select_read(fspace, args); 770 if selection.mshape is None:; 771 arr = numpy.ndarray((), dtype=new_dtype). /opt/conda/lib/python3.8/site-packages/h5py/_hl/selections2.py in select_read(fspace, args); 99 """"""; 100 if fspace.shape == ():; --> 101 return ScalarReadSelection(fspace, args); 102 ; 103 raise NotImplementedError(). /opt/conda/lib/python3.8/site-packages/h5py/_hl/selections2.py in __init__(self, fspace, args); 84 self.mshape = (); 85 else:; ---> 86 raise ValueErro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203
https://github.com/scverse/scanpy/issues/2203:213,Deployability,rolling,rolling,213,"Hi . When attempting so simply read a h5 file with: . ```; Python version - 3.8.8; # results_file = path to 10X h5 file ; # adata = sc.read_10x_h5(results_file); ```. I get the following error which is fixed when rolling back to scanpy=1.8.2; ```pytb; ValueError Traceback (most recent call last); <ipython-input-3-8ddd0a13aab2> in <module>; 8 print(results_file); ----> 9 adata = sc.read_10x_h5(results_file); 10 adata.var_names_make_unique(); 11 adata.obs.index = meta.iloc[idx,2] + '-' + adata.obs.index. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url); 181 v3 = '/matrix' in f; 182 if v3:; --> 183 adata = _read_v3_10x_h5(filename, start=start); 184 if genome:; 185 if genome not in adata.var['genome'].values:. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_h5(filename, start); 266 try:; 267 dsets = {}; --> 268 _collect_datasets(dsets, f[""matrix""]); 269 ; 270 from scipy.sparse import csr_matrix. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in _collect_datasets(dsets, group); 254 for k, v in group.items():; 255 if isinstance(v, h5py.Dataset):; --> 256 dsets[k] = v[:]; 257 else:; 258 _collect_datasets(dsets, v). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). /opt/conda/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args, new_dtype); 767 if self.shape == ():; 768 fspace = self.id.get_space(); --> 769 selection = sel2.select_read(fspace, args); 770 if selection.mshape is None:; 771 arr = numpy.ndarray((), dtype=new_dtype). /opt/conda/lib/python3.8/site-packages/h5py/_hl/selections2.py in select_read(fspace, args); 99 """"""; 100 if fspace.shape == ():; --> 101 return ScalarReadSelection(fspace, args); 102 ; 103 raise NotImplementedError(). /opt/conda/lib/python3.8/site-packages/h5py/_hl/selections2.py in __init__(self, fspace, args); 84 self.mshape = (); 85 else:; ---> 86 raise ValueErro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203
https://github.com/scverse/scanpy/issues/2203:1276,Integrability,wrap,wrapper,1276,"llowing error which is fixed when rolling back to scanpy=1.8.2; ```pytb; ValueError Traceback (most recent call last); <ipython-input-3-8ddd0a13aab2> in <module>; 8 print(results_file); ----> 9 adata = sc.read_10x_h5(results_file); 10 adata.var_names_make_unique(); 11 adata.obs.index = meta.iloc[idx,2] + '-' + adata.obs.index. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url); 181 v3 = '/matrix' in f; 182 if v3:; --> 183 adata = _read_v3_10x_h5(filename, start=start); 184 if genome:; 185 if genome not in adata.var['genome'].values:. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_h5(filename, start); 266 try:; 267 dsets = {}; --> 268 _collect_datasets(dsets, f[""matrix""]); 269 ; 270 from scipy.sparse import csr_matrix. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in _collect_datasets(dsets, group); 254 for k, v in group.items():; 255 if isinstance(v, h5py.Dataset):; --> 256 dsets[k] = v[:]; 257 else:; 258 _collect_datasets(dsets, v). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). /opt/conda/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args, new_dtype); 767 if self.shape == ():; 768 fspace = self.id.get_space(); --> 769 selection = sel2.select_read(fspace, args); 770 if selection.mshape is None:; 771 arr = numpy.ndarray((), dtype=new_dtype). /opt/conda/lib/python3.8/site-packages/h5py/_hl/selections2.py in select_read(fspace, args); 99 """"""; 100 if fspace.shape == ():; --> 101 return ScalarReadSelection(fspace, args); 102 ; 103 raise NotImplementedError(). /opt/conda/lib/python3.8/site-packages/h5py/_hl/selections2.py in __init__(self, fspace, args); 84 self.mshape = (); 85 else:; ---> 86 raise ValueError(""Illegal slicing argument for scalar dataspace""); 87 ; 88 self.mspace = h5s.create(h5s.SCALAR). ValueError: Illegal slicing argument for scalar dataspace; ```. Thanks!! . Nadav",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203
https://github.com/scverse/scanpy/issues/2203:1332,Integrability,wrap,wrapper,1332,"llowing error which is fixed when rolling back to scanpy=1.8.2; ```pytb; ValueError Traceback (most recent call last); <ipython-input-3-8ddd0a13aab2> in <module>; 8 print(results_file); ----> 9 adata = sc.read_10x_h5(results_file); 10 adata.var_names_make_unique(); 11 adata.obs.index = meta.iloc[idx,2] + '-' + adata.obs.index. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url); 181 v3 = '/matrix' in f; 182 if v3:; --> 183 adata = _read_v3_10x_h5(filename, start=start); 184 if genome:; 185 if genome not in adata.var['genome'].values:. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_h5(filename, start); 266 try:; 267 dsets = {}; --> 268 _collect_datasets(dsets, f[""matrix""]); 269 ; 270 from scipy.sparse import csr_matrix. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in _collect_datasets(dsets, group); 254 for k, v in group.items():; 255 if isinstance(v, h5py.Dataset):; --> 256 dsets[k] = v[:]; 257 else:; 258 _collect_datasets(dsets, v). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). /opt/conda/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args, new_dtype); 767 if self.shape == ():; 768 fspace = self.id.get_space(); --> 769 selection = sel2.select_read(fspace, args); 770 if selection.mshape is None:; 771 arr = numpy.ndarray((), dtype=new_dtype). /opt/conda/lib/python3.8/site-packages/h5py/_hl/selections2.py in select_read(fspace, args); 99 """"""; 100 if fspace.shape == ():; --> 101 return ScalarReadSelection(fspace, args); 102 ; 103 raise NotImplementedError(). /opt/conda/lib/python3.8/site-packages/h5py/_hl/selections2.py in __init__(self, fspace, args); 84 self.mshape = (); 85 else:; ---> 86 raise ValueError(""Illegal slicing argument for scalar dataspace""); 87 ; 88 self.mspace = h5s.create(h5s.SCALAR). ValueError: Illegal slicing argument for scalar dataspace; ```. Thanks!! . Nadav",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203
https://github.com/scverse/scanpy/issues/2203:24,Usability,simpl,simply,24,"Hi . When attempting so simply read a h5 file with: . ```; Python version - 3.8.8; # results_file = path to 10X h5 file ; # adata = sc.read_10x_h5(results_file); ```. I get the following error which is fixed when rolling back to scanpy=1.8.2; ```pytb; ValueError Traceback (most recent call last); <ipython-input-3-8ddd0a13aab2> in <module>; 8 print(results_file); ----> 9 adata = sc.read_10x_h5(results_file); 10 adata.var_names_make_unique(); 11 adata.obs.index = meta.iloc[idx,2] + '-' + adata.obs.index. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url); 181 v3 = '/matrix' in f; 182 if v3:; --> 183 adata = _read_v3_10x_h5(filename, start=start); 184 if genome:; 185 if genome not in adata.var['genome'].values:. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_h5(filename, start); 266 try:; 267 dsets = {}; --> 268 _collect_datasets(dsets, f[""matrix""]); 269 ; 270 from scipy.sparse import csr_matrix. /opt/conda/lib/python3.8/site-packages/scanpy/readwrite.py in _collect_datasets(dsets, group); 254 for k, v in group.items():; 255 if isinstance(v, h5py.Dataset):; --> 256 dsets[k] = v[:]; 257 else:; 258 _collect_datasets(dsets, v). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). /opt/conda/lib/python3.8/site-packages/h5py/_hl/dataset.py in __getitem__(self, args, new_dtype); 767 if self.shape == ():; 768 fspace = self.id.get_space(); --> 769 selection = sel2.select_read(fspace, args); 770 if selection.mshape is None:; 771 arr = numpy.ndarray((), dtype=new_dtype). /opt/conda/lib/python3.8/site-packages/h5py/_hl/selections2.py in select_read(fspace, args); 99 """"""; 100 if fspace.shape == ():; --> 101 return ScalarReadSelection(fspace, args); 102 ; 103 raise NotImplementedError(). /opt/conda/lib/python3.8/site-packages/h5py/_hl/selections2.py in __init__(self, fspace, args); 84 self.mshape = (); 85 else:; ---> 86 raise ValueErro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2203
https://github.com/scverse/scanpy/pull/2204:29,Modifiability,config,config,29,"You already set that, so the config isnt modified at runtime",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2204
https://github.com/scverse/scanpy/pull/2205:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2205
https://github.com/scverse/scanpy/pull/2205:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2205
https://github.com/scverse/scanpy/issues/2208:414,Availability,error,error,414,"- [x] I have checked that this issue has not already been reported. ; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; ; I am reproducing [3k PBMCs tutorial](https://github.com/scverse/scanpy-tutorials/blob/master/pbmc3k.ipynb), which I run with no problem previously in Google Colab. But suddenly this error pop up during plotting which I believe due to latest update 1.9.0. I verified by installing previous version, this is not an issue:. `!pip install scanpy==1.8.2 # work fine`. ### Error code . ```python; # scatter plot in the PCA coordinates, but we will not use that later on.; sc.pl.pca(adata, color='CST3') # <-- this produces the error; ```. ```pytb; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:00); ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); [<ipython-input-10-615d33c5cea9>](https://localhost:8080/#) in <module>(); 3 ; 4 # scatter plot in the PCA coordinates, but we will not use that later on.; ----> 5 sc.pl.pca(adata, color='CST3'); 6 ; 7 '''. 5 frames; [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 870 if not annotate_var_explained:; 871 return embedding(; --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ); 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208
https://github.com/scverse/scanpy/issues/2208:599,Availability,Error,Error,599,"- [x] I have checked that this issue has not already been reported. ; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; ; I am reproducing [3k PBMCs tutorial](https://github.com/scverse/scanpy-tutorials/blob/master/pbmc3k.ipynb), which I run with no problem previously in Google Colab. But suddenly this error pop up during plotting which I believe due to latest update 1.9.0. I verified by installing previous version, this is not an issue:. `!pip install scanpy==1.8.2 # work fine`. ### Error code . ```python; # scatter plot in the PCA coordinates, but we will not use that later on.; sc.pl.pca(adata, color='CST3') # <-- this produces the error; ```. ```pytb; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:00); ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); [<ipython-input-10-615d33c5cea9>](https://localhost:8080/#) in <module>(); 3 ; 4 # scatter plot in the PCA coordinates, but we will not use that later on.; ----> 5 sc.pl.pca(adata, color='CST3'); 6 ; 7 '''. 5 frames; [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 870 if not annotate_var_explained:; 871 return embedding(; --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ); 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208
https://github.com/scverse/scanpy/issues/2208:753,Availability,error,error,753,"- [x] I have checked that this issue has not already been reported. ; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; ; I am reproducing [3k PBMCs tutorial](https://github.com/scverse/scanpy-tutorials/blob/master/pbmc3k.ipynb), which I run with no problem previously in Google Colab. But suddenly this error pop up during plotting which I believe due to latest update 1.9.0. I verified by installing previous version, this is not an issue:. `!pip install scanpy==1.8.2 # work fine`. ### Error code . ```python; # scatter plot in the PCA coordinates, but we will not use that later on.; sc.pl.pca(adata, color='CST3') # <-- this produces the error; ```. ```pytb; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:00); ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); [<ipython-input-10-615d33c5cea9>](https://localhost:8080/#) in <module>(); 3 ; 4 # scatter plot in the PCA coordinates, but we will not use that later on.; ----> 5 sc.pl.pca(adata, color='CST3'); 6 ; 7 '''. 5 frames; [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 870 if not annotate_var_explained:; 871 return embedding(; --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ); 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208
https://github.com/scverse/scanpy/issues/2208:473,Deployability,update,update,473,"- [x] I have checked that this issue has not already been reported. ; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; ; I am reproducing [3k PBMCs tutorial](https://github.com/scverse/scanpy-tutorials/blob/master/pbmc3k.ipynb), which I run with no problem previously in Google Colab. But suddenly this error pop up during plotting which I believe due to latest update 1.9.0. I verified by installing previous version, this is not an issue:. `!pip install scanpy==1.8.2 # work fine`. ### Error code . ```python; # scatter plot in the PCA coordinates, but we will not use that later on.; sc.pl.pca(adata, color='CST3') # <-- this produces the error; ```. ```pytb; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:00); ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); [<ipython-input-10-615d33c5cea9>](https://localhost:8080/#) in <module>(); 3 ; 4 # scatter plot in the PCA coordinates, but we will not use that later on.; ----> 5 sc.pl.pca(adata, color='CST3'); 6 ; 7 '''. 5 frames; [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 870 if not annotate_var_explained:; 871 return embedding(; --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ); 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208
https://github.com/scverse/scanpy/issues/2208:501,Deployability,install,installing,501,"- [x] I have checked that this issue has not already been reported. ; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; ; I am reproducing [3k PBMCs tutorial](https://github.com/scverse/scanpy-tutorials/blob/master/pbmc3k.ipynb), which I run with no problem previously in Google Colab. But suddenly this error pop up during plotting which I believe due to latest update 1.9.0. I verified by installing previous version, this is not an issue:. `!pip install scanpy==1.8.2 # work fine`. ### Error code . ```python; # scatter plot in the PCA coordinates, but we will not use that later on.; sc.pl.pca(adata, color='CST3') # <-- this produces the error; ```. ```pytb; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:00); ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); [<ipython-input-10-615d33c5cea9>](https://localhost:8080/#) in <module>(); 3 ; 4 # scatter plot in the PCA coordinates, but we will not use that later on.; ----> 5 sc.pl.pca(adata, color='CST3'); 6 ; 7 '''. 5 frames; [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 870 if not annotate_var_explained:; 871 return embedding(; --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ); 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208
https://github.com/scverse/scanpy/issues/2208:559,Deployability,install,install,559,"- [x] I have checked that this issue has not already been reported. ; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; ; I am reproducing [3k PBMCs tutorial](https://github.com/scverse/scanpy-tutorials/blob/master/pbmc3k.ipynb), which I run with no problem previously in Google Colab. But suddenly this error pop up during plotting which I believe due to latest update 1.9.0. I verified by installing previous version, this is not an issue:. `!pip install scanpy==1.8.2 # work fine`. ### Error code . ```python; # scatter plot in the PCA coordinates, but we will not use that later on.; sc.pl.pca(adata, color='CST3') # <-- this produces the error; ```. ```pytb; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:00); ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); [<ipython-input-10-615d33c5cea9>](https://localhost:8080/#) in <module>(); 3 ; 4 # scatter plot in the PCA coordinates, but we will not use that later on.; ----> 5 sc.pl.pca(adata, color='CST3'); 6 ; 7 '''. 5 frames; [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 870 if not annotate_var_explained:; 871 return embedding(; --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ); 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208
https://github.com/scverse/scanpy/issues/2208:5616,Deployability,update,updated,5616,"b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; astor 0.8.1; astunparse 1.6.3; bottleneck 1.3.4; cached_property 1.5.2; certifi 2021.10.08; cffi 1.15.0; chardet 3.0.4; cloudpickle 1.3.0; cvxopt 1.2.7; cycler 0.10.0; cython_runtime NA; dask 2.12.0; dateutil 2.8.2; debugpy 1.0.0; decorator 4.4.2; dill 0.3.4; flatbuffers 2.0; gast 0.5.3; google NA; google_auth_httplib2 NA; googleapiclient NA; h5py 3.1.0; httplib2 0.17.4; idna 2.10; igraph 0.9.9; ipykernel 4.10.1; ipython_genutils 0.2.0; ipywidgets 7.7.0; jax 0.3.4; jaxlib 0.3.2; joblib 1.1.0; keras 2.8.0; keras_preprocessing 1.1.2; kiwisolver 1.4.0; leidenalg 0.8.9; llvmlite 0.34.0; matplotlib 3.2.2; mpl_toolkits NA; natsort 5.5.0; numba 0.51.2; numexpr 2.8.1; numpy 1.21.5; oauth2client 4.1.3; opt_einsum v3.3.0; packaging 21.3; pandas 1.3.5; patsy 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; portpicker NA; prompt_toolkit 1.0.18; psutil 5.4.8; ptyprocess 0.7.0; pyarrow 6.0.1; pyasn1 0.4.8; pyasn1_modules 0.2.8; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.0.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot_ng 2.0.0; pygments 2.6.1; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2018.9; requests 2.23.0; rsa 4.8; scipy 1.4.1; seaborn 0.11.2; session_info 1.0.0; simplegeneric NA; sitecustomize NA; six 1.15.0; sklearn 1.0.2; socks 1.7.1; sphinxcontrib NA; statsmodels 0.10.2; storemagic NA; tblib 1.7.0; tensorboard 2.8.0; tensorflow 2.8.0; tensorflow_probability 0.16.0; termcolor 1.1.0; texttable 1.6.4; threadpoolctl 3.1.0; toolz 0.11.2; tornado 5.1.1; tqdm 4.63.0; traitlets 5.1.1; tree 0.1.6; typing_extensions NA; umap 0.5.2; uritemplate 3.0.1; urllib3 1.24.3; wcwidth 0.2.5; wrapt 1.14.0; yaml 3.13; zipp NA; zmq 22.3.0. IPython 5.5.0; jupyter_client 5.3.5; jupyter_core 4.9.2; notebook 5.3.1. Python 3.7.13 (default, Mar 16 2022, 17:37:17) [GCC 7.5.0]; Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-04-04 17:56. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208
https://github.com/scverse/scanpy/issues/2208:5369,Integrability,wrap,wrapt,5369,"b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; astor 0.8.1; astunparse 1.6.3; bottleneck 1.3.4; cached_property 1.5.2; certifi 2021.10.08; cffi 1.15.0; chardet 3.0.4; cloudpickle 1.3.0; cvxopt 1.2.7; cycler 0.10.0; cython_runtime NA; dask 2.12.0; dateutil 2.8.2; debugpy 1.0.0; decorator 4.4.2; dill 0.3.4; flatbuffers 2.0; gast 0.5.3; google NA; google_auth_httplib2 NA; googleapiclient NA; h5py 3.1.0; httplib2 0.17.4; idna 2.10; igraph 0.9.9; ipykernel 4.10.1; ipython_genutils 0.2.0; ipywidgets 7.7.0; jax 0.3.4; jaxlib 0.3.2; joblib 1.1.0; keras 2.8.0; keras_preprocessing 1.1.2; kiwisolver 1.4.0; leidenalg 0.8.9; llvmlite 0.34.0; matplotlib 3.2.2; mpl_toolkits NA; natsort 5.5.0; numba 0.51.2; numexpr 2.8.1; numpy 1.21.5; oauth2client 4.1.3; opt_einsum v3.3.0; packaging 21.3; pandas 1.3.5; patsy 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; portpicker NA; prompt_toolkit 1.0.18; psutil 5.4.8; ptyprocess 0.7.0; pyarrow 6.0.1; pyasn1 0.4.8; pyasn1_modules 0.2.8; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.0.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot_ng 2.0.0; pygments 2.6.1; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2018.9; requests 2.23.0; rsa 4.8; scipy 1.4.1; seaborn 0.11.2; session_info 1.0.0; simplegeneric NA; sitecustomize NA; six 1.15.0; sklearn 1.0.2; socks 1.7.1; sphinxcontrib NA; statsmodels 0.10.2; storemagic NA; tblib 1.7.0; tensorboard 2.8.0; tensorflow 2.8.0; tensorflow_probability 0.16.0; termcolor 1.1.0; texttable 1.6.4; threadpoolctl 3.1.0; toolz 0.11.2; tornado 5.1.1; tqdm 4.63.0; traitlets 5.1.1; tree 0.1.6; typing_extensions NA; umap 0.5.2; uritemplate 3.0.1; urllib3 1.24.3; wcwidth 0.2.5; wrapt 1.14.0; yaml 3.13; zipp NA; zmq 22.3.0. IPython 5.5.0; jupyter_client 5.3.5; jupyter_core 4.9.2; notebook 5.3.1. Python 3.7.13 (default, Mar 16 2022, 17:37:17) [GCC 7.5.0]; Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-04-04 17:56. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208
https://github.com/scverse/scanpy/issues/2208:799,Modifiability,variab,variable,799,"- [x] I have checked that this issue has not already been reported. ; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; ; I am reproducing [3k PBMCs tutorial](https://github.com/scverse/scanpy-tutorials/blob/master/pbmc3k.ipynb), which I run with no problem previously in Google Colab. But suddenly this error pop up during plotting which I believe due to latest update 1.9.0. I verified by installing previous version, this is not an issue:. `!pip install scanpy==1.8.2 # work fine`. ### Error code . ```python; # scatter plot in the PCA coordinates, but we will not use that later on.; sc.pl.pca(adata, color='CST3') # <-- this produces the error; ```. ```pytb; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:00); ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); [<ipython-input-10-615d33c5cea9>](https://localhost:8080/#) in <module>(); 3 ; 4 # scatter plot in the PCA coordinates, but we will not use that later on.; ----> 5 sc.pl.pca(adata, color='CST3'); 6 ; 7 '''. 5 frames; [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 870 if not annotate_var_explained:; 871 return embedding(; --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ); 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208
https://github.com/scverse/scanpy/issues/2208:3729,Performance,bottleneck,bottleneck,3729,"cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}; -> 2238 cb = cbar.colorbar_factory(cax, mappable, **cb_kw); 2239 ; 2240 self.sca(current_ax). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in colorbar_factory(cax, mappable, **kwargs); 1683 cb = ColorbarPatch(cax, mappable, **kwargs); 1684 else:; -> 1685 cb = Colorbar(cax, mappable, **kwargs); 1686 ; 1687 cid = mappable.callbacksSM.connect('changed', cb.on_mappable_changed). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw); 1228 kw['alpha'] = mappable.get_alpha(); 1229 ; -> 1230 ColorbarBase.__init__(self, ax, **kw); 1231 ; 1232 def on_mappable_changed(self, mappable):. TypeError: __init__() got an unexpected keyword argument 'location'; ```. #### Versions. <details>. anndata 0.8.0; scanpy 1.9.0. PIL 7.1.2; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; astor 0.8.1; astunparse 1.6.3; bottleneck 1.3.4; cached_property 1.5.2; certifi 2021.10.08; cffi 1.15.0; chardet 3.0.4; cloudpickle 1.3.0; cvxopt 1.2.7; cycler 0.10.0; cython_runtime NA; dask 2.12.0; dateutil 2.8.2; debugpy 1.0.0; decorator 4.4.2; dill 0.3.4; flatbuffers 2.0; gast 0.5.3; google NA; google_auth_httplib2 NA; googleapiclient NA; h5py 3.1.0; httplib2 0.17.4; idna 2.10; igraph 0.9.9; ipykernel 4.10.1; ipython_genutils 0.2.0; ipywidgets 7.7.0; jax 0.3.4; jaxlib 0.3.2; joblib 1.1.0; keras 2.8.0; keras_preprocessing 1.1.2; kiwisolver 1.4.0; leidenalg 0.8.9; llvmlite 0.34.0; matplotlib 3.2.2; mpl_toolkits NA; natsort 5.5.0; numba 0.51.2; numexpr 2.8.1; numpy 1.21.5; oauth2client 4.1.3; opt_einsum v3.3.0; packaging 21.3; pandas 1.3.5; patsy 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; portpicker NA; prompt_toolkit 1.0.18; psutil 5.4.8; ptyprocess 0.7.0; pyarrow 6.0.1; pyasn1 0.4.8; pyasn1_modules 0.2.8; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.0.0; pydevd_concurrency_analyser NA; p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208
https://github.com/scverse/scanpy/issues/2208:4949,Usability,simpl,simplegeneric,4949,"b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; astor 0.8.1; astunparse 1.6.3; bottleneck 1.3.4; cached_property 1.5.2; certifi 2021.10.08; cffi 1.15.0; chardet 3.0.4; cloudpickle 1.3.0; cvxopt 1.2.7; cycler 0.10.0; cython_runtime NA; dask 2.12.0; dateutil 2.8.2; debugpy 1.0.0; decorator 4.4.2; dill 0.3.4; flatbuffers 2.0; gast 0.5.3; google NA; google_auth_httplib2 NA; googleapiclient NA; h5py 3.1.0; httplib2 0.17.4; idna 2.10; igraph 0.9.9; ipykernel 4.10.1; ipython_genutils 0.2.0; ipywidgets 7.7.0; jax 0.3.4; jaxlib 0.3.2; joblib 1.1.0; keras 2.8.0; keras_preprocessing 1.1.2; kiwisolver 1.4.0; leidenalg 0.8.9; llvmlite 0.34.0; matplotlib 3.2.2; mpl_toolkits NA; natsort 5.5.0; numba 0.51.2; numexpr 2.8.1; numpy 1.21.5; oauth2client 4.1.3; opt_einsum v3.3.0; packaging 21.3; pandas 1.3.5; patsy 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; portpicker NA; prompt_toolkit 1.0.18; psutil 5.4.8; ptyprocess 0.7.0; pyarrow 6.0.1; pyasn1 0.4.8; pyasn1_modules 0.2.8; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.0.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot_ng 2.0.0; pygments 2.6.1; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2018.9; requests 2.23.0; rsa 4.8; scipy 1.4.1; seaborn 0.11.2; session_info 1.0.0; simplegeneric NA; sitecustomize NA; six 1.15.0; sklearn 1.0.2; socks 1.7.1; sphinxcontrib NA; statsmodels 0.10.2; storemagic NA; tblib 1.7.0; tensorboard 2.8.0; tensorflow 2.8.0; tensorflow_probability 0.16.0; termcolor 1.1.0; texttable 1.6.4; threadpoolctl 3.1.0; toolz 0.11.2; tornado 5.1.1; tqdm 4.63.0; traitlets 5.1.1; tree 0.1.6; typing_extensions NA; umap 0.5.2; uritemplate 3.0.1; urllib3 1.24.3; wcwidth 0.2.5; wrapt 1.14.0; yaml 3.13; zipp NA; zmq 22.3.0. IPython 5.5.0; jupyter_client 5.3.5; jupyter_core 4.9.2; notebook 5.3.1. Python 3.7.13 (default, Mar 16 2022, 17:37:17) [GCC 7.5.0]; Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-04-04 17:56. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2208
https://github.com/scverse/scanpy/pull/2209:110,Availability,error,error,110,"When I call `sc.pp.normalize_total(adata)` on a system that does not have Dask installed, I get the following error:. ```; AnnData object with n_obs  n_vars = 710  33538; obs: 'filter_with_counts', 'scrublet_doublet_score', 'filter_with_scrublet'; var: 'gene_ids', 'feature_types', 'genome', 'filter_with_counts'. File ""/viash_automount/home/rcannood/workspace/viash_temp//viash-run-normalize_total-ppLnd4"", line 32, in <module>; sc.pp.normalize_total(; File ""/usr/local/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py"", line 200, in normalize_total; adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer; File ""/usr/local/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py"", line 25, in _normalize_data; if isinstance(counts, DaskArray):; TypeError: isinstance() arg 2 must be a type, a tuple of types, or a union; ```. The error was introduced in [9cb915](https://github.com/scverse/scanpy/commit/9cb915bee5bfe11f62ffb37c0405656aae4574f2#diff-34d549afa2b23d0b2066964a51f698d918398edffd38379a73d02390e31ae5e8R24). . This PR solves the issue by checking that DaskArray is not None, though I'm sure alternative solutions are also possible.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2209
https://github.com/scverse/scanpy/pull/2209:878,Availability,error,error,878,"When I call `sc.pp.normalize_total(adata)` on a system that does not have Dask installed, I get the following error:. ```; AnnData object with n_obs  n_vars = 710  33538; obs: 'filter_with_counts', 'scrublet_doublet_score', 'filter_with_scrublet'; var: 'gene_ids', 'feature_types', 'genome', 'filter_with_counts'. File ""/viash_automount/home/rcannood/workspace/viash_temp//viash-run-normalize_total-ppLnd4"", line 32, in <module>; sc.pp.normalize_total(; File ""/usr/local/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py"", line 200, in normalize_total; adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer; File ""/usr/local/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py"", line 25, in _normalize_data; if isinstance(counts, DaskArray):; TypeError: isinstance() arg 2 must be a type, a tuple of types, or a union; ```. The error was introduced in [9cb915](https://github.com/scverse/scanpy/commit/9cb915bee5bfe11f62ffb37c0405656aae4574f2#diff-34d549afa2b23d0b2066964a51f698d918398edffd38379a73d02390e31ae5e8R24). . This PR solves the issue by checking that DaskArray is not None, though I'm sure alternative solutions are also possible.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2209
https://github.com/scverse/scanpy/pull/2209:79,Deployability,install,installed,79,"When I call `sc.pp.normalize_total(adata)` on a system that does not have Dask installed, I get the following error:. ```; AnnData object with n_obs  n_vars = 710  33538; obs: 'filter_with_counts', 'scrublet_doublet_score', 'filter_with_scrublet'; var: 'gene_ids', 'feature_types', 'genome', 'filter_with_counts'. File ""/viash_automount/home/rcannood/workspace/viash_temp//viash-run-normalize_total-ppLnd4"", line 32, in <module>; sc.pp.normalize_total(; File ""/usr/local/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py"", line 200, in normalize_total; adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer; File ""/usr/local/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py"", line 25, in _normalize_data; if isinstance(counts, DaskArray):; TypeError: isinstance() arg 2 must be a type, a tuple of types, or a union; ```. The error was introduced in [9cb915](https://github.com/scverse/scanpy/commit/9cb915bee5bfe11f62ffb37c0405656aae4574f2#diff-34d549afa2b23d0b2066964a51f698d918398edffd38379a73d02390e31ae5e8R24). . This PR solves the issue by checking that DaskArray is not None, though I'm sure alternative solutions are also possible.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2209
https://github.com/scverse/scanpy/issues/2210:15,Deployability,update,update,15,"Hi,. Since the update I get this TypeError when running `sc.pp.normalize_total`. ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); sc.pp.normalize_total(adata, target_sum=1e4); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Input In [4], in <cell line: 3>(); 1 import scanpy as sc; 2 adata = sc.datasets.pbmc3k(); ----> 3 sc.pp.normalize_total(adata, target_sum=1e4). File ~/my-conda-envs/sc2022-multiomics/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py:200, in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 197 if key_added is not None:; 198 adata.obs[key_added] = counts_per_cell; 199 _set_obs_rep(; --> 200 adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer; 201 ); 202 else:; 203 # not recarray because need to support sparse; 204 dat = dict(; 205 X=_normalize_data(X, counts_per_cell, target_sum, copy=True),; 206 norm_factor=counts_per_cell,; 207 ). File ~/my-conda-envs/sc2022-multiomics/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py:25, in _normalize_data(X, counts, after, copy); 23 if issubclass(X.dtype.type, (int, np.integer)):; 24 X = X.astype(np.float32) # TODO: Check if float64 should be used; ---> 25 if isinstance(counts, DaskArray):; 26 counts_greater_than_zero = counts[counts > 0].compute_chunk_sizes(); 27 else:. TypeError: isinstance() arg 2 must be a type, a tuple of types, or a union; ```. I've checked that obs_names, var_names, obs columns names are all unique. Any clue how to solve?. Thanks!. #### Versions. <details>. -----; anndata 0.7.8; scanpy 1.9.0; -----; PIL 9.1.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; entrypoints 0.4; executing 0.8.3; google NA; h5py 3.6.0; hypergeom_ufunc NA; ipykernel 6.12.1; jedi 0.18.1; job",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2210
https://github.com/scverse/scanpy/issues/2210:2926,Deployability,update,updated,2926,"ct(; 205 X=_normalize_data(X, counts_per_cell, target_sum, copy=True),; 206 norm_factor=counts_per_cell,; 207 ). File ~/my-conda-envs/sc2022-multiomics/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py:25, in _normalize_data(X, counts, after, copy); 23 if issubclass(X.dtype.type, (int, np.integer)):; 24 X = X.astype(np.float32) # TODO: Check if float64 should be used; ---> 25 if isinstance(counts, DaskArray):; 26 counts_greater_than_zero = counts[counts > 0].compute_chunk_sizes(); 27 else:. TypeError: isinstance() arg 2 must be a type, a tuple of types, or a union; ```. I've checked that obs_names, var_names, obs columns names are all unique. Any clue how to solve?. Thanks!. #### Versions. <details>. -----; anndata 0.7.8; scanpy 1.9.0; -----; PIL 9.1.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; entrypoints 0.4; executing 0.8.3; google NA; h5py 3.6.0; hypergeom_ufunc NA; ipykernel 6.12.1; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.2; llvmlite 0.38.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numpy 1.21.5; packaging 21.3; pandas 1.4.2; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.29; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.7; pytz 2022.1; scipy 1.8.0; session_info 1.0.0; setuptools 62.0.0; six 1.16.0; sklearn 1.0.2; stack_data 0.2.0; threadpoolctl 3.1.0; tornado 6.1; traitlets 5.1.1; wcwidth 0.2.5; zmq 22.3.0; -----; IPython 8.2.0; jupyter_client 7.2.1; jupyter_core 4.9.2; -----; Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:39:04) [GCC 10.3.0]; Linux-4.15.0-112-generic-x86_64-with-glibc2.31; -----; Session information updated at 2022-04-05 09:40. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2210
https://github.com/scverse/scanpy/issues/2210:677,Modifiability,layers,layers,677,"Hi,. Since the update I get this TypeError when running `sc.pp.normalize_total`. ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); sc.pp.normalize_total(adata, target_sum=1e4); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Input In [4], in <cell line: 3>(); 1 import scanpy as sc; 2 adata = sc.datasets.pbmc3k(); ----> 3 sc.pp.normalize_total(adata, target_sum=1e4). File ~/my-conda-envs/sc2022-multiomics/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py:200, in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 197 if key_added is not None:; 198 adata.obs[key_added] = counts_per_cell; 199 _set_obs_rep(; --> 200 adata, _normalize_data(X, counts_per_cell, target_sum), layer=layer; 201 ); 202 else:; 203 # not recarray because need to support sparse; 204 dat = dict(; 205 X=_normalize_data(X, counts_per_cell, target_sum, copy=True),; 206 norm_factor=counts_per_cell,; 207 ). File ~/my-conda-envs/sc2022-multiomics/lib/python3.10/site-packages/scanpy/preprocessing/_normalization.py:25, in _normalize_data(X, counts, after, copy); 23 if issubclass(X.dtype.type, (int, np.integer)):; 24 X = X.astype(np.float32) # TODO: Check if float64 should be used; ---> 25 if isinstance(counts, DaskArray):; 26 counts_greater_than_zero = counts[counts > 0].compute_chunk_sizes(); 27 else:. TypeError: isinstance() arg 2 must be a type, a tuple of types, or a union; ```. I've checked that obs_names, var_names, obs columns names are all unique. Any clue how to solve?. Thanks!. #### Versions. <details>. -----; anndata 0.7.8; scanpy 1.9.0; -----; PIL 9.1.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; entrypoints 0.4; executing 0.8.3; google NA; h5py 3.6.0; hypergeom_ufunc NA; ipykernel 6.12.1; jedi 0.18.1; job",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2210
https://github.com/scverse/scanpy/issues/2211:38,Deployability,install,installed,38,#2210 is triggered by not having dask installed. Our current CI setup can't test for this. This should be addressed with a CI run that uses minimal dependencies.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211
https://github.com/scverse/scanpy/issues/2211:148,Integrability,depend,dependencies,148,#2210 is triggered by not having dask installed. Our current CI setup can't test for this. This should be addressed with a CI run that uses minimal dependencies.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211
https://github.com/scverse/scanpy/issues/2211:76,Testability,test,test,76,#2210 is triggered by not having dask installed. Our current CI setup can't test for this. This should be addressed with a CI run that uses minimal dependencies.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2211
https://github.com/scverse/scanpy/pull/2213:55,Availability,error,error,55,Backport PR #2209: Fix isinstance arg 2 must be a type error,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2213
https://github.com/scverse/scanpy/pull/2220:382,Deployability,release,release,382,"This is a version of Sphix-book-based scanpy docs. **What's lost?**; - Docsearch; - Edit on github button (was weird anyway as no other package does that). **What's gained?**; - Aesthetics, easier to read; - Git submodule for tutorials; - sphinx.ext.viewcode so each function has a source button (effectively replaces edit on github button). **What else changed?**; - I removed the release latest stuff, not sure what value it was adding; - API docs are split logically. View the rendered docs here:. https://icb-scanpy--2220.com.readthedocs.build/en/2220/index.html. What's left to do:. - [x] Update tutorials index page to use nbgallery feature of nbsphinx; - [x] Make home index page use a grid of cards, two columns; - [x] Add to contributing guide how to manage the git submodule (really just occasionally do `git submodule update --remote`); - [x] Annotate CSS overrides; - [x] Exchange sphinx ext viewcode for linkcode (probably in scanpydoc)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220
https://github.com/scverse/scanpy/pull/2220:594,Deployability,Update,Update,594,"This is a version of Sphix-book-based scanpy docs. **What's lost?**; - Docsearch; - Edit on github button (was weird anyway as no other package does that). **What's gained?**; - Aesthetics, easier to read; - Git submodule for tutorials; - sphinx.ext.viewcode so each function has a source button (effectively replaces edit on github button). **What else changed?**; - I removed the release latest stuff, not sure what value it was adding; - API docs are split logically. View the rendered docs here:. https://icb-scanpy--2220.com.readthedocs.build/en/2220/index.html. What's left to do:. - [x] Update tutorials index page to use nbgallery feature of nbsphinx; - [x] Make home index page use a grid of cards, two columns; - [x] Add to contributing guide how to manage the git submodule (really just occasionally do `git submodule update --remote`); - [x] Annotate CSS overrides; - [x] Exchange sphinx ext viewcode for linkcode (probably in scanpydoc)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220
https://github.com/scverse/scanpy/pull/2220:829,Deployability,update,update,829,"This is a version of Sphix-book-based scanpy docs. **What's lost?**; - Docsearch; - Edit on github button (was weird anyway as no other package does that). **What's gained?**; - Aesthetics, easier to read; - Git submodule for tutorials; - sphinx.ext.viewcode so each function has a source button (effectively replaces edit on github button). **What else changed?**; - I removed the release latest stuff, not sure what value it was adding; - API docs are split logically. View the rendered docs here:. https://icb-scanpy--2220.com.readthedocs.build/en/2220/index.html. What's left to do:. - [x] Update tutorials index page to use nbgallery feature of nbsphinx; - [x] Make home index page use a grid of cards, two columns; - [x] Add to contributing guide how to manage the git submodule (really just occasionally do `git submodule update --remote`); - [x] Annotate CSS overrides; - [x] Exchange sphinx ext viewcode for linkcode (probably in scanpydoc)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220
https://github.com/scverse/scanpy/pull/2220:460,Testability,log,logically,460,"This is a version of Sphix-book-based scanpy docs. **What's lost?**; - Docsearch; - Edit on github button (was weird anyway as no other package does that). **What's gained?**; - Aesthetics, easier to read; - Git submodule for tutorials; - sphinx.ext.viewcode so each function has a source button (effectively replaces edit on github button). **What else changed?**; - I removed the release latest stuff, not sure what value it was adding; - API docs are split logically. View the rendered docs here:. https://icb-scanpy--2220.com.readthedocs.build/en/2220/index.html. What's left to do:. - [x] Update tutorials index page to use nbgallery feature of nbsphinx; - [x] Make home index page use a grid of cards, two columns; - [x] Add to contributing guide how to manage the git submodule (really just occasionally do `git submodule update --remote`); - [x] Annotate CSS overrides; - [x] Exchange sphinx ext viewcode for linkcode (probably in scanpydoc)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220
https://github.com/scverse/scanpy/pull/2220:747,Usability,guid,guide,747,"This is a version of Sphix-book-based scanpy docs. **What's lost?**; - Docsearch; - Edit on github button (was weird anyway as no other package does that). **What's gained?**; - Aesthetics, easier to read; - Git submodule for tutorials; - sphinx.ext.viewcode so each function has a source button (effectively replaces edit on github button). **What else changed?**; - I removed the release latest stuff, not sure what value it was adding; - API docs are split logically. View the rendered docs here:. https://icb-scanpy--2220.com.readthedocs.build/en/2220/index.html. What's left to do:. - [x] Update tutorials index page to use nbgallery feature of nbsphinx; - [x] Make home index page use a grid of cards, two columns; - [x] Add to contributing guide how to manage the git submodule (really just occasionally do `git submodule update --remote`); - [x] Annotate CSS overrides; - [x] Exchange sphinx ext viewcode for linkcode (probably in scanpydoc)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2220
https://github.com/scverse/scanpy/pull/2222:461,Deployability,install,installs,461,"Fixes #2211. Ill first try with all removed. I expect the min_tests run to fail. Seeing what fails,. - If its not much, Ill just refactor the fixtures a bit and so on; - Else Ill move algorithms to the `test` extra. Then we can merge this PR and over time refactor our tests so more and more extras go from `tests` to `tests-full`. @ivirshup do you like the collection extras names (`io`, `speedups`, `algorithms`)? Should we add an extra named `all` that installs all the `-full` extras?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2222
https://github.com/scverse/scanpy/pull/2222:132,Modifiability,refactor,refactor,132,"Fixes #2211. Ill first try with all removed. I expect the min_tests run to fail. Seeing what fails,. - If its not much, Ill just refactor the fixtures a bit and so on; - Else Ill move algorithms to the `test` extra. Then we can merge this PR and over time refactor our tests so more and more extras go from `tests` to `tests-full`. @ivirshup do you like the collection extras names (`io`, `speedups`, `algorithms`)? Should we add an extra named `all` that installs all the `-full` extras?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2222
https://github.com/scverse/scanpy/pull/2222:260,Modifiability,refactor,refactor,260,"Fixes #2211. Ill first try with all removed. I expect the min_tests run to fail. Seeing what fails,. - If its not much, Ill just refactor the fixtures a bit and so on; - Else Ill move algorithms to the `test` extra. Then we can merge this PR and over time refactor our tests so more and more extras go from `tests` to `tests-full`. @ivirshup do you like the collection extras names (`io`, `speedups`, `algorithms`)? Should we add an extra named `all` that installs all the `-full` extras?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2222
https://github.com/scverse/scanpy/pull/2222:207,Testability,test,test,207,"Fixes #2211. Ill first try with all removed. I expect the min_tests run to fail. Seeing what fails,. - If its not much, Ill just refactor the fixtures a bit and so on; - Else Ill move algorithms to the `test` extra. Then we can merge this PR and over time refactor our tests so more and more extras go from `tests` to `tests-full`. @ivirshup do you like the collection extras names (`io`, `speedups`, `algorithms`)? Should we add an extra named `all` that installs all the `-full` extras?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2222
https://github.com/scverse/scanpy/pull/2222:273,Testability,test,tests,273,"Fixes #2211. Ill first try with all removed. I expect the min_tests run to fail. Seeing what fails,. - If its not much, Ill just refactor the fixtures a bit and so on; - Else Ill move algorithms to the `test` extra. Then we can merge this PR and over time refactor our tests so more and more extras go from `tests` to `tests-full`. @ivirshup do you like the collection extras names (`io`, `speedups`, `algorithms`)? Should we add an extra named `all` that installs all the `-full` extras?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2222
https://github.com/scverse/scanpy/pull/2222:312,Testability,test,tests,312,"Fixes #2211. Ill first try with all removed. I expect the min_tests run to fail. Seeing what fails,. - If its not much, Ill just refactor the fixtures a bit and so on; - Else Ill move algorithms to the `test` extra. Then we can merge this PR and over time refactor our tests so more and more extras go from `tests` to `tests-full`. @ivirshup do you like the collection extras names (`io`, `speedups`, `algorithms`)? Should we add an extra named `all` that installs all the `-full` extras?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2222
https://github.com/scverse/scanpy/pull/2222:323,Testability,test,tests-full,323,"Fixes #2211. Ill first try with all removed. I expect the min_tests run to fail. Seeing what fails,. - If its not much, Ill just refactor the fixtures a bit and so on; - Else Ill move algorithms to the `test` extra. Then we can merge this PR and over time refactor our tests so more and more extras go from `tests` to `tests-full`. @ivirshup do you like the collection extras names (`io`, `speedups`, `algorithms`)? Should we add an extra named `all` that installs all the `-full` extras?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2222
https://github.com/scverse/scanpy/pull/2223:11,Deployability,release,release,11,Adding new release notes for 1.9.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2223
https://github.com/scverse/scanpy/issues/2225:566,Availability,error,error,566,"Pytest supports two test layouts, in-package and outside-of-package. I prefer the outside-of-package mode outlined here: https://docs.pytest.org/en/6.2.x/goodpractices.html. Scanpy currently mixes test utils with tests, but pytests test files (`test_*.py` and `conftest.py`) arent Python modules one is supposed to import from. To clean things up, we can refactor scanpy to a in-package structure:. - `pyproject.toml`: add `addopts = ['--import-mode=importlib']` to `[tool.pytest.ini_options]`; - `scanpy/tests/__init__.py` during implementation, make it throw an error on import so we can make sure nobody imports things from there, then delete; - `scanpy/tests/**/__init__.py` delete; - `scanpy/test_utils/` or `scanpy/testing/`; - `__init__.py`: leave empty for now, later add public, documented test utils; - `_private.py` add private test utils that can be imported in our tests, such as the `@needs_somepackage` decorators. Later we can decide if we want to keep the in-package layout or switch to the outside-of-package layout",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:357,Modifiability,refactor,refactor,357,"Pytest supports two test layouts, in-package and outside-of-package. I prefer the outside-of-package mode outlined here: https://docs.pytest.org/en/6.2.x/goodpractices.html. Scanpy currently mixes test utils with tests, but pytests test files (`test_*.py` and `conftest.py`) arent Python modules one is supposed to import from. To clean things up, we can refactor scanpy to a in-package structure:. - `pyproject.toml`: add `addopts = ['--import-mode=importlib']` to `[tool.pytest.ini_options]`; - `scanpy/tests/__init__.py` during implementation, make it throw an error on import so we can make sure nobody imports things from there, then delete; - `scanpy/tests/**/__init__.py` delete; - `scanpy/test_utils/` or `scanpy/testing/`; - `__init__.py`: leave empty for now, later add public, documented test utils; - `_private.py` add private test utils that can be imported in our tests, such as the `@needs_somepackage` decorators. Later we can decide if we want to keep the in-package layout or switch to the outside-of-package layout",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:20,Testability,test,test,20,"Pytest supports two test layouts, in-package and outside-of-package. I prefer the outside-of-package mode outlined here: https://docs.pytest.org/en/6.2.x/goodpractices.html. Scanpy currently mixes test utils with tests, but pytests test files (`test_*.py` and `conftest.py`) arent Python modules one is supposed to import from. To clean things up, we can refactor scanpy to a in-package structure:. - `pyproject.toml`: add `addopts = ['--import-mode=importlib']` to `[tool.pytest.ini_options]`; - `scanpy/tests/__init__.py` during implementation, make it throw an error on import so we can make sure nobody imports things from there, then delete; - `scanpy/tests/**/__init__.py` delete; - `scanpy/test_utils/` or `scanpy/testing/`; - `__init__.py`: leave empty for now, later add public, documented test utils; - `_private.py` add private test utils that can be imported in our tests, such as the `@needs_somepackage` decorators. Later we can decide if we want to keep the in-package layout or switch to the outside-of-package layout",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:197,Testability,test,test,197,"Pytest supports two test layouts, in-package and outside-of-package. I prefer the outside-of-package mode outlined here: https://docs.pytest.org/en/6.2.x/goodpractices.html. Scanpy currently mixes test utils with tests, but pytests test files (`test_*.py` and `conftest.py`) arent Python modules one is supposed to import from. To clean things up, we can refactor scanpy to a in-package structure:. - `pyproject.toml`: add `addopts = ['--import-mode=importlib']` to `[tool.pytest.ini_options]`; - `scanpy/tests/__init__.py` during implementation, make it throw an error on import so we can make sure nobody imports things from there, then delete; - `scanpy/tests/**/__init__.py` delete; - `scanpy/test_utils/` or `scanpy/testing/`; - `__init__.py`: leave empty for now, later add public, documented test utils; - `_private.py` add private test utils that can be imported in our tests, such as the `@needs_somepackage` decorators. Later we can decide if we want to keep the in-package layout or switch to the outside-of-package layout",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:213,Testability,test,tests,213,"Pytest supports two test layouts, in-package and outside-of-package. I prefer the outside-of-package mode outlined here: https://docs.pytest.org/en/6.2.x/goodpractices.html. Scanpy currently mixes test utils with tests, but pytests test files (`test_*.py` and `conftest.py`) arent Python modules one is supposed to import from. To clean things up, we can refactor scanpy to a in-package structure:. - `pyproject.toml`: add `addopts = ['--import-mode=importlib']` to `[tool.pytest.ini_options]`; - `scanpy/tests/__init__.py` during implementation, make it throw an error on import so we can make sure nobody imports things from there, then delete; - `scanpy/tests/**/__init__.py` delete; - `scanpy/test_utils/` or `scanpy/testing/`; - `__init__.py`: leave empty for now, later add public, documented test utils; - `_private.py` add private test utils that can be imported in our tests, such as the `@needs_somepackage` decorators. Later we can decide if we want to keep the in-package layout or switch to the outside-of-package layout",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:233,Testability,test,test,233,"Pytest supports two test layouts, in-package and outside-of-package. I prefer the outside-of-package mode outlined here: https://docs.pytest.org/en/6.2.x/goodpractices.html. Scanpy currently mixes test utils with tests, but pytests test files (`test_*.py` and `conftest.py`) arent Python modules one is supposed to import from. To clean things up, we can refactor scanpy to a in-package structure:. - `pyproject.toml`: add `addopts = ['--import-mode=importlib']` to `[tool.pytest.ini_options]`; - `scanpy/tests/__init__.py` during implementation, make it throw an error on import so we can make sure nobody imports things from there, then delete; - `scanpy/tests/**/__init__.py` delete; - `scanpy/test_utils/` or `scanpy/testing/`; - `__init__.py`: leave empty for now, later add public, documented test utils; - `_private.py` add private test utils that can be imported in our tests, such as the `@needs_somepackage` decorators. Later we can decide if we want to keep the in-package layout or switch to the outside-of-package layout",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:507,Testability,test,tests,507,"Pytest supports two test layouts, in-package and outside-of-package. I prefer the outside-of-package mode outlined here: https://docs.pytest.org/en/6.2.x/goodpractices.html. Scanpy currently mixes test utils with tests, but pytests test files (`test_*.py` and `conftest.py`) arent Python modules one is supposed to import from. To clean things up, we can refactor scanpy to a in-package structure:. - `pyproject.toml`: add `addopts = ['--import-mode=importlib']` to `[tool.pytest.ini_options]`; - `scanpy/tests/__init__.py` during implementation, make it throw an error on import so we can make sure nobody imports things from there, then delete; - `scanpy/tests/**/__init__.py` delete; - `scanpy/test_utils/` or `scanpy/testing/`; - `__init__.py`: leave empty for now, later add public, documented test utils; - `_private.py` add private test utils that can be imported in our tests, such as the `@needs_somepackage` decorators. Later we can decide if we want to keep the in-package layout or switch to the outside-of-package layout",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:659,Testability,test,tests,659,"Pytest supports two test layouts, in-package and outside-of-package. I prefer the outside-of-package mode outlined here: https://docs.pytest.org/en/6.2.x/goodpractices.html. Scanpy currently mixes test utils with tests, but pytests test files (`test_*.py` and `conftest.py`) arent Python modules one is supposed to import from. To clean things up, we can refactor scanpy to a in-package structure:. - `pyproject.toml`: add `addopts = ['--import-mode=importlib']` to `[tool.pytest.ini_options]`; - `scanpy/tests/__init__.py` during implementation, make it throw an error on import so we can make sure nobody imports things from there, then delete; - `scanpy/tests/**/__init__.py` delete; - `scanpy/test_utils/` or `scanpy/testing/`; - `__init__.py`: leave empty for now, later add public, documented test utils; - `_private.py` add private test utils that can be imported in our tests, such as the `@needs_somepackage` decorators. Later we can decide if we want to keep the in-package layout or switch to the outside-of-package layout",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:723,Testability,test,testing,723,"Pytest supports two test layouts, in-package and outside-of-package. I prefer the outside-of-package mode outlined here: https://docs.pytest.org/en/6.2.x/goodpractices.html. Scanpy currently mixes test utils with tests, but pytests test files (`test_*.py` and `conftest.py`) arent Python modules one is supposed to import from. To clean things up, we can refactor scanpy to a in-package structure:. - `pyproject.toml`: add `addopts = ['--import-mode=importlib']` to `[tool.pytest.ini_options]`; - `scanpy/tests/__init__.py` during implementation, make it throw an error on import so we can make sure nobody imports things from there, then delete; - `scanpy/tests/**/__init__.py` delete; - `scanpy/test_utils/` or `scanpy/testing/`; - `__init__.py`: leave empty for now, later add public, documented test utils; - `_private.py` add private test utils that can be imported in our tests, such as the `@needs_somepackage` decorators. Later we can decide if we want to keep the in-package layout or switch to the outside-of-package layout",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:801,Testability,test,test,801,"Pytest supports two test layouts, in-package and outside-of-package. I prefer the outside-of-package mode outlined here: https://docs.pytest.org/en/6.2.x/goodpractices.html. Scanpy currently mixes test utils with tests, but pytests test files (`test_*.py` and `conftest.py`) arent Python modules one is supposed to import from. To clean things up, we can refactor scanpy to a in-package structure:. - `pyproject.toml`: add `addopts = ['--import-mode=importlib']` to `[tool.pytest.ini_options]`; - `scanpy/tests/__init__.py` during implementation, make it throw an error on import so we can make sure nobody imports things from there, then delete; - `scanpy/tests/**/__init__.py` delete; - `scanpy/test_utils/` or `scanpy/testing/`; - `__init__.py`: leave empty for now, later add public, documented test utils; - `_private.py` add private test utils that can be imported in our tests, such as the `@needs_somepackage` decorators. Later we can decide if we want to keep the in-package layout or switch to the outside-of-package layout",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:841,Testability,test,test,841,"Pytest supports two test layouts, in-package and outside-of-package. I prefer the outside-of-package mode outlined here: https://docs.pytest.org/en/6.2.x/goodpractices.html. Scanpy currently mixes test utils with tests, but pytests test files (`test_*.py` and `conftest.py`) arent Python modules one is supposed to import from. To clean things up, we can refactor scanpy to a in-package structure:. - `pyproject.toml`: add `addopts = ['--import-mode=importlib']` to `[tool.pytest.ini_options]`; - `scanpy/tests/__init__.py` during implementation, make it throw an error on import so we can make sure nobody imports things from there, then delete; - `scanpy/tests/**/__init__.py` delete; - `scanpy/test_utils/` or `scanpy/testing/`; - `__init__.py`: leave empty for now, later add public, documented test utils; - `_private.py` add private test utils that can be imported in our tests, such as the `@needs_somepackage` decorators. Later we can decide if we want to keep the in-package layout or switch to the outside-of-package layout",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/issues/2225:880,Testability,test,tests,880,"Pytest supports two test layouts, in-package and outside-of-package. I prefer the outside-of-package mode outlined here: https://docs.pytest.org/en/6.2.x/goodpractices.html. Scanpy currently mixes test utils with tests, but pytests test files (`test_*.py` and `conftest.py`) arent Python modules one is supposed to import from. To clean things up, we can refactor scanpy to a in-package structure:. - `pyproject.toml`: add `addopts = ['--import-mode=importlib']` to `[tool.pytest.ini_options]`; - `scanpy/tests/__init__.py` during implementation, make it throw an error on import so we can make sure nobody imports things from there, then delete; - `scanpy/tests/**/__init__.py` delete; - `scanpy/test_utils/` or `scanpy/testing/`; - `__init__.py`: leave empty for now, later add public, documented test utils; - `_private.py` add private test utils that can be imported in our tests, such as the `@needs_somepackage` decorators. Later we can decide if we want to keep the in-package layout or switch to the outside-of-package layout",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2225
https://github.com/scverse/scanpy/pull/2226:43,Integrability,depend,dependencies,43,Backport PR #2222: Add CI job with minimal dependencies,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2226
https://github.com/scverse/scanpy/issues/2229:257,Usability,guid,guide,257,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. In the documentation at https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.embedding.html#scanpy.pl.embedding, the description of the ""legend_loc"" param is as follows:. > legend_loc : [str](https://docs.python.org/3/library/stdtypes.html#str) (default: 'right margin'); > Location of legend, either 'on data', 'right margin' **or a valid keyword for the loc parameter of [Legend](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend).**. The part in bold does not seem to be implemented, as the ""legend_loc"" only has if/elif conditions for it is ""right margin"" or ""on data""... nothing for the matplotlib ""loc"" keywords. I am not sure if it is best to implement this to match the description, or change the description to omit the part in bold. ### Minimal code sample (that we can copy&paste without having any data); https://github.com/scverse/scanpy/blob/2e98705347ea484c36caa9ba10de1987b09081bf/scanpy/plotting/_tools/scatterplots.py#L55-L461. https://github.com/scverse/scanpy/blob/2e98705347ea484c36caa9ba10de1987b09081bf/scanpy/plotting/_tools/scatterplots.py#L1099-L1109. #### Versions. Not applicable",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2229
https://github.com/scverse/scanpy/issues/2230:698,Availability,error,error,698,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. If there are very few genes some of the bins in `sc.pp.highly_variable_genes(adata, n_top_genes=1000, flavor=""cell_ranger"")` can contain a single gene leading to `NaN` values in the normalized expression vector which are removed here https://github.com/scverse/scanpy/blob/9018e16cae6f3199f914f58841b00a00790cd494/scanpy/preprocessing/_highly_variable_genes.py#L261. If after this filtering the dispersion vector is shorter then than `n_top_genes` there is an indexing error when selecting the dispersion cutoff here https://github.com/scverse/scanpy/blob/9018e16cae6f3199f914f58841b00a00790cd494/scanpy/preprocessing/_highly_variable_genes.py#L268. There should probably be a check (with a warning) when this happens. ### Minimal code sample (that we can copy&paste without having any data). ```python; import anndata; import numpy as np; import scanpy as sc. adata = anndata.AnnData(np.random.poisson(2, (100, 30))); sc.pp.normalize_total(adata); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, n_top_genes=1000, flavor=""cell_ranger""); ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes; df = _highly_variable_genes_single_batch(; File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 268, in _highly_variable_genes_single_batch; disp_cut_off = dispersion_norm[n_top_genes - 1]; IndexError: index 29 is out of bounds for axis 0 with size 21; ```. #### Versions. <details>. -----; anndata 0.7.8; scanpy 1.9.1; -----; PIL 9.1.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2230
https://github.com/scverse/scanpy/issues/2230:2626,Deployability,update,updated,2626,"_top_genes` there is an indexing error when selecting the dispersion cutoff here https://github.com/scverse/scanpy/blob/9018e16cae6f3199f914f58841b00a00790cd494/scanpy/preprocessing/_highly_variable_genes.py#L268. There should probably be a check (with a warning) when this happens. ### Minimal code sample (that we can copy&paste without having any data). ```python; import anndata; import numpy as np; import scanpy as sc. adata = anndata.AnnData(np.random.poisson(2, (100, 30))); sc.pp.normalize_total(adata); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, n_top_genes=1000, flavor=""cell_ranger""); ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes; df = _highly_variable_genes_single_batch(; File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 268, in _highly_variable_genes_single_batch; disp_cut_off = dispersion_norm[n_top_genes - 1]; IndexError: index 29 is out of bounds for axis 0 with size 21; ```. #### Versions. <details>. -----; anndata 0.7.8; scanpy 1.9.1; -----; PIL 9.1.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1; google NA; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.9; joblib 1.1.0; kiwisolver 1.4.2; llvmlite 0.38.0; louvain 0.7.1; matplotlib 3.5.1; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numpy 1.21.5; packaging 21.3; pandas 1.4.2; pkg_resources NA; psutil 5.9.0; pyparsing 3.0.8; pytz 2022.1; scipy 1.8.0; session_info 1.0.0; six 1.16.0; sklearn 1.0.2; statsmodels 0.13.2; texttable 1.6.4; threadpoolctl 3.1.0; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; -----; Python 3.8.13 (default, Apr 7 2022, 04:56:26) [GCC 10.2.1 20210110]; Linux-5.10.76-linuxkit-x86_64-with-glibc2.2.5; -----; Session information updated at 2022-04-11 12:44. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2230
https://github.com/scverse/scanpy/pull/2232:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/pre-commit/pre-commit-hooks: v4.1.0  v4.2.0](https://github.com/pre-commit/pre-commit-hooks/compare/v4.1.0...v4.2.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2232
https://github.com/scverse/scanpy/issues/2234:44,Availability,mask,mask,44,"I think we should introduce a standardized mask argument to scanpy functions. This would be a boolean array (or reference to a boolean array in `obs`/ `var`) which masks out certain data entries. This can be thought of as a generalization of how highly variable genes is handled. As an example:. ```python; sc.pp.pca(adata, use_highly_variable=True); ```. Would be equivalent to:. ```python; sc.pp.pca(adata, mask=""highly_variable""); # or; sc.pp.pca(adata, mask=adata.obs[""highly_variable""]); ```. One of the big advantages of making this more widespread is that tasks which previously required using `.raw` or creating new anndata objects will be much easier. Some uses for this change:. ### Plotting. A big one is plotting. Right now if you want to show gene expression for a subset of cells, you have to manually work with the Matplotlib Axes:. ```python; ax = sc.pl.umap(pbmc, show=False); sc.pl.umap(; pbmc[pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells',])],; color=""LDHB"",; ax=ax,; ); ```. If a user could provide a mask, this could be reduced, and would make plotting more than one value possible:. ```python; sc.pl.umap(; pbmc,; color=['LDHB', 'LYZ', 'CD79A],; mask=pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells,]),; ); ```. ### Other uses. This has come up before in a few contexts:. * Performing normalization on just some variables https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522; * Selecting a subset of variables for DE tests: https://github.com/scverse/scanpy/issues/1744; * See also https://github.com/scverse/scanpy/issues/748; * Changing use_raw https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988. ## Implementation. I think this could fit quite well into the `sc.get` getter/ validation functions (https://github.com/scverse/scanpy/issues/828#issuecomment-560072919).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:166,Availability,mask,masks,166,"I think we should introduce a standardized mask argument to scanpy functions. This would be a boolean array (or reference to a boolean array in `obs`/ `var`) which masks out certain data entries. This can be thought of as a generalization of how highly variable genes is handled. As an example:. ```python; sc.pp.pca(adata, use_highly_variable=True); ```. Would be equivalent to:. ```python; sc.pp.pca(adata, mask=""highly_variable""); # or; sc.pp.pca(adata, mask=adata.obs[""highly_variable""]); ```. One of the big advantages of making this more widespread is that tasks which previously required using `.raw` or creating new anndata objects will be much easier. Some uses for this change:. ### Plotting. A big one is plotting. Right now if you want to show gene expression for a subset of cells, you have to manually work with the Matplotlib Axes:. ```python; ax = sc.pl.umap(pbmc, show=False); sc.pl.umap(; pbmc[pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells',])],; color=""LDHB"",; ax=ax,; ); ```. If a user could provide a mask, this could be reduced, and would make plotting more than one value possible:. ```python; sc.pl.umap(; pbmc,; color=['LDHB', 'LYZ', 'CD79A],; mask=pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells,]),; ); ```. ### Other uses. This has come up before in a few contexts:. * Performing normalization on just some variables https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522; * Selecting a subset of variables for DE tests: https://github.com/scverse/scanpy/issues/1744; * See also https://github.com/scverse/scanpy/issues/748; * Changing use_raw https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988. ## Implementation. I think this could fit quite well into the `sc.get` getter/ validation functions (https://github.com/scverse/scanpy/issues/828#issuecomment-560072919).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:411,Availability,mask,mask,411,"I think we should introduce a standardized mask argument to scanpy functions. This would be a boolean array (or reference to a boolean array in `obs`/ `var`) which masks out certain data entries. This can be thought of as a generalization of how highly variable genes is handled. As an example:. ```python; sc.pp.pca(adata, use_highly_variable=True); ```. Would be equivalent to:. ```python; sc.pp.pca(adata, mask=""highly_variable""); # or; sc.pp.pca(adata, mask=adata.obs[""highly_variable""]); ```. One of the big advantages of making this more widespread is that tasks which previously required using `.raw` or creating new anndata objects will be much easier. Some uses for this change:. ### Plotting. A big one is plotting. Right now if you want to show gene expression for a subset of cells, you have to manually work with the Matplotlib Axes:. ```python; ax = sc.pl.umap(pbmc, show=False); sc.pl.umap(; pbmc[pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells',])],; color=""LDHB"",; ax=ax,; ); ```. If a user could provide a mask, this could be reduced, and would make plotting more than one value possible:. ```python; sc.pl.umap(; pbmc,; color=['LDHB', 'LYZ', 'CD79A],; mask=pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells,]),; ); ```. ### Other uses. This has come up before in a few contexts:. * Performing normalization on just some variables https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522; * Selecting a subset of variables for DE tests: https://github.com/scverse/scanpy/issues/1744; * See also https://github.com/scverse/scanpy/issues/748; * Changing use_raw https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988. ## Implementation. I think this could fit quite well into the `sc.get` getter/ validation functions (https://github.com/scverse/scanpy/issues/828#issuecomment-560072919).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:459,Availability,mask,mask,459,"I think we should introduce a standardized mask argument to scanpy functions. This would be a boolean array (or reference to a boolean array in `obs`/ `var`) which masks out certain data entries. This can be thought of as a generalization of how highly variable genes is handled. As an example:. ```python; sc.pp.pca(adata, use_highly_variable=True); ```. Would be equivalent to:. ```python; sc.pp.pca(adata, mask=""highly_variable""); # or; sc.pp.pca(adata, mask=adata.obs[""highly_variable""]); ```. One of the big advantages of making this more widespread is that tasks which previously required using `.raw` or creating new anndata objects will be much easier. Some uses for this change:. ### Plotting. A big one is plotting. Right now if you want to show gene expression for a subset of cells, you have to manually work with the Matplotlib Axes:. ```python; ax = sc.pl.umap(pbmc, show=False); sc.pl.umap(; pbmc[pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells',])],; color=""LDHB"",; ax=ax,; ); ```. If a user could provide a mask, this could be reduced, and would make plotting more than one value possible:. ```python; sc.pl.umap(; pbmc,; color=['LDHB', 'LYZ', 'CD79A],; mask=pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells,]),; ); ```. ### Other uses. This has come up before in a few contexts:. * Performing normalization on just some variables https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522; * Selecting a subset of variables for DE tests: https://github.com/scverse/scanpy/issues/1744; * See also https://github.com/scverse/scanpy/issues/748; * Changing use_raw https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988. ## Implementation. I think this could fit quite well into the `sc.get` getter/ validation functions (https://github.com/scverse/scanpy/issues/828#issuecomment-560072919).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:1043,Availability,mask,mask,1043,"I think we should introduce a standardized mask argument to scanpy functions. This would be a boolean array (or reference to a boolean array in `obs`/ `var`) which masks out certain data entries. This can be thought of as a generalization of how highly variable genes is handled. As an example:. ```python; sc.pp.pca(adata, use_highly_variable=True); ```. Would be equivalent to:. ```python; sc.pp.pca(adata, mask=""highly_variable""); # or; sc.pp.pca(adata, mask=adata.obs[""highly_variable""]); ```. One of the big advantages of making this more widespread is that tasks which previously required using `.raw` or creating new anndata objects will be much easier. Some uses for this change:. ### Plotting. A big one is plotting. Right now if you want to show gene expression for a subset of cells, you have to manually work with the Matplotlib Axes:. ```python; ax = sc.pl.umap(pbmc, show=False); sc.pl.umap(; pbmc[pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells',])],; color=""LDHB"",; ax=ax,; ); ```. If a user could provide a mask, this could be reduced, and would make plotting more than one value possible:. ```python; sc.pl.umap(; pbmc,; color=['LDHB', 'LYZ', 'CD79A],; mask=pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells,]),; ); ```. ### Other uses. This has come up before in a few contexts:. * Performing normalization on just some variables https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522; * Selecting a subset of variables for DE tests: https://github.com/scverse/scanpy/issues/1744; * See also https://github.com/scverse/scanpy/issues/748; * Changing use_raw https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988. ## Implementation. I think this could fit quite well into the `sc.get` getter/ validation functions (https://github.com/scverse/scanpy/issues/828#issuecomment-560072919).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:1191,Availability,mask,mask,1191,"I think we should introduce a standardized mask argument to scanpy functions. This would be a boolean array (or reference to a boolean array in `obs`/ `var`) which masks out certain data entries. This can be thought of as a generalization of how highly variable genes is handled. As an example:. ```python; sc.pp.pca(adata, use_highly_variable=True); ```. Would be equivalent to:. ```python; sc.pp.pca(adata, mask=""highly_variable""); # or; sc.pp.pca(adata, mask=adata.obs[""highly_variable""]); ```. One of the big advantages of making this more widespread is that tasks which previously required using `.raw` or creating new anndata objects will be much easier. Some uses for this change:. ### Plotting. A big one is plotting. Right now if you want to show gene expression for a subset of cells, you have to manually work with the Matplotlib Axes:. ```python; ax = sc.pl.umap(pbmc, show=False); sc.pl.umap(; pbmc[pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells',])],; color=""LDHB"",; ax=ax,; ); ```. If a user could provide a mask, this could be reduced, and would make plotting more than one value possible:. ```python; sc.pl.umap(; pbmc,; color=['LDHB', 'LYZ', 'CD79A],; mask=pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells,]),; ); ```. ### Other uses. This has come up before in a few contexts:. * Performing normalization on just some variables https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522; * Selecting a subset of variables for DE tests: https://github.com/scverse/scanpy/issues/1744; * See also https://github.com/scverse/scanpy/issues/748; * Changing use_raw https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988. ## Implementation. I think this could fit quite well into the `sc.get` getter/ validation functions (https://github.com/scverse/scanpy/issues/828#issuecomment-560072919).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:1063,Energy Efficiency,reduce,reduced,1063,"I think we should introduce a standardized mask argument to scanpy functions. This would be a boolean array (or reference to a boolean array in `obs`/ `var`) which masks out certain data entries. This can be thought of as a generalization of how highly variable genes is handled. As an example:. ```python; sc.pp.pca(adata, use_highly_variable=True); ```. Would be equivalent to:. ```python; sc.pp.pca(adata, mask=""highly_variable""); # or; sc.pp.pca(adata, mask=adata.obs[""highly_variable""]); ```. One of the big advantages of making this more widespread is that tasks which previously required using `.raw` or creating new anndata objects will be much easier. Some uses for this change:. ### Plotting. A big one is plotting. Right now if you want to show gene expression for a subset of cells, you have to manually work with the Matplotlib Axes:. ```python; ax = sc.pl.umap(pbmc, show=False); sc.pl.umap(; pbmc[pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells',])],; color=""LDHB"",; ax=ax,; ); ```. If a user could provide a mask, this could be reduced, and would make plotting more than one value possible:. ```python; sc.pl.umap(; pbmc,; color=['LDHB', 'LYZ', 'CD79A],; mask=pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells,]),; ); ```. ### Other uses. This has come up before in a few contexts:. * Performing normalization on just some variables https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522; * Selecting a subset of variables for DE tests: https://github.com/scverse/scanpy/issues/1744; * See also https://github.com/scverse/scanpy/issues/748; * Changing use_raw https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988. ## Implementation. I think this could fit quite well into the `sc.get` getter/ validation functions (https://github.com/scverse/scanpy/issues/828#issuecomment-560072919).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:255,Modifiability,variab,variable,255,"I think we should introduce a standardized mask argument to scanpy functions. This would be a boolean array (or reference to a boolean array in `obs`/ `var`) which masks out certain data entries. This can be thought of as a generalization of how highly variable genes is handled. As an example:. ```python; sc.pp.pca(adata, use_highly_variable=True); ```. Would be equivalent to:. ```python; sc.pp.pca(adata, mask=""highly_variable""); # or; sc.pp.pca(adata, mask=adata.obs[""highly_variable""]); ```. One of the big advantages of making this more widespread is that tasks which previously required using `.raw` or creating new anndata objects will be much easier. Some uses for this change:. ### Plotting. A big one is plotting. Right now if you want to show gene expression for a subset of cells, you have to manually work with the Matplotlib Axes:. ```python; ax = sc.pl.umap(pbmc, show=False); sc.pl.umap(; pbmc[pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells',])],; color=""LDHB"",; ax=ax,; ); ```. If a user could provide a mask, this could be reduced, and would make plotting more than one value possible:. ```python; sc.pl.umap(; pbmc,; color=['LDHB', 'LYZ', 'CD79A],; mask=pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells,]),; ); ```. ### Other uses. This has come up before in a few contexts:. * Performing normalization on just some variables https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522; * Selecting a subset of variables for DE tests: https://github.com/scverse/scanpy/issues/1744; * See also https://github.com/scverse/scanpy/issues/748; * Changing use_raw https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988. ## Implementation. I think this could fit quite well into the `sc.get` getter/ validation functions (https://github.com/scverse/scanpy/issues/828#issuecomment-560072919).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:1375,Modifiability,variab,variables,1375,"I think we should introduce a standardized mask argument to scanpy functions. This would be a boolean array (or reference to a boolean array in `obs`/ `var`) which masks out certain data entries. This can be thought of as a generalization of how highly variable genes is handled. As an example:. ```python; sc.pp.pca(adata, use_highly_variable=True); ```. Would be equivalent to:. ```python; sc.pp.pca(adata, mask=""highly_variable""); # or; sc.pp.pca(adata, mask=adata.obs[""highly_variable""]); ```. One of the big advantages of making this more widespread is that tasks which previously required using `.raw` or creating new anndata objects will be much easier. Some uses for this change:. ### Plotting. A big one is plotting. Right now if you want to show gene expression for a subset of cells, you have to manually work with the Matplotlib Axes:. ```python; ax = sc.pl.umap(pbmc, show=False); sc.pl.umap(; pbmc[pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells',])],; color=""LDHB"",; ax=ax,; ); ```. If a user could provide a mask, this could be reduced, and would make plotting more than one value possible:. ```python; sc.pl.umap(; pbmc,; color=['LDHB', 'LYZ', 'CD79A],; mask=pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells,]),; ); ```. ### Other uses. This has come up before in a few contexts:. * Performing normalization on just some variables https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522; * Selecting a subset of variables for DE tests: https://github.com/scverse/scanpy/issues/1744; * See also https://github.com/scverse/scanpy/issues/748; * Changing use_raw https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988. ## Implementation. I think this could fit quite well into the `sc.get` getter/ validation functions (https://github.com/scverse/scanpy/issues/828#issuecomment-560072919).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:1480,Modifiability,variab,variables,1480,"I think we should introduce a standardized mask argument to scanpy functions. This would be a boolean array (or reference to a boolean array in `obs`/ `var`) which masks out certain data entries. This can be thought of as a generalization of how highly variable genes is handled. As an example:. ```python; sc.pp.pca(adata, use_highly_variable=True); ```. Would be equivalent to:. ```python; sc.pp.pca(adata, mask=""highly_variable""); # or; sc.pp.pca(adata, mask=adata.obs[""highly_variable""]); ```. One of the big advantages of making this more widespread is that tasks which previously required using `.raw` or creating new anndata objects will be much easier. Some uses for this change:. ### Plotting. A big one is plotting. Right now if you want to show gene expression for a subset of cells, you have to manually work with the Matplotlib Axes:. ```python; ax = sc.pl.umap(pbmc, show=False); sc.pl.umap(; pbmc[pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells',])],; color=""LDHB"",; ax=ax,; ); ```. If a user could provide a mask, this could be reduced, and would make plotting more than one value possible:. ```python; sc.pl.umap(; pbmc,; color=['LDHB', 'LYZ', 'CD79A],; mask=pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells,]),; ); ```. ### Other uses. This has come up before in a few contexts:. * Performing normalization on just some variables https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522; * Selecting a subset of variables for DE tests: https://github.com/scverse/scanpy/issues/1744; * See also https://github.com/scverse/scanpy/issues/748; * Changing use_raw https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988. ## Implementation. I think this could fit quite well into the `sc.get` getter/ validation functions (https://github.com/scverse/scanpy/issues/828#issuecomment-560072919).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:1337,Performance,Perform,Performing,1337,"I think we should introduce a standardized mask argument to scanpy functions. This would be a boolean array (or reference to a boolean array in `obs`/ `var`) which masks out certain data entries. This can be thought of as a generalization of how highly variable genes is handled. As an example:. ```python; sc.pp.pca(adata, use_highly_variable=True); ```. Would be equivalent to:. ```python; sc.pp.pca(adata, mask=""highly_variable""); # or; sc.pp.pca(adata, mask=adata.obs[""highly_variable""]); ```. One of the big advantages of making this more widespread is that tasks which previously required using `.raw` or creating new anndata objects will be much easier. Some uses for this change:. ### Plotting. A big one is plotting. Right now if you want to show gene expression for a subset of cells, you have to manually work with the Matplotlib Axes:. ```python; ax = sc.pl.umap(pbmc, show=False); sc.pl.umap(; pbmc[pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells',])],; color=""LDHB"",; ax=ax,; ); ```. If a user could provide a mask, this could be reduced, and would make plotting more than one value possible:. ```python; sc.pl.umap(; pbmc,; color=['LDHB', 'LYZ', 'CD79A],; mask=pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells,]),; ); ```. ### Other uses. This has come up before in a few contexts:. * Performing normalization on just some variables https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522; * Selecting a subset of variables for DE tests: https://github.com/scverse/scanpy/issues/1744; * See also https://github.com/scverse/scanpy/issues/748; * Changing use_raw https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988. ## Implementation. I think this could fit quite well into the `sc.get` getter/ validation functions (https://github.com/scverse/scanpy/issues/828#issuecomment-560072919).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:1776,Security,validat,validation,1776,"I think we should introduce a standardized mask argument to scanpy functions. This would be a boolean array (or reference to a boolean array in `obs`/ `var`) which masks out certain data entries. This can be thought of as a generalization of how highly variable genes is handled. As an example:. ```python; sc.pp.pca(adata, use_highly_variable=True); ```. Would be equivalent to:. ```python; sc.pp.pca(adata, mask=""highly_variable""); # or; sc.pp.pca(adata, mask=adata.obs[""highly_variable""]); ```. One of the big advantages of making this more widespread is that tasks which previously required using `.raw` or creating new anndata objects will be much easier. Some uses for this change:. ### Plotting. A big one is plotting. Right now if you want to show gene expression for a subset of cells, you have to manually work with the Matplotlib Axes:. ```python; ax = sc.pl.umap(pbmc, show=False); sc.pl.umap(; pbmc[pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells',])],; color=""LDHB"",; ax=ax,; ); ```. If a user could provide a mask, this could be reduced, and would make plotting more than one value possible:. ```python; sc.pl.umap(; pbmc,; color=['LDHB', 'LYZ', 'CD79A],; mask=pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells,]),; ); ```. ### Other uses. This has come up before in a few contexts:. * Performing normalization on just some variables https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522; * Selecting a subset of variables for DE tests: https://github.com/scverse/scanpy/issues/1744; * See also https://github.com/scverse/scanpy/issues/748; * Changing use_raw https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988. ## Implementation. I think this could fit quite well into the `sc.get` getter/ validation functions (https://github.com/scverse/scanpy/issues/828#issuecomment-560072919).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/issues/2234:1497,Testability,test,tests,1497,"I think we should introduce a standardized mask argument to scanpy functions. This would be a boolean array (or reference to a boolean array in `obs`/ `var`) which masks out certain data entries. This can be thought of as a generalization of how highly variable genes is handled. As an example:. ```python; sc.pp.pca(adata, use_highly_variable=True); ```. Would be equivalent to:. ```python; sc.pp.pca(adata, mask=""highly_variable""); # or; sc.pp.pca(adata, mask=adata.obs[""highly_variable""]); ```. One of the big advantages of making this more widespread is that tasks which previously required using `.raw` or creating new anndata objects will be much easier. Some uses for this change:. ### Plotting. A big one is plotting. Right now if you want to show gene expression for a subset of cells, you have to manually work with the Matplotlib Axes:. ```python; ax = sc.pl.umap(pbmc, show=False); sc.pl.umap(; pbmc[pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells',])],; color=""LDHB"",; ax=ax,; ); ```. If a user could provide a mask, this could be reduced, and would make plotting more than one value possible:. ```python; sc.pl.umap(; pbmc,; color=['LDHB', 'LYZ', 'CD79A],; mask=pbmc.obs[""louvain""].isin(['CD4 T cells', 'B cells', 'CD8 T cells,]),; ); ```. ### Other uses. This has come up before in a few contexts:. * Performing normalization on just some variables https://github.com/scverse/scanpy/issues/2142#issuecomment-1046729522; * Selecting a subset of variables for DE tests: https://github.com/scverse/scanpy/issues/1744; * See also https://github.com/scverse/scanpy/issues/748; * Changing use_raw https://github.com/scverse/scanpy/issues/1798#issuecomment-819998988. ## Implementation. I think this could fit quite well into the `sc.get` getter/ validation functions (https://github.com/scverse/scanpy/issues/828#issuecomment-560072919).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2234
https://github.com/scverse/scanpy/pull/2235:157,Integrability,depend,dependencies,157,"This is basically the minimum amount of changes to separate things out and fix some problems with the test setup, plus unification of how we handle optional dependencies in tests. Fixes #2225",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:102,Testability,test,test,102,"This is basically the minimum amount of changes to separate things out and fix some problems with the test setup, plus unification of how we handle optional dependencies in tests. Fixes #2225",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/pull/2235:173,Testability,test,tests,173,"This is basically the minimum amount of changes to separate things out and fix some problems with the test setup, plus unification of how we handle optional dependencies in tests. Fixes #2225",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2235
https://github.com/scverse/scanpy/issues/2236:422,Availability,error,error,422,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am running the standard scrnaseq pipeline on some data and am experiencing an issue. When I run. ```py; sc.pp.highly_variable_genes(adata,n_top_genes=4000, batch_key='batch'); ```. I get the error. ```; If you pass `n_top_genes`, all cutoffs are ignored.; extracting highly variable genes; ZeroDivisionError: division by zero; ```. I've unfortunately never seen this before, and i'm not sure how to address it. I would love if someone could help with this. Some additional information on my data. ```pycon; >>> adata.X.shape; Out[21]: (3433, 16836). >>> adata.X; array([[0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; ...,; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.]], dtype=float32); ```. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; AlexFunctions NA; JonFunctions NA; PIL 9.1.0; PyQt5 NA; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bs4 4.11.1; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.1; import_all NA; ipykernel 6.13.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.2; leidenalg 0.8.4; llvmlite 0.38.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numpy 1.21.6; packaging 21.3; pandas 1.4.2; params NA; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.7.0; prompt_toolkit 3.0.29; psutil 5.9.0; ptyprocess 0.7.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynnd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2236
https://github.com/scverse/scanpy/issues/2236:264,Deployability,pipeline,pipeline,264,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am running the standard scrnaseq pipeline on some data and am experiencing an issue. When I run. ```py; sc.pp.highly_variable_genes(adata,n_top_genes=4000, batch_key='batch'); ```. I get the error. ```; If you pass `n_top_genes`, all cutoffs are ignored.; extracting highly variable genes; ZeroDivisionError: division by zero; ```. I've unfortunately never seen this before, and i'm not sure how to address it. I would love if someone could help with this. Some additional information on my data. ```pycon; >>> adata.X.shape; Out[21]: (3433, 16836). >>> adata.X; array([[0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; ...,; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.]], dtype=float32); ```. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; AlexFunctions NA; JonFunctions NA; PIL 9.1.0; PyQt5 NA; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bs4 4.11.1; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.1; import_all NA; ipykernel 6.13.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.2; leidenalg 0.8.4; llvmlite 0.38.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numpy 1.21.6; packaging 21.3; pandas 1.4.2; params NA; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.7.0; prompt_toolkit 3.0.29; psutil 5.9.0; ptyprocess 0.7.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynnd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2236
https://github.com/scverse/scanpy/issues/2236:2684,Deployability,update,updated,2684,"ata. ```pycon; >>> adata.X.shape; Out[21]: (3433, 16836). >>> adata.X; array([[0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; ...,; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.]], dtype=float32); ```. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; AlexFunctions NA; JonFunctions NA; PIL 9.1.0; PyQt5 NA; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bs4 4.11.1; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.1; import_all NA; ipykernel 6.13.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.2; leidenalg 0.8.4; llvmlite 0.38.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numpy 1.21.6; packaging 21.3; pandas 1.4.2; params NA; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.7.0; prompt_toolkit 3.0.29; psutil 5.9.0; ptyprocess 0.7.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.6; pyparsing 3.0.8; pytz 2022.1; scipy 1.8.0; seaborn 0.11.2; session_info 1.0.0; setuptools 62.1.0; sip NA; six 1.16.0; sklearn 1.0.2; soupsieve 2.3.1; sphinxcontrib NA; spyder 5.3.0; spyder_kernels 2.3.0; spydercustomize NA; statsmodels 0.13.2; storemagic NA; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.1; tqdm 4.64.0; traitlets 5.1.1; typing_extensions NA; umap 0.5.3; wcwidth 0.2.5; wurlitzer 3.0.2; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 7.32.0; jupyter_client 7.2.2; jupyter_core 4.9.2; -----; Python 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:25:59) [GCC 10.3.0]; Linux-5.4.0-100-generic-x86_64-with-glibc2.31; -----; Session information updated at 2022-04-14 16:33. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2236
https://github.com/scverse/scanpy/issues/2236:505,Modifiability,variab,variable,505,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am running the standard scrnaseq pipeline on some data and am experiencing an issue. When I run. ```py; sc.pp.highly_variable_genes(adata,n_top_genes=4000, batch_key='batch'); ```. I get the error. ```; If you pass `n_top_genes`, all cutoffs are ignored.; extracting highly variable genes; ZeroDivisionError: division by zero; ```. I've unfortunately never seen this before, and i'm not sure how to address it. I would love if someone could help with this. Some additional information on my data. ```pycon; >>> adata.X.shape; Out[21]: (3433, 16836). >>> adata.X; array([[0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; ...,; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.],; [0., 0., 0., ..., 0., 0., 0.]], dtype=float32); ```. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; AlexFunctions NA; JonFunctions NA; PIL 9.1.0; PyQt5 NA; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bs4 4.11.1; cffi 1.15.0; chardet 4.0.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.1; import_all NA; ipykernel 6.13.0; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.2; leidenalg 0.8.4; llvmlite 0.38.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numpy 1.21.6; packaging 21.3; pandas 1.4.2; params NA; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.7.0; prompt_toolkit 3.0.29; psutil 5.9.0; ptyprocess 0.7.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynnd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2236
https://github.com/scverse/scanpy/issues/2237:39,Deployability,install,installing,39,"Hi all.; I've been running into issues installing scanpy on M1 Mac (Apple Silicone) hardware. (It looks like something is wrong with numba?) I'm sure this is not new to you. I've seen a few issues on that here and there but it's not clear to me at this time:; 1. whether there is any workaround to getting this to work? (I'm using M1 homebrew); 2. where can I track the status of the fix for this? . The lack of scanpy is quite debilitating in my daily workflows, so it would be awesome if there is a way to get it to work even temporarily while waiting for the fix. Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2237
https://github.com/scverse/scanpy/issues/2237:233,Usability,clear,clear,233,"Hi all.; I've been running into issues installing scanpy on M1 Mac (Apple Silicone) hardware. (It looks like something is wrong with numba?) I'm sure this is not new to you. I've seen a few issues on that here and there but it's not clear to me at this time:; 1. whether there is any workaround to getting this to work? (I'm using M1 homebrew); 2. where can I track the status of the fix for this? . The lack of scanpy is quite debilitating in my daily workflows, so it would be awesome if there is a way to get it to work even temporarily while waiting for the fix. Thanks ahead!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2237
https://github.com/scverse/scanpy/issues/2238:119,Integrability,message,message,119,"Hi,; I'd like to plot a bunch of figures using the sc.pl.xx functions.; Is there some solution to suppress the Warning message during saving the figure?; the warning looks like that:; ```; WARNING: saving figure to file /home/test/figure/umap.marker1.png; WARNING: saving figure to file /home/test/figure/umap.marker2.png; WARNING: saving figure to file /home/test/figure/umap.marker3.png; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2238
https://github.com/scverse/scanpy/issues/2238:226,Testability,test,test,226,"Hi,; I'd like to plot a bunch of figures using the sc.pl.xx functions.; Is there some solution to suppress the Warning message during saving the figure?; the warning looks like that:; ```; WARNING: saving figure to file /home/test/figure/umap.marker1.png; WARNING: saving figure to file /home/test/figure/umap.marker2.png; WARNING: saving figure to file /home/test/figure/umap.marker3.png; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2238
https://github.com/scverse/scanpy/issues/2238:293,Testability,test,test,293,"Hi,; I'd like to plot a bunch of figures using the sc.pl.xx functions.; Is there some solution to suppress the Warning message during saving the figure?; the warning looks like that:; ```; WARNING: saving figure to file /home/test/figure/umap.marker1.png; WARNING: saving figure to file /home/test/figure/umap.marker2.png; WARNING: saving figure to file /home/test/figure/umap.marker3.png; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2238
https://github.com/scverse/scanpy/issues/2238:360,Testability,test,test,360,"Hi,; I'd like to plot a bunch of figures using the sc.pl.xx functions.; Is there some solution to suppress the Warning message during saving the figure?; the warning looks like that:; ```; WARNING: saving figure to file /home/test/figure/umap.marker1.png; WARNING: saving figure to file /home/test/figure/umap.marker2.png; WARNING: saving figure to file /home/test/figure/umap.marker3.png; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2238
https://github.com/scverse/scanpy/issues/2239:603,Availability,error,error,603,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; sc.tl.rank_genes_groups(adata, ""origin"", method=""wilcoxon""); ```. ```pytb; [Paste the error output produced by the above code here]; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Input In [18], in <cell line: 1>(); ----> 1 sc.tl.rank_genes_groups(adata, ""origin"", method=""wilcoxon""); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). File ~/app/miniconda3/envs/bio/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/app/miniconda3/envs/bio/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1514,Testability,log,logreg,1514,"e; sc.tl.rank_genes_groups(adata, ""origin"", method=""wilcoxon""); ```. ```pytb; [Paste the error output produced by the above code here]; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Input In [18], in <cell line: 1>(); ----> 1 sc.tl.rank_genes_groups(adata, ""origin"", method=""wilcoxon""); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). File ~/app/miniconda3/envs/bio/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/app/miniconda3/envs/bio/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.1; -----; Levenshtein NA; OpenSSL 21.0.0; PIL 9.1.0; adjustText NA; airr 1.3.1; appdirs 1.4.4; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bioservices 1.8.4; boto3 1.21.42; botocore",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1528,Testability,log,logg,1528,"e; sc.tl.rank_genes_groups(adata, ""origin"", method=""wilcoxon""); ```. ```pytb; [Paste the error output produced by the above code here]; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Input In [18], in <cell line: 1>(); ----> 1 sc.tl.rank_genes_groups(adata, ""origin"", method=""wilcoxon""); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). File ~/app/miniconda3/envs/bio/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/app/miniconda3/envs/bio/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.1; -----; Levenshtein NA; OpenSSL 21.0.0; PIL 9.1.0; adjustText NA; airr 1.3.1; appdirs 1.4.4; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bioservices 1.8.4; boto3 1.21.42; botocore",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:1621,Testability,log,logarithmize,1621,"e here]; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Input In [18], in <cell line: 1>(); ----> 1 sc.tl.rank_genes_groups(adata, ""origin"", method=""wilcoxon""); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). File ~/app/miniconda3/envs/bio/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/app/miniconda3/envs/bio/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.1; -----; Levenshtein NA; OpenSSL 21.0.0; PIL 9.1.0; adjustText NA; airr 1.3.1; appdirs 1.4.4; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bioservices 1.8.4; boto3 1.21.42; botocore 1.24.42; brotli NA; bs4 4.11.1; cattr NA; certifi 2021.10.08; cffi 1.15.0; charset_normalizer 2.0.4; colorama 0.4.4; colorlog",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:2080,Testability,log,log,2080,"ps, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/app/miniconda3/envs/bio/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.1; -----; Levenshtein NA; OpenSSL 21.0.0; PIL 9.1.0; adjustText NA; airr 1.3.1; appdirs 1.4.4; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bioservices 1.8.4; boto3 1.21.42; botocore 1.24.42; brotli NA; bs4 4.11.1; cattr NA; certifi 2021.10.08; cffi 1.15.0; charset_normalizer 2.0.4; colorama 0.4.4; colorlog NA; cryptography 36.0.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; easydev 0.12.0; entrypoints 0.4; executing 0.8.3; gseapy 0.10.8; h5py 3.6.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.10; ipykernel 6.13.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; jmespath 1.0.0; joblib 1.1.0; jupyter_server 1.16.0; kiwisolver 1.4.2; leidenalg 0.8.9; llvmlite 0.38.0; lxml 4.8.0; matplo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:2201,Testability,log,logging,2201,"s[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/app/miniconda3/envs/bio/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.1; -----; Levenshtein NA; OpenSSL 21.0.0; PIL 9.1.0; adjustText NA; airr 1.3.1; appdirs 1.4.4; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bioservices 1.8.4; boto3 1.21.42; botocore 1.24.42; brotli NA; bs4 4.11.1; cattr NA; certifi 2021.10.08; cffi 1.15.0; charset_normalizer 2.0.4; colorama 0.4.4; colorlog NA; cryptography 36.0.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; easydev 0.12.0; entrypoints 0.4; executing 0.8.3; gseapy 0.10.8; h5py 3.6.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.10; ipykernel 6.13.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; jmespath 1.0.0; joblib 1.1.0; jupyter_server 1.16.0; kiwisolver 1.4.2; leidenalg 0.8.9; llvmlite 0.38.0; lxml 4.8.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; networkx 2.8; numba 0.55.1; numpy 1.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/issues/2239:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; sc.tl.rank_genes_groups(adata, ""origin"", method=""wilcoxon""); ```. ```pytb; [Paste the error output produced by the above code here]; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Input In [18], in <cell line: 1>(); ----> 1 sc.tl.rank_genes_groups(adata, ""origin"", method=""wilcoxon""); 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). File ~/app/miniconda3/envs/bio/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File ~/app/miniconda3/envs/bio/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2239
https://github.com/scverse/scanpy/pull/2241:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2241
https://github.com/scverse/scanpy/pull/2241:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2241
https://github.com/scverse/scanpy/issues/2242:492,Availability,error,error,492,"Hi, I know this issue has been previously opened but I am still unable to resolve this problem. Any help would be great.; ---------------------------------------; I am new to Scanpy and I followed this tutorial link below.; https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_01_qc.html. Its a great tutorial and everything is working till I start the following code:-. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, flavor='seurat'). The error I receive is; -----------------------------------------------; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, flavor='seurat'); /Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py:200: RuntimeWarning: overflow encountered in expm1; X = np.expm1(X); /Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:11: RuntimeWarning: overflow encountered in multiply; mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); /Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:12: RuntimeWarning: invalid value encountered in subtract; var = mean_sq - mean**2; Traceback (most recent call last):. File ""/var/folders/xl/40x0m_b12y5fz7w2hqr_yf480000gp/T/ipykernel_11768/414963115.py"", line 1, in <cell line: 1>; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, flavor='seurat'). File ""/Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes; df = _highly_variable_genes_single_batch(. File ""/Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/Users/Shamini",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242
https://github.com/scverse/scanpy/issues/2242:2623,Availability,error,error,2623,"p.expm1(X); /Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:11: RuntimeWarning: overflow encountered in multiply; mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); /Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_utils.py:12: RuntimeWarning: invalid value encountered in subtract; var = mean_sq - mean**2; Traceback (most recent call last):. File ""/var/folders/xl/40x0m_b12y5fz7w2hqr_yf480000gp/T/ipykernel_11768/414963115.py"", line 1, in <cell line: 1>; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, flavor='seurat'). File ""/Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes; df = _highly_variable_genes_single_batch(. File ""/Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/Users/ShaminiAyyadhury/anaconda3/envs/scIntegration/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 262, in cut; raise ValueError(. ValueError: cannot specify integer `bins` when input data contains infinity. --------------------------------------------. Concerns:; 1. I am not sure if its the way I created the anndata that is causing this problem.; 2. I have already log_normalized my data object and I am not sure what else to do. ; 3. I have also read the GitHub issues and tried to fix the problems but I am unable to. ; 4. I am attaching my own code here, which is exactly the one found on the website above. The error code is in the last few lines of my script. Not sure if anything I am doing before is causing the problem. [scanpy.txt]; (https://github.com/scverse/scanpy/files/8536536/scanpy.txt). Thank you.; Regards,; Shamini A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2242
https://github.com/scverse/scanpy/issues/2244:4031,Testability,log,logical,4031,"; charset_normalizer 2.0.7; cloudpickle 2.0.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; dask 2021.10.0; dateutil 2.8.0; debugpy 1.4.1; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; fasteners NA; fsspec 2021.10.1; gi 3.36.0; gio NA; glib NA; gobject NA; gtk NA; h5py 3.5.0; idna 2.8; igraph 0.9.9; ipykernel 6.3.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 2.10.1; joblib 1.0.1; json5 NA; jsonpointer 2.0; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.2; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.37.0; louvain 0.7.1; markupsafe 1.1.0; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; nbinom_ufunc NA; netifaces 0.10.4; numba 0.54.0; numcodecs 0.9.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0; pandas 1.3.2; parso 0.8.2; patsy 0.5.1; pexpect 4.6.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.20; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pydev_ipython NA; pydevconsole NA; pydevd 2.4.1; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.10.0; pynndescent 0.5.5; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.26.0; roifile 2021.6.6; scipy 1.7.1; seaborn 0.11.2; send2trash NA; shapely 1.7.1; simplejson 3.16.0; sitecustomize NA; six 1.14.0; sklearn 1.0.2; sniffio 1.2.0; sparse 0.13.0; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; terminado 0.11.1; texttable 1.6.4; threadpoolctl 2.2.0; tlz 0.11.1; toolz 0.11.1; torch 1.6.0; tornado 6.1; tqdm 4.62.2; traitlets 5.1.0; typing_extensions NA; umap 0.5.1; urllib3 1.26.6; wcwidth 0.2.5; websocket 1.2.1; yaml 6.0; zarr 2.10.2; zmq 22.2.1; zope NA; -----; IPython 7.27.0; jupyter_client 7.0.2; jupyter_core 4.7.1; jupyterlab 3.1.12; notebook 6.4.3; -----; Python 3.8.10 (default, Sep 28 2021, 16:10:42) [GCC 9.3.0]; Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.29; 8 logical CPU cores, x86_64. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2244
https://github.com/scverse/scanpy/issues/2244:3386,Usability,simpl,simplejson,3386,"; charset_normalizer 2.0.7; cloudpickle 2.0.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; dask 2021.10.0; dateutil 2.8.0; debugpy 1.4.1; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.3; fasteners NA; fsspec 2021.10.1; gi 3.36.0; gio NA; glib NA; gobject NA; gtk NA; h5py 3.5.0; idna 2.8; igraph 0.9.9; ipykernel 6.3.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 2.10.1; joblib 1.0.1; json5 NA; jsonpointer 2.0; jsonschema 3.2.0; jupyter_server 1.10.2; jupyterlab_server 2.7.2; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.37.0; louvain 0.7.1; markupsafe 1.1.0; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; nbinom_ufunc NA; netifaces 0.10.4; numba 0.54.0; numcodecs 0.9.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0; pandas 1.3.2; parso 0.8.2; patsy 0.5.1; pexpect 4.6.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.20; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pydev_ipython NA; pydevconsole NA; pydevd 2.4.1; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.10.0; pynndescent 0.5.5; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.26.0; roifile 2021.6.6; scipy 1.7.1; seaborn 0.11.2; send2trash NA; shapely 1.7.1; simplejson 3.16.0; sitecustomize NA; six 1.14.0; sklearn 1.0.2; sniffio 1.2.0; sparse 0.13.0; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; terminado 0.11.1; texttable 1.6.4; threadpoolctl 2.2.0; tlz 0.11.1; toolz 0.11.1; torch 1.6.0; tornado 6.1; tqdm 4.62.2; traitlets 5.1.0; typing_extensions NA; umap 0.5.1; urllib3 1.26.6; wcwidth 0.2.5; websocket 1.2.1; yaml 6.0; zarr 2.10.2; zmq 22.2.1; zope NA; -----; IPython 7.27.0; jupyter_client 7.0.2; jupyter_core 4.7.1; jupyterlab 3.1.12; notebook 6.4.3; -----; Python 3.8.10 (default, Sep 28 2021, 16:10:42) [GCC 9.3.0]; Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.29; 8 logical CPU cores, x86_64. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2244
https://github.com/scverse/scanpy/issues/2245:336,Deployability,integrat,integrated,336,"**Set name for storing Umap coordinates explicitly in tl.umap and pl.umap**; tl.umap(..., x_umap = ""X_umap""); pl.umap(..., x_umap = ""X_umap""). Sometimes it would be helpful to specify the adata obsm field for storing the umap coordinates.; For example : ; -if I want to compute and plot the umap for the raw data and afterwards for the integrated or in any way modified data. The first x_umap is going to be overwritten and needs to be computed again, if I need to plot the first step again.; So it would be cool to enable a workflow like the following:. ```; tl.umap(adata, ..., x_umap = ""X_umap_raw""); # do some operations ...; tl.umap(adata, ..., x_umap = ""X_umap_mod). # now after computation I might need to take a look on both umaps again, or plot them in direct comparison; pl.umap(adata, ..., x_umap = ""X_umap_raw""); pl.umap(adata, ..., x_umap = ""X_umap_mod""). ```. I hope I was able to explain what I mean and did not oversee such feature or misunderstood the usage.; All the best ; maflot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2245
https://github.com/scverse/scanpy/issues/2245:336,Integrability,integrat,integrated,336,"**Set name for storing Umap coordinates explicitly in tl.umap and pl.umap**; tl.umap(..., x_umap = ""X_umap""); pl.umap(..., x_umap = ""X_umap""). Sometimes it would be helpful to specify the adata obsm field for storing the umap coordinates.; For example : ; -if I want to compute and plot the umap for the raw data and afterwards for the integrated or in any way modified data. The first x_umap is going to be overwritten and needs to be computed again, if I need to plot the first step again.; So it would be cool to enable a workflow like the following:. ```; tl.umap(adata, ..., x_umap = ""X_umap_raw""); # do some operations ...; tl.umap(adata, ..., x_umap = ""X_umap_mod). # now after computation I might need to take a look on both umaps again, or plot them in direct comparison; pl.umap(adata, ..., x_umap = ""X_umap_raw""); pl.umap(adata, ..., x_umap = ""X_umap_mod""). ```. I hope I was able to explain what I mean and did not oversee such feature or misunderstood the usage.; All the best ; maflot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2245
https://github.com/scverse/scanpy/issues/2246:258,Availability,down,download,258,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To reproduce this issue:; 1. download the public 10x dataset here (https://cf.10xgenomics.com/samples/cell-exp/2.1.0/hgmm_12k/hgmm_12k_raw_gene_bc_matrices_h5.h5) ; 2. run the following. ```python; import scanpy as sc. adata_human = sc.read_10x_h5('hgmm_12k_raw_gene_bc_matrices_h5.h5', genome='hg19'); adata_mouse = sc.read_10x_h5('hgmm_12k_raw_gene_bc_matrices_h5.h5', genome='mm10'). assert (adata_human.X != adata_mouse.X).sum() > 0, 'these count matrices are equal'; ```. which produces the assertion error. We see that the loaded data is the same regardless of `'genome'` argument. A look at the file itself shows this is not the case (notice the number of gene names, which are different for hg19 and mm10):. ![image](https://user-images.githubusercontent.com/10214815/165848884-0ef5c172-83f9-4ead-9687-0acadb496e87.png). #### Versions. Also I think I can say confidently that this was working fine as of scanpy 1.8.1. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 8.1.0; appnope 0.1.2; backcall 0.2.0; cached_property 1.5.2; cellbender NA; cffi 1.14.5; colorcet 3.0.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 5.0.9; fontTools 4.33.3; h5py 3.2.0; igraph 0.9.10; ipykernel 5.5.5; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.10; llvmlite 0.38.0; lxml 4.8.0; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; numba 0.55.1; numexpr 2.7.3; numpy 1.19.2; packaging 20.9; pandas 1.2.3; param 1.12.1; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.18; psutil 5.8.0; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.0; pynndescent 0.5.6; pyparsing 2.4.7; pytz 2021.1; scipy 1.6.1; seaborn 0.11.2; session_info 1.0.0; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:735,Availability,error,error,735,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To reproduce this issue:; 1. download the public 10x dataset here (https://cf.10xgenomics.com/samples/cell-exp/2.1.0/hgmm_12k/hgmm_12k_raw_gene_bc_matrices_h5.h5) ; 2. run the following. ```python; import scanpy as sc. adata_human = sc.read_10x_h5('hgmm_12k_raw_gene_bc_matrices_h5.h5', genome='hg19'); adata_mouse = sc.read_10x_h5('hgmm_12k_raw_gene_bc_matrices_h5.h5', genome='mm10'). assert (adata_human.X != adata_mouse.X).sum() > 0, 'these count matrices are equal'; ```. which produces the assertion error. We see that the loaded data is the same regardless of `'genome'` argument. A look at the file itself shows this is not the case (notice the number of gene names, which are different for hg19 and mm10):. ![image](https://user-images.githubusercontent.com/10214815/165848884-0ef5c172-83f9-4ead-9687-0acadb496e87.png). #### Versions. Also I think I can say confidently that this was working fine as of scanpy 1.8.1. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 8.1.0; appnope 0.1.2; backcall 0.2.0; cached_property 1.5.2; cellbender NA; cffi 1.14.5; colorcet 3.0.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 5.0.9; fontTools 4.33.3; h5py 3.2.0; igraph 0.9.10; ipykernel 5.5.5; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.10; llvmlite 0.38.0; lxml 4.8.0; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; numba 0.55.1; numexpr 2.7.3; numpy 1.19.2; packaging 20.9; pandas 1.2.3; param 1.12.1; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.18; psutil 5.8.0; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.0; pynndescent 0.5.6; pyparsing 2.4.7; pytz 2021.1; scipy 1.6.1; seaborn 0.11.2; session_info 1.0.0; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:758,Performance,load,loaded,758,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To reproduce this issue:; 1. download the public 10x dataset here (https://cf.10xgenomics.com/samples/cell-exp/2.1.0/hgmm_12k/hgmm_12k_raw_gene_bc_matrices_h5.h5) ; 2. run the following. ```python; import scanpy as sc. adata_human = sc.read_10x_h5('hgmm_12k_raw_gene_bc_matrices_h5.h5', genome='hg19'); adata_mouse = sc.read_10x_h5('hgmm_12k_raw_gene_bc_matrices_h5.h5', genome='mm10'). assert (adata_human.X != adata_mouse.X).sum() > 0, 'these count matrices are equal'; ```. which produces the assertion error. We see that the loaded data is the same regardless of `'genome'` argument. A look at the file itself shows this is not the case (notice the number of gene names, which are different for hg19 and mm10):. ![image](https://user-images.githubusercontent.com/10214815/165848884-0ef5c172-83f9-4ead-9687-0acadb496e87.png). #### Versions. Also I think I can say confidently that this was working fine as of scanpy 1.8.1. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 8.1.0; appnope 0.1.2; backcall 0.2.0; cached_property 1.5.2; cellbender NA; cffi 1.14.5; colorcet 3.0.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 5.0.9; fontTools 4.33.3; h5py 3.2.0; igraph 0.9.10; ipykernel 5.5.5; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.10; llvmlite 0.38.0; lxml 4.8.0; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; numba 0.55.1; numexpr 2.7.3; numpy 1.19.2; packaging 20.9; pandas 1.2.3; param 1.12.1; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.18; psutil 5.8.0; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.0; pynndescent 0.5.6; pyparsing 2.4.7; pytz 2021.1; scipy 1.6.1; seaborn 0.11.2; session_info 1.0.0; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:616,Testability,assert,assert,616,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To reproduce this issue:; 1. download the public 10x dataset here (https://cf.10xgenomics.com/samples/cell-exp/2.1.0/hgmm_12k/hgmm_12k_raw_gene_bc_matrices_h5.h5) ; 2. run the following. ```python; import scanpy as sc. adata_human = sc.read_10x_h5('hgmm_12k_raw_gene_bc_matrices_h5.h5', genome='hg19'); adata_mouse = sc.read_10x_h5('hgmm_12k_raw_gene_bc_matrices_h5.h5', genome='mm10'). assert (adata_human.X != adata_mouse.X).sum() > 0, 'these count matrices are equal'; ```. which produces the assertion error. We see that the loaded data is the same regardless of `'genome'` argument. A look at the file itself shows this is not the case (notice the number of gene names, which are different for hg19 and mm10):. ![image](https://user-images.githubusercontent.com/10214815/165848884-0ef5c172-83f9-4ead-9687-0acadb496e87.png). #### Versions. Also I think I can say confidently that this was working fine as of scanpy 1.8.1. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 8.1.0; appnope 0.1.2; backcall 0.2.0; cached_property 1.5.2; cellbender NA; cffi 1.14.5; colorcet 3.0.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 5.0.9; fontTools 4.33.3; h5py 3.2.0; igraph 0.9.10; ipykernel 5.5.5; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.10; llvmlite 0.38.0; lxml 4.8.0; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; numba 0.55.1; numexpr 2.7.3; numpy 1.19.2; packaging 20.9; pandas 1.2.3; param 1.12.1; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.18; psutil 5.8.0; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.0; pynndescent 0.5.6; pyparsing 2.4.7; pytz 2021.1; scipy 1.6.1; seaborn 0.11.2; session_info 1.0.0; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2246:725,Testability,assert,assertion,725,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To reproduce this issue:; 1. download the public 10x dataset here (https://cf.10xgenomics.com/samples/cell-exp/2.1.0/hgmm_12k/hgmm_12k_raw_gene_bc_matrices_h5.h5) ; 2. run the following. ```python; import scanpy as sc. adata_human = sc.read_10x_h5('hgmm_12k_raw_gene_bc_matrices_h5.h5', genome='hg19'); adata_mouse = sc.read_10x_h5('hgmm_12k_raw_gene_bc_matrices_h5.h5', genome='mm10'). assert (adata_human.X != adata_mouse.X).sum() > 0, 'these count matrices are equal'; ```. which produces the assertion error. We see that the loaded data is the same regardless of `'genome'` argument. A look at the file itself shows this is not the case (notice the number of gene names, which are different for hg19 and mm10):. ![image](https://user-images.githubusercontent.com/10214815/165848884-0ef5c172-83f9-4ead-9687-0acadb496e87.png). #### Versions. Also I think I can say confidently that this was working fine as of scanpy 1.8.1. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 8.1.0; appnope 0.1.2; backcall 0.2.0; cached_property 1.5.2; cellbender NA; cffi 1.14.5; colorcet 3.0.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 5.0.9; fontTools 4.33.3; h5py 3.2.0; igraph 0.9.10; ipykernel 5.5.5; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.10; llvmlite 0.38.0; lxml 4.8.0; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; numba 0.55.1; numexpr 2.7.3; numpy 1.19.2; packaging 20.9; pandas 1.2.3; param 1.12.1; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.18; psutil 5.8.0; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.0; pynndescent 0.5.6; pyparsing 2.4.7; pytz 2021.1; scipy 1.6.1; seaborn 0.11.2; session_info 1.0.0; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2246
https://github.com/scverse/scanpy/issues/2247:644,Testability,log,logfoldchanges,644,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hi,. Thanks for developing scanpy, which is quite handy. I am just wondering would it be possible to add a parameter like `sort_by` in `tl.rank_genes_groups()`, so sorting by logfoldchanges could be feasible for each group. Or I will appreciate it if you can help me with alternatives. . I understand this might be a minor thing, so please feel free to say no :). Thanks,; Nan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2247
https://github.com/scverse/scanpy/issues/2247:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hi,. Thanks for developing scanpy, which is quite handy. I am just wondering would it be possible to add a parameter like `sort_by` in `tl.rank_genes_groups()`, so sorting by logfoldchanges could be feasible for each group. Or I will appreciate it if you can help me with alternatives. . I understand this might be a minor thing, so please feel free to say no :). Thanks,; Nan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2247
https://github.com/scverse/scanpy/pull/2248:47,Testability,test,test,47,"Fixes #2246 . A very small change with a small test. The new test fails for the current master branch, but passes with the fix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2248
https://github.com/scverse/scanpy/pull/2248:61,Testability,test,test,61,"Fixes #2246 . A very small change with a small test. The new test fails for the current master branch, but passes with the fix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2248
https://github.com/scverse/scanpy/issues/2249:684,Availability,error,error,684,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hey,; currently, when trying to use plotting functions that require categorical obs columns (for example `sc.pl.clustermap` `obs_keys` parameter), but one passes a boolean column key in `.obs,` scanpy will raise an error (or pandas does but the origin is in scanpy's codebase): `AttributeError: Can only use .cat accessor with a 'category' dtype`. Would it be possible to let the passed key be from a column of `dtype bool` as well? Are there any downsides? Happy to provide more detail if needed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2249
https://github.com/scverse/scanpy/issues/2249:916,Availability,down,downsides,916,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hey,; currently, when trying to use plotting functions that require categorical obs columns (for example `sc.pl.clustermap` `obs_keys` parameter), but one passes a boolean column key in `.obs,` scanpy will raise an error (or pandas does but the origin is in scanpy's codebase): `AttributeError: Can only use .cat accessor with a 'category' dtype`. Would it be possible to let the passed key be from a column of `dtype bool` as well? Are there any downsides? Happy to provide more detail if needed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2249
https://github.com/scverse/scanpy/issues/2249:782,Security,access,accessor,782,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hey,; currently, when trying to use plotting functions that require categorical obs columns (for example `sc.pl.clustermap` `obs_keys` parameter), but one passes a boolean column key in `.obs,` scanpy will raise an error (or pandas does but the origin is in scanpy's codebase): `AttributeError: Can only use .cat accessor with a 'category' dtype`. Would it be possible to let the passed key be from a column of `dtype bool` as well? Are there any downsides? Happy to provide more detail if needed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2249
https://github.com/scverse/scanpy/issues/2249:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hey,; currently, when trying to use plotting functions that require categorical obs columns (for example `sc.pl.clustermap` `obs_keys` parameter), but one passes a boolean column key in `.obs,` scanpy will raise an error (or pandas does but the origin is in scanpy's codebase): `AttributeError: Can only use .cat accessor with a 'category' dtype`. Would it be possible to let the passed key be from a column of `dtype bool` as well? Are there any downsides? Happy to provide more detail if needed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2249
https://github.com/scverse/scanpy/issues/2250:675,Availability,error,error,675,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; categories_order=['0','1','9','8','2','5','4','7','3','6']; sc.pl.tracksplot(adata,markers,groupby='leiden',vmax=3,categories_order=categories_order); ```. ```pytb; [Paste the error output produced by the above code here]; ```; ![image](https://user-images.githubusercontent.com/50618480/166931336-26e4431a-7bdb-41b4-a575-69aa5e9ef948.png); I can not get the order as ['0','1','9','8','2','5','4','7','3','6']; #### Versions; 1.9.1; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:971,Testability,log,logging,971,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; categories_order=['0','1','9','8','2','5','4','7','3','6']; sc.pl.tracksplot(adata,markers,groupby='leiden',vmax=3,categories_order=categories_order); ```. ```pytb; [Paste the error output produced by the above code here]; ```; ![image](https://user-images.githubusercontent.com/50618480/166931336-26e4431a-7bdb-41b4-a575-69aa5e9ef948.png); I can not get the order as ['0','1','9','8','2','5','4','7','3','6']; #### Versions; 1.9.1; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2250:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; categories_order=['0','1','9','8','2','5','4','7','3','6']; sc.pl.tracksplot(adata,markers,groupby='leiden',vmax=3,categories_order=categories_order); ```. ```pytb; [Paste the error output produced by the above code here]; ```; ![image](https://user-images.githubusercontent.com/50618480/166931336-26e4431a-7bdb-41b4-a575-69aa5e9ef948.png); I can not get the order as ['0','1','9','8','2','5','4','7','3','6']; #### Versions; 1.9.1; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2250
https://github.com/scverse/scanpy/issues/2251:565,Deployability,pipeline,pipelines,565,"<!--;  If you need help using Scanpy, please ask in https://discourse.scverse.org/ instead ; If you want to know about design decisions and the like, please ask below:; -->; ... Hi,. I noticed that when scanpy reads the spatial information from the ""tisslue_position_list.csv"" file of the 10X visium data, the (x,y) coordinate for pixels is flipped:. positions.columns = [; 'barcode',; 'in_tissue',; 'array_row',; 'array_col',; 'pxl_col_in_fullres',; 'pxl_row_in_fullres',; ]. However, from here: [https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/images](url), the pxl_row is supposed to be ahead of pxl_col . Is there any explanation for this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2251
https://github.com/scverse/scanpy/issues/2252:593,Usability,clear,clear,593,"<!--;  If you need help using Scanpy, please ask in https://discourse.scverse.org/ instead ; If you want to know about design decisions and the like, please ask below:; -->; ...; Hello. I would like to plot the ""log1p_total_counts"" of a **visium transcriptomic dataset** (AnnData object with n_obs  n_vars) using sc.pl.spatial. **sc.pl.spatial(adatal, img_key=""hires"", color=[""gene1"", ""gene2"", ""gene3""]) -**-> gives 3 images (the 3 genes are plotted stacked on 3 images). But instead of I would like to plot **the mean of the 3 genes on 1 image**. is it possible ??; I hope the question is clear :); Manys thanks for your help; Sophie",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2252
https://github.com/scverse/scanpy/issues/2253:104,Performance,load,loading,104,"... Hello, I hope I'm in the correct place. I was wondering, in Spatial Transcriptomics analyses, after loading data `adata = sc.read_visium`, where are the spot co-ordinates stored?. Example; spot x y; 1x17x20	17	20	; 1x17x21	17	21",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2253
https://github.com/scverse/scanpy/issues/2254:1682,Deployability,update,updated,1682,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### This is the code I'm using which was copied from the tutorial:. ```python; import scanpy as sc; adata = sc.datasets.paul15(); sc.pp.log1p(adata); sc.pp.neighbors(adata, n_neighbors=20, use_rep='X', method='gauss'); sc.tl.diffmap(adata); sc.tl.dpt(adata, n_branchings=1, n_dcs=10); sc.pl.diffmap(adata, color=['dpt_pseudotime', 'dpt_groups', 'paul15_clusters']); ```; The results I got are:; ![image](https://user-images.githubusercontent.com/33322882/168080076-f6767970-0b3b-4623-ab25-e9e38201e6ef.png). Which is totally different than in the tutorial:; ![image](https://user-images.githubusercontent.com/33322882/168081015-cddf77eb-7b83-4802-8890-3b0d87a5755d.png). Can anyone run into this problem ever? Thanks for your help. #### Versions. <details>; -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.6.0. google NA. h5py 3.6.0. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. joblib 0.17.0. kiwisolver 1.3.1. llvmlite 0.38.0. ... Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]. Linux-3.16.0-11-amd64-x86_64-with-glibc2.19. -----. Session information updated at 2022-05-12 14:59. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2254
https://github.com/scverse/scanpy/issues/2254:1273,Performance,bottleneck,bottleneck,1273,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### This is the code I'm using which was copied from the tutorial:. ```python; import scanpy as sc; adata = sc.datasets.paul15(); sc.pp.log1p(adata); sc.pp.neighbors(adata, n_neighbors=20, use_rep='X', method='gauss'); sc.tl.diffmap(adata); sc.tl.dpt(adata, n_branchings=1, n_dcs=10); sc.pl.diffmap(adata, color=['dpt_pseudotime', 'dpt_groups', 'paul15_clusters']); ```; The results I got are:; ![image](https://user-images.githubusercontent.com/33322882/168080076-f6767970-0b3b-4623-ab25-e9e38201e6ef.png). Which is totally different than in the tutorial:; ![image](https://user-images.githubusercontent.com/33322882/168081015-cddf77eb-7b83-4802-8890-3b0d87a5755d.png). Can anyone run into this problem ever? Thanks for your help. #### Versions. <details>; -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.6.0. google NA. h5py 3.6.0. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. joblib 0.17.0. kiwisolver 1.3.1. llvmlite 0.38.0. ... Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]. Linux-3.16.0-11-amd64-x86_64-with-glibc2.19. -----. Session information updated at 2022-05-12 14:59. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2254
https://github.com/scverse/scanpy/issues/2254:257,Usability,guid,guide,257,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### This is the code I'm using which was copied from the tutorial:. ```python; import scanpy as sc; adata = sc.datasets.paul15(); sc.pp.log1p(adata); sc.pp.neighbors(adata, n_neighbors=20, use_rep='X', method='gauss'); sc.tl.diffmap(adata); sc.tl.dpt(adata, n_branchings=1, n_dcs=10); sc.pl.diffmap(adata, color=['dpt_pseudotime', 'dpt_groups', 'paul15_clusters']); ```; The results I got are:; ![image](https://user-images.githubusercontent.com/33322882/168080076-f6767970-0b3b-4623-ab25-e9e38201e6ef.png). Which is totally different than in the tutorial:; ![image](https://user-images.githubusercontent.com/33322882/168081015-cddf77eb-7b83-4802-8890-3b0d87a5755d.png). Can anyone run into this problem ever? Thanks for your help. #### Versions. <details>; -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.6.0. google NA. h5py 3.6.0. ipykernel 6.4.1. ipython_genutils 0.2.0. jedi 0.18.1. joblib 0.17.0. kiwisolver 1.3.1. llvmlite 0.38.0. ... Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]. Linux-3.16.0-11-amd64-x86_64-with-glibc2.19. -----. Session information updated at 2022-05-12 14:59. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2254
https://github.com/scverse/scanpy/issues/2256:67,Availability,error,error,67,Calling `sc.get.obs_df` with `keys=adata.var_names` raises a value error since [here](https://github.com/scverse/scanpy/blob/bd06cc3d1e0bd990f6994e54414512fa0b25fea0/scanpy/get/get.py#L303-L304) an Index object is used to re-order the dataframe. ; I think its a trivial fix to re-cast `keys` locally if an Index object is passed (aka `adata.var_names`) and could be nice for the user :),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2256
https://github.com/scverse/scanpy/issues/2259:168,Usability,simpl,simple,168,<!-- What kind of feature would you like to request? -->; - [ x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Is there an option to use umap transform (https://umap-learn.readthedocs.io/en/latest/transform.html) with scanpy? E.g. for embedding new data into the same UMAP space.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/issues/2259:525,Usability,learn,learn,525,<!-- What kind of feature would you like to request? -->; - [ x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Is there an option to use umap transform (https://umap-learn.readthedocs.io/en/latest/transform.html) with scanpy? E.g. for embedding new data into the same UMAP space.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2259
https://github.com/scverse/scanpy/pull/2263:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2263
https://github.com/scverse/scanpy/pull/2263:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2263
https://github.com/scverse/scanpy/issues/2264:2,Deployability,update,updated,2,"I updated anndata to 0.8.0 and was not able to load my scanpy 1.8.2 properly. Any ideas?. ```; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); /tmp/ipykernel_31935/912249142.py in <module>; ----> 1 import scanpy as sc. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2264
https://github.com/scverse/scanpy/issues/2264:47,Performance,load,load,47,"I updated anndata to 0.8.0 and was not able to load my scanpy 1.8.2 properly. Any ideas?. ```; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); /tmp/ipykernel_31935/912249142.py in <module>; ----> 1 import scanpy as sc. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2264
https://github.com/scverse/scanpy/issues/2264:1053,Testability,log,logging,1053,"I updated anndata to 0.8.0 and was not able to load my scanpy 1.8.2 properly. Any ideas?. ```; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); /tmp/ipykernel_31935/912249142.py in <module>; ----> 1 import scanpy as sc. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2264
https://github.com/scverse/scanpy/issues/2264:1064,Testability,log,logg,1064,"I updated anndata to 0.8.0 and was not able to load my scanpy 1.8.2 properly. Any ideas?. ```; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); /tmp/ipykernel_31935/912249142.py in <module>; ----> 1 import scanpy as sc. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2264
https://github.com/scverse/scanpy/issues/2265:71,Availability,Error,Error,71,"I upgraded anndata to 0.8.0 and couldn't load my scanpy 1.8.2 anymore. Error:. ```; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); /tmp/ipykernel_31935/912249142.py in <module>; ----> 1 import scanpy as sc. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```. The messages when updating anndata:; ```; The following packages will be REMOVED:. pytables-3.6.1-py38h9f153d1_1. The following packages will be UPDATED:. anndata 0.7.6-py38h578d9bd_0 --> 0.8.0-py38h578d9bd_0; ca-certificates pkgs/main::ca-certificates-2022.4.26-~ --> conda-forge::ca-certificates-2022.5.18.1-ha878542_0; h5py 2.10.0-nompi_py38h513d04c_102 --> 3.6.0-nompi_py38hfbb2109_100; hdf5 1.10.5-nompi_h5b725eb_1114 --> 1.12.1-nompi_h2750804_100. The following packages will be SUPERSEDED by a higher-priority channel:. certifi pkgs/main::certifi-2022.5.18.1-py38h0~ --> conda-forge::certifi-2022.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265
https://github.com/scverse/scanpy/issues/2265:2132,Availability,Down,Downloading,2132,b/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```. The messages when updating anndata:; ```; The following packages will be REMOVED:. pytables-3.6.1-py38h9f153d1_1. The following packages will be UPDATED:. anndata 0.7.6-py38h578d9bd_0 --> 0.8.0-py38h578d9bd_0; ca-certificates pkgs/main::ca-certificates-2022.4.26-~ --> conda-forge::ca-certificates-2022.5.18.1-ha878542_0; h5py 2.10.0-nompi_py38h513d04c_102 --> 3.6.0-nompi_py38hfbb2109_100; hdf5 1.10.5-nompi_h5b725eb_1114 --> 1.12.1-nompi_h2750804_100. The following packages will be SUPERSEDED by a higher-priority channel:. certifi pkgs/main::certifi-2022.5.18.1-py38h0~ --> conda-forge::certifi-2022.5.18.1-py38h578d9bd_0; openssl pkgs/main::openssl-1.1.1o-h7f8727e_0 --> conda-forge::openssl-1.1.1o-h166bdaf_0. Proceed ([y]/n)? y. Downloading and Extracting Packages; keyutils-1.6.1 | 115 KB | ############################################################################# | 100% ; h5py-3.6.0 | 1.4 MB | ############################################################################# | 100% ; cached_property-1.5. | 11 KB | ############################################################################# | 100% ; c-ares-1.18.1 | 113 KB | ############################################################################# | 100% ; anndata-0.8.0 | 151 KB | ############################################################################# | 100% ; libev-4.33 | 104 KB | ############################################################################# | 100% ; libnghttp2-1.46.0 | 680 KB | ############################################################################# | 100% ; libcurl-7.82.0 | 342 KB | ############################################################################# | 100% ; libssh2-1.10.0 | 233 KB | ###########################################################,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265
https://github.com/scverse/scanpy/issues/2265:2,Deployability,upgrade,upgraded,2,"I upgraded anndata to 0.8.0 and couldn't load my scanpy 1.8.2 anymore. Error:. ```; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); /tmp/ipykernel_31935/912249142.py in <module>; ----> 1 import scanpy as sc. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```. The messages when updating anndata:; ```; The following packages will be REMOVED:. pytables-3.6.1-py38h9f153d1_1. The following packages will be UPDATED:. anndata 0.7.6-py38h578d9bd_0 --> 0.8.0-py38h578d9bd_0; ca-certificates pkgs/main::ca-certificates-2022.4.26-~ --> conda-forge::ca-certificates-2022.5.18.1-ha878542_0; h5py 2.10.0-nompi_py38h513d04c_102 --> 3.6.0-nompi_py38hfbb2109_100; hdf5 1.10.5-nompi_h5b725eb_1114 --> 1.12.1-nompi_h2750804_100. The following packages will be SUPERSEDED by a higher-priority channel:. certifi pkgs/main::certifi-2022.5.18.1-py38h0~ --> conda-forge::certifi-2022.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265
https://github.com/scverse/scanpy/issues/2265:1541,Deployability,UPDATE,UPDATED,1541,"rt preprocessing as pp; 16 from . import plotting as pl. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```. The messages when updating anndata:; ```; The following packages will be REMOVED:. pytables-3.6.1-py38h9f153d1_1. The following packages will be UPDATED:. anndata 0.7.6-py38h578d9bd_0 --> 0.8.0-py38h578d9bd_0; ca-certificates pkgs/main::ca-certificates-2022.4.26-~ --> conda-forge::ca-certificates-2022.5.18.1-ha878542_0; h5py 2.10.0-nompi_py38h513d04c_102 --> 3.6.0-nompi_py38hfbb2109_100; hdf5 1.10.5-nompi_h5b725eb_1114 --> 1.12.1-nompi_h2750804_100. The following packages will be SUPERSEDED by a higher-priority channel:. certifi pkgs/main::certifi-2022.5.18.1-py38h0~ --> conda-forge::certifi-2022.5.18.1-py38h578d9bd_0; openssl pkgs/main::openssl-1.1.1o-h7f8727e_0 --> conda-forge::openssl-1.1.1o-h166bdaf_0. Proceed ([y]/n)? y. Downloading and Extracting Packages; keyutils-1.6.1 | 115 KB | ############################################################################# | 100% ; h5py-3.6.0 | 1.4 MB | ############################################################################# | 100% ; cached_property-1.5. | 11 KB | ############################################################################# | 100% ; c-ares-1.18.1 | 113 K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265
https://github.com/scverse/scanpy/issues/2265:1400,Integrability,message,messages,1400,"from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```. The messages when updating anndata:; ```; The following packages will be REMOVED:. pytables-3.6.1-py38h9f153d1_1. The following packages will be UPDATED:. anndata 0.7.6-py38h578d9bd_0 --> 0.8.0-py38h578d9bd_0; ca-certificates pkgs/main::ca-certificates-2022.4.26-~ --> conda-forge::ca-certificates-2022.5.18.1-ha878542_0; h5py 2.10.0-nompi_py38h513d04c_102 --> 3.6.0-nompi_py38hfbb2109_100; hdf5 1.10.5-nompi_h5b725eb_1114 --> 1.12.1-nompi_h2750804_100. The following packages will be SUPERSEDED by a higher-priority channel:. certifi pkgs/main::certifi-2022.5.18.1-py38h0~ --> conda-forge::certifi-2022.5.18.1-py38h578d9bd_0; openssl pkgs/main::openssl-1.1.1o-h7f8727e_0 --> conda-forge::openssl-1.1.1o-h166bdaf_0. Proceed ([y]/n)? y. Downloading and Extracting Packages; keyutils-1.6.1 | 115 KB | ############################################################################# | 100% ; h5py-3.6.0 | 1.4 MB | ############################################################################# | 100% ; cached_property-1.5. | 11 KB | ###############",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265
https://github.com/scverse/scanpy/issues/2265:41,Performance,load,load,41,"I upgraded anndata to 0.8.0 and couldn't load my scanpy 1.8.2 anymore. Error:. ```; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); /tmp/ipykernel_31935/912249142.py in <module>; ----> 1 import scanpy as sc. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```. The messages when updating anndata:; ```; The following packages will be REMOVED:. pytables-3.6.1-py38h9f153d1_1. The following packages will be UPDATED:. anndata 0.7.6-py38h578d9bd_0 --> 0.8.0-py38h578d9bd_0; ca-certificates pkgs/main::ca-certificates-2022.4.26-~ --> conda-forge::ca-certificates-2022.5.18.1-ha878542_0; h5py 2.10.0-nompi_py38h513d04c_102 --> 3.6.0-nompi_py38hfbb2109_100; hdf5 1.10.5-nompi_h5b725eb_1114 --> 1.12.1-nompi_h2750804_100. The following packages will be SUPERSEDED by a higher-priority channel:. certifi pkgs/main::certifi-2022.5.18.1-py38h0~ --> conda-forge::certifi-2022.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265
https://github.com/scverse/scanpy/issues/2265:3184,Performance,cache,cached-property-,3184,1.1.1o-h166bdaf_0. Proceed ([y]/n)? y. Downloading and Extracting Packages; keyutils-1.6.1 | 115 KB | ############################################################################# | 100% ; h5py-3.6.0 | 1.4 MB | ############################################################################# | 100% ; cached_property-1.5. | 11 KB | ############################################################################# | 100% ; c-ares-1.18.1 | 113 KB | ############################################################################# | 100% ; anndata-0.8.0 | 151 KB | ############################################################################# | 100% ; libev-4.33 | 104 KB | ############################################################################# | 100% ; libnghttp2-1.46.0 | 680 KB | ############################################################################# | 100% ; libcurl-7.82.0 | 342 KB | ############################################################################# | 100% ; libssh2-1.10.0 | 233 KB | ############################################################################# | 100% ; cached-property-1.5. | 4 KB | ############################################################################# | 100% ; openssl-1.1.1o | 2.1 MB | ############################################################################# | 100% ; certifi-2022.5.18.1 | 150 KB | ############################################################################# | 100% ; hdf5-1.12.1 | 3.5 MB | ############################################################################# | 100% ; libedit-3.1.20191231 | 121 KB | ############################################################################# | 100% ; ca-certificates-2022 | 144 KB | ############################################################################# | 100% ; krb5-1.19.3 | 1.4 MB | ############################################################################# | 100% ; Preparing transaction: done; Verifying transaction: done; Executing transaction: done. ```. Any ideas??,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265
https://github.com/scverse/scanpy/issues/2265:1609,Security,certificate,certificates,1609,"8/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```. The messages when updating anndata:; ```; The following packages will be REMOVED:. pytables-3.6.1-py38h9f153d1_1. The following packages will be UPDATED:. anndata 0.7.6-py38h578d9bd_0 --> 0.8.0-py38h578d9bd_0; ca-certificates pkgs/main::ca-certificates-2022.4.26-~ --> conda-forge::ca-certificates-2022.5.18.1-ha878542_0; h5py 2.10.0-nompi_py38h513d04c_102 --> 3.6.0-nompi_py38hfbb2109_100; hdf5 1.10.5-nompi_h5b725eb_1114 --> 1.12.1-nompi_h2750804_100. The following packages will be SUPERSEDED by a higher-priority channel:. certifi pkgs/main::certifi-2022.5.18.1-py38h0~ --> conda-forge::certifi-2022.5.18.1-py38h578d9bd_0; openssl pkgs/main::openssl-1.1.1o-h7f8727e_0 --> conda-forge::openssl-1.1.1o-h166bdaf_0. Proceed ([y]/n)? y. Downloading and Extracting Packages; keyutils-1.6.1 | 115 KB | ############################################################################# | 100% ; h5py-3.6.0 | 1.4 MB | ############################################################################# | 100% ; cached_property-1.5. | 11 KB | ############################################################################# | 100% ; c-ares-1.18.1 | 113 KB | ############################################################################# | 100% ; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265
https://github.com/scverse/scanpy/issues/2265:1636,Security,certificate,certificates-,1636,"8/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```. The messages when updating anndata:; ```; The following packages will be REMOVED:. pytables-3.6.1-py38h9f153d1_1. The following packages will be UPDATED:. anndata 0.7.6-py38h578d9bd_0 --> 0.8.0-py38h578d9bd_0; ca-certificates pkgs/main::ca-certificates-2022.4.26-~ --> conda-forge::ca-certificates-2022.5.18.1-ha878542_0; h5py 2.10.0-nompi_py38h513d04c_102 --> 3.6.0-nompi_py38hfbb2109_100; hdf5 1.10.5-nompi_h5b725eb_1114 --> 1.12.1-nompi_h2750804_100. The following packages will be SUPERSEDED by a higher-priority channel:. certifi pkgs/main::certifi-2022.5.18.1-py38h0~ --> conda-forge::certifi-2022.5.18.1-py38h578d9bd_0; openssl pkgs/main::openssl-1.1.1o-h7f8727e_0 --> conda-forge::openssl-1.1.1o-h166bdaf_0. Proceed ([y]/n)? y. Downloading and Extracting Packages; keyutils-1.6.1 | 115 KB | ############################################################################# | 100% ; h5py-3.6.0 | 1.4 MB | ############################################################################# | 100% ; cached_property-1.5. | 11 KB | ############################################################################# | 100% ; c-ares-1.18.1 | 113 KB | ############################################################################# | 100% ; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265
https://github.com/scverse/scanpy/issues/2265:1681,Security,certificate,certificates-,1681," from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```. The messages when updating anndata:; ```; The following packages will be REMOVED:. pytables-3.6.1-py38h9f153d1_1. The following packages will be UPDATED:. anndata 0.7.6-py38h578d9bd_0 --> 0.8.0-py38h578d9bd_0; ca-certificates pkgs/main::ca-certificates-2022.4.26-~ --> conda-forge::ca-certificates-2022.5.18.1-ha878542_0; h5py 2.10.0-nompi_py38h513d04c_102 --> 3.6.0-nompi_py38hfbb2109_100; hdf5 1.10.5-nompi_h5b725eb_1114 --> 1.12.1-nompi_h2750804_100. The following packages will be SUPERSEDED by a higher-priority channel:. certifi pkgs/main::certifi-2022.5.18.1-py38h0~ --> conda-forge::certifi-2022.5.18.1-py38h578d9bd_0; openssl pkgs/main::openssl-1.1.1o-h7f8727e_0 --> conda-forge::openssl-1.1.1o-h166bdaf_0. Proceed ([y]/n)? y. Downloading and Extracting Packages; keyutils-1.6.1 | 115 KB | ############################################################################# | 100% ; h5py-3.6.0 | 1.4 MB | ############################################################################# | 100% ; cached_property-1.5. | 11 KB | ############################################################################# | 100% ; c-ares-1.18.1 | 113 KB | ############################################################################# | 100% ; anndata-0.8.0 | 151 KB | ################################",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265
https://github.com/scverse/scanpy/issues/2265:3764,Security,certificate,certificates-,3764,1.1.1o-h166bdaf_0. Proceed ([y]/n)? y. Downloading and Extracting Packages; keyutils-1.6.1 | 115 KB | ############################################################################# | 100% ; h5py-3.6.0 | 1.4 MB | ############################################################################# | 100% ; cached_property-1.5. | 11 KB | ############################################################################# | 100% ; c-ares-1.18.1 | 113 KB | ############################################################################# | 100% ; anndata-0.8.0 | 151 KB | ############################################################################# | 100% ; libev-4.33 | 104 KB | ############################################################################# | 100% ; libnghttp2-1.46.0 | 680 KB | ############################################################################# | 100% ; libcurl-7.82.0 | 342 KB | ############################################################################# | 100% ; libssh2-1.10.0 | 233 KB | ############################################################################# | 100% ; cached-property-1.5. | 4 KB | ############################################################################# | 100% ; openssl-1.1.1o | 2.1 MB | ############################################################################# | 100% ; certifi-2022.5.18.1 | 150 KB | ############################################################################# | 100% ; hdf5-1.12.1 | 3.5 MB | ############################################################################# | 100% ; libedit-3.1.20191231 | 121 KB | ############################################################################# | 100% ; ca-certificates-2022 | 144 KB | ############################################################################# | 100% ; krb5-1.19.3 | 1.4 MB | ############################################################################# | 100% ; Preparing transaction: done; Verifying transaction: done; Executing transaction: done. ```. Any ideas??,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265
https://github.com/scverse/scanpy/issues/2265:1042,Testability,log,logging,1042,"load my scanpy 1.8.2 anymore. Error:. ```; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); /tmp/ipykernel_31935/912249142.py in <module>; ----> 1 import scanpy as sc. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```. The messages when updating anndata:; ```; The following packages will be REMOVED:. pytables-3.6.1-py38h9f153d1_1. The following packages will be UPDATED:. anndata 0.7.6-py38h578d9bd_0 --> 0.8.0-py38h578d9bd_0; ca-certificates pkgs/main::ca-certificates-2022.4.26-~ --> conda-forge::ca-certificates-2022.5.18.1-ha878542_0; h5py 2.10.0-nompi_py38h513d04c_102 --> 3.6.0-nompi_py38hfbb2109_100; hdf5 1.10.5-nompi_h5b725eb_1114 --> 1.12.1-nompi_h2750804_100. The following packages will be SUPERSEDED by a higher-priority channel:. certifi pkgs/main::certifi-2022.5.18.1-py38h0~ --> conda-forge::certifi-2022.5.18.1-py38h578d9bd_0; openssl pkgs/main::",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265
https://github.com/scverse/scanpy/issues/2265:1053,Testability,log,logg,1053,"load my scanpy 1.8.2 anymore. Error:. ```; ---------------------------------------------------------------------------; ModuleNotFoundError Traceback (most recent call last); /tmp/ipykernel_31935/912249142.py in <module>; ----> 1 import scanpy as sc. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ModuleNotFoundError: No module named 'tables'. ```. The messages when updating anndata:; ```; The following packages will be REMOVED:. pytables-3.6.1-py38h9f153d1_1. The following packages will be UPDATED:. anndata 0.7.6-py38h578d9bd_0 --> 0.8.0-py38h578d9bd_0; ca-certificates pkgs/main::ca-certificates-2022.4.26-~ --> conda-forge::ca-certificates-2022.5.18.1-ha878542_0; h5py 2.10.0-nompi_py38h513d04c_102 --> 3.6.0-nompi_py38hfbb2109_100; hdf5 1.10.5-nompi_h5b725eb_1114 --> 1.12.1-nompi_h2750804_100. The following packages will be SUPERSEDED by a higher-priority channel:. certifi pkgs/main::certifi-2022.5.18.1-py38h0~ --> conda-forge::certifi-2022.5.18.1-py38h578d9bd_0; openssl pkgs/main::",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2265
https://github.com/scverse/scanpy/issues/2266:783,Availability,error,error,783,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ------it is easy for v1.9.1 out of memory.; I have the same data(200000x20000), the RAM of my compute is 64 GB, and the v1.8 can cope it easy, but the v1.9.1 is easy to occur the memoryError from the sc.read('./xxx.h5ad'). **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); sc.read('./xxx.h5ad'); ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions; v1.9.1; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>; ![image](https://user-images.githubusercontent.com/50618480/170998448-db4300d9-54f0-4f03-b2be-7f6880006b29.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2266
https://github.com/scverse/scanpy/issues/2266:897,Testability,log,logging,897,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ------it is easy for v1.9.1 out of memory.; I have the same data(200000x20000), the RAM of my compute is 64 GB, and the v1.8 can cope it easy, but the v1.9.1 is easy to occur the memoryError from the sc.read('./xxx.h5ad'). **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); sc.read('./xxx.h5ad'); ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions; v1.9.1; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>; ![image](https://user-images.githubusercontent.com/50618480/170998448-db4300d9-54f0-4f03-b2be-7f6880006b29.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2266
https://github.com/scverse/scanpy/issues/2266:475,Usability,guid,guide,475,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ------it is easy for v1.9.1 out of memory.; I have the same data(200000x20000), the RAM of my compute is 64 GB, and the v1.8 can cope it easy, but the v1.9.1 is easy to occur the memoryError from the sc.read('./xxx.h5ad'). **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); sc.read('./xxx.h5ad'); ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions; v1.9.1; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>; ![image](https://user-images.githubusercontent.com/50618480/170998448-db4300d9-54f0-4f03-b2be-7f6880006b29.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2266
https://github.com/scverse/scanpy/issues/2267:2335,Deployability,update,updated,2335,"# Make a dummy label column; data.obs['rand'] = np.random.randint(0, 5, data.obs.shape).astype(str). sc.pl.pca(; data,; color='rand',; legend_loc='upper right', #or any other default in matplotlib ; ); ```. You will see that the plot does not have any visible legend at all. This is consistent with other legend locations that are not 'on data' or 'None'; <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.0.1; appnope 0.1.2; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 0.8.3; fastjsonschema NA; fontTools 4.33.3; google NA; h5py 3.6.0; hypergeom_ufunc NA; idna 3.3; ipykernel 6.13.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; jsonschema 4.5.1; kaleido 0.2.1; kiwisolver 1.3.2; llvmlite 0.38.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbformat 5.4.0; nbinom_ufunc NA; numba 0.55.1; numpy 1.20.3; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.8.0; prompt_toolkit 3.0.20; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.12.0; pynndescent 0.5.7; pyparsing 3.0.9; pyrsistent NA; pytz 2022.1; scipy 1.8.0; session_info 1.0.0; setuptools 61.2.0; six 1.16.0; sklearn 1.0.2; sphinxcontrib NA; stack_data 0.2.0; tenacity NA; threadpoolctl 3.1.0; tornado 6.1; tqdm 4.64.0; traitlets 5.1.1; typing_extensions NA; umap 0.5.3; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 8.2.0; jupyter_client 7.2.2; jupyter_core 4.9.2; notebook 6.4.11; -----; Python 3.9.12 (main, Apr 5 2022, 01:53:17) [Clang 12.0.0 ]; macOS-10.16-x86_64-i386-64bit; -----; Session information updated at 2022-05-30 13:19. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2267
https://github.com/scverse/scanpy/issues/2267:28,Usability,guid,guide,28,"**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc ; import random ; import numpy as np. data = sc.datasets.pbmc3k(); sc.pp.pca(data). # Make a dummy label column; data.obs['rand'] = np.random.randint(0, 5, data.obs.shape).astype(str). sc.pl.pca(; data,; color='rand',; legend_loc='upper right', #or any other default in matplotlib ; ); ```. You will see that the plot does not have any visible legend at all. This is consistent with other legend locations that are not 'on data' or 'None'; <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.0.1; appnope 0.1.2; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 0.8.3; fastjsonschema NA; fontTools 4.33.3; google NA; h5py 3.6.0; hypergeom_ufunc NA; idna 3.3; ipykernel 6.13.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; jsonschema 4.5.1; kaleido 0.2.1; kiwisolver 1.3.2; llvmlite 0.38.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbformat 5.4.0; nbinom_ufunc NA; numba 0.55.1; numpy 1.20.3; packaging 21.3; pandas 1.4.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.8.0; prompt_toolkit 3.0.20; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.12.0; pynndescent 0.5.7; pyparsing 3.0.9; pyrsistent NA; pytz 2022.1; scipy 1.8.0; session_info 1.0.0; setuptools 61.2.0; six 1.16.0; sklearn 1.0.2; sphinxcontrib NA; stack_data 0.2.0; tenacity NA; threadpoolctl 3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2267
https://github.com/scverse/scanpy/pull/2269:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2269
https://github.com/scverse/scanpy/pull/2269:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2269
https://github.com/scverse/scanpy/pull/2271:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/pre-commit/pre-commit-hooks: v4.2.0  v4.3.0](https://github.com/pre-commit/pre-commit-hooks/compare/v4.2.0...v4.3.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2271
https://github.com/scverse/scanpy/pull/2272:0,Availability,mask,mask,0,mask parameter added to pca method in _pca.py ; test_pca_mask added to test_pca.py; Deprecation warning on use_highly_variable parameter added to test_deprecations.py. ### [rendered docs](https://icb-scanpy--2272.com.readthedocs.build/en/2272/generated/scanpy.pp.pca.html),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2272
https://github.com/scverse/scanpy/pull/2274:186,Deployability,update,updated,186,"Some tests are broken, here are some fixes for that. * Visium reference test was just wrong, dots should have been transparent.; * igraph 0.9.11 has different results for `""fr""` layout, updated tests accordingly (https://github.com/igraph/python-igraph/issues/545); * 32 bit PCA computation is now accurate within 32 bit rounding, so tests checking for random seed changes have been disabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2274
https://github.com/scverse/scanpy/pull/2274:5,Testability,test,tests,5,"Some tests are broken, here are some fixes for that. * Visium reference test was just wrong, dots should have been transparent.; * igraph 0.9.11 has different results for `""fr""` layout, updated tests accordingly (https://github.com/igraph/python-igraph/issues/545); * 32 bit PCA computation is now accurate within 32 bit rounding, so tests checking for random seed changes have been disabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2274
https://github.com/scverse/scanpy/pull/2274:72,Testability,test,test,72,"Some tests are broken, here are some fixes for that. * Visium reference test was just wrong, dots should have been transparent.; * igraph 0.9.11 has different results for `""fr""` layout, updated tests accordingly (https://github.com/igraph/python-igraph/issues/545); * 32 bit PCA computation is now accurate within 32 bit rounding, so tests checking for random seed changes have been disabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2274
https://github.com/scverse/scanpy/pull/2274:194,Testability,test,tests,194,"Some tests are broken, here are some fixes for that. * Visium reference test was just wrong, dots should have been transparent.; * igraph 0.9.11 has different results for `""fr""` layout, updated tests accordingly (https://github.com/igraph/python-igraph/issues/545); * 32 bit PCA computation is now accurate within 32 bit rounding, so tests checking for random seed changes have been disabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2274
https://github.com/scverse/scanpy/pull/2274:334,Testability,test,tests,334,"Some tests are broken, here are some fixes for that. * Visium reference test was just wrong, dots should have been transparent.; * igraph 0.9.11 has different results for `""fr""` layout, updated tests accordingly (https://github.com/igraph/python-igraph/issues/545); * 32 bit PCA computation is now accurate within 32 bit rounding, so tests checking for random seed changes have been disabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2274
https://github.com/scverse/scanpy/pull/2275:23,Testability,test,tests,23,Backport PR #2274: Fix tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2275
https://github.com/scverse/scanpy/pull/2277:29,Testability,Test,Tests,29,Fixes #2267 . ## TODO. - [ ] Tests; - [ ] Changelog,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2277
https://github.com/scverse/scanpy/pull/2279:19,Deployability,Update,Update,19,Backport PR #2269: Update CellRank's metion in the ecosystem,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2279
https://github.com/scverse/scanpy/pull/2280:72,Testability,log,logic,72,"Alternative to #2255. Fixes #2254, #2227. Puts all the diffmap specific logic inside the diffmap plotting function. ## TODO. - [ ] consider the components argument; - [ ] tests (cause it has none apparently)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2280
https://github.com/scverse/scanpy/pull/2280:171,Testability,test,tests,171,"Alternative to #2255. Fixes #2254, #2227. Puts all the diffmap specific logic inside the diffmap plotting function. ## TODO. - [ ] consider the components argument; - [ ] tests (cause it has none apparently)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2280
https://github.com/scverse/scanpy/issues/2281:159,Deployability,pipeline,pipeline,159,"Hey,. we moved from conda-forge to Bioconda -> https://github.com/scverse/scanpy/issues/1169. Unfortunately, this comes at a cost which is highly relevant for pipeline building. nf-core wants to add support for scverse data structures: https://github.com/nf-core/scrnaseq/issues/68 The issue is that Bioconda autogenerates Docker & Singularity containers which Nextflow pipelines always use to provide support for all execution environments. conda-forge does not. The official Dockerhub is firstly stuck in an old version and, when used, it lacks the package `procps` that is used by nextflow to track execution. How serious are the Bioconda issues? Can we resolve them and move back? I'd avoid always having to manage also our own container releases and love the automated container building by Bioconda.; I was also made aware by @apeltzer that bio specific tools should live in bioconda. Choosing to put them in conda-forge is not really desired. @ivirshup @flying-sheep . CC @drpatelh @fmalmeida @apeltzer @grst",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:370,Deployability,pipeline,pipelines,370,"Hey,. we moved from conda-forge to Bioconda -> https://github.com/scverse/scanpy/issues/1169. Unfortunately, this comes at a cost which is highly relevant for pipeline building. nf-core wants to add support for scverse data structures: https://github.com/nf-core/scrnaseq/issues/68 The issue is that Bioconda autogenerates Docker & Singularity containers which Nextflow pipelines always use to provide support for all execution environments. conda-forge does not. The official Dockerhub is firstly stuck in an old version and, when used, it lacks the package `procps` that is used by nextflow to track execution. How serious are the Bioconda issues? Can we resolve them and move back? I'd avoid always having to manage also our own container releases and love the automated container building by Bioconda.; I was also made aware by @apeltzer that bio specific tools should live in bioconda. Choosing to put them in conda-forge is not really desired. @ivirshup @flying-sheep . CC @drpatelh @fmalmeida @apeltzer @grst",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:742,Deployability,release,releases,742,"Hey,. we moved from conda-forge to Bioconda -> https://github.com/scverse/scanpy/issues/1169. Unfortunately, this comes at a cost which is highly relevant for pipeline building. nf-core wants to add support for scverse data structures: https://github.com/nf-core/scrnaseq/issues/68 The issue is that Bioconda autogenerates Docker & Singularity containers which Nextflow pipelines always use to provide support for all execution environments. conda-forge does not. The official Dockerhub is firstly stuck in an old version and, when used, it lacks the package `procps` that is used by nextflow to track execution. How serious are the Bioconda issues? Can we resolve them and move back? I'd avoid always having to manage also our own container releases and love the automated container building by Bioconda.; I was also made aware by @apeltzer that bio specific tools should live in bioconda. Choosing to put them in conda-forge is not really desired. @ivirshup @flying-sheep . CC @drpatelh @fmalmeida @apeltzer @grst",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2281:689,Safety,avoid,avoid,689,"Hey,. we moved from conda-forge to Bioconda -> https://github.com/scverse/scanpy/issues/1169. Unfortunately, this comes at a cost which is highly relevant for pipeline building. nf-core wants to add support for scverse data structures: https://github.com/nf-core/scrnaseq/issues/68 The issue is that Bioconda autogenerates Docker & Singularity containers which Nextflow pipelines always use to provide support for all execution environments. conda-forge does not. The official Dockerhub is firstly stuck in an old version and, when used, it lacks the package `procps` that is used by nextflow to track execution. How serious are the Bioconda issues? Can we resolve them and move back? I'd avoid always having to manage also our own container releases and love the automated container building by Bioconda.; I was also made aware by @apeltzer that bio specific tools should live in bioconda. Choosing to put them in conda-forge is not really desired. @ivirshup @flying-sheep . CC @drpatelh @fmalmeida @apeltzer @grst",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2281
https://github.com/scverse/scanpy/issues/2282:1297,Availability,Avail,Available,1297,"- [x ] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # create new env; conda install -c pytorch pytorch; conda install -c pytorch cudatoolkit=11.3. conda install -c bioconda scanpy; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/linux-64::__glibc==2.31=0; - feature:|@/linux-64::__glibc==2.31=0. Your installed version is: 2.31; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282
https://github.com/scverse/scanpy/issues/2282:525,Deployability,install,install,525,"- [x ] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # create new env; conda install -c pytorch pytorch; conda install -c pytorch cudatoolkit=11.3. conda install -c bioconda scanpy; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/linux-64::__glibc==2.31=0; - feature:|@/linux-64::__glibc==2.31=0. Your installed version is: 2.31; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282
https://github.com/scverse/scanpy/issues/2282:559,Deployability,install,install,559,"- [x ] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # create new env; conda install -c pytorch pytorch; conda install -c pytorch cudatoolkit=11.3. conda install -c bioconda scanpy; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/linux-64::__glibc==2.31=0; - feature:|@/linux-64::__glibc==2.31=0. Your installed version is: 2.31; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282
https://github.com/scverse/scanpy/issues/2282:602,Deployability,install,install,602,"- [x ] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # create new env; conda install -c pytorch pytorch; conda install -c pytorch cudatoolkit=11.3. conda install -c bioconda scanpy; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/linux-64::__glibc==2.31=0; - feature:|@/linux-64::__glibc==2.31=0. Your installed version is: 2.31; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282
https://github.com/scverse/scanpy/issues/2282:1476,Deployability,install,installed,1476,"- [x ] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # create new env; conda install -c pytorch pytorch; conda install -c pytorch cudatoolkit=11.3. conda install -c bioconda scanpy; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/linux-64::__glibc==2.31=0; - feature:|@/linux-64::__glibc==2.31=0. Your installed version is: 2.31; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282
https://github.com/scverse/scanpy/issues/2282:758,Modifiability,flexible,flexible,758,"- [x ] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # create new env; conda install -c pytorch pytorch; conda install -c pytorch cudatoolkit=11.3. conda install -c bioconda scanpy; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/linux-64::__glibc==2.31=0; - feature:|@/linux-64::__glibc==2.31=0. Your installed version is: 2.31; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282
https://github.com/scverse/scanpy/issues/2282:1004,Modifiability,flexible,flexible,1004,"- [x ] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # create new env; conda install -c pytorch pytorch; conda install -c pytorch cudatoolkit=11.3. conda install -c bioconda scanpy; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/linux-64::__glibc==2.31=0; - feature:|@/linux-64::__glibc==2.31=0. Your installed version is: 2.31; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282
https://github.com/scverse/scanpy/issues/2282:1145,Safety,abort,abort,1145,"- [x ] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # create new env; conda install -c pytorch pytorch; conda install -c pytorch cudatoolkit=11.3. conda install -c bioconda scanpy; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/linux-64::__glibc==2.31=0; - feature:|@/linux-64::__glibc==2.31=0. Your installed version is: 2.31; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282
https://github.com/scverse/scanpy/issues/2282:259,Usability,guid,guide,259,"- [x ] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # create new env; conda install -c pytorch pytorch; conda install -c pytorch cudatoolkit=11.3. conda install -c bioconda scanpy; Collecting package metadata (current_repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): done; Solving environment: failed with initial frozen solve. Retrying with flexible solve.; Solving environment: \; Found conflicts! Looking for incompatible packages.; This can take several minutes. Press CTRL-C to abort.; failed. UnsatisfiableError: The following specifications were found to be incompatible with each other:. Output in format: Requested package -> Available versionsThe following specifications were found to be incompatible with your system:. - feature:/linux-64::__glibc==2.31=0; - feature:|@/linux-64::__glibc==2.31=0. Your installed version is: 2.31; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2282
https://github.com/scverse/scanpy/issues/2284:158,Deployability,integrat,integrated,158,"Is it possible to have one figure pf spatial gene expression stack over (superimpose) another? The following function will give me two subplots instead of an integrated one ; `sc.pl.spatial(ada, img_key=""hires"", color=[""Gene1"", ""Gene2""]); `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2284
https://github.com/scverse/scanpy/issues/2284:158,Integrability,integrat,integrated,158,"Is it possible to have one figure pf spatial gene expression stack over (superimpose) another? The following function will give me two subplots instead of an integrated one ; `sc.pl.spatial(ada, img_key=""hires"", color=[""Gene1"", ""Gene2""]); `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2284
https://github.com/scverse/scanpy/issues/2285:519,Availability,error,error,519,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # NOTE: This throws error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='3d'; ). # NOTE: This doesn't throw error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='2d'; ). # NOTE: the error is that one of the genes in `de_genes` has almost the value for all cells; np.unique(adata.X[:, de_genes.index('KRT1')]); > array([-0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931]). # Thus this is a combination of projection 3d and rounding. This should not throw an error and just plot all points same color; ```. ```pytb; [Paste the error output produced by the above code here]; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Input In [403], in <cell line: 1>(); ----> 1 sc.pl.embedding(; 2 adata, basis='X_phate_alone', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; 3 projection='3d'; 4 ). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/scanpy/plotting/_tools/scatte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:679,Availability,error,error,679,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # NOTE: This throws error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='3d'; ). # NOTE: This doesn't throw error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='2d'; ). # NOTE: the error is that one of the genes in `de_genes` has almost the value for all cells; np.unique(adata.X[:, de_genes.index('KRT1')]); > array([-0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931]). # Thus this is a combination of projection 3d and rounding. This should not throw an error and just plot all points same color; ```. ```pytb; [Paste the error output produced by the above code here]; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Input In [403], in <cell line: 1>(); ----> 1 sc.pl.embedding(; 2 adata, basis='X_phate_alone', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; 3 projection='3d'; 4 ). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/scanpy/plotting/_tools/scatte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:824,Availability,error,error,824,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # NOTE: This throws error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='3d'; ). # NOTE: This doesn't throw error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='2d'; ). # NOTE: the error is that one of the genes in `de_genes` has almost the value for all cells; np.unique(adata.X[:, de_genes.index('KRT1')]); > array([-0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931]). # Thus this is a combination of projection 3d and rounding. This should not throw an error and just plot all points same color; ```. ```pytb; [Paste the error output produced by the above code here]; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Input In [403], in <cell line: 1>(); ----> 1 sc.pl.embedding(; 2 adata, basis='X_phate_alone', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; 3 projection='3d'; 4 ). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/scanpy/plotting/_tools/scatte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:1496,Availability,error,error,1496," This throws error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='3d'; ). # NOTE: This doesn't throw error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='2d'; ). # NOTE: the error is that one of the genes in `de_genes` has almost the value for all cells; np.unique(adata.X[:, de_genes.index('KRT1')]); > array([-0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931]). # Thus this is a combination of projection 3d and rounding. This should not throw an error and just plot all points same color; ```. ```pytb; [Paste the error output produced by the above code here]; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Input In [403], in <cell line: 1>(); ----> 1 sc.pl.embedding(; 2 adata, basis='X_phate_alone', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; 3 projection='3d'; 4 ). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:325, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 32",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:1564,Availability,error,error,1564,"is doesn't throw error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='2d'; ). # NOTE: the error is that one of the genes in `de_genes` has almost the value for all cells; np.unique(adata.X[:, de_genes.index('KRT1')]); > array([-0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931]). # Thus this is a combination of projection 3d and rounding. This should not throw an error and just plot all points same color; ```. ```pytb; [Paste the error output produced by the above code here]; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Input In [403], in <cell line: 1>(); ----> 1 sc.pl.embedding(; 2 adata, basis='X_phate_alone', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; 3 projection='3d'; 4 ). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:325, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 323 # make the scatter plot; 324 if projection == '3d':; --> 325 cax = ax.scatter(; 326 coords[:, 0],; 327 coords[:, 1],; 328 coords[:, 2],; 329 marker=""."",; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:4820,Availability,mask,masked,4820,"ection to initialize the face and edgecolors; 541 # just in case it is a scalarmappable with a colormap.; --> 542 self.update_scalarmappable(); 543 offsets = self.get_offsets(); 544 if len(offsets) > 0:. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/collections.py:926, in Collection.update_scalarmappable(self); 924 # pcolormesh, scatter, maybe others flatten their _A; 925 self._alpha = self._alpha.reshape(self._A.shape); --> 926 self._mapped_colors = self.to_rgba(self._A, self._alpha); 928 if self._face_is_mapped:; 929 self._facecolors = self._mapped_colors. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/cm.py:359, in ScalarMappable.to_rgba(self, x, alpha, bytes, norm); 357 x = ma.asarray(x); 358 if norm:; --> 359 x = self.norm(x); 360 rgba = self.cmap(x, alpha=alpha, bytes=bytes); 361 return rgba. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/colors.py:1193, in Normalize.__call__(self, value, clip); 1191 result.fill(0) # Or should it be all masked? Or 0.5?; 1192 elif vmin > vmax:; -> 1193 raise ValueError(""minvalue must be less than or equal to maxvalue""); 1194 else:; 1195 if clip:. ValueError: minvalue must be less than or equal to maxvalue. ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); File ~/anaconda3/envs/ml/lib/python3.9/site-packages/IPython/core/formatters.py:339, in BaseFormatter.__call__(self, obj); 337 pass; 338 else:; --> 339 return printer(obj); 340 # Finally look for special method names; 341 method = get_real_method(obj, self.print_method). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/IPython/core/pylabtools.py:151, in print_figure(fig, fmt, bbox_inches, base64, **kwargs); 148 from matplotlib.backend_bases import FigureCanvasBase; 149 FigureCanvasBase(fig); --> 151 fig.canvas.print_figure(bytes_io, **kw); 152 data = bytes_io.getvalue(); 153 if fmt == 'svg':. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:3123,Deployability,patch,patches,3123,"rs_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 323 # make the scatter plot; 324 if projection == '3d':; --> 325 cax = ax.scatter(; 326 coords[:, 0],; 327 coords[:, 1],; 328 coords[:, 2],; 329 marker=""."",; 330 c=color_vector,; 331 rasterized=settings._vector_friendly,; 332 norm=normalize,; 333 **kwargs,; 334 ); 335 else:; 336 scatter = (; 337 partial(ax.scatter, s=size, plotnonfinite=True); 338 if scale_factor is None; (...); 341 ) # size in circles is radius; 342 ). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:2417, in Axes3D.scatter(self, xs, ys, zs, zdir, s, c, depthshade, *args, **kwargs); 2414 zs = zs.copy(); 2416 patches = super().scatter(xs, ys, s=s, c=c, *args, **kwargs); -> 2417 art3d.patch_collection_2d_to_3d(patches, zs=zs, zdir=zdir,; 2418 depthshade=depthshade); 2420 if self._zmargin < 0.05 and xs.size > 0:; 2421 self.set_zmargin(0.05). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/art3d.py:674, in patch_collection_2d_to_3d(col, zs, zdir, depthshade); 672 col._depthshade = depthshade; 673 col._in_draw = False; --> 674 col.set_3d_properties(zs, zdir). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/art3d.py:542, in Path3DCollection.set_3d_properties(self, zs, zdir); 539 def set_3d_properties(self, zs, zdir):; 540 # Force the collection to initialize the face and edgecolors; 541 # just in case it is a scalarmappable with a colormap.; --> 542 self.update_scalarmappable(); 543 offsets = self.get_offsets(); 544 if len(offsets) > 0:. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/collections.py:926, in Collection.update_scalar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:3225,Deployability,patch,patches,3225,"_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 323 # make the scatter plot; 324 if projection == '3d':; --> 325 cax = ax.scatter(; 326 coords[:, 0],; 327 coords[:, 1],; 328 coords[:, 2],; 329 marker=""."",; 330 c=color_vector,; 331 rasterized=settings._vector_friendly,; 332 norm=normalize,; 333 **kwargs,; 334 ); 335 else:; 336 scatter = (; 337 partial(ax.scatter, s=size, plotnonfinite=True); 338 if scale_factor is None; (...); 341 ) # size in circles is radius; 342 ). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:2417, in Axes3D.scatter(self, xs, ys, zs, zdir, s, c, depthshade, *args, **kwargs); 2414 zs = zs.copy(); 2416 patches = super().scatter(xs, ys, s=s, c=c, *args, **kwargs); -> 2417 art3d.patch_collection_2d_to_3d(patches, zs=zs, zdir=zdir,; 2418 depthshade=depthshade); 2420 if self._zmargin < 0.05 and xs.size > 0:; 2421 self.set_zmargin(0.05). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/art3d.py:674, in patch_collection_2d_to_3d(col, zs, zdir, depthshade); 672 col._depthshade = depthshade; 673 col._in_draw = False; --> 674 col.set_3d_properties(zs, zdir). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/art3d.py:542, in Path3DCollection.set_3d_properties(self, zs, zdir); 539 def set_3d_properties(self, zs, zdir):; 540 # Force the collection to initialize the face and edgecolors; 541 # just in case it is a scalarmappable with a colormap.; --> 542 self.update_scalarmappable(); 543 offsets = self.get_offsets(); 544 if len(offsets) > 0:. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/collections.py:926, in Collection.update_scalarmappable(self); 924 # pcolormesh, scatter, maybe others flatten their _A; 925 self._alpha = self._alpha.reshape(self._A.s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:7096,Deployability,patch,patch,7096," suppress()); 2229 with ctx:; -> 2230 self.figure.draw(renderer); 2232 if bbox_inches:; 2233 if bbox_inches == ""tight"":. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/artist.py:74, in _finalize_rasterization.<locals>.draw_wrapper(artist, renderer, *args, **kwargs); 72 @wraps(draw); 73 def draw_wrapper(artist, renderer, *args, **kwargs):; ---> 74 result = draw(artist, renderer, *args, **kwargs); 75 if renderer._rasterizing:; 76 renderer.stop_rasterizing(). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/artist.py:51, in allow_rasterization.<locals>.draw_wrapper(artist, renderer, *args, **kwargs); 48 if artist.get_agg_filter() is not None:; 49 renderer.start_filter(); ---> 51 return draw(artist, renderer, *args, **kwargs); 52 finally:; 53 if artist.get_agg_filter() is not None:. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/figure.py:2790, in Figure.draw(self, renderer); 2787 # ValueError can occur when resizing a window.; 2789 self.patch.draw(renderer); -> 2790 mimage._draw_list_compositing_images(; 2791 renderer, self, artists, self.suppressComposite); 2793 for sfig in self.subfigs:; 2794 sfig.draw(renderer). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/image.py:132, in _draw_list_compositing_images(renderer, parent, artists, suppress_composite); 130 if not_composite or not has_images:; 131 for a in artists:; --> 132 a.draw(renderer); 133 else:; 134 # Composite any adjacent images together; 135 image_group = []. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/artist.py:51, in allow_rasterization.<locals>.draw_wrapper(artist, renderer, *args, **kwargs); 48 if artist.get_agg_filter() is not None:; 49 renderer.start_filter(); ---> 51 return draw(artist, renderer, *args, **kwargs); 52 finally:; 53 if artist.get_agg_filter() is not None:. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:485, in Axes3D.draw(self, renderer); 480 # Calculate projection o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:8117,Deployability,patch,patches,8117,".patch.draw(renderer); -> 2790 mimage._draw_list_compositing_images(; 2791 renderer, self, artists, self.suppressComposite); 2793 for sfig in self.subfigs:; 2794 sfig.draw(renderer). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/image.py:132, in _draw_list_compositing_images(renderer, parent, artists, suppress_composite); 130 if not_composite or not has_images:; 131 for a in artists:; --> 132 a.draw(renderer); 133 else:; 134 # Composite any adjacent images together; 135 image_group = []. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/artist.py:51, in allow_rasterization.<locals>.draw_wrapper(artist, renderer, *args, **kwargs); 48 if artist.get_agg_filter() is not None:; 49 renderer.start_filter(); ---> 51 return draw(artist, renderer, *args, **kwargs); 52 finally:; 53 if artist.get_agg_filter() is not None:. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:485, in Axes3D.draw(self, renderer); 480 # Calculate projection of collections and patches and zorder them.; 481 # Make sure they are drawn above the grids.; 482 zorder_offset = max(axis.get_zorder(); 483 for axis in self._get_axis_list()) + 1; 484 for i, col in enumerate(; --> 485 sorted(self.collections,; 486 key=do_3d_projection,; 487 reverse=True)):; 488 col.zorder = zorder_offset + i; 489 for i, patch in enumerate(; 490 sorted(self.patches,; 491 key=do_3d_projection,; 492 reverse=True)):. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:471, in Axes3D.draw.<locals>.do_3d_projection(artist); 458 """"""; 459 Call `do_3d_projection` on an *artist*, and warn if passing; 460 *renderer*.; (...); 464 *renderer* and raise a warning.; 465 """"""; 467 if artist.__module__ == 'mpl_toolkits.mplot3d.art3d':; 468 # Our 3D Artists have deprecated the renderer parameter, so; 469 # avoid passing it to them; call this directly once the; 470 # deprecation has expired.; --> 471 return artist.do_3d_projection(); 473 _api.warn_deprec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:8438,Deployability,patch,patch,8438,"130 if not_composite or not has_images:; 131 for a in artists:; --> 132 a.draw(renderer); 133 else:; 134 # Composite any adjacent images together; 135 image_group = []. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/artist.py:51, in allow_rasterization.<locals>.draw_wrapper(artist, renderer, *args, **kwargs); 48 if artist.get_agg_filter() is not None:; 49 renderer.start_filter(); ---> 51 return draw(artist, renderer, *args, **kwargs); 52 finally:; 53 if artist.get_agg_filter() is not None:. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:485, in Axes3D.draw(self, renderer); 480 # Calculate projection of collections and patches and zorder them.; 481 # Make sure they are drawn above the grids.; 482 zorder_offset = max(axis.get_zorder(); 483 for axis in self._get_axis_list()) + 1; 484 for i, col in enumerate(; --> 485 sorted(self.collections,; 486 key=do_3d_projection,; 487 reverse=True)):; 488 col.zorder = zorder_offset + i; 489 for i, patch in enumerate(; 490 sorted(self.patches,; 491 key=do_3d_projection,; 492 reverse=True)):. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:471, in Axes3D.draw.<locals>.do_3d_projection(artist); 458 """"""; 459 Call `do_3d_projection` on an *artist*, and warn if passing; 460 *renderer*.; (...); 464 *renderer* and raise a warning.; 465 """"""; 467 if artist.__module__ == 'mpl_toolkits.mplot3d.art3d':; 468 # Our 3D Artists have deprecated the renderer parameter, so; 469 # avoid passing it to them; call this directly once the; 470 # deprecation has expired.; --> 471 return artist.do_3d_projection(); 473 _api.warn_deprecated(; 474 ""3.4"",; 475 message=""The 'renderer' parameter of ""; 476 ""do_3d_projection() was deprecated in Matplotlib ""; 477 ""%(since)s and will be removed %(removal)s.""); 478 return artist.do_3d_projection(renderer). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:431, in delete_parameter.<locals>.wrapper(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:8475,Deployability,patch,patches,8475,"> 132 a.draw(renderer); 133 else:; 134 # Composite any adjacent images together; 135 image_group = []. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/artist.py:51, in allow_rasterization.<locals>.draw_wrapper(artist, renderer, *args, **kwargs); 48 if artist.get_agg_filter() is not None:; 49 renderer.start_filter(); ---> 51 return draw(artist, renderer, *args, **kwargs); 52 finally:; 53 if artist.get_agg_filter() is not None:. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:485, in Axes3D.draw(self, renderer); 480 # Calculate projection of collections and patches and zorder them.; 481 # Make sure they are drawn above the grids.; 482 zorder_offset = max(axis.get_zorder(); 483 for axis in self._get_axis_list()) + 1; 484 for i, col in enumerate(; --> 485 sorted(self.collections,; 486 key=do_3d_projection,; 487 reverse=True)):; 488 col.zorder = zorder_offset + i; 489 for i, patch in enumerate(; 490 sorted(self.patches,; 491 key=do_3d_projection,; 492 reverse=True)):. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:471, in Axes3D.draw.<locals>.do_3d_projection(artist); 458 """"""; 459 Call `do_3d_projection` on an *artist*, and warn if passing; 460 *renderer*.; (...); 464 *renderer* and raise a warning.; 465 """"""; 467 if artist.__module__ == 'mpl_toolkits.mplot3d.art3d':; 468 # Our 3D Artists have deprecated the renderer parameter, so; 469 # avoid passing it to them; call this directly once the; 470 # deprecation has expired.; --> 471 return artist.do_3d_projection(); 473 _api.warn_deprecated(; 474 ""3.4"",; 475 message=""The 'renderer' parameter of ""; 476 ""do_3d_projection() was deprecated in Matplotlib ""; 477 ""%(since)s and will be removed %(removal)s.""); 478 return artist.do_3d_projection(renderer). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:431, in delete_parameter.<locals>.wrapper(*inner_args, **inner_kwargs); 421 deprecation_addendum = (; 422 f""I",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:12634,Deployability,update,updated,12634,"7.4; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; certifi 2022.05.18.1; cffi 1.15.0; charset_normalizer 2.0.12; cloudpickle 2.1.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dask 2022.6.1; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; deprecated 1.2.13; diffxpy v0.7.4; entrypoints 0.4; executing 0.8.3; flatbuffers NA; fsspec 2022.5.0; future 0.18.2; gast NA; google NA; graphtools 1.5.2; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; ipykernel 6.15.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.1.0; keras 2.9.0; kiwisolver 1.4.3; llvmlite 0.38.1; magic 3.0.0; markupsafe 2.1.1; matplotlib 3.4.3; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.2; numexpr 2.8.1; numpy 1.22.3; opt_einsum v3.3.0; packaging 21.3; pandas 1.4.2; parso 0.8.3; patsy 0.5.2; pcurve NA; pexpect 4.8.0; phate 1.0.7; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.29; psutil 5.9.1; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.12.0; pygsp 0.5.1; pyparsing 3.0.9; pytz 2022.1; requests 2.28.0; s_gd2 1.8; scipy 1.8.1; scprep 1.2.0; seaborn 0.11.2; session_info 1.0.0; setuptools 62.6.0; six 1.16.0; sklearn 1.1.1; slingshot NA; sparse 0.13.0; stack_data 0.3.0; statsmodels 0.13.2; swig_runtime_data4 NA; tasklogger 1.1.2; tensorboard 2.9.1; tensorflow 2.9.1; termcolor 1.1.0; threadpoolctl 3.1.0; tlz 0.11.2; toolz 0.11.2; torch 1.11.0; tornado 6.1; tqdm 4.64.0; traitlets 5.3.0; typing_extensions NA; unicodedata2 NA; urllib3 1.26.9; wcwidth 0.2.5; wrapt 1.14.1; yaml 6.0; zipp NA; zmq 23.1.0; -----; IPython 8.4.0; jupyter_client 7.3.4; jupyter_core 4.10.0; notebook 6.4.12; -----; Python 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:25:59) [GCC 10.3.0]; Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31; -----; Session information updated at 2022-06-28 16:19; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:6387,Integrability,wrap,wraps,6387,"anaconda3/envs/ml/lib/python3.9/site-packages/IPython/core/pylabtools.py:151, in print_figure(fig, fmt, bbox_inches, base64, **kwargs); 148 from matplotlib.backend_bases import FigureCanvasBase; 149 FigureCanvasBase(fig); --> 151 fig.canvas.print_figure(bytes_io, **kw); 152 data = bytes_io.getvalue(); 153 if fmt == 'svg':. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/backend_bases.py:2230, in FigureCanvasBase.print_figure(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs); 2226 ctx = (renderer._draw_disabled(); 2227 if hasattr(renderer, '_draw_disabled'); 2228 else suppress()); 2229 with ctx:; -> 2230 self.figure.draw(renderer); 2232 if bbox_inches:; 2233 if bbox_inches == ""tight"":. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/artist.py:74, in _finalize_rasterization.<locals>.draw_wrapper(artist, renderer, *args, **kwargs); 72 @wraps(draw); 73 def draw_wrapper(artist, renderer, *args, **kwargs):; ---> 74 result = draw(artist, renderer, *args, **kwargs); 75 if renderer._rasterizing:; 76 renderer.stop_rasterizing(). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/artist.py:51, in allow_rasterization.<locals>.draw_wrapper(artist, renderer, *args, **kwargs); 48 if artist.get_agg_filter() is not None:; 49 renderer.start_filter(); ---> 51 return draw(artist, renderer, *args, **kwargs); 52 finally:; 53 if artist.get_agg_filter() is not None:. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/figure.py:2790, in Figure.draw(self, renderer); 2787 # ValueError can occur when resizing a window.; 2789 self.patch.draw(renderer); -> 2790 mimage._draw_list_compositing_images(; 2791 renderer, self, artists, self.suppressComposite); 2793 for sfig in self.subfigs:; 2794 sfig.draw(renderer). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/image.py:132, in _draw_list_compositing_images(renderer, parent, artists, suppress_composi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:9118,Integrability,message,message,9118,"rids.; 482 zorder_offset = max(axis.get_zorder(); 483 for axis in self._get_axis_list()) + 1; 484 for i, col in enumerate(; --> 485 sorted(self.collections,; 486 key=do_3d_projection,; 487 reverse=True)):; 488 col.zorder = zorder_offset + i; 489 for i, patch in enumerate(; 490 sorted(self.patches,; 491 key=do_3d_projection,; 492 reverse=True)):. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:471, in Axes3D.draw.<locals>.do_3d_projection(artist); 458 """"""; 459 Call `do_3d_projection` on an *artist*, and warn if passing; 460 *renderer*.; (...); 464 *renderer* and raise a warning.; 465 """"""; 467 if artist.__module__ == 'mpl_toolkits.mplot3d.art3d':; 468 # Our 3D Artists have deprecated the renderer parameter, so; 469 # avoid passing it to them; call this directly once the; 470 # deprecation has expired.; --> 471 return artist.do_3d_projection(); 473 _api.warn_deprecated(; 474 ""3.4"",; 475 message=""The 'renderer' parameter of ""; 476 ""do_3d_projection() was deprecated in Matplotlib ""; 477 ""%(since)s and will be removed %(removal)s.""); 478 return artist.do_3d_projection(renderer). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:431, in delete_parameter.<locals>.wrapper(*inner_args, **inner_kwargs); 421 deprecation_addendum = (; 422 f""If any parameter follows {name!r}, they should be passed as ""; 423 f""keyword, not positionally.""); 424 warn_deprecated(; 425 since,; 426 name=repr(name),; (...); 429 else deprecation_addendum,; 430 **kwargs); --> 431 return func(*inner_args, **inner_kwargs). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/art3d.py:599, in Path3DCollection.do_3d_projection(self, renderer); 597 @_api.delete_parameter('3.4', 'renderer'); 598 def do_3d_projection(self, renderer=None):; --> 599 xs, ys, zs = self._offsets3d; 600 vxs, vys, vzs, vis = proj3d.proj_transform_clip(xs, ys, zs,; 601 self.axes.M); 602 # Sort the points based on z coordinates; 603 # Performance o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:9429,Integrability,wrap,wrapper,9429,"92 reverse=True)):. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:471, in Axes3D.draw.<locals>.do_3d_projection(artist); 458 """"""; 459 Call `do_3d_projection` on an *artist*, and warn if passing; 460 *renderer*.; (...); 464 *renderer* and raise a warning.; 465 """"""; 467 if artist.__module__ == 'mpl_toolkits.mplot3d.art3d':; 468 # Our 3D Artists have deprecated the renderer parameter, so; 469 # avoid passing it to them; call this directly once the; 470 # deprecation has expired.; --> 471 return artist.do_3d_projection(); 473 _api.warn_deprecated(; 474 ""3.4"",; 475 message=""The 'renderer' parameter of ""; 476 ""do_3d_projection() was deprecated in Matplotlib ""; 477 ""%(since)s and will be removed %(removal)s.""); 478 return artist.do_3d_projection(renderer). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:431, in delete_parameter.<locals>.wrapper(*inner_args, **inner_kwargs); 421 deprecation_addendum = (; 422 f""If any parameter follows {name!r}, they should be passed as ""; 423 f""keyword, not positionally.""); 424 warn_deprecated(; 425 since,; 426 name=repr(name),; (...); 429 else deprecation_addendum,; 430 **kwargs); --> 431 return func(*inner_args, **inner_kwargs). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/art3d.py:599, in Path3DCollection.do_3d_projection(self, renderer); 597 @_api.delete_parameter('3.4', 'renderer'); 598 def do_3d_projection(self, renderer=None):; --> 599 xs, ys, zs = self._offsets3d; 600 vxs, vys, vzs, vis = proj3d.proj_transform_clip(xs, ys, zs,; 601 self.axes.M); 602 # Sort the points based on z coordinates; 603 # Performance optimization: Create a sorted index array and reorder; 604 # points and point properties according to the index array. AttributeError: 'Path3DCollection' object has no attribute '_offsets3d'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; an",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:12324,Integrability,wrap,wrapt,12324,"7.4; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; certifi 2022.05.18.1; cffi 1.15.0; charset_normalizer 2.0.12; cloudpickle 2.1.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dask 2022.6.1; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; deprecated 1.2.13; diffxpy v0.7.4; entrypoints 0.4; executing 0.8.3; flatbuffers NA; fsspec 2022.5.0; future 0.18.2; gast NA; google NA; graphtools 1.5.2; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; ipykernel 6.15.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.1.0; keras 2.9.0; kiwisolver 1.4.3; llvmlite 0.38.1; magic 3.0.0; markupsafe 2.1.1; matplotlib 3.4.3; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.2; numexpr 2.8.1; numpy 1.22.3; opt_einsum v3.3.0; packaging 21.3; pandas 1.4.2; parso 0.8.3; patsy 0.5.2; pcurve NA; pexpect 4.8.0; phate 1.0.7; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.29; psutil 5.9.1; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.12.0; pygsp 0.5.1; pyparsing 3.0.9; pytz 2022.1; requests 2.28.0; s_gd2 1.8; scipy 1.8.1; scprep 1.2.0; seaborn 0.11.2; session_info 1.0.0; setuptools 62.6.0; six 1.16.0; sklearn 1.1.1; slingshot NA; sparse 0.13.0; stack_data 0.3.0; statsmodels 0.13.2; swig_runtime_data4 NA; tasklogger 1.1.2; tensorboard 2.9.1; tensorflow 2.9.1; termcolor 1.1.0; threadpoolctl 3.1.0; tlz 0.11.2; toolz 0.11.2; torch 1.11.0; tornado 6.1; tqdm 4.64.0; traitlets 5.3.0; typing_extensions NA; unicodedata2 NA; urllib3 1.26.9; wcwidth 0.2.5; wrapt 1.14.1; yaml 6.0; zipp NA; zmq 23.1.0; -----; IPython 8.4.0; jupyter_client 7.3.4; jupyter_core 4.10.0; notebook 6.4.12; -----; Python 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:25:59) [GCC 10.3.0]; Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31; -----; Session information updated at 2022-06-28 16:19; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:10172,Performance,Perform,Performance,10172,"b ""; 477 ""%(since)s and will be removed %(removal)s.""); 478 return artist.do_3d_projection(renderer). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:431, in delete_parameter.<locals>.wrapper(*inner_args, **inner_kwargs); 421 deprecation_addendum = (; 422 f""If any parameter follows {name!r}, they should be passed as ""; 423 f""keyword, not positionally.""); 424 warn_deprecated(; 425 since,; 426 name=repr(name),; (...); 429 else deprecation_addendum,; 430 **kwargs); --> 431 return func(*inner_args, **inner_kwargs). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/art3d.py:599, in Path3DCollection.do_3d_projection(self, renderer); 597 @_api.delete_parameter('3.4', 'renderer'); 598 def do_3d_projection(self, renderer=None):; --> 599 xs, ys, zs = self._offsets3d; 600 vxs, vys, vzs, vis = proj3d.proj_transform_clip(xs, ys, zs,; 601 self.axes.M); 602 # Sort the points based on z coordinates; 603 # Performance optimization: Create a sorted index array and reorder; 604 # points and point properties according to the index array. AttributeError: 'Path3DCollection' object has no attribute '_offsets3d'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.1.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; batchglm v0.7.4; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; certifi 2022.05.18.1; cffi 1.15.0; charset_normalizer 2.0.12; cloudpickle 2.1.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dask 2022.6.1; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; deprecated 1.2.13; diffxpy v0.7.4; entrypoints 0.4; executing 0.8.3; flatbuffers NA; fsspec 2022.5.0; future 0.18.2; gast NA; google NA; graphtools 1.5.2; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; ipykernel 6.15.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:10184,Performance,optimiz,optimization,10184,"b ""; 477 ""%(since)s and will be removed %(removal)s.""); 478 return artist.do_3d_projection(renderer). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:431, in delete_parameter.<locals>.wrapper(*inner_args, **inner_kwargs); 421 deprecation_addendum = (; 422 f""If any parameter follows {name!r}, they should be passed as ""; 423 f""keyword, not positionally.""); 424 warn_deprecated(; 425 since,; 426 name=repr(name),; (...); 429 else deprecation_addendum,; 430 **kwargs); --> 431 return func(*inner_args, **inner_kwargs). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/art3d.py:599, in Path3DCollection.do_3d_projection(self, renderer); 597 @_api.delete_parameter('3.4', 'renderer'); 598 def do_3d_projection(self, renderer=None):; --> 599 xs, ys, zs = self._offsets3d; 600 vxs, vys, vzs, vis = proj3d.proj_transform_clip(xs, ys, zs,; 601 self.axes.M); 602 # Sort the points based on z coordinates; 603 # Performance optimization: Create a sorted index array and reorder; 604 # points and point properties according to the index array. AttributeError: 'Path3DCollection' object has no attribute '_offsets3d'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.1.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; batchglm v0.7.4; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; certifi 2022.05.18.1; cffi 1.15.0; charset_normalizer 2.0.12; cloudpickle 2.1.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dask 2022.6.1; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; deprecated 1.2.13; diffxpy v0.7.4; entrypoints 0.4; executing 0.8.3; flatbuffers NA; fsspec 2022.5.0; future 0.18.2; gast NA; google NA; graphtools 1.5.2; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; ipykernel 6.15.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:10709,Performance,bottleneck,bottleneck,10709,"30 **kwargs); --> 431 return func(*inner_args, **inner_kwargs). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/art3d.py:599, in Path3DCollection.do_3d_projection(self, renderer); 597 @_api.delete_parameter('3.4', 'renderer'); 598 def do_3d_projection(self, renderer=None):; --> 599 xs, ys, zs = self._offsets3d; 600 vxs, vys, vzs, vis = proj3d.proj_transform_clip(xs, ys, zs,; 601 self.axes.M); 602 # Sort the points based on z coordinates; 603 # Performance optimization: Create a sorted index array and reorder; 604 # points and point properties according to the index array. AttributeError: 'Path3DCollection' object has no attribute '_offsets3d'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.1.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; batchglm v0.7.4; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; certifi 2022.05.18.1; cffi 1.15.0; charset_normalizer 2.0.12; cloudpickle 2.1.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dask 2022.6.1; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; deprecated 1.2.13; diffxpy v0.7.4; entrypoints 0.4; executing 0.8.3; flatbuffers NA; fsspec 2022.5.0; future 0.18.2; gast NA; google NA; graphtools 1.5.2; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; ipykernel 6.15.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.1.0; keras 2.9.0; kiwisolver 1.4.3; llvmlite 0.38.1; magic 3.0.0; markupsafe 2.1.1; matplotlib 3.4.3; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.2; numexpr 2.8.1; numpy 1.22.3; opt_einsum v3.3.0; packaging 21.3; pandas 1.4.2; parso 0.8.3; patsy 0.5.2; pcurve NA; pexpect 4.8.0; phate 1.0.7; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.29; psutil 5.9.1; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:8946,Safety,avoid,avoid,8946,". File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:485, in Axes3D.draw(self, renderer); 480 # Calculate projection of collections and patches and zorder them.; 481 # Make sure they are drawn above the grids.; 482 zorder_offset = max(axis.get_zorder(); 483 for axis in self._get_axis_list()) + 1; 484 for i, col in enumerate(; --> 485 sorted(self.collections,; 486 key=do_3d_projection,; 487 reverse=True)):; 488 col.zorder = zorder_offset + i; 489 for i, patch in enumerate(; 490 sorted(self.patches,; 491 key=do_3d_projection,; 492 reverse=True)):. File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:471, in Axes3D.draw.<locals>.do_3d_projection(artist); 458 """"""; 459 Call `do_3d_projection` on an *artist*, and warn if passing; 460 *renderer*.; (...); 464 *renderer* and raise a warning.; 465 """"""; 467 if artist.__module__ == 'mpl_toolkits.mplot3d.art3d':; 468 # Our 3D Artists have deprecated the renderer parameter, so; 469 # avoid passing it to them; call this directly once the; 470 # deprecation has expired.; --> 471 return artist.do_3d_projection(); 473 _api.warn_deprecated(; 474 ""3.4"",; 475 message=""The 'renderer' parameter of ""; 476 ""do_3d_projection() was deprecated in Matplotlib ""; 477 ""%(since)s and will be removed %(removal)s.""); 478 return artist.do_3d_projection(renderer). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:431, in delete_parameter.<locals>.wrapper(*inner_args, **inner_kwargs); 421 deprecation_addendum = (; 422 f""If any parameter follows {name!r}, they should be passed as ""; 423 f""keyword, not positionally.""); 424 warn_deprecated(; 425 since,; 426 name=repr(name),; (...); 429 else deprecation_addendum,; 430 **kwargs); --> 431 return func(*inner_args, **inner_kwargs). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/art3d.py:599, in Path3DCollection.do_3d_projection(self, renderer); 597 @_api.delete_parameter('3.4', 'renderer')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:10435,Testability,log,logging,10435,"nner_args, **inner_kwargs); 421 deprecation_addendum = (; 422 f""If any parameter follows {name!r}, they should be passed as ""; 423 f""keyword, not positionally.""); 424 warn_deprecated(; 425 since,; 426 name=repr(name),; (...); 429 else deprecation_addendum,; 430 **kwargs); --> 431 return func(*inner_args, **inner_kwargs). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/mpl_toolkits/mplot3d/art3d.py:599, in Path3DCollection.do_3d_projection(self, renderer); 597 @_api.delete_parameter('3.4', 'renderer'); 598 def do_3d_projection(self, renderer=None):; --> 599 xs, ys, zs = self._offsets3d; 600 vxs, vys, vzs, vis = proj3d.proj_transform_clip(xs, ys, zs,; 601 self.axes.M); 602 # Sort the points based on z coordinates; 603 # Performance optimization: Create a sorted index array and reorder; 604 # points and point properties according to the index array. AttributeError: 'Path3DCollection' object has no attribute '_offsets3d'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.1.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; batchglm v0.7.4; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; certifi 2022.05.18.1; cffi 1.15.0; charset_normalizer 2.0.12; cloudpickle 2.1.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dask 2022.6.1; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; deprecated 1.2.13; diffxpy v0.7.4; entrypoints 0.4; executing 0.8.3; flatbuffers NA; fsspec 2022.5.0; future 0.18.2; gast NA; google NA; graphtools 1.5.2; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; ipykernel 6.15.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.1.0; keras 2.9.0; kiwisolver 1.4.3; llvmlite 0.38.1; magic 3.0.0; markupsafe 2.1.1; matplotlib 3.4.3; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.2; numexpr 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2285:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # NOTE: This throws error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='3d'; ). # NOTE: This doesn't throw error; sc.pl.embedding(; adata, basis='X_emb', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; projection='2d'; ). # NOTE: the error is that one of the genes in `de_genes` has almost the value for all cells; np.unique(adata.X[:, de_genes.index('KRT1')]); > array([-0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931, -0.09614931,; -0.09614931, -0.09614931, -0.09614931, -0.09614931]). # Thus this is a combination of projection 3d and rounding. This should not throw an error and just plot all points same color; ```. ```pytb; [Paste the error output produced by the above code here]; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Input In [403], in <cell line: 1>(); ----> 1 sc.pl.embedding(; 2 adata, basis='X_phate_alone', color=de_genes[:10], sort_order=True, vmin=0, color_map='magma',; 3 projection='3d'; 4 ). File ~/anaconda3/envs/ml/lib/python3.9/site-packages/scanpy/plotting/_tools/scatte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2285
https://github.com/scverse/scanpy/issues/2286:344,Usability,guid,guide,344,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; AttributeError: module 'fa2.fa2util' has no attribute 'Node' for scanpy version 1.9.1. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.pp.recipe_zheng17(adata); sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20); sc.tl.draw_graph(adata); ```. ```pytb; Traceback (most recent call last):; File ""C:\Users\wubaosheng\AppData\Local\Programs\Python\Python39\lib\site-packages\IPython\core\interactiveshell.py"", line 3398, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-9-e2440b0eca68>"", line 1, in <cell line: 1>; sc.tl.draw_graph(adata); File ""C:\Users\wubaosheng\AppData\Local\Programs\Python\Python39\lib\site-packages\scanpy\tools\_draw_graph.py"", line 159, in draw_graph; positions = forceatlas2.forceatlas2(; File ""C:\Users\wubaosheng\AppData\Local\Programs\Python\Python39\lib\site-packages\fa2-0.3.5-py3.9-win-amd64.egg\fa2\forceatlas2.py"", line 162, in forceatlas2; nodes, edges = self.init(G, pos); File ""C:\Users\wubaosheng\AppData\Local\Programs\Python\Python39\lib\site-packages\fa2-0.3.5-py3.9-win-amd64.egg\fa2\forceatlas2.py"", line 103, in init; n = fa2util.Node(); AttributeError: module 'fa2.fa2util' has no attribute 'Node'; ```. #### Versions; '1.9.1' for scanpy; 3.9.7 for python. ![image](https://user-images.githubusercontent.com/50618480/176398309-d16c671f-e4bf-43b5-a23d-abf9bdbe2329.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2286
https://github.com/scverse/scanpy/issues/2287:167,Usability,simpl,simple,167,<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [x] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; I would like to add AutoGeneS (https://github.com/theislab/AutoGeneS) as an external package.; It's a bulk deconvolution tool that is based on anndata and scanpy.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2287
https://github.com/scverse/scanpy/issues/2288:447,Availability,error,error,447,"Hi there,; using `sc.read(filename, ext='txt')` I get the following irrelevant warning:; `WARNING: Your filename has more than two extensions: ['.5_E9', '.0_E9', '.5', '.txt'].; Only considering the two last: ['.5', '.txt'].; WARNING: Your filename has more than two extensions: ['.5_E9', '.0_E9', '.5', '.txt'].; Only considering the two last: ['.5', '.txt'].`; (filename is `GSE136689_Counts_Matrix_AllCells_E8.5_E9.0_E9.5.txt`). digging in the error is raised by the `readwrite` module's function `is_valid_filename(filename)`, that checks the extensions regardless of the 'ext' parameter the `sc.read` function gets, and if it passes it sends it to `_read`. inside the `_read` function, there is a second call to `is_valid_filename`, which raises the second warning (with exactly the same text). seeing as this is the process, i don't get why even have the `ext` parameter, because currently it seams like it is only used to indicate when someone uses an unsupported extension; ; #### Versions. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.1.0; PyQt5 NA; appnope 0.1.3; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; bs4 4.11.1; certifi 2022.05.18.1; cffi 1.15.0; chardet 4.0.0; charset_normalizer 2.0.12; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.05.0; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fastcluster 1.1.26; fsspec 2022.3.0; gprofiler 1.0.0; h5py 3.6.0; idna 3.3; igraph 0.9.9; ipykernel 6.13.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.1.0; jupyter_server 1.17.0; kiwisolver 1.4.2; leidenalg 0.8.8; llvmlite 0.38.0; louvain 0.7.1; markupsafe 2.1.1; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; networkx 2.6.3; numba 0.55.0; numpy 1.21.5; packaging 21.3; pandas 1.4.0; parso 0.8.3; pexpect 4.8.0; phyloproc NA; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2288
https://github.com/scverse/scanpy/issues/2288:2921,Deployability,update,updated,2921,"ne uses an unsupported extension; ; #### Versions. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.1.0; PyQt5 NA; appnope 0.1.3; atomicwrites 1.4.0; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; bs4 4.11.1; certifi 2022.05.18.1; cffi 1.15.0; chardet 4.0.0; charset_normalizer 2.0.12; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.05.0; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fastcluster 1.1.26; fsspec 2022.3.0; gprofiler 1.0.0; h5py 3.6.0; idna 3.3; igraph 0.9.9; ipykernel 6.13.0; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.1.0; jupyter_server 1.17.0; kiwisolver 1.4.2; leidenalg 0.8.8; llvmlite 0.38.0; louvain 0.7.1; markupsafe 2.1.1; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; networkx 2.6.3; numba 0.55.0; numpy 1.21.5; packaging 21.3; pandas 1.4.0; parso 0.8.3; pexpect 4.8.0; phyloproc NA; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.29; psutil 5.9.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.12.0; pyparsing 3.0.9; pytz 2022.1; requests 2.27.1; scipy 1.7.3; seaborn 0.11.2; session_info 1.0.0; setuptools 62.2.0; sip NA; six 1.16.0; sklearn 1.0.2; socks 1.7.1; soupsieve 2.3.1; sphinxcontrib NA; spyder 5.2.2; spyder_kernels 2.2.1; spydercustomize NA; statsmodels 0.13.2; storemagic NA; texttable 1.6.4; threadpoolctl 3.1.0; tlz 0.11.2; toolz 0.11.2; tornado 6.1; traitlets 5.2.0; typing_extensions NA; unicodedata2 NA; urllib3 1.26.9; wcwidth 0.2.5; wurlitzer 3.0.2; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 7.33.0; jupyter_client 7.3.1; jupyter_core 4.10.0; jupyterlab 3.2.8; notebook 6.4.11; -----; Python 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:27:05) [Clang 12.0.1 ]; macOS-12.4-x86_64-i386-64bit; -----; Session information updated at 2022-07-03 15:14",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2288
https://github.com/scverse/scanpy/pull/2289:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/psf/black: 22.3.0  22.6.0](https://github.com/psf/black/compare/22.3.0...22.6.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2289
https://github.com/scverse/scanpy/issues/2292:453,Deployability,continuous,continuous,453,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; When trying to plot the PAGA graph some of the nodes don't show up in the graph. The nodes/clusters don't show up specifically for color=dpt_pseudotime. The nodes are still visible with categorical variables, and with other continuous variables.; Even when copying dpt_pseudotime column, the color=dpt_pseudotime_copy does not show up correctly. ### Minimal code sample ; ```python; # preprocessing; sc.pp.recipe_zheng17(adata); adata_wt= adata[adata.obs[""genotype""].isin([""WT""])]; adata_pca = sc.tl.pca(adata_wt, svd_solver='arpack', copy=True); adata_n = sc.pp.neighbors(adata_pca, n_neighbors=4, n_pcs=20, copy=True); adata_graph = sc.tl.draw_graph(adata_n, copy=True); # paga; adata_full = sc.tl.paga(adata_graph, groups='final_bulk_labels', copy=True); # dpt; adata_full.uns['iroot'] = np.flatnonzero(adata_full.obs['final_bulk_labels'] == 'HSC')[1000]; adata_paga_dpt_nonan = sc.tl.diffmap(adata_full, copy=True, n_comps=10); adata_paga_dpt_nonan = sc.tl.dpt(adata_paga_dpt_nonan, copy=True). adata_paga_dpt_nonan.obs[""dpt_pseudotime_copy""]=adata_paga_dpt_nonan.obs[""dpt_pseudotime""]. sc.pl.paga(adata_paga_dpt_nonan, ; threshold=0.05, ; color=['dpt_pseudotime', 'final_bulk_labels', 'dpt_pseudotime_copy', 'total_counts'],; ; # layout: Optional[_IGraphLayout] = None,; # layout_kwds: Mapping[str, Any] = MappingProxyType({}),; # init_pos: Optional[np.ndarray] = None,; # root: Union[int, str, Sequence[int], None] = 0,; # labels: Union[str, Sequence[str], Mapping[str, str], None] = None,; single_component = True,; solid_edges= 'connectivities',; # dashed_edges: Optional[str] = None,; # transitions: Optional[str] = None,; fontsize = 5,. fontweight='light', ; # fontoutline=2, ; # text_kwds: Mapping[str, Any] = MappingProxyType({}),; node_size_scale = 3, ; node_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2292
https://github.com/scverse/scanpy/issues/2292:4575,Deployability,update,updated,4575,"ards compat; # groups=None, # backwards compat; # plot: bool = True,; # show: Optional[bool] = None,; save=""/reg_label_full_nonan.pdf""; # ax: Optional[Axes] = None,; ). ```; Plot output showing lack of nodes with dpt_pseudotime:; [reg_label_full_nonan.pdf](https://github.com/scverse/scanpy/files/9073420/reg_label_full_nonan.pdf); ![reg_label_full_nonan](https://user-images.githubusercontent.com/64251655/178032248-88717c04-ae02-4a8f-b13b-b8a679d9c6c2.png). #### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.9.1. -----; PIL 9.0.1; appnope 0.1.3; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 0.8.3; fontTools 4.25.0; google NA; h5py 3.6.0; hypergeom_ufunc NA; igraph 0.9.10; ipykernel 6.13.1; ipython_genutils 0.2.0; jedi 0.18.1; joblib 1.1.0; jupyter_server 1.17.1; kiwisolver 1.3.2; leidenalg 0.8.10; llvmlite 0.38.0; louvain 0.7.1; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; networkx 2.7.1; numba 0.55.1; numpy 1.21.6; packaging 21.3; pandas 1.4.2; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.29; psutil 5.9.1; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.4; pytz 2021.3; scipy 1.8.0; session_info 1.0.0; setuptools 61.2.0; six 1.16.0; sklearn 1.0.2; sphinxcontrib NA; stack_data 0.2.0; texttable 1.6.4; threadpoolctl 2.2.0; tornado 6.1; traitlets 5.2.2; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 23.1.0; -----; IPython 8.4.0; jupyter_client 7.3.4; jupyter_core 4.10.0; jupyterlab 3.4.3; notebook 6.4.12; -----; Python 3.8.13 (default, Mar 28 2022, 06:16:26) [Clang 12.0.0 ]; macOS-10.16-x86_64-i386-64bit; -----; Session information updated at 2022-07-08 11:58; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2292
https://github.com/scverse/scanpy/issues/2292:427,Modifiability,variab,variables,427,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; When trying to plot the PAGA graph some of the nodes don't show up in the graph. The nodes/clusters don't show up specifically for color=dpt_pseudotime. The nodes are still visible with categorical variables, and with other continuous variables.; Even when copying dpt_pseudotime column, the color=dpt_pseudotime_copy does not show up correctly. ### Minimal code sample ; ```python; # preprocessing; sc.pp.recipe_zheng17(adata); adata_wt= adata[adata.obs[""genotype""].isin([""WT""])]; adata_pca = sc.tl.pca(adata_wt, svd_solver='arpack', copy=True); adata_n = sc.pp.neighbors(adata_pca, n_neighbors=4, n_pcs=20, copy=True); adata_graph = sc.tl.draw_graph(adata_n, copy=True); # paga; adata_full = sc.tl.paga(adata_graph, groups='final_bulk_labels', copy=True); # dpt; adata_full.uns['iroot'] = np.flatnonzero(adata_full.obs['final_bulk_labels'] == 'HSC')[1000]; adata_paga_dpt_nonan = sc.tl.diffmap(adata_full, copy=True, n_comps=10); adata_paga_dpt_nonan = sc.tl.dpt(adata_paga_dpt_nonan, copy=True). adata_paga_dpt_nonan.obs[""dpt_pseudotime_copy""]=adata_paga_dpt_nonan.obs[""dpt_pseudotime""]. sc.pl.paga(adata_paga_dpt_nonan, ; threshold=0.05, ; color=['dpt_pseudotime', 'final_bulk_labels', 'dpt_pseudotime_copy', 'total_counts'],; ; # layout: Optional[_IGraphLayout] = None,; # layout_kwds: Mapping[str, Any] = MappingProxyType({}),; # init_pos: Optional[np.ndarray] = None,; # root: Union[int, str, Sequence[int], None] = 0,; # labels: Union[str, Sequence[str], Mapping[str, str], None] = None,; single_component = True,; solid_edges= 'connectivities',; # dashed_edges: Optional[str] = None,; # transitions: Optional[str] = None,; fontsize = 5,. fontweight='light', ; # fontoutline=2, ; # text_kwds: Mapping[str, Any] = MappingProxyType({}),; node_size_scale = 3, ; node_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2292
https://github.com/scverse/scanpy/issues/2292:464,Modifiability,variab,variables,464,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; When trying to plot the PAGA graph some of the nodes don't show up in the graph. The nodes/clusters don't show up specifically for color=dpt_pseudotime. The nodes are still visible with categorical variables, and with other continuous variables.; Even when copying dpt_pseudotime column, the color=dpt_pseudotime_copy does not show up correctly. ### Minimal code sample ; ```python; # preprocessing; sc.pp.recipe_zheng17(adata); adata_wt= adata[adata.obs[""genotype""].isin([""WT""])]; adata_pca = sc.tl.pca(adata_wt, svd_solver='arpack', copy=True); adata_n = sc.pp.neighbors(adata_pca, n_neighbors=4, n_pcs=20, copy=True); adata_graph = sc.tl.draw_graph(adata_n, copy=True); # paga; adata_full = sc.tl.paga(adata_graph, groups='final_bulk_labels', copy=True); # dpt; adata_full.uns['iroot'] = np.flatnonzero(adata_full.obs['final_bulk_labels'] == 'HSC')[1000]; adata_paga_dpt_nonan = sc.tl.diffmap(adata_full, copy=True, n_comps=10); adata_paga_dpt_nonan = sc.tl.dpt(adata_paga_dpt_nonan, copy=True). adata_paga_dpt_nonan.obs[""dpt_pseudotime_copy""]=adata_paga_dpt_nonan.obs[""dpt_pseudotime""]. sc.pl.paga(adata_paga_dpt_nonan, ; threshold=0.05, ; color=['dpt_pseudotime', 'final_bulk_labels', 'dpt_pseudotime_copy', 'total_counts'],; ; # layout: Optional[_IGraphLayout] = None,; # layout_kwds: Mapping[str, Any] = MappingProxyType({}),; # init_pos: Optional[np.ndarray] = None,; # root: Union[int, str, Sequence[int], None] = 0,; # labels: Union[str, Sequence[str], Mapping[str, str], None] = None,; single_component = True,; solid_edges= 'connectivities',; # dashed_edges: Optional[str] = None,; # transitions: Optional[str] = None,; fontsize = 5,. fontweight='light', ; # fontoutline=2, ; # text_kwds: Mapping[str, Any] = MappingProxyType({}),; node_size_scale = 3, ; node_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2292
https://github.com/scverse/scanpy/issues/2293:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```adata = sc.read_csv('/stanley/granger_lab_storage/Users/Will/120722_MOp_matrix_GABA_Glut_only_dropped_column.csv', delimiter = ""\t"")```. ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-43-462cb48f7ebe> in <module>; ----> 1 adata = sc.read_csv('/stanley/granger_lab_storage/Users/Will/120722_MOp_matrix_GABA_Glut_only_dropped_column.csv', delimiter = ""\t""). ~/.local/lib/python3.8/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype); 51 Numpy data type.; 52 """"""; ---> 53 return read_text(filename, delimiter, first_column_names, dtype); 54 ; 55 . ~/.local/lib/python3.8/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype); 358 else:; 359 with filename.open() as f:; --> 360 return _read_text(f, delimiter, first_column_names, dtype); 361 ; 362 . ~/.local/lib/python3.8/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype); 423 data.append(np.array(line_list[1:], dtype=dtype)); 424 else:; --> 425 data.append(np.array(line_list, dtype=dtype)); 426 break; 427 # if row names are just integers. ValueError: could not convert string to float: 'AAACCTGAGGAGTCTG-L8TX_171026_01_F03'; ```. #### Versions. anndata 0.8.0; scanpy 1.9.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2293
https://github.com/scverse/scanpy/pull/2295:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295
https://github.com/scverse/scanpy/pull/2295:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2295
https://github.com/scverse/scanpy/pull/2296:8,Deployability,update,updates,8,This PR updates scanpy to accommodate the latest changes made in spaceranger 2.0 which will break the released version of scanpy. Will provide backwards compatibility to pre 2.0 releases. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:102,Deployability,release,released,102,This PR updates scanpy to accommodate the latest changes made in spaceranger 2.0 which will break the released version of scanpy. Will provide backwards compatibility to pre 2.0 releases. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:178,Deployability,release,releases,178,This PR updates scanpy to accommodate the latest changes made in spaceranger 2.0 which will break the released version of scanpy. Will provide backwards compatibility to pre 2.0 releases. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:259,Usability,guid,guidelines,259,This PR updates scanpy to accommodate the latest changes made in spaceranger 2.0 which will break the released version of scanpy. Will provide backwards compatibility to pre 2.0 releases. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:290,Usability,guid,guide,290,This PR updates scanpy to accommodate the latest changes made in spaceranger 2.0 which will break the released version of scanpy. Will provide backwards compatibility to pre 2.0 releases. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/issues/2297:65,Availability,error,error,65,"I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```; adata=sc.read_h5ad('XXXX.h5ad'); ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):; --> 156 parent = elem.store # Not sure how to always get a name out of this; 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name); 386 def __getitem__(cls, name):; --> 387 return cls._member_map_[name]; 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-15-a2632df74a34> in <module>; ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 160 parent = elem.file.name; 161 return parent; --> 162 ; 163 ; 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1573,Availability,error,error,1573,"I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```; adata=sc.read_h5ad('XXXX.h5ad'); ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):; --> 156 parent = elem.store # Not sure how to always get a name out of this; 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name); 386 def __getitem__(cls, name):; --> 387 return cls._member_map_[name]; 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-15-a2632df74a34> in <module>; ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 160 parent = elem.file.name; 161 return parent; --> 162 ; 163 ; 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1154,Integrability,wrap,wrapper,1154,"I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```; adata=sc.read_h5ad('XXXX.h5ad'); ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):; --> 156 parent = elem.store # Not sure how to always get a name out of this; 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name); 386 def __getitem__(cls, name):; --> 387 return cls._member_map_[name]; 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-15-a2632df74a34> in <module>; ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 160 parent = elem.file.name; 161 return parent; --> 162 ; 163 ; 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1606,Modifiability,layers,layers,1606,"I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```; adata=sc.read_h5ad('XXXX.h5ad'); ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):; --> 156 parent = elem.store # Not sure how to always get a name out of this; 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name); 386 def __getitem__(cls, name):; --> 387 return cls._member_map_[name]; 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-15-a2632df74a34> in <module>; ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 160 parent = elem.file.name; 161 return parent; --> 162 ; 163 ; 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2299:222,Integrability,depend,depends,222,"Hi,; I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/pull/2303:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/PyCQA/flake8: 4.0.1  5.0.4](https://github.com/PyCQA/flake8/compare/4.0.1...5.0.4); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2303
https://github.com/scverse/scanpy/issues/2304:98,Availability,error,error,98,"Running through UMI count data analysis via Pearson Residual on Jupyternotebook on Mac, caught an error at sc.pp.calculate_qc_metrics. I checked the array and it should be able to capture the mito genes; the mitochondrial genes are denoted as 'mt-' (with hyphen). ; for adata in adata_control:; adata.var[""mt""] = adata.var_names.str.startswith(""mt-""); sc.pp.calculate_qc_metrics(; adata, qc_vars[""mt""], percent_top=None, log1p=False, inplace=True; ); I'm not sure where it went wrong and why it wouldn't parse the mt genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2304
https://github.com/scverse/scanpy/issues/2305:338,Availability,error,error,338,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python; # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'); adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:; adata.var_names_make_unique(); print(adata.uns[""name""], "": data shape"", adata.shape); sc.pp.filter_cells(adata, min_genes=100); sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:; adata.var['mt'] = adata.var_names.str.startswith('mt-'); sc.pp.calculate_qc_metrics(; adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:; print(adata.uns[""name""], "":""); sc.pl.violin(; adata,; [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],; jitter =0.4,; multi_panel=True,; ); ```. ```pytb; zfish_Control :; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>; 1 for adata in adata_control:; 2 print(adata.uns[""name""], "":""); ----> 3 sc.pl.violin(; 4 adata,; 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 779 ); 780 else:; --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw); 782 if groupby is None:; 783 obs_tidy ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:287,Performance,perform,perform,287,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python; # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'); adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:; adata.var_names_make_unique(); print(adata.uns[""name""], "": data shape"", adata.shape); sc.pp.filter_cells(adata, min_genes=100); sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:; adata.var['mt'] = adata.var_names.str.startswith('mt-'); sc.pp.calculate_qc_metrics(; adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:; print(adata.uns[""name""], "":""); sc.pl.violin(; adata,; [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],; jitter =0.4,; multi_panel=True,; ); ```. ```pytb; zfish_Control :; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>; 1 for adata in adata_control:; 2 print(adata.uns[""name""], "":""); ----> 3 sc.pl.violin(; 4 adata,; 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 779 ); 780 else:; --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw); 782 if groupby is None:; 783 obs_tidy ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:2935,Performance,bottleneck,bottleneck,2935,"s=keys, layer=layer, use_raw=use_raw); 782 if groupby is None:; 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 270 alias_index = None; 271 ; --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(; 273 adata.obs,; 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw); 165 not_found.append(key); 166 if len(not_found) > 0:; --> 167 raise KeyError(; 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in""; 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names.""; ]; ```. #### Versions. <details>. anndata 0.8.0; scanpy 1.9.1; -----; PIL 8.4.0; anyio NA; appnope 0.1.2; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; brotli NA; certifi 2022.06.15; cffi 1.14.6; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; debugpy 1.4.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fastjsonschema NA; fsspec 2021.08.1; google NA; h5py 3.2.1; idna 3.2; igraph 0.9.11; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 2.11.3; joblib 1.1.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.8.2; kiwisolver 1.3.1; leidenalg 0.8.10; llvmlite 0.37.0; louvain 0.7.1; markupsafe 1.1.1; matplotlib 3.4.3; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 8.1.0; nbclassic NA; nbformat 5.1.3; nbinom_ufunc NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0; pandas 1.4.2; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.20; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:1744,Testability,log,log,1744,"er_cells(adata, min_genes=100); sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:; adata.var['mt'] = adata.var_names.str.startswith('mt-'); sc.pp.calculate_qc_metrics(; adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:; print(adata.uns[""name""], "":""); sc.pl.violin(; adata,; [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],; jitter =0.4,; multi_panel=True,; ); ```. ```pytb; zfish_Control :; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>; 1 for adata in adata_control:; 2 print(adata.uns[""name""], "":""); ----> 3 sc.pl.violin(; 4 adata,; 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 779 ); 780 else:; --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw); 782 if groupby is None:; 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 270 alias_index = None; 271 ; --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(; 273 adata.obs,; 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw); 165 not_found.append(key); 166 if len(not_found) > 0:; --> 167 raise KeyError(; 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in""; 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names.""; ]; ```. #### Versions. <details>. anndata 0.8.0; sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2306:265,Availability,error,errors,265,"- [ x] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python; import scanpy as sc; ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-0074c9bc0b31> in <module>; ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>; 6 from ._utils import check_versions; 7 ; ----> 8 check_versions(); 9 del check_versions, within_flit; 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(); 47 umap_version = pkg_version(""umap-learn""); 48 ; ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):; 50 from .. import __version__; 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version); 47 """"""; 48 try:; ---> 49 return Version(version); 50 except InvalidVersion:; 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version); 262 ; 263 # Validate the version and parse it into pieces; --> 264 match = self._regex.search(version); 265 if not match:; 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux""; VERSION=""7 (Core)""; ID=""centos""; ID_LIKE=""rhel fedora""; VERSION_ID=""7""; PRETTY_NAME=""CentOS Linux 7 (Core)""; ANSI_COLOR=""0;31""; CPE_NAME=""cpe:/o:centos:centos:7""; HOME_URL=""https://www.centos.org/""; BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7""; CENTOS_MANTISBT_PROJECT_VERSION=""7""; REDHAT_SUPPORT_PRODUCT=""centos""; REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```; sys.version_info(major=3, minor=9, micro=2, rel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:322,Availability,error,error,322,"- [ x] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python; import scanpy as sc; ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-0074c9bc0b31> in <module>; ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>; 6 from ._utils import check_versions; 7 ; ----> 8 check_versions(); 9 del check_versions, within_flit; 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(); 47 umap_version = pkg_version(""umap-learn""); 48 ; ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):; 50 from .. import __version__; 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version); 47 """"""; 48 try:; ---> 49 return Version(version); 50 except InvalidVersion:; 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version); 262 ; 263 # Validate the version and parse it into pieces; --> 264 match = self._regex.search(version); 265 if not match:; 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux""; VERSION=""7 (Core)""; ID=""centos""; ID_LIKE=""rhel fedora""; VERSION_ID=""7""; PRETTY_NAME=""CentOS Linux 7 (Core)""; ANSI_COLOR=""0;31""; CPE_NAME=""cpe:/o:centos:centos:7""; HOME_URL=""https://www.centos.org/""; BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7""; CENTOS_MANTISBT_PROJECT_VERSION=""7""; REDHAT_SUPPORT_PRODUCT=""centos""; REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```; sys.version_info(major=3, minor=9, micro=2, rel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:240,Deployability,install,installed,240,"- [ x] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python; import scanpy as sc; ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-0074c9bc0b31> in <module>; ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>; 6 from ._utils import check_versions; 7 ; ----> 8 check_versions(); 9 del check_versions, within_flit; 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(); 47 umap_version = pkg_version(""umap-learn""); 48 ; ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):; 50 from .. import __version__; 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version); 47 """"""; 48 try:; ---> 49 return Version(version); 50 except InvalidVersion:; 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version); 262 ; 263 # Validate the version and parse it into pieces; --> 264 match = self._regex.search(version); 265 if not match:; 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux""; VERSION=""7 (Core)""; ID=""centos""; ID_LIKE=""rhel fedora""; VERSION_ID=""7""; PRETTY_NAME=""CentOS Linux 7 (Core)""; ANSI_COLOR=""0;31""; CPE_NAME=""cpe:/o:centos:centos:7""; HOME_URL=""https://www.centos.org/""; BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7""; CENTOS_MANTISBT_PROJECT_VERSION=""7""; REDHAT_SUPPORT_PRODUCT=""centos""; REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```; sys.version_info(major=3, minor=9, micro=2, rel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1522,Deployability,release,release,1522,"sue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python; import scanpy as sc; ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-0074c9bc0b31> in <module>; ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>; 6 from ._utils import check_versions; 7 ; ----> 8 check_versions(); 9 del check_versions, within_flit; 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(); 47 umap_version = pkg_version(""umap-learn""); 48 ; ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):; 50 from .. import __version__; 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version); 47 """"""; 48 try:; ---> 49 return Version(version); 50 except InvalidVersion:; 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version); 262 ; 263 # Validate the version and parse it into pieces; --> 264 match = self._regex.search(version); 265 if not match:; 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux""; VERSION=""7 (Core)""; ID=""centos""; ID_LIKE=""rhel fedora""; VERSION_ID=""7""; PRETTY_NAME=""CentOS Linux 7 (Core)""; ANSI_COLOR=""0;31""; CPE_NAME=""cpe:/o:centos:centos:7""; HOME_URL=""https://www.centos.org/""; BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7""; CENTOS_MANTISBT_PROJECT_VERSION=""7""; REDHAT_SUPPORT_PRODUCT=""centos""; REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```; sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1998,Deployability,release,releaselevel,1998,"sue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python; import scanpy as sc; ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-0074c9bc0b31> in <module>; ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>; 6 from ._utils import check_versions; 7 ; ----> 8 check_versions(); 9 del check_versions, within_flit; 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(); 47 umap_version = pkg_version(""umap-learn""); 48 ; ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):; 50 from .. import __version__; 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version); 47 """"""; 48 try:; ---> 49 return Version(version); 50 except InvalidVersion:; 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version); 262 ; 263 # Validate the version and parse it into pieces; --> 264 match = self._regex.search(version); 265 if not match:; 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux""; VERSION=""7 (Core)""; ID=""centos""; ID_LIKE=""rhel fedora""; VERSION_ID=""7""; PRETTY_NAME=""CentOS Linux 7 (Core)""; ANSI_COLOR=""0;31""; CPE_NAME=""cpe:/o:centos:centos:7""; HOME_URL=""https://www.centos.org/""; BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7""; CENTOS_MANTISBT_PROJECT_VERSION=""7""; REDHAT_SUPPORT_PRODUCT=""centos""; REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```; sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1257,Security,Validat,Validate,1257,"sue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python; import scanpy as sc; ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-0074c9bc0b31> in <module>; ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>; 6 from ._utils import check_versions; 7 ; ----> 8 check_versions(); 9 del check_versions, within_flit; 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(); 47 umap_version = pkg_version(""umap-learn""); 48 ; ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):; 50 from .. import __version__; 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version); 47 """"""; 48 try:; ---> 49 return Version(version); 50 except InvalidVersion:; 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version); 262 ; 263 # Validate the version and parse it into pieces; --> 264 match = self._regex.search(version); 265 if not match:; 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux""; VERSION=""7 (Core)""; ID=""centos""; ID_LIKE=""rhel fedora""; VERSION_ID=""7""; PRETTY_NAME=""CentOS Linux 7 (Core)""; ANSI_COLOR=""0;31""; CPE_NAME=""cpe:/o:centos:centos:7""; HOME_URL=""https://www.centos.org/""; BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7""; CENTOS_MANTISBT_PROJECT_VERSION=""7""; REDHAT_SUPPORT_PRODUCT=""centos""; REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```; sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:859,Usability,learn,learn,859,"- [ x] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python; import scanpy as sc; ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-0074c9bc0b31> in <module>; ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>; 6 from ._utils import check_versions; 7 ; ----> 8 check_versions(); 9 del check_versions, within_flit; 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(); 47 umap_version = pkg_version(""umap-learn""); 48 ; ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):; 50 from .. import __version__; 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version); 47 """"""; 48 try:; ---> 49 return Version(version); 50 except InvalidVersion:; 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version); 262 ; 263 # Validate the version and parse it into pieces; --> 264 match = self._regex.search(version); 265 if not match:; 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux""; VERSION=""7 (Core)""; ID=""centos""; ID_LIKE=""rhel fedora""; VERSION_ID=""7""; PRETTY_NAME=""CentOS Linux 7 (Core)""; ANSI_COLOR=""0;31""; CPE_NAME=""cpe:/o:centos:centos:7""; HOME_URL=""https://www.centos.org/""; BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7""; CENTOS_MANTISBT_PROJECT_VERSION=""7""; REDHAT_SUPPORT_PRODUCT=""centos""; REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```; sys.version_info(major=3, minor=9, micro=2, rel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/pull/2307:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/pre-commit/mirrors-autopep8: v1.6.0  v1.7.0](https://github.com/pre-commit/mirrors-autopep8/compare/v1.6.0...v1.7.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2307
https://github.com/scverse/scanpy/issues/2308:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. For gEAR (Gene Expression Analysis Resource), we have had a few users request Similarity Weighted Nonnegative Embedding (SWNE) plots instead of tSNE or UMAP plots. Having this embedding option (scanpy.tl and scanpy.pl) would allow use to expand functionality in several of our tools without having to leave the scanpy environment in order to provide them. Repo: https://github.com/yanwu2014/swne; Paper: https://www.sciencedirect.com/science/article/pii/S240547121830440X?via%3Dihub; ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2308
https://github.com/scverse/scanpy/issues/2310:750,Availability,error,error,750,"---. Hello, I have been working locally with scanpy where everything works well; I can save anndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable); 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience!. ```python; adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'); ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 176 try:; --> 177 return func(elem, *args, **kwargs); 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 526 if encoding_type:; --> 527 EncodingVersions[encoding_type].check(; 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name); 343 def __getitem__(cls, name):; --> 344 return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-2-2626ee07d023> in <module>; ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2645,Availability,error,error,2645,"return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-2-2626ee07d023> in <module>; ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 7.2.0; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.0; cloudpickle 1.5.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.1; dask 2022.7.1; dateutil 2.8.1; decorator 4.4.2; fsspec 2022.01.0; google NA; h5py 3.6.0; igraph 0.9.9; ipykernel 5.3.2; ipython_genutils 0.2.0; jedi 0.17.1; jinja2 2.11.2; joblib 0.16.0; kiwisolver 1.2.0; leidenalg 0.8.0; llvmlite 0.38.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.5.2; mpl_toolkits NA; natsort 8.1.0; numba 0.55.2; numexpr 2.7.1; numpy 1.21.6; packaging 21.3; pandas 1.4.0; parso 0.7.0; pexpect 4.8.0; pickleshare ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2761,Availability,error,error,2761,"hon-input-2-2626ee07d023> in <module>; ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 7.2.0; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.0; cloudpickle 1.5.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.1; dask 2022.7.1; dateutil 2.8.1; decorator 4.4.2; fsspec 2022.01.0; google NA; h5py 3.6.0; igraph 0.9.9; ipykernel 5.3.2; ipython_genutils 0.2.0; jedi 0.17.1; jinja2 2.11.2; joblib 0.16.0; kiwisolver 1.2.0; leidenalg 0.8.0; llvmlite 0.38.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.5.2; mpl_toolkits NA; natsort 8.1.0; numba 0.55.2; numexpr 2.7.1; numpy 1.21.6; packaging 21.3; pandas 1.4.0; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.7.0; ptyprocess 0.6.0; pyarrow 8.0.0; pygments 2.6.1; pyparsing 2.4.7; pytoml NA; pytz 2020.1; scipy 1.5.0; setuptools_scm NA;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:783,Deployability,install,installed,783,"---. Hello, I have been working locally with scanpy where everything works well; I can save anndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable); 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience!. ```python; adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'); ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 176 try:; --> 177 return func(elem, *args, **kwargs); 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 526 if encoding_type:; --> 527 EncodingVersions[encoding_type].check(; 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name); 343 def __getitem__(cls, name):; --> 344 return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-2-2626ee07d023> in <module>; ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2269,Integrability,wrap,wrapper,2269,"up(group); 526 if encoding_type:; --> 527 EncodingVersions[encoding_type].check(; 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name); 343 def __getitem__(cls, name):; --> 344 return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-2-2626ee07d023> in <module>; ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 7.2.0; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.0; cloudpickle 1.5.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.1; dask 2022.7.1; dateutil 2.8.1; decorator 4.4.2; fsspec 2022.01.0; google NA; h5py 3.6.0; igraph 0.9.9; ipykernel 5.3.2; ipython_genutils 0.2.0; jedi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:6689,Integrability,wrap,wrapt,6689,"1.1; easydev 0.12.0; entrypoints 0.3; fsspec 2021.08.1; get_version 3.5.4; google NA; gridfs NA; gseapy 0.10.8; h5py 3.6.0; html5lib 1.1; idna 3.2; igraph 0.9.11; importlib_metadata NA; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; itsdangerous 2.0.1; jedi 0.18.0; jinja2 2.11.3; joblib 1.1.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.8.2; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.9; llvmlite 0.36.0; lxml 4.6.3; markupsafe 1.1.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbclassic NA; nbformat 5.1.3; nbinom_ufunc NA; numba 0.53.0; numexpr 2.7.3; numpy 1.22.3; opt_einsum v3.3.0; packaging 21.0; pandas 1.4.3; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.20; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pyarrow 8.0.0; pycparser 2.20; pydev_ipython NA; pydevconsole NA; pydevd 2.4.1; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pyexpat NA; pygments 2.10.0; pylab NA; pymongo 4.1.0; pyparsing 3.0.4; pyro 1.8.1; pyrsistent NA; pytorch_lightning 1.5.10; pytz 2021.3; regex 2.5.97; requests 2.26.0; requests_cache 0.9.4; rich NA; scipy 1.7.1; scvelo 0.2.4; scvi 0.12.0; send2trash NA; setuptools_scm NA; six 1.16.0; sklearn 1.0.2; sniffio 1.2.0; socks 1.7.1; soupsieve 2.2.1; sphinxcontrib NA; storemagic NA; tables 3.6.1; tblib 1.7.0; tensorboard 2.8.0; texttable 1.6.4; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.1; torch 1.11.0; torchmetrics 0.8.1; tornado 6.1; tqdm 4.62.3; traitlets 5.1.0; typing_extensions NA; ujson 4.0.2; url_normalize 1.4.3; urllib3 1.26.7; utils NA; wcwidth 0.2.5; webencodings 0.5.1; wrapt 1.12.1; yaml 5.4.1; zipp NA; zmq 22.2.1; zope NA; -----; IPython 7.29.0; jupyter_client 6.1.12; jupyter_core 4.8.1; jupyterlab 3.2.1; notebook 6.4.5; -----; Python 3.9.7 (default, Sep 16 2021, 08:50:36) [Clang 10.0.0 ]; macOS-10.16-x86_64-i386-64bit; 10 logical CPU cores, i386. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2794,Modifiability,layers,layers,2794,"hon-input-2-2626ee07d023> in <module>; ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 7.2.0; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.0; cloudpickle 1.5.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.1; dask 2022.7.1; dateutil 2.8.1; decorator 4.4.2; fsspec 2022.01.0; google NA; h5py 3.6.0; igraph 0.9.9; ipykernel 5.3.2; ipython_genutils 0.2.0; jedi 0.17.1; jinja2 2.11.2; joblib 0.16.0; kiwisolver 1.2.0; leidenalg 0.8.0; llvmlite 0.38.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.5.2; mpl_toolkits NA; natsort 8.1.0; numba 0.55.2; numexpr 2.7.1; numpy 1.21.6; packaging 21.3; pandas 1.4.0; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.7.0; ptyprocess 0.6.0; pyarrow 8.0.0; pygments 2.6.1; pyparsing 2.4.7; pytoml NA; pytz 2020.1; scipy 1.5.0; setuptools_scm NA;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:3047,Performance,bottleneck,bottleneck,3047,"(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 7.2.0; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.0; cloudpickle 1.5.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.1; dask 2022.7.1; dateutil 2.8.1; decorator 4.4.2; fsspec 2022.01.0; google NA; h5py 3.6.0; igraph 0.9.9; ipykernel 5.3.2; ipython_genutils 0.2.0; jedi 0.17.1; jinja2 2.11.2; joblib 0.16.0; kiwisolver 1.2.0; leidenalg 0.8.0; llvmlite 0.38.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.5.2; mpl_toolkits NA; natsort 8.1.0; numba 0.55.2; numexpr 2.7.1; numpy 1.21.6; packaging 21.3; pandas 1.4.0; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.7.0; ptyprocess 0.6.0; pyarrow 8.0.0; pygments 2.6.1; pyparsing 2.4.7; pytoml NA; pytz 2020.1; scipy 1.5.0; setuptools_scm NA; six 1.14.0; sklearn 1.0.2; sphinxcontrib NA; storemagic NA; tables 3.6.1; tblib 1.6.0; texttable 1.6.4; threadpoolctl 2.1.0; tlz 0.10.1; toolz 0.10.0; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zmq 19.0.1; zope NA; -----; IPython 7.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:4581,Performance,bottleneck,bottleneck,4581,"pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.7.0; ptyprocess 0.6.0; pyarrow 8.0.0; pygments 2.6.1; pyparsing 2.4.7; pytoml NA; pytz 2020.1; scipy 1.5.0; setuptools_scm NA; six 1.14.0; sklearn 1.0.2; sphinxcontrib NA; storemagic NA; tables 3.6.1; tblib 1.6.0; texttable 1.6.4; threadpoolctl 2.1.0; tlz 0.10.1; toolz 0.10.0; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zmq 19.0.1; zope NA; -----; IPython 7.16.1; jupyter_client 6.1.6; jupyter_core 4.6.3; jupyterlab 2.1.5; notebook 6.0.3; -----; Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]; Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10; 52 logical CPU cores, x86_64; -----; </details>. The following is my package version list. <details>. -----; anndata 0.8.0; scanpy 1.7.0; sinfo 0.3.4; -----; OpenSSL 21.0.0; PIL 8.4.0; absl NA; anyio NA; appdirs 1.4.4; appnope 0.1.2; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bioservices 1.9.0; bottleneck 1.3.2; brotli NA; bs4 4.10.0; bson NA; cairo NA; cattr NA; certifi 2021.10.08; cffi 1.14.6; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.0.0; colorama 0.4.4; colorlog NA; cryptography 3.4.8; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; debugpy 1.4.1; decorator 5.1.0; defusedxml 0.7.1; deprecate 0.3.1; dill 0.3.5.1; docutils 0.17.1; dunamai 1.11.1; easydev 0.12.0; entrypoints 0.3; fsspec 2021.08.1; get_version 3.5.4; google NA; gridfs NA; gseapy 0.10.8; h5py 3.6.0; html5lib 1.1; idna 3.2; igraph 0.9.11; importlib_metadata NA; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; itsdangerous 2.0.1; jedi 0.18.0; jinja2 2.11.3; joblib 1.1.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.8.2; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.9; llvmlite 0.36.0; lxml 4.6.3; markupsafe 1.1.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbclassic NA; nbformat 5.1.3; nbinom_ufunc NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:4258,Testability,log,logical,4258,".3.2; ipython_genutils 0.2.0; jedi 0.17.1; jinja2 2.11.2; joblib 0.16.0; kiwisolver 1.2.0; leidenalg 0.8.0; llvmlite 0.38.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.5.2; mpl_toolkits NA; natsort 8.1.0; numba 0.55.2; numexpr 2.7.1; numpy 1.21.6; packaging 21.3; pandas 1.4.0; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.7.0; ptyprocess 0.6.0; pyarrow 8.0.0; pygments 2.6.1; pyparsing 2.4.7; pytoml NA; pytz 2020.1; scipy 1.5.0; setuptools_scm NA; six 1.14.0; sklearn 1.0.2; sphinxcontrib NA; storemagic NA; tables 3.6.1; tblib 1.6.0; texttable 1.6.4; threadpoolctl 2.1.0; tlz 0.10.1; toolz 0.10.0; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zmq 19.0.1; zope NA; -----; IPython 7.16.1; jupyter_client 6.1.6; jupyter_core 4.6.3; jupyterlab 2.1.5; notebook 6.0.3; -----; Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]; Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10; 52 logical CPU cores, x86_64; -----; </details>. The following is my package version list. <details>. -----; anndata 0.8.0; scanpy 1.7.0; sinfo 0.3.4; -----; OpenSSL 21.0.0; PIL 8.4.0; absl NA; anyio NA; appdirs 1.4.4; appnope 0.1.2; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bioservices 1.9.0; bottleneck 1.3.2; brotli NA; bs4 4.10.0; bson NA; cairo NA; cattr NA; certifi 2021.10.08; cffi 1.14.6; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.0.0; colorama 0.4.4; colorlog NA; cryptography 3.4.8; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; debugpy 1.4.1; decorator 5.1.0; defusedxml 0.7.1; deprecate 0.3.1; dill 0.3.5.1; docutils 0.17.1; dunamai 1.11.1; easydev 0.12.0; entrypoints 0.3; fsspec 2021.08.1; get_version 3.5.4; google NA; gridfs NA; gseapy 0.10.8; h5py 3.6.0; html5lib 1.1; idna 3.2; igraph 0.9.11; importlib_metadata NA; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; itsdangerous 2.0.1; jedi 0.18.0; jinja2 2.11.3; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:6949,Testability,log,logical,6949,"1.1; easydev 0.12.0; entrypoints 0.3; fsspec 2021.08.1; get_version 3.5.4; google NA; gridfs NA; gseapy 0.10.8; h5py 3.6.0; html5lib 1.1; idna 3.2; igraph 0.9.11; importlib_metadata NA; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; itsdangerous 2.0.1; jedi 0.18.0; jinja2 2.11.3; joblib 1.1.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.8.2; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.9; llvmlite 0.36.0; lxml 4.6.3; markupsafe 1.1.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbclassic NA; nbformat 5.1.3; nbinom_ufunc NA; numba 0.53.0; numexpr 2.7.3; numpy 1.22.3; opt_einsum v3.3.0; packaging 21.0; pandas 1.4.3; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.20; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pyarrow 8.0.0; pycparser 2.20; pydev_ipython NA; pydevconsole NA; pydevd 2.4.1; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pyexpat NA; pygments 2.10.0; pylab NA; pymongo 4.1.0; pyparsing 3.0.4; pyro 1.8.1; pyrsistent NA; pytorch_lightning 1.5.10; pytz 2021.3; regex 2.5.97; requests 2.26.0; requests_cache 0.9.4; rich NA; scipy 1.7.1; scvelo 0.2.4; scvi 0.12.0; send2trash NA; setuptools_scm NA; six 1.16.0; sklearn 1.0.2; sniffio 1.2.0; socks 1.7.1; soupsieve 2.2.1; sphinxcontrib NA; storemagic NA; tables 3.6.1; tblib 1.7.0; tensorboard 2.8.0; texttable 1.6.4; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.1; torch 1.11.0; torchmetrics 0.8.1; tornado 6.1; tqdm 4.62.3; traitlets 5.1.0; typing_extensions NA; ujson 4.0.2; url_normalize 1.4.3; urllib3 1.26.7; utils NA; wcwidth 0.2.5; webencodings 0.5.1; wrapt 1.12.1; yaml 5.4.1; zipp NA; zmq 22.2.1; zope NA; -----; IPython 7.29.0; jupyter_client 6.1.12; jupyter_core 4.8.1; jupyterlab 3.2.1; notebook 6.4.5; -----; Python 3.9.7 (default, Sep 16 2021, 08:50:36) [Clang 10.0.0 ]; macOS-10.16-x86_64-i386-64bit; 10 logical CPU cores, i386. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2311:667,Usability,clear,clear,667,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. From [pl.embedding documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.embedding.html), for `palette`, it states; >If provided, values of adata.uns[""{var}_colors""] will be set. This implies that if not provided, then those values will not be set.; However, they are being set - either without specifying `palette` (default:None), or explicitly passing `palette=None`; Either it's a bug, or the documentation is not clear. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.read_h5ad('my_matrix.h5ad'); adata.uns = {} #confirming *_colors is not set already; sc.pl.embedding(adata, basis='X_umap', palette=None, color=['cell_type']); adata.uns['cell_type_colors']; ```. ```pytb; ['#1f77b4',; '#ff7f0e',; '#279e68',; '#d62728',; '#aa40fc',; '#8c564b',; '#e377c2',; '#b5bd61',; '#17becf']; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311
https://github.com/scverse/scanpy/issues/2314:202,Performance,load,loadings,202,"`sc.external.pp.harmony_integrate(adata, 'Batch')` only adds an obsm key `'X_pca_harmony'`. In order to analyze values for a specific gene after harmony, you would need to multiply `X_pca_harmony` by a loadings matrix, but `adata.varm` doesn't seem to get a `harmony_PCs` to accompany vanilla `adata.varm['PCs']`. . Is there a method I'm missing to analyze a harmony-corrected counts matrix in scanpy? If so, I'd love to see it documented. If not, I'd love to see it added.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2316:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; It seems like there is an argument in `sc.pl.spatial` to return the Matplotlib figure used for plotting. However, from inspecting the source code, I think that this doesn't really do that; it seems more like that argument just makes the function return the Matplotlib Axes instead? For context, I am using `sc.pl.spatial` + `sq.pl.extract` to plot many features on subplots, but I would like to add a ""suptitle"" to the whole figure.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2317:1784,Testability,test,testing,1784,"you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. ; ; 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Input In [72], in <cell line: 2>(); 1 # each WT sample individually vs all other WT samples; ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], ; method='wilcoxon'); ; File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in ; rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, ; tie_correct, layer, **kwds); 568 if isinstance(groups_order[0], int):; 569 groups_order = [str(n) for n in groups_order]; --> 570 if reference != 'rest' and reference not in set(groups_order):; 571 groups_order += [reference]; 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'; ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated!; Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:1868,Testability,test,tested,1868,"you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. ; ; 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Input In [72], in <cell line: 2>(); 1 # each WT sample individually vs all other WT samples; ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], ; method='wilcoxon'); ; File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in ; rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, ; tie_correct, layer, **kwds); 568 if isinstance(groups_order[0], int):; 569 groups_order = [str(n) for n in groups_order]; --> 570 if reference != 'rest' and reference not in set(groups_order):; 571 groups_order += [reference]; 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'; ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated!; Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:1908,Testability,test,test,1908,"you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. ; ; 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Input In [72], in <cell line: 2>(); 1 # each WT sample individually vs all other WT samples; ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], ; method='wilcoxon'); ; File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in ; rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, ; tie_correct, layer, **kwds); 568 if isinstance(groups_order[0], int):; 569 groups_order = [str(n) for n in groups_order]; --> 570 if reference != 'rest' and reference not in set(groups_order):; 571 groups_order += [reference]; 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'; ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated!; Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:2014,Testability,test,test,2014,"you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. ; ; 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Input In [72], in <cell line: 2>(); 1 # each WT sample individually vs all other WT samples; ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], ; method='wilcoxon'); ; File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in ; rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, ; tie_correct, layer, **kwds); 568 if isinstance(groups_order[0], int):; 569 groups_order = [str(n) for n in groups_order]; --> 570 if reference != 'rest' and reference not in set(groups_order):; 571 groups_order += [reference]; 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'; ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated!; Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:2218,Testability,test,tested,2218,"you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. ; ; 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Input In [72], in <cell line: 2>(); 1 # each WT sample individually vs all other WT samples; ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], ; method='wilcoxon'); ; File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in ; rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, ; tie_correct, layer, **kwds); 568 if isinstance(groups_order[0], int):; 569 groups_order = [str(n) for n in groups_order]; --> 570 if reference != 'rest' and reference not in set(groups_order):; 571 groups_order += [reference]; 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'; ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated!; Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:2308,Testability,test,tested,2308,"you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. ; ; 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Input In [72], in <cell line: 2>(); 1 # each WT sample individually vs all other WT samples; ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], ; method='wilcoxon'); ; File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in ; rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, ; tie_correct, layer, **kwds); 568 if isinstance(groups_order[0], int):; 569 groups_order = [str(n) for n in groups_order]; --> 570 if reference != 'rest' and reference not in set(groups_order):; 571 groups_order += [reference]; 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'; ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated!; Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. ; ; 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Input In [72], in <cell line: 2>(); 1 # each WT sample individually vs all other WT samples; ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], ; method='wilcoxon'); ; File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in ; rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, ; tie_correct, layer, **kwds); 568 if isinstance(groups_order[0], int):; 569 groups_order = [str(n) for n in groups_order]; --> 570 if reference != 'rest' and reference not in set(groups_order):; 571 groups_order += [reference]; 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'; ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Cur",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2318:142,Availability,error,error,142,"I was running this code `sc.pl.umap(adata, color = ['KIR3DL1'], frameon = False, layer = 'scvi_normalized')` to create umap but it gave me an error message with empty heatmap color bar legend. ![ 2022-09-02  9 34 00](https://user-images.githubusercontent.com/64761042/188034720-20eacca2-efa0-4d6c-9e7f-0543f85d1cd7.png). ![ 2022-09-01  6 58 54](https://user-images.githubusercontent.com/64761042/188034773-c32610cc-60a3-4c17-a000-8296f013b3e7.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:148,Integrability,message,message,148,"I was running this code `sc.pl.umap(adata, color = ['KIR3DL1'], frameon = False, layer = 'scvi_normalized')` to create umap but it gave me an error message with empty heatmap color bar legend. ![ 2022-09-02  9 34 00](https://user-images.githubusercontent.com/64761042/188034720-20eacca2-efa0-4d6c-9e7f-0543f85d1cd7.png). ![ 2022-09-01  6 58 54](https://user-images.githubusercontent.com/64761042/188034773-c32610cc-60a3-4c17-a000-8296f013b3e7.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2319:816,Deployability,integrat,integrated,816,"According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500); ```. ```pytb; WARNING: Out of memory, consider turning on batched computation with batch_size parameter.; Traceback (most recent call last):; File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>; sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500); File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate; integrated = scanorama.assemble(; File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble; bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,; File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform; avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,; File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias; weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma); File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel; X, Y = check_pairwise_arrays(X, Y); File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays; X = check_array(; File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array; warnings.warn(; FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:816,Integrability,integrat,integrated,816,"According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500); ```. ```pytb; WARNING: Out of memory, consider turning on batched computation with batch_size parameter.; Traceback (most recent call last):; File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>; sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500); File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate; integrated = scanorama.assemble(; File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble; bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,; File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform; avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,; File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias; weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma); File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel; X, Y = check_pairwise_arrays(X, Y); File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays; X = check_array(; File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array; warnings.warn(; FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:1829,Security,validat,validation,1829,", I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500); ```. ```pytb; WARNING: Out of memory, consider turning on batched computation with batch_size parameter.; Traceback (most recent call last):; File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>; sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500); File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate; integrated = scanorama.assemble(; File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble; bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,; File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform; avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,; File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias; weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma); File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel; X, Y = check_pairwise_arrays(X, Y); File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays; X = check_array(; File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array; warnings.warn(; FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/pull/2320:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/psf/black: 22.6.0  22.8.0](https://github.com/psf/black/compare/22.6.0...22.8.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2320
https://github.com/scverse/scanpy/issues/2321:794,Availability,error,error,794,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""); ```. ```pytb; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### ; anndata == 0.8.0; scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help.; What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; absl NA; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2022.06.15; cffi 1.15.1; charset_normalizer 2.1.0; chex 0.1.3; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; deprecate 0.3.2; docrep 0.3.2; entrypoints 0.4; etils 0.6.0; executing 0.8.3; flatbuffers 2.0; flax 0.5.2; fsspec 2022.5.0; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.11; iniconfig NA; ipykernel 6.15.1; ipython_genutils 0.2.0; ipywidgets 7.7.1; jax 0.3.14; jaxlib 0.3.14; jedi 0.18",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:1192,Availability,error,error,1192,"master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""); ```. ```pytb; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### ; anndata == 0.8.0; scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help.; What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; absl NA; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2022.06.15; cffi 1.15.1; charset_normalizer 2.1.0; chex 0.1.3; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; deprecate 0.3.2; docrep 0.3.2; entrypoints 0.4; etils 0.6.0; executing 0.8.3; flatbuffers 2.0; flax 0.5.2; fsspec 2022.5.0; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.11; iniconfig NA; ipykernel 6.15.1; ipython_genutils 0.2.0; ipywidgets 7.7.1; jax 0.3.14; jaxlib 0.3.14; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.3; leidenalg 0.8.10; llvmlite 0.38.1; louvain 0.7.1; matplotlib 3.5.2; matplotlib_inline NA; mpl_toolkits NA; msgpack 1.0.4; mudata 0.2.0; multipledispatch 0.6.0; na",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:3460,Deployability,update,updated,3460,"ntime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; deprecate 0.3.2; docrep 0.3.2; entrypoints 0.4; etils 0.6.0; executing 0.8.3; flatbuffers 2.0; flax 0.5.2; fsspec 2022.5.0; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.11; iniconfig NA; ipykernel 6.15.1; ipython_genutils 0.2.0; ipywidgets 7.7.1; jax 0.3.14; jaxlib 0.3.14; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.3; leidenalg 0.8.10; llvmlite 0.38.1; louvain 0.7.1; matplotlib 3.5.2; matplotlib_inline NA; mpl_toolkits NA; msgpack 1.0.4; mudata 0.2.0; multipledispatch 0.6.0; natsort 8.1.0; nbinom_ufunc NA; newick 1.0.0; numba 0.55.2; numpy 1.22.4; numpyro 0.10.0; opt_einsum v3.3.0; optax 0.1.3; packaging 21.3; pandas 1.4.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; pluggy 1.0.0; prompt_toolkit 3.0.30; psutil 5.9.1; ptyprocess 0.7.0; pure_eval 0.2.2; py 1.11.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.12.0; pyparsing 3.0.9; pyro 1.8.1; pytest 7.1.2; pytorch_lightning 1.6.5; pytz 2022.1; requests 2.28.1; rich NA; scHPL NA; scarches 0.5.3; scipy 1.8.1; scvi 0.17.1; seaborn 0.11.2; session_info 1.0.0; setuptools 63.1.0; six 1.16.0; sklearn 1.1.1; socks 1.7.1; stack_data 0.3.0; statsmodels 0.13.2; tensorboard 2.9.1; texttable 1.6.4; threadpoolctl 3.1.0; toolz 0.12.0; torch 1.12.0+cu102; torchmetrics 0.9.2; tornado 6.2; tqdm 4.64.0; traitlets 5.3.0; tree 0.1.7; typing_extensions NA; urllib3 1.26.10; wcwidth 0.2.5; wrapt 1.14.1; yaml 6.0; zmq 23.2.0; -----; IPython 8.4.0; jupyter_client 7.3.4; jupyter_core 4.10.0; notebook 6.4.12; -----; Python 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:04:59) [GCC 10.3.0]; Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17; -----; Session information updated at 2022-09-09 14:21; combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""); combined_data.write(f""{workspace}Data/Models/H",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:3165,Integrability,wrap,wrapt,3165,"ntime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; deprecate 0.3.2; docrep 0.3.2; entrypoints 0.4; etils 0.6.0; executing 0.8.3; flatbuffers 2.0; flax 0.5.2; fsspec 2022.5.0; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.11; iniconfig NA; ipykernel 6.15.1; ipython_genutils 0.2.0; ipywidgets 7.7.1; jax 0.3.14; jaxlib 0.3.14; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.3; leidenalg 0.8.10; llvmlite 0.38.1; louvain 0.7.1; matplotlib 3.5.2; matplotlib_inline NA; mpl_toolkits NA; msgpack 1.0.4; mudata 0.2.0; multipledispatch 0.6.0; natsort 8.1.0; nbinom_ufunc NA; newick 1.0.0; numba 0.55.2; numpy 1.22.4; numpyro 0.10.0; opt_einsum v3.3.0; optax 0.1.3; packaging 21.3; pandas 1.4.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; pluggy 1.0.0; prompt_toolkit 3.0.30; psutil 5.9.1; ptyprocess 0.7.0; pure_eval 0.2.2; py 1.11.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.12.0; pyparsing 3.0.9; pyro 1.8.1; pytest 7.1.2; pytorch_lightning 1.6.5; pytz 2022.1; requests 2.28.1; rich NA; scHPL NA; scarches 0.5.3; scipy 1.8.1; scvi 0.17.1; seaborn 0.11.2; session_info 1.0.0; setuptools 63.1.0; six 1.16.0; sklearn 1.1.1; socks 1.7.1; stack_data 0.3.0; statsmodels 0.13.2; tensorboard 2.9.1; texttable 1.6.4; threadpoolctl 3.1.0; toolz 0.12.0; torch 1.12.0+cu102; torchmetrics 0.9.2; tornado 6.2; tqdm 4.64.0; traitlets 5.3.0; tree 0.1.7; typing_extensions NA; urllib3 1.26.10; wcwidth 0.2.5; wrapt 1.14.1; yaml 6.0; zmq 23.2.0; -----; IPython 8.4.0; jupyter_client 7.3.4; jupyter_core 4.10.0; notebook 6.4.12; -----; Python 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:04:59) [GCC 10.3.0]; Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17; -----; Session information updated at 2022-09-09 14:21; combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""); combined_data.write(f""{workspace}Data/Models/H",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:1293,Testability,log,logging,1293,"ork/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""); ```. ```pytb; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### ; anndata == 0.8.0; scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help.; What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; absl NA; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2022.06.15; cffi 1.15.1; charset_normalizer 2.1.0; chex 0.1.3; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; deprecate 0.3.2; docrep 0.3.2; entrypoints 0.4; etils 0.6.0; executing 0.8.3; flatbuffers 2.0; flax 0.5.2; fsspec 2022.5.0; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.11; iniconfig NA; ipykernel 6.15.1; ipython_genutils 0.2.0; ipywidgets 7.7.1; jax 0.3.14; jaxlib 0.3.14; jedi 0.18.1; joblib 1.1.0; kiwisolver 1.4.3; leidenalg 0.8.10; llvmlite 0.38.1; louvain 0.7.1; matplotlib 3.5.2; matplotlib_inline NA; mpl_toolkits NA; msgpack 1.0.4; mudata 0.2.0; multipledispatch 0.6.0; natsort 8.1.0; nbinom_ufunc NA; newick 1.0.0; numba 0.55.2; numpy 1.22.4; numpyro 0.10.0; opt_einsum",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""); ```. ```pytb; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### ; anndata == 0.8.0; scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help.; What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; absl NA; asttokens NA; attr 21.4.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2022.06.15; cffi 1.15.1; charset_normalizer 2.1.0; chex 0.1.3; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; deprecate 0.3.2; docrep 0.3.2; entrypoints 0.4; etils 0.6.0; executing 0.8.3; flatbuffers 2.0; flax 0.5.2; fsspec 2022.5.0; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.11; iniconfig NA; ipykernel 6.15.1; ipython_genutils 0.2.0; ipywidgets 7.7.1; jax 0.3.14; jaxlib 0.3.14; jedi 0.18",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2323:394,Availability,down,downstream,394,"Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. ; > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:310,Deployability,integrat,integration,310,"Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. ; > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:25,Integrability,wrap,wrapper,25,"Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. ; > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:310,Integrability,integrat,integration,310,"Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. ; > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:152,Usability,simpl,simply,152,"Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. ; > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2328:2310,Availability,error,error,2310,"t call last); Input In [3], in <cell line: 1>(); ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url); 178 if not is_present:; 179 logg.debug(f'... did not find original file {filename}'); --> 180 with h5py.File(str(filename), 'r') as f:; 181 v3 = '/matrix' in f; 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds); 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,; 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds); 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,; 505 fs_persist=fs_persist, fs_threshold=fs_threshold,; 506 fs_page_size=fs_page_size); --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr); 509 if isinstance(libver, tuple):; 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr); 218 if swmr and swmr_support:; 219 flags |= h5f.ACC_SWMR_READ; --> 220 fid = h5f.open(name, flags, fapl=fapl); 221 elif mode == 'r+':; 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022; , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0); `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:2004,Integrability,wrap,wrapper,2004,"t call last); Input In [3], in <cell line: 1>(); ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url); 178 if not is_present:; 179 logg.debug(f'... did not find original file {filename}'); --> 180 with h5py.File(str(filename), 'r') as f:; 181 v3 = '/matrix' in f; 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds); 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,; 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds); 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,; 505 fs_persist=fs_persist, fs_threshold=fs_threshold,; 506 fs_page_size=fs_page_size); --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr); 509 if isinstance(libver, tuple):; 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr); 218 if swmr and swmr_support:; 219 flags |= h5f.ACC_SWMR_READ; --> 220 fid = h5f.open(name, flags, fapl=fapl); 221 elif mode == 'r+':; 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022; , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0); `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:2069,Integrability,wrap,wrapper,2069,"t call last); Input In [3], in <cell line: 1>(); ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url); 178 if not is_present:; 179 logg.debug(f'... did not find original file {filename}'); --> 180 with h5py.File(str(filename), 'r') as f:; 181 v3 = '/matrix' in f; 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds); 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,; 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds); 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,; 505 fs_persist=fs_persist, fs_threshold=fs_threshold,; 506 fs_page_size=fs_page_size); --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr); 509 if isinstance(libver, tuple):; 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr); 218 if swmr and swmr_support:; 219 flags |= h5f.ACC_SWMR_READ; --> 220 fid = h5f.open(name, flags, fapl=fapl); 221 elif mode == 'r+':; 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022; , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0); `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:2316,Integrability,message,message,2316,"t call last); Input In [3], in <cell line: 1>(); ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url); 178 if not is_present:; 179 logg.debug(f'... did not find original file {filename}'); --> 180 with h5py.File(str(filename), 'r') as f:; 181 v3 = '/matrix' in f; 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds); 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,; 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds); 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,; 505 fs_persist=fs_persist, fs_threshold=fs_threshold,; 506 fs_page_size=fs_page_size); --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr); 509 if isinstance(libver, tuple):; 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr); 218 if swmr and swmr_support:; 219 flags |= h5f.ACC_SWMR_READ; --> 220 fid = h5f.open(name, flags, fapl=fapl); 221 elif mode == 'r+':; 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022; , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0); `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:14,Performance,load,load,14,"I'm trying to load the GSE164690 data using sc.read_10x_h5(), for which I'm including the path to the folders which contain the barcodes.tsv, features.tsv and matrix.mtx but I'm getting the IsADirectoryError every time I run the function. . `; adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'); reading GSE164690_RAW/GSM5017021_HN01_PBL/; ---------------------------------------------------------------------------; IsADirectoryError Traceback (most recent call last); Input In [3], in <cell line: 1>(); ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url); 178 if not is_present:; 179 logg.debug(f'... did not find original file {filename}'); --> 180 with h5py.File(str(filename), 'r') as f:; 181 v3 = '/matrix' in f; 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds); 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,; 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds); 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,; 505 fs_persist=fs_persist, fs_threshold=fs_threshold,; 506 fs_page_size=fs_page_size); --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr); 509 if isinstance(libver, tuple):; 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr); 218 if swmr and swmr_support:; 219 flags |= h5f.ACC_SWMR_READ; --> 220 fid = h5f.open(name, flags, fapl=fapl); 221 elif mode == 'r+':; 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_ph",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:745,Testability,log,logg,745,"I'm trying to load the GSE164690 data using sc.read_10x_h5(), for which I'm including the path to the folders which contain the barcodes.tsv, features.tsv and matrix.mtx but I'm getting the IsADirectoryError every time I run the function. . `; adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'); reading GSE164690_RAW/GSM5017021_HN01_PBL/; ---------------------------------------------------------------------------; IsADirectoryError Traceback (most recent call last); Input In [3], in <cell line: 1>(); ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url); 178 if not is_present:; 179 logg.debug(f'... did not find original file {filename}'); --> 180 with h5py.File(str(filename), 'r') as f:; 181 v3 = '/matrix' in f; 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds); 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,; 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds); 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,; 505 fs_persist=fs_persist, fs_threshold=fs_threshold,; 506 fs_page_size=fs_page_size); --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr); 509 if isinstance(libver, tuple):; 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr); 218 if swmr and swmr_support:; 219 flags |= h5f.ACC_SWMR_READ; --> 220 fid = h5f.open(name, flags, fapl=fapl); 221 elif mode == 'r+':; 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_ph",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2330:1527,Availability,error,error,1527," 'mean_counts', 'pct_dropout_by_counts', 'total_counts'; uns: 'genome'; ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA; on highly variable genes; with n_comps=30; finished (0:01:25); computing neighbors; finished: added to `.uns['neighbors']`; `.obsp['distances']`, distances for each pair of neighbors; `.obsp['connectivities']`, weighted adjacency matrix (0:00:04); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:00:18); running Leiden clustering; finished: found 23 clusters and added; 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04); ```; But when I check my anndata, none present. As such if I try to generate a umap image I get the following error; ```; AnnData object with n_obs  n_vars = 28752  22603; obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'; var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'; uns: 'genome', 'log1p', 'hvg'; ```. ```; sc.pl.umap(adata,color=['overall'], palette=colors_list); ```; ```pytb; raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm""; ```. #### Versions. <details>. [-----; anndata 0.8.0; scanpy 1.9.1; -----; AlexFunctions NA; JonFunctions NA; PIL 9.2.0; PyQt5 NA; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; astunparse 1.6.3; atomicwrites 1.4.1; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; bs4 4.11.1; certifi 2022.09.14; cffi 1.15.1; chardet 5.0.0; charset_normalizer 2.1.1; cloudpickle 2.2.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:4432,Deployability,update,updated,4432,"3c4f42 NA; absl NA; astunparse 1.6.3; atomicwrites 1.4.1; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; bs4 4.11.1; certifi 2022.09.14; cffi 1.15.1; chardet 5.0.0; charset_normalizer 2.1.1; cloudpickle 2.2.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.5.1; entrypoints 0.4; flatbuffers 2.0; gast 0.5.3; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.11; import_all NA; ipykernel 6.15.3; jedi 0.18.1; joblib 1.2.0; keras 2.8.0; keras_preprocessing 1.1.2; kiwisolver 1.4.4; leidenalg 0.8.10; llvmlite 0.38.1; louvain 0.7.1; lxml 4.9.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.55.2; numpy 1.22.4; opt_einsum v3.3.0; packaging 21.3; pandas 1.4.4; params NA; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.10.0; prompt_toolkit 3.0.31; psutil 5.9.2; ptyprocess 0.7.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pynndescent 0.5.7; pyparsing 3.0.9; pytz 2022.2.1; requests 2.28.1; scipy 1.9.1; seaborn 0.12.0; session_info 1.0.0; setuptools 65.3.0; sip NA; six 1.16.0; sklearn 1.1.2; socks 1.7.1; soupsieve 2.3.2.post1; sphinxcontrib NA; spyder 5.3.3; spyder_kernels 2.3.3; spydercustomize NA; statsmodels 0.13.2; storemagic NA; tensorboard 2.8.0; tensorflow 2.8.0; termcolor 1.1.0; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.2; tqdm 4.64.1; traitlets 5.4.0; typing_extensions NA; umap 0.5.3; unicodedata2 NA; urllib3 1.26.11; wcwidth 0.2.5; wrapt 1.14.1; wurlitzer 3.0.2; yaml 6.0; zipp NA; zmq 24.0.0; -----; IPython 7.33.0; jupyter_client 7.3.5; jupyter_core 4.11.1; -----; Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]; Linux-5.4.0-124-generic-x86_64-with-glibc2.31; -----; Session information updated at 2022-09-16 10:24]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:4137,Integrability,wrap,wrapt,4137,"3c4f42 NA; absl NA; astunparse 1.6.3; atomicwrites 1.4.1; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; bs4 4.11.1; certifi 2022.09.14; cffi 1.15.1; chardet 5.0.0; charset_normalizer 2.1.1; cloudpickle 2.2.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.5.1; entrypoints 0.4; flatbuffers 2.0; gast 0.5.3; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.11; import_all NA; ipykernel 6.15.3; jedi 0.18.1; joblib 1.2.0; keras 2.8.0; keras_preprocessing 1.1.2; kiwisolver 1.4.4; leidenalg 0.8.10; llvmlite 0.38.1; louvain 0.7.1; lxml 4.9.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.55.2; numpy 1.22.4; opt_einsum v3.3.0; packaging 21.3; pandas 1.4.4; params NA; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.10.0; prompt_toolkit 3.0.31; psutil 5.9.2; ptyprocess 0.7.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pynndescent 0.5.7; pyparsing 3.0.9; pytz 2022.2.1; requests 2.28.1; scipy 1.9.1; seaborn 0.12.0; session_info 1.0.0; setuptools 65.3.0; sip NA; six 1.16.0; sklearn 1.1.2; socks 1.7.1; soupsieve 2.3.2.post1; sphinxcontrib NA; spyder 5.3.3; spyder_kernels 2.3.3; spydercustomize NA; statsmodels 0.13.2; storemagic NA; tensorboard 2.8.0; tensorflow 2.8.0; termcolor 1.1.0; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.2; tqdm 4.64.1; traitlets 5.4.0; typing_extensions NA; umap 0.5.3; unicodedata2 NA; urllib3 1.26.11; wcwidth 0.2.5; wrapt 1.14.1; wurlitzer 3.0.2; yaml 6.0; zipp NA; zmq 24.0.0; -----; IPython 7.33.0; jupyter_client 7.3.5; jupyter_core 4.11.1; -----; Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]; Linux-5.4.0-124-generic-x86_64-with-glibc2.31; -----; Session information updated at 2022-09-16 10:24]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:959,Modifiability,variab,variable,959,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata; ```; AnnData object with n_obs  n_vars = 28752  22603; obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'; var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'; uns: 'genome'; ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA; on highly variable genes; with n_comps=30; finished (0:01:25); computing neighbors; finished: added to `.uns['neighbors']`; `.obsp['distances']`, distances for each pair of neighbors; `.obsp['connectivities']`, weighted adjacency matrix (0:00:04); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:00:18); running Leiden clustering; finished: found 23 clusters and added; 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04); ```; But when I check my anndata, none present. As such if I try to generate a umap image I get the following error; ```; AnnData object with n_obs  n_vars = 28752  22603; obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'; var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata; ```; AnnData object with n_obs  n_vars = 28752  22603; obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'; var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'; uns: 'genome'; ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA; on highly variable genes; with n_comps=30; finished (0:01:25); computing neighbors; finished: added to `.uns['neighbors']`; `.obsp['distances']`, distances for each pair of neighbors; `.obsp['connectivities']`, weighted adjacency matrix (0:00:04); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:00:18); running Leiden clustering; finished: found 23 clusters and added; 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04); ```; But when I check my anndata, none present. As such if I try to generate a umap image I get the following error; ```; AnnData object with n_obs  n_vars = 28752  22603; obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'; var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2331:141,Deployability,update,updated,141,I think it makes sense to deprecate and then remove `sc.read_visium`. and `sc.pl.spatial` since I don't plan to maintain it here anymore and updated versions are present in Squidpy. What do you think @ivirshup ?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2331
https://github.com/scverse/scanpy/issues/2332:78,Availability,error,error,78,"---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks!. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here. # making a simple adata object; data = {'gene1':[1,2,3],; 'gene2':[3,2,2],; 'gene3':[1,4,1]}; df = pd.DataFrame(data); dft = df.T; adata = anndata.AnnData(X= df.iloc[0:,0:],; obs= df.iloc[0:,0:1],; var= dft.iloc[0:,0:1]). # computing principal component analysis; sc.tl.pca(adata, svd_solver='arpack'); sc.pl.pca(adata, color='gene2'). ```. ```pytb; [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>; ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames; [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 870 if not annotate_var_explained:; 871 return embedding(; --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ); 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 451 elif colorbar_loc is not None:; 452 pl.colorbar(; --> 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:183,Availability,error,error,183,"---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks!. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here. # making a simple adata object; data = {'gene1':[1,2,3],; 'gene2':[3,2,2],; 'gene3':[1,4,1]}; df = pd.DataFrame(data); dft = df.T; adata = anndata.AnnData(X= df.iloc[0:,0:],; obs= df.iloc[0:,0:1],; var= dft.iloc[0:,0:1]). # computing principal component analysis; sc.tl.pca(adata, svd_solver='arpack'); sc.pl.pca(adata, color='gene2'). ```. ```pytb; [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>; ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames; [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 870 if not annotate_var_explained:; 871 return embedding(; --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ); 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 451 elif colorbar_loc is not None:; 452 pl.colorbar(; --> 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:721,Availability,error,error,721,"---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks!. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here. # making a simple adata object; data = {'gene1':[1,2,3],; 'gene2':[3,2,2],; 'gene3':[1,4,1]}; df = pd.DataFrame(data); dft = df.T; adata = anndata.AnnData(X= df.iloc[0:,0:],; obs= df.iloc[0:,0:1],; var= dft.iloc[0:,0:1]). # computing principal component analysis; sc.tl.pca(adata, svd_solver='arpack'); sc.pl.pca(adata, color='gene2'). ```. ```pytb; [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>; ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames; [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 870 if not annotate_var_explained:; 871 return embedding(; --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ); 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 451 elif colorbar_loc is not None:; 452 pl.colorbar(; --> 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:4830,Availability,error,error,4830,"0/#) in __init__(self, ax, mappable, **kw); 1228 they will need to be customized again. However, if the norm only; 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter; -> 1230 and locator will be preserved.; 1231 """"""; 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0; scanpy 1.9.1. PIL 7.1.2; astor 0.8.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cached_property 1.5.2; certifi 2022.06.15; cffi 1.15.1; cloudpickle 1.5.0; cycler 0.10.0; cython_runtime NA; dask 2022.02.0; dateutil 2.8.2; debugpy 1.0.0; decorator 4.4.2; fsspec 2022.8.2; google NA; h5py 3.1.0; httplib2 0.17.4; ipykernel 5.3.4; ipython_genutils 0.2.0; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.4.4; llvmlite 0.39.1; markupsafe 2.0.1; matplotlib 3.2.2; mpl_toolkits NA; natsort 5.5.0; nbinom_ufunc NA; numba 0.56.2; numexpr 2.8.3; numpy 1.21.6; packaging 21.3; pandas 1.3.5; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; portpicker NA; prompt_toolkit 2.0.10; psutil 5.4.8; ptyprocess 0.7.0; pyarrow 6.0.1; pydev_ipython NA; pydevconsole NA; pydevd 2.0.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.6.1; pyparsing 3.0.9; pytz 2022.2.1; scipy 1.7.3; session_info 1.0.0; sitecustomize NA; six 1.15.0; sklearn 1.0.2; socks 1.7.1; sphinxcontrib NA; storemagic NA; tblib 1.7.0; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; tornado 5.1.1; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 23.2.1. IPython 7.9.0; jupyter_client 6.1.12; jupyter_core 4.11.1; notebook 5.3.1. Python 3.7.14 (default, Sep 8 2022, 00:06:44) [GCC 7.5.0]; Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-09-16 19:14. </details>; ![error](https://user-images.githubusercontent.com/72993520/190715283-6ae522e3-dd86-4179-956b-196f3f2c845b.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:4787,Deployability,update,updated,4787,"0/#) in __init__(self, ax, mappable, **kw); 1228 they will need to be customized again. However, if the norm only; 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter; -> 1230 and locator will be preserved.; 1231 """"""; 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0; scanpy 1.9.1. PIL 7.1.2; astor 0.8.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cached_property 1.5.2; certifi 2022.06.15; cffi 1.15.1; cloudpickle 1.5.0; cycler 0.10.0; cython_runtime NA; dask 2022.02.0; dateutil 2.8.2; debugpy 1.0.0; decorator 4.4.2; fsspec 2022.8.2; google NA; h5py 3.1.0; httplib2 0.17.4; ipykernel 5.3.4; ipython_genutils 0.2.0; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.4.4; llvmlite 0.39.1; markupsafe 2.0.1; matplotlib 3.2.2; mpl_toolkits NA; natsort 5.5.0; nbinom_ufunc NA; numba 0.56.2; numexpr 2.8.3; numpy 1.21.6; packaging 21.3; pandas 1.3.5; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; portpicker NA; prompt_toolkit 2.0.10; psutil 5.4.8; ptyprocess 0.7.0; pyarrow 6.0.1; pydev_ipython NA; pydevconsole NA; pydevd 2.0.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.6.1; pyparsing 3.0.9; pytz 2022.2.1; scipy 1.7.3; session_info 1.0.0; sitecustomize NA; six 1.15.0; sklearn 1.0.2; socks 1.7.1; sphinxcontrib NA; storemagic NA; tblib 1.7.0; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; tornado 5.1.1; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 23.2.1. IPython 7.9.0; jupyter_client 6.1.12; jupyter_core 4.11.1; notebook 5.3.1. Python 3.7.14 (default, Sep 8 2022, 00:06:44) [GCC 7.5.0]; Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-09-16 19:14. </details>; ![error](https://user-images.githubusercontent.com/72993520/190715283-6ae522e3-dd86-4179-956b-196f3f2c845b.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:3311,Testability,log,logging,3311,"otnotes; 2010 ; 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw); 2236 for ax in self.axes:; 2237 if not isinstance(ax, SubplotBase):; -> 2238 # Check if sharing a subplots axis; 2239 if isinstance(ax._sharex, SubplotBase):; 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw); 1228 they will need to be customized again. However, if the norm only; 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter; -> 1230 and locator will be preserved.; 1231 """"""; 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0; scanpy 1.9.1. PIL 7.1.2; astor 0.8.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cached_property 1.5.2; certifi 2022.06.15; cffi 1.15.1; cloudpickle 1.5.0; cycler 0.10.0; cython_runtime NA; dask 2022.02.0; dateutil 2.8.2; debugpy 1.0.0; decorator 4.4.2; fsspec 2022.8.2; google NA; h5py 3.1.0; httplib2 0.17.4; ipykernel 5.3.4; ipython_genutils 0.2.0; jinja2 2.11.3; joblib 1.1.0; kiwisolver 1.4.4; llvmlite 0.39.1; markupsafe 2.0.1; matplotlib 3.2.2; mpl_toolkits NA; natsort 5.5.0; nbinom_ufunc NA; numba 0.56.2; numexpr 2.8.3; numpy 1.21.6; packaging 21.3; pandas 1.3.5; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; portpicker NA; prompt_toolkit 2.0.10; psutil 5.4.8; ptyprocess 0.7.0; pyarrow 6.0.1; pydev_ipython NA; pydevconsole NA; pydevd 2.0.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.6.1; pyparsing 3.0.9; pytz 2022.2.1; scipy 1.7.3; se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:371,Usability,simpl,simple,371,"---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks!. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here. # making a simple adata object; data = {'gene1':[1,2,3],; 'gene2':[3,2,2],; 'gene3':[1,4,1]}; df = pd.DataFrame(data); dft = df.T; adata = anndata.AnnData(X= df.iloc[0:,0:],; obs= df.iloc[0:,0:1],; var= dft.iloc[0:,0:1]). # computing principal component analysis; sc.tl.pca(adata, svd_solver='arpack'); sc.pl.pca(adata, color='gene2'). ```. ```pytb; [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>; ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames; [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 870 if not annotate_var_explained:; 871 return embedding(; --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ); 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 451 elif colorbar_loc is not None:; 452 pl.colorbar(; --> 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2333:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ... Currently, to compare gene expressions on the umap between different samples or conditions; I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:; print(i); sc.pl.umap(; adata[adata.obs[""bulk.ident""] == i], size=20,; color=[""gene""],; frameon=False, ; ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy?. +addendum; Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:1001,Usability,simpl,simply,1001,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ... Currently, to compare gene expressions on the umap between different samples or conditions; I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:; print(i); sc.pl.umap(; adata[adata.obs[""bulk.ident""] == i], size=20,; color=[""gene""],; frameon=False, ; ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy?. +addendum; Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2337:13,Usability,learn,learning,13,"Hi all,; I'm learning scanpy following tutorial, but the picture after tl.umap looks very strange. I'm not sure what's the problem is..; ![tl.umap](https://github.com/FionaMoon/Picture-Saving/blob/master/img/umap.pdf)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337
https://github.com/scverse/scanpy/issues/2338:4009,Testability,log,logfoldchanges,4009,", -13.793954, -5.828585 ),; (-27.61369 , -31.664293, -16.766815, -20.83902 , -14.882286, -5.9672713)],; dtype=[('0', '<f4'), ('1', '<f4'), ('2', '<f4'), ('3', '<f4'), ('4', '<f4'), ('5', '<f4')]), 'pvals': rec.array([(5.76757182e-213, 1.70978363e-252, 6.59163276e-208, 4.99861075e-188, 7.91707478e-61, 2.17405930e-09),; (5.30272154e-171, 1.27177903e-235, 2.38824940e-153, 2.68829460e-181, 2.67790267e-58, 2.17405930e-09),; (3.40236053e-161, 7.94325574e-233, 8.36374334e-147, 1.96443112e-166, 9.50323353e-57, 2.17933501e-09),; ...,; (5.70224910e-158, 2.16463296e-132, 7.54533758e-047, 1.13797729e-068, 8.33159464e-43, 9.46726154e-09),; (2.41092484e-164, 7.73129397e-167, 2.11823139e-048, 5.05610163e-085, 2.77143736e-43, 5.58993361e-09),; (7.62160014e-168, 4.82099981e-220, 4.26779582e-063, 1.91722780e-096, 4.29568606e-50, 2.41253723e-09)],; dtype=[('0', '<f8'), ('1', '<f8'), ('2', '<f8'), ('3', '<f8'), ('4', '<f8'), ('5', '<f8')]), 'pvals_adj': rec.array([(7.14083067e-209, 2.11688312e-248, 8.16110052e-204, 6.18877997e-184, 9.80213028e-57, 2.99072523e-06),; (3.28264977e-167, 7.87294806e-232, 1.47844579e-149, 1.66418877e-177, 1.65775565e-54, 2.99072523e-06),; (8.42492515e-158, 3.27818164e-229, 3.45171688e-143, 8.10720722e-163, 3.92198448e-53, 2.99072523e-06),; ...,; (1.17665910e-154, 1.11668003e-129, 5.18993470e-044, 8.28782167e-066, 8.59612277e-40, 6.51189806e-06),; (7.46241510e-161, 5.63065592e-164, 1.63911392e-045, 4.17330628e-082, 3.43131660e-40, 4.94349772e-06),; (3.14543438e-164, 9.94813310e-217, 4.80359819e-060, 1.82593826e-093, 8.86414818e-47, 2.99072523e-06)],; dtype=[('0', '<f8'), ('1', '<f8'), ('2', '<f8'), ('3', '<f8'), ('4', '<f8'), ('5', '<f8')]), 'logfoldchanges': rec.array([(nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan),; (nan, nan, nan, nan, nan, nan), ...,; (nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan),; (nan, nan, nan, nan, nan, nan)],; dtype=[('0', '<f4'), ('1', '<f4'), ('2', '<f4'), ('3', '<f4'), ('4', '<f4'), ('5', '<f4')])}",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2338
https://github.com/scverse/scanpy/issues/2339:38,Availability,ERROR,ERROR,38,"sc.tl.leiden(adata,use_weights=False) ERROR; ![image](https://user-images.githubusercontent.com/39158528/192767636-991ed282-cf6c-46be-841f-389007976b16.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2340:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->; ...; `sc.pl.stacked_violin` legend shows the group median by default, How can I show the group means instead? . Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2340
https://github.com/scverse/scanpy/issues/2341:519,Availability,error,error,519,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.leiden(adata); ```. ```pytb; BaseException Traceback (most recent call last); Cell In [15], line 1; ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs); 142 partition_kwargs[resolution_parameter] = resolution; 143 # clustering proper;  144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs); 145 # store output into adata.obs; 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs); 79 if not weights is None:; 80 kwargs[weights] = weights; > 81 partition = partition_type(graph,; 82 initial_membership=initial_membership,; 83 **kwargs); 84 optimiser = Optimiser(); 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartition.init(self, graph, initial_membership, weights, node_sizes, resolution_parameter); 851 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:565,Deployability,install,installing,565,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.leiden(adata); ```. ```pytb; BaseException Traceback (most recent call last); Cell In [15], line 1; ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs); 142 partition_kwargs[resolution_parameter] = resolution; 143 # clustering proper;  144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs); 145 # store output into adata.obs; 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs); 79 if not weights is None:; 80 kwargs[weights] = weights; > 81 partition = partition_type(graph,; 82 initial_membership=initial_membership,; 83 **kwargs); 84 optimiser = Optimiser(); 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartition.init(self, graph, initial_membership, weights, node_sizes, resolution_parameter); 851 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:610,Deployability,install,install,610,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.leiden(adata); ```. ```pytb; BaseException Traceback (most recent call last); Cell In [15], line 1; ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs); 142 partition_kwargs[resolution_parameter] = resolution; 143 # clustering proper;  144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs); 145 # store output into adata.obs; 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs); 79 if not weights is None:; 80 kwargs[weights] = weights; > 81 partition = partition_type(graph,; 82 initial_membership=initial_membership,; 83 **kwargs); 84 optimiser = Optimiser(); 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartition.init(self, graph, initial_membership, weights, node_sizes, resolution_parameter); 851 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:3957,Deployability,update,updated,3957,"else:; 852 # Make sure it is a list; 853 node_sizes = list(node_sizes);  855 self._partition = _c_leiden._new_RBConfigurationVertexPartition(pygraph_t,; 856 initial_membership, weights, node_sizes, resolution_parameter); 857 self._update_internal_membership(). BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; ```. #### Versions. <details>. ```; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 1.1.0; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.9.11; ipykernel 6.16.0; ipython_genutils 0.2.0; ipywidgets 8.0.2; jedi 0.18.1; joblib 1.2.0; jupyter_server 1.19.1; kiwisolver 1.4.4; leidenalg 0.8.10; llvmlite 0.39.1; louvain 0.7.1; matplotlib 3.6.0; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.56.2; numpy 1.23.3; packaging 21.3; pandas 1.5.0; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.31; psutil 5.9.2; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pynndescent 0.5.7; pyparsing 3.0.9; pytz 2022.2.1; scipy 1.9.1; session_info 1.0.0; setuptools 65.4.0; six 1.16.0; sklearn 1.1.2; sphinxcontrib NA; stack_data 0.5.1; statsmodels 0.13.2; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.2; tqdm 4.64.1; traitlets 5.4.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.5; zipp NA; zmq 24.0.1; zoneinfo NA; -----; IPython 8.5.0; jupyter_client 7.3.5; jupyter_core 4.11.1; jupyterlab 3.4.7; notebook 6.4.12; -----; Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) [Clang 13.0.1 ]; macOS-12.6-arm64-arm-64bit; -----; Session information updated at 2022-09-29 11:08; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/pull/2342:34,Performance,load,loader,34,Backport PR #2248: Fix legacy 10x loader when more than one genome exists,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2342
https://github.com/scverse/scanpy/issues/2343:904,Availability,error,error,904,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'); scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False); markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]; markers=list(np.unique(markers_df.melt().value.values)); ```pytb; [Paste the error output produced by the above code here]; ```; AttributeError Traceback (most recent call last); Input In [18], in <cell line: 4>(); 8 adata_st=diopy.input.read_h5(file = path); 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'); ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False); 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]; 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'; #### Versions; 1.9.1; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; AttributeError: module 'scanpy' has no attribute 'logging'; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1542,Testability,log,logging,1542,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'); scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False); markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]; markers=list(np.unique(markers_df.melt().value.values)); ```pytb; [Paste the error output produced by the above code here]; ```; AttributeError Traceback (most recent call last); Input In [18], in <cell line: 4>(); 8 adata_st=diopy.input.read_h5(file = path); 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'); ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False); 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]; 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'; #### Versions; 1.9.1; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; AttributeError: module 'scanpy' has no attribute 'logging'; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1662,Testability,log,logging,1662,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'); scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False); markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]; markers=list(np.unique(markers_df.melt().value.values)); ```pytb; [Paste the error output produced by the above code here]; ```; AttributeError Traceback (most recent call last); Input In [18], in <cell line: 4>(); 8 adata_st=diopy.input.read_h5(file = path); 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'); ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False); 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]; 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'; #### Versions; 1.9.1; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; AttributeError: module 'scanpy' has no attribute 'logging'; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:296,Usability,guid,guide,296,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'); scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False); markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]; markers=list(np.unique(markers_df.melt().value.values)); ```pytb; [Paste the error output produced by the above code here]; ```; AttributeError Traceback (most recent call last); Input In [18], in <cell line: 4>(); 8 adata_st=diopy.input.read_h5(file = path); 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'); ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False); 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]; 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'; #### Versions; 1.9.1; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; AttributeError: module 'scanpy' has no attribute 'logging'; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/pull/2344:68,Performance,load,loading,68,"After @ivirshup's pytables PR (#2064) we started having issues with loading h5 files with scalar datasets, such as those created by CellBender (https://github.com/broadinstitute/CellBender/issues/128). It is currently not an issue for the 10X h5 files for now since they don't have any scalars, however it'd be good to just handle scalars as well as arrays for two reasons, 1) to fix the cellbender file loading problem 2) to fix potential problems we might end up having if 10X h5 format includes scalar datasets. I am not an HDF/h5py/tables person though, so please review carefully :) (although it's a tiny PR) Also let me know what you think, @sjfleming!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/pull/2344:404,Performance,load,loading,404,"After @ivirshup's pytables PR (#2064) we started having issues with loading h5 files with scalar datasets, such as those created by CellBender (https://github.com/broadinstitute/CellBender/issues/128). It is currently not an issue for the 10X h5 files for now since they don't have any scalars, however it'd be good to just handle scalars as well as arrays for two reasons, 1) to fix the cellbender file loading problem 2) to fix potential problems we might end up having if 10X h5 format includes scalar datasets. I am not an HDF/h5py/tables person though, so please review carefully :) (although it's a tiny PR) Also let me know what you think, @sjfleming!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/issues/2345:309,Availability,error,error,309,"#### Problem; File `tissue_positions_list.csv` not found when running `sc.read_visium`; This issue was caused by the file name change by `spaceranger`. . #### Solution; Make a copy of the `outs/spatial/tissue_positions.csv` and name it as `outs/spatial/tissue_positions_list.csv`. #### Problem; The following error messages appeared when running `sc.pl.spatial`:; ```python; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In [4], line 1; ----> 1 sc.pl.spatial(adata, color=adata.var_names.tolist()[0], img_key='hires', scale_factor=None). File scanpy/plotting/_tools/scatterplots.py:1003, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs); 1000 cmap_img = None; 1001 circle_radius = size * scale_factor * spot_size * 0.5; -> 1003 axs = embedding(; 1004 adata,; 1005 basis=basis,; 1006 scale_factor=scale_factor,; 1007 size=circle_radius,; 1008 na_color=na_color,; 1009 show=False,; 1010 save=False,; 1011 **kwargs,; 1012 ); 1013 if not isinstance(axs, list):; 1014 axs = [axs]. File scanpy/plotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 389 # if user did not set alpha, set alpha to 0.7; 390 kwargs['alpha'] = 0.7 if alpha is None else alpha; --> 392 cax = scatter(; 393 coords[:, 0],; 394 coords[:, 1],; 395 marker=""."",; 396 c=color_vector,; 397 rasterized=settings._vector_friendly,; 398 norm=normalize,; 399 **kwargs,; 400 ); 402 # remo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:2205,Deployability,patch,patch,2205,"plotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 389 # if user did not set alpha, set alpha to 0.7; 390 kwargs['alpha'] = 0.7 if alpha is None else alpha; --> 392 cax = scatter(; 393 coords[:, 0],; 394 coords[:, 1],; 395 marker=""."",; 396 c=color_vector,; 397 rasterized=settings._vector_friendly,; 398 norm=normalize,; 399 **kwargs,; 400 ); 402 # remove y and x ticks; 403 ax.set_yticks([]). File scanpy/plotting/_utils.py:1111, in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs); 1105 # You can set `facecolor` with an array for each patch,; 1106 # while you can only set `facecolors` with a value for all.; 1107 if scale_factor != 1.0:; -> 1108 x = x * scale_factor; 1109 y = y * scale_factor; 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'; ```. #### Solution. This issue was caused by non-integer values in `adata.obsm['spatial']` after reading using `sc.read_visium`. Either of the following two solutions works:. 1. `adata.obsm['spatial'] = adata.obsm['spatial'].astype(int)`; 2. Add the following line 1108 - 1110 in `scanpy/plotting/_utils.py`:. ```python; 1107 if scale_factor != 1.0:; 1108 if not isinstance(x[0], int) or not isinstance(y[0], int):; 1109 x = x.astype(int); 1110 y = y.astype(int); 1111 x = x * scale_factor; 1112 y = y * scale_factor; ```. Personally, I suggest the second solution. Also, there is a post talking about not maintaining the spatial module in `scanpy`. . #### Versions; * `scanpy==1.9.1`; * `spaceranger==2.0.0`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:315,Integrability,message,messages,315,"#### Problem; File `tissue_positions_list.csv` not found when running `sc.read_visium`; This issue was caused by the file name change by `spaceranger`. . #### Solution; Make a copy of the `outs/spatial/tissue_positions.csv` and name it as `outs/spatial/tissue_positions_list.csv`. #### Problem; The following error messages appeared when running `sc.pl.spatial`:; ```python; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In [4], line 1; ----> 1 sc.pl.spatial(adata, color=adata.var_names.tolist()[0], img_key='hires', scale_factor=None). File scanpy/plotting/_tools/scatterplots.py:1003, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs); 1000 cmap_img = None; 1001 circle_radius = size * scale_factor * spot_size * 0.5; -> 1003 axs = embedding(; 1004 adata,; 1005 basis=basis,; 1006 scale_factor=scale_factor,; 1007 size=circle_radius,; 1008 na_color=na_color,; 1009 show=False,; 1010 save=False,; 1011 **kwargs,; 1012 ); 1013 if not isinstance(axs, list):; 1014 axs = [axs]. File scanpy/plotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 389 # if user did not set alpha, set alpha to 0.7; 390 kwargs['alpha'] = 0.7 if alpha is None else alpha; --> 392 cax = scatter(; 393 coords[:, 0],; 394 coords[:, 1],; 395 marker=""."",; 396 c=color_vector,; 397 rasterized=settings._vector_friendly,; 398 norm=normalize,; 399 **kwargs,; 400 ); 402 # remo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/pull/2346:109,Availability,error,error,109,"When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python; adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))); sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):; File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>; sc.preprocessing._qc.describe_obs(adata); File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs; proportions = top_segment_proportions(X, percent_top); File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions; raise IndexError(""Positions outside range of features.""); IndexError: Positions outside range of features.; ```; (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:; - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section?; - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:1778,Modifiability,refactor,refactor,1778,"When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python; adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))); sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):; File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>; sc.preprocessing._qc.describe_obs(adata); File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs; proportions = top_segment_proportions(X, percent_top); File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions; raise IndexError(""Positions outside range of features.""); IndexError: Positions outside range of features.; ```; (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:; - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section?; - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2347:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/psf/black: 22.8.0  22.10.0](https://github.com/psf/black/compare/22.8.0...22.10.0); - [github.com/pre-commit/mirrors-autopep8: v1.7.0  v2.0.0](https://github.com/pre-commit/mirrors-autopep8/compare/v1.7.0...v2.0.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2347
https://github.com/scverse/scanpy/issues/2351:44,Availability,error,error,44,"If I used the X_pca_harmony, it gave us the error. ![image](https://user-images.githubusercontent.com/97800939/195247592-f02e1342-5d29-4654-9c59-1ec35dd21913.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2351
https://github.com/scverse/scanpy/issues/2352:2500,Deployability,install,install,2500,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'); Traceback (most recent call last):; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3; from skmisc.loess import loess; File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import; module = self._system_import(name, *args, **kwargs); File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>; from ._loess import (loess, loess_model, loess_inputs, loess_control,; File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import; module = self._system_import(name, *args, **kwargs); ImportError: DLL load failed while importing _loess: ; During handling of the above exception, another exception occurred:; Traceback (most recent call last):; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>; sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'); File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes; return _highly_variable_genes_seurat_v3(; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3; raise ImportError(; ImportError: Please install skmisc package via `pip install --user scikit-misc; ```. #### Versions. <details>; scanpy 1.9.1; [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>; I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2532,Deployability,install,install,2532,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'); Traceback (most recent call last):; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3; from skmisc.loess import loess; File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import; module = self._system_import(name, *args, **kwargs); File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>; from ._loess import (loess, loess_model, loess_inputs, loess_control,; File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import; module = self._system_import(name, *args, **kwargs); ImportError: DLL load failed while importing _loess: ; During handling of the above exception, another exception occurred:; Traceback (most recent call last):; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>; sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'); File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes; return _highly_variable_genes_seurat_v3(; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3; raise ImportError(; ImportError: Please install skmisc package via `pip install --user scikit-misc; ```. #### Versions. <details>; scanpy 1.9.1; [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>; I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1115,Modifiability,plugin,plugins,1115,"] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T; import scvi ; sc.pp.filter_genes(adata, min_cells = 10); sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'); ```. ```pytb; >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'); Traceback (most recent call last):; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3; from skmisc.loess import loess; File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import; module = self._system_import(name, *args, **kwargs); File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>; from ._loess import (loess, loess_model, loess_inputs, loess_control,; File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import; module = self._system_import(name, *args, **kwargs); ImportError: DLL load failed while importing _loess: ; During handling of the above exception, another exception occurred:; Traceback (most recent call last):; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>; sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'); File ""D:\A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1507,Modifiability,plugin,plugins,1507,"v(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T; import scvi ; sc.pp.filter_genes(adata, min_cells = 10); sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'); ```. ```pytb; >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'); Traceback (most recent call last):; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3; from skmisc.loess import loess; File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import; module = self._system_import(name, *args, **kwargs); File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>; from ._loess import (loess, loess_model, loess_inputs, loess_control,; File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import; module = self._system_import(name, *args, **kwargs); ImportError: DLL load failed while importing _loess: ; During handling of the above exception, another exception occurred:; Traceback (most recent call last):; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>; sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'); File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes; return _highly_variable_genes_seurat_v3(; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3; raise ImportError(; ImportError: Please install skmisc package via `pip instal",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1669,Performance,load,load,1669,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'); Traceback (most recent call last):; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3; from skmisc.loess import loess; File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import; module = self._system_import(name, *args, **kwargs); File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>; from ._loess import (loess, loess_model, loess_inputs, loess_control,; File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import; module = self._system_import(name, *args, **kwargs); ImportError: DLL load failed while importing _loess: ; During handling of the above exception, another exception occurred:; Traceback (most recent call last):; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>; sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'); File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes; return _highly_variable_genes_seurat_v3(; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3; raise ImportError(; ImportError: Please install skmisc package via `pip install --user scikit-misc; ```. #### Versions. <details>; scanpy 1.9.1; [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>; I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2633,Testability,log,logging,2633,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'); Traceback (most recent call last):; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3; from skmisc.loess import loess; File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import; module = self._system_import(name, *args, **kwargs); File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>; from ._loess import (loess, loess_model, loess_inputs, loess_control,; File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import; module = self._system_import(name, *args, **kwargs); ImportError: DLL load failed while importing _loess: ; During handling of the above exception, another exception occurred:; Traceback (most recent call last):; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>; sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'); File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes; return _highly_variable_genes_seurat_v3(; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3; raise ImportError(; ImportError: Please install skmisc package via `pip install --user scikit-misc; ```. #### Versions. <details>; scanpy 1.9.1; [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>; I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T; import scvi ; sc.pp.filter_genes(adata, min_cells = 10); sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'); ```. ```pytb; >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'); Traceback (most recent call last):; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3; from skmisc.loess import loess; File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import; module = self._system_import(name, *args, **kwargs); File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>; from ._loess import (loess, loess_model, loess_inputs, loess_control,; File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import; module = self._system_import(name, *args, **kwargs); ImportError: DLL load failed while importing _loess: ; During handling of the above exception, another exception occurred:; Traceback (most recent call last):; File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-inpu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/pull/2353:39,Deployability,integrat,integration,39,"Hi, ; we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!; Lei . <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:63,Deployability,integrat,integrate,63,"Hi, ; we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!; Lei . <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:39,Integrability,integrat,integration,39,"Hi, ; we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!; Lei . <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:63,Integrability,integrat,integrate,63,"Hi, ; we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!; Lei . <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:483,Usability,guid,guidelines,483,"Hi, ; we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!; Lei . <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:514,Usability,guid,guide,514,"Hi, ; we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!; Lei . <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2354:38,Deployability,integrat,integration,38,"Hi,; we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!; Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:62,Deployability,integrat,integrate,62,"Hi,; we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!; Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:38,Integrability,integrat,integration,38,"Hi,; we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!; Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:62,Integrability,integrat,integrate,62,"Hi,; we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!; Lei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2355:38,Deployability,integrat,integration,38,"Hi,; we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:62,Deployability,integrat,integrate,62,"Hi,; we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:38,Integrability,integrat,integration,38,"Hi,; we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:62,Integrability,integrat,integrate,62,"Hi,; we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/issues/2356:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [N] Additional function parameters / changed functionality / changed defaults?; - [N] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [Y] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [N] External tools: Do you know an existing package that should go into `sc.external.*`?; - [N] Other?. <!-- Please describe your wishes below: -->; Hello Scanpy,; As we know, Scanpy can calculate PCs and plot PCA plots by clustering cells with similar PCs around the nearby locations in the PCA space.; ```python; sc.tl.pca(adata, svd_solver='arpack'); sc.pl.pca(adata, color='leiden'); ```; ![image](https://user-images.githubusercontent.com/75048821/196794747-04e88d2d-05e8-4224-91d7-f403b5376e4f.png); Sometimes, we're trying to use PCA plots to show that how similar multiple samples are. For examples, we concatenate multiple scRNA-seq datasets, and do the PCA plot.; ```python; adata_concat = adata1.concatenate(adata2, adata3, adata4, batch_categories=['adata1', 'adata2', 'adata3', 'adata4']); sc.tl.pca(adata_concat, svd_solver='arpack'); sc.pl.pca(adata_concat, color='batch'); ```; We're expecting to see the PCA plots like this (one scRNA-seq dataset, one dot); ![image](https://user-images.githubusercontent.com/75048821/196796252-12c072d1-992e-4056-af09-10168f225a9a.png); but it generates PCA plots like this (every cell has a dot); ![image](https://user-images.githubusercontent.com/75048821/196802697-e751d475-2ac6-4cea-9af5-02340ef6d023.png). **We're wondering whether it is possible to plot a PCA plot for multiple datasets with one single dot representing one scRNA-seq dataset.**. Thanks!; Best,; Yuanjian",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2356
https://github.com/scverse/scanpy/issues/2357:301,Availability,error,error,301,"- [x ] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python; # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ); ```. ```pytb; [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.; using data matrix X directly; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-71-f7d35408db0b> in <module>; ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds); 671 tl.dendrogram; 672 """"""; --> 673 return _rank_genes_groups_plot(; 674 adata,; 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 590 from .._anndata import heatmap; 591 ; --> 592 return heatmap(; 593 adata,; 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:1966,Testability,log,log,1966,"=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds); 671 tl.dendrogram; 672 """"""; --> 673 return _rank_genes_groups_plot(; 674 adata,; 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 590 from .._anndata import heatmap; 591 ; --> 592 return heatmap(; 593 adata,; 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds); 1085 ; 1086 if dendrogram:; -> 1087 dendro_data = _reorder_categories_after_dendrogram(; 1088 adata,; 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories); 2132 """"""; 2133 ; -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby); 2135 ; 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby); 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently.""; 2235 ); -> 2236 dendrogram(adata, groupby, key_added=dendrogram_key); 2237 ; 2238 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.local/lib/python3.8/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2358:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2359:64,Availability,error,error,64,"At the stage of finding neighbors, my jupyter kept showing this error:; <img width=""1103"" alt=""Screen Shot 2022-10-22 at 2 51 46 PM"" src=""https://user-images.githubusercontent.com/99854950/197325988-9a22e635-43df-4461-9d22-81f160fa652b.png"">. the error:; ```; OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; And it killed the kernel entirely. ; ```. I try to make this work by running this in Linux but it got killed again. ; <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:; ```python; def pp(adata):; sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes; sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98); lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02); adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]; adata = adata[adata.obs.pct_counts_mt < 25]; sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI; sc.pp.log1p(adata) #change to log counts; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values; adata.raw = adata #save raw data before processing values and further filtering; adata = adata[:, adata.var.highly_variable] #filter highly variable; sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed; sc.pp.scale(adata, max_value=10) #scale each gene to unit variance; sc.tl.pca(adata, svd_solver=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:247,Availability,error,error,247,"At the stage of finding neighbors, my jupyter kept showing this error:; <img width=""1103"" alt=""Screen Shot 2022-10-22 at 2 51 46 PM"" src=""https://user-images.githubusercontent.com/99854950/197325988-9a22e635-43df-4461-9d22-81f160fa652b.png"">. the error:; ```; OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; And it killed the kernel entirely. ; ```. I try to make this work by running this in Linux but it got killed again. ; <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:; ```python; def pp(adata):; sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes; sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98); lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02); adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]; adata = adata[adata.obs.pct_counts_mt < 25]; sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI; sc.pp.log1p(adata) #change to log counts; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values; adata.raw = adata #save raw data before processing values and further filtering; adata = adata[:, adata.var.highly_variable] #filter highly variable; sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed; sc.pp.scale(adata, max_value=10) #scale each gene to unit variance; sc.tl.pca(adata, svd_solver=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:4627,Deployability,update,updated,4627,".0.1; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; deprecate 0.3.2; dill 0.3.4; docrep 0.3.2; entrypoints 0.4; etils 0.8.0; flax 0.6.1; fsspec 2022.7.1; google NA; graphviz 0.20; h5py 3.7.0; idna 3.4; igraph 0.10.2; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jax 0.3.23; jaxlib 0.3.22; jedi 0.18.1; jinja2 2.11.3; jmespath 0.10.0; joblib 1.1.1; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.8.10; llvmlite 0.39.1; louvain 0.8.0; lz4 3.1.3; markupsafe 2.0.1; matplotlib 3.5.2; matplotlib_inline 0.1.6; ml_collections NA; mpl_toolkits NA; msgpack 1.0.3; mudata 0.2.0; multipledispatch 0.6.0; natsort 8.1.0; nbinom_ufunc NA; numba 0.56.3; numexpr 2.8.3; numpy 1.22.4; numpyro 0.10.1; opt_einsum v3.3.0; optax 0.1.3; packaging 21.3; pandas 1.4.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.9.0; prompt_toolkit 3.0.20; psutil 5.9.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.9; pyro 1.8.2; pytorch_lightning 1.7.7; pytz 2022.1; regex 2.5.116; requests 2.28.1; rich NA; scipy 1.7.3; scvi 0.18.0; session_info 1.0.0; setuptools 63.4.1; simplejson 3.17.6; six 1.16.0; sklearn 1.1.2; snappy NA; socks 1.7.1; sphinxcontrib NA; storemagic NA; tblib 1.7.0; tensorboard 2.9.1; texttable 1.6.4; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.2; torch 1.12.1; torchmetrics 0.10.0; torchvision 0.13.1; tornado 6.1; tqdm 4.64.1; traitlets 5.1.1; tree 0.1.7; typing_extensions NA; urllib3 1.26.12; wcwidth 0.2.5; wrapt 1.14.1; yaml 6.0; zipp NA; zmq 23.2.0; zope NA; -----; IPython 7.31.1; jupyter_client 7.3.4; jupyter_core 4.11.1; jupyterlab 3.4.4; notebook 6.4.12; -----; Python 3.9.12 (main, Jun 1 2022, 06:36:29) [Clang 12.0.0 ]; macOS-10.16-x86_64-i386-64bit; -----; Session information updated at 2022-10-22 15:12. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:291,Integrability,rout,routine,291,"At the stage of finding neighbors, my jupyter kept showing this error:; <img width=""1103"" alt=""Screen Shot 2022-10-22 at 2 51 46 PM"" src=""https://user-images.githubusercontent.com/99854950/197325988-9a22e635-43df-4461-9d22-81f160fa652b.png"">. the error:; ```; OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.; And it killed the kernel entirely. ; ```. I try to make this work by running this in Linux but it got killed again. ; <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:; ```python; def pp(adata):; sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes; sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98); lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02); adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]; adata = adata[adata.obs.pct_counts_mt < 25]; sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI; sc.pp.log1p(adata) #change to log counts; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values; adata.raw = adata #save raw data before processing values and further filtering; adata = adata[:, adata.var.highly_variable] #filter highly variable; sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed; sc.pp.scale(adata, max_value=10) #scale each gene to unit variance; sc.tl.pca(adata, svd_solver=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:4347,Integrability,wrap,wrapt,4347,".0.1; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; deprecate 0.3.2; dill 0.3.4; docrep 0.3.2; entrypoints 0.4; etils 0.8.0; flax 0.6.1; fsspec 2022.7.1; google NA; graphviz 0.20; h5py 3.7.0; idna 3.4; igraph 0.10.2; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jax 0.3.23; jaxlib 0.3.22; jedi 0.18.1; jinja2 2.11.3; jmespath 0.10.0; joblib 1.1.1; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.8.10; llvmlite 0.39.1; louvain 0.8.0; lz4 3.1.3; markupsafe 2.0.1; matplotlib 3.5.2; matplotlib_inline 0.1.6; ml_collections NA; mpl_toolkits NA; msgpack 1.0.3; mudata 0.2.0; multipledispatch 0.6.0; natsort 8.1.0; nbinom_ufunc NA; numba 0.56.3; numexpr 2.8.3; numpy 1.22.4; numpyro 0.10.1; opt_einsum v3.3.0; optax 0.1.3; packaging 21.3; pandas 1.4.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.9.0; prompt_toolkit 3.0.20; psutil 5.9.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.9; pyro 1.8.2; pytorch_lightning 1.7.7; pytz 2022.1; regex 2.5.116; requests 2.28.1; rich NA; scipy 1.7.3; scvi 0.18.0; session_info 1.0.0; setuptools 63.4.1; simplejson 3.17.6; six 1.16.0; sklearn 1.1.2; snappy NA; socks 1.7.1; sphinxcontrib NA; storemagic NA; tblib 1.7.0; tensorboard 2.9.1; texttable 1.6.4; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.2; torch 1.12.1; torchmetrics 0.10.0; torchvision 0.13.1; tornado 6.1; tqdm 4.64.1; traitlets 5.1.1; tree 0.1.7; typing_extensions NA; urllib3 1.26.12; wcwidth 0.2.5; wrapt 1.14.1; yaml 6.0; zipp NA; zmq 23.2.0; zope NA; -----; IPython 7.31.1; jupyter_client 7.3.4; jupyter_core 4.11.1; jupyterlab 3.4.4; notebook 6.4.12; -----; Python 3.9.12 (main, Jun 1 2022, 06:36:29) [Clang 12.0.0 ]; macOS-10.16-x86_64-i386-64bit; -----; Session information updated at 2022-10-22 15:12. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1736,Modifiability,variab,variable,1736,", min_genes=200) #get rid of cells with fewer than 200 genes; sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98); lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02); adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]; adata = adata[adata.obs.pct_counts_mt < 25]; sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI; sc.pp.log1p(adata) #change to log counts; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values; adata.raw = adata #save raw data before processing values and further filtering; adata = adata[:, adata.var.highly_variable] #filter highly variable; sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed; sc.pp.scale(adata, max_value=10) #scale each gene to unit variance; sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20); sc.tl.umap(adata); return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True); adata = pp(adata); ```. My computer is Mac book Intel i5. Thanks!; #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; OpenSSL 22.0.0; PIL 9.2.0; PyObjCTools NA; absl NA; appnope 0.1.2; astunparse 1.6.3; attr 21.4.0; backcall 0.2.0; bcrypt 3.2.0; beta_ufunc NA; binom_ufunc NA; boto3 1.24.28; botocore 1.27.28; bottleneck 1.3.5; brotli NA; certifi 2022.09.24; cffi 1.15.1; chardet 4.0.0; charset_normalizer 2.0.4; chex 0.1.5; cloudpickle 2.0.0; colorama 0.4.5; contextlib2 NA; cryptography 37.0.1; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:2485,Performance,bottleneck,bottleneck,2485,"; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values; adata.raw = adata #save raw data before processing values and further filtering; adata = adata[:, adata.var.highly_variable] #filter highly variable; sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed; sc.pp.scale(adata, max_value=10) #scale each gene to unit variance; sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20); sc.tl.umap(adata); return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True); adata = pp(adata); ```. My computer is Mac book Intel i5. Thanks!; #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; OpenSSL 22.0.0; PIL 9.2.0; PyObjCTools NA; absl NA; appnope 0.1.2; astunparse 1.6.3; attr 21.4.0; backcall 0.2.0; bcrypt 3.2.0; beta_ufunc NA; binom_ufunc NA; boto3 1.24.28; botocore 1.27.28; bottleneck 1.3.5; brotli NA; certifi 2022.09.24; cffi 1.15.1; chardet 4.0.0; charset_normalizer 2.0.4; chex 0.1.5; cloudpickle 2.0.0; colorama 0.4.5; contextlib2 NA; cryptography 37.0.1; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; deprecate 0.3.2; dill 0.3.4; docrep 0.3.2; entrypoints 0.4; etils 0.8.0; flax 0.6.1; fsspec 2022.7.1; google NA; graphviz 0.20; h5py 3.7.0; idna 3.4; igraph 0.10.2; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jax 0.3.23; jaxlib 0.3.22; jedi 0.18.1; jinja2 2.11.3; jmespath 0.10.0; joblib 1.1.1; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.8.10; llvmlite 0.39.1; louvain 0.8.0; lz4 3.1.3; markupsafe 2.0.1; matplotlib 3.5.2; matplotlib_inline 0.1.6; ml_collections NA; mpl_toolkits NA; msgpack 1.0.3; mudata 0.2.0; multipledispatch 0.6.0; natsort 8.1.0; nbinom_ufunc NA; numba 0.56.3; numexpr 2.8.3; numpy 1.22.4; numpyro 0.10.1; opt_einsum v3.3.0; optax 0.1.3; p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1479,Testability,log,log,1479,"; <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:; ```python; def pp(adata):; sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes; sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98); lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02); adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]; adata = adata[adata.obs.pct_counts_mt < 25]; sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI; sc.pp.log1p(adata) #change to log counts; sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values; adata.raw = adata #save raw data before processing values and further filtering; adata = adata[:, adata.var.highly_variable] #filter highly variable; sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed; sc.pp.scale(adata, max_value=10) #scale each gene to unit variance; sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20); sc.tl.umap(adata); return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True); adata = pp(adata); ```. My computer is Mac book Intel i5. Thanks!; #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; OpenSSL 22.0.0; PIL 9.2.0; PyObjCTools NA; absl NA; appnope 0.1.2; astunparse 1.6.3; attr 21.4.0; backcall 0.2.0; bcrypt 3.2.0; beta_ufunc NA; binom_ufunc NA; boto3 1.24.28; botocore",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:3984,Usability,simpl,simplejson,3984,".0.1; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; deprecate 0.3.2; dill 0.3.4; docrep 0.3.2; entrypoints 0.4; etils 0.8.0; flax 0.6.1; fsspec 2022.7.1; google NA; graphviz 0.20; h5py 3.7.0; idna 3.4; igraph 0.10.2; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jax 0.3.23; jaxlib 0.3.22; jedi 0.18.1; jinja2 2.11.3; jmespath 0.10.0; joblib 1.1.1; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.8.10; llvmlite 0.39.1; louvain 0.8.0; lz4 3.1.3; markupsafe 2.0.1; matplotlib 3.5.2; matplotlib_inline 0.1.6; ml_collections NA; mpl_toolkits NA; msgpack 1.0.3; mudata 0.2.0; multipledispatch 0.6.0; natsort 8.1.0; nbinom_ufunc NA; numba 0.56.3; numexpr 2.8.3; numpy 1.22.4; numpyro 0.10.1; opt_einsum v3.3.0; optax 0.1.3; packaging 21.3; pandas 1.4.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.9.0; prompt_toolkit 3.0.20; psutil 5.9.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.9; pyro 1.8.2; pytorch_lightning 1.7.7; pytz 2022.1; regex 2.5.116; requests 2.28.1; rich NA; scipy 1.7.3; scvi 0.18.0; session_info 1.0.0; setuptools 63.4.1; simplejson 3.17.6; six 1.16.0; sklearn 1.1.2; snappy NA; socks 1.7.1; sphinxcontrib NA; storemagic NA; tblib 1.7.0; tensorboard 2.9.1; texttable 1.6.4; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.2; torch 1.12.1; torchmetrics 0.10.0; torchvision 0.13.1; tornado 6.1; tqdm 4.64.1; traitlets 5.1.1; tree 0.1.7; typing_extensions NA; urllib3 1.26.12; wcwidth 0.2.5; wrapt 1.14.1; yaml 6.0; zipp NA; zmq 23.2.0; zope NA; -----; IPython 7.31.1; jupyter_client 7.3.4; jupyter_core 4.11.1; jupyterlab 3.4.4; notebook 6.4.12; -----; Python 3.9.12 (main, Jun 1 2022, 06:36:29) [Clang 12.0.0 ]; macOS-10.16-x86_64-i386-64bit; -----; Session information updated at 2022-10-22 15:12. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2361:51,Availability,error,error,51,"Is it because I have too many cells? But no memory error is reported. ```pycon; >>> adata; AnnData object with n_obs  n_vars = 1493240  4489; obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'; var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'brain_area_colors', 'hvg', 'pca'; obsm: 'X_pca'; varm: 'PCs'; ```. ```python; topPC = 40; n_neigbor = 15; resolution = 0.3; sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC); ```. ```pytb; computing neighbors; using 'X_pca' with n_pcs = 40; Segmentation fault (core dumped); ### error file: core.212911; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.4.0; anndata 0.7.8; asciitree NA; attr 21.2.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; dask 2021.11.1; dateutil 2.8.0; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; encodings NA; entrypoints 0.3; fasteners NA; fsspec 2021.11.0; genericpath NA; h5py 3.4.0; idna 3.1; igraph 0.9.8; ipykernel 6.5.0; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.3; joblib 1.1.0; jsonschema 4.2.1; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.36.0; louvain 0.7.0; markupsafe 2.0.1; matplotlib 3.4.3; mpl_toolkits NA; natsort 8.0.0; nbformat 5.1.3; nbinom_ufunc NA; ntpath NA; numba 0.53.1; numcodecs 0.9.1; numexpr 2.7.3; numpy 1.21.4; opcode NA; packaging 21.0; pandas 1.3.4; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; posixpath NA; prometheus_client NA; prompt_toolkit 3.0.22; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pyarrow 9.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydoc_data NA; pyexpat NA; pygments 2.10.0; pyparsing 3.0.6; py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:619,Availability,fault,fault,619,"Is it because I have too many cells? But no memory error is reported. ```pycon; >>> adata; AnnData object with n_obs  n_vars = 1493240  4489; obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'; var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'brain_area_colors', 'hvg', 'pca'; obsm: 'X_pca'; varm: 'PCs'; ```. ```python; topPC = 40; n_neigbor = 15; resolution = 0.3; sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC); ```. ```pytb; computing neighbors; using 'X_pca' with n_pcs = 40; Segmentation fault (core dumped); ### error file: core.212911; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.4.0; anndata 0.7.8; asciitree NA; attr 21.2.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; dask 2021.11.1; dateutil 2.8.0; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; encodings NA; entrypoints 0.3; fasteners NA; fsspec 2021.11.0; genericpath NA; h5py 3.4.0; idna 3.1; igraph 0.9.8; ipykernel 6.5.0; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.3; joblib 1.1.0; jsonschema 4.2.1; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.36.0; louvain 0.7.0; markupsafe 2.0.1; matplotlib 3.4.3; mpl_toolkits NA; natsort 8.0.0; nbformat 5.1.3; nbinom_ufunc NA; ntpath NA; numba 0.53.1; numcodecs 0.9.1; numexpr 2.7.3; numpy 1.21.4; opcode NA; packaging 21.0; pandas 1.3.4; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; posixpath NA; prometheus_client NA; prompt_toolkit 3.0.22; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pyarrow 9.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydoc_data NA; pyexpat NA; pygments 2.10.0; pyparsing 3.0.6; py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:644,Availability,error,error,644,"Is it because I have too many cells? But no memory error is reported. ```pycon; >>> adata; AnnData object with n_obs  n_vars = 1493240  4489; obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'; var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'brain_area_colors', 'hvg', 'pca'; obsm: 'X_pca'; varm: 'PCs'; ```. ```python; topPC = 40; n_neigbor = 15; resolution = 0.3; sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC); ```. ```pytb; computing neighbors; using 'X_pca' with n_pcs = 40; Segmentation fault (core dumped); ### error file: core.212911; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.4.0; anndata 0.7.8; asciitree NA; attr 21.2.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; dask 2021.11.1; dateutil 2.8.0; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; encodings NA; entrypoints 0.3; fasteners NA; fsspec 2021.11.0; genericpath NA; h5py 3.4.0; idna 3.1; igraph 0.9.8; ipykernel 6.5.0; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.3; joblib 1.1.0; jsonschema 4.2.1; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.36.0; louvain 0.7.0; markupsafe 2.0.1; matplotlib 3.4.3; mpl_toolkits NA; natsort 8.0.0; nbformat 5.1.3; nbinom_ufunc NA; ntpath NA; numba 0.53.1; numcodecs 0.9.1; numexpr 2.7.3; numpy 1.21.4; opcode NA; packaging 21.0; pandas 1.3.4; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; posixpath NA; prometheus_client NA; prompt_toolkit 3.0.22; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pyarrow 9.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydoc_data NA; pyexpat NA; pygments 2.10.0; pyparsing 3.0.6; py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:2728,Deployability,update,updated,2728,"---; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.4.0; anndata 0.7.8; asciitree NA; attr 21.2.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; dask 2021.11.1; dateutil 2.8.0; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; encodings NA; entrypoints 0.3; fasteners NA; fsspec 2021.11.0; genericpath NA; h5py 3.4.0; idna 3.1; igraph 0.9.8; ipykernel 6.5.0; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.3; joblib 1.1.0; jsonschema 4.2.1; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.36.0; louvain 0.7.0; markupsafe 2.0.1; matplotlib 3.4.3; mpl_toolkits NA; natsort 8.0.0; nbformat 5.1.3; nbinom_ufunc NA; ntpath NA; numba 0.53.1; numcodecs 0.9.1; numexpr 2.7.3; numpy 1.21.4; opcode NA; packaging 21.0; pandas 1.3.4; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; posixpath NA; prometheus_client NA; prompt_toolkit 3.0.22; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pyarrow 9.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydoc_data NA; pyexpat NA; pygments 2.10.0; pyparsing 3.0.6; pyrsistent NA; pytz 2021.3; scanpy 1.8.2; scipy 1.7.2; seaborn 0.11.2; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 1.0.1; sphinxcontrib NA; sre_compile NA; sre_constants NA; sre_parse NA; statsmodels 0.13.1; tables 3.6.1; terminado 0.12.1; texttable 1.6.4; threadpoolctl 3.0.0; tlz 0.11.2; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; xmlrpc NA; yaml 6.0; zarr 2.10.2; zmq 22.3.0; -----; IPython 7.29.0; jupyter_client 7.0.6; jupyter_core 4.9.1; notebook 6.4.5; -----; Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]; Linux-4.18.0-80.7.1.el8_0.x86_64-x86_64-with-glibc2.17; 224 logical CPU cores, x86_64; -----; Session information updated at 2022-10-24 15:07. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:969,Performance,concurren,concurrent,969,"Is it because I have too many cells? But no memory error is reported. ```pycon; >>> adata; AnnData object with n_obs  n_vars = 1493240  4489; obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'; var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'brain_area_colors', 'hvg', 'pca'; obsm: 'X_pca'; varm: 'PCs'; ```. ```python; topPC = 40; n_neigbor = 15; resolution = 0.3; sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC); ```. ```pytb; computing neighbors; using 'X_pca' with n_pcs = 40; Segmentation fault (core dumped); ### error file: core.212911; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.4.0; anndata 0.7.8; asciitree NA; attr 21.2.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; dask 2021.11.1; dateutil 2.8.0; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; encodings NA; entrypoints 0.3; fasteners NA; fsspec 2021.11.0; genericpath NA; h5py 3.4.0; idna 3.1; igraph 0.9.8; ipykernel 6.5.0; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.3; joblib 1.1.0; jsonschema 4.2.1; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.36.0; louvain 0.7.0; markupsafe 2.0.1; matplotlib 3.4.3; mpl_toolkits NA; natsort 8.0.0; nbformat 5.1.3; nbinom_ufunc NA; ntpath NA; numba 0.53.1; numcodecs 0.9.1; numexpr 2.7.3; numpy 1.21.4; opcode NA; packaging 21.0; pandas 1.3.4; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; posixpath NA; prometheus_client NA; prompt_toolkit 3.0.22; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pyarrow 9.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydoc_data NA; pyexpat NA; pygments 2.10.0; pyparsing 3.0.6; py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:2674,Testability,log,logical,2674,"---; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.4.0; anndata 0.7.8; asciitree NA; attr 21.2.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; dask 2021.11.1; dateutil 2.8.0; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; encodings NA; entrypoints 0.3; fasteners NA; fsspec 2021.11.0; genericpath NA; h5py 3.4.0; idna 3.1; igraph 0.9.8; ipykernel 6.5.0; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.3; joblib 1.1.0; jsonschema 4.2.1; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.36.0; louvain 0.7.0; markupsafe 2.0.1; matplotlib 3.4.3; mpl_toolkits NA; natsort 8.0.0; nbformat 5.1.3; nbinom_ufunc NA; ntpath NA; numba 0.53.1; numcodecs 0.9.1; numexpr 2.7.3; numpy 1.21.4; opcode NA; packaging 21.0; pandas 1.3.4; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; posixpath NA; prometheus_client NA; prompt_toolkit 3.0.22; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pyarrow 9.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydoc_data NA; pyexpat NA; pygments 2.10.0; pyparsing 3.0.6; pyrsistent NA; pytz 2021.3; scanpy 1.8.2; scipy 1.7.2; seaborn 0.11.2; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 1.0.1; sphinxcontrib NA; sre_compile NA; sre_constants NA; sre_parse NA; statsmodels 0.13.1; tables 3.6.1; terminado 0.12.1; texttable 1.6.4; threadpoolctl 3.0.0; tlz 0.11.2; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; xmlrpc NA; yaml 6.0; zarr 2.10.2; zmq 22.3.0; -----; IPython 7.29.0; jupyter_client 7.0.6; jupyter_core 4.9.1; notebook 6.4.5; -----; Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]; Linux-4.18.0-80.7.1.el8_0.x86_64-x86_64-with-glibc2.17; 224 logical CPU cores, x86_64; -----; Session information updated at 2022-10-24 15:07. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2362:64,Availability,avail,available,64,"Hi!. I have tried using the tutorial for basic spatial analysis available in the docs.; Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```; sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",; groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],; alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only.; values = values.replace(values.categories.difference(groups), np.nan); ```; The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2364:472,Availability,down,download,472,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Data location: ; celltypist_adata can be found here under ""download"": https://www.celltypist.org/#video; hachoen_adata download: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE178341. ### Minimal code sample. ```python; # Your code here; celltypist_adata = sc.read_h5ad('/random-path/celltypist_allcells_raw.h5ad'); celltypist_myeloid_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']; celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'); hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']; hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'; celltypist_myeloid_adata.obs['dataset'] = 'celltypist'; combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-25-5f4cc5c2e544> in <module>; 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'; 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'; ----> 3 combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='datas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:532,Availability,down,download,532,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Data location: ; celltypist_adata can be found here under ""download"": https://www.celltypist.org/#video; hachoen_adata download: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE178341. ### Minimal code sample. ```python; # Your code here; celltypist_adata = sc.read_h5ad('/random-path/celltypist_allcells_raw.h5ad'); celltypist_myeloid_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']; celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'); hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']; hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'; celltypist_myeloid_adata.obs['dataset'] = 'celltypist'; combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-25-5f4cc5c2e544> in <module>; 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'; 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'; ----> 3 combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='datas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4015,Availability,toler,tolerance,4015,".0); 524 ; 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):; --> 526 dfs = [df.reindex(index=new_index) for df in dfs]; 527 # New dataframe with all shared data; 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 322 @wraps(func); 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 324 return func(*args, **kwargs); 325 ; 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4770 kwargs.pop(""axis"", None); 4771 kwargs.pop(""labels"", None); -> 4772 return super().reindex(**kwargs); 4773 ; 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4817 # perform the reindex on the axes; 4818 return self._reindex_axes(; -> 4819 axes, level, limit, tolerance, method, fill_value, copy; 4820 ).__finalize__(self, method=""reindex""); 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4596 if index is not None:; 4597 frame = frame._reindex_index(; -> 4598 index, method, copy, level, fill_value, limit, tolerance; 4599 ); 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4618 copy=copy,; 4619 fill_value=fill_value,; -> 4620 allow_dups=False,; 4621 ); 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4887 fill_value=fill_value,; 4888 allow_dups=allow_dups,; -> 4889 copy=copy,; 4890 ); 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, inde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4205,Availability,toler,tolerance,4205,"(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 322 @wraps(func); 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 324 return func(*args, **kwargs); 325 ; 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4770 kwargs.pop(""axis"", None); 4771 kwargs.pop(""labels"", None); -> 4772 return super().reindex(**kwargs); 4773 ; 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4817 # perform the reindex on the axes; 4818 return self._reindex_axes(; -> 4819 axes, level, limit, tolerance, method, fill_value, copy; 4820 ).__finalize__(self, method=""reindex""); 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4596 if index is not None:; 4597 frame = frame._reindex_index(; -> 4598 index, method, copy, level, fill_value, limit, tolerance; 4599 ); 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4618 copy=copy,; 4619 fill_value=fill_value,; -> 4620 allow_dups=False,; 4621 ); 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4887 fill_value=fill_value,; 4888 allow_dups=allow_dups,; -> 4889 copy=copy,; 4890 ); 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 668 # some axes don't allow reindexing with dups; 669 if not allow_dups:; --> 670 self.axes[axis]._validate_can_reindex(indexer); 671 ; 672 if ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4362,Availability,toler,tolerance,4362,"(*args, **kwargs); 322 @wraps(func); 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 324 return func(*args, **kwargs); 325 ; 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4770 kwargs.pop(""axis"", None); 4771 kwargs.pop(""labels"", None); -> 4772 return super().reindex(**kwargs); 4773 ; 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4817 # perform the reindex on the axes; 4818 return self._reindex_axes(; -> 4819 axes, level, limit, tolerance, method, fill_value, copy; 4820 ).__finalize__(self, method=""reindex""); 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4596 if index is not None:; 4597 frame = frame._reindex_index(; -> 4598 index, method, copy, level, fill_value, limit, tolerance; 4599 ); 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4618 copy=copy,; 4619 fill_value=fill_value,; -> 4620 allow_dups=False,; 4621 ); 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4887 fill_value=fill_value,; 4888 allow_dups=allow_dups,; -> 4889 copy=copy,; 4890 ); 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 668 # some axes don't allow reindexing with dups; 669 if not allow_dups:; --> 670 self.axes[axis]._validate_can_reindex(indexer); 671 ; 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4521,Availability,toler,tolerance,4521,"local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4770 kwargs.pop(""axis"", None); 4771 kwargs.pop(""labels"", None); -> 4772 return super().reindex(**kwargs); 4773 ; 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4817 # perform the reindex on the axes; 4818 return self._reindex_axes(; -> 4819 axes, level, limit, tolerance, method, fill_value, copy; 4820 ).__finalize__(self, method=""reindex""); 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4596 if index is not None:; 4597 frame = frame._reindex_index(; -> 4598 index, method, copy, level, fill_value, limit, tolerance; 4599 ); 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4618 copy=copy,; 4619 fill_value=fill_value,; -> 4620 allow_dups=False,; 4621 ); 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4887 fill_value=fill_value,; 4888 allow_dups=allow_dups,; -> 4889 copy=copy,; 4890 ); 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 668 # some axes don't allow reindexing with dups; 669 if not allow_dups:; --> 670 self.axes[axis]._validate_can_reindex(indexer); 671 ; 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer); 3783 # trying to reindex on an axis with duplicates; 3784 if not self._index_as_unique and len(indexer):; -> 3785 raise ValueError(""cannot reindex from a duplicate axis""); 3786 ; 37",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:6933,Deployability,update,updated,6933,".py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 668 # some axes don't allow reindexing with dups; 669 if not allow_dups:; --> 670 self.axes[axis]._validate_can_reindex(indexer); 671 ; 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer); 3783 # trying to reindex on an axis with duplicates; 3784 if not self._index_as_unique and len(indexer):; -> 3785 raise ValueError(""cannot reindex from a duplicate axis""); 3786 ; 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.9.1; -----; PIL 7.2.0; backcall 0.1.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.0; cloudpickle 1.3.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.1; dask 2.13.0; dateutil 2.8.1; decorator 4.4.2; google NA; h5py 2.10.0; igraph 0.9.7; ipykernel 5.1.4; ipython_genutils 0.2.0; jedi 0.15.2; joblib 0.17.0; kiwisolver 1.1.0; leidenalg 0.8.8; llvmlite 0.39.1; louvain 0.7.0; matplotlib 3.5.3; mpl_toolkits NA; natsort 7.0.1; nbinom_ufunc NA; numba 0.56.2; numexpr 2.7.3; numpy 1.21.6; packaging 20.3; pandas 1.3.4; parso 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.4; psutil 5.7.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.6; pyteomics NA; pytz 2019.3; scipy 1.7.1; session_info 1.0.0; setuptools_scm NA; six 1.14.0; sklearn 1.0.2; sphinxcontrib NA; storemagic NA; tblib 1.6.0; texttable 1.6.3; threadpoolctl 2.1.0; tlz 0.10.1; toolz 0.10.0; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; wcwidth NA; yaml 5.3.1; zipp NA; zmq 17.1.2; -----; IPython 7.13.0; jupyter_client 6.1.2; jupyter_core 4.6.3; jupyterlab 1.2.6; notebook 6.0.3; -----; Python 3.7.3 (default, Mar 27 2019, 22:11:17) [GCC 7.3.0]; Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-centos-7.6.1810-Core; -----; Session information updated at 2022-10-25 16:14. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3331,Integrability,wrap,wrapper,3331,", uns_merge, label, keys, index_unique, fill_value, pairwise); 813 # Annotation for other axis; 814 alt_annot = merge_dataframes(; --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge; 816 ); 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy); 524 ; 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):; --> 526 dfs = [df.reindex(index=new_index) for df in dfs]; 527 # New dataframe with all shared data; 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0); 524 ; 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):; --> 526 dfs = [df.reindex(index=new_index) for df in dfs]; 527 # New dataframe with all shared data; 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 322 @wraps(func); 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 324 return func(*args, **kwargs); 325 ; 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4770 kwargs.pop(""axis"", None); 4771 kwargs.pop(""labels"", None); -> 4772 return super().reindex(**kwargs); 4773 ; 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4817 # perform the reindex on the axes; 4818 return self._reindex_axes(; -> 4819 axes, level, limit, tolerance, method, fill_value, copy; 4820 ).__finalize__(self, method=""reindex""); 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4596 if index is not None:; 4597 frame = frame._reindex_index(; -> 4598 index, method, copy, level, fill_value, limit, tolerance; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3362,Integrability,wrap,wraps,3362,", uns_merge, label, keys, index_unique, fill_value, pairwise); 813 # Annotation for other axis; 814 alt_annot = merge_dataframes(; --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge; 816 ); 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy); 524 ; 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):; --> 526 dfs = [df.reindex(index=new_index) for df in dfs]; 527 # New dataframe with all shared data; 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0); 524 ; 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):; --> 526 dfs = [df.reindex(index=new_index) for df in dfs]; 527 # New dataframe with all shared data; 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 322 @wraps(func); 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 324 return func(*args, **kwargs); 325 ; 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4770 kwargs.pop(""axis"", None); 4771 kwargs.pop(""labels"", None); -> 4772 return super().reindex(**kwargs); 4773 ; 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4817 # perform the reindex on the axes; 4818 return self._reindex_axes(; -> 4819 axes, level, limit, tolerance, method, fill_value, copy; 4820 ).__finalize__(self, method=""reindex""); 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4596 if index is not None:; 4597 frame = frame._reindex_index(; -> 4598 index, method, copy, level, fill_value, limit, tolerance; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3383,Integrability,wrap,wrapper,3383,", uns_merge, label, keys, index_unique, fill_value, pairwise); 813 # Annotation for other axis; 814 alt_annot = merge_dataframes(; --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge; 816 ); 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy); 524 ; 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):; --> 526 dfs = [df.reindex(index=new_index) for df in dfs]; 527 # New dataframe with all shared data; 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0); 524 ; 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):; --> 526 dfs = [df.reindex(index=new_index) for df in dfs]; 527 # New dataframe with all shared data; 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 322 @wraps(func); 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 324 return func(*args, **kwargs); 325 ; 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4770 kwargs.pop(""axis"", None); 4771 kwargs.pop(""labels"", None); -> 4772 return super().reindex(**kwargs); 4773 ; 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4817 # perform the reindex on the axes; 4818 return self._reindex_axes(; -> 4819 axes, level, limit, tolerance, method, fill_value, copy; 4820 ).__finalize__(self, method=""reindex""); 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4596 if index is not None:; 4597 frame = frame._reindex_index(; -> 4598 index, method, copy, level, fill_value, limit, tolerance; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3921,Performance,perform,perform,3921,"index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0); 524 ; 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):; --> 526 dfs = [df.reindex(index=new_index) for df in dfs]; 527 # New dataframe with all shared data; 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 322 @wraps(func); 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:; --> 324 return func(*args, **kwargs); 325 ; 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs); 4770 kwargs.pop(""axis"", None); 4771 kwargs.pop(""labels"", None); -> 4772 return super().reindex(**kwargs); 4773 ; 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs); 4817 # perform the reindex on the axes; 4818 return self._reindex_axes(; -> 4819 axes, level, limit, tolerance, method, fill_value, copy; 4820 ).__finalize__(self, method=""reindex""); 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy); 4596 if index is not None:; 4597 frame = frame._reindex_index(; -> 4598 index, method, copy, level, fill_value, limit, tolerance; 4599 ); 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance); 4618 copy=copy,; 4619 fill_value=fill_value,; -> 4620 allow_dups=False,; 4621 ); 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups); 4887 fill_value=fill_value,; 4888 allow_dups=allow_dups,; -> 4889 copy=copy,; 4890 ); 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5731,Performance,bottleneck,bottleneck,5731,"ers, fill_value, copy, allow_dups); 4887 fill_value=fill_value,; 4888 allow_dups=allow_dups,; -> 4889 copy=copy,; 4890 ); 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice); 668 # some axes don't allow reindexing with dups; 669 if not allow_dups:; --> 670 self.axes[axis]._validate_can_reindex(indexer); 671 ; 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer); 3783 # trying to reindex on an axis with duplicates; 3784 if not self._index_as_unique and len(indexer):; -> 3785 raise ValueError(""cannot reindex from a duplicate axis""); 3786 ; 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.9.1; -----; PIL 7.2.0; backcall 0.1.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.0; cloudpickle 1.3.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.1; dask 2.13.0; dateutil 2.8.1; decorator 4.4.2; google NA; h5py 2.10.0; igraph 0.9.7; ipykernel 5.1.4; ipython_genutils 0.2.0; jedi 0.15.2; joblib 0.17.0; kiwisolver 1.1.0; leidenalg 0.8.8; llvmlite 0.39.1; louvain 0.7.0; matplotlib 3.5.3; mpl_toolkits NA; natsort 7.0.1; nbinom_ufunc NA; numba 0.56.2; numexpr 2.7.3; numpy 1.21.6; packaging 20.3; pandas 1.3.4; parso 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.4; psutil 5.7.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.6; pyteomics NA; pytz 2019.3; scipy 1.7.1; session_info 1.0.0; setuptools_scm NA; six 1.14.0; sklearn 1.0.2; sphinxcontrib NA; storemagic NA; tblib 1.6.0; texttable 1.6.3; threadpoolctl 2.1.0; tlz 0.10.1; toolz 0.10.0; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; wcwidth NA; yaml 5.3.1; zipp NA; zmq 17.1.2; -----; IPython 7.13.0; jupyter_client 6.1.2; ju",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:256,Usability,guid,guide,256,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Data location: ; celltypist_adata can be found here under ""download"": https://www.celltypist.org/#video; hachoen_adata download: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE178341. ### Minimal code sample. ```python; # Your code here; celltypist_adata = sc.read_h5ad('/random-path/celltypist_allcells_raw.h5ad'); celltypist_myeloid_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']; celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'); hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']; hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'; celltypist_myeloid_adata.obs['dataset'] = 'celltypist'; combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-25-5f4cc5c2e544> in <module>; 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'; 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'; ----> 3 combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='datas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2365:1529,Availability,down,download,1529,"till read to memory, even in backed mode.; As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`; But this method has the following implementation in the latest version:; ```python; def read_sparse(elem):; return SparseDataset(elem).to_memory(); ```; Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data); (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python; import scanpy. # Download command; # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'; adata = scanpy.read_h5ad(PATH, backed=True); ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory); ```pytb; Traceback (most recent call last):; File ""scanpy_test.py"", line 9, in <module>; adata = sc.read_h5ad(PATH, backed=True); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad; return read_h5ad_backed(filename, mode); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed; d.update({k: read_elem(f[k]) for k in attributes if k in f}); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>; d.update({k: read_elem(f[k]) for k in attributes if k in f}); File ""[python-pat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1647,Availability,Down,Download,1647," `_io/specs/methods.py`; But this method has the following implementation in the latest version:; ```python; def read_sparse(elem):; return SparseDataset(elem).to_memory(); ```; Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data); (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python; import scanpy. # Download command; # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'; adata = scanpy.read_h5ad(PATH, backed=True); ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory); ```pytb; Traceback (most recent call last):; File ""scanpy_test.py"", line 9, in <module>; adata = sc.read_h5ad(PATH, backed=True); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad; return read_h5ad_backed(filename, mode); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed; d.update({k: read_elem(f[k]) for k in attributes if k in f}); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>; d.update({k: read_elem(f[k]) for k in attributes if k in f}); File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem; return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2344,Deployability,update,update,2344,"aving any data); (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python; import scanpy. # Download command; # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'; adata = scanpy.read_h5ad(PATH, backed=True); ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory); ```pytb; Traceback (most recent call last):; File ""scanpy_test.py"", line 9, in <module>; adata = sc.read_h5ad(PATH, backed=True); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad; return read_h5ad_backed(filename, mode); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed; d.update({k: read_elem(f[k]) for k in attributes if k in f}); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>; d.update({k: read_elem(f[k]) for k in attributes if k in f}); File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem; return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem); File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic; return {k: read_elem(v) for k, v in elem.items()}; File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>; return {k: read_elem(v) for k, v in elem.items()}; File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem; return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem); File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse; return SparseDataset(elem).to_memory(); File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory; m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2487,Deployability,update,update,2487,"o the big dataset that is causing the crash on my 24GB memory machine). ```python; import scanpy. # Download command; # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'; adata = scanpy.read_h5ad(PATH, backed=True); ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory); ```pytb; Traceback (most recent call last):; File ""scanpy_test.py"", line 9, in <module>; adata = sc.read_h5ad(PATH, backed=True); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad; return read_h5ad_backed(filename, mode); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed; d.update({k: read_elem(f[k]) for k in attributes if k in f}); File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>; d.update({k: read_elem(f[k]) for k in attributes if k in f}); File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem; return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem); File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic; return {k: read_elem(v) for k, v in elem.items()}; File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>; return {k: read_elem(v) for k, v in elem.items()}; File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem; return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem); File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse; return SparseDataset(elem).to_memory(); File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory; mtx.indices = self.group[""indices""][...]; File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py\_objects.pyx"", line 55, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:4832,Deployability,update,updated,4832,"hon-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>; return {k: read_elem(v) for k, v in elem.items()}; File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem; return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem); File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse; return SparseDataset(elem).to_memory(); File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory; mtx.indices = self.group[""indices""][...]; File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__; return self._fast_reader.read(args); File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read; File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array; numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; beta_ufunc NA; binom_ufunc NA; colorama 0.4.5; console_thrift NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; h5py 3.7.0; hypergeom_ufunc NA; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.39.1; matplotlib 3.6.0; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; nt NA; numba 0.56.2; numpy 1.22.3; packaging 21.3; pandas 1.4.1; pkg_resources NA; pydev_console NA; pydev_ipython NA; pydevconsole NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pyparsing 3.0.7; pytz 2022.1; scipy 1.8.0; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.1.2; threadpoolctl 3.1.0; -----; Python 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]; Windows-10-10.0.22000-SP0; -----; Session information updated at 2022-10-26 15:35. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:3896,Energy Efficiency,allocate,allocate,3896,"hon-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>; return {k: read_elem(v) for k, v in elem.items()}; File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem; return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem); File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse; return SparseDataset(elem).to_memory(); File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory; mtx.indices = self.group[""indices""][...]; File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__; return self._fast_reader.read(args); File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read; File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array; numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; beta_ufunc NA; binom_ufunc NA; colorama 0.4.5; console_thrift NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; h5py 3.7.0; hypergeom_ufunc NA; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.39.1; matplotlib 3.6.0; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; nt NA; numba 0.56.2; numpy 1.22.3; packaging 21.3; pandas 1.4.1; pkg_resources NA; pydev_console NA; pydev_ipython NA; pydevconsole NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pyparsing 3.0.7; pytz 2022.1; scipy 1.8.0; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.1.2; threadpoolctl 3.1.0; -----; Python 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]; Windows-10-10.0.22000-SP0; -----; Session information updated at 2022-10-26 15:35. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:3503,Integrability,wrap,wrapper,3503," k in attributes if k in f}); File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem; return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem); File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic; return {k: read_elem(v) for k, v in elem.items()}; File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>; return {k: read_elem(v) for k, v in elem.items()}; File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem; return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem); File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse; return SparseDataset(elem).to_memory(); File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory; mtx.indices = self.group[""indices""][...]; File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__; return self._fast_reader.read(args); File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read; File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array; numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; beta_ufunc NA; binom_ufunc NA; colorama 0.4.5; console_thrift NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; h5py 3.7.0; hypergeom_ufunc NA; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.39.1; matplotlib 3.6.0; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; nt NA; numba 0.56.2; numpy 1.22.3; packaging 21.3; pandas 1.4.1; pkg_resources NA; pydev_console NA; pydev_ipython NA; pydevconsole NA; pydevd_file_utils NA; pyd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:3574,Integrability,wrap,wrapper,3574,"try.py"", line 183, in read_elem; return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem); File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic; return {k: read_elem(v) for k, v in elem.items()}; File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>; return {k: read_elem(v) for k, v in elem.items()}; File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem; return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem); File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse; return SparseDataset(elem).to_memory(); File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory; mtx.indices = self.group[""indices""][...]; File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__; return self._fast_reader.read(args); File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read; File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array; numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; beta_ufunc NA; binom_ufunc NA; colorama 0.4.5; console_thrift NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; h5py 3.7.0; hypergeom_ufunc NA; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.39.1; matplotlib 3.6.0; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; nt NA; numba 0.56.2; numpy 1.22.3; packaging 21.3; pandas 1.4.1; pkg_resources NA; pydev_console NA; pydev_ipython NA; pydevconsole NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pyparsing 3.0.7; pytz 2022.1; scipy 1.8.0; session_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:891,Performance,load,loading,891,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB); When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode.; As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`; But this method has the following implementation in the latest version:; ```python; def read_sparse(elem):; return SparseDataset(elem).to_memory(); ```; Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data); (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python; import scanpy. # Download command; # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'; adata = scanpy.read_h5ad(PATH, backed=True); ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1051,Performance,load,loads,1051,"dy been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB); When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode.; As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`; But this method has the following implementation in the latest version:; ```python; def read_sparse(elem):; return SparseDataset(elem).to_memory(); ```; Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data); (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python; import scanpy. # Download command; # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'; adata = scanpy.read_h5ad(PATH, backed=True); ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory); ```pytb; Traceback (most recent call last):; Fi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2366:2993,Deployability,update,updated,2993,"how = False); ```; The empty subplot axes are plotted first: ; ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png); then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 1.0.0; google NA; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.9.11; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 8.0.2; jedi 0.18.1; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.8.10; llvmlite 0.39.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.56.2; numexpr 2.8.3; numpy 1.23.3; packaging 21.3; pandas 1.4.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.31; psutil 5.9.2; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pyparsing 3.0.9; pytz 2022.2.1; scipy 1.9.1; seaborn 0.12.0; session_info 1.0.0; setuptools 63.4.1; six 1.16.0; sklearn 1.1.2; stack_data 0.5.0; statsmodels 0.13.2; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.2; tqdm 4.64.1; traitlets 5.3.0; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 23.2.1; -----; IPython 8.5.0; jupyter_client 7.3.5; jupyter_core 4.11.1; jupyterlab 3.4.6; notebook 6.4.12; -----; Python 3.8.0 (default, Nov 6 2019, 21:49:08) [GCC 7.3.0]; Linux-4.15.0-192-generic-x86_64-with-glibc2.10; -----; Session information updated at 2022-10-28 15:05. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); ; ```python; fig, axs = plt.subplots(1, 3); sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False); sc.pl.rank_genes_groups(ad, ax =axs[0], show = False); sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False); sc.pl.rank_genes_groups(ad, ax = axs[1], show = False); sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False); sc.pl.rank_genes_groups(ad, ax = axs[2], show = False); ```; The empty subplot axes are plotted first: ; ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png); then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 1.0.0; google NA; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.9.11; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 8.0.2; jedi 0.18.1; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.8.10; llvmlite 0.39.1; matp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2368:2562,Deployability,update,updated,2562,"max(0)).fillna(0); ```; and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions; `sc.__version__`; '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; <details>. ```; -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.1.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2021.10.08; cffi 1.15.0; charset_normalizer 2.0.12; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 0.8.3; gprofiler 1.0.0; h5py 3.6.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.10; ipykernel 6.12.1; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; jupyter_server 1.16.0; kiwisolver 1.4.2; leidenalg 0.8.9; llvmlite 0.38.0; matplotlib 3.6.2; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numpy 1.21.4; packaging 21.3; pandas 1.5.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.29; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.9; pytz 2022.1; requests 2.27.1; scipy 1.8.1; seaborn 0.12.1; session_info 1.0.0; setuptools 62.0.0; setuptools_scm NA; six 1.16.0; sklearn 1.0.2; socks 1.7.1; stack_data 0.2.0; statsmodels 0.13.2; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.1; traitlets 5.1.1; typing_extensions NA; urllib3 1.26.9; wcwidth 0.2.5; zmq 22.3.0; zoneinfo NA; -----; IPython 8.2.0; jupyter_client 7.2.2; jupyter_core 4.9.2; jupyterlab 3.3.3; notebook 6.4.10; -----; Python 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:22:55) [GCC 10.3.0]; Linux-5.15.0-52-generic-x86_64-with-glibc2.31; -----; Session information updated at 2022-11-11 15:54; ```; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:712,Testability,log,logfoldchanges,712,"- [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 ; I only see two places in the code where nan gets set to 0 for matrix plots; ```python; ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0); ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0); ```; and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions; `sc.__version__`; '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; <details>. ```; -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.1.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2021.10.08; cffi 1.15.0; charset_normalizer 2.0.12; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 0.8.3; gprofiler 1.0.0; h5py 3.6.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.10; ipykernel 6.12.1; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; jupyter_server 1.16.0; kiwisolver 1.4.2; leidenalg 0.8.9; llvmlite 0.38.0; matplotlib 3.6.2; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numpy 1.21.4; packaging 21.3; pandas 1.5.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.29; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.9; pytz 2022.1; requests 2.27.1; scipy 1.8.1; sea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:897,Testability,log,logging,897,"- [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 ; I only see two places in the code where nan gets set to 0 for matrix plots; ```python; ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0); ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0); ```; and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions; `sc.__version__`; '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; <details>. ```; -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.1.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2021.10.08; cffi 1.15.0; charset_normalizer 2.0.12; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 0.8.3; gprofiler 1.0.0; h5py 3.6.0; hypergeom_ufunc NA; idna 3.3; igraph 0.9.10; ipykernel 6.12.1; ipython_genutils 0.2.0; ipywidgets 7.7.0; jedi 0.18.1; joblib 1.1.0; jupyter_server 1.16.0; kiwisolver 1.4.2; leidenalg 0.8.9; llvmlite 0.38.0; matplotlib 3.6.2; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numpy 1.21.4; packaging 21.3; pandas 1.5.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.29; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.9; pytz 2022.1; requests 2.27.1; scipy 1.8.1; sea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2369:231,Availability,error,error,231,"At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:442,Availability,error,error,442,"At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:120,Deployability,install,installation,120,"At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:255,Deployability,install,install,255,"At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:300,Deployability,install,install,300,"At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:399,Deployability,install,installation,399,"At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:461,Deployability,install,installing,461,"At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:448,Integrability,message,message,448,"At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2370:216,Availability,error,error,216,"When I use ""scanpy.pl.spatial"" to to plot the spatial position of the cells, I want the cells in the space to be represented by square instead of ""point"". I have tried to set the parameter "" marker = 's' "", but an error is reported as following:; TypeError: functools.partial object got multiple values for keyword argument 'marker'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2370
https://github.com/scverse/scanpy/issues/2371:5520,Availability,error,error,5520,".0; scanpy 1.9.1; -----; PIL 9.2.0; PyObjCTools NA; appnope 0.1.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fsspec 2022.7.1; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.2; ipykernel 6.15.2; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.9.0; llvmlite 0.38.0; louvain 0.8.0; lxml 4.9.1; lz4 3.1.3; markupsafe 2.0.1; matplotlib 3.5.2; mkl 2.4.0; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.55.1; numexpr 2.8.3; numpy 1.21.5; openpyxl 3.0.10; packaging 21.3; pandas 1.4.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.9.0; prompt_toolkit 3.0.20; psutil 5.9.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.9; pytz 2022.1; scipy 1.9.1; session_info 1.0.0; setuptools 63.4.1; six 1.16.0; sklearn 1.0.2; snappy NA; sphinxcontrib NA; storemagic NA; tblib 1.7.0; texttable 1.6.7; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; xlrd 2.0.1; yaml 6.0; zipp NA; zmq 23.2.0; zope NA; -----; IPython 7.31.1; jupyter_client 7.3.4; jupyter_core 4.11.1; jupyterlab 3.4.4; notebook 6.4.12; -----; Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]; macOS-10.16-x86_64-i386-64bit; -----; Session information updated at 2022-11-26 11:30]. </details>; When trying to read-in the .xlsx file, I get the error that the sheet does not exist. A screen shot of the excel file is attached. <img width=""1399"" alt=""Screenshot 2022-11-26 at 11 33 18 AM"" src=""https://user-images.githubusercontent.com/119125018/204099054-96ba4b72-815b-45fa-8bdc-a9f7d91ba662.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:5429,Deployability,update,updated,5429,".0; scanpy 1.9.1; -----; PIL 9.2.0; PyObjCTools NA; appnope 0.1.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fsspec 2022.7.1; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.2; ipykernel 6.15.2; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.9.0; llvmlite 0.38.0; louvain 0.8.0; lxml 4.9.1; lz4 3.1.3; markupsafe 2.0.1; matplotlib 3.5.2; mkl 2.4.0; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.55.1; numexpr 2.8.3; numpy 1.21.5; openpyxl 3.0.10; packaging 21.3; pandas 1.4.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.9.0; prompt_toolkit 3.0.20; psutil 5.9.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.9; pytz 2022.1; scipy 1.9.1; session_info 1.0.0; setuptools 63.4.1; six 1.16.0; sklearn 1.0.2; snappy NA; sphinxcontrib NA; storemagic NA; tblib 1.7.0; texttable 1.6.7; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.2; tornado 6.1; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; xlrd 2.0.1; yaml 6.0; zipp NA; zmq 23.2.0; zope NA; -----; IPython 7.31.1; jupyter_client 7.3.4; jupyter_core 4.11.1; jupyterlab 3.4.4; notebook 6.4.12; -----; Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]; macOS-10.16-x86_64-i386-64bit; -----; Session information updated at 2022-11-26 11:30]. </details>; When trying to read-in the .xlsx file, I get the error that the sheet does not exist. A screen shot of the excel file is attached. <img width=""1399"" alt=""Screenshot 2022-11-26 at 11 33 18 AM"" src=""https://user-images.githubusercontent.com/119125018/204099054-96ba4b72-815b-45fa-8bdc-a9f7d91ba662.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:1576,Integrability,wrap,wrapper,1576," 'expression'); ```. ```pytb; [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed; warn(msg). ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>; ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype); 73 from pandas import read_excel; 74 ; ---> 75 df = read_excel(fspath(filename), sheet); 76 X = df.values[:, 1:]; 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 309 stacklevel=stacklevel,; 310 ); --> 311 return func(*args, **kwargs); 312 ; 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options); 463 ; 464 try:; --> 465 data = io.parse(; 466 sheet_name=sheet_name,; 467 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds); 1456 DataFrame from the passed in Excel file.; 1457 """"""; -> 1458 return self._reader.parse(; 1459 sheet_name=sheet_name,; 1460 header=header,. ~/opt/anaconda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:1692,Integrability,wrap,wrapper,1692," 'expression'); ```. ```pytb; [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed; warn(msg). ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>; ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype); 73 from pandas import read_excel; 74 ; ---> 75 df = read_excel(fspath(filename), sheet); 76 X = df.values[:, 1:]; 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 309 stacklevel=stacklevel,; 310 ); --> 311 return func(*args, **kwargs); 312 ; 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options); 463 ; 464 try:; --> 465 data = io.parse(; 466 sheet_name=sheet_name,; 467 header=header,. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in parse(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds); 1456 DataFrame from the passed in Excel file.; 1457 """"""; -> 1458 return self._reader.parse(; 1459 sheet_name=sheet_name,; 1460 header=header,. ~/opt/anaconda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:3886,Performance,bottleneck,bottleneck,3886,"l, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds); 632 ; 633 if isinstance(asheetname, str):; --> 634 sheet = self.get_sheet_by_name(asheetname); 635 else: # assume an integer if not a string; 636 sheet = self.get_sheet_by_index(asheetname). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_openpyxl.py in get_sheet_by_name(self, name); 543 ; 544 def get_sheet_by_name(self, name: str):; --> 545 self.raise_if_bad_sheet_by_name(name); 546 return self.book[name]; 547 . ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in raise_if_bad_sheet_by_name(self, name); 568 def raise_if_bad_sheet_by_name(self, name: str) -> None:; 569 if name not in self.sheet_names:; --> 570 raise ValueError(f""Worksheet named '{name}' not found""); 571 ; 572 def parse(. ValueError: Worksheet named 'expression' not found]; ```. #### '1.9.1'. <details>. [-----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; PyObjCTools NA; appnope 0.1.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fsspec 2022.7.1; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.2; ipykernel 6.15.2; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.9.0; llvmlite 0.38.0; louvain 0.8.0; lxml 4.9.1; lz4 3.1.3; markupsafe 2.0.1; matplotlib 3.5.2; mkl 2.4.0; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.55.1; numexpr 2.8.3; numpy 1.21.5; openpyxl 3.0.10; packaging 21.3; pandas 1.4.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.9.0; prompt_toolkit 3.0.20; psutil 5.9.0; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pyparsing 3.0.9; pytz 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2371:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'); ```. ```pytb; [/Users/dan/opt/anaconda3/lib/python3.9/site-packages/openpyxl/reader/workbook.py:88: UserWarning: File contains an invalid specification for expression. This will be removed; warn(msg). ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); /var/folders/f1/7pq3lkn50cb7mtfkxrk9fnfh0000gn/T/ipykernel_3372/1224090119.py in <module>; ----> 1 adata = sc.read_excel(filename = '/Users/dan/Documents/Graduate_School/Bioinformatics_MS/BF550/Project/muscle_expression_.xlsx', sheet = 'expression'). ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_io/read.py in read_excel(filename, sheet, dtype); 73 from pandas import read_excel; 74 ; ---> 75 df = read_excel(fspath(filename), sheet); 76 X = df.values[:, 1:]; 77 row = dict(row_names=df.iloc[:, 0].values.astype(str)). ~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs); 309 stacklevel=stacklevel,; 310 ); --> 311 return func(*args, **kwargs); 312 ; 313 return wrapper. ~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py in read_excel(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2371
https://github.com/scverse/scanpy/issues/2372:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->; Hello Scanpy,; I'm merging millions of cells to run the Scanpy, and the steps for constructing UMAP kill me. Is it possible or is there any plan to make these functions `sc.tl.pca, sc.pp.neighbors, sc.tl.leiden, and sc.tl.umap` support multiprocessing?; Thanks!; Best,; Yuanjian",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2372
https://github.com/scverse/scanpy/pull/2373:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/psf/black: 22.10.0  23.1.0](https://github.com/psf/black/compare/22.10.0...23.1.0); - [github.com/PyCQA/flake8: 5.0.4  6.0.0](https://github.com/PyCQA/flake8/compare/5.0.4...6.0.0); - [github.com/pre-commit/mirrors-autopep8: v2.0.0  v2.0.1](https://github.com/pre-commit/mirrors-autopep8/compare/v2.0.0...v2.0.1); - [github.com/pre-commit/pre-commit-hooks: v4.3.0  v4.4.0](https://github.com/pre-commit/pre-commit-hooks/compare/v4.3.0...v4.4.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2373
https://github.com/scverse/scanpy/pull/2374:30,Availability,error,errors,30,"This was giving out-of-memory errors since scanorama's default is batch_size=None, and setting batch_size to another value wasn't doing anything. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2374
https://github.com/scverse/scanpy/pull/2374:217,Usability,guid,guidelines,217,"This was giving out-of-memory errors since scanorama's default is batch_size=None, and setting batch_size to another value wasn't doing anything. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2374
https://github.com/scverse/scanpy/pull/2374:248,Usability,guid,guide,248,"This was giving out-of-memory errors since scanorama's default is batch_size=None, and setting batch_size to another value wasn't doing anything. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2374
https://github.com/scverse/scanpy/issues/2376:54,Availability,error,error,54,"When I tried to read h5ad using scanpy or anndata, an error occurs:. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 176 try:; --> 177 return func(elem, *args, **kwargs); 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 526 if encoding_type:; --> 527 EncodingVersions[encoding_type].check(; 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name); 343 def __getitem__(cls, name):; --> 344 return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-17-97568eff5295> in <module>; ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 872 '1 positional argument'); 873 ; --> 874 return dispatch(args[0].__class__)(*args, **kw); 875 ; 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:1679,Availability,error,error,1679,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 176 try:; --> 177 return func(elem, *args, **kwargs); 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 526 if encoding_type:; --> 527 EncodingVersions[encoding_type].check(; 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name); 343 def __getitem__(cls, name):; --> 344 return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-17-97568eff5295> in <module>; ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 872 '1 positional argument'); 873 ; --> 874 return dispatch(args[0].__class__)(*args, **kw); 875 ; 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:1795,Availability,error,error,1795,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 176 try:; --> 177 return func(elem, *args, **kwargs); 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 526 if encoding_type:; --> 527 EncodingVersions[encoding_type].check(; 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name); 343 def __getitem__(cls, name):; --> 344 return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-17-97568eff5295> in <module>; ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 872 '1 positional argument'); 873 ; --> 874 return dispatch(args[0].__class__)(*args, **kw); 875 ; 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:2017,Availability,error,error,2017,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 176 try:; --> 177 return func(elem, *args, **kwargs); 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 526 if encoding_type:; --> 527 EncodingVersions[encoding_type].check(; 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name); 343 def __getitem__(cls, name):; --> 344 return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-17-97568eff5295> in <module>; ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 872 '1 positional argument'); 873 ; --> 874 return dispatch(args[0].__class__)(*args, **kw); 875 ; 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:1299,Integrability,wrap,wrapper,1299,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 176 try:; --> 177 return func(elem, *args, **kwargs); 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 526 if encoding_type:; --> 527 EncodingVersions[encoding_type].check(; 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name); 343 def __getitem__(cls, name):; --> 344 return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-17-97568eff5295> in <module>; ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 872 '1 positional argument'); 873 ; --> 874 return dispatch(args[0].__class__)(*args, **kw); 875 ; 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:1828,Modifiability,layers,layers,1828,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 176 try:; --> 177 return func(elem, *args, **kwargs); 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 526 if encoding_type:; --> 527 EncodingVersions[encoding_type].check(; 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name); 343 def __getitem__(cls, name):; --> 344 return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-17-97568eff5295> in <module>; ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 872 '1 positional argument'); 873 ; --> 874 return dispatch(args[0].__class__)(*args, **kw); 875 ; 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2376:2123,Testability,log,logging,2123,"niconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 176 try:; --> 177 return func(elem, *args, **kwargs); 178 except Exception as e:. ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group); 526 if encoding_type:; --> 527 EncodingVersions[encoding_type].check(; 528 group.name, group.attrs[""encoding-version""]. ~/miniconda3/lib/python3.8/enum.py in __getitem__(cls, name); 343 def __getitem__(cls, name):; --> 344 return cls._member_map_[name]; 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last); <ipython-input-17-97568eff5295> in <module>; ----> 1 adata=anndata.read_h5ad('./visium_merge_inter_upload.h5ad'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 419 d[k] = read_dataframe(f[k]); 420 else: # Base case; --> 421 d[k] = read_attribute(f[k]); 422 ; 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). ~/miniconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 872 '1 positional argument'); 873 ; --> 874 return dispatch(args[0].__class__)(*args, **kw); 875 ; 876 funcname = getattr(func, '__name__', 'singledispatch function'). ~/miniconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs); 181 else:; 182 parent = _get_parent(elem); --> 183 raise AnnDataReadError(; 184 f""Above error raised while reading key {elem.name!r} of ""; 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /.; ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2376
https://github.com/scverse/scanpy/issues/2377:690,Availability,error,error,690,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data); I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error.; ```python; import scanpy; adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes; sc.external.pp.scrublet(test_adata, batch_key = ""label""); ```. ```pytb; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata). Automatically set threshold at doublet score = 0.16; Detected doublet rate = 6.4%; Estimated detectable doublet fraction = 61.7%; Overall doublet rate:; 	Expected = 5.0%; 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalizatio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:975,Availability,error,error,975,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data); I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error.; ```python; import scanpy; adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes; sc.external.pp.scrublet(test_adata, batch_key = ""label""); ```. ```pytb; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata). Automatically set threshold at doublet score = 0.16; Detected doublet rate = 6.4%; Estimated detectable doublet fraction = 61.7%; Overall doublet rate:; 	Expected = 5.0%; 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalizatio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:6718,Deployability,update,updated,6718,"; certifi 2021.10.08; cffi 1.14.6; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; debugpy 1.4.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fastjsonschema NA; fsspec 2021.08.1; h5py 3.3.0; idna 3.2; igraph 0.10.2; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.1.2; joblib 1.1.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.23.3; jupyterlab_server 2.8.2; kiwisolver 1.3.1; leidenalg 0.9.0; llvmlite 0.37.0; markupsafe 2.1.1; matplotlib 3.4.3; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 8.2.0; nbclassic 0.4.8; nbformat 5.7.0; nbinom_ufunc NA; notebook_shim NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0; pandas 1.3.4; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.11.0; prometheus_client NA; prompt_toolkit 3.0.20; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pydev_ipython NA; pydevconsole NA; pydevd 2.4.1; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pyexpat NA; pygments 2.10.0; pynndescent 0.5.8; pyparsing 3.0.4; pyrsistent NA; pytz 2021.3; pywt 1.1.1; requests 2.26.0; scipy 1.7.1; scrublet NA; seaborn 0.11.2; send2trash NA; session_info 1.0.0; settings NA; simplejson 3.17.6; six 1.16.0; skimage 0.18.3; sklearn 0.24.2; sniffio 1.2.0; socks 1.7.1; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tblib 1.7.0; terminado 0.9.4; texttable 1.6.4; tlz 0.11.0; toolz 0.11.1; tornado 6.1; tqdm 4.62.3; traitlets 5.1.0; typing_extensions NA; umap 0.5.3; urllib3 1.26.7; wcwidth 0.2.5; websocket 1.4.2; yaml 6.0; zmq 22.2.1; zope NA; -----; IPython 7.29.0; jupyter_client 6.1.12; jupyter_core 4.8.1; jupyterlab 3.2.1; notebook 6.4.5; -----; Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]; Linux-4.18.0-305.45.1.el8_4.x86_64-x86_64-with-glibc2.28; -----; Session information updated at 2022-12-04. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:4724,Performance,bottleneck,bottleneck,4724,"; 1092 # A collection of keys; -> 1093 keyarr, indexer = self._get_listlike_indexer(key, axis); 1094 return self.obj._reindex_with_indexers(; 1095 {axis: [keyarr, indexer]}, copy=True, allow_dups=True. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _get_listlike_indexer(self, key, axis); 1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr); 1313 ; -> 1314 self._validate_read_indexer(keyarr, indexer, axis); 1315 ; 1316 if needs_i8_conversion(ax.dtype) or isinstance(. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis); 1375 ; 1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique()); -> 1377 raise KeyError(f""{not_found} not in index""); 1378 ; 1379 . KeyError: ""['GGAACCCTCTCCCAGC-batch1'] not in index""; ```. #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 8.4.0; annoy NA; anyio NA; attr 21.2.0; autoreload NA; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; brotli NA; certifi 2021.10.08; cffi 1.14.6; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; debugpy 1.4.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fastjsonschema NA; fsspec 2021.08.1; h5py 3.3.0; idna 3.2; igraph 0.10.2; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.1.2; joblib 1.1.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.23.3; jupyterlab_server 2.8.2; kiwisolver 1.3.1; leidenalg 0.9.0; llvmlite 0.37.0; markupsafe 2.1.1; matplotlib 3.4.3; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 8.2.0; nbclassic 0.4.8; nbformat 5.7.0; nbinom_ufunc NA; notebook_shim NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0; pandas 1.3.4; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.11.0; prometheus_client NA; prompt_toolkit 3.0.20; psutil 5.8.0; ptyprocess 0.7.0; pv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1585,Safety,Detect,Detected,1585,"/github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data); I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error.; ```python; import scanpy; adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes; sc.external.pp.scrublet(test_adata, batch_key = ""label""); ```. ```pytb; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata). Automatically set threshold at doublet score = 0.16; Detected doublet rate = 6.4%; Estimated detectable doublet fraction = 61.7%; Overall doublet rate:; 	Expected = 5.0%; 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata). Automatically set threshold at doublet score = 0.17; Detected doublet rate = 5.8%; Estimated detectable doublet fraction = 55.7%; Overall doublet rate:; 	Expected = 5.0%; 	Estimated = 10.5%. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/ipykernel_2434661/1304834185.py in <module>; ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1625,Safety,detect,detectable,1625,"/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data); I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error.; ```python; import scanpy; adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes; sc.external.pp.scrublet(test_adata, batch_key = ""label""); ```. ```pytb; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata). Automatically set threshold at doublet score = 0.16; Detected doublet rate = 6.4%; Estimated detectable doublet fraction = 61.7%; Overall doublet rate:; 	Expected = 5.0%; 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata). Automatically set threshold at doublet score = 0.17; Detected doublet rate = 5.8%; Estimated detectable doublet fraction = 55.7%; Overall doublet rate:; 	Expected = 5.0%; 	Estimated = 10.5%. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/ipykernel_2434661/1304834185.py in <module>; ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:2147,Safety,Detect,Detected,2147,"b; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata). Automatically set threshold at doublet score = 0.16; Detected doublet rate = 6.4%; Estimated detectable doublet fraction = 61.7%; Overall doublet rate:; 	Expected = 5.0%; 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata). Automatically set threshold at doublet score = 0.17; Detected doublet rate = 5.8%; Estimated detectable doublet fraction = 55.7%; Overall doublet rate:; 	Expected = 5.0%; 	Estimated = 10.5%. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/ipykernel_2434661/1304834185.py in <module>; ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state); 250 # Now reset the obs to get the scrublet scores; 251 ; --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]; 253 ; 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getite",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:2187,Safety,detect,detectable,2187,"s/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata). Automatically set threshold at doublet score = 0.16; Detected doublet rate = 6.4%; Estimated detectable doublet fraction = 61.7%; Overall doublet rate:; 	Expected = 5.0%; 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata). Automatically set threshold at doublet score = 0.17; Detected doublet rate = 5.8%; Estimated detectable doublet fraction = 55.7%; Overall doublet rate:; 	Expected = 5.0%; 	Estimated = 10.5%. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/ipykernel_2434661/1304834185.py in <module>; ----> 1 sc.external.pp.scrublet(test_adata, batch_key = ""label""). ~/.local/lib/python3.9/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state); 250 # Now reset the obs to get the scrublet scores; 251 ; --> 252 adata.obs = scrubbed_obs.loc[adata.obs_names.values]; 253 ; 254 # Save the .uns from each batch separately. <path>/lib/python3.9/site-packages/pandas/core/indexing.py in __getitem__(self, key); 929 ; 930 maybe_callabl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:1030,Testability,test,test,1030,"s issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data); I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error.; ```python; import scanpy; adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes; sc.external.pp.scrublet(test_adata, batch_key = ""label""); ```. ```pytb; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata). Automatically set threshold at doublet score = 0.16; Detected doublet rate = 6.4%; Estimated detectable doublet fraction = 61.7%; Overall doublet rate:; 	Expected = 5.0%; 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Receiv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:257,Usability,guid,guide,257,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. _run_scrublet sometimes removes cells, due to [these lines](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L175-L176). As a result, [this line](https://github.com/scverse/scanpy/blob/master/scanpy/external/pp/_scrublet.py#L252) results in a key error since the scrubbed data contains fewer cells than the original adata. ### Minimal code sample (that we can copy&paste without having any data); I do not have a code sample that does not require data, but any anndata that contains cells with fewer than 3 genes should trigger the error.; ```python; import scanpy; adata = scanpy.read(""test.h5ad"") # e.g. contains cells with fewer than 3 genes; sc.external.pp.scrublet(test_adata, batch_key = ""label""); ```. ```pytb; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata). Automatically set threshold at doublet score = 0.16; Detected doublet rate = 6.4%; Estimated detectable doublet fraction = 61.7%; Overall doublet rate:; 	Expected = 5.0%; 	Estimated = 10.4%. ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.; adata.var['n_cells'] = number; ~/.local/lib/python3.9/site-packages/scanpy/preprocessing/_normalizatio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2377:6094,Usability,simpl,simplejson,6094,"; certifi 2021.10.08; cffi 1.14.6; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.10.0; dateutil 2.8.2; debugpy 1.4.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fastjsonschema NA; fsspec 2021.08.1; h5py 3.3.0; idna 3.2; igraph 0.10.2; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.1.2; joblib 1.1.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.23.3; jupyterlab_server 2.8.2; kiwisolver 1.3.1; leidenalg 0.9.0; llvmlite 0.37.0; markupsafe 2.1.1; matplotlib 3.4.3; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 8.2.0; nbclassic 0.4.8; nbformat 5.7.0; nbinom_ufunc NA; notebook_shim NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0; pandas 1.3.4; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.11.0; prometheus_client NA; prompt_toolkit 3.0.20; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pydev_ipython NA; pydevconsole NA; pydevd 2.4.1; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pyexpat NA; pygments 2.10.0; pynndescent 0.5.8; pyparsing 3.0.4; pyrsistent NA; pytz 2021.3; pywt 1.1.1; requests 2.26.0; scipy 1.7.1; scrublet NA; seaborn 0.11.2; send2trash NA; session_info 1.0.0; settings NA; simplejson 3.17.6; six 1.16.0; skimage 0.18.3; sklearn 0.24.2; sniffio 1.2.0; socks 1.7.1; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tblib 1.7.0; terminado 0.9.4; texttable 1.6.4; tlz 0.11.0; toolz 0.11.1; tornado 6.1; tqdm 4.62.3; traitlets 5.1.0; typing_extensions NA; umap 0.5.3; urllib3 1.26.7; wcwidth 0.2.5; websocket 1.4.2; yaml 6.0; zmq 22.2.1; zope NA; -----; IPython 7.29.0; jupyter_client 6.1.12; jupyter_core 4.8.1; jupyterlab 3.2.1; notebook 6.4.5; -----; Python 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]; Linux-4.18.0-305.45.1.el8_4.x86_64-x86_64-with-glibc2.28; -----; Session information updated at 2022-12-04. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2377
https://github.com/scverse/scanpy/issues/2378:1014,Availability,error,error,1014,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.experimental.pp.highly_variable_genes(; placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'; ); ```. ```pytb; AttributeError: module 'scanpy' has no attribute 'experimental'; ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. ; Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. ; But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this; ```; /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/;  cli.py;  _compat.py;  datasets;  experimental;  external;  get;  __init__.py;  logging.py;  __main__.py;  _metadata.py;  metrics;  neighbors;  plotting;  preprocessing;  __pycache__;  queries;  readwrite.py;  _settings.py;  sim_models;  tools;  _utils; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1207,Availability,error,error,1207,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.experimental.pp.highly_variable_genes(; placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'; ); ```. ```pytb; AttributeError: module 'scanpy' has no attribute 'experimental'; ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. ; Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. ; But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this; ```; /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/;  cli.py;  _compat.py;  datasets;  experimental;  external;  get;  __init__.py;  logging.py;  __main__.py;  _metadata.py;  metrics;  neighbors;  plotting;  preprocessing;  __pycache__;  queries;  readwrite.py;  _settings.py;  sim_models;  tools;  _utils; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1149,Deployability,update,updated,1149,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.experimental.pp.highly_variable_genes(; placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'; ); ```. ```pytb; AttributeError: module 'scanpy' has no attribute 'experimental'; ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. ; Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. ; But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this; ```; /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/;  cli.py;  _compat.py;  datasets;  experimental;  external;  get;  __init__.py;  logging.py;  __main__.py;  _metadata.py;  metrics;  neighbors;  plotting;  preprocessing;  __pycache__;  queries;  readwrite.py;  _settings.py;  sim_models;  tools;  _utils; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:1590,Testability,log,logging,1590,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.experimental.pp.highly_variable_genes(; placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'; ); ```. ```pytb; AttributeError: module 'scanpy' has no attribute 'experimental'; ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. ; Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. ; But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this; ```; /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/;  cli.py;  _compat.py;  datasets;  experimental;  external;  get;  __init__.py;  logging.py;  __main__.py;  _metadata.py;  metrics;  neighbors;  plotting;  preprocessing;  __pycache__;  queries;  readwrite.py;  _settings.py;  sim_models;  tools;  _utils; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.experimental.pp.highly_variable_genes(; placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'; ); ```. ```pytb; AttributeError: module 'scanpy' has no attribute 'experimental'; ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. ; Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. ; But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this; ```; /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/;  cli.py;  _compat.py;  datasets;  experimental;  external;  get;  __init__.py;  logging.py;  __main__.py;  _metadata.py;  metrics;  neighbors;  plotting;  preprocessing;  __pycache__;  queries;  readwrite.py;  _settings.py;  sim_models;  tools;  _utils; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/issues/2378:833,Usability,learn,learn,833,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.experimental.pp.highly_variable_genes(; placenta, flavor=""pearson_residuals"", n_top_genes=2000, layer='raw', batch_key='sample'; ); ```. ```pytb; AttributeError: module 'scanpy' has no attribute 'experimental'; ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>. I have used sc.experimental for a time and it went well with version 1.7.2. ; Today I got this error, I thought it could be the version problem and I checked the experimental is in the main branch of version 1.9.1 on github, so I updated it to version 1.9.1. ; But it still gets the same error. Would this be due to the jupyterlab? (But I didn't change anything in the environment, it went well with this jupyter before). And I have the full set of files from the main branch like this; ```; /mnt/data/hong/anaconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/;  cli.py;  _compat.py;  datasets;  experimental;  external;  get;  __init__.py;  logging.py;  __main__.py;  _metadata.py;  metrics;  neighbors;  plotting;  preprocessing;  __pycache__;  queries;  readwrite.py;  _settings.py;  sim_models;  tools;  _utils; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2378
https://github.com/scverse/scanpy/pull/2379:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; I'd like to improve hvg selection documentation a bit.; I haven't verified the docs yet.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2379
https://github.com/scverse/scanpy/pull/2379:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; I'd like to improve hvg selection documentation a bit.; I haven't verified the docs yet.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2379
https://github.com/scverse/scanpy/issues/2380:648,Availability,error,error,648,"- [ x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380
https://github.com/scverse/scanpy/issues/2380:827,Modifiability,flexible,flexible,827,"- [ x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I have tried to plot `umap` `embedding` with the `groups` parameters set to 4 out of ~200 groups (since palettes with ~200 colors cant be distinguished and scanpy anyways assigns gray to everything). However, even when we have only 5 elements in the legend (NA and 4 groups) they still remain all gray. I thus tried to specify the `palette` as dictionary of group_names:colors (for the four group), but then I get the error that groups that are in fact not gonna be plotted are missing in the palette dict input. . I think it would be nice that when using `groups` the `palette` argument would be flexible enough to take only the colors for these groups.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2380
https://github.com/scverse/scanpy/issues/2381:500,Availability,down,downstream,500,"I'm not sure if this is a bug or not. It might just be something that I need clarification on, so apologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing?; Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sp; import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000); sp.pp.log1p(data); sp.pp.highly_variable_genes(data, n_top_genes=2000) ; sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ); sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}; for i in range(data.obsp['distances'].shape[0]):; num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column; #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors; #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column; ```. ```pytb; No error; ```. #### Versions. <details>. -----; anndata 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:1946,Availability,error,error,1946," data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000); sp.pp.log1p(data); sp.pp.highly_variable_genes(data, n_top_genes=2000) ; sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ); sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}; for i in range(data.obsp['distances'].shape[0]):; num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column; #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors; #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column; ```. ```pytb; No error; ```. #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.1.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.1.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; etils 0.7.1; executing 0.10.0; flatbuffers 22.11.23; fsspec 2022.7.1; gast NA; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.10.2; ipykernel 6.14.0; ipython_genutils 0.2.0; ipywidgets 7.7.1; jax 0.3.16; jaxlib 0.3.15; jedi 0.18.1; joblib 1.1.0; jupyter_server 1.18.1; keras 2.11.0; kiwisolver 1.4.3; leidenalg 0.9.0; llvmlite 0.38.1; louvain 0.8.0; lz4 4.0.2; matplotlib 3.5.3; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.2; numexpr 2.8.3; numpy 1.22.4; opt_einsum v3.3.0; packaging 21.3; pandas 1.4.2; parso 0.8.3; pexpect 4.8.0; picklesh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:3919,Deployability,update,updated,3919,"#### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.1.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.1.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; etils 0.7.1; executing 0.10.0; flatbuffers 22.11.23; fsspec 2022.7.1; gast NA; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.10.2; ipykernel 6.14.0; ipython_genutils 0.2.0; ipywidgets 7.7.1; jax 0.3.16; jaxlib 0.3.15; jedi 0.18.1; joblib 1.1.0; jupyter_server 1.18.1; keras 2.11.0; kiwisolver 1.4.3; leidenalg 0.9.0; llvmlite 0.38.1; louvain 0.8.0; lz4 4.0.2; matplotlib 3.5.3; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.2; numexpr 2.8.3; numpy 1.22.4; opt_einsum v3.3.0; packaging 21.3; pandas 1.4.2; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.30; psutil 5.9.1; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 9.0.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pynndescent 0.5.7; pyparsing 3.0.9; pytz 2022.2.1; requests 2.28.1; scipy 1.8.1; session_info 1.0.0; six 1.16.0; sklearn 1.1.1; socks 1.7.1; sphinxcontrib NA; stack_data 0.4.0; tensorboard 2.11.0; tensorflow 2.11.0; termcolor NA; texttable 1.6.7; threadpoolctl 3.1.0; tornado 6.2; tqdm 4.64.0; traitlets 5.3.0; typing_extensions NA; umap 0.5.3; unicodedata2 NA; urllib3 1.26.11; wcwidth 0.2.5; wrapt 1.14.1; yaml 6.0; zmq 23.2.1; zope NA; -----; IPython 8.4.0; jupyter_client 7.3.4; jupyter_core 4.11.1; jupyterlab 3.4.5; notebook 6.4.12; -----; Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]; Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-glibc2.17; -----; Session information updated at 2022-12-15 16:32. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:3597,Integrability,wrap,wrapt,3597,"#### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.1.1; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; asttokens NA; astunparse 1.6.3; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.1.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; etils 0.7.1; executing 0.10.0; flatbuffers 22.11.23; fsspec 2022.7.1; gast NA; google NA; h5py 3.7.0; hypergeom_ufunc NA; idna 3.3; igraph 0.10.2; ipykernel 6.14.0; ipython_genutils 0.2.0; ipywidgets 7.7.1; jax 0.3.16; jaxlib 0.3.15; jedi 0.18.1; joblib 1.1.0; jupyter_server 1.18.1; keras 2.11.0; kiwisolver 1.4.3; leidenalg 0.9.0; llvmlite 0.38.1; louvain 0.8.0; lz4 4.0.2; matplotlib 3.5.3; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.2; numexpr 2.8.3; numpy 1.22.4; opt_einsum v3.3.0; packaging 21.3; pandas 1.4.2; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.30; psutil 5.9.1; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 9.0.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pynndescent 0.5.7; pyparsing 3.0.9; pytz 2022.2.1; requests 2.28.1; scipy 1.8.1; session_info 1.0.0; six 1.16.0; sklearn 1.1.1; socks 1.7.1; sphinxcontrib NA; stack_data 0.4.0; tensorboard 2.11.0; tensorflow 2.11.0; termcolor NA; texttable 1.6.7; threadpoolctl 3.1.0; tornado 6.2; tqdm 4.64.0; traitlets 5.3.0; typing_extensions NA; umap 0.5.3; unicodedata2 NA; urllib3 1.26.11; wcwidth 0.2.5; wrapt 1.14.1; yaml 6.0; zmq 23.2.1; zope NA; -----; IPython 8.4.0; jupyter_client 7.3.4; jupyter_core 4.11.1; jupyterlab 3.4.5; notebook 6.4.12; -----; Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]; Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-glibc2.17; -----; Session information updated at 2022-12-15 16:32. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2381:478,Performance,perform,performed,478,"I'm not sure if this is a bug or not. It might just be something that I need clarification on, so apologies if adding it here is inappropriate. I've found that the `.obsp['distances']` matrix output by `sc.pp.neighbors()` is non-symmetric, which doesn't make sense to me. I don't see any parameters in the function for calculating directed vs undirected graph, which might have otherwise led to asymmetry. What am I missing?; Is there some special treatment of the matrix being performed to optimise downstream processing? Or is there something wrong causing this behaviour? . Many thanks. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sp; import pandas as pd. data = sp.datasets.pbmc3k(). sp.pp.normalize_total(data,target_sum=10000); sp.pp.log1p(data); sp.pp.highly_variable_genes(data, n_top_genes=2000) ; sp.pp.scale(data). sp.tl.pca(data, svd_solver='arpack', ); sp.pp.neighbors(data, n_neighbors=20). num_nonzeros = {}; for i in range(data.obsp['distances'].shape[0]):; num_nonzeros[i]= (data.obsp['distances'][i,:].count_nonzero(), data.obsp['distances'][:,i].count_nonzero()). df_nonzeros = pd.DataFrame.from_dict(num_nonzeros, orient = 'index', columns = ['row','column']). print((data.obsp['distances'].A == data.obsp['distances'].A.transpose()).all()) #demonstration that matrix is not symmetric. print(df_nonzeros) #number of non-zero entries in each row and column; #each row has 20 non-zero entries (when adding 1 for self-loops), which is the k parameter used in sp.pp.neighbors; #each column has a varying number of non-zero entries. print(df_nonzeros.column.mean()) #there is still an average of 20 connections in each column; ```. ```pytb; No error; ```. #### Versions. <details>. -----; anndata 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2381
https://github.com/scverse/scanpy/issues/2382:612,Testability,log,logging,612,- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When sorting the adata object using adata.var.sort_index(inplace=True) the adata.X is not sorting accordingly (see example below). ![Capture](https://user-images.githubusercontent.com/104442627/208289144-0572dca3-7a36-435a-955c-3ec33250f105.PNG). ```python. import numpy as np; import pandas as pd; import scanpy as sc; import matplotlib.pyplot as plt; sc.settings.verbosity = 3; sc.logging.print_header(). adata = sc.datasets.pbmc3k(); adata.to_df()['MPO'].sum(); adata.var.sort_index(inplace=True); adata.to_df()['MPO'].sum(). ```. #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 0.8.3; google NA; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.9.11; ipykernel 6.17.1; ipython_genutils 0.2.0; ipywidgets 8.0.2; jedi 0.18.1; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.8.10; llvmlite 0.39.1; loompy 3.0.7; matplotlib 3.6.0; matplotlib_inline NA; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.56.2; numpy 1.23.3; numpy_groupies 0.9.19; packaging 21.3; pandas 1.4.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.6.0; prompt_toolkit 3.0.20; psutil 5.9.4; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.7; pyparsing 3.0.9; pytz 2022.2.1; scipy 1.9.1; scvelo 0.2.4; session_info 1.0.0; setuptools_scm NA; six 1.16.0; sklearn 1.1.2; stack_data 0.2.0; statsmodels 0.13.2; texttable 1.6.4; threadpoolctl 3.1.0; tor,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2382
https://github.com/scverse/scanpy/issues/2383:1688,Availability,error,error,1688,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); Write any anndata with pearson residuals in uns; ```python; ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'); ```; The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :; ```python; {'theta': 100,; 'clip': None,; 'computed_on': 'adata.X',; 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \; barcode ; GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 ; TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 ; CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 ; TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 ; TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 ; ... ... ... ... ... ; CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 ; AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 ; CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 ; AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 ; TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 ; ```. ```pytb; Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /; ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:1659,Integrability,message,message,1659,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); Write any anndata with pearson residuals in uns; ```python; ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'); ```; The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :; ```python; {'theta': 100,; 'clip': None,; 'computed_on': 'adata.X',; 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \; barcode ; GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 ; TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 ; CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 ; TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 ; TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 ; ... ... ... ... ... ; CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 ; AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 ; CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 ; AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 ; TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 ; ```. ```pytb; Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /; ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); Write any anndata with pearson residuals in uns; ```python; ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'); ```; The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :; ```python; {'theta': 100,; 'clip': None,; 'computed_on': 'adata.X',; 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \; barcode ; GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 ; TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 ; CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 ; TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 ; TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 ; ... ... ... ... ... ; CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 ; AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 ; CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 ; AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 ; TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 ; ```. ```pytb; Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /; ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/issues/2383:1902,Usability,learn,learn,1902,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); Write any anndata with pearson residuals in uns; ```python; ad_all.write(filename='output/10x_h5/ad_all_2cello.h5ad'); ```; The pearson_residual_df looks like this, with 38291 rows (obs) and 5000 columns (features) :; ```python; {'theta': 100,; 'clip': None,; 'computed_on': 'adata.X',; 'pearson_residuals_df': gene_name A2M AADACL2-AS1 AAK1 ABCA1 \; barcode ; GAACGTTCACACCGAC-1-placenta_81 -1.125285 -1.159130 -3.921314 -2.533474 ; TATACCTGTTAGCTAC-1-placenta_81 -1.091364 3.267127 -1.806667 -2.109586 ; CTCAAGAGTGACTGTT-1-placenta_81 -1.074943 12.272920 -1.948798 -2.735791 ; TTCATTGTCACGAACT-1-placenta_81 -1.098699 -1.131765 3.481171 4.472371 ; TATCAGGCAGCTCATA-1-placenta_81 -1.107734 -1.141064 -0.571775 -2.813671 ; ... ... ... ... ... ; CACAACATCGGCGATC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 ; AGCCAGCGTGCCCAGT-1-placenta_314 -0.097424 -0.100394 -0.366482 -0.256219 ; CCGGTGAGTGTTCGAT-1-placenta_314 -0.110334 -0.113696 -0.414971 -0.290148 ; AGGTCATAGCCTGACC-1-placenta_314 -0.115585 -0.119107 -0.434686 -0.303945 ; TTTATGCCAAAGGGTC-1-placenta_314 -0.112876 -0.116316 -0.424515 -0.296827 ; ```. ```pytb; Unable to create attribute (object header message is too large). Above error raised while writing key 'pearson_residuals_df' of <class 'h5py._hl.group.Group'> to /; ```. #### Versions. <details>. scanpy==1.9.1 anndata==0.8.0 umap==0.5.2 numpy==1.21.5 scipy==1.8.0 pandas==1.4.1 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.9.9 pynndescent==0.5.6. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2383
https://github.com/scverse/scanpy/pull/2384:613,Availability,down,downstream,613,"### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**; - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**; - Subset of genes defined by `var_names` is now used. **In addition:**; - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix.; - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis).; - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`; - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct.; - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384
https://github.com/scverse/scanpy/pull/2384:653,Availability,error,error,653,"### Bug: `var_names` -parameter for `sc.tl.dendrogram` -function is not used properly. **Currently:**; - Hierarchical clustering is calculated on **all** of the var_names (genes) when `var_names is not None`. **Fix:**; - Subset of genes defined by `var_names` is now used. **In addition:**; - When all of the values of some row of `rep_df` (or `mean_df`) are equal, `df.T.corr()` is not defined for that row resulting in `NaNs` in correlation matrix.; - This is quite common with a subset of genes `var_names`, e.g. all `0` in all cells (these cells have already passed quality control/filtering at this point of downstream analysis).; - This throws an error in `distance.squareform(1-corr_matrix)`: `ValueError: Distance matrix 'X' must be symmetric.`; - Fix: In this case add 'dummy' feature `rep_df[""dummy""] = -1` to make sure that at least one feature in a row is distinct.; - Notice, this addition affects (increases) the correlation between the rows. However, it should affect all rows equally and hence the hierarchy stays as is.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2384
https://github.com/scverse/scanpy/issues/2385:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [X] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; Is it possible to impliment [PyDESeq2](https://github.com/owkin/PyDESeq2) in `scanpy`; Thanks,; Shams",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2385
https://github.com/scverse/scanpy/issues/2386:942,Availability,down,down,942,"Hello. I tried umap visualization by:. ```; sc.pp.normalize_total(adata, target_sum=1e6); sc.pp.log1p(adata, base=2); sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None); sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0); sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'); ```; But the cells can't separate well; ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version; ```; anndata 0.7.5; scanpy 1.6.1; ```. I tried another small dataset with `scanpy` using the same parameters as before:; ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```; import umap; import umap.plot; mapper = umap.UMAP().fit(adata.X); umap.plot.points(mapper); ```. Now the original `umap` package can do down dimension very well:; ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason?; Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:1245,Availability,down,down,1245,"Hello. I tried umap visualization by:. ```; sc.pp.normalize_total(adata, target_sum=1e6); sc.pp.log1p(adata, base=2); sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None); sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0); sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'); ```; But the cells can't separate well; ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version; ```; anndata 0.7.5; scanpy 1.6.1; ```. I tried another small dataset with `scanpy` using the same parameters as before:; ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```; import umap; import umap.plot; mapper = umap.UMAP().fit(adata.X); umap.plot.points(mapper); ```. Now the original `umap` package can do down dimension very well:; ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason?; Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2386:1032,Usability,learn,learn,1032,"Hello. I tried umap visualization by:. ```; sc.pp.normalize_total(adata, target_sum=1e6); sc.pp.log1p(adata, base=2); sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=400). sc.pp.scale(adata, zero_center=True, max_value=None, copy=False, layer=None, obsm=None); sc.pp.pca(adata, n_comps=50, use_highly_variable=True, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=50). sc.tl.umap(adata, min_dist=0.5, spread=1.0); sc.pl.umap(adata, color='fullname', use_raw=False, save='samples_umap.pdf'); ```; But the cells can't separate well; ![image](https://user-images.githubusercontent.com/33963919/209233854-db64fddd-4266-4f87-805b-dced45b1547f.png). version; ```; anndata 0.7.5; scanpy 1.6.1; ```. I tried another small dataset with `scanpy` using the same parameters as before:; ![1](https://user-images.githubusercontent.com/33963919/209387824-3a5b1037-f226-49c8-9222-f54c04a62155.jpg). `sc.tl.umap` still failed to down dimension the data properly. Then I tried the original [`umap` package](https://umap-learn.readthedocs.io/en/latest/plotting.html) using the same data set:. ```; import umap; import umap.plot; mapper = umap.UMAP().fit(adata.X); umap.plot.points(mapper); ```. Now the original `umap` package can do down dimension very well:; ![2](https://user-images.githubusercontent.com/33963919/209387903-0161dfa6-0ca5-48cc-8661-465930e23fef.jpg). I think there may be something wrong with the `umap` function in `scanpy`. Can anyone please let me know the reason?; Thanks a lot.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2386
https://github.com/scverse/scanpy/issues/2389:487,Availability,down,downstream,487,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:; Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning.; pp.normalize_total() normalized my .layers['counts'] as well; The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but; such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()); print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""); sc.pp.normalize_total(adata, target_sum=1e4); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too; print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:5796,Deployability,update,updated,5796,"m of count layer of MALAT1 in cell: (0, 0)	289.61862; .X value of MALAT1 in cell: (0, 0)	289.61862; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; anndata2ri 1.1; annoy NA; backcall 0.2.0; backports NA; bbknn NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; cloudpickle 2.2.0; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2022.02.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; deprecated 1.2.13; entrypoints 0.4; fsspec 2022.11.0; future_fstrings NA; google NA; h5py 3.7.0; igraph 0.9.1; ipykernel 6.14.0; ipython_genutils 0.2.0; ipywidgets 8.0.2; jedi 0.18.1; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.8.10; llvmlite 0.39.1; louvain 0.7.2; markupsafe 2.1.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; numba 0.56.3; numpy 1.21.6; packaging 21.3; pandas 1.3.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.31; psutil 5.9.3; ptyprocess 0.7.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pynndescent 0.5.7; pyparsing 3.0.9; pytz 2022.5; pytz_deprecation_shim NA; rpy2 3.5.1; scib 1.0.4; scipy 1.7.3; seaborn 0.12.1; session_info 1.0.0; six 1.16.0; sklearn 1.0.2; statsmodels 0.13.2; storemagic NA; texttable 1.6.4; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; tornado 6.2; tqdm 4.64.1; traitlets 5.5.0; typing_extensions NA; tzlocal NA; umap 0.5.3; wcwidth 0.2.5; wrapt 1.14.1; yaml 6.0; zipp NA; zmq 24.0.1; zope NA; -----; IPython 7.33.0; jupyter_client 7.4.4; jupyter_core 4.11.1; notebook 6.5.1; -----; Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]; Linux-5.4.0-131-generic-x86_64-with-debian-buster-sid; -----; Session information updated at 2022-12-28 13:52; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:5483,Integrability,wrap,wrapt,5483,"m of count layer of MALAT1 in cell: (0, 0)	289.61862; .X value of MALAT1 in cell: (0, 0)	289.61862; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; anndata2ri 1.1; annoy NA; backcall 0.2.0; backports NA; bbknn NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; cloudpickle 2.2.0; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2022.02.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; deprecated 1.2.13; entrypoints 0.4; fsspec 2022.11.0; future_fstrings NA; google NA; h5py 3.7.0; igraph 0.9.1; ipykernel 6.14.0; ipython_genutils 0.2.0; ipywidgets 8.0.2; jedi 0.18.1; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.8.10; llvmlite 0.39.1; louvain 0.7.2; markupsafe 2.1.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; numba 0.56.3; numpy 1.21.6; packaging 21.3; pandas 1.3.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.31; psutil 5.9.3; ptyprocess 0.7.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pynndescent 0.5.7; pyparsing 3.0.9; pytz 2022.5; pytz_deprecation_shim NA; rpy2 3.5.1; scib 1.0.4; scipy 1.7.3; seaborn 0.12.1; session_info 1.0.0; six 1.16.0; sklearn 1.0.2; statsmodels 0.13.2; storemagic NA; texttable 1.6.4; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; tornado 6.2; tqdm 4.64.1; traitlets 5.5.0; typing_extensions NA; tzlocal NA; umap 0.5.3; wcwidth 0.2.5; wrapt 1.14.1; yaml 6.0; zipp NA; zmq 24.0.1; zope NA; -----; IPython 7.33.0; jupyter_client 7.4.4; jupyter_core 4.11.1; notebook 6.5.1; -----; Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]; Linux-5.4.0-131-generic-x86_64-with-debian-buster-sid; -----; Session information updated at 2022-12-28 13:52; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:618,Modifiability,layers,layers,618,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:; Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning.; pp.normalize_total() normalized my .layers['counts'] as well; The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but; such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()); print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""); sc.pp.normalize_total(adata, target_sum=1e4); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too; print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:1004,Modifiability,layers,layers,1004,"cked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:; Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning.; pp.normalize_total() normalized my .layers['counts'] as well; The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but; such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()); print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""); sc.pp.normalize_total(adata, target_sum=1e4); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too; print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:1385,Modifiability,layers,layers,1385," reproduce your bug. Hi, everyone:; Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning.; pp.normalize_total() normalized my .layers['counts'] as well; The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but; such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()); print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""); sc.pp.normalize_total(adata, target_sum=1e4); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too; print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:1619,Modifiability,layers,layers,1619,"'] as well; The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but; such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()); print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""); sc.pp.normalize_total(adata, target_sum=1e4); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too; print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""); sc.pp.normalize_total(adata, target_sum=1e4, layer = None); print('su",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:1859,Modifiability,layers,layers,1859,"# Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()); print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""); sc.pp.normalize_total(adata, target_sum=1e4); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too; print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""); sc.pp.normalize_total(adata, target_sum=1e4, layer = None); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()); print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:2122,Modifiability,layers,layers,2122," of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()); print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""); sc.pp.normalize_total(adata, target_sum=1e4); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too; print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""); sc.pp.normalize_total(adata, target_sum=1e4, layer = None); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()); print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X); ```. ```pytb; #Output:; Run 1: initial values after simple processing: ; sum of count layer in designated cell: 4903.0; obs[total_cou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:2240,Modifiability,layers,layers,2240,"lace=True). print(""Run 1: initial values after simple processing: ""); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()); print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""); sc.pp.normalize_total(adata, target_sum=1e4); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too; print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""); sc.pp.normalize_total(adata, target_sum=1e4, layer = None); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()); print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X); ```. ```pytb; #Output:; Run 1: initial values after simple processing: ; sum of count layer in designated cell: 4903.0; obs[total_counts] value in cell: 4903.0; .X.sum() value in cell: 4903.0; sum of count layer of MALAT1 in cell: (0, 0)	142.0; .X va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:2687,Modifiability,layers,layers,2687,"].X). print(""\nRun 2: after sc.pp.normalize_total: ""); sc.pp.normalize_total(adata, target_sum=1e4); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too; print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""); sc.pp.normalize_total(adata, target_sum=1e4, layer = None); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()); print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X); ```. ```pytb; #Output:; Run 1: initial values after simple processing: ; sum of count layer in designated cell: 4903.0; obs[total_counts] value in cell: 4903.0; .X.sum() value in cell: 4903.0; sum of count layer of MALAT1 in cell: (0, 0)	142.0; .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: ; normalizing counts per cell; finished (0:00:00); sum of count layer in designated cell: 10000.049; obs[total_counts] value in cell: 4903.0; .X.sum() value in cell: 10000.049; sum of count layer of MALAT1 in cell: (0, 0)	289.61862; .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None; normalizing counts per cell; finished ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:2921,Modifiability,layers,layers,2921,"ts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""); sc.pp.normalize_total(adata, target_sum=1e4, layer = None); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()); print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X); ```. ```pytb; #Output:; Run 1: initial values after simple processing: ; sum of count layer in designated cell: 4903.0; obs[total_counts] value in cell: 4903.0; .X.sum() value in cell: 4903.0; sum of count layer of MALAT1 in cell: (0, 0)	142.0; .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: ; normalizing counts per cell; finished (0:00:00); sum of count layer in designated cell: 10000.049; obs[total_counts] value in cell: 4903.0; .X.sum() value in cell: 10000.049; sum of count layer of MALAT1 in cell: (0, 0)	289.61862; .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None; normalizing counts per cell; finished (0:00:00); sum of count layer in designated cell: 10000.049; obs[total_counts] value in cell: 4903.0; .X.sum() value in cell: 10000.049; sum of count layer of MALAT1 in cell: (0, 0)	289.61862; .X value of MALAT1 in cell: (0, 0)	289.61862; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:3994,Testability,log,logging,3994,".X); ```. ```pytb; #Output:; Run 1: initial values after simple processing: ; sum of count layer in designated cell: 4903.0; obs[total_counts] value in cell: 4903.0; .X.sum() value in cell: 4903.0; sum of count layer of MALAT1 in cell: (0, 0)	142.0; .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: ; normalizing counts per cell; finished (0:00:00); sum of count layer in designated cell: 10000.049; obs[total_counts] value in cell: 4903.0; .X.sum() value in cell: 10000.049; sum of count layer of MALAT1 in cell: (0, 0)	289.61862; .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None; normalizing counts per cell; finished (0:00:00); sum of count layer in designated cell: 10000.049; obs[total_counts] value in cell: 4903.0; .X.sum() value in cell: 10000.049; sum of count layer of MALAT1 in cell: (0, 0)	289.61862; .X value of MALAT1 in cell: (0, 0)	289.61862; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; anndata2ri 1.1; annoy NA; backcall 0.2.0; backports NA; bbknn NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; cloudpickle 2.2.0; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2022.02.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; deprecated 1.2.13; entrypoints 0.4; fsspec 2022.11.0; future_fstrings NA; google NA; h5py 3.7.0; igraph 0.9.1; ipykernel 6.14.0; ipython_genutils 0.2.0; ipywidgets 8.0.2; jedi 0.18.1; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.8.10; llvmlite 0.39.1; louvain 0.7.2; markupsafe 2.1.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; numba 0.56.3; numpy 1.21.6; packaging 21.3; pandas 1.3.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.31; psutil 5.9.3; ptyprocess 0.7.0; pycparser 2.21; pydev_ipython NA; p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:; Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning.; pp.normalize_total() normalized my .layers['counts'] as well; The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but; such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()); print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""); sc.pp.normalize_total(adata, target_sum=1e4); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too; print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:1299,Usability,simpl,simple,1299,"reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, everyone:; Many users probably do not rely on pp.normalize_total for downstream analysis, but I found a strange default behavior that I think is worth mentioning.; pp.normalize_total() normalized my .layers['counts'] as well; The documentation is a bit murky; not sure if that is the expected behavior when layer is unspecified, but; such default behavior would undermine anyone who wishes to save the count information before RPKM normalization. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""Run 1: initial values after simple processing: ""); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()); print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). print(""\nRun 2: after sc.pp.normalize_total: ""); sc.pp.normalize_total(adata, target_sum=1e4); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()) # Note that this changed too; print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2389:3055,Usability,simpl,simple,3055," of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X). adata = sc.datasets.pbmc3k(); adata.layers['counts'] = adata.X; cell = adata.obs.index[1]; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). print(""\nRun 3: normalization, specifing argument layer=None""); sc.pp.normalize_total(adata, target_sum=1e4, layer = None); print('sum of count layer in designated cell: ', adata[cell,:].layers['counts'].sum()); print('obs[total_counts] value in cell: ', adata[cell,:].obs['total_counts'][0]); print('.X.sum() value in cell: ', adata[cell,:].X.sum()); print('sum of count layer of MALAT1 in cell: ', adata[cell,'MALAT1'].layers['counts']); print('.X value of MALAT1 in cell: ', adata[cell,'MALAT1'].X); ```. ```pytb; #Output:; Run 1: initial values after simple processing: ; sum of count layer in designated cell: 4903.0; obs[total_counts] value in cell: 4903.0; .X.sum() value in cell: 4903.0; sum of count layer of MALAT1 in cell: (0, 0)	142.0; .X value of MALAT1 in cell: (0, 0)	142.0. Run 2: after sc.pp.normalize_total: ; normalizing counts per cell; finished (0:00:00); sum of count layer in designated cell: 10000.049; obs[total_counts] value in cell: 4903.0; .X.sum() value in cell: 10000.049; sum of count layer of MALAT1 in cell: (0, 0)	289.61862; .X value of MALAT1 in cell: (0, 0)	289.61862. Run 3: normalization, specifing argument layer=None; normalizing counts per cell; finished (0:00:00); sum of count layer in designated cell: 10000.049; obs[total_counts] value in cell: 4903.0; .X.sum() value in cell: 10000.049; sum of count layer of MALAT1 in cell: (0, 0)	289.61862; .X value of MALAT1 in cell: (0, 0)	289.61862; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2389
https://github.com/scverse/scanpy/issues/2391:437,Availability,error,error,437,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python; healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'); ```. I calculated qc metrics with this command.; ```python; sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True); ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") ; ```; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/ipykernel_1314047/3602867448.py in <module>; ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs); 1009 show=False,; 1010 save=False,; -> 1011 **kwargs,; 1012 ); 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:2914,Availability,error,error,2914,"ng(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 397 rasterized=settings._vector_friendly,; 398 norm=normalize,; --> 399 **kwargs,; 400 ); 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs); 1106 # while you can only set `facecolors` with a value for all.; 1107 if scale_factor != 1.0:; -> 1108 x = x * scale_factor; 1109 y = y * scale_factor; 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'; ```; Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; annoy NA; asciitree NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; cloudpickle 2.2.0; cycler 0.10.0; cython_runtime NA; dask 2022.02.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; fbpca NA; fsspec 2022.11.0; google NA; h5py 3.7.0; igraph 0.10.2; intervaltree NA; ipykernel 6.16.2; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.1; matplotli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3071,Availability,error,error,3071,"na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 397 rasterized=settings._vector_friendly,; 398 norm=normalize,; --> 399 **kwargs,; 400 ); 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs); 1106 # while you can only set `facecolors` with a value for all.; 1107 if scale_factor != 1.0:; -> 1108 x = x * scale_factor; 1109 y = y * scale_factor; 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'; ```; Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; annoy NA; asciitree NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; cloudpickle 2.2.0; cycler 0.10.0; cython_runtime NA; dask 2022.02.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; fbpca NA; fsspec 2022.11.0; google NA; h5py 3.7.0; igraph 0.10.2; intervaltree NA; ipykernel 6.16.2; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; mpl_toolkits NA; msgpack 1.0.4; natsort 8.2.0; nbinom_ufunc NA; numba 0.56.4; numcodecs 0.10.2; numpy 1.21.6; packaging 22.0; pandas 1.3.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3121,Availability,error,error,3121,"na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 397 rasterized=settings._vector_friendly,; 398 norm=normalize,; --> 399 **kwargs,; 400 ); 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs); 1106 # while you can only set `facecolors` with a value for all.; 1107 if scale_factor != 1.0:; -> 1108 x = x * scale_factor; 1109 y = y * scale_factor; 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'; ```; Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; annoy NA; asciitree NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; cloudpickle 2.2.0; cycler 0.10.0; cython_runtime NA; dask 2022.02.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; fbpca NA; fsspec 2022.11.0; google NA; h5py 3.7.0; igraph 0.10.2; intervaltree NA; ipykernel 6.16.2; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; mpl_toolkits NA; msgpack 1.0.4; natsort 8.2.0; nbinom_ufunc NA; numba 0.56.4; numcodecs 0.10.2; numpy 1.21.6; packaging 22.0; pandas 1.3.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:4974,Deployability,update,updated,4974," same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; annoy NA; asciitree NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; cloudpickle 2.2.0; cycler 0.10.0; cython_runtime NA; dask 2022.02.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; fbpca NA; fsspec 2022.11.0; google NA; h5py 3.7.0; igraph 0.10.2; intervaltree NA; ipykernel 6.16.2; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; mpl_toolkits NA; msgpack 1.0.4; natsort 8.2.0; nbinom_ufunc NA; numba 0.56.4; numcodecs 0.10.2; numpy 1.21.6; packaging 22.0; pandas 1.3.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.36; psutil 5.9.3; ptyprocess 0.7.0; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pyparsing 3.0.9; pytz 2022.7; scanorama 1.7.1; scipy 1.7.3; seaborn 0.12.1; session_info 1.0.0; setuptools 65.6.3; six 1.16.0; sklearn 1.0.2; sortedcontainers 2.4.0; statsmodels 0.13.5; storemagic NA; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; tornado 6.2; traitlets 5.8.0; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zarr 2.12.0; zipp NA; zmq 24.0.1; -----; IPython 7.33.0; jupyter_client 7.4.8; jupyter_core 4.11.1; jupyterlab 3.5.2; notebook 6.5.2; -----; Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]; Linux-5.4.0-121-generic-x86_64-with-debian-bullseye-sid; -----; Session information updated at 2022-12-28 21:40; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3019,Integrability,message,message,3019,"ows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 397 rasterized=settings._vector_friendly,; 398 norm=normalize,; --> 399 **kwargs,; 400 ); 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs); 1106 # while you can only set `facecolors` with a value for all.; 1107 if scale_factor != 1.0:; -> 1108 x = x * scale_factor; 1109 y = y * scale_factor; 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'; ```; Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; annoy NA; asciitree NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; cloudpickle 2.2.0; cycler 0.10.0; cython_runtime NA; dask 2022.02.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; fbpca NA; fsspec 2022.11.0; google NA; h5py 3.7.0; igraph 0.10.2; intervaltree NA; ipykernel 6.16.2; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; mpl_toolkits NA; msgpack 1.0.4; natsort 8.2.0; nbinom_ufunc NA; numba 0.56.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:3127,Integrability,message,message,3127,"na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 397 rasterized=settings._vector_friendly,; 398 norm=normalize,; --> 399 **kwargs,; 400 ); 401 . ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_utils.py in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs); 1106 # while you can only set `facecolors` with a value for all.; 1107 if scale_factor != 1.0:; -> 1108 x = x * scale_factor; 1109 y = y * scale_factor; 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'; ```; Bascially, the same type of error keeps showing up no matter what the `color = ` parameter is. I put a gene name there, and the same message showed up. Additional information about the error (the image that showed up together with the error message from the jupyter notebook cell): ![image](https://user-images.githubusercontent.com/78611089/209900312-f6acd040-93e5-43b8-858d-3d1ef0c91cd0.png). #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.2.0; annoy NA; asciitree NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; cloudpickle 2.2.0; cycler 0.10.0; cython_runtime NA; dask 2022.02.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; fbpca NA; fsspec 2022.11.0; google NA; h5py 3.7.0; igraph 0.10.2; intervaltree NA; ipykernel 6.16.2; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; mpl_toolkits NA; msgpack 1.0.4; natsort 8.2.0; nbinom_ufunc NA; numba 0.56.4; numcodecs 0.10.2; numpy 1.21.6; packaging 22.0; pandas 1.3.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2391:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. It is hard to show the error without my data, but here it is what I did. I read in my 10 visium data (output from SpaceRanger 2.0.0) and everything seems fine. All I had to do was to change a file name (tissue_positions.csv to tissue_positions_list.csv) in my `outs/spatial` folder. ```python; healthy_A1 = sc.read_visium('../data/MGI3535_A1_010322NHK/outs/', count_file='raw_feature_bc_matrix.h5'); ```. I calculated qc metrics with this command.; ```python; sc.pp.calculate_qc_metrics(healthy_A1, percent_top=None, log1p=False, inplace=True); ```. But then, the problem occurs when I try to use scanpy.pl.spatial. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""total_counts"") ; ```; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/ipykernel_1314047/3602867448.py in <module>; ----> 1 sc.pl.spatial(healthy_A1, img_key = ""hires"", color = ""ACTA2""). ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs); 1009 show=False,; 1010 save=False,; -> 1011 **kwargs,; 1012 ); 1013 if not isinstance(axs, list):. ~/.conda/envs/python_spatial/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2391
https://github.com/scverse/scanpy/issues/2393:542,Availability,error,error,542,- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:648,Testability,log,logging,648,- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2393:257,Usability,guid,guide,257,- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2393
https://github.com/scverse/scanpy/issues/2396:655,Availability,error,errors,655,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; pbmc = sc.datasets.pbmc3k(); log_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""); ```. ```pytb; >>> import scanpy as sc; g_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1537,Availability,error,errors,1537,"p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""); ```. ```pytb; >>> import scanpy as sc; g_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True); >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(); >>> ; >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; >>> # ValueError: cannot specify integer `bins` when input d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2431,Availability,error,errors,2431,"mc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True); >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(); >>> ; >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; >>> # ValueError: cannot specify integer `bins` when input data contains infinity; >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False); .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes; df = _highly_variable_genes_single_batch(; File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins); File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut; raise ValueError(; ValueError: cannot specify integer `bins` when input data contains infinity; >>> ; >>> # This",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:6114,Deployability,update,updated,6114,"-12 NaN (-0.00411, 0.205] 0.0 False; 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]; >>> ; >>> # This raises ValueError again; >>> pbmc.obs['batch'] = 'A'; >>> column_index = pbmc.obs.columns.get_indexer(['batch']); >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""); .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes; hvg = _highly_variable_genes_single_batch(; File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins); File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut; raise ValueError(; ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.3.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; google NA; h5py 3.7.0; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.39.1; matplotlib 3.6.2; mpl_toolkits NA; natsort 8.2.0; numba 0.56.4; numpy 1.23.5; packaging 22.0; pandas 1.5.2; psutil 5.9.4; pyarrow 10.0.1; pyparsing 3.0.9; pytz 2022.7; scipy 1.9.3; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.2.0; threadpoolctl 3.1.0; typing_extensions NA; yaml 6.0; zoneinfo NA; -----; Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]; Linux-5.15.0-57-generic-x86_64-with-glibc2.35; -----; Session information updated at 2023-01-09 18:53. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:598,Modifiability,layers,layers,598,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; pbmc = sc.datasets.pbmc3k(); log_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""); ```. ```pytb; >>> import scanpy as sc; g_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1480,Modifiability,layers,layers,1480,"mport scanpy as sc; pbmc = sc.datasets.pbmc3k(); log_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""); ```. ```pytb; >>> import scanpy as sc; g_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True); >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(); >>> ; >>> # This errors, because X is not normalized and flavor=""seurat"" requires norm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:2364,Modifiability,layers,layers,2364,"""batch""); ```. ```pytb; >>> import scanpy as sc; g_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True); >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(); >>> ; >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; >>> # ValueError: cannot specify integer `bins` when input data contains infinity; >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False); .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes; df = _highly_variable_genes_single_batch(; File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins); File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut; raise ValueError(; ValueError: cannot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:920,Testability,log,log,920,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; pbmc = sc.datasets.pbmc3k(); log_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""); ```. ```pytb; >>> import scanpy as sc; g_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:1802,Testability,log,log,1802,"ins infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""); ```. ```pytb; >>> import scanpy as sc; g_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch"")>>> pbmc = sc.datasets.pbmc3k(). >>> log_anndata = sc.pp.log1p(pbmc, copy=True); >>> pbmc.layers['log_transformed'] = log_anndata.X.copy(); >>> ; >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; >>> # ValueError: cannot specify integer `bins` when input data contains infinity; >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False); .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1; result = op(s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:3475,Testability,log,log,3475,">>> ; >>> # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; >>> # ValueError: cannot specify integer `bins` when input data contains infinity; >>> sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False); .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 434, in highly_variable_genes; df = _highly_variable_genes_single_batch(; File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins); File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut; raise ValueError(; ValueError: cannot specify integer `bins` when input data contains infinity; >>> ; >>> # This works, we pass log tranformed data; >>> pbmc.uns['log1p'] = log_anndata.uns['log1p']; >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False); means dispersions mean_bin dispersions_norm highly_variable; 0 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False; 1 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False; 2 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False; 3 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False; 4 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False; ... ... ... ... ... ...; 32733 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False; 32734 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False; 32735 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False; 32736 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False; 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]; >>> ; >>> # This raises ValueError again; >>> pbmc.obs['batch'] = 'A'; >>> column_index = pbmc.obs.columns.get_indexer(['batch']); >>> pbmc.obs.ilo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:5417,Testability,log,logging,5417,"-12 NaN (-0.00411, 0.205] 0.0 False; 32737 1.000000e-12 NaN (-0.00411, 0.205] 0.0 False. [32738 rows x 5 columns]; >>> ; >>> # This raises ValueError again; >>> pbmc.obs['batch'] = 'A'; >>> column_index = pbmc.obs.columns.get_indexer(['batch']); >>> pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; >>> sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""); .venv/lib/python3.10/site-packages/scipy/sparse/_data.py:133: RuntimeWarning: overflow encountered in expm1; result = op(self._deduped_data()); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 459, in highly_variable_genes; hvg = _highly_variable_genes_single_batch(; File "".venv/lib/python3.10/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 215, in _highly_variable_genes_single_batch; df['mean_bin'] = pd.cut(df['means'], bins=n_bins); File "".venv/lib/python3.10/site-packages/pandas/core/reshape/tile.py"", line 263, in cut; raise ValueError(; ValueError: cannot specify integer `bins` when input data contains infinity. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.3.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; google NA; h5py 3.7.0; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.39.1; matplotlib 3.6.2; mpl_toolkits NA; natsort 8.2.0; numba 0.56.4; numpy 1.23.5; packaging 22.0; pandas 1.5.2; psutil 5.9.4; pyarrow 10.0.1; pyparsing 3.0.9; pytz 2022.7; scipy 1.9.3; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.2.0; threadpoolctl 3.1.0; typing_extensions NA; yaml 6.0; zoneinfo NA; -----; Python 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]; Linux-5.15.0-57-generic-x86_64-with-glibc2.35; -----; Session information updated at 2023-01-09 18:53. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/issues/2396:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; pbmc = sc.datasets.pbmc3k(); log_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError again; pbmc.obs['batch'] = 'A'; column_index = pbmc.obs.columns.get_indexer(['batch']); pbmc.obs.iloc[slice(pbmc.n_obs//2, None), column_index] = 'B'; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False, batch_key=""batch""); ```. ```pytb; >>> import scanpy as sc; g_anndata = sc.pp.log1p(pbmc, copy=True); pbmc.layers['log_transformed'] = log_anndata.X.copy(). # This errors, because X is not normalized and flavor=""seurat"" requires normalizes data.; # ValueError: cannot specify integer `bins` when input data contains infinity; sc.pp.highly_variable_genes(pbmc, flavor=""seurat"", subset=False, inplace=False). # This works, we pass log tranformed data; pbmc.uns['log1p'] = log_anndata.uns['log1p']; sc.pp.highly_variable_genes(pbmc, layer=""log_transformed"", flavor=""seurat"", subset=False, inplace=False). # This raises ValueError a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2396
https://github.com/scverse/scanpy/pull/2397:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2397
https://github.com/scverse/scanpy/pull/2397:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2397
https://github.com/scverse/scanpy/issues/2399:218,Deployability,update,updated,218,"Hi all, I have some pseudo counts data, which containing value like 0.5, and if I run sc.pp.filter_cells based on this dataset, the filtered number of cells is very low. I wonder if the codes of sc.pp.filter_cells are updated or not, and how to handle such pseudo counts scRNA-seq data based on scanpy. Thanks a lot. The dataset I used is https://portal.hubmapconsortium.org/browse/dataset/fd57a928d9f3cee7e95d284f1d5b9935",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2399
https://github.com/scverse/scanpy/pull/2400:0,Deployability,Update,Update,0,Update policy for external tools and point to scverse ecosystem packages instead.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2400
https://github.com/scverse/scanpy/issues/2401:350,Availability,error,error,350,"- [x ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; `_set_colors_for_categorical_obs` copies adata if it is a view (e.g. rows/cells are reordered for plotting), leading to error in plotting. The below fails as adata is view (reordered cells) and color of 'CellType' is not in uns; However, if we first run the plot without reordering cells so that uns color is set on adata and then reorder the cells and plot the view, this works; ```. random_indices=np.random.permutation(adatas['Human'].obs_names); sc.pl.embedding(adatas['Human'][random_indices,:],ACTIONet2D',; color=['CellType'],hspace=0.9); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-48-8a1d75e9b375> in <module>; 2 np.random.seed(0); 3 random_indices=np.random.permutation(adatas['Human'].obs_names); ----> 4 sc.pl.embedding(adatas['Human'][random_indices,:],'ACTIONet2D',; 5 color=['Batch','Region','Condition', 'Grade', ; 6 'PMI','Sex', 'Age','SubType','CellType'],hspace=0.9). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 250 groups=groups,; 251 ); --> 252 color_vector, categorical = _color_vector(; 253 adata,; 254 value_to_plot,. ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:4061,Energy Efficiency,reduce,reduce,4061,", values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot); 468 ); 469 ; --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]); 471 ; 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette); 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]; 429 ; --> 430 adata.uns[value_to_plot + '_colors'] = colors_list; 431 ; 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value); 104 self.overloaded[key].set(value); 105 else:; --> 106 self.data[key] = value; 107 ; 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value); 32 stacklevel=2,; 33 ); ---> 34 with self._update() as container:; 35 container[idx] = value; 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self); 111 del self.args, self.kwds, self.func; 112 try:; --> 113 return next(self.gen); 114 except StopIteration:; 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self); 38 def _update(self):; 39 adata_view, attr_name, keys = self._view_args; ---> 40 new = adata_view.copy(); 41 attr = getattr(new, attr_name); 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename); 1526 ; 1527 if filename is None:; -> 1528 raise ValueError(; 1529 ""To copy an AnnData object in backed mode, ""; 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. #### Versions. Scanpy: 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2401:4486,Performance,load,load,4486,", values_key). ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_default_colors_for_categorical_obs(adata, value_to_plot); 468 ); 469 ; --> 470 _set_colors_for_categorical_obs(adata, value_to_plot, palette[:length]); 471 ; 472 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/scanpy/plotting/_utils.py in _set_colors_for_categorical_obs(adata, value_to_plot, palette); 428 colors_list = [to_hex(next(cc)['color']) for x in range(len(categories))]; 429 ; --> 430 adata.uns[value_to_plot + '_colors'] = colors_list; 431 ; 432 . ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/compat/_overloaded_dict.py in __setitem__(self, key, value); 104 self.overloaded[key].set(value); 105 else:; --> 106 self.data[key] = value; 107 ; 108 def __delitem__(self, key):. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in __setitem__(self, idx, value); 32 stacklevel=2,; 33 ); ---> 34 with self._update() as container:; 35 container[idx] = value; 36 . ~/miniconda3/envs/csp/lib/python3.8/contextlib.py in __enter__(self); 111 del self.args, self.kwds, self.func; 112 try:; --> 113 return next(self.gen); 114 except StopIteration:; 115 raise RuntimeError(""generator didn't yield"") from None. ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/views.py in _update(self); 38 def _update(self):; 39 adata_view, attr_name, keys = self._view_args; ---> 40 new = adata_view.copy(); 41 attr = getattr(new, attr_name); 42 container = reduce(lambda d, k: d[k], keys, attr). ~/miniconda3/envs/csp/lib/python3.8/site-packages/anndata/_core/anndata.py in copy(self, filename); 1526 ; 1527 if filename is None:; -> 1528 raise ValueError(; 1529 ""To copy an AnnData object in backed mode, ""; 1530 ""pass a filename: `.copy(filename='myfilename.h5ad')`. "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. #### Versions. Scanpy: 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2401
https://github.com/scverse/scanpy/issues/2402:1138,Availability,error,error,1138,"x that contains 8 samples to analyze. My goal is to read count matrix as AnnData object. I am transposing the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). . ```python; # Read the count matrix ; adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names; adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]; adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names; sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample; for sample in sample_list:; sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```; However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. ; ```pytb; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); Input In [5], in <cell line: 2>(); 1 # iterate through the sample names and create a new AnnData object for each sample; 2 for sample in sample_list:; ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index); 1111 def __getitem__(self, index: Index) -> ""AnnData"":; 1112 """"""Returns a sliced view of the object.""""""; -> 1113 oidx, vidx = self._normalize_indices(index); 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index); 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1094 return _nor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3235,Availability,error,error,3235,"Data object for each sample; 2 for sample in sample_list:; ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index); 1111 def __getitem__(self, index: Index) -> ""AnnData"":; 1112 """"""Returns a sliced view of the object.""""""; -> 1113 oidx, vidx = self._normalize_indices(index); 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index); 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1); 34 ax0, ax1 = unpack_index(index); 35 ax0 = _normalize_index(ax0, names0); ---> 36 ax1 = _normalize_index(ax1, names1); 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index); 88 elif issubclass(indexer.dtype.type, np.bool_):; 89 if indexer.shape != index.shape:; ---> 90 raise IndexError(; 91 f""Boolean index does not match AnnDatas shape along this ""; 92 f""dimension. Boolean index has shape {indexer.shape} while ""; 93 f""AnnData index has shape {index.shape}.""; 94 ); 95 positions = np.where(indexer)[0]; 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```; I would appreciate any insights. Thank you so much! ; #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version; version('scanpy'). I got an output: '1.9.1'. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:1144,Integrability,message,message,1144,"x that contains 8 samples to analyze. My goal is to read count matrix as AnnData object. I am transposing the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). . ```python; # Read the count matrix ; adata = sc.read_text('/file_path').T #transposed the matrix because I wanted the rows to represent cells (5258) and the columns to represent genes (17143). adata #5258 cells, 17143 genes. # extract the sample name from the column names; adata.obs['sample_name'] = adata.obs.index.str.split('_').str[0]; adata.obs['barcode'] = adata.obs.index.str.split('_').str[1]. # create a list of the sample names; sample_list = ['Pb.F1', 'Pb.M1', 'Ctl.M1', 'Pb.F2', 'Ctl.F1', 'Pb.M2', 'Ctl.M2', 'Ctl.F2']. # iterate through the sample names and create a new AnnData object for each sample; for sample in sample_list:; sample_adata = adata[:, adata.obs['sample_name'] == sample]. ```; However when I run the code for ""iterate through the sample names and create a new AnnData object for each sample"" this is where an error message is generated. ; ```pytb; ---------------------------------------------------------------------------; IndexError Traceback (most recent call last); Input In [5], in <cell line: 2>(); 1 # iterate through the sample names and create a new AnnData object for each sample; 2 for sample in sample_list:; ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index); 1111 def __getitem__(self, index: Index) -> ""AnnData"":; 1112 """"""Returns a sliced view of the object.""""""; -> 1113 oidx, vidx = self._normalize_indices(index); 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index); 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1094 return _nor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3241,Integrability,message,message,3241,"Data object for each sample; 2 for sample in sample_list:; ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index); 1111 def __getitem__(self, index: Index) -> ""AnnData"":; 1112 """"""Returns a sliced view of the object.""""""; -> 1113 oidx, vidx = self._normalize_indices(index); 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index); 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1); 34 ax0, ax1 = unpack_index(index); 35 ax0 = _normalize_index(ax0, names0); ---> 36 ax1 = _normalize_index(ax1, names1); 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index); 88 elif issubclass(indexer.dtype.type, np.bool_):; 89 if indexer.shape != index.shape:; ---> 90 raise IndexError(; 91 f""Boolean index does not match AnnDatas shape along this ""; 92 f""dimension. Boolean index has shape {indexer.shape} while ""; 93 f""AnnData index has shape {index.shape}.""; 94 ); 95 positions = np.where(indexer)[0]; 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```; I would appreciate any insights. Thank you so much! ; #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version; version('scanpy'). I got an output: '1.9.1'. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2402:3149,Testability,log,logging,3149,"Data object for each sample; 2 for sample in sample_list:; ----> 3 sample_adata = adata[:, adata.obs['sample_name'] == sample]. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1113, in AnnData.__getitem__(self, index); 1111 def __getitem__(self, index: Index) -> ""AnnData"":; 1112 """"""Returns a sliced view of the object.""""""; -> 1113 oidx, vidx = self._normalize_indices(index); 1114 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/anndata.py:1094, in AnnData._normalize_indices(self, index); 1093 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1094 return _normalize_indices(index, self.obs_names, self.var_names). File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:36, in _normalize_indices(index, names0, names1); 34 ax0, ax1 = unpack_index(index); 35 ax0 = _normalize_index(ax0, names0); ---> 36 ax1 = _normalize_index(ax1, names1); 37 return ax0, ax1. File ~/opt/anaconda3/lib/python3.9/site-packages/anndata/_core/index.py:90, in _normalize_index(indexer, index); 88 elif issubclass(indexer.dtype.type, np.bool_):; 89 if indexer.shape != index.shape:; ---> 90 raise IndexError(; 91 f""Boolean index does not match AnnDatas shape along this ""; 92 f""dimension. Boolean index has shape {indexer.shape} while ""; 93 f""AnnData index has shape {index.shape}.""; 94 ); 95 positions = np.where(indexer)[0]; 96 return positions # np.ndarray[int]. IndexError: Boolean index does not match AnnDatas shape along this dimension. Boolean index has shape (5258,) while AnnData index has shape (17143,). ```; I would appreciate any insights. Thank you so much! ; #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. this code had a error message because scanpy wasn't defined, but when I ran . from importlib.metadata import version; version('scanpy'). I got an output: '1.9.1'. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2402
https://github.com/scverse/scanpy/issues/2404:944,Availability,error,errors,944,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy. ---; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ...; ...; test_data = sc.pp.regress_out(test_data,['n_count'], copy=True); sc.pp.scale(test_data); sc.tl.pca(test_data,n_comps=30, use_highly_variable=True); sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical; OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8; and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:733,Integrability,rout,routine,733,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy. ---; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ...; ...; test_data = sc.pp.regress_out(test_data,['n_count'], copy=True); sc.pp.scale(test_data); sc.tl.pca(test_data,n_comps=30, use_highly_variable=True); sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical; OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8; and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/issues/2404:174,Usability,guid,guide,174,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy. ---; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ...; ...; test_data = sc.pp.regress_out(test_data,['n_count'], copy=True); sc.pp.scale(test_data); sc.tl.pca(test_data,n_comps=30, use_highly_variable=True); sc.pp.neighbors(test_data,n_neighbors=20). ```. ```output print. ...storing 'feature_types' as categorical; OMP: Info #276:omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. ```. #### Versions. my python version is 3.8; and the versions of scanpy I have tried were 1.8.2 and 1.9.1. I guess that the reason inducing the errors was the version of python is too high. . How can I solve the problem?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2404
https://github.com/scverse/scanpy/pull/2405:143,Usability,guid,guidelines,143,Found some typos in the docstring. Also searched them in other places.; <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2405
https://github.com/scverse/scanpy/pull/2405:174,Usability,guid,guide,174,Found some typos in the docstring. Also searched them in other places.; <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2405
https://github.com/scverse/scanpy/issues/2406:93,Availability,Error,Error,93,"I have an issue similar to this https://github.com/lmcinnes/pynndescent/issues/133. Code and Error message::; ```; sc.tl.ingest(bdata,; lungreference,obs='new_celltype'; ); ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data); 486 # If key already exists, we will overwrite the file; --> 487 data_name = overloads[key]; 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last); /tmp/ipykernel_875/1088574315.py in <module>; 2 print(transgene); 3 bdata=adata[adata.obs.treatment==transgene]; ----> 4 sc.tl.ingest(bdata,; 5 lungreference,obs='new_celltype'; 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 128 ; 129 for method in embedd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:3855,Availability,error,errors,3855,"lon=epsilon; 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon); 1564 """"""; 1565 if not hasattr(self, ""_search_graph""):; -> 1566 self._init_search_graph(); 1567 ; 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self); 1054 ); 1055 else:; -> 1056 diversify_csr(; 1057 reverse_graph.indptr,; 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws); 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 433 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 434 raise e; 435 ; 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws); 365 argtypes.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 823 raise e.bind_fold_arguments(folded); 824 self.add_overload(cres); --> 825 self._cache.save_overload(sig, cres); 826 return cres.entry_point; 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data); 669 """"""; 670 with self._guard_against_spurious_io_errors():; --> 671 self._save_overload(sig, data); 672 ; 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data); 679 k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:4909,Energy Efficiency,reduce,reduce,4909,"ompile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 823 raise e.bind_fold_arguments(folded); 824 self.add_overload(cres); --> 825 self._cache.save_overload(sig, cres); 826 return cres.entry_point; 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data); 669 """"""; 670 with self._guard_against_spurious_io_errors():; --> 671 self._save_overload(sig, data); 672 ; 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data); 679 key = self._index_key(sig, _get_codegen(data)); 680 data = self._impl.reduce(data); --> 681 self._cache_file.save(key, data); 682 ; 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data); 494 break; 495 overloads[key] = data_name; --> 496 self._save_index(overloads); 497 self._save_data(data_name, data); 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads); 540 def _save_index(self, overloads):; 541 data = self._source_stamp, overloads; --> 542 data = self._dump(data); 543 with self._open_for_write(self._index_path) as f:; 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj); 568 ; 569 def _dump(self, obj):; --> 570 return pickle.dumps(obj, protocol=-1); 571 ; 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object; ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:99,Integrability,message,message,99,"I have an issue similar to this https://github.com/lmcinnes/pynndescent/issues/133. Code and Error message::; ```; sc.tl.ingest(bdata,; lungreference,obs='new_celltype'; ); ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data); 486 # If key already exists, we will overwrite the file; --> 487 data_name = overloads[key]; 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fbafd5a19d0>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'skylake-avx512', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,+avx512bw,+avx512cd,+avx512dq,-avx512er,+avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,+avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,+clflushopt,+clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,+pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,+xsavec,+xsaveopt,+xsaves'), ('447c56dc5e270e4f82ab71861b297ed6de3def7f442a5fd25f557203e9177f64', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last); /tmp/ipykernel_875/1088574315.py in <module>; 2 print(transgene); 3 bdata=adata[adata.obs.treatment==transgene]; ----> 4 sc.tl.ingest(bdata,; 5 lungreference,obs='new_celltype'; 6 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 128 ; 129 for method in embedd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5535,Integrability,protocol,protocol,5535,"ompile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 823 raise e.bind_fold_arguments(folded); 824 self.add_overload(cres); --> 825 self._cache.save_overload(sig, cres); 826 return cres.entry_point; 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data); 669 """"""; 670 with self._guard_against_spurious_io_errors():; --> 671 self._save_overload(sig, data); 672 ; 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data); 679 key = self._index_key(sig, _get_codegen(data)); 680 data = self._impl.reduce(data); --> 681 self._cache_file.save(key, data); 682 ; 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data); 494 break; 495 overloads[key] = data_name; --> 496 self._save_index(overloads); 497 self._save_data(data_name, data); 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads); 540 def _save_index(self, overloads):; 541 data = self._source_stamp, overloads; --> 542 data = self._dump(data); 543 with self._open_for_write(self._index_path) as f:; 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj); 568 ; 569 def _dump(self, obj):; --> 570 return pickle.dumps(obj, protocol=-1); 571 ; 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object; ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:5709,Integrability,protocol,protocol,5709,"ompile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 823 raise e.bind_fold_arguments(folded); 824 self.add_overload(cres); --> 825 self._cache.save_overload(sig, cres); 826 return cres.entry_point; 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save_overload(self, sig, data); 669 """"""; 670 with self._guard_against_spurious_io_errors():; --> 671 self._save_overload(sig, data); 672 ; 673 def _save_overload(self, sig, data):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_overload(self, sig, data); 679 key = self._index_key(sig, _get_codegen(data)); 680 data = self._impl.reduce(data); --> 681 self._cache_file.save(key, data); 682 ; 683 @contextlib.contextmanager. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save(self, key, data); 494 break; 495 overloads[key] = data_name; --> 496 self._save_index(overloads); 497 self._save_data(data_name, data); 498 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _save_index(self, overloads); 540 def _save_index(self, overloads):; 541 data = self._source_stamp, overloads; --> 542 data = self._dump(data); 543 with self._open_for_write(self._index_path) as f:; 544 pickle.dump(self._version, f, protocol=-1). ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in _dump(self, obj); 568 ; 569 def _dump(self, obj):; --> 570 return pickle.dumps(obj, protocol=-1); 571 ; 572 @contextlib.contextmanager. TypeError: cannot pickle 'weakref' object; ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2406:3528,Modifiability,config,config,3528,"ef map_embedding(self, method):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/umap/umap_.py in transform(self, X); 2715 else:; 2716 epsilon = 0.24 if self._knn_search_index._angular_trees else 0.12; -> 2717 indices, dists = self._knn_search_index.query(; 2718 X, self.n_neighbors, epsilon=epsilon; 2719 ). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon); 1564 """"""; 1565 if not hasattr(self, ""_search_graph""):; -> 1566 self._init_search_graph(); 1567 ; 1568 if not self._is_sparse:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pynndescent/pynndescent_.py in _init_search_graph(self); 1054 ); 1055 else:; -> 1056 diversify_csr(; 1057 reverse_graph.indptr,; 1058 reverse_graph.indices,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws); 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 433 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 434 raise e; 435 ; 436 def inspect_llvm(self, signature=None):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws); 365 argtypes.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 823 raise e.bind_fold_arguments(folded); 824 self.add_overload(cres); --> 825 self._cache.save_overload(sig, cres); 826 return cres.entry_point; 827 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/numba/core/caching.py in save",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2406
https://github.com/scverse/scanpy/issues/2408:301,Deployability,update,updated,301,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields; 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters; 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/issues/2408:619,Testability,log,logic,619,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. 1. The documentation of `sc.tl.tsne` and `sc.external.tl.phate` weren't updated to indicate that `X_{tsne,phate}` are `obs*m*` fields; 2. The documentation of both `sc.tl.tsne` and `sc.tl.umap` don't indicate the addition of the `uns` dictionary with the details of the embedding parameters; 3. The `uns` dictionaries returned by `sc.tl.tsne` and `sc.tl.umap` don't seem to follow the same logic: tsne's param dictionary holds most of the adjustable parameters (even irrelevant ones like `n_jobs`), while the umap dictionary holds only a and b parameters.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2408
https://github.com/scverse/scanpy/pull/2409:71,Usability,guid,guidelines,71,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; In this contribution , we have introduced a new flavour 'katana' in the already existing leiden and louvain implementation. The implementation of this new flavour is based on the KatanaGraph library , which comes out to be a faster alternative to the already existing flavours, providing more than 2x speedup to the leiden and louvain execution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2409
https://github.com/scverse/scanpy/pull/2409:102,Usability,guid,guide,102,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; In this contribution , we have introduced a new flavour 'katana' in the already existing leiden and louvain implementation. The implementation of this new flavour is based on the KatanaGraph library , which comes out to be a faster alternative to the already existing flavours, providing more than 2x speedup to the leiden and louvain execution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2409
https://github.com/scverse/scanpy/issues/2410:229,Availability,error,error,229,"when run sc.utils.sanitize_anndata(adata), it returns:; AttributeError: module 'scanpy' has no attribute 'utils'. I didn't find any information about `sanitize_anndata()` under the path of scanpy, does anyone encounter a similar error?; the version of scanpy which i use is 1.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2410
https://github.com/scverse/scanpy/issues/2411:150,Deployability,Update,Updated,150,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```; (new-venv) $ pip install scanpy==1.9.1; ```. Then from within that venv:. ```python; import scanpy; ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File "".../site-packages/scanpy/__init__.py"", line 16, in <module>; from . import plotting as pl; File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import (; File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>; from . import _utils; File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>; class _AxesSubplot(Axes, axes.SubplotBase, ABC):; TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases; ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:344,Deployability,install,install,344,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```; (new-venv) $ pip install scanpy==1.9.1; ```. Then from within that venv:. ```python; import scanpy; ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File "".../site-packages/scanpy/__init__.py"", line 16, in <module>; from . import plotting as pl; File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import (; File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>; from . import _utils; File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>; class _AxesSubplot(Axes, axes.SubplotBase, ABC):; TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases; ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:277,Testability,Test,Tested,277,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```; (new-venv) $ pip install scanpy==1.9.1; ```. Then from within that venv:. ```python; import scanpy; ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File "".../site-packages/scanpy/__init__.py"", line 16, in <module>; from . import plotting as pl; File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import (; File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>; from . import _utils; File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>; class _AxesSubplot(Axes, axes.SubplotBase, ABC):; TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases; ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2411:1110,Testability,log,logging,1110,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] **Updated:** I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. Start from a fresh venv. (Tested on Python 3.9.2 on Debian Bullseye.). ```; (new-venv) $ pip install scanpy==1.9.1; ```. Then from within that venv:. ```python; import scanpy; ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File "".../site-packages/scanpy/__init__.py"", line 16, in <module>; from . import plotting as pl; File "".../site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import (; File "".../site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>; from . import _utils; File "".../site-packages/scanpy/plotting/_utils.py"", line 35, in <module>; class _AxesSubplot(Axes, axes.SubplotBase, ABC):; TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases; ```. ### Versions. You can't get to `scanpy.logging.print_versions()` on account of the crash.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2411
https://github.com/scverse/scanpy/issues/2413:116,Deployability,install,installed,116,https://github.com/scverse/scanpy/blob/d26be443373549f26226de367f0213f153556915/pyproject.toml#L57. Colab has 3.2.2 installed and installing scanpy requires restarting the runtime. I also can't find a great reason why 3.4 was chosen. https://github.com/scverse/scanpy/pull/2212/. based on this 3.2.2 should be fine?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2413
https://github.com/scverse/scanpy/issues/2413:130,Deployability,install,installing,130,https://github.com/scverse/scanpy/blob/d26be443373549f26226de367f0213f153556915/pyproject.toml#L57. Colab has 3.2.2 installed and installing scanpy requires restarting the runtime. I also can't find a great reason why 3.4 was chosen. https://github.com/scverse/scanpy/pull/2212/. based on this 3.2.2 should be fine?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2413
https://github.com/scverse/scanpy/issues/2416:51,Deployability,update,update,51,I merged a bunch of PRs and we shouldn't forget to update the release notes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2416
https://github.com/scverse/scanpy/issues/2416:62,Deployability,release,release,62,I merged a bunch of PRs and we shouldn't forget to update the release notes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2416
https://github.com/scverse/scanpy/issues/2418:4261,Deployability,update,updated,4261,"22.12.07; cffi 1.15.1; charset_normalizer 2.1.1; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.2; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.1.1; dateutil 2.8.2; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; fastcluster 1.2.6; fastjsonschema NA; gepdynamics NA; h5py 3.8.0; hypergeom_ufunc NA; idna 3.4; igraph 0.10.4; invgauss_ufunc NA; ipykernel 6.21.1; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonschema 4.17.3; jupyter_events 0.5.0; jupyter_server 2.2.1; jupyterlab_server 2.19.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; louvain 0.8.0; markupsafe 2.1.2; matplotlib 3.6.3; mpl_toolkits NA; natsort 8.2.0; nbformat 5.7.3; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numexpr 2.8.3; numpy 1.23.5; packaging 23.0; pandas 1.5.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.6.2; prometheus_client NA; prompt_toolkit 3.0.36; psutil 5.9.4; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pydev_ipython NA; pydevd 1.4.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.14.0; pyparsing 3.0.9; pyrsistent NA; pythonjsonlogger NA; pytz 2022.7.1; requests 2.28.2; scipy 1.10.0; seaborn 0.12.2; send2trash NA; session_info 1.0.0; setuptools 67.1.0; sip NA; sitecustomize NA; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.1; sniffio 1.3.0; socks 1.7.1; stack_data 0.6.2; statsmodels 0.13.5; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; tornado 6.2; traitlets 5.9.0; typing_extensions NA; unicodedata2 NA; urllib3 1.26.14; wcwidth 0.2.6; websocket 1.5.1; yaml 6.0; zipp NA; zmq 25.0.0; zoneinfo NA; -----; IPython 8.9.0; jupyter_client 8.0.2; jupyter_core 5.2.0; jupyterlab 3.6.1; notebook 6.5.2; -----; Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:42:20) [Clang 14.0.6 ]; macOS-13.2.1-x86_64-i386-64bit; -----; Session information updated at 2023-02-15 22:51; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:2261,Performance,bottleneck,bottleneck,2261,"veshell.py"", line 3442, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>; sc.tl.dendrogram(adata, 'cat_key', use_rep='X'); File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram; corr_condensed = distance.squareform(1 - corr_matrix); File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform; is_valid_dm(X, throw=True, name='X'); File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm; raise ValueError(('Distance matrix \'%s\' must be '; ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() ; -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.4.0; PyQt5 NA; anyio NA; asttokens NA; attr 22.2.0; babel 2.11.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.6; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.1.1; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.2; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.1.1; dateutil 2.8.2; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; fastcluster 1.2.6; fastjsonschema NA; gepdynamics NA; h5py 3.8.0; hypergeom_ufunc NA; idna 3.4; igraph 0.10.4; invgauss_ufunc NA; ipykernel 6.21.1; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonschema 4.17.3; jupyter_events 0.5.0; jupyter_server 2.2.1; jupyterlab_server 2.19.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; louvain 0.8.0; markupsafe 2.1.2; matplotlib 3.6.3; mpl_toolkits NA; natsort 8.2.0; nbformat 5.7.3; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numexpr 2.8.3; numpy 1.23.5; packaging 23.0; pandas 1.5.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.6.2; prometheus_client NA; p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/issues/2418:2072,Testability,log,logging,2072,"'cat_key', use_rep='X'); ```. ```pytb; Traceback (most recent call last):; File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3442, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-8-1616c771d0da>"", line 1, in <module>; sc.tl.dendrogram(adata, 'cat_key', use_rep='X'); File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scanpy/tools/_dendrogram.py"", line 139, in dendrogram; corr_condensed = distance.squareform(1 - corr_matrix); File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2354, in squareform; is_valid_dm(X, throw=True, name='X'); File ""/Applications/miniconda3/envs/gep-dynamics/lib/python3.9/site-packages/scipy/spatial/distance.py"", line 2429, in is_valid_dm; raise ValueError(('Distance matrix \'%s\' must be '; ValueError: Distance matrix 'X' must be symmetric.```. #### Versions. <details>. sc.logging.print_versions() ; -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.4.0; PyQt5 NA; anyio NA; asttokens NA; attr 22.2.0; babel 2.11.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.6; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.1.1; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.2; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.1.1; dateutil 2.8.2; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; fastcluster 1.2.6; fastjsonschema NA; gepdynamics NA; h5py 3.8.0; hypergeom_ufunc NA; idna 3.4; igraph 0.10.4; invgauss_ufunc NA; ipykernel 6.21.1; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonschema 4.17.3; jupyter_events 0.5.0; jupyter_server 2.2.1; jupyterlab_server 2.19.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; louvain 0.8.0; markupsafe 2.1.2; matplotlib 3.6.3; mpl_toolkits NA; natsort 8.2.0; nbformat 5.7.3; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2418
https://github.com/scverse/scanpy/pull/2420:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2420
https://github.com/scverse/scanpy/pull/2420:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2420
https://github.com/scverse/scanpy/pull/2421:123,Availability,error,error,123,"Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:252,Availability,error,error,252,"Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:65,Deployability,install,install,65,"Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:329,Deployability,release,release,329,"Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:258,Integrability,message,messages,258,"Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2421:34,Testability,test,tests,34,"Follow up to #2420, which let the tests run, but didn't actually install anndata-dev. Current version was quoted due to my error in reading a `pre-commit` complaint about yaml syntax. Tbf, yaml syntax is complicated, and the pre-commit check gives bad error messages. ----. Additionally apply other fixes from yesterdays bug fix release to main branch",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2421
https://github.com/scverse/scanpy/pull/2422:42,Testability,test,tests,42,Reverts scverse/scanpy#2296 due to broken tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2422
https://github.com/scverse/scanpy/issues/2423:313,Availability,error,error,313,"Hi, I was doing DE for a processed dataset. However, when I did `sc.tl.rank_genes_groups(adata,'Celltypes',method='wilcoxon')` after `adata = sc.read_h5ad('mydata.h5ad')` it tells me `'AnnData' object has no attribute 'tl'`. . My AnnData is version 0.8.0 and scanpy 1.9.1, I'm not sure how I should check for the error? Thank you!. `View of AnnData object with n_obs  n_vars = 1358  1147. obs: 'Celltypes', 'Celltypes_master_high', 'Celltypes_master_higher', 'Celltypes_master_higher_immune', 'Celltypes_master_2', 'Celltypes_master_3', 'Loc_true', 'Material', 'scsn', 'Donor', 'Donor_ID_2', 'Gender', 'Sample', 'ID', 'Protocol_plot', 'Version', 'Study', 'PoolDon', 'DonorPool', 'scDonor_snBatch', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'mt', 'gene_ids-0', 'n_cells-0', 'n_cells_by_counts-0', 'mean_counts-0', 'pct_dropout_by_counts-0', 'total_counts-0', 'gene_ids-1', 'n_cells-1', 'n_cells_by_counts-1', 'mean_counts-1', 'pct_dropout_by_counts-1', 'total_counts-1', 'feature_types-1', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'mean', 'std'. uns: 'Celltypes_colors', 'Celltypes_int_F_colors', 'Celltypes_int_colors', 'Celltypes_int_updB_colors', 'Celltypes_master_high_colors', 'ID_colors', 'Loc_true_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'scDonor_snBatch_colors', 'scsn_colors', 'umap'. obsm: 'X_pca', 'X_pca_hm', 'X_umap', 'X_umap_BBKNN_scDonor_snBatch', 'X_umap_Harmony_Donor_n_Material', 'X_umap_Harmony_Material', 'X_umap_Harmony_scDonor_snBatch'. varm: 'PCs'. obsp: 'connectivities', 'distances'`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2423
https://github.com/scverse/scanpy/issues/2425:197,Availability,avail,available,197,"Thank you for creating `scanpy`! It's such a useful tool!. ## Overview of request; Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior; I would like to be able to...; 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page; ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png); 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources; - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html); - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags); - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example; As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:336,Deployability,release,releases,336,"Thank you for creating `scanpy`! It's such a useful tool!. ## Overview of request; Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior; I would like to be able to...; 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page; ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png); 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources; - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html); - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags); - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example; As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:671,Deployability,release,release,671,"Thank you for creating `scanpy`! It's such a useful tool!. ## Overview of request; Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior; I would like to be able to...; 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page; ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png); 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources; - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html); - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags); - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example; As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1029,Deployability,integrat,integrations,1029,"Thank you for creating `scanpy`! It's such a useful tool!. ## Overview of request; Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior; I would like to be able to...; 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page; ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png); 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources; - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html); - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags); - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example; As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1080,Deployability,continuous,continuous,1080,"Thank you for creating `scanpy`! It's such a useful tool!. ## Overview of request; Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior; I would like to be able to...; 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page; ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png); 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources; - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html); - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags); - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example; As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1105,Deployability,deploy,deployment,1105,"Thank you for creating `scanpy`! It's such a useful tool!. ## Overview of request; Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior; I would like to be able to...; 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page; ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png); 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources; - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html); - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags); - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example; As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2425:1029,Integrability,integrat,integrations,1029,"Thank you for creating `scanpy`! It's such a useful tool!. ## Overview of request; Is there any chance that you can start tagging versions of your documentation on readthedocs? Currently, the only available versions are **stable** and **latest**. That makes it easy to view the current documentation but difficult to view docs from old releases of `scanpy`. ## Desired behavior; I would like to be able to...; 1. Click on `v: stable` in the flyout menu at the bottom-left corner of the page; ![image](https://user-images.githubusercontent.com/23412689/220255767-3fbf84e9-ccf5-420b-b067-7a4054aed047.png); 2. Click on the version of the documentation tagged for the older release of `scanpy` that I'm using. ## Resources; - [How to version RTD documentation](https://docs.readthedocs.io/en/stable/versions.html); - [How to automatically maintain versions upon creating new git tags](https://docs.readthedocs.io/en/stable/automation-rules.html#activate-all-new-tags); - [Automated versioning](https://docs.readthedocs.io/en/stable/integrations.html#automated-versioning) as part of continuous documentation deployment. ## An example; As an example of versioned documentation, take a look at [Snakemake's documentation](https://snakemake.readthedocs.io/). ![image](https://user-images.githubusercontent.com/23412689/220255676-39e9eee9-e658-4866-b8b9-63a6174577ba.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2425
https://github.com/scverse/scanpy/issues/2427:73,Deployability,integrat,integration,73,"Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me?. Thanks a lot!. ```; adata; AnnData object with n_obs  n_vars = 73998  13639; obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'; uns: 'log1p'; layers: 'counts'. for i in adatas:; i.layers['counts'] = i.X; adata = ad.concat(adatas); adata.obs_names_make_unique; sc.pp.log1p(adata); sc.pp.highly_variable_genes(; adata,; flavor=""seurat_v3"",; layer=""counts"",; batch_key=""Sample"",; subset=True; ); ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In [197], line 1; ----> 1 sc.pp.highly_variable_genes(; 2 adata_new,; 3 flavor=""seurat_v3"",; 4 layer=""counts"",; 5 batch_key=""Sample"",; 6 subset=True; 7 ); 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 416 raise ValueError(; 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '; 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'; 419 ); 421 if flavor == 'seurat_v3':; --> 422 return _highly_variable_genes_seurat_v3(; 423 adata,; 424 layer=layer,; 425 n_top_genes=n_top_genes,; 426 batch_key=batch_key,; 427 check_values=check_values,; 428 span=span,; 429 subset=subset,; 430 inplace=inplace,; 431 ); 433 if batch_key is None:; 434 df = _highly_variable_genes_single_batch(; 435 adata,; 436 layer=layer,; (...); 443",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:73,Integrability,integrat,integration,73,"Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me?. Thanks a lot!. ```; adata; AnnData object with n_obs  n_vars = 73998  13639; obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'; uns: 'log1p'; layers: 'counts'. for i in adatas:; i.layers['counts'] = i.X; adata = ad.concat(adatas); adata.obs_names_make_unique; sc.pp.log1p(adata); sc.pp.highly_variable_genes(; adata,; flavor=""seurat_v3"",; layer=""counts"",; batch_key=""Sample"",; subset=True; ); ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In [197], line 1; ----> 1 sc.pp.highly_variable_genes(; 2 adata_new,; 3 flavor=""seurat_v3"",; 4 layer=""counts"",; 5 batch_key=""Sample"",; 6 subset=True; 7 ); 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 416 raise ValueError(; 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '; 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'; 419 ); 421 if flavor == 'seurat_v3':; --> 422 return _highly_variable_genes_seurat_v3(; 423 adata,; 424 layer=layer,; 425 n_top_genes=n_top_genes,; 426 batch_key=batch_key,; 427 check_values=check_values,; 428 span=span,; 429 subset=subset,; 430 inplace=inplace,; 431 ); 433 if batch_key is None:; 434 df = _highly_variable_genes_single_batch(; 435 adata,; 436 layer=layer,; (...); 443",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:662,Modifiability,layers,layers,662,"Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me?. Thanks a lot!. ```; adata; AnnData object with n_obs  n_vars = 73998  13639; obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'; uns: 'log1p'; layers: 'counts'. for i in adatas:; i.layers['counts'] = i.X; adata = ad.concat(adatas); adata.obs_names_make_unique; sc.pp.log1p(adata); sc.pp.highly_variable_genes(; adata,; flavor=""seurat_v3"",; layer=""counts"",; batch_key=""Sample"",; subset=True; ); ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In [197], line 1; ----> 1 sc.pp.highly_variable_genes(; 2 adata_new,; 3 flavor=""seurat_v3"",; 4 layer=""counts"",; 5 batch_key=""Sample"",; 6 subset=True; 7 ); 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 416 raise ValueError(; 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '; 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'; 419 ); 421 if flavor == 'seurat_v3':; --> 422 return _highly_variable_genes_seurat_v3(; 423 adata,; 424 layer=layer,; 425 n_top_genes=n_top_genes,; 426 batch_key=batch_key,; 427 check_values=check_values,; 428 span=span,; 429 subset=subset,; 430 inplace=inplace,; 431 ); 433 if batch_key is None:; 434 df = _highly_variable_genes_single_batch(; 435 adata,; 436 layer=layer,; (...); 443",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/issues/2427:700,Modifiability,layers,layers,700,"Hi, I have a Seruat processed dataset, of which I wanted to use scVI for integration. I stored the raw count and cell information then assembled them in scanpy as anndata via method mentioned: `https://smorabit.github.io/tutorials/8_velocyto/`. . So I could get batch HVG function to work without specifying flavor, however, I couldn't get it to work with specifying `flavor=""seurat_v3""`, I wonder how important it is to set this parameter and why does it not work for me?. Thanks a lot!. ```; adata; AnnData object with n_obs  n_vars = 73998  13639; obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'barcode', 'Celltype2', 'Clusters', 'Sample'; uns: 'log1p'; layers: 'counts'. for i in adatas:; i.layers['counts'] = i.X; adata = ad.concat(adatas); adata.obs_names_make_unique; sc.pp.log1p(adata); sc.pp.highly_variable_genes(; adata,; flavor=""seurat_v3"",; layer=""counts"",; batch_key=""Sample"",; subset=True; ); ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In [197], line 1; ----> 1 sc.pp.highly_variable_genes(; 2 adata_new,; 3 flavor=""seurat_v3"",; 4 layer=""counts"",; 5 batch_key=""Sample"",; 6 subset=True; 7 ); 8 adata_new. File ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:422, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 416 raise ValueError(; 417 '`pp.highly_variable_genes` expects an `AnnData` argument, '; 418 'pass `inplace=False` if you want to return a `pd.DataFrame`.'; 419 ); 421 if flavor == 'seurat_v3':; --> 422 return _highly_variable_genes_seurat_v3(; 423 adata,; 424 layer=layer,; 425 n_top_genes=n_top_genes,; 426 batch_key=batch_key,; 427 check_values=check_values,; 428 span=span,; 429 subset=subset,; 430 inplace=inplace,; 431 ); 433 if batch_key is None:; 434 df = _highly_variable_genes_single_batch(; 435 adata,; 436 layer=layer,; (...); 443",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2427
https://github.com/scverse/scanpy/pull/2426:84,Usability,learn,learn,84,"We have replaced the existing nearest neighbor implementation from umap with scikit-learn's implementation. By using Intel extension for scikit-learn, this implementation can be upto 2x faster for large datasets.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2426
https://github.com/scverse/scanpy/pull/2426:144,Usability,learn,learn,144,"We have replaced the existing nearest neighbor implementation from umap with scikit-learn's implementation. By using Intel extension for scikit-learn, this implementation can be upto 2x faster for large datasets.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2426
https://github.com/scverse/scanpy/issues/2428:814,Availability,error,error,814,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ```python; #remove all ribosomal genes; malat1 = adata1.var_names.str.startswith('MALAT1'); ribo_genes = adata1.var_names.str.startswith((""RPS"",""RPL"")); # we need to redefine the mito_genes since they were first ; # calculated on the full object before removing low expressed genes.; mito_genes = adata1.var_names.str.startswith('MT-'); hb_genes = adata1.var_names.str.contains('^HB[^(P)]'). remove = np.add(mito_genes, malat1); remove = np.add(remove, hb_genes); keep = np.invert(remove). adata3 = adata1[:,keep]. adata3; ```. #### Versions; anndata 0.8.0; scanpy 1.7.2. I am getting this error ""ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual.; self.data[key] = value "" as soon as i write the above code(subset data based on genes i need) and then the kernel crashes because of memory issues",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2428
https://github.com/scverse/scanpy/pull/2429:73,Modifiability,Rewrite,Rewrite,73,"Hi, this is a PR with some changes to Hashsolo, mainly the docstring:; - Rewrite some param descriptions for brevity + clarity; - Explicitly list the obs keys being added to adata; - Copy input adata if inplace=False",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2429
https://github.com/scverse/scanpy/pull/2429:38,Security,Hash,Hashsolo,38,"Hi, this is a PR with some changes to Hashsolo, mainly the docstring:; - Rewrite some param descriptions for brevity + clarity; - Explicitly list the obs keys being added to adata; - Copy input adata if inplace=False",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2429
https://github.com/scverse/scanpy/issues/2430:556,Availability,error,error,556,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.pca(adata, color='CST3'); ```. ```pytb; [Paste the error output produced by the above code here]; ```KeyError Traceback (most recent call last); D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 3628 try:; -> 3629 return self._engine.get_loc(casted_key); 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>; 1 #  PCA ; ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 869 """"""; 870 if not annotate_var_explained:; --> 871 return embedding(; 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:738,Availability,toler,tolerance,738,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.pca(adata, color='CST3'); ```. ```pytb; [Paste the error output produced by the above code here]; ```KeyError Traceback (most recent call last); D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 3628 try:; -> 3629 return self._engine.get_loc(casted_key); 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>; 1 #  PCA ; ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 869 """"""; 870 if not annotate_var_explained:; --> 871 return embedding(; 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:2691,Availability,error,error,2691," 871 return embedding(; 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 255 # ]; 256 for count, (value_to_plot, dims) in enumerate(zip(color, dimensions)):; --> 257 color_source_vector = _get_color_source_vector(; 258 adata,; 259 value_to_plot,. D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in _get_color_source_vector(adata, value_to_plot, use_raw, gene_symbols, layer, groups); 1165 ] # TODO: Throw helpful error if this doesn't work; 1166 if use_raw and value_to_plot not in adata.obs.columns:; -> 1167 values = adata.raw.obs_vector(value_to_plot); 1168 else:; 1169 values = adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k); 169 def obs_vector(self, k: str) -> np.ndarray:; 170 # TODO decorator to copy AnnData.obs_vector docstring; --> 171 idx = self._normalize_indices((slice(None), k)); 172 a = self.X[idx]; 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index); 160 obs, var = unpack_index(packed_index); 161 obs = _normalize_index(obs, self._adata.obs_names); --> 162 var = _normalize_index(var, self.var_names); 163 return obs, var; 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index); 73 return indexer; 74 elif isinstance(indexer, str):; ---> 75 return index.get_loc(indexer) # int; 76 elif isinstance",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:3862,Availability,toler,tolerance,3862,"adata.obs_vector(value_to_plot, layer=layer). D:\anaconda\lib\site-packages\anndata\_core\raw.py in obs_vector(self, k); 169 def obs_vector(self, k: str) -> np.ndarray:; 170 # TODO decorator to copy AnnData.obs_vector docstring; --> 171 idx = self._normalize_indices((slice(None), k)); 172 a = self.X[idx]; 173 if issparse(a):. D:\anaconda\lib\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index); 160 obs, var = unpack_index(packed_index); 161 obs = _normalize_index(obs, self._adata.obs_names); --> 162 var = _normalize_index(var, self.var_names); 163 return obs, var; 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index); 73 return indexer; 74 elif isinstance(indexer, str):; ---> 75 return index.get_loc(indexer) # int; 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):; 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 3629 return self._engine.get_loc(casted_key); 3630 except KeyError as err:; -> 3631 raise KeyError(key) from err; 3632 except TypeError:; 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions; scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.2; -----; PIL 9.2.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fsspec 2022.7.1; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.0.3; joblib 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:6219,Deployability,update,updated,6219,"ynndescent==0.5.8; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.2; -----; PIL 9.2.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fsspec 2022.7.1; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.9.1; llvmlite 0.38.0; lz4 3.1.3; markupsafe 2.1.2; matplotlib 3.5.2; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; nt NA; ntsecuritycon NA; numba 0.55.1; numexpr 2.8.3; numpy 1.21.6; packaging 21.3; pandas 1.4.4; parso 0.8.3; patsy 0.5.2; pickleshare 0.7.5; pkg_resources NA; plotly 5.9.0; prompt_toolkit 3.0.20; psutil 5.9.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.8; pyparsing 3.0.9; pythoncom NA; pytz 2022.1; pywintypes NA; ruamel NA; scipy 1.9.1; seaborn 0.11.2; session_info 1.0.0; setuptools 63.4.1; setuptools_scm NA; six 1.16.0; sklearn 1.0.2; snappy NA; sphinxcontrib NA; statsmodels 0.13.2; storemagic NA; tblib 1.7.0; texttable 1.6.7; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.2; tornado 6.1; tqdm 4.64.1; traitlets 5.1.1; typing_extensions NA; umap 0.5.3; wcwidth 0.2.5; win32api NA; win32com NA; win32security NA; yaml 5.4.1; zipp NA; zmq 23.2.0; zope NA; -----; IPython 7.31.1; jupyter_client 7.3.4; jupyter_core 4.11.1; jupyterlab 3.4.4; notebook 6.4.12; -----; Python 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.19045-SP0; -----; Session information updated at 2023-02-24 14:04; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:4487,Performance,bottleneck,bottleneck,4487,"\site-packages\anndata\_core\index.py in _normalize_index(indexer, index); 73 return indexer; 74 elif isinstance(indexer, str):; ---> 75 return index.get_loc(indexer) # int; 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):; 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 3629 return self._engine.get_loc(casted_key); 3630 except KeyError as err:; -> 3631 raise KeyError(key) from err; 3632 except TypeError:; 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions; scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.2; -----; PIL 9.2.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fsspec 2022.7.1; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.9.1; llvmlite 0.38.0; lz4 3.1.3; markupsafe 2.1.2; matplotlib 3.5.2; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; nt NA; ntsecuritycon NA; numba 0.55.1; numexpr 2.8.3; numpy 1.21.6; packaging 21.3; pandas 1.4.4; parso 0.8.3; patsy 0.5.2; pickleshare 0.7.5; pkg_resources NA; plotly 5.9.0; prompt_toolkit 3.0.20; psutil 5.9.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:1092,Security,hash,hashtable,1092,"bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.pca(adata, color='CST3'); ```. ```pytb; [Paste the error output produced by the above code here]; ```KeyError Traceback (most recent call last); D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 3628 try:; -> 3629 return self._engine.get_loc(casted_key); 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>; 1 #  PCA ; ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 869 """"""; 870 if not annotate_var_explained:; --> 871 return embedding(; 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, siz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:1188,Security,hash,hashtable,1188,"n the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.pca(adata, color='CST3'); ```. ```pytb; [Paste the error output produced by the above code here]; ```KeyError Traceback (most recent call last); D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 3628 try:; -> 3629 return self._engine.get_loc(casted_key); 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>; 1 #  PCA ; ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 869 """"""; 870 if not annotate_var_explained:; --> 871 return embedding(; 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:4316,Testability,log,logging,4316,"ex); 161 obs = _normalize_index(obs, self._adata.obs_names); --> 162 var = _normalize_index(var, self.var_names); 163 return obs, var; 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index); 73 return indexer; 74 elif isinstance(indexer, str):; ---> 75 return index.get_loc(indexer) # int; 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):; 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 3629 return self._engine.get_loc(casted_key); 3630 except KeyError as err:; -> 3631 raise KeyError(key) from err; 3632 except TypeError:; 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions; scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.2; -----; PIL 9.2.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fsspec 2022.7.1; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.9.1; llvmlite 0.38.0; lz4 3.1.3; markupsafe 2.1.2; matplotlib 3.5.2; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; nt NA; ntsecuritycon NA; numba 0.55.1; numexpr 2.8.3; numpy 1.21.6; packaging 21.3; pandas 1.4.4; parso 0.8.3; patsy 0.5.2; pickleshare 0.7.5; pkg_resources NA; plotly 5.9.0; prompt_toolkit 3.0.20; psutil 5.9.0; pycparser 2.21; pydev_ipython NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.pca(adata, color='CST3'); ```. ```pytb; [Paste the error output produced by the above code here]; ```KeyError Traceback (most recent call last); D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 3628 try:; -> 3629 return self._engine.get_loc(casted_key); 3630 except KeyError as err:. D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). D:\anaconda\lib\site-packages\pandas\_libs\index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas\_libs\hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'CST3'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); ~\AppData\Local\Temp\ipykernel_42228\2632014446.py in <module>; 1 #  PCA ; ----> 2 sc.pl.pca(adata, color='CST3'). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 869 """"""; 870 if not annotate_var_explained:; --> 871 return embedding(; 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 873 ). D:\anaconda\lib\site-packages\scanpy\plotting\_tools\scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2430:4202,Usability,learn,learn,4202,"b\site-packages\anndata\_core\raw.py in _normalize_indices(self, packed_index); 160 obs, var = unpack_index(packed_index); 161 obs = _normalize_index(obs, self._adata.obs_names); --> 162 var = _normalize_index(var, self.var_names); 163 return obs, var; 164 . D:\anaconda\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index); 73 return indexer; 74 elif isinstance(indexer, str):; ---> 75 return index.get_loc(indexer) # int; 76 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):; 77 if hasattr(indexer, ""shape"") and (. D:\anaconda\lib\site-packages\pandas\core\indexes\base.py in get_loc(self, key, method, tolerance); 3629 return self._engine.get_loc(casted_key); 3630 except KeyError as err:; -> 3631 raise KeyError(key) from err; 3632 except TypeError:; 3633 # If we have a listlike key, _check_indexing_error will raise. KeyError: 'CST3'. #### Versions; scanpy==1.9.2 anndata==0.8.0 umap==0.5.3 numpy==1.21.6 scipy==1.9.1 pandas==1.4.4 scikit-learn==1.0.2 statsmodels==0.13.2 python-igraph==0.10.4 pynndescent==0.5.8; <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; -----; anndata 0.8.0; scanpy 1.9.2; -----; PIL 9.2.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fsspec 2022.7.1; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.9.1; llvmlite 0.38.0; lz4 3.1.3; markupsafe 2.1.2; matplotlib 3.5.2; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; nt NA; ntsecuritycon NA; numba 0.55.1; numexpr 2.8.3; numpy 1.21.6; packaging 21.3; pandas 1.4.4; parso 0.8.3; patsy 0.5.2; pi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2430
https://github.com/scverse/scanpy/issues/2431:2499,Deployability,update,updated,2499,"AnnData(csr_matrix(np.random.poisson(1, size(100, 100)), dtype=np.float32)); rs = np.random.RandomState(1). sc.pp.pca(adata, random_state=rs); sc.pp.neighbors(adata, random_state=rs); sc.tl.leiden(adata, random_state=rs). ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/scanpy/tools/_leiden.py"", line 144, in leiden; part = leidenalg.find_partition(g, partition_type, **partition_kwargs); File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/functions.py"", line 89, in find_partition; optimiser.set_rng_seed(seed); File ""/home/griffen/mambaforge/envs/scanpy-1.9.2/lib/python3.9/site-packages/leidenalg/Optimiser.py"", line 244, in set_rng_seed; _c_leiden._Optimiser_set_rng_seed(self._optimiser, value); TypeError: an integer is required (got type numpy.random.mtrand.RandomState); ```. #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.2; -----; PIL 9.4.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.4; importlib_resources NA; invgauss_ufunc NA; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.7.0; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; packaging 23.0; pandas 1.5.3; pkg_resources NA; psutil 5.9.4; pycparser 2.21; pynndescent 0.5.8; pyparsing 3.0.9; pytz 2022.7.1; scipy 1.10.1; session_info 1.0.0; setuptools 67.4.0; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.1; texttable 1.6.7; threadpoolctl 3.1.0; tqdm 4.64.1; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; yaml 6.0; zipp NA; zoneinfo NA; -----; Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]; Linux-6.1.12-arch1-1-x86_64-with-glibc2.37; -----; Session information updated at 2023-02-25 19:07. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2431
https://github.com/scverse/scanpy/issues/2432:1006,Availability,error,errors,1006,"Hi, I was doing a dataset integration on quite some datasets. . ```py; adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:; i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas); adata.obs_names_make_unique. sc.pp.log1p(adata); sc.pp.highly_variable_genes(; adata,; layer=""logcounts"",; batch_key=""Sample"",; subset=True; ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256); vae.train(); adata.obsm[""X_scVI""] = vae.get_latent_representation(); sc.pp.neighbors(adata, use_rep=""X_scVI""); from scvi.model.utils import mde; import pymde; adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]); adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(); adata.write_h5ad('Integrated.h5ad'); ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb; Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items.; Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]; Traceback (most recent call last):; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem; _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array; f.create_dataset(k, data=elem.astype(st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:4231,Availability,error,error,4231,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write; File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw; File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen; File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter; File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen; TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:; Traceback (most recent call last):; File ""integration.py"", line 66, in <module>; adata.write_h5ad('Integrated.h5ad'); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad; _write_h5ad(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad; write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem; _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe; write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper; raise type(e)(; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /; /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>; _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:26,Deployability,integrat,integration,26,"Hi, I was doing a dataset integration on quite some datasets. . ```py; adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:; i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas); adata.obs_names_make_unique. sc.pp.log1p(adata); sc.pp.highly_variable_genes(; adata,; layer=""logcounts"",; batch_key=""Sample"",; subset=True; ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256); vae.train(); adata.obsm[""X_scVI""] = vae.get_latent_representation(); sc.pp.neighbors(adata, use_rep=""X_scVI""); from scvi.model.utils import mde; import pymde; adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]); adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(); adata.write_h5ad('Integrated.h5ad'); ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb; Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items.; Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]; Traceback (most recent call last):; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem; _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array; f.create_dataset(k, data=elem.astype(st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:817,Deployability,Integrat,Integrated,817,"Hi, I was doing a dataset integration on quite some datasets. . ```py; adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:; i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas); adata.obs_names_make_unique. sc.pp.log1p(adata); sc.pp.highly_variable_genes(; adata,; layer=""logcounts"",; batch_key=""Sample"",; subset=True; ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256); vae.train(); adata.obsm[""X_scVI""] = vae.get_latent_representation(); sc.pp.neighbors(adata, use_rep=""X_scVI""); from scvi.model.utils import mde; import pymde; adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]); adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(); adata.write_h5ad('Integrated.h5ad'); ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb; Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items.; Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]; Traceback (most recent call last):; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem; _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array; f.create_dataset(k, data=elem.astype(st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:940,Deployability,integrat,integration,940,"Hi, I was doing a dataset integration on quite some datasets. . ```py; adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:; i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas); adata.obs_names_make_unique. sc.pp.log1p(adata); sc.pp.highly_variable_genes(; adata,; layer=""logcounts"",; batch_key=""Sample"",; subset=True; ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256); vae.train(); adata.obsm[""X_scVI""] = vae.get_latent_representation(); sc.pp.neighbors(adata, use_rep=""X_scVI""); from scvi.model.utils import mde; import pymde; adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]); adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(); adata.write_h5ad('Integrated.h5ad'); ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb; Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items.; Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]; Traceback (most recent call last):; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem; _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array; f.create_dataset(k, data=elem.astype(st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:2991,Deployability,integrat,integration,2991,"te_vlen_string_array; f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset; dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds); File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset; dset_id.write(h5s.ALL, h5s.ALL, data); File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write; File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw; File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen; File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter; File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen; TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:; Traceback (most recent call last):; File ""integration.py"", line 66, in <module>; adata.write_h5ad('Integrated.h5ad'); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad; _write_h5ad(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad; write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem; _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3048,Deployability,Integrat,Integrated,3048,"File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset; dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds); File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset; dset_id.write(h5s.ALL, h5s.ALL, data); File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write; File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw; File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen; File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter; File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen; TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:; Traceback (most recent call last):; File ""integration.py"", line 66, in <module>; adata.write_h5ad('Integrated.h5ad'); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad; _write_h5ad(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad; write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem; _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe; write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs); File ""/home/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:26,Integrability,integrat,integration,26,"Hi, I was doing a dataset integration on quite some datasets. . ```py; adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:; i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas); adata.obs_names_make_unique. sc.pp.log1p(adata); sc.pp.highly_variable_genes(; adata,; layer=""logcounts"",; batch_key=""Sample"",; subset=True; ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256); vae.train(); adata.obsm[""X_scVI""] = vae.get_latent_representation(); sc.pp.neighbors(adata, use_rep=""X_scVI""); from scvi.model.utils import mde; import pymde; adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]); adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(); adata.write_h5ad('Integrated.h5ad'); ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb; Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items.; Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]; Traceback (most recent call last):; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem; _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array; f.create_dataset(k, data=elem.astype(st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:817,Integrability,Integrat,Integrated,817,"Hi, I was doing a dataset integration on quite some datasets. . ```py; adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:; i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas); adata.obs_names_make_unique. sc.pp.log1p(adata); sc.pp.highly_variable_genes(; adata,; layer=""logcounts"",; batch_key=""Sample"",; subset=True; ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256); vae.train(); adata.obsm[""X_scVI""] = vae.get_latent_representation(); sc.pp.neighbors(adata, use_rep=""X_scVI""); from scvi.model.utils import mde; import pymde; adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]); adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(); adata.write_h5ad('Integrated.h5ad'); ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb; Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items.; Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]; Traceback (most recent call last):; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem; _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array; f.create_dataset(k, data=elem.astype(st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:940,Integrability,integrat,integration,940,"Hi, I was doing a dataset integration on quite some datasets. . ```py; adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:; i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas); adata.obs_names_make_unique. sc.pp.log1p(adata); sc.pp.highly_variable_genes(; adata,; layer=""logcounts"",; batch_key=""Sample"",; subset=True; ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256); vae.train(); adata.obsm[""X_scVI""] = vae.get_latent_representation(); sc.pp.neighbors(adata, use_rep=""X_scVI""); from scvi.model.utils import mde; import pymde; adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]); adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(); adata.write_h5ad('Integrated.h5ad'); ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb; Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items.; Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]; Traceback (most recent call last):; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem; _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array; f.create_dataset(k, data=elem.astype(st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:1790,Integrability,wrap,wrapper,1790,"'Integrated.h5ad'); ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb; Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items.; Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]; Traceback (most recent call last):; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem; _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array; f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset; dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds); File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset; dset_id.write(h5s.ALL, h5s.ALL, data); File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write; File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw; File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen; File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter; File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen; Type",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:2430,Integrability,wrap,wrapper,2430,"4, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem; _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array; f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset; dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds); File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset; dset_id.write(h5s.ALL, h5s.ALL, data); File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write; File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw; File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen; File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter; File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen; TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:; Traceback (most recent call last):; File ""integration.py"", line 66, in <module>; adata.write_h5ad('Integrated.h5ad'); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad; _write_h5ad(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad; write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:2501,Integrability,wrap,wrapper,2501,"e ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem; _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array; f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset; dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds); File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset; dset_id.write(h5s.ALL, h5s.ALL, data); File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write; File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw; File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen; File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter; File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen; TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:; Traceback (most recent call last):; File ""integration.py"", line 66, in <module>; adata.write_h5ad('Integrated.h5ad'); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad; _write_h5ad(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad; write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:2991,Integrability,integrat,integration,2991,"te_vlen_string_array; f.create_dataset(k, data=elem.astype(str_dtype), dtype=str_dtype, **dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset; dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds); File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset; dset_id.write(h5s.ALL, h5s.ALL, data); File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write; File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw; File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen; File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter; File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen; TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:; Traceback (most recent call last):; File ""integration.py"", line 66, in <module>; adata.write_h5ad('Integrated.h5ad'); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad; _write_h5ad(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad; write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem; _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3048,Integrability,Integrat,Integrated,3048,"File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/group.py"", line 183, in create_dataset; dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds); File ""/home/joyzheng/.local/lib/python3.8/site-packages/h5py/_hl/dataset.py"", line 168, in make_new_dset; dset_id.write(h5s.ALL, h5s.ALL, data); File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write; File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw; File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen; File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter; File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen; TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:; Traceback (most recent call last):; File ""integration.py"", line 66, in <module>; adata.write_h5ad('Integrated.h5ad'); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad; _write_h5ad(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad; write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem; _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe; write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs); File ""/home/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:3797,Integrability,wrap,wrapper,3797,"ile ""h5py/h5d.pyx"", line 280, in h5py.h5d.DatasetID.write; File ""h5py/_proxy.pyx"", line 145, in h5py._proxy.dset_rw; File ""h5py/_conv.pyx"", line 444, in h5py._conv.str2vlen; File ""h5py/_conv.pyx"", line 95, in h5py._conv.generic_converter; File ""h5py/_conv.pyx"", line 249, in h5py._conv.conv_str2vlen; TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:; Traceback (most recent call last):; File ""integration.py"", line 66, in <module>; adata.write_h5ad('Integrated.h5ad'); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_core/anndata.py"", line 1918, in write_h5ad; _write_h5ad(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py"", line 98, in write_h5ad; write_elem(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 175, in write_elem; _REGISTRY.get_writer(dest_type, t, modifiers)(f, k, elem, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 514, in write_dataframe; write_elem(group, colname, series._values, dataset_kwargs=dataset_kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 220, in func_wrapper; raise type(e)(; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'orig.ident' of <class 'h5py._hl.group.Group'> to /; /home/joyzheng/.conda/envs/cellrank/lib/python3.8/tempfile.py:818: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmpzjzxl3q5'>; _warnings.warn(warn_message, ResourceWarning)```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:171,Modifiability,layers,layers,171,"Hi, I was doing a dataset integration on quite some datasets. . ```py; adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:; i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas); adata.obs_names_make_unique. sc.pp.log1p(adata); sc.pp.highly_variable_genes(; adata,; layer=""logcounts"",; batch_key=""Sample"",; subset=True; ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256); vae.train(); adata.obsm[""X_scVI""] = vae.get_latent_representation(); sc.pp.neighbors(adata, use_rep=""X_scVI""); from scvi.model.utils import mde; import pymde; adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]); adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(); adata.write_h5ad('Integrated.h5ad'); ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb; Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items.; Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]; Traceback (most recent call last):; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem; _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array; f.create_dataset(k, data=elem.astype(st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2432:356,Testability,log,logcounts,356,"Hi, I was doing a dataset integration on quite some datasets. . ```py; adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7] #each is an adata object from scRNA-seq. for i in adatas:; i.layers['counts'] = i.X. adatas = [AT1,AT2,AT3,AT4,AT5,AT6,AT7]. adata = ad.concat(adatas); adata.obs_names_make_unique. sc.pp.log1p(adata); sc.pp.highly_variable_genes(; adata,; layer=""logcounts"",; batch_key=""Sample"",; subset=True; ). scvi.model.SCVI.setup_anndata(adata, layer=""counts"", batch_key=""Sample""). vae = scvi.model.SCVI(adata, n_hidden=256); vae.train(); adata.obsm[""X_scVI""] = vae.get_latent_representation(); sc.pp.neighbors(adata, use_rep=""X_scVI""); from scvi.model.utils import mde; import pymde; adata.obsm[""X_mde""] = mde(adata.obsm[""X_scVI""]); adata.obsm[""X_normalized_scVI""] = vae.get_normalized_expression(); adata.write_h5ad('Integrated.h5ad'); ```. So I did use make obs names unique after ad.concat(adatas). However, after I was finished with the integration and moving on to write_h5ad, it returns the following errors and tells me they can't write my h5ad cuz I have duplicated rows:. ```pytb; Feb 26 11:20:39 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items.; Feb 26 11:20:39 PM: The following items have duplicates [60449 60452 60455 ... 70783 70784 70785]; Traceback (most recent call last):; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/utils.py"", line 214, in func_wrapper; return func(elem, key, val, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 171, in write_elem; _REGISTRY.get_writer(dest_type, (t, elem.dtype.kind), modifiers)(; File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/registry.py"", line 24, in wrapper; result = func(g, k, *args, **kwargs); File ""/home/joyzheng/.local/lib/python3.8/site-packages/anndata/_io/specs/methods.py"", line 346, in write_vlen_string_array; f.create_dataset(k, data=elem.astype(st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2432
https://github.com/scverse/scanpy/issues/2433:224,Modifiability,variab,variables,224,<!-- What kind of feature would you like to request? -->; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?. <!-- Please describe your wishes below: -->; Computes a hierarchical clustering for the variables(genes) in sc.pl.matrixplot or sc.pl.dotplot.Thanks!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2433
https://github.com/scverse/scanpy/pull/2434:208,Testability,test,tests,208,"Collection of fixes for pandas 2.0. Interestingly enough, for is_categorical -> is_categorical_dtype we have already made this change in all but one file. I'm suspecting this file is left because this has no tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2434
https://github.com/scverse/scanpy/pull/2435:252,Deployability,Release,Release,252,"* is_categorical -> is_categorical_dtype. * cat.replace(to_remove, np.nan) -> cat.remove_categories(to_remove). * df1.append(df2) -> pd.concat([df1, df2]). * Series.iteritems -> Series.items. * Fix indexing a pandas object with a set in score genes. * Release notes. (cherry picked from commit 0692ef9ea30335b95f7e7f9aab7be856469d9f35). <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2435
https://github.com/scverse/scanpy/pull/2435:408,Usability,guid,guidelines,408,"* is_categorical -> is_categorical_dtype. * cat.replace(to_remove, np.nan) -> cat.remove_categories(to_remove). * df1.append(df2) -> pd.concat([df1, df2]). * Series.iteritems -> Series.items. * Fix indexing a pandas object with a set in score genes. * Release notes. (cherry picked from commit 0692ef9ea30335b95f7e7f9aab7be856469d9f35). <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2435
https://github.com/scverse/scanpy/pull/2435:439,Usability,guid,guide,439,"* is_categorical -> is_categorical_dtype. * cat.replace(to_remove, np.nan) -> cat.remove_categories(to_remove). * df1.append(df2) -> pd.concat([df1, df2]). * Series.iteritems -> Series.items. * Fix indexing a pandas object with a set in score genes. * Release notes. (cherry picked from commit 0692ef9ea30335b95f7e7f9aab7be856469d9f35). <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2435
https://github.com/scverse/scanpy/issues/2436:3174,Availability,error,error,3174,"t, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 133 ; 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs; --> 135 datas, mnn_list, angle_list = mnn_correct(; 136 *datas,; 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 120 if var_subset is not None and set(adata_vars) == set(var_subset):; 121 var_subset = None; --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,; 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,; 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 176 new_batch_out = out_batches[target]; 177 print(' Looking for MNNs...'); --> 178 mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_batch_in, k1=k, k2=k,; 179 n_jobs=n_jobs); 180 print(' Computing correction vectors...'). _ckdtree.pyx in scipy.spatial._ckdtree.cKDTree.query(). _ckdtree.pyx in scipy.spatial._ckdtree.get_num_workers(). TypeError: Unexpected keyword argument {'n_jobs': 48}; ---------------------------------------------------------------------------. ```. #### Versions; python 3.9. <details>; The function scanpy.external.pp.mnn_correct has a n_jobs for the argument, but scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'. I think you should remove it. It keeps showing an error. . [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:3211,Testability,log,logging,3211,"t, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 133 ; 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs; --> 135 datas, mnn_list, angle_list = mnn_correct(; 136 *datas,; 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 120 if var_subset is not None and set(adata_vars) == set(var_subset):; 121 var_subset = None; --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,; 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,; 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 176 new_batch_out = out_batches[target]; 177 print(' Looking for MNNs...'); --> 178 mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_batch_in, k1=k, k2=k,; 179 n_jobs=n_jobs); 180 print(' Computing correction vectors...'). _ckdtree.pyx in scipy.spatial._ckdtree.cKDTree.query(). _ckdtree.pyx in scipy.spatial._ckdtree.get_num_workers(). TypeError: Unexpected keyword argument {'n_jobs': 48}; ---------------------------------------------------------------------------. ```. #### Versions; python 3.9. <details>; The function scanpy.external.pp.mnn_correct has a n_jobs for the argument, but scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'. I think you should remove it. It keeps showing an error. . [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:263,Usability,guid,guide,263,"- [ yes] I have checked that this issue has not already been reported.; - [ yes] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']); ```. ```pytb; ![Screenshot 2023-03-05 at 18 18 05](https://user-images.githubusercontent.com/22848603/222991823-36da6d04-44ca-4504-a030-b2b4256bfa9c.png). ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/ipykernel_1797574/3779544909.py in <module>; ----> 1 sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 133 ; 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs; --> 135 datas, mnn_list, angle_list = mnn_correct(; 136 *datas,; 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs); 120 if var_subset is not None and set(adata_vars) == set(var_subset):; 121 var_subset = None; --> 122 corrected = mnn_correct(*(adata.X for adata in datas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/pull/2437:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/psf/black: 23.1.0  23.3.0](https://github.com/psf/black/compare/23.1.0...23.3.0); - [github.com/pre-commit/mirrors-autopep8: v2.0.1  v2.0.2](https://github.com/pre-commit/mirrors-autopep8/compare/v2.0.1...v2.0.2); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2437
https://github.com/scverse/scanpy/issues/2438:44,Availability,error,error,44,"Hello, I am unable to import scanpy and the error message shows below:. ```python; import scanpy as sc; ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>; from ._utils import check_versions; File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>; from .compute.is_constant import is_constant; File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>; from numba import njit; ImportError: cannot import name 'njit' from 'numba' (unknown location)```; ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:50,Integrability,message,message,50,"Hello, I am unable to import scanpy and the error message shows below:. ```python; import scanpy as sc; ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>; from ._utils import check_versions; File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>; from .compute.is_constant import is_constant; File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>; from numba import njit; ImportError: cannot import name 'njit' from 'numba' (unknown location)```; ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2440:836,Testability,test,test,836,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import harmonypy as hm; h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']); har= h_data.Z_corr; har = har.T; a_data.obsm['X_harmony'] = har.copy(); sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'); res = 1; sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res); a_data.write(test.h5ad); a_data = sc.read(test.h5ad); sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'); ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-6-8d70f4e1a0fa> in <module>; ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 588 ); 589 ; --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 591 ; 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 91 ):; 92 ; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. #### Versions. <details>. [P",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:865,Testability,test,test,865,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import harmonypy as hm; h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']); har= h_data.Z_corr; har = har.T; a_data.obsm['X_harmony'] = har.copy(); sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'); res = 1; sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res); a_data.write(test.h5ad); a_data = sc.read(test.h5ad); sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'); ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-6-8d70f4e1a0fa> in <module>; ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 588 ); 589 ; --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 591 ; 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 91 ):; 92 ; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. #### Versions. <details>. [P",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1599,Testability,log,logreg,1599," on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import harmonypy as hm; h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']); har= h_data.Z_corr; har = har.T; a_data.obsm['X_harmony'] = har.copy(); sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'); res = 1; sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res); a_data.write(test.h5ad); a_data = sc.read(test.h5ad); sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'); ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-6-8d70f4e1a0fa> in <module>; ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 588 ); 589 ; --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 591 ; 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 91 ):; 92 ; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1906,Testability,log,log,1906," on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import harmonypy as hm; h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']); har= h_data.Z_corr; har = har.T; a_data.obsm['X_harmony'] = har.copy(); sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'); res = 1; sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res); a_data.write(test.h5ad); a_data = sc.read(test.h5ad); sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'); ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-6-8d70f4e1a0fa> in <module>; ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 588 ); 589 ; --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 591 ; 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 91 ):; 92 ; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:2027,Testability,log,logging,2027," on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import harmonypy as hm; h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']); har= h_data.Z_corr; har = har.T; a_data.obsm['X_harmony'] = har.copy(); sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'); res = 1; sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res); a_data.write(test.h5ad); a_data = sc.read(test.h5ad); sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'); ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-6-8d70f4e1a0fa> in <module>; ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 588 ); 589 ; --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 591 ; 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 91 ):; 92 ; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:257,Usability,guid,guide,257,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import harmonypy as hm; h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']); har= h_data.Z_corr; har = har.T; a_data.obsm['X_harmony'] = har.copy(); sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'); res = 1; sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res); a_data.write(test.h5ad); a_data = sc.read(test.h5ad); sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'); ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-6-8d70f4e1a0fa> in <module>; ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 588 ); 589 ; --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 591 ; 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 91 ):; 92 ; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. #### Versions. <details>. [P",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2441:296,Deployability,install,install,296,"- [ y] I have checked that this issue has not already been reported.; - [ y] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:; [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem?. Thanks!. ### Minimal code sample (that we can copy&paste without having any data). ```python; from skmisc.loess import loess; ```. ```pytb; sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0); File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes; return _highly_variable_genes_seurat_v3(; File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3; raise ImportError(; ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>; from ._loess import (loess, loess_model, loess_inputs, loess_control,; ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.4.0; anndata 0.7.5; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_run",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:328,Deployability,install,install,328,"- [ y] I have checked that this issue has not already been reported.; - [ y] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:; [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem?. Thanks!. ### Minimal code sample (that we can copy&paste without having any data). ```python; from skmisc.loess import loess; ```. ```pytb; sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0); File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes; return _highly_variable_genes_seurat_v3(; File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3; raise ImportError(; ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>; from ._loess import (loess, loess_model, loess_inputs, loess_control,; ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.4.0; anndata 0.7.5; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_run",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:404,Deployability,install,installed,404,"- [ y] I have checked that this issue has not already been reported.; - [ y] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:; [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem?. Thanks!. ### Minimal code sample (that we can copy&paste without having any data). ```python; from skmisc.loess import loess; ```. ```pytb; sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0); File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes; return _highly_variable_genes_seurat_v3(; File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3; raise ImportError(; ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>; from ._loess import (loess, loess_model, loess_inputs, loess_control,; ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.4.0; anndata 0.7.5; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_run",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1284,Deployability,install,install,1284,"t it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:; [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem?. Thanks!. ### Minimal code sample (that we can copy&paste without having any data). ```python; from skmisc.loess import loess; ```. ```pytb; sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0); File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes; return _highly_variable_genes_seurat_v3(; File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3; raise ImportError(; ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>; from ._loess import (loess, loess_model, loess_inputs, loess_control,; ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.4.0; anndata 0.7.5; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1; google NA; h5py 3.8.0; hypergeom_ufunc NA; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.39.1; matplotlib 3.5.0; mpl_toolkits NA; natsort 8.3.1; nbinom_ufunc NA; numba 0.56.4; numexpr 2.8.3; numpy 1.22.4; packaging 23.0; pandas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1316,Deployability,install,install,1316,"t it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:; [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem?. Thanks!. ### Minimal code sample (that we can copy&paste without having any data). ```python; from skmisc.loess import loess; ```. ```pytb; sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0); File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes; return _highly_variable_genes_seurat_v3(; File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3; raise ImportError(; ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>; from ._loess import (loess, loess_model, loess_inputs, loess_control,; ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.4.0; anndata 0.7.5; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1; google NA; h5py 3.8.0; hypergeom_ufunc NA; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.39.1; matplotlib 3.5.0; mpl_toolkits NA; natsort 8.3.1; nbinom_ufunc NA; numba 0.56.4; numexpr 2.8.3; numpy 1.22.4; packaging 23.0; pandas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:2667,Testability,log,logical,2667," any data). ```python; from skmisc.loess import loess; ```. ```pytb; sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0); File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes; return _highly_variable_genes_seurat_v3(; File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3; raise ImportError(; ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>; from ._loess import (loess, loess_model, loess_inputs, loess_control,; ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.4.0; anndata 0.7.5; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1; google NA; h5py 3.8.0; hypergeom_ufunc NA; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.39.1; matplotlib 3.5.0; mpl_toolkits NA; natsort 8.3.1; nbinom_ufunc NA; numba 0.56.4; numexpr 2.8.3; numpy 1.22.4; packaging 23.0; pandas 1.5.3; pkg_resources NA; psutil 5.9.4; pyexpat NA; pyparsing 3.0.9; pytz 2022.7.1; scanpy 1.8.2; scipy 1.8.0; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 1.0.1; skmisc 0.1.4; tables 3.6.1; threadpoolctl 3.1.0; typing_extensions NA; yaml 6.0; -----; Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]; Linux-3.10.0-1127.el7.x86_64-x86_64-with-glibc2.17; 8 logical CPU cores, x86_64. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2442:300,Availability,reliab,reliably,300,"I want to use the regress_out function, analyse my data set, and then sub-cluster (for which I want to run highly_variable_genes again). However, this is not possible as the regress_out function removes the offset and therefore sets the means of genes to zero, so then the hvg function cannot be run reliably (see previous issue). I found a closed issue mentioning this problem and suggesting to ''add the offset again'. However I do not know how to do this. Could someone explain it to me?. _Originally posted by @VivianeSchulz in https://github.com/scverse/scanpy/issues/707#issuecomment-1446770111_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2442
https://github.com/scverse/scanpy/issues/2443:332,Availability,error,error,332,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached).; I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead.; Any help would be greatly appreciated!. My code:; adata_vel = scv.utils.merge(adata, adatal). This is my error:; <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----; anndata 0.8.0; scanpy 1.9.3; -----; OpenSSL 20.0.1; PIL 8.2.0; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; anndata2ri 1.0.6; annoy NA; anyio NA; appnope 0.1.2; asttokens NA; astunparse 1.6.3; attr 21.4.0; babel 2.9.0; backcall 0.2.0; backports NA; boto3 1.26.7; botocore 1.29.7; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cryptography 3.4.7; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; debugpy 1.5.1; decorator 5.0.6; dot_parser NA; dunamai 1.6.0; executing 0.8.2; fbpca NA; flatbuffers NA; fsspec 0.7.4; gast 0.5.3; get_version 3.5; google NA; gprofiler 1.0.0; h5py 3.7.0; idna 2.10; igraph 0.10.2; importlib_resources NA; intervaltree NA; ipykernel 6.8.0; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 3.0.2; jmespath 1.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; keras 2.8.0; keras_preprocessi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:348,Availability,error,error,348,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached).; I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead.; Any help would be greatly appreciated!. My code:; adata_vel = scv.utils.merge(adata, adatal). This is my error:; <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----; anndata 0.8.0; scanpy 1.9.3; -----; OpenSSL 20.0.1; PIL 8.2.0; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; anndata2ri 1.0.6; annoy NA; anyio NA; appnope 0.1.2; asttokens NA; astunparse 1.6.3; attr 21.4.0; babel 2.9.0; backcall 0.2.0; backports NA; boto3 1.26.7; botocore 1.29.7; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cryptography 3.4.7; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; debugpy 1.5.1; decorator 5.0.6; dot_parser NA; dunamai 1.6.0; executing 0.8.2; fbpca NA; flatbuffers NA; fsspec 0.7.4; gast 0.5.3; get_version 3.5; google NA; gprofiler 1.0.0; h5py 3.7.0; idna 2.10; igraph 0.10.2; importlib_resources NA; intervaltree NA; ipykernel 6.8.0; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 3.0.2; jmespath 1.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; keras 2.8.0; keras_preprocessi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:527,Availability,error,error,527,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached).; I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead.; Any help would be greatly appreciated!. My code:; adata_vel = scv.utils.merge(adata, adatal). This is my error:; <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----; anndata 0.8.0; scanpy 1.9.3; -----; OpenSSL 20.0.1; PIL 8.2.0; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; anndata2ri 1.0.6; annoy NA; anyio NA; appnope 0.1.2; asttokens NA; astunparse 1.6.3; attr 21.4.0; babel 2.9.0; backcall 0.2.0; backports NA; boto3 1.26.7; botocore 1.29.7; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cryptography 3.4.7; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; debugpy 1.5.1; decorator 5.0.6; dot_parser NA; dunamai 1.6.0; executing 0.8.2; fbpca NA; flatbuffers NA; fsspec 0.7.4; gast 0.5.3; get_version 3.5; google NA; gprofiler 1.0.0; h5py 3.7.0; idna 2.10; igraph 0.10.2; importlib_resources NA; intervaltree NA; ipykernel 6.8.0; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 3.0.2; jmespath 1.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; keras 2.8.0; keras_preprocessi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:825,Availability,error,error,825,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached).; I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead.; Any help would be greatly appreciated!. My code:; adata_vel = scv.utils.merge(adata, adatal). This is my error:; <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----; anndata 0.8.0; scanpy 1.9.3; -----; OpenSSL 20.0.1; PIL 8.2.0; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; anndata2ri 1.0.6; annoy NA; anyio NA; appnope 0.1.2; asttokens NA; astunparse 1.6.3; attr 21.4.0; babel 2.9.0; backcall 0.2.0; backports NA; boto3 1.26.7; botocore 1.29.7; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cryptography 3.4.7; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; debugpy 1.5.1; decorator 5.0.6; dot_parser NA; dunamai 1.6.0; executing 0.8.2; fbpca NA; flatbuffers NA; fsspec 0.7.4; gast 0.5.3; get_version 3.5; google NA; gprofiler 1.0.0; h5py 3.7.0; idna 2.10; igraph 0.10.2; importlib_resources NA; intervaltree NA; ipykernel 6.8.0; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 3.0.2; jmespath 1.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; keras 2.8.0; keras_preprocessi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:3213,Integrability,wrap,wrapt,3213,"me NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; debugpy 1.5.1; decorator 5.0.6; dot_parser NA; dunamai 1.6.0; executing 0.8.2; fbpca NA; flatbuffers NA; fsspec 0.7.4; gast 0.5.3; get_version 3.5; google NA; gprofiler 1.0.0; h5py 3.7.0; idna 2.10; igraph 0.10.2; importlib_resources NA; intervaltree NA; ipykernel 6.8.0; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 3.0.2; jmespath 1.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; keras 2.8.0; keras_preprocessing 1.1.2; kiwisolver 1.3.1; leidenalg 0.7.0; llvmlite 0.36.0; louvain 0.7.0; markupsafe 2.0.1; matplotlib 3.7.1; matplotlib_inline NA; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.53.1; numpy 1.22.0; opt_einsum v3.3.0; packaging 20.9; pandas 1.2.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.17; psutil 5.8.0; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pycparser 2.20; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 1.4.2; pygments 2.8.1; pynndescent 0.5.4; pyparsing 2.4.7; pyrsistent NA; pytz 2021.3; requests 2.25.1; rpy2 3.4.2; ruamel NA; scanorama 1.7.1; scipy 1.6.2; scrublet NA; scvelo 0.2.5; seaborn 0.11.1; send2trash NA; session_info 1.0.0; six 1.15.0; sklearn 0.24.1; sniffio 1.2.0; socks 1.7.1; sortedcontainers 2.3.0; sparse 0.13.0; sphinxcontrib NA; stack_data 0.1.4; statsmodels 0.12.2; tblib 1.7.0; tensorboard 2.8.0; tensorflow 2.8.0; termcolor 1.1.0; texttable 1.6.4; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.1.1; typing_extensions NA; tzlocal NA; umap 0.5.1; urllib3 1.26.4; wcwidth 0.2.5; wrapt 1.12.1; yaml 5.4.1; zipp NA; zmq 20.0.0; zope NA; -----; IPython 8.0.1; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.0.14; notebook 6.3.0; -----; Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]; macOS-10.15.7-x86_64-i386-64bit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:1311,Performance,bottleneck,bottleneck,1311," files I get an error (code and error attached).; I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead.; Any help would be greatly appreciated!. My code:; adata_vel = scv.utils.merge(adata, adatal). This is my error:; <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----; anndata 0.8.0; scanpy 1.9.3; -----; OpenSSL 20.0.1; PIL 8.2.0; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; anndata2ri 1.0.6; annoy NA; anyio NA; appnope 0.1.2; asttokens NA; astunparse 1.6.3; attr 21.4.0; babel 2.9.0; backcall 0.2.0; backports NA; boto3 1.26.7; botocore 1.29.7; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cryptography 3.4.7; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; debugpy 1.5.1; decorator 5.0.6; dot_parser NA; dunamai 1.6.0; executing 0.8.2; fbpca NA; flatbuffers NA; fsspec 0.7.4; gast 0.5.3; get_version 3.5; google NA; gprofiler 1.0.0; h5py 3.7.0; idna 2.10; igraph 0.10.2; importlib_resources NA; intervaltree NA; ipykernel 6.8.0; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 3.0.2; jmespath 1.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; keras 2.8.0; keras_preprocessing 1.1.2; kiwisolver 1.3.1; leidenalg 0.7.0; llvmlite 0.36.0; louvain 0.7.0; markupsafe 2.0.1; matplotlib 3.7.1; matplotlib_inline NA; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.53.1; numpy 1.22.0; opt_einsum v3.3.0; packaging 20.9; pandas 1.2.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2444:1368,Modifiability,flexible,flexible,1368,"- [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [x] External tools: Do you know an existing package that should go into `sc.external.*`?. Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python; sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]); ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python; viz = AnnDataViz(adata); viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip; viz.add_left(key=""cell_type"", plot=""label""); viz.render(); ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:613,Usability,intuit,intuitively,613,"- [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [x] External tools: Do you know an existing package that should go into `sc.external.*`?. Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python; sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]); ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python; viz = AnnDataViz(adata); viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip; viz.add_left(key=""cell_type"", plot=""label""); viz.render(); ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2445:1479,Availability,error,error,1479,"```; Python 3.9.15 (main, Nov 24 2022, 14:31:59) ; [GCC 11.2.0] :: Anaconda, Inc. on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import scanpy; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>; from . import plotting as pl; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import (; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>; from . import _utils; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>; class _AxesSubplot(Axes, axes.SubplotBase, ABC):; TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases; ```. - [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1585,Testability,log,logging,1585,"```; Python 3.9.15 (main, Nov 24 2022, 14:31:59) ; [GCC 11.2.0] :: Anaconda, Inc. on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import scanpy; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>; from . import plotting as pl; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import (; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>; from . import _utils; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>; class _AxesSubplot(Axes, axes.SubplotBase, ABC):; TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases; ```. - [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1194,Usability,guid,guide,1194,"```; Python 3.9.15 (main, Nov 24 2022, 14:31:59) ; [GCC 11.2.0] :: Anaconda, Inc. on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import scanpy; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>; from . import plotting as pl; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>; from ._anndata import (; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>; from . import _utils; File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>; class _AxesSubplot(Axes, axes.SubplotBase, ABC):; TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases; ```. - [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2446:53,Deployability,pipeline,pipelines,53,"https://github.com/scverse/scanpy/blob/master/.azure-pipelines.yml#L14. https://learn.microsoft.com/en-us/answers/questions/1181262/what-happens-to-azure-vms-with-ubuntu-18-04-lts-af. and our CI already cries about it. Let's up this to a more recent version, maybe even 22.04?. While we're at it, I'd also remove 3.7 from the CI because it'll lose support very soon. We could add one of the more recent Python versions instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2446
https://github.com/scverse/scanpy/issues/2446:80,Usability,learn,learn,80,"https://github.com/scverse/scanpy/blob/master/.azure-pipelines.yml#L14. https://learn.microsoft.com/en-us/answers/questions/1181262/what-happens-to-azure-vms-with-ubuntu-18-04-lts-af. and our CI already cries about it. Let's up this to a more recent version, maybe even 22.04?. While we're at it, I'd also remove 3.7 from the CI because it'll lose support very soon. We could add one of the more recent Python versions instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2446
https://github.com/scverse/scanpy/issues/2448:332,Availability,avail,available,332,"<!-- What kind of feature would you like to request? -->; How to read in the Spatial object directly from gene count matrix (.mtx) file and related images (without HDF5 file)?; - [ +] Additional function parameters / changed functionality / changed defaults?. <!-- Please describe your wishes below: -->; I am working on a publicly available dataset which only has provided the gene count (matrix.mtx), features (features.tsv) and barcodes (barcodes.tsv) in addition to the spatial folder (the output of spaceranger). How should I read in this dataset using scanpy?. Thank you very much in advance; ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2448
https://github.com/scverse/scanpy/issues/2449:1419,Availability,error,error,1419,"copy&paste without having any data). ```python; import scanpy; acc = ""E-MTAB-4888""; ad_df = scanpy.datasets.ebi_expression_atlas(acc); ```. ```pytb; File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response); [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's; [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted.; [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):; --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(; [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs); [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args); [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:; [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args; --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1893,Availability,error,error,1893,"request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's; [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted.; [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):; --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(; [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs); [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args); [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:; [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args; --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args); [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:; [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name); --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3757,Availability,Error,Error,3757,"); [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:; [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args; --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args); [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:; [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name); --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args); [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:; [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs); [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):; --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/); ```. #### Versions. <details>. anndata 0.8.0; scanpy 1.9.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3784,Availability,Error,Error,3784,"); [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:; [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args; --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args); [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:; [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name); --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args); [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:; [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs); [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):; --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/); ```. #### Versions. <details>. anndata 0.8.0; scanpy 1.9.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:259,Usability,guid,guide,259,"- [ X] I have checked that this issue has not already been reported.; - [ X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy; acc = ""E-MTAB-4888""; ad_df = scanpy.datasets.ebi_expression_atlas(acc); ```. ```pytb; File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response); [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's; [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted.; [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):; --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(; [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs); [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args); [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2450:477,Security,expose,exposed,477,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ x] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ... 1. exposed a setting to prevent `sc.pp.<fn>` from saving with a ""prefix"" (default filename) if `type(save) == str`. Why?; I don't want my files having that prefix. . 2. please add PHATE and magic-impute to embedding options :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2450
https://github.com/scverse/scanpy/issues/2450:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ x] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ... 1. exposed a setting to prevent `sc.pp.<fn>` from saving with a ""prefix"" (default filename) if `type(save) == str`. Why?; I don't want my files having that prefix. . 2. please add PHATE and magic-impute to embedding options :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2450
https://github.com/scverse/scanpy/pull/2452:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Code changes pertaining to this issue: https://github.com/scverse/scanpy/issues/1673/; Added Discourse and twitter links to scanpy's pypi packaging.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2452
https://github.com/scverse/scanpy/pull/2452:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Code changes pertaining to this issue: https://github.com/scverse/scanpy/issues/1673/; Added Discourse and twitter links to scanpy's pypi packaging.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2452
https://github.com/scverse/scanpy/issues/2453:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; I would like to use a precomputed distance or affinity matrix with many of the tools in scanpy. Currently this feature is unsupported. It should be a relatively small PR - essentially adding ""precomputed_key"" to `sc.pp.neighbors` etc that specifies a key in `obsp` to look for distances.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2453
https://github.com/scverse/scanpy/pull/2458:294,Deployability,pipeline,pipelines,294,"The ""outs"" from `spaceranger count` v2 differ from v1. Specifically, `tissue_positions_list.csv` has been renamed `tissue_positions.csv` and now has headers. Fortunately the column names exactly match those used by `scanpy`. See https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/spatial (search for `tissue_positions.csv`). This PR adjusts `sc.read_visium()` so that it can load the outputs of `spaceranger count` v2. The API / method signature is unchanged, so no changes to the documentation are required. The version is inferred from the presence or otherwise of the old `tissue_positions_list.csv` (implying v1) and then the files in `spatial/` are handled accordingly, including differential handling of headers / column names. @linhuawang; @sopvdl; @TaopengWang",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2458
https://github.com/scverse/scanpy/pull/2458:413,Performance,load,load,413,"The ""outs"" from `spaceranger count` v2 differ from v1. Specifically, `tissue_positions_list.csv` has been renamed `tissue_positions.csv` and now has headers. Fortunately the column names exactly match those used by `scanpy`. See https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/spatial (search for `tissue_positions.csv`). This PR adjusts `sc.read_visium()` so that it can load the outputs of `spaceranger count` v2. The API / method signature is unchanged, so no changes to the documentation are required. The version is inferred from the presence or otherwise of the old `tissue_positions_list.csv` (implying v1) and then the files in `spatial/` are handled accordingly, including differential handling of headers / column names. @linhuawang; @sopvdl; @TaopengWang",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2458
https://github.com/scverse/scanpy/issues/2459:1204,Availability,FAILURE,FAILURES,1204,"tructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash; git clone https://github.com/scverse/scanpy.git; cd scanpy; git submodule update --init --recursive; conda create --name scanpy-dev python=3.8; conda activate scanpy-dev; pip install -e '.[dev,doc,test]'; pytest; ```. ```pytb; =========================================================================================== FAILURES ============================================================================================; _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>; pbmc = AnnData object with n_obs  n_vars = 700  765; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'; test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph; @pytest.mark.parametrize(; ""test_id,func"",; [; (""master_paga"", sc.pl.paga),; (""master_paga_continuous"", partial(sc.pl.paga, color=""CST3"")),; (""master_paga_continuous_obs"", partial(sc.pl.paga, color=""cool_feature"")),; (; ""master_paga_continuous_multiple"",; partial(sc.pl.paga, color=['CST3', 'GATA2']),; ),; (""master_paga_compare"", partial(s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:247,Deployability,install,installing,247,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash; git clone https://github.com/scverse/scanpy.git; cd scanpy; git submodule update --init --recursive; conda create --name scanpy-dev python=3.8; conda activate scanpy-dev; pip install -e '.[dev,doc,test]'; pytest; ```. ```pytb; =========================================================================================== FAILURES ============================================================================================; _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>; pbmc = AnnData object with n_obs  n_vars = 700  765; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'; test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph; @pytest.mark.parametrize(; ""test_id,fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:451,Deployability,install,installation,451,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash; git clone https://github.com/scverse/scanpy.git; cd scanpy; git submodule update --init --recursive; conda create --name scanpy-dev python=3.8; conda activate scanpy-dev; pip install -e '.[dev,doc,test]'; pytest; ```. ```pytb; =========================================================================================== FAILURES ============================================================================================; _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>; pbmc = AnnData object with n_obs  n_vars = 700  765; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'; test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph; @pytest.mark.parametrize(; ""test_id,fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:959,Deployability,update,update,959,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash; git clone https://github.com/scverse/scanpy.git; cd scanpy; git submodule update --init --recursive; conda create --name scanpy-dev python=3.8; conda activate scanpy-dev; pip install -e '.[dev,doc,test]'; pytest; ```. ```pytb; =========================================================================================== FAILURES ============================================================================================; _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>; pbmc = AnnData object with n_obs  n_vars = 700  765; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'; test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph; @pytest.mark.parametrize(; ""test_id,fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:1060,Deployability,install,install,1060,"ady been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash; git clone https://github.com/scverse/scanpy.git; cd scanpy; git submodule update --init --recursive; conda create --name scanpy-dev python=3.8; conda activate scanpy-dev; pip install -e '.[dev,doc,test]'; pytest; ```. ```pytb; =========================================================================================== FAILURES ============================================================================================; _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>; pbmc = AnnData object with n_obs  n_vars = 700  765; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'; test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph; @pytest.mark.parametrize(; ""test_id,func"",; [; (""master_paga"", sc.pl.paga),; (""master_pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:6856,Deployability,update,updated,6856," return next(iter(obj)); elif isinstance(obj, np.flatiter):; # TODO do the finite filtering on this; return obj[0]; elif isinstance(obj, collections.abc.Iterator):; raise RuntimeError(""matplotlib does not ""; ""support generators as input""); else:; > return next(val for val in obj if safe_isfinite(val)); E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration; ...; ======================================================================== short test summary info =========================================================================; FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration; FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: ; ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================; ```. #### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.10.0.dev47+g99697347; -----; PIL 9.5.0; asciitree NA; cloudpickle 2.2.1; cycler 0.10.0; cython_runtime NA; dask 2023.3.2; dateutil 2.8.2; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; h5py 3.8.0; igraph 0.10.4; importlib_resources NA; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.2; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.3.1; numba 0.56.4; numcodecs 0.11.0; numpy 1.23.5; packaging 23.0; pandas 1.5.3; pkg_resources NA; psutil 5.9.4; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.6.1; setuptools_scm NA; six 1.16.0; sklearn 1.2.2; sphinxcontrib NA; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; typing_extensions NA; wcwidth 0.2.6; yaml 6.0; zarr 2.14.2; zipp NA; -----; Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:05:36) [Clang 14.0.6 ]; macOS-10.16-x86_64-i386-64bit; -----; Session information updated at 2023-04-01 09:45; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:4163,Integrability,protocol,protocol,4163,"paga.py:911: in _paga_graph; sct = ax.scatter(; ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/__init__.py:1442: in inner; return func(ax, *map(sanitize_sequence, args), **kwargs); ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4602: in scatter; self._parse_scatter_color_args(; ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4400: in _parse_scatter_color_args; and isinstance(cbook._safe_first_finite(c), str))); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. obj = [nan, nan, nan, nan, nan, nan, ...]. def _safe_first_finite(obj, *, skip_nonfinite=True):; """"""; Return the first non-None (and optionally finite) element in *obj*.; ; This is a method for internal use.; ; This is a type-independent way of obtaining the first non-None element,; supporting both index access and the iterator protocol.; The first non-None element will be obtained when skip_none is True.; """"""; def safe_isfinite(val):; if val is None:; return False; try:; return np.isfinite(val) if np.isscalar(val) else True; except TypeError:; # This is something that numpy can not make heads or tails; # of, assume ""finite""; return True; if skip_nonfinite is False:; if isinstance(obj, collections.abc.Iterator):; # needed to accept `array.flat` as input.; # np.flatiter reports as an instance of collections.Iterator; # but can still be indexed via [].; # This has the side effect of re-setting the iterator, but; # that is acceptable.; try:; return obj[0]; except TypeError:; pass; raise RuntimeError(""matplotlib does not support generators ""; ""as input""); return next(iter(obj)); elif isinstance(obj, np.flatiter):; # TODO do the finite filtering on this; return obj[0]; elif isinstance(obj, collections.abc.Iterator):; raise RuntimeError(""matplotlib does not """,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:4139,Security,access,access,4139,"paga.py:911: in _paga_graph; sct = ax.scatter(; ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/__init__.py:1442: in inner; return func(ax, *map(sanitize_sequence, args), **kwargs); ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4602: in scatter; self._parse_scatter_color_args(; ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4400: in _parse_scatter_color_args; and isinstance(cbook._safe_first_finite(c), str))); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. obj = [nan, nan, nan, nan, nan, nan, ...]. def _safe_first_finite(obj, *, skip_nonfinite=True):; """"""; Return the first non-None (and optionally finite) element in *obj*.; ; This is a method for internal use.; ; This is a type-independent way of obtaining the first non-None element,; supporting both index access and the iterator protocol.; The first non-None element will be obtained when skip_none is True.; """"""; def safe_isfinite(val):; if val is None:; return False; try:; return np.isfinite(val) if np.isscalar(val) else True; except TypeError:; # This is something that numpy can not make heads or tails; # of, assume ""finite""; return True; if skip_nonfinite is False:; if isinstance(obj, collections.abc.Iterator):; # needed to accept `array.flat` as input.; # np.flatiter reports as an instance of collections.Iterator; # but can still be indexed via [].; # This has the side effect of re-setting the iterator, but; # that is acceptable.; try:; return obj[0]; except TypeError:; pass; raise RuntimeError(""matplotlib does not support generators ""; ""as input""); return next(iter(obj)); elif isinstance(obj, np.flatiter):; # TODO do the finite filtering on this; return obj[0]; elif isinstance(obj, collections.abc.Iterator):; raise RuntimeError(""matplotlib does not """,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:503,Testability,test,tests,503,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash; git clone https://github.com/scverse/scanpy.git; cd scanpy; git submodule update --init --recursive; conda create --name scanpy-dev python=3.8; conda activate scanpy-dev; pip install -e '.[dev,doc,test]'; pytest; ```. ```pytb; =========================================================================================== FAILURES ============================================================================================; _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>; pbmc = AnnData object with n_obs  n_vars = 700  765; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'; test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph; @pytest.mark.parametrize(; ""test_id,fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:1082,Testability,test,test,1082,"rmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash; git clone https://github.com/scverse/scanpy.git; cd scanpy; git submodule update --init --recursive; conda create --name scanpy-dev python=3.8; conda activate scanpy-dev; pip install -e '.[dev,doc,test]'; pytest; ```. ```pytb; =========================================================================================== FAILURES ============================================================================================; _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>; pbmc = AnnData object with n_obs  n_vars = 700  765; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'; test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph; @pytest.mark.parametrize(; ""test_id,func"",; [; (""master_paga"", sc.pl.paga),; (""master_paga_continuous"", partial(sc.pl.paga, co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:2798,Testability,test,tests,2798,"s', 'connectivities'; test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph; @pytest.mark.parametrize(; ""test_id,func"",; [; (""master_paga"", sc.pl.paga),; (""master_paga_continuous"", partial(sc.pl.paga, color=""CST3"")),; (""master_paga_continuous_obs"", partial(sc.pl.paga, color=""cool_feature"")),; (; ""master_paga_continuous_multiple"",; partial(sc.pl.paga, color=['CST3', 'GATA2']),; ),; (""master_paga_compare"", partial(sc.pl.paga_compare, legend_fontoutline=2)),; (; ""master_paga_compare_continuous"",; partial(sc.pl.paga_compare, color='CST3', legend_fontsize=5),; ),; (; ""master_paga_compare_pca"",; partial(sc.pl.paga_compare, basis='X_pca', legend_fontweight='normal'),; ),; ],; ); def test_paga_plots(image_comparer, pbmc, test_id, func):; save_and_compare_images = image_comparer(ROOT, FIGS, tol=30); common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False); ; > func(pbmc, **common). scanpy/tests/test_paga.py:57: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _; scanpy/plotting/_tools/paga.py:576: in paga; sct = _paga_graph(; scanpy/plotting/_tools/paga.py:911: in _paga_graph; sct = ax.scatter(; ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/__init__.py:1442: in inner; return func(ax, *map(sanitize_sequence, args), **kwargs); ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4602: in scatter; self._parse_scatter_color_args(; ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4400: in _parse_scatter_color_args; and isinstance(cbook._safe_first_finite(c), str))); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5421,Testability,test,test,5421,"; # of, assume ""finite""; return True; if skip_nonfinite is False:; if isinstance(obj, collections.abc.Iterator):; # needed to accept `array.flat` as input.; # np.flatiter reports as an instance of collections.Iterator; # but can still be indexed via [].; # This has the side effect of re-setting the iterator, but; # that is acceptable.; try:; return obj[0]; except TypeError:; pass; raise RuntimeError(""matplotlib does not support generators ""; ""as input""); return next(iter(obj)); elif isinstance(obj, np.flatiter):; # TODO do the finite filtering on this; return obj[0]; elif isinstance(obj, collections.abc.Iterator):; raise RuntimeError(""matplotlib does not ""; ""support generators as input""); else:; > return next(val for val in obj if safe_isfinite(val)); E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration; ...; ======================================================================== short test summary info =========================================================================; FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration; FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: ; ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================; ```. #### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.10.0.dev47+g99697347; -----; PIL 9.5.0; asciitree NA; cloudpickle 2.2.1; cycler 0.10.0; cython_runtime NA; dask 2023.3.2; dateutil 2.8.2; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; h5py 3.8.0; igraph 0.10.4; importlib_resources NA; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.2; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.3.1; numba 0.56.4; numcodecs 0.11.0; numpy 1.23.5; packaging 23.0; pandas 1.5.3; pkg_resources NA; psutil 5.9.4; pyparsing 3.0.9; pytz ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5528,Testability,test,tests,5528,"; # of, assume ""finite""; return True; if skip_nonfinite is False:; if isinstance(obj, collections.abc.Iterator):; # needed to accept `array.flat` as input.; # np.flatiter reports as an instance of collections.Iterator; # but can still be indexed via [].; # This has the side effect of re-setting the iterator, but; # that is acceptable.; try:; return obj[0]; except TypeError:; pass; raise RuntimeError(""matplotlib does not support generators ""; ""as input""); return next(iter(obj)); elif isinstance(obj, np.flatiter):; # TODO do the finite filtering on this; return obj[0]; elif isinstance(obj, collections.abc.Iterator):; raise RuntimeError(""matplotlib does not ""; ""support generators as input""); else:; > return next(val for val in obj if safe_isfinite(val)); E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration; ...; ======================================================================== short test summary info =========================================================================; FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration; FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: ; ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================; ```. #### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.10.0.dev47+g99697347; -----; PIL 9.5.0; asciitree NA; cloudpickle 2.2.1; cycler 0.10.0; cython_runtime NA; dask 2023.3.2; dateutil 2.8.2; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; h5py 3.8.0; igraph 0.10.4; importlib_resources NA; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.2; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.3.1; numba 0.56.4; numcodecs 0.11.0; numpy 1.23.5; packaging 23.0; pandas 1.5.3; pkg_resources NA; psutil 5.9.4; pyparsing 3.0.9; pytz ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5629,Testability,test,tests,5629,"ut.; # np.flatiter reports as an instance of collections.Iterator; # but can still be indexed via [].; # This has the side effect of re-setting the iterator, but; # that is acceptable.; try:; return obj[0]; except TypeError:; pass; raise RuntimeError(""matplotlib does not support generators ""; ""as input""); return next(iter(obj)); elif isinstance(obj, np.flatiter):; # TODO do the finite filtering on this; return obj[0]; elif isinstance(obj, collections.abc.Iterator):; raise RuntimeError(""matplotlib does not ""; ""support generators as input""); else:; > return next(val for val in obj if safe_isfinite(val)); E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration; ...; ======================================================================== short test summary info =========================================================================; FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration; FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: ; ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================; ```. #### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.10.0.dev47+g99697347; -----; PIL 9.5.0; asciitree NA; cloudpickle 2.2.1; cycler 0.10.0; cython_runtime NA; dask 2023.3.2; dateutil 2.8.2; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; h5py 3.8.0; igraph 0.10.4; importlib_resources NA; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.2; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.3.1; numba 0.56.4; numcodecs 0.11.0; numpy 1.23.5; packaging 23.0; pandas 1.5.3; pkg_resources NA; psutil 5.9.4; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.6.1; setuptools_scm NA; six 1.16.0; sklearn 1.2.2; sphinxcontrib NA; texttable 1.6.7; threadpool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5667,Testability,Assert,AssertionError,5667,"t of re-setting the iterator, but; # that is acceptable.; try:; return obj[0]; except TypeError:; pass; raise RuntimeError(""matplotlib does not support generators ""; ""as input""); return next(iter(obj)); elif isinstance(obj, np.flatiter):; # TODO do the finite filtering on this; return obj[0]; elif isinstance(obj, collections.abc.Iterator):; raise RuntimeError(""matplotlib does not ""; ""support generators as input""); else:; > return next(val for val in obj if safe_isfinite(val)); E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration; ...; ======================================================================== short test summary info =========================================================================; FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration; FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: ; ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================; ```. #### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.10.0.dev47+g99697347; -----; PIL 9.5.0; asciitree NA; cloudpickle 2.2.1; cycler 0.10.0; cython_runtime NA; dask 2023.3.2; dateutil 2.8.2; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; h5py 3.8.0; igraph 0.10.4; importlib_resources NA; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; markupsafe 2.1.2; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.3.1; numba 0.56.4; numcodecs 0.11.0; numpy 1.23.5; packaging 23.0; pandas 1.5.3; pkg_resources NA; psutil 5.9.4; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.6.1; setuptools_scm NA; six 1.16.0; sklearn 1.2.2; sphinxcontrib NA; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; typing_extensions NA; wcwidth 0.2.6; yaml 6.0; zarr 2.14.2; zipp NA; -----; Python 3.8.16 | ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:645,Usability,guid,guide,645,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash; git clone https://github.com/scverse/scanpy.git; cd scanpy; git submodule update --init --recursive; conda create --name scanpy-dev python=3.8; conda activate scanpy-dev; pip install -e '.[dev,doc,test]'; pytest; ```. ```pytb; =========================================================================================== FAILURES ============================================================================================; _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>; pbmc = AnnData object with n_obs  n_vars = 700  765; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'; test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph; @pytest.mark.parametrize(; ""test_id,fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/pull/2460:47,Modifiability,variab,variables,47,Fixes #1646 . Now supports coloring by boolean variables such as `True` and `False`. **Tasks to complete:** . - [x] Add test,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460
https://github.com/scverse/scanpy/pull/2460:120,Testability,test,test,120,Fixes #1646 . Now supports coloring by boolean variables such as `True` and `False`. **Tasks to complete:** . - [x] Add test,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460
https://github.com/scverse/scanpy/issues/2461:86,Availability,Error,Error,86,"Dears; Thanks for this great tools. We had loom file from Seurat(V4), while got those Error when used 'sc.read_loom' function:. ```pytb; sc_adata=sc.read_loom(sc_input,sparse = True); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f; return f(*args, **kwargs); File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 280, in read_loom; obs, obsm = _fmt_loom_axis_attrs(dict(lc.col_attrs), obs_names, obsm_mapping); File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 159, in _fmt_loom_axis_attrs; if v.ndim > 1 and v.shape[1] > 1:; AttributeError: 'NoneType' object has no attribute 'ndim' ; ```. We want to know how to solve this, we are looking forward for your help, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2461
https://github.com/scverse/scanpy/issues/2462:40,Deployability,upgrade,upgraded,40,Will the api of scanpy.read_visium be upgraded to be compatible with the new space information file name tissue_positions.csv which was previously named tissue_positions_list.csv after Space Ranger 2.0?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2462
https://github.com/scverse/scanpy/pull/2463:43,Deployability,pipeline,pipelines,43,Following what nf-core did to all of their pipelines and tools.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2463
https://github.com/scverse/scanpy/issues/2464:383,Modifiability,layers,layers,383,"I have an anndata object like this . > adata_all:; > AnnData object with n_obs  n_vars = 10000  14; > obs: 'sample', 'batch', 'condition'; > var: 'n', 'channel', 'marker', '$PnB', '$PnG', '$PnE', 'signal_type', '$PnR-0', '$PnR-1', '$PnR-2', 'AB'; > uns: 'meta', 'neighbors', 'pca', 'sample_colors', 'umap', 'condition_colors'; > obsm: 'X_pca', 'X_umap', 'X_tsne'; > varm: 'PCs'; > layers: 'original'; > obsp: 'connectivities', 'distances'. The conditions are as follow: conditions = ['a', 'b', 'c'].; How can I draw tSNEs for each marker separated by each condition in a row? As you can see condition is a feature of obstacles and marker is a feature of variables. I want to plot tSNEs for each marker in three different tSNEs based on conditions. Is this possible?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2464
https://github.com/scverse/scanpy/issues/2464:656,Modifiability,variab,variables,656,"I have an anndata object like this . > adata_all:; > AnnData object with n_obs  n_vars = 10000  14; > obs: 'sample', 'batch', 'condition'; > var: 'n', 'channel', 'marker', '$PnB', '$PnG', '$PnE', 'signal_type', '$PnR-0', '$PnR-1', '$PnR-2', 'AB'; > uns: 'meta', 'neighbors', 'pca', 'sample_colors', 'umap', 'condition_colors'; > obsm: 'X_pca', 'X_umap', 'X_tsne'; > varm: 'PCs'; > layers: 'original'; > obsp: 'connectivities', 'distances'. The conditions are as follow: conditions = ['a', 'b', 'c'].; How can I draw tSNEs for each marker separated by each condition in a row? As you can see condition is a feature of obstacles and marker is a feature of variables. I want to plot tSNEs for each marker in three different tSNEs based on conditions. Is this possible?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2464
https://github.com/scverse/scanpy/issues/2465:358,Availability,error,error,358,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PRs fix is released in a stable anndata version, well start seeing this error unless we fix it first. (the minimal tests + anndata dev dont have dask, so we dont see the error there either). ```console; $ pip install dask; $ pytest -k test_normalize_total; ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb; IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb; ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']); def test_normalize_total(typ, dtype):; adata = AnnData(typ(X_total), dtype=dtype); sc.pp.normalize_total(adata, key_added='n_counts'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]); sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:538,Availability,error,error,538,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PRs fix is released in a stable anndata version, well start seeing this error unless we fix it first. (the minimal tests + anndata dev dont have dask, so we dont see the error there either). ```console; $ pip install dask; $ pytest -k test_normalize_total; ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb; IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb; ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']); def test_normalize_total(typ, dtype):; adata = AnnData(typ(X_total), dtype=dtype); sc.pp.normalize_total(adata, key_added='n_counts'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]); sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:638,Availability,error,error,638,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PRs fix is released in a stable anndata version, well start seeing this error unless we fix it first. (the minimal tests + anndata dev dont have dask, so we dont see the error there either). ```console; $ pip install dask; $ pytest -k test_normalize_total; ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb; IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb; ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']); def test_normalize_total(typ, dtype):; adata = AnnData(typ(X_total), dtype=dtype); sc.pp.normalize_total(adata, key_added='n_counts'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]); sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:734,Availability,error,error,734,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PRs fix is released in a stable anndata version, well start seeing this error unless we fix it first. (the minimal tests + anndata dev dont have dask, so we dont see the error there either). ```console; $ pip install dask; $ pytest -k test_normalize_total; ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb; IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb; ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']); def test_normalize_total(typ, dtype):; adata = AnnData(typ(X_total), dtype=dtype); sc.pp.normalize_total(adata, key_added='n_counts'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]); sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:476,Deployability,release,released,476,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PRs fix is released in a stable anndata version, well start seeing this error unless we fix it first. (the minimal tests + anndata dev dont have dask, so we dont see the error there either). ```console; $ pip install dask; $ pytest -k test_normalize_total; ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb; IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb; ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']); def test_normalize_total(typ, dtype):; adata = AnnData(typ(X_total), dtype=dtype); sc.pp.normalize_total(adata, key_added='n_counts'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]); sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:677,Deployability,install,install,677,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PRs fix is released in a stable anndata version, well start seeing this error unless we fix it first. (the minimal tests + anndata dev dont have dask, so we dont see the error there either). ```console; $ pip install dask; $ pytest -k test_normalize_total; ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb; IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb; ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']); def test_normalize_total(typ, dtype):; adata = AnnData(typ(X_total), dtype=dtype); sc.pp.normalize_total(adata, key_added='n_counts'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]); sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:4965,Deployability,update,updated,4965,"44051 exclude bool, which would return a 2d ndarray; key = com.cast_scalar_indexer(key, warn_float=True); return getitem(key); ; if isinstance(key, slice):; # This case is separated from the conditional above to avoid; # pessimization com.is_bool_indexer and ndim checks.; result = getitem(key); # Going through simple_new for performance.; return type(self)._simple_new(result, name=self._name); ; if com.is_bool_indexer(key):; # if we have list[bools, length=1e5] then doing this check+convert; # takes 166 s + 2.1 ms and cuts the ndarray.__getitem__; # time below from 3.8 ms to 496 s; # if we already have ndarray[bool], the overhead is 1.4 s or .25%; key = np.asarray(key, dtype=bool); ; > result = getitem(key); E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError; ```. #### Versions. <details>. -----; anndata 0.9.0rc2.dev18+g7771f6ee; scanpy 1.10.0.dev50+g3e3427d0; -----; PIL 9.1.1; asciitree NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.2.1; cycler 0.10.0; cython_runtime NA; dask 2023.3.2; dateutil 2.8.2; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.17.3; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; jinja2 3.1.2; joblib 1.1.0; kiwisolver 1.4.3; leidenalg 0.9.1; llvmlite 0.38.1; markupsafe 2.1.1; matplotlib 3.5.2; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.2; numcodecs 0.10.2; numpy 1.22.4; packaging 21.3; pandas 1.4.3; pkg_resources NA; psutil 5.9.1; pyparsing 3.0.9; pytz 2022.1; scipy 1.8.1; session_info 1.0.0; setuptools 67.2.0; setuptools_scm NA; six 1.16.0; sklearn 1.1.1; sphinxcontrib NA; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zarr 2.12.0; zipp NA; -----; Python 3.8.16 (default, Dec 7 2022, 12:42:00) [GCC 12.2.0]; Linux-6.2.10-zen1-1-zen-x86_64-with-glibc2.34; -----; Session information updated at 2023-04-11 15:57. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:3331,Performance,perform,performance,3331,"e_total; ' The following highly-expressed genes are not considered during '; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = Index(['0', '1', '2'], dtype='object'); key = dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, key):; """"""; Override numpy.ndarray's __getitem__ method to work as desired.; ; This function adds lists and Series as valid boolean indexers; (ndarrays only supports ndarray with dtype=bool).; ; If resulting ndim != 1, plain ndarray is returned instead of; corresponding `Index` subclass.; ; """"""; getitem = self._data.__getitem__; ; if is_integer(key) or is_float(key):; # GH#44051 exclude bool, which would return a 2d ndarray; key = com.cast_scalar_indexer(key, warn_float=True); return getitem(key); ; if isinstance(key, slice):; # This case is separated from the conditional above to avoid; # pessimization com.is_bool_indexer and ndim checks.; result = getitem(key); # Going through simple_new for performance.; return type(self)._simple_new(result, name=self._name); ; if com.is_bool_indexer(key):; # if we have list[bools, length=1e5] then doing this check+convert; # takes 166 s + 2.1 ms and cuts the ndarray.__getitem__; # time below from 3.8 ms to 496 s; # if we already have ndarray[bool], the overhead is 1.4 s or .25%; key = np.asarray(key, dtype=bool); ; > result = getitem(key); E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError; ```. #### Versions. <details>. -----; anndata 0.9.0rc2.dev18+g7771f6ee; scanpy 1.10.0.dev50+g3e3427d0; -----; PIL 9.1.1; asciitree NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.2.1; cycler 0.10.0; cython_runtime NA; dask 2023.3.2; dateutil 2.8.2; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.17.3; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; jinja2 3.1.2; joblib 1.1.0; kiwisolve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:3216,Safety,avoid,avoid,3216,"ization.py:45: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; scanpy/preprocessing/_normalization.py:185: in normalize_total; ' The following highly-expressed genes are not considered during '; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = Index(['0', '1', '2'], dtype='object'); key = dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, key):; """"""; Override numpy.ndarray's __getitem__ method to work as desired.; ; This function adds lists and Series as valid boolean indexers; (ndarrays only supports ndarray with dtype=bool).; ; If resulting ndim != 1, plain ndarray is returned instead of; corresponding `Index` subclass.; ; """"""; getitem = self._data.__getitem__; ; if is_integer(key) or is_float(key):; # GH#44051 exclude bool, which would return a 2d ndarray; key = com.cast_scalar_indexer(key, warn_float=True); return getitem(key); ; if isinstance(key, slice):; # This case is separated from the conditional above to avoid; # pessimization com.is_bool_indexer and ndim checks.; result = getitem(key); # Going through simple_new for performance.; return type(self)._simple_new(result, name=self._name); ; if com.is_bool_indexer(key):; # if we have list[bools, length=1e5] then doing this check+convert; # takes 166 s + 2.1 ms and cuts the ndarray.__getitem__; # time below from 3.8 ms to 496 s; # if we already have ndarray[bool], the overhead is 1.4 s or .25%; key = np.asarray(key, dtype=bool); ; > result = getitem(key); E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError; ```. #### Versions. <details>. -----; anndata 0.9.0rc2.dev18+g7771f6ee; scanpy 1.10.0.dev50+g3e3427d0; -----; PIL 9.1.1; asciitree NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.2.1; cycler 0.10.0; cython_runtime NA; dask 2023.3.2;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:438,Testability,test,tests,438,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PRs fix is released in a stable anndata version, well start seeing this error unless we fix it first. (the minimal tests + anndata dev dont have dask, so we dont see the error there either). ```console; $ pip install dask; $ pytest -k test_normalize_total; ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb; IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb; ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']); def test_normalize_total(typ, dtype):; adata = AnnData(typ(X_total), dtype=dtype); sc.pp.normalize_total(adata, key_added='n_counts'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]); sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:581,Testability,test,tests,581,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PRs fix is released in a stable anndata version, well start seeing this error unless we fix it first. (the minimal tests + anndata dev dont have dask, so we dont see the error there either). ```console; $ pip install dask; $ pytest -k test_normalize_total; ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb; IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb; ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']); def test_normalize_total(typ, dtype):; adata = AnnData(typ(X_total), dtype=dtype); sc.pp.normalize_total(adata, key_added='n_counts'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]); sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:1375,Testability,test,tests,1375,"thub.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PRs fix is released in a stable anndata version, well start seeing this error unless we fix it first. (the minimal tests + anndata dev dont have dask, so we dont see the error there either). ```console; $ pip install dask; $ pytest -k test_normalize_total; ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb; IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb; ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']); def test_normalize_total(typ, dtype):; adata = AnnData(typ(X_total), dtype=dtype); sc.pp.normalize_total(adata, key_added='n_counts'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]); sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0]); ; adata = AnnData(typ(X_frac), dtype=dtype); > sc.pp.normalize_total(adata, exclude_highly_expressed=True, max_fraction=0.7). scanpy/tests/test_normalization.py:45: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; scanpy/preprocessing/_normalization.py:185: in normalize_total; ' The following highly-expressed genes are not considered during '",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:1802,Testability,assert,assert,1802,"verse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb; IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb; ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']); def test_normalize_total(typ, dtype):; adata = AnnData(typ(X_total), dtype=dtype); sc.pp.normalize_total(adata, key_added='n_counts'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]); sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0]); ; adata = AnnData(typ(X_frac), dtype=dtype); > sc.pp.normalize_total(adata, exclude_highly_expressed=True, max_fraction=0.7). scanpy/tests/test_normalization.py:45: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; scanpy/preprocessing/_normalization.py:185: in normalize_total; ' The following highly-expressed genes are not considered during '; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = Index(['0', '1', '2'], dtype='object'); key = dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, key):; """"""; Override numpy.ndarray's __getitem__ method to work as desired.; ; This function adds lists and Series as valid boolean indexers; (ndarrays only",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:1937,Testability,assert,assert,1937,": `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb; IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb; ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']); def test_normalize_total(typ, dtype):; adata = AnnData(typ(X_total), dtype=dtype); sc.pp.normalize_total(adata, key_added='n_counts'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]); sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0]); ; adata = AnnData(typ(X_frac), dtype=dtype); > sc.pp.normalize_total(adata, exclude_highly_expressed=True, max_fraction=0.7). scanpy/tests/test_normalization.py:45: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; scanpy/preprocessing/_normalization.py:185: in normalize_total; ' The following highly-expressed genes are not considered during '; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = Index(['0', '1', '2'], dtype='object'); key = dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, key):; """"""; Override numpy.ndarray's __getitem__ method to work as desired.; ; This function adds lists and Series as valid boolean indexers; (ndarrays only supports ndarray with dtype=bool).; ; If resulting ndim != 1, plain ndarray is returned instead of; corresponding `Index` subcl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:2138,Testability,test,tests,2138,"xed; ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb; ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed; typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']); def test_normalize_total(typ, dtype):; adata = AnnData(typ(X_total), dtype=dtype); sc.pp.normalize_total(adata, key_added='n_counts'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]); sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'); assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0]); ; adata = AnnData(typ(X_frac), dtype=dtype); > sc.pp.normalize_total(adata, exclude_highly_expressed=True, max_fraction=0.7). scanpy/tests/test_normalization.py:45: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; scanpy/preprocessing/_normalization.py:185: in normalize_total; ' The following highly-expressed genes are not considered during '; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = Index(['0', '1', '2'], dtype='object'); key = dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, key):; """"""; Override numpy.ndarray's __getitem__ method to work as desired.; ; This function adds lists and Series as valid boolean indexers; (ndarrays only supports ndarray with dtype=bool).; ; If resulting ndim != 1, plain ndarray is returned instead of; corresponding `Index` subclass.; ; """"""; getitem = self._data.__getitem__; ; if is_integer(key) or is_float(key):; # GH#44051 exclude bool, which would return a 2d ndarray; key = com.cast_scalar_indexer(key, warn_float=True); return getitem(key); ; if isinstance(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/pull/2466:59,Availability,error,error,59,"Fixes #2465. `adata.var_names[~gene_subset]` will throw an error if `gene_subset` is an 1D dask array, so we convert it to a numpy array.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2466
https://github.com/scverse/scanpy/pull/2468:50,Testability,test,tests,50,Also do `pytest -v` for more immediate display of tests (helps to see e.g. when a test hangs),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2468
https://github.com/scverse/scanpy/pull/2468:82,Testability,test,test,82,Also do `pytest -v` for more immediate display of tests (helps to see e.g. when a test hangs),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2468
https://github.com/scverse/scanpy/pull/2469:71,Usability,guid,guidelines,71,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Hello scanpy,. I noticed some inconsistencies in the [scanpy pca function](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.pca.html) even when fixing the random seed. I looked at the pca code and it looks like the random seed in the PCA initialization is not set. I fixed it. Best,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2469
https://github.com/scverse/scanpy/pull/2469:102,Usability,guid,guide,102,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Hello scanpy,. I noticed some inconsistencies in the [scanpy pca function](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.pca.html) even when fixing the random seed. I looked at the pca code and it looks like the random seed in the PCA initialization is not set. I fixed it. Best,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2469
https://github.com/scverse/scanpy/pull/2470:501,Availability,down,downstream,501,"Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:; - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size); - The structure of a probe barcode h5 file is; ```; /matrix Group; /matrix/barcodes Dataset {4987}; /matrix/data Dataset {17581240/Inf}; /matrix/features Group; /matrix/features/feature_type Dataset {21178}; /matrix/features/filtered_probes Dataset {21178}; /matrix/features/gene_id Dataset {21178}; /matrix/features/gene_name Dataset {21178}; /matrix/features/genome Dataset {21178}; /matrix/features/id Dataset {21178}; /matrix/features/name Dataset {21178}; /matrix/features/probe_region Dataset {21178}; /matrix/features/target_sets Group; /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}; /matrix/filtered_barcodes Dataset {4987}; /matrix/indices Dataset {17581240/Inf}; /matrix/indptr Dataset {4988}; /matrix/shape Dataset {2}; ```; - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - thi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:650,Availability,down,downstream,650,"Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:; - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size); - The structure of a probe barcode h5 file is; ```; /matrix Group; /matrix/barcodes Dataset {4987}; /matrix/data Dataset {17581240/Inf}; /matrix/features Group; /matrix/features/feature_type Dataset {21178}; /matrix/features/filtered_probes Dataset {21178}; /matrix/features/gene_id Dataset {21178}; /matrix/features/gene_name Dataset {21178}; /matrix/features/genome Dataset {21178}; /matrix/features/id Dataset {21178}; /matrix/features/name Dataset {21178}; /matrix/features/probe_region Dataset {21178}; /matrix/features/target_sets Group; /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}; /matrix/filtered_barcodes Dataset {4987}; /matrix/indices Dataset {17581240/Inf}; /matrix/indptr Dataset {4988}; /matrix/shape Dataset {2}; ```; - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - thi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:838,Availability,down,downsampled,838,ial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:; - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size); - The structure of a probe barcode h5 file is; ```; /matrix Group; /matrix/barcodes Dataset {4987}; /matrix/data Dataset {17581240/Inf}; /matrix/features Group; /matrix/features/feature_type Dataset {21178}; /matrix/features/filtered_probes Dataset {21178}; /matrix/features/gene_id Dataset {21178}; /matrix/features/gene_name Dataset {21178}; /matrix/features/genome Dataset {21178}; /matrix/features/id Dataset {21178}; /matrix/features/name Dataset {21178}; /matrix/features/probe_region Dataset {21178}; /matrix/features/target_sets Group; /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}; /matrix/filtered_barcodes Dataset {4987}; /matrix/indices Dataset {17581240/Inf}; /matrix/indptr Dataset {4988}; /matrix/shape Dataset {2}; ```; - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - this will read any additional fields if we put them in too). ; - Adds a test to make sure the reader works correctly.; <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:870,Energy Efficiency,reduce,reduce,870,ial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:; - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size); - The structure of a probe barcode h5 file is; ```; /matrix Group; /matrix/barcodes Dataset {4987}; /matrix/data Dataset {17581240/Inf}; /matrix/features Group; /matrix/features/feature_type Dataset {21178}; /matrix/features/filtered_probes Dataset {21178}; /matrix/features/gene_id Dataset {21178}; /matrix/features/gene_name Dataset {21178}; /matrix/features/genome Dataset {21178}; /matrix/features/id Dataset {21178}; /matrix/features/name Dataset {21178}; /matrix/features/probe_region Dataset {21178}; /matrix/features/target_sets Group; /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}; /matrix/filtered_barcodes Dataset {4987}; /matrix/indices Dataset {17581240/Inf}; /matrix/indptr Dataset {4988}; /matrix/shape Dataset {2}; ```; - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - this will read any additional fields if we put them in too). ; - Adds a test to make sure the reader works correctly.; <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:752,Testability,test,tests,752,"Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:; - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size); - The structure of a probe barcode h5 file is; ```; /matrix Group; /matrix/barcodes Dataset {4987}; /matrix/data Dataset {17581240/Inf}; /matrix/features Group; /matrix/features/feature_type Dataset {21178}; /matrix/features/filtered_probes Dataset {21178}; /matrix/features/gene_id Dataset {21178}; /matrix/features/gene_name Dataset {21178}; /matrix/features/genome Dataset {21178}; /matrix/features/id Dataset {21178}; /matrix/features/name Dataset {21178}; /matrix/features/probe_region Dataset {21178}; /matrix/features/target_sets Group; /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}; /matrix/filtered_barcodes Dataset {4987}; /matrix/indices Dataset {17581240/Inf}; /matrix/indptr Dataset {4988}; /matrix/shape Dataset {2}; ```; - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - thi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:2070,Testability,test,test,2070,erage of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:; - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size); - The structure of a probe barcode h5 file is; ```; /matrix Group; /matrix/barcodes Dataset {4987}; /matrix/data Dataset {17581240/Inf}; /matrix/features Group; /matrix/features/feature_type Dataset {21178}; /matrix/features/filtered_probes Dataset {21178}; /matrix/features/gene_id Dataset {21178}; /matrix/features/gene_name Dataset {21178}; /matrix/features/genome Dataset {21178}; /matrix/features/id Dataset {21178}; /matrix/features/name Dataset {21178}; /matrix/features/probe_region Dataset {21178}; /matrix/features/target_sets Group; /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}; /matrix/filtered_barcodes Dataset {4987}; /matrix/indices Dataset {17581240/Inf}; /matrix/indptr Dataset {4988}; /matrix/shape Dataset {2}; ```; - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - this will read any additional fields if we put them in too). ; - Adds a test to make sure the reader works correctly.; <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:2188,Usability,guid,guidelines,2188,erage of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:; - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size); - The structure of a probe barcode h5 file is; ```; /matrix Group; /matrix/barcodes Dataset {4987}; /matrix/data Dataset {17581240/Inf}; /matrix/features Group; /matrix/features/feature_type Dataset {21178}; /matrix/features/filtered_probes Dataset {21178}; /matrix/features/gene_id Dataset {21178}; /matrix/features/gene_name Dataset {21178}; /matrix/features/genome Dataset {21178}; /matrix/features/id Dataset {21178}; /matrix/features/name Dataset {21178}; /matrix/features/probe_region Dataset {21178}; /matrix/features/target_sets Group; /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}; /matrix/filtered_barcodes Dataset {4987}; /matrix/indices Dataset {17581240/Inf}; /matrix/indptr Dataset {4988}; /matrix/shape Dataset {2}; ```; - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - this will read any additional fields if we put them in too). ; - Adds a test to make sure the reader works correctly.; <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:2219,Usability,guid,guide,2219,erage of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:; - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size); - The structure of a probe barcode h5 file is; ```; /matrix Group; /matrix/barcodes Dataset {4987}; /matrix/data Dataset {17581240/Inf}; /matrix/features Group; /matrix/features/feature_type Dataset {21178}; /matrix/features/filtered_probes Dataset {21178}; /matrix/features/gene_id Dataset {21178}; /matrix/features/gene_name Dataset {21178}; /matrix/features/genome Dataset {21178}; /matrix/features/id Dataset {21178}; /matrix/features/name Dataset {21178}; /matrix/features/probe_region Dataset {21178}; /matrix/features/target_sets Group; /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}; /matrix/filtered_barcodes Dataset {4987}; /matrix/indices Dataset {17581240/Inf}; /matrix/indptr Dataset {4988}; /matrix/shape Dataset {2}; ```; - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - this will read any additional fields if we put them in too). ; - Adds a test to make sure the reader works correctly.; <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/issues/2471:594,Availability,down,downloaded,594,"- [ X] I have checked that this issue has not already been reported.; - [ X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); sc.tl.umap(adata); sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']); sc.tl.leiden(adata); sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb; The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this?; ```. #### Versions. <details>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.0.1; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.02.1; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; executing 0.8.3; fsspec 2022.02.0; google NA; h5py 3.6.0; igraph 0.10.4; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.13.5; kiwisolver 1.3.2; leidenalg 0.9.1; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 8.3.1; nbinom_ufunc NA; nt NA; ntsecuritycon NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.5; packaging 21.3; pandas 1.4.2; parso 0.8.3; patsy 0.5.2; pickleshare 0.7.5; pkg_resources NA; plotly 5.6.0; prompt_toolkit 3.0.20; psutil 5.8.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.8; pyparsing 3.0.4; pythoncom NA; pytz 2021.3; pywintypes NA; ruamel NA; scipy 1.7.3; seaborn 0.11.2; session_info 1.0.0; setuptools 61.2.0; six",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:2589,Deployability,update,updated,2589,"#### Versions. <details>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.0.1; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.02.1; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; executing 0.8.3; fsspec 2022.02.0; google NA; h5py 3.6.0; igraph 0.10.4; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.13.5; kiwisolver 1.3.2; leidenalg 0.9.1; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 8.3.1; nbinom_ufunc NA; nt NA; ntsecuritycon NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.5; packaging 21.3; pandas 1.4.2; parso 0.8.3; patsy 0.5.2; pickleshare 0.7.5; pkg_resources NA; plotly 5.6.0; prompt_toolkit 3.0.20; psutil 5.8.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.8; pyparsing 3.0.4; pythoncom NA; pytz 2021.3; pywintypes NA; ruamel NA; scipy 1.7.3; seaborn 0.11.2; session_info 1.0.0; setuptools 61.2.0; six 1.16.0; sklearn 1.0.2; snappy NA; sphinxcontrib NA; stack_data 0.2.0; statsmodels 0.13.2; tblib 1.7.0; texttable 1.6.7; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.2; tornado 6.1; tqdm 4.64.0; traitlets 5.1.1; typing_extensions NA; umap 0.5.3; wcwidth 0.2.5; win32api NA; win32com NA; win32security NA; yaml 6.0; zipp NA; zmq 22.3.0; zope NA; -----; IPython 8.2.0; jupyter_client 6.1.12; jupyter_core 4.9.2; jupyterlab 3.3.2; notebook 6.4.8; -----; Python 3.9.12 (main, Apr 4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.17763-SP0; </details>. -----; Session information updated at 2023-04-18 14:50; ![image-tr](https://user-images.githubusercontent.com/80623801/232782829-c209af87-b1de-41c1-9a00-f11529a24bcd.JPG)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:873,Performance,bottleneck,bottleneck,873,"- [ X] I have checked that this issue has not already been reported.; - [ X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); sc.tl.umap(adata); sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']); sc.tl.leiden(adata); sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb; The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this?; ```. #### Versions. <details>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.0.1; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.02.1; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; executing 0.8.3; fsspec 2022.02.0; google NA; h5py 3.6.0; igraph 0.10.4; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.13.5; kiwisolver 1.3.2; leidenalg 0.9.1; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 8.3.1; nbinom_ufunc NA; nt NA; ntsecuritycon NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.5; packaging 21.3; pandas 1.4.2; parso 0.8.3; patsy 0.5.2; pickleshare 0.7.5; pkg_resources NA; plotly 5.6.0; prompt_toolkit 3.0.20; psutil 5.8.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.8; pyparsing 3.0.4; pythoncom NA; pytz 2021.3; pywintypes NA; ruamel NA; scipy 1.7.3; seaborn 0.11.2; session_info 1.0.0; setuptools 61.2.0; six",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2472:788,Availability,error,error,788,"- [ x] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs  n_vars = 17928  3101; obs: 'n_genes_by_counts', 'total_counts'; var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'; uns: 'log1p', 'pca'; obsm: 'X_pca'; varm: 'PCs'; ```; This is the command that leads to error:; ```python; sc.pp.neighbors(adata ); ```; ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-79-c7d46fa554b4> in <module>; ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 792 X = pairwise_distances(X, metric=metric, **metric_kwds); 793 metric = 'precomputed'; --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(; 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds; 796 ). ~/.local/lib/python3.8/site-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6050,Availability,error,error,6050,"exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs); 593 def __call__(self, *args, **kwargs):; 594 try:; --> 595 return self.func(*args, **kwargs); 596 except KeyboardInterrupt as e:; 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self); 260 # change the default number of processes to -1; 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):; --> 262 return [func(*args, **kwargs); 263 for func, args, kwargs in self.items]; 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0); 260 # change the default number of processes to -1; 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):; --> 262 return [func(*args, **kwargs); 263 for func, args, kwargs in self.items]; 264 . ValueError: cannot assign slice from input of different size```. #### Versions; ```. <details>. here is the error from ` sc.logging.print_versions()` ; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-81-c71c26e11b3b> in <module>; ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones. KeyError: 'dask'. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:3905,Integrability,message,message,3905,"batch_queries, verbose); 802 self._angular_trees,; 803 ); --> 804 leaf_array = rptree_leaf_array(self._rp_forest); 805 else:; 806 self._rp_forest = None. ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array(rp_forest); 1095 def rptree_leaf_array(rp_forest):; 1096 if len(rp_forest) > 0:; -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)); 1098 else:; 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest); 1087 ; 1088 def rptree_leaf_array_parallel(rp_forest):; -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(; 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest; 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable); 1054 ; 1055 with self._backend.retrieval_context():; -> 1056 self.retrieve(); 1057 # Make sure that we get a last message telling us we are done; 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self); 933 try:; 934 if getattr(self._backend, 'supports_timeout', False):; --> 935 self._output.extend(job.get(timeout=self.timeout)); 936 else:; 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout); 769 return self._value; 770 else:; --> 771 raise self._value; 772 ; 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception); 123 job, i, func, args, kwds = task; 124 try:; --> 125 result = (True, func(*args, **kwds)); 126 except Exception as e:; 127 if wrap_exception and func is not _helper_reraises_exception:. /om",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6451,Integrability,depend,dependencies,6451,"exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs); 593 def __call__(self, *args, **kwargs):; 594 try:; --> 595 return self.func(*args, **kwargs); 596 except KeyboardInterrupt as e:; 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self); 260 # change the default number of processes to -1; 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):; --> 262 return [func(*args, **kwargs); 263 for func, args, kwargs in self.items]; 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0); 260 # change the default number of processes to -1; 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):; --> 262 return [func(*args, **kwargs); 263 for func, args, kwargs in self.items]; 264 . ValueError: cannot assign slice from input of different size```. #### Versions; ```. <details>. here is the error from ` sc.logging.print_versions()` ; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-81-c71c26e11b3b> in <module>; ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones. KeyError: 'dask'. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6576,Integrability,depend,dependencies,6576,"exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs); 593 def __call__(self, *args, **kwargs):; 594 try:; --> 595 return self.func(*args, **kwargs); 596 except KeyboardInterrupt as e:; 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self); 260 # change the default number of processes to -1; 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):; --> 262 return [func(*args, **kwargs); 263 for func, args, kwargs in self.items]; 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0); 260 # change the default number of processes to -1; 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):; --> 262 return [func(*args, **kwargs); 263 for func, args, kwargs in self.items]; 264 . ValueError: cannot assign slice from input of different size```. #### Versions; ```. <details>. here is the error from ` sc.logging.print_versions()` ; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-81-c71c26e11b3b> in <module>; ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones. KeyError: 'dask'. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4216,Modifiability,extend,extend,4216," 0:; -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)); 1098 else:; 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest); 1087 ; 1088 def rptree_leaf_array_parallel(rp_forest):; -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(; 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest; 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable); 1054 ; 1055 with self._backend.retrieval_context():; -> 1056 self.retrieve(); 1057 # Make sure that we get a last message telling us we are done; 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self); 933 try:; 934 if getattr(self._backend, 'supports_timeout', False):; --> 935 self._output.extend(job.get(timeout=self.timeout)); 936 else:; 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout); 769 return self._value; 770 else:; --> 771 raise self._value; 772 ; 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception); 123 job, i, func, args, kwds = task; 124 try:; --> 125 result = (True, func(*args, **kwds)); 126 except Exception as e:; 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs); 593 def __call__(self, *args, **kwargs):; 594 try:; --> 595 return self.func(*args, **kwargs); 596 except KeyboardInterrupt as e:; 597 # We capture the",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4283,Modifiability,extend,extend,4283,"); 1098 else:; 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest); 1087 ; 1088 def rptree_leaf_array_parallel(rp_forest):; -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(; 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest; 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable); 1054 ; 1055 with self._backend.retrieval_context():; -> 1056 self.retrieve(); 1057 # Make sure that we get a last message telling us we are done; 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self); 933 try:; 934 if getattr(self._backend, 'supports_timeout', False):; --> 935 self._output.extend(job.get(timeout=self.timeout)); 936 else:; 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout); 769 return self._value; 770 else:; --> 771 raise self._value; 772 ; 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception); 123 job, i, func, args, kwds = task; 124 try:; --> 125 result = (True, func(*args, **kwds)); 126 except Exception as e:; 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs); 593 def __call__(self, *args, **kwargs):; 594 try:; --> 595 return self.func(*args, **kwargs); 596 except KeyboardInterrupt as e:; 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4231,Safety,timeout,timeout,4231,"eturn np.vstack(rptree_leaf_array_parallel(rp_forest)); 1098 else:; 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest); 1087 ; 1088 def rptree_leaf_array_parallel(rp_forest):; -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(; 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest; 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable); 1054 ; 1055 with self._backend.retrieval_context():; -> 1056 self.retrieve(); 1057 # Make sure that we get a last message telling us we are done; 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self); 933 try:; 934 if getattr(self._backend, 'supports_timeout', False):; --> 935 self._output.extend(job.get(timeout=self.timeout)); 936 else:; 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout); 769 return self._value; 770 else:; --> 771 raise self._value; 772 ; 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception); 123 job, i, func, args, kwds = task; 124 try:; --> 125 result = (True, func(*args, **kwds)); 126 except Exception as e:; 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs); 593 def __call__(self, *args, **kwargs):; 594 try:; --> 595 return self.func(*args, **kwargs); 596 except KeyboardInterrupt as e:; 597 # We capture the KeyboardInter",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4244,Safety,timeout,timeout,4244,"eaf_array_parallel(rp_forest)); 1098 else:; 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest); 1087 ; 1088 def rptree_leaf_array_parallel(rp_forest):; -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(; 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest; 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable); 1054 ; 1055 with self._backend.retrieval_context():; -> 1056 self.retrieve(); 1057 # Make sure that we get a last message telling us we are done; 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self); 933 try:; 934 if getattr(self._backend, 'supports_timeout', False):; --> 935 self._output.extend(job.get(timeout=self.timeout)); 936 else:; 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout); 769 return self._value; 770 else:; --> 771 raise self._value; 772 ; 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception); 123 job, i, func, args, kwds = task; 124 try:; --> 125 result = (True, func(*args, **kwds)); 126 except Exception as e:; 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs); 593 def __call__(self, *args, **kwargs):; 594 try:; --> 595 return self.func(*args, **kwargs); 596 except KeyboardInterrupt as e:; 597 # We capture the KeyboardInterrupt and reraise it as. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4424,Safety,timeout,timeout,4424,"rest); 1087 ; 1088 def rptree_leaf_array_parallel(rp_forest):; -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(; 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest; 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable); 1054 ; 1055 with self._backend.retrieval_context():; -> 1056 self.retrieve(); 1057 # Make sure that we get a last message telling us we are done; 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self); 933 try:; 934 if getattr(self._backend, 'supports_timeout', False):; --> 935 self._output.extend(job.get(timeout=self.timeout)); 936 else:; 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout); 769 return self._value; 770 else:; --> 771 raise self._value; 772 ; 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception); 123 job, i, func, args, kwds = task; 124 try:; --> 125 result = (True, func(*args, **kwds)); 126 except Exception as e:; 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs); 593 def __call__(self, *args, **kwargs):; 594 try:; --> 595 return self.func(*args, **kwargs); 596 except KeyboardInterrupt as e:; 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self); 260 # change the default number ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:842,Testability,log,logging,842,"- [ x] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs  n_vars = 17928  3101; obs: 'n_genes_by_counts', 'total_counts'; var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'; uns: 'log1p', 'pca'; obsm: 'X_pca'; varm: 'PCs'; ```; This is the command that leads to error:; ```python; sc.pp.neighbors(adata ); ```; ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-79-c7d46fa554b4> in <module>; ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 792 X = pairwise_distances(X, metric=metric, **metric_kwds); 793 metric = 'precomputed'; --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(; 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds; 796 ). ~/.local/lib/python3.8/site-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6066,Testability,log,logging,6066,"exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs); 593 def __call__(self, *args, **kwargs):; 594 try:; --> 595 return self.func(*args, **kwargs); 596 except KeyboardInterrupt as e:; 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self); 260 # change the default number of processes to -1; 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):; --> 262 return [func(*args, **kwargs); 263 for func, args, kwargs in self.items]; 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0); 260 # change the default number of processes to -1; 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):; --> 262 return [func(*args, **kwargs); 263 for func, args, kwargs in self.items]; 264 . ValueError: cannot assign slice from input of different size```. #### Versions; ```. <details>. here is the error from ` sc.logging.print_versions()` ; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-81-c71c26e11b3b> in <module>; ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones. KeyError: 'dask'. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6280,Testability,log,logging,6280,"exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs); 593 def __call__(self, *args, **kwargs):; 594 try:; --> 595 return self.func(*args, **kwargs); 596 except KeyboardInterrupt as e:; 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self); 260 # change the default number of processes to -1; 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):; --> 262 return [func(*args, **kwargs); 263 for func, args, kwargs in self.items]; 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0); 260 # change the default number of processes to -1; 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):; --> 262 return [func(*args, **kwargs); 263 for func, args, kwargs in self.items]; 264 . ValueError: cannot assign slice from input of different size```. #### Versions; ```. <details>. here is the error from ` sc.logging.print_versions()` ; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-81-c71c26e11b3b> in <module>; ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones. KeyError: 'dask'. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6350,Testability,log,logging,6350,"exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs); 593 def __call__(self, *args, **kwargs):; 594 try:; --> 595 return self.func(*args, **kwargs); 596 except KeyboardInterrupt as e:; 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self); 260 # change the default number of processes to -1; 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):; --> 262 return [func(*args, **kwargs); 263 for func, args, kwargs in self.items]; 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0); 260 # change the default number of processes to -1; 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):; --> 262 return [func(*args, **kwargs); 263 for func, args, kwargs in self.items]; 264 . ValueError: cannot assign slice from input of different size```. #### Versions; ```. <details>. here is the error from ` sc.logging.print_versions()` ; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-81-c71c26e11b3b> in <module>; ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones. KeyError: 'dask'. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:259,Usability,guid,guide,259,"- [ x] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs  n_vars = 17928  3101; obs: 'n_genes_by_counts', 'total_counts'; var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'; uns: 'log1p', 'pca'; obsm: 'X_pca'; varm: 'PCs'; ```; This is the command that leads to error:; ```python; sc.pp.neighbors(adata ); ```; ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-79-c7d46fa554b4> in <module>; ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 792 X = pairwise_distances(X, metric=metric, **metric_kwds); 793 metric = 'precomputed'; --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(; 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds; 796 ). ~/.local/lib/python3.8/site-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2473:233,Availability,error,error,233,"<!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->; Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python; sc.tl.pca(adata, svd_solver='arpack'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb; Traceback (most recent call last):; File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>; sc.tl.pca(adata, svd_solver='arpack'); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca; X_pca = pca_.fit_transform(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped; data_to_wrap = f(self, X, *args, **kwargs); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform; U, S, Vt = self._fit(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit; return self._fit_truncated(X, n_components, self._fit_svd_solver); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated; U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds; _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,; File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:519,Availability,Error,Error,519,"<!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->; Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python; sc.tl.pca(adata, svd_solver='arpack'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb; Traceback (most recent call last):; File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>; sc.tl.pca(adata, svd_solver='arpack'); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca; X_pca = pca_.fit_transform(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped; data_to_wrap = f(self, X, *args, **kwargs); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform; U, S, Vt = self._fit(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit; return self._fit_truncated(X, n_components, self._fit_svd_solver); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated; U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds; _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,; File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:2300,Availability,error,error,2300,"aconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca; X_pca = pca_.fit_transform(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped; data_to_wrap = f(self, X, *args, **kwargs); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform; U, S, Vt = self._fit(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit; return self._fit_truncated(X, n_components, self._fit_svd_solver); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated; U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds; _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,; File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh; params.iterate(); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate; raise ArpackError(self.info, infodict=self.iterate_infodict); scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > ; <!-- Relevant screenshots -->. Thanks; Patrick",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:2498,Energy Efficiency,allocate,allocated,2498,"aconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca; X_pca = pca_.fit_transform(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped; data_to_wrap = f(self, X, *args, **kwargs); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform; U, S, Vt = self._fit(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit; return self._fit_truncated(X, n_components, self._fit_svd_solver); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated; U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds; _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,; File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh; params.iterate(); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate; raise ArpackError(self.info, infodict=self.iterate_infodict); scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > ; <!-- Relevant screenshots -->. Thanks; Patrick",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:1088,Integrability,wrap,wrapped,1088,"en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->; Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python; sc.tl.pca(adata, svd_solver='arpack'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb; Traceback (most recent call last):; File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>; sc.tl.pca(adata, svd_solver='arpack'); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca; X_pca = pca_.fit_transform(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped; data_to_wrap = f(self, X, *args, **kwargs); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform; U, S, Vt = self._fit(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit; return self._fit_truncated(X, n_components, self._fit_svd_solver); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated; U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds; _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,; File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh; params.iterate(); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:745,Testability,test,test,745,"<!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->; Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python; sc.tl.pca(adata, svd_solver='arpack'); ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb; Traceback (most recent call last):; File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>; sc.tl.pca(adata, svd_solver='arpack'); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca; X_pca = pca_.fit_transform(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped; data_to_wrap = f(self, X, *args, **kwargs); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform; U, S, Vt = self._fit(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit; return self._fit_truncated(X, n_components, self._fit_svd_solver); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated; U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds; _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,; File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:2693,Usability,learn,learn,2693,"aconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca; X_pca = pca_.fit_transform(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped; data_to_wrap = f(self, X, *args, **kwargs); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform; U, S, Vt = self._fit(X); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit; return self._fit_truncated(X, n_components, self._fit_svd_solver); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated; U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds; _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,; File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh; params.iterate(); File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate; raise ArpackError(self.info, infodict=self.iterate_infodict); scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > ; <!-- Relevant screenshots -->. Thanks; Patrick",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2474:5512,Deployability,update,updated,5512,"or 5.1.1; defusedxml 0.7.1; docrep 0.3.2; executing 0.8.3; flax 0.6.1; fsspec 2023.4.0; gmpy2 2.1.2; h5py 3.8.0; hypergeom_ufunc NA; idna 3.4; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.19.2; ipython_genutils 0.2.0; ipywidgets 8.0.4; jax 0.4.8; jaxlib 0.4.7; jedi 0.18.1; joblib 1.2.0; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.9.1; lightning_fabric 1.9.4; lightning_utilities 0.8.0; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mkl 2.4.0; ml_collections NA; ml_dtypes 0.1.0; mpl_toolkits NA; mpmath 1.2.1; msgpack 1.0.5; mudata 0.2.2; multipledispatch 0.6.0; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; numpyro 0.11.0; nvfuser NA; opt_einsum v3.3.0; optax 0.1.5; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.2.0; prompt_toolkit 3.0.36; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.0.9; pyro 1.8.4+9ed468d; pytorch_lightning 1.9.4; pytz 2023.3; requests 2.28.1; rich NA; scipy 1.10.1; scvi 0.20.3; seaborn 0.12.2; session_info 1.0.0; setuptools 66.0.0; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; skmisc 0.1.4; socks 1.7.1; stack_data 0.2.0; statsmodels 0.13.5; sympy 1.11.1; texttable 1.6.7; threadpoolctl 3.1.0; toolz 0.12.0; torch 2.0.0; torchmetrics 0.11.4; torchvision 0.15.0; tornado 6.2; tqdm 4.65.0; traitlets 5.7.1; tree 0.1.7; typing_extensions NA; unicodedata2 NA; urllib3 1.26.15; wcwidth 0.2.5; yaml 6.0; zmq 23.2.0; zoneinfo NA; -----; IPython 8.12.0; jupyter_client 8.1.0; jupyter_core 5.3.0; jupyterlab 3.5.3; notebook 6.5.4; -----; Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]; Linux-5.19.0-40-generic-x86_64-with-glibc2.35; -----; Session information updated at 2023-04-26 05:02. </details>; Thanks for your help",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:1876,Performance,Cache,CachedAccessor,1876,"200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1); 201 ); 202 doublet_adata.obs[LABELS_KEY] = ""doublet""; --> 204 full_adata = latent_adata.concatenate(doublet_adata); 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY); 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas); 1799 pat = rf""-({'|'.join(batch_categories)})$""; 1800 out.var = merge_dataframes(; 1801 [a.var for a in all_adatas],; 1802 out.var_names,; 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),; 1804 ); 1805 out.var = out.var.iloc[; 1806 :,; 1807 (; -> 1808 out.var.columns.str.extract(pat, expand=False); 1809 .fillna(""""); 1810 .argsort(kind=""stable""); 1811 ),; 1812 ]; 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls); 221 if obj is None:; 222 # we're accessing the attribute of the class, i.e., Dataset.geo; 223 return self._accessor; --> 224 accessor_obj = self._accessor(obj); 225 # Replace the property with the accessor object. Inspired by:; 226 # https://www.pydanny.com/cached-property.html; 227 # We need to use object.__setattr__ because we overwrite __setattr__ on; 228 # NDFrame; 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data); 178 def __init__(self, data) -> None:; 179 from pandas.core.arrays.string_ import StringDtype; --> 181 self._inferred_dtype = self._validate(data); 182 self._is_categorical = is_categorical_dtype(data.dtype); 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data); 23",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:2174,Performance,cache,cached-property,2174,"e ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas); 1799 pat = rf""-({'|'.join(batch_categories)})$""; 1800 out.var = merge_dataframes(; 1801 [a.var for a in all_adatas],; 1802 out.var_names,; 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),; 1804 ); 1805 out.var = out.var.iloc[; 1806 :,; 1807 (; -> 1808 out.var.columns.str.extract(pat, expand=False); 1809 .fillna(""""); 1810 .argsort(kind=""stable""); 1811 ),; 1812 ]; 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls); 221 if obj is None:; 222 # we're accessing the attribute of the class, i.e., Dataset.geo; 223 return self._accessor; --> 224 accessor_obj = self._accessor(obj); 225 # Replace the property with the accessor object. Inspired by:; 226 # https://www.pydanny.com/cached-property.html; 227 # We need to use object.__setattr__ because we overwrite __setattr__ on; 228 # NDFrame; 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data); 178 def __init__(self, data) -> None:; 179 from pandas.core.arrays.string_ import StringDtype; --> 181 self._inferred_dtype = self._validate(data); 182 self._is_categorical = is_categorical_dtype(data.dtype); 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data); 232 inferred_dtype = lib.infer_dtype(values, skipna=True); 234 if inferred_dtype not in allowed_types:; --> 235 raise AttributeError(""Can only use .str accessor with string values!""); 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values!; ```; I did try to eleminate e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:1856,Security,access,accessor,1856,"; 199 doublet_adata = AnnData(; 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1); 201 ); 202 doublet_adata.obs[LABELS_KEY] = ""doublet""; --> 204 full_adata = latent_adata.concatenate(doublet_adata); 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY); 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas); 1799 pat = rf""-({'|'.join(batch_categories)})$""; 1800 out.var = merge_dataframes(; 1801 [a.var for a in all_adatas],; 1802 out.var_names,; 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),; 1804 ); 1805 out.var = out.var.iloc[; 1806 :,; 1807 (; -> 1808 out.var.columns.str.extract(pat, expand=False); 1809 .fillna(""""); 1810 .argsort(kind=""stable""); 1811 ),; 1812 ]; 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls); 221 if obj is None:; 222 # we're accessing the attribute of the class, i.e., Dataset.geo; 223 return self._accessor; --> 224 accessor_obj = self._accessor(obj); 225 # Replace the property with the accessor object. Inspired by:; 226 # https://www.pydanny.com/cached-property.html; 227 # We need to use object.__setattr__ because we overwrite __setattr__ on; 228 # NDFrame; 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data); 178 def __init__(self, data) -> None:; 179 from pandas.core.arrays.string_ import StringDtype; --> 181 self._inferred_dtype = self._validate(data); 182 self._is_categorical = is_categorical_dtype(data.dtype); 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in S",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:1949,Security,access,accessing,1949,"e)], axis=1); 201 ); 202 doublet_adata.obs[LABELS_KEY] = ""doublet""; --> 204 full_adata = latent_adata.concatenate(doublet_adata); 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY); 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas); 1799 pat = rf""-({'|'.join(batch_categories)})$""; 1800 out.var = merge_dataframes(; 1801 [a.var for a in all_adatas],; 1802 out.var_names,; 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),; 1804 ); 1805 out.var = out.var.iloc[; 1806 :,; 1807 (; -> 1808 out.var.columns.str.extract(pat, expand=False); 1809 .fillna(""""); 1810 .argsort(kind=""stable""); 1811 ),; 1812 ]; 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls); 221 if obj is None:; 222 # we're accessing the attribute of the class, i.e., Dataset.geo; 223 return self._accessor; --> 224 accessor_obj = self._accessor(obj); 225 # Replace the property with the accessor object. Inspired by:; 226 # https://www.pydanny.com/cached-property.html; 227 # We need to use object.__setattr__ because we overwrite __setattr__ on; 228 # NDFrame; 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data); 178 def __init__(self, data) -> None:; 179 from pandas.core.arrays.string_ import StringDtype; --> 181 self._inferred_dtype = self._validate(data); 182 self._is_categorical = is_categorical_dtype(data.dtype); 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data); 232 inferred_dtype = lib.infer_dtype(values, skipna=True); 234 i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:2113,Security,access,accessor,2113,"l_adata, labels_key=LABELS_KEY); 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas); 1799 pat = rf""-({'|'.join(batch_categories)})$""; 1800 out.var = merge_dataframes(; 1801 [a.var for a in all_adatas],; 1802 out.var_names,; 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),; 1804 ); 1805 out.var = out.var.iloc[; 1806 :,; 1807 (; -> 1808 out.var.columns.str.extract(pat, expand=False); 1809 .fillna(""""); 1810 .argsort(kind=""stable""); 1811 ),; 1812 ]; 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls); 221 if obj is None:; 222 # we're accessing the attribute of the class, i.e., Dataset.geo; 223 return self._accessor; --> 224 accessor_obj = self._accessor(obj); 225 # Replace the property with the accessor object. Inspired by:; 226 # https://www.pydanny.com/cached-property.html; 227 # We need to use object.__setattr__ because we overwrite __setattr__ on; 228 # NDFrame; 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data); 178 def __init__(self, data) -> None:; 179 from pandas.core.arrays.string_ import StringDtype; --> 181 self._inferred_dtype = self._validate(data); 182 self._is_categorical = is_categorical_dtype(data.dtype); 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data); 232 inferred_dtype = lib.infer_dtype(values, skipna=True); 234 if inferred_dtype not in allowed_types:; --> 235 raise AttributeError(""Can only use .str accessor with string values!""); 236 return inferred_dtype. Attribut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:2422,Security,access,accessor,2422,"h_categories)})$""; 1800 out.var = merge_dataframes(; 1801 [a.var for a in all_adatas],; 1802 out.var_names,; 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),; 1804 ); 1805 out.var = out.var.iloc[; 1806 :,; 1807 (; -> 1808 out.var.columns.str.extract(pat, expand=False); 1809 .fillna(""""); 1810 .argsort(kind=""stable""); 1811 ),; 1812 ]; 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls); 221 if obj is None:; 222 # we're accessing the attribute of the class, i.e., Dataset.geo; 223 return self._accessor; --> 224 accessor_obj = self._accessor(obj); 225 # Replace the property with the accessor object. Inspired by:; 226 # https://www.pydanny.com/cached-property.html; 227 # We need to use object.__setattr__ because we overwrite __setattr__ on; 228 # NDFrame; 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data); 178 def __init__(self, data) -> None:; 179 from pandas.core.arrays.string_ import StringDtype; --> 181 self._inferred_dtype = self._validate(data); 182 self._is_categorical = is_categorical_dtype(data.dtype); 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data); 232 inferred_dtype = lib.infer_dtype(values, skipna=True); 234 if inferred_dtype not in allowed_types:; --> 235 raise AttributeError(""Can only use .str accessor with string values!""); 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values!; ```; I did try to eleminate empty cells, but it didn't work; #### Versions. <details>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; absl NA; asttokens NA; attr 22.1.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; certifi 2022.12.07; cf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:2825,Security,access,accessor,2825,"npy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls); 221 if obj is None:; 222 # we're accessing the attribute of the class, i.e., Dataset.geo; 223 return self._accessor; --> 224 accessor_obj = self._accessor(obj); 225 # Replace the property with the accessor object. Inspired by:; 226 # https://www.pydanny.com/cached-property.html; 227 # We need to use object.__setattr__ because we overwrite __setattr__ on; 228 # NDFrame; 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data); 178 def __init__(self, data) -> None:; 179 from pandas.core.arrays.string_ import StringDtype; --> 181 self._inferred_dtype = self._validate(data); 182 self._is_categorical = is_categorical_dtype(data.dtype); 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data); 232 inferred_dtype = lib.infer_dtype(values, skipna=True); 234 if inferred_dtype not in allowed_types:; --> 235 raise AttributeError(""Can only use .str accessor with string values!""); 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values!; ```; I did try to eleminate empty cells, but it didn't work; #### Versions. <details>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; absl NA; asttokens NA; attr 22.1.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.0.4; chex 0.1.7; colorama 0.4.6; comm 0.1.2; contextlib2 NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; docrep 0.3.2; executing 0.8.3; flax 0.6.1; fsspec 2023.4.0; gmpy2 2.1.2; h5py 3.8.0; hypergeom_ufunc NA; idna 3.4; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.19.2; ipython_genutils 0.2.0; ipywidgets 8.0.4; j",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:3028,Security,access,accessor,3028," self._accessor(obj); 225 # Replace the property with the accessor object. Inspired by:; 226 # https://www.pydanny.com/cached-property.html; 227 # We need to use object.__setattr__ because we overwrite __setattr__ on; 228 # NDFrame; 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data); 178 def __init__(self, data) -> None:; 179 from pandas.core.arrays.string_ import StringDtype; --> 181 self._inferred_dtype = self._validate(data); 182 self._is_categorical = is_categorical_dtype(data.dtype); 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data); 232 inferred_dtype = lib.infer_dtype(values, skipna=True); 234 if inferred_dtype not in allowed_types:; --> 235 raise AttributeError(""Can only use .str accessor with string values!""); 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values!; ```; I did try to eleminate empty cells, but it didn't work; #### Versions. <details>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; absl NA; asttokens NA; attr 22.1.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.0.4; chex 0.1.7; colorama 0.4.6; comm 0.1.2; contextlib2 NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; docrep 0.3.2; executing 0.8.3; flax 0.6.1; fsspec 2023.4.0; gmpy2 2.1.2; h5py 3.8.0; hypergeom_ufunc NA; idna 3.4; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.19.2; ipython_genutils 0.2.0; ipywidgets 8.0.4; jax 0.4.8; jaxlib 0.4.7; jedi 0.18.1; joblib 1.2.0; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.9.1; lightning_fabric 1.9.4; lightning_utilities 0.8.0; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mkl 2.4.0; ml_collection",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:3121,Security,access,accessor,3121,"om/cached-property.html; 227 # We need to use object.__setattr__ because we overwrite __setattr__ on; 228 # NDFrame; 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data); 178 def __init__(self, data) -> None:; 179 from pandas.core.arrays.string_ import StringDtype; --> 181 self._inferred_dtype = self._validate(data); 182 self._is_categorical = is_categorical_dtype(data.dtype); 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data); 232 inferred_dtype = lib.infer_dtype(values, skipna=True); 234 if inferred_dtype not in allowed_types:; --> 235 raise AttributeError(""Can only use .str accessor with string values!""); 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values!; ```; I did try to eleminate empty cells, but it didn't work; #### Versions. <details>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; absl NA; asttokens NA; attr 22.1.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.0.4; chex 0.1.7; colorama 0.4.6; comm 0.1.2; contextlib2 NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; docrep 0.3.2; executing 0.8.3; flax 0.6.1; fsspec 2023.4.0; gmpy2 2.1.2; h5py 3.8.0; hypergeom_ufunc NA; idna 3.4; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.19.2; ipython_genutils 0.2.0; ipywidgets 8.0.4; jax 0.4.8; jaxlib 0.4.7; jedi 0.18.1; joblib 1.2.0; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.9.1; lightning_fabric 1.9.4; lightning_utilities 0.8.0; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mkl 2.4.0; ml_collections NA; ml_dtypes 0.1.0; mpl_toolkits NA; mpmath 1.2.1; msgpack 1.0.5; mudata 0.2.2; multipledispatch 0.6.0; natsort 8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:921,Testability,log,log,921,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata; ```python; import scvi; scvi.model.SCVI.setup_anndata(adata); vae = scvi.model.SCVI(adata); vae.train(); ```. initialize the model using the scvi.model.SCVI object. ```python; solo = scvi.external.SOLO.from_scvi_model(vae); ```; And I got AttributeError; ```pytb; AttributeError Traceback (most recent call last); Cell In[29], line 1; ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs); 199 doublet_adata = AnnData(; 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1); 201 ); 202 doublet_adata.obs[LABELS_KEY] = ""doublet""; --> 204 full_adata = latent_adata.concatenate(doublet_adata); 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY); 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas); 1799 pat = rf""-({'|'.join(batch_categories)})$""; 1800 out.var = merge_dataframes(; 1801 [a.var for a in all_adatas],; 1802 out.var_names,; 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),; 1804 ); 1805 out.var = out.var.iloc[; 1806 :,; 1807 (; -> 1808 out.var.columns.str.extract(pat, expand=False); 1809 .fillna(""""); 1810 .argsort(kind=""stable""); 1811 ),; 1812 ]; 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls); 221 if obj is None:; 222 # we're accessing the attribute of the class, i.e., Dataset.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2475:1423,Energy Efficiency,adapt,adapting,1423,"wishes below: -->; ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: ; * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529); * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: ; * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:; """"""; http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr; """"""; assert np.all(x >= 0); if multiplicative_replacement == ""auto"":; if np.any(x == 0):; multiplicative_replacement = 1/(len(x)**2); if multiplicative_replacement is None:; multiplicative_replacement = 0; x = x.copy() + multiplicative_replacement; x = x/x.sum(); log_x = np.log(x); geometric_mean = log_x.mean(); return log_x ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1475,Energy Efficiency,power,power,1475,"wishes below: -->; ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: ; * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529); * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: ; * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:; """"""; http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr; """"""; assert np.all(x >= 0); if multiplicative_replacement == ""auto"":; if np.any(x == 0):; multiplicative_replacement = 1/(len(x)**2); if multiplicative_replacement is None:; multiplicative_replacement = 0; x = x.copy() + multiplicative_replacement; x = x/x.sum(); log_x = np.log(x); geometric_mean = log_x.mean(); return log_x ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:577,Integrability,wrap,wrap,577,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->; ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: ; * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529); * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: ; * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1423,Modifiability,adapt,adapting,1423,"wishes below: -->; ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: ; * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529); * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: ; * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:; """"""; http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr; """"""; assert np.all(x >= 0); if multiplicative_replacement == ""auto"":; if np.any(x == 0):; multiplicative_replacement = 1/(len(x)**2); if multiplicative_replacement is None:; multiplicative_replacement = 0; x = x.copy() + multiplicative_replacement; x = x/x.sum(); log_x = np.log(x); geometric_mean = log_x.mean(); return log_x ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:2621,Modifiability,layers,layers,2621,"o a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: ; * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529); * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: ; * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:; """"""; http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr; """"""; assert np.all(x >= 0); if multiplicative_replacement == ""auto"":; if np.any(x == 0):; multiplicative_replacement = 1/(len(x)**2); if multiplicative_replacement is None:; multiplicative_replacement = 0; x = x.copy() + multiplicative_replacement; x = x/x.sum(); log_x = np.log(x); geometric_mean = log_x.mean(); return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the layers; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:2129,Testability,assert,assert,2129,"o a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: ; * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529); * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: ; * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:; """"""; http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr; """"""; assert np.all(x >= 0); if multiplicative_replacement == ""auto"":; if np.any(x == 0):; multiplicative_replacement = 1/(len(x)**2); if multiplicative_replacement is None:; multiplicative_replacement = 0; x = x.copy() + multiplicative_replacement; x = x/x.sum(); log_x = np.log(x); geometric_mean = log_x.mean(); return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the layers; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:2399,Testability,log,log,2399,"o a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: ; * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529); * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: ; * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:; """"""; http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr; """"""; assert np.all(x >= 0); if multiplicative_replacement == ""auto"":; if np.any(x == 0):; multiplicative_replacement = 1/(len(x)**2); if multiplicative_replacement is None:; multiplicative_replacement = 0; x = x.copy() + multiplicative_replacement; x = x/x.sum(); log_x = np.log(x); geometric_mean = log_x.mean(); return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the layers; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->; ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: ; * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529); * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: ; * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:659,Usability,learn,learning,659,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->; ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: ; * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529); * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: ; * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:919,Usability,guid,guide,919,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->; ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: ; * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529); * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: ; * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2476:477,Energy Efficiency,adapt,adapting,477,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->; ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:; """"""; http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr; """"""; assert np.all(x >= 0); if multiplicative_replacement == ""auto"":; if np.any(x == 0):; multiplicative_replacement = 1/(len(x)**2); if multiplicative_replacement is None:; multiplicative_replacement = 0; x = x.copy() + multiplicative_replacement; x = x/x.sum(); log_x = np.log(x); geometric_mean = log_x.mean(); return log_x - geometric_mean. # Add CLR to layers; adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:477,Modifiability,adapt,adapting,477,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->; ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:; """"""; http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr; """"""; assert np.all(x >= 0); if multiplicative_replacement == ""auto"":; if np.any(x == 0):; multiplicative_replacement = 1/(len(x)**2); if multiplicative_replacement is None:; multiplicative_replacement = 0; x = x.copy() + multiplicative_replacement; x = x/x.sum(); log_x = np.log(x); geometric_mean = log_x.mean(); return log_x - geometric_mean. # Add CLR to layers; adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1455,Modifiability,layers,layers,1455,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->; ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:; """"""; http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr; """"""; assert np.all(x >= 0); if multiplicative_replacement == ""auto"":; if np.any(x == 0):; multiplicative_replacement = 1/(len(x)**2); if multiplicative_replacement is None:; multiplicative_replacement = 0; x = x.copy() + multiplicative_replacement; x = x/x.sum(); log_x = np.log(x); geometric_mean = log_x.mean(); return log_x - geometric_mean. # Add CLR to layers; adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1469,Modifiability,layers,layers,1469,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->; ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:; """"""; http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr; """"""; assert np.all(x >= 0); if multiplicative_replacement == ""auto"":; if np.any(x == 0):; multiplicative_replacement = 1/(len(x)**2); if multiplicative_replacement is None:; multiplicative_replacement = 0; x = x.copy() + multiplicative_replacement; x = x/x.sum(); log_x = np.log(x); geometric_mean = log_x.mean(); return log_x - geometric_mean. # Add CLR to layers; adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:642,Performance,perform,perform,642,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->; ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:; """"""; http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr; """"""; assert np.all(x >= 0); if multiplicative_replacement == ""auto"":; if np.any(x == 0):; multiplicative_replacement = 1/(len(x)**2); if multiplicative_replacement is None:; multiplicative_replacement = 0; x = x.copy() + multiplicative_replacement; x = x/x.sum(); log_x = np.log(x); geometric_mean = log_x.mean(); return log_x - geometric_mean. # Add CLR to layers; adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1656,Performance,perform,performed,1656,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->; ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:; """"""; http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr; """"""; assert np.all(x >= 0); if multiplicative_replacement == ""auto"":; if np.any(x == 0):; multiplicative_replacement = 1/(len(x)**2); if multiplicative_replacement is None:; multiplicative_replacement = 0; x = x.copy() + multiplicative_replacement; x = x/x.sum(); log_x = np.log(x); geometric_mean = log_x.mean(); return log_x - geometric_mean. # Add CLR to layers; adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1102,Testability,assert,assert,1102,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->; ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:; """"""; http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr; """"""; assert np.all(x >= 0); if multiplicative_replacement == ""auto"":; if np.any(x == 0):; multiplicative_replacement = 1/(len(x)**2); if multiplicative_replacement is None:; multiplicative_replacement = 0; x = x.copy() + multiplicative_replacement; x = x/x.sum(); log_x = np.log(x); geometric_mean = log_x.mean(); return log_x - geometric_mean. # Add CLR to layers; adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1372,Testability,log,log,1372,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->; ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:; """"""; http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr; """"""; assert np.all(x >= 0); if multiplicative_replacement == ""auto"":; if np.any(x == 0):; multiplicative_replacement = 1/(len(x)**2); if multiplicative_replacement is None:; multiplicative_replacement = 0; x = x.copy() + multiplicative_replacement; x = x/x.sum(); log_x = np.log(x); geometric_mean = log_x.mean(); return log_x - geometric_mean. # Add CLR to layers; adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->; ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python; import numpy as np; import pandas as pd; from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:; """"""; http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr; """"""; assert np.all(x >= 0); if multiplicative_replacement == ""auto"":; if np.any(x == 0):; multiplicative_replacement = 1/(len(x)**2); if multiplicative_replacement is None:; multiplicative_replacement = 0; x = x.copy() + multiplicative_replacement; x = x/x.sum(); log_x = np.log(x); geometric_mean = log_x.mean(); return log_x - geometric_mean. # Add CLR to layers; adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2477:3119,Deployability,update,updated,3119,"l 0.12.10; certifi 2022.12.07; cffi 1.15.0; charset_normalizer 2.0.11; colorama 0.4.4; comm 0.1.1; compositional 2022.8.31; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.4; decorator 5.1.1; defusedxml 0.7.1; ensemble_networkx 2023.1.23; entrypoints 0.4; ete3 3.1.2; executing 0.8.2; fastcluster 1.1.26; fontTools 4.29.1; h5py 3.7.0; hdmedians NA; hive_networkx 2021.05.18; hypergeom_ufunc NA; idna 3.3; igraph 0.10.2; ipykernel 6.19.4; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; jupyter_server 1.23.4; kiwisolver 1.3.2; leidenalg 0.9.1; llvmlite 0.38.0; lxml 4.7.1; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; matplotlib_venn 0.11.6; mpl_toolkits NA; msgpack 1.0.3; natsort 8.1.0; nbinom_ufunc NA; networkx 2.6.3; numba 0.55.1; numpy 1.21.5; packaging 21.3; palettable 3.3.0; pandas 1.4.0; parso 0.8.3; patsy 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.3.0; prompt_toolkit 3.0.26; psutil 5.9.4; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.1; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2021.3; pytz_deprecation_shim NA; requests 2.27.1; rpy2 3.5.6; scipy 1.8.0; seaborn 0.11.2; session_info 1.0.0; setuptools 60.7.1; sip NA; six 1.16.0; skbio 0.5.6; sklearn 1.0.2; socks 1.7.1; soothsayer 2022.8.31; soothsayer_utils 2022.6.24; stack_data 0.1.4; statsmodels 0.13.1; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.1; tqdm 4.62.3; traitlets 5.1.1; typing_extensions NA; tzlocal NA; umap 0.5.2; unicodedata2 NA; urllib3 1.26.8; wcwidth 0.2.5; xarray 2023.1.0; zmq 24.0.1; zoneinfo NA; -----; IPython 8.0.1; jupyter_client 7.3.4; jupyter_core 5.0.0; jupyterlab 3.5.2; notebook 6.5.2; -----; Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:55:37) [Clang 14.0.6 ]; macOS-12.6-x86_64-i386-64bit; -----; Session information updated at 2023-04-27 15:56; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:1147,Performance,cache,cachecontrol,1147," scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; with plt.style.context(""seaborn-white""):; fig, ax = plt.subplots(figsize=(8,8)); sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ); fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15); ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```; ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.3; -----; Bio 1.79; PIL 9.0.1; PyQt5 NA; adjustText NA; appnope 0.1.2; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; cachecontrol 0.12.10; certifi 2022.12.07; cffi 1.15.0; charset_normalizer 2.0.11; colorama 0.4.4; comm 0.1.1; compositional 2022.8.31; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.4; decorator 5.1.1; defusedxml 0.7.1; ensemble_networkx 2023.1.23; entrypoints 0.4; ete3 3.1.2; executing 0.8.2; fastcluster 1.1.26; fontTools 4.29.1; h5py 3.7.0; hdmedians NA; hive_networkx 2021.05.18; hypergeom_ufunc NA; idna 3.3; igraph 0.10.2; ipykernel 6.19.4; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; jupyter_server 1.23.4; kiwisolver 1.3.2; leidenalg 0.9.1; llvmlite 0.38.0; lxml 4.7.1; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; matplotlib_venn 0.11.6; mpl_toolkits NA; msgpack 1.0.3; natsort 8.1.0; nbinom_ufunc NA; networkx 2.6.3; numba 0.55.1; numpy 1.21.5; packaging 21.3; palettable 3.3.0; pandas 1.4.0; parso 0.8.3; patsy 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.3.0; prompt_toolkit 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; with plt.style.context(""seaborn-white""):; fig, ax = plt.subplots(figsize=(8,8)); sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ); fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15); ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```; ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.9.3; -----; Bio 1.79; PIL 9.0.1; PyQt5 NA; adjustText NA; appnope 0.1.2; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; cachecontrol 0.12.10; certifi 2022.12.07; cffi 1.15.0; charset_normalizer 2.0.11; colorama 0.4.4; comm 0.1.1; compositional 2022.8.31; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.4; decorator 5.1.1; defusedxml 0.7.1; ensemble_networkx 2023.1.23; entrypoints 0.4; ete3 3.1.2; executing 0.8.2; fastcluster 1.1.26; fontTools 4.29.1; h5py 3.7.0; hdmedians NA; hive_networkx 2021.05.18; hypergeom_ufunc NA; idna 3.3; igraph 0.10.2; ipykernel 6.19.4; ipython_genutils 0.2.0; ipywidgets 8.0.4; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; jupyter_server 1.23.4; kiwisolver 1.3.2; leidenalg 0.9.1; llvmlite 0.38.0; lxml 4.7.1; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; matplotlib_venn 0.11.6; mpl_toolkits NA; msgpack 1.0.3; natsort 8.1.0; nbinom_ufunc NA; networkx 2.6.3; numba 0.55.1; numpy 1.21.5; packaging 21.3; palettable 3.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/pull/2478:65,Deployability,pipeline,pipelines,65,adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:0,Energy Efficiency,adapt,adapted,0,adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:0,Modifiability,adapt,adapted,0,adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:151,Usability,guid,guidelines,151,adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:182,Usability,guid,guide,182,adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/issues/2479:1006,Availability,Error,Error,1006,"have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate; - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue; - Re-installed the latest version of R; - Re-installed the latest version of miniconda; - Created a new conda environment and re-installed scanpy; - Ran the code in Rstudio and command line; - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux; - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R; sc <- reticulate::import(""scanpy"", convert = FALSE); ```. ```bash; *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x81329)[0x7f78837b9329]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]; /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0x7f78842ca06b]; /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_applyClo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:548,Deployability,install,installed,548,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate; - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue; - Re-installed the latest version of R; - Re-installed the latest version of miniconda; - Created a new conda environment and re-installed scanpy; - Ran the code in Rstudio and command line; - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux; - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R; sc <- reticulate::import(""scanpy"", convert = FALSE); ```. ```bash; *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x81329)[0x7f78837b9329]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]; /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0x7f78842ca06b]; /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:588,Deployability,install,installed,588,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate; - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue; - Re-installed the latest version of R; - Re-installed the latest version of miniconda; - Created a new conda environment and re-installed scanpy; - Ran the code in Rstudio and command line; - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux; - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R; sc <- reticulate::import(""scanpy"", convert = FALSE); ```. ```bash; *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x81329)[0x7f78837b9329]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]; /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0x7f78842ca06b]; /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:672,Deployability,install,installed,672,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate; - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue; - Re-installed the latest version of R; - Re-installed the latest version of miniconda; - Created a new conda environment and re-installed scanpy; - Ran the code in Rstudio and command line; - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux; - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R; sc <- reticulate::import(""scanpy"", convert = FALSE); ```. ```bash; *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x81329)[0x7f78837b9329]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]; /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]; /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]; /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0x7f78842ca06b]; /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:9538,Performance,load,loaded,9538,"c88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5; 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5; 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5; 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5; 7f741168f000-7f7411691000 rw-p 00000000 00:00 0; 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0; 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted; ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python; libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so; pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi; version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]; numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy; numpy_version: 1.23.5. python versions found:; /home/dgc88/miniconda3/bin/python3; /home/dgc88/miniconda3/bin/python; /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15); Platform: x86_64-pc-linux-gnu (64-bit); Running under: Red Hat Enterprise Linux. Matrix products: default; BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so; LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:; [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C; [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8; [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8; [7] LC_PAPER=en_US.UTF-8 LC_NAME=C; [9] LC_ADDRESS=C LC_TELEPHONE=C; [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C. attached base packages:; [1] stats graphics grDevices utils datasets methods base. other attached packages:; [1] reticulate_1.28. loaded via a namespace (and not attached):; [1] compiler_4.2.3 Matrix_1.5-4 Rcpp_1.0.10 grid_4.2.3 jsonlite_1.8.4; [6] png_0.1-8 lattice_0.21-8. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2480:2629,Deployability,update,updated,2629,"bmc3k(). sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata); adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata); sc.pp.pca(adata); sc.pp.neighbors(adata). sc.tl.leiden(adata); sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""); ```. #### Versions. <details>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; gmpy2 2.1.2; google NA; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.4; invgauss_ufunc NA; ipykernel 6.22.0; ipywidgets 8.0.6; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mpl_toolkits NA; mpmath 1.3.0; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; nvfuser NA; opt_einsum v3.3.0; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; setuptools 67.7.2; setuptools_scm NA; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; stack_data 0.6.2; sympy 1.11.1; texttable 1.6.7; threadpoolctl 3.1.0; torch 2.0.0; tornado 6.3; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; wcwidth 0.2.6; yaml 6.0; zmq 25.0.2; zoneinfo NA; -----; IPython 8.12.1; jupyter_client 8.2.0; jupyter_core 5.3.0; -----; Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]; Linux-5.19.0-41-generic-x86_64-with-glibc2.36; -----; Session information updated at 2023-05-02 16:27. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2481:346,Usability,simpl,simple,346,"Is there a way to interactively visualize and filter spots in Visium data based on coordinate values from `adata.obsm['spatial']`? There are some spots lying outside of the tissue which I'd like to filter from the data or even removing rows/ columns of spots from the array. Since the spaceranger coordinates are not perfectly aligned, writing a simple condition does not extract all spots of interest.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2481
https://github.com/scverse/scanpy/pull/2482:253,Testability,benchmark,benchmarking,253,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. This PR introduces benchmarking for Scanpy with airspeed-velocity (asv) ([Link](https://asv.readthedocs.io/en/stable/index.html)),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2482
https://github.com/scverse/scanpy/pull/2482:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. This PR introduces benchmarking for Scanpy with airspeed-velocity (asv) ([Link](https://asv.readthedocs.io/en/stable/index.html)),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2482
https://github.com/scverse/scanpy/pull/2482:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. This PR introduces benchmarking for Scanpy with airspeed-velocity (asv) ([Link](https://asv.readthedocs.io/en/stable/index.html)),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2482
https://github.com/scverse/scanpy/pull/2483:371,Testability,test,tested,371,"I tried to keep the resulting AnnData as compatible as possible with the Visium output, but it is still going to break sc.pl.spatial due to the lack of scale factors. In theory, we could calculate the scale factors ourselves, but that's probably not useful for plotting anyway, since the current spatial plotting function also requires spot sizes, which we don't have. I tested it on the example Xenium data set from the 10x web site. The images in this data set are JPEG2000-compressed, which is not supported by Pillow. Manually creating an image with zlib compression and passing that to the reader works. I don't know if the 10x Xenium software can only output this type of image file or if it can also produce TIFFs with another compression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2483
https://github.com/scverse/scanpy/pull/2484:108,Usability,responsiv,responsive,108,"The previous docs PRs moved the generated docs path, which breaks old urls. This fixes that. This also adds responsive handling of the grid on the main index page.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2484
https://github.com/scverse/scanpy/issues/2486:1194,Availability,error,error,1194,"this bug exists on the master branch of scanpy. ---. I have imported NanoString CosMX data using the `sq.read.nanostring()` function and stored as `adata`. The NanoString data has multiple field of views references (FOV's) stored in the `adata.obs` dataframe as well as spatial data in `adata.uns` and `adata.obsm`. To illustrate: . ```pytp; ---------------------------------------------------------------------------; View of AnnData object with n_obs  n_vars = 52078  6200; obs: 'fov', ' ... 'pct_counts_is_mito', 'total_counts_is_ribo', 'pct_counts_is_ribo', 'total_counts_is_NegPrb', 'leiden', 'h_oligo', 'h_opc', 'h_tCRM', 'h_exc', 'h_IRM', 'hPIG_DE', 'h_TRM', 'h_inh', 'h_astro', 'h_CRM1', 'h_micro', 'h_DAM', 'h_CRM2', 'h_HLA', 'h_endo', 'Cell Type', 'Leiden_Cell_Type'; uns: 'spatial'; obsm: 'spatial', 'spatial_fov'; ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,; using the `sc.pl.spatial` function I get the following error:. ```python; sc.pl.spatial(; adata, ; basis=""spatial_fov"",; color=[""Leiden_Cell_Type""], ; spot_size=120, , ; ); ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[45], line 1; ----> 1 sc.pl.spatial(; 2 AD_adata,; 3 basis = 'spatial_fov',; 4 color = 'total_counts',; 5 spot_size = 120; 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs); 936 """"""\; 937 Scatter plot in spatial coordinates.; 938 ; (...); 985 Tutorial on spatial analysis.; 986 """"""; 987 # get default image params if available; --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id); 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw); 990 spot_size = _check_spot_size",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:1991,Availability,avail,available,1991,"; ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,; using the `sc.pl.spatial` function I get the following error:. ```python; sc.pl.spatial(; adata, ; basis=""spatial_fov"",; color=[""Leiden_Cell_Type""], ; spot_size=120, , ; ); ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[45], line 1; ----> 1 sc.pl.spatial(; 2 AD_adata,; 3 basis = 'spatial_fov',; 4 color = 'total_counts',; 5 spot_size = 120; 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs); 936 """"""\; 937 Scatter plot in spatial coordinates.; 938 ; (...); 985 Tutorial on spatial analysis.; 986 """"""; 987 # get default image params if available; --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id); 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw); 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id); 1289 if library_id is _empty:; 1290 if len(spatial_mapping) > 1:; -> 1291 raise ValueError(; 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify.""; 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}""; 1294 ); 1295 elif len(spatial_mapping) == 1:; 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:; 	['1', '10', '100', '101', '102', '103', '104', '105', '106'...; ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow; in this SquidPy [tutorial](htt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:3392,Usability,learn,learn,3392,"or = 'total_counts',; 5 spot_size = 120; 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs); 936 """"""\; 937 Scatter plot in spatial coordinates.; 938 ; (...); 985 Tutorial on spatial analysis.; 986 """"""; 987 # get default image params if available; --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id); 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw); 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id); 1289 if library_id is _empty:; 1290 if len(spatial_mapping) > 1:; -> 1291 raise ValueError(; 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify.""; 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}""; 1294 ); 1295 elif len(spatial_mapping) == 1:; 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:; 	['1', '10', '100', '101', '102', '103', '104', '105', '106'...; ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow; in this SquidPy [tutorial](https://squidpy.readthedocs.io/en/stable/external_tutorials/tutorial_nanostring.html) where I use the `sq.pl.spatial_segment()`, or `sq.pl.spatial_scatter()` and specify a list of library keys, it states that the format of the library keys argument is of an unhashable type. #### Versions. <details>. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.22.4 scipy==1.9.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.14.0rc0 python-igraph==0.10.4 pynndescent==0.5.10. </details>. I would much appreciate if anyone could advise. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2487:583,Availability,error,error,583,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'); ```. ```pytb; [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:735,Testability,log,logging,735,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'); ```. ```pytb; [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:257,Usability,guid,guide,257,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'); ```. ```pytb; [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2488:231,Availability,error,error,231,"Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py; >>> import os; >>> # p = os.path.join( ""path to outs location""); >>> print(p); ""path to outs location""; >>> print(os.path.exists(p)); True; >>> ad = sc.read_visium(p); ```. ```pytb; Traceback (most recent call last):. Cell In[6], line 1; ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium; raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'; ```. ### Session/scanpy info:; Software versions; Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]; IPython 8.10.0; OS Windows 10 10.0.22621 SP0; scanpy 1.9.3; Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488
https://github.com/scverse/scanpy/issues/2488:37,Performance,load,load,37,"Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py; >>> import os; >>> # p = os.path.join( ""path to outs location""); >>> print(p); ""path to outs location""; >>> print(os.path.exists(p)); True; >>> ad = sc.read_visium(p); ```. ```pytb; Traceback (most recent call last):. Cell In[6], line 1; ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium; raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'; ```. ### Session/scanpy info:; Software versions; Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]; IPython 8.10.0; OS Windows 10 10.0.22621 SP0; scanpy 1.9.3; Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488
https://github.com/scverse/scanpy/issues/2489:369,Availability,error,error,369,"Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions?. NoteI stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version; Scanpy version: 1.9.3; AnnData version: 0.9.1; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:614,Availability,down,download,614,"Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions?. NoteI stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version; Scanpy version: 1.9.3; AnnData version: 0.9.1; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2491:264,Availability,error,error,264,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python; import zarr; import anndata as a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:6605,Deployability,update,updated,6605,"l 0.2.0; brotli NA; certifi 2023.05.07; cffi 1.15.1; charset_normalizer 3.1.0; click 8.1.3; cloudpickle 2.2.1; colorama 0.4.6; colorful 0.5.5; colorful_orig 0.5.5; comm 0.1.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.5.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; distributed 2023.5.0; entrypoints 0.4; executing 1.2.0; fasteners 0.17.3; filelock 3.12.0; fsspec 2023.5.0; google NA; grpc 1.43.0; h5py 3.8.0; idna 3.4; igraph 0.10.4; ipykernel 6.23.1; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; jsonschema 4.17.3; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; locket NA; lz4 4.3.2; markupsafe 2.1.2; matplotlib 3.6.3; matplotlib_inline 0.1.6; mpl_toolkits NA; msgpack 1.0.5; natsort 8.3.1; numba 0.57.0; numcodecs 0.11.0; numpy 1.24.3; packaging 23.1; pandas 2.0.1; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.1; prometheus_client NA; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pyarrow 9.0.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pynvml NA; pyparsing 3.0.9; pyrsistent NA; pytz 2023.3; ray 2.3.0; rb_analysis NA; requests 2.29.0; scipy 1.10.1; seaborn 0.12.2; session_info 1.0.0; setproctitle 1.2.2; setuptools 67.7.2; six 1.16.0; sklearn 1.2.2; socks 1.7.1; sortedcontainers 2.4.0; stack_data 0.6.2; statsmodels 0.14.0; tblib 1.7.0; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; tornado 6.3.2; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; urllib3 1.26.15; wcwidth 0.2.6; yaml 6.0; zarr 2.14.2; zict 3.0.0; zipp NA; zmq 25.0.2; zoneinfo NA; -----; IPython 8.13.2; jupyter_client 8.2.0; jupyter_core 5.3.0; -----; Python 3.10.11 | packaged by conda-forge | (main, May 10 2023, 19:01:19) [Clang 14.0.6 ]; macOS-13.3.1-arm64-arm-64bit; -----; Session information updated at 2023-05-18 14:00. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:670,Integrability,depend,dependency,670,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python; import zarr; import anndata as a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:840,Integrability,wrap,wrap,840,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python; import zarr; import anndata as a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:1717,Integrability,wrap,wrapped,1717," dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python; import zarr; import anndata as ad; import dask.array as da; import scanpy as sc. # write data to zarr file; rel_zarr_path = 'data/pbmc3k_processed.zarr'; adata = sc.datasets.pbmc3k_processed(); adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]); zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array; def read_dask(store):; f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):; if iospec.encoding_type in (; ""dataframe"",; ""csr_matrix"",; ""csc_matrix"",; ""awkward-array"",; ):; # Preventing recursing inside of these types; return ad.experimental.read_elem(elem); elif iospec.encoding_type == ""array"":; return da.fr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3437,Integrability,wrap,wrapper,3437,"ward-array"",; ):; # Preventing recursing inside of these types; return ad.experimental.read_elem(elem); elif iospec.encoding_type == ""array"":; return da.from_zarr(elem); else:; return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata; adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing; sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); sc.pp.scale(adata_dask, max_value=10); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[1], line 39; 37 sc.pp.log1p(adata); 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw); 885 if not args:; 886 raise TypeError(f'{funcname} requires at least '; 887 '1 positional argument'); --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm); 842 view_to_actual(adata); 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm); --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(; 845 X,; 846 zero_center=zero_center,; 847 max_value=max_value,; 848 copy=False, # because a copy has already been made, if it were to be made; 849 return_mean_std=True,; 850 ); 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm); 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw); 885 if not args:; 886 raise TypeError(f'{funcname} requires at least '; 887 '1 positional argument'); --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'; ```. #### Versions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:4242,Integrability,wrap,wrapper,4242,"pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw); 885 if not args:; 886 raise TypeError(f'{funcname} requires at least '; 887 '1 positional argument'); --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm); 842 view_to_actual(adata); 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm); --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(; 845 X,; 846 zero_center=zero_center,; 847 max_value=max_value,; 848 copy=False, # because a copy has already been made, if it were to be made; 849 return_mean_std=True,; 850 ); 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm); 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw); 885 if not args:; 886 raise TypeError(f'{funcname} requires at least '; 887 '1 positional argument'); --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'; ```. #### Versions. <details>. -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; appnope 0.1.3; asciitree NA; asttokens NA; attr 23.1.0; backcall 0.2.0; brotli NA; certifi 2023.05.07; cffi 1.15.1; charset_normalizer 3.1.0; click 8.1.3; cloudpickle 2.2.1; colorama 0.4.6; colorful 0.5.5; colorful_orig 0.5.5; comm 0.1.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.5.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; distributed 2023.5.0; entrypoints 0.4; executing 1.2.0; fasteners 0.17.3; filelock 3.12.0; fsspec 2023.5.0; google NA; grpc 1.43.0; h5py 3.8.0; idna 3.4; igraph 0.10.4; ipykernel 6.23.1; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; jsonschema 4.17.3; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; locket NA; lz4 4.3.2; markupsafe 2.1.2; matplotlib 3.6.3; matplotlib_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:1046,Modifiability,enhance,enhancement,1046,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python; import zarr; import anndata as a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:2836,Performance,perform,perform,2836,"ata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python; import zarr; import anndata as ad; import dask.array as da; import scanpy as sc. # write data to zarr file; rel_zarr_path = 'data/pbmc3k_processed.zarr'; adata = sc.datasets.pbmc3k_processed(); adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]); zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array; def read_dask(store):; f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):; if iospec.encoding_type in (; ""dataframe"",; ""csr_matrix"",; ""csc_matrix"",; ""awkward-array"",; ):; # Preventing recursing inside of these types; return ad.experimental.read_elem(elem); elif iospec.encoding_type == ""array"":; return da.from_zarr(elem); else:; return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata; adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing; sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); sc.pp.scale(adata_dask, max_value=10); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[1], line 39; 37 sc.pp.log1p(adata); 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw); 885 if not args:; 886 raise TypeError(f'{funcname} requires at least '; 887 '1 positional argument'); --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm); 842 view_to_actual(adata); 843 X = _get_obs_rep(adata, layer=layer,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:1364,Usability,guid,guide,1364,".scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python; import zarr; import anndata as ad; import dask.array as da; import scanpy as sc. # write data to zarr file; rel_zarr_path = 'data/pbmc3k_processed.zarr'; adata = sc.datasets.pbmc3k_processed(); adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]); zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array; def read_dask(store):; f = zarr.open(s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2493:190,Availability,avail,available,190,"When I run:; ```; sc.pp.highly_variable_genes(; adata,; flavor=""seurat_v3"",; batch_key=""batch"",; n_top_genes=2000,; subset=False,; )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb; sc.pp.highly_variable_genes(; adata,; flavor=""seurat_v3"",; #batch_key=""batch"",; n_top_genes=2000,; subset=False,; )```. It finished in about 10 seconds. #### Versions. <details>. -----; anndata 0.8.0; scanpy 1.10.0.dev57+g08be4e9; -----; PIL 9.4.0; aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA; absl NA; adjustText 0.8; anyio NA; arrow 1.2.3; arviz 0.15.0; asciitree NA; asttokens NA; astunparse 1.6.3; attr 22.2.0; babel 2.12.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bokeh 2.4.3; brotli NA; captum 0.6.0; cellrank 1.5.1; certifi 2023.05.07; cffi 1.15.1; charset_normalizer 2.1.1; chex 0.1.6; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.2; contextlib2 NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.3.0; dask_image 2022.09.0; dateutil 2.8.2; debugpy 1.6.6; decorator 5.1.1; decoupler 1.4.0; defusedxml 0.7.1; dill 0.3.6; docrep 0.3.2; dot_parser NA; entrypoints 0.4; executing 1.2.0; fasteners 0.17.3; fastjsonschema NA; flatbuffers 23.1.21; flax 0.5.0; fqdn NA; fsspec 2023.1.0; gast NA; google NA; gseapy 1.0.4; h5py 3.8.0; hypergeom_ufunc NA; idna 3.4; igraph 0.10.3; imagecodecs 2023.1.23; imageio 2.26.0; invgauss_ufunc NA; ipykernel 6.21.2; ipython_genutils 0.2.0; ipywidgets 8.0.4; isoduration NA; jax 0.4.10; jaxlib 0.4.10; jedi 0.18.2; jinja2 3.0.3; joblib 1.2.0; json5 NA; jsonpointer 2.3; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.3.0; jupyterlab_server 2.19.0; keras 2.11.0; kiwisolver 1.4.4; leidenalg 0.9.1; lightning_fabric 1.9.3; lightning_utilities 0.7.0; llvmlite 0.39.1; lz4 4.3.2; markupsafe 2.1.2; matplotlib 3.7.1; matplotlib_inline 0.1.6; matplotlib_scalebar 0.8.1; ml_collections NA; ml_dtypes 0.1.0; mpl_toolkits NA; msgpack 1.0.4; mudata 0.2.1; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:4181,Deployability,update,updated,4181,".0; opt_einsum v3.3.0; optax 0.1.4; packaging 23.0; pandas 1.5.3; parso 0.8.3; paste NA; patsy 0.5.3; petsc4py 3.19.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.0.0; progressbar 4.2.0; prometheus_client NA; prompt_toolkit 3.0.38; psutil 5.9.4; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 1.4.2; pygam 0.8.0; pygments 2.14.0; pygpcca 1.0.4; pyparsing 3.0.9; pyro 1.8.4+9ed468d; pyrsistent NA; python_utils NA; pythonjsonlogger NA; pytorch_lightning 1.9.3; pytz 2022.7.1; pywt 1.4.1; requests 2.28.2; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rich NA; scHPL NA; scarches 0.5.7; sccoda 0.1.9; scipy 1.10.1; scvelo 0.2.5; scvi 0.20.1; seaborn 0.12.2; send2trash NA; session_info 1.0.0; setuptools 67.4.0; six 1.16.0; skewnorm_ufunc NA; skimage 0.19.3; sklearn 1.2.1; slepc4py 3.19.0; sniffio 1.3.0; socks 1.7.1; squidpy 1.2.2; stack_data 0.6.2; statsmodels 0.13.5; tblib 1.7.0; tcr_embedding NA; tensorboard 2.11.2; tensorflow 2.11.0; tensorflow_probability 0.19.0; termcolor NA; texttable 1.6.7; threadpoolctl 3.1.0; tifffile 2023.2.28; tlz 0.12.0; toolz 0.12.0; torch 1.13.1; torch_cluster 1.6.0; torch_geometric 2.2.0; torch_scatter 2.1.0; torch_sparse 0.6.15; torchmetrics 0.11.3; torchvision 0.14.1; tornado 6.2; tqdm 4.64.1; traitlets 5.9.0; tree 0.1.7; typing_extensions NA; unicodedata2 NA; uri_template NA; urllib3 1.26.14; validators 0.20.0; wcwidth 0.2.6; webcolors 1.11.1; websocket 1.5.1; wrapt 1.15.0; xarray 2023.2.0; xarray_einstats 0.5.1; yaml 6.0; zarr 2.13.6; zipp NA; zmq 25.0.0; zoneinfo NA; zope NA; -----; IPython 8.11.0; jupyter_client 8.0.3; jupyter_core 5.2.0; jupyterlab 3.6.1; notebook 6.5.2; -----; Python 3.10.9 | packaged by conda-forge | (main, Feb 2 2023, 20:20:04) [GCC 11.3.0]; Linux-3.10.0-1160.83.1.el7.x86_64-x86_64-with-glibc2.17; -----; Session information updated at 2023-05-26 01:06. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:3786,Integrability,wrap,wrapt,3786,".0; opt_einsum v3.3.0; optax 0.1.4; packaging 23.0; pandas 1.5.3; parso 0.8.3; paste NA; patsy 0.5.3; petsc4py 3.19.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.0.0; progressbar 4.2.0; prometheus_client NA; prompt_toolkit 3.0.38; psutil 5.9.4; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 1.4.2; pygam 0.8.0; pygments 2.14.0; pygpcca 1.0.4; pyparsing 3.0.9; pyro 1.8.4+9ed468d; pyrsistent NA; python_utils NA; pythonjsonlogger NA; pytorch_lightning 1.9.3; pytz 2022.7.1; pywt 1.4.1; requests 2.28.2; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rich NA; scHPL NA; scarches 0.5.7; sccoda 0.1.9; scipy 1.10.1; scvelo 0.2.5; scvi 0.20.1; seaborn 0.12.2; send2trash NA; session_info 1.0.0; setuptools 67.4.0; six 1.16.0; skewnorm_ufunc NA; skimage 0.19.3; sklearn 1.2.1; slepc4py 3.19.0; sniffio 1.3.0; socks 1.7.1; squidpy 1.2.2; stack_data 0.6.2; statsmodels 0.13.5; tblib 1.7.0; tcr_embedding NA; tensorboard 2.11.2; tensorflow 2.11.0; tensorflow_probability 0.19.0; termcolor NA; texttable 1.6.7; threadpoolctl 3.1.0; tifffile 2023.2.28; tlz 0.12.0; toolz 0.12.0; torch 1.13.1; torch_cluster 1.6.0; torch_geometric 2.2.0; torch_scatter 2.1.0; torch_sparse 0.6.15; torchmetrics 0.11.3; torchvision 0.14.1; tornado 6.2; tqdm 4.64.1; traitlets 5.9.0; tree 0.1.7; typing_extensions NA; unicodedata2 NA; uri_template NA; urllib3 1.26.14; validators 0.20.0; wcwidth 0.2.6; webcolors 1.11.1; websocket 1.5.1; wrapt 1.15.0; xarray 2023.2.0; xarray_einstats 0.5.1; yaml 6.0; zarr 2.13.6; zipp NA; zmq 25.0.0; zoneinfo NA; zope NA; -----; IPython 8.11.0; jupyter_client 8.0.3; jupyter_core 5.2.0; jupyterlab 3.6.1; notebook 6.5.2; -----; Python 3.10.9 | packaged by conda-forge | (main, Feb 2 2023, 20:20:04) [GCC 11.3.0]; Linux-3.10.0-1160.83.1.el7.x86_64-x86_64-with-glibc2.17; -----; Session information updated at 2023-05-26 01:06. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:3717,Security,validat,validators,3717,".0; opt_einsum v3.3.0; optax 0.1.4; packaging 23.0; pandas 1.5.3; parso 0.8.3; paste NA; patsy 0.5.3; petsc4py 3.19.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.0.0; progressbar 4.2.0; prometheus_client NA; prompt_toolkit 3.0.38; psutil 5.9.4; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 1.4.2; pygam 0.8.0; pygments 2.14.0; pygpcca 1.0.4; pyparsing 3.0.9; pyro 1.8.4+9ed468d; pyrsistent NA; python_utils NA; pythonjsonlogger NA; pytorch_lightning 1.9.3; pytz 2022.7.1; pywt 1.4.1; requests 2.28.2; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rich NA; scHPL NA; scarches 0.5.7; sccoda 0.1.9; scipy 1.10.1; scvelo 0.2.5; scvi 0.20.1; seaborn 0.12.2; send2trash NA; session_info 1.0.0; setuptools 67.4.0; six 1.16.0; skewnorm_ufunc NA; skimage 0.19.3; sklearn 1.2.1; slepc4py 3.19.0; sniffio 1.3.0; socks 1.7.1; squidpy 1.2.2; stack_data 0.6.2; statsmodels 0.13.5; tblib 1.7.0; tcr_embedding NA; tensorboard 2.11.2; tensorflow 2.11.0; tensorflow_probability 0.19.0; termcolor NA; texttable 1.6.7; threadpoolctl 3.1.0; tifffile 2023.2.28; tlz 0.12.0; toolz 0.12.0; torch 1.13.1; torch_cluster 1.6.0; torch_geometric 2.2.0; torch_scatter 2.1.0; torch_sparse 0.6.15; torchmetrics 0.11.3; torchvision 0.14.1; tornado 6.2; tqdm 4.64.1; traitlets 5.9.0; tree 0.1.7; typing_extensions NA; unicodedata2 NA; uri_template NA; urllib3 1.26.14; validators 0.20.0; wcwidth 0.2.6; webcolors 1.11.1; websocket 1.5.1; wrapt 1.15.0; xarray 2023.2.0; xarray_einstats 0.5.1; yaml 6.0; zarr 2.13.6; zipp NA; zmq 25.0.0; zoneinfo NA; zope NA; -----; IPython 8.11.0; jupyter_client 8.0.3; jupyter_core 5.2.0; jupyterlab 3.6.1; notebook 6.5.2; -----; Python 3.10.9 | packaged by conda-forge | (main, Feb 2 2023, 20:20:04) [GCC 11.3.0]; Linux-3.10.0-1160.83.1.el7.x86_64-x86_64-with-glibc2.17; -----; Session information updated at 2023-05-26 01:06. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2494:205,Availability,error,error,205,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy. ---; I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata_rna.obs['thing']= 'a'; plt.rcParams[""figure.figsize""] = (8, 8); sc.pl.spatial(adata_rna, color = 'thing'); ```. ```pytb; ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:299,Deployability,install,install,299,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy. ---; I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata_rna.obs['thing']= 'a'; plt.rcParams[""figure.figsize""] = (8, 8); sc.pl.spatial(adata_rna, color = 'thing'); ```. ```pytb; ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:1090,Testability,log,logging,1090,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy. ---; I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata_rna.obs['thing']= 'a'; plt.rcParams[""figure.figsize""] = (8, 8); sc.pl.spatial(adata_rna, color = 'thing'); ```. ```pytb; ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:464,Usability,guid,guide,464,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy. ---; I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata_rna.obs['thing']= 'a'; plt.rcParams[""figure.figsize""] = (8, 8); sc.pl.spatial(adata_rna, color = 'thing'); ```. ```pytb; ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2495:1151,Performance,load,load,1151,"## Feature type; <!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. ## Request; <!-- Please describe your wishes below: -->; The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python; import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""); adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True); ```; yields:; ```; ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`.; ```; ### Workaround:; A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python; import numpy as np. FRACTION = 0.01. np.random.seed(0); random_bool = np.random.choice(; [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]; ). adata_sample = adata[random_bool, :]; adata_sample_mem = adata_sample.to_memory(); ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:184,Usability,simpl,simple,184,"## Feature type; <!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. ## Request; <!-- Please describe your wishes below: -->; The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python; import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""); adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True); ```; yields:; ```; ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`.; ```; ### Workaround:; A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python; import numpy as np. FRACTION = 0.01. np.random.seed(0); random_bool = np.random.choice(; [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]; ). adata_sample = adata[random_bool, :]; adata_sample_mem = adata_sample.to_memory(); ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:658,Usability,simpl,simply,658,"## Feature type; <!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. ## Request; <!-- Please describe your wishes below: -->; The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python; import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""); adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True); ```; yields:; ```; ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`.; ```; ### Workaround:; A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python; import numpy as np. FRACTION = 0.01. np.random.seed(0); random_bool = np.random.choice(; [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]; ). adata_sample = adata[random_bool, :]; adata_sample_mem = adata_sample.to_memory(); ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2496:1817,Modifiability,layers,layers,1817,"rocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, I'm trying to follow [Analytic Pearson residuals](https://www.sc-best-practices.org/preprocessing_visualization/normalization.html); but after getting first 2 nomalizations, I'm stucked with Pearson residuals normalization. It seems like a devided by 0 issue? I don't know. What else I can do to check if the matrix is the problem. already did gene (`min_cells=3`) and cell filtering(`min_genes=200`).; ### Minimal code sample (that we can copy&paste without having any data). ```python; analytic_pearson = sc.experimental.pp.normalize_pearson_residuals(adata, inplace=False); ```. ```pytb; /home/sxykdx/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/experimental/pp/_normalization.py:59: RuntimeWarning: invalid value encountered in divide; residuals = diff / np.sqrt(mu + mu**2 / theta); ```; `analytic_pearson[""X""]` ; Output:; ```py; array([[-0.08038502, -0.10195383, -0.24513291, ..., 1.47699586,; -0.08709449, -0.16926342],; [-0.08623174, -0.109369 , 3.53739781, ..., -0.54014355,; -0.09342913, -0.18157157],; [-0.07625086, -0.09671059, -0.2325321 , ..., -0.47777291,; 12.02085262, 6.06603257],; ...,; [-0.02799957, -0.03551299, -0.08540438, ..., -0.17560885,; -0.03033674, -0.05896328],; [-0.02840246, -0.03602399, -0.08663319, ..., -0.17813493,; -0.03077326, -0.05981169],; [-0.02914286, -0.03696307, -0.08889143, ..., -0.18277714,; -0.03157547, -0.06137084]]); ```. ```py; adata.layers[""analytic_pearson_residuals""] = analytic_pearson[""X""]; adata.layers[""analytic_pearson_residuals""].sum(1); ```; Output:; `array([nan, nan, nan, ..., nan, nan, nan])`. #### Versions. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.3 pynndescent==0.5.10. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2496
https://github.com/scverse/scanpy/issues/2496:1885,Modifiability,layers,layers,1885,"rocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, I'm trying to follow [Analytic Pearson residuals](https://www.sc-best-practices.org/preprocessing_visualization/normalization.html); but after getting first 2 nomalizations, I'm stucked with Pearson residuals normalization. It seems like a devided by 0 issue? I don't know. What else I can do to check if the matrix is the problem. already did gene (`min_cells=3`) and cell filtering(`min_genes=200`).; ### Minimal code sample (that we can copy&paste without having any data). ```python; analytic_pearson = sc.experimental.pp.normalize_pearson_residuals(adata, inplace=False); ```. ```pytb; /home/sxykdx/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/experimental/pp/_normalization.py:59: RuntimeWarning: invalid value encountered in divide; residuals = diff / np.sqrt(mu + mu**2 / theta); ```; `analytic_pearson[""X""]` ; Output:; ```py; array([[-0.08038502, -0.10195383, -0.24513291, ..., 1.47699586,; -0.08709449, -0.16926342],; [-0.08623174, -0.109369 , 3.53739781, ..., -0.54014355,; -0.09342913, -0.18157157],; [-0.07625086, -0.09671059, -0.2325321 , ..., -0.47777291,; 12.02085262, 6.06603257],; ...,; [-0.02799957, -0.03551299, -0.08540438, ..., -0.17560885,; -0.03033674, -0.05896328],; [-0.02840246, -0.03602399, -0.08663319, ..., -0.17813493,; -0.03077326, -0.05981169],; [-0.02914286, -0.03696307, -0.08889143, ..., -0.18277714,; -0.03157547, -0.06137084]]); ```. ```py; adata.layers[""analytic_pearson_residuals""] = analytic_pearson[""X""]; adata.layers[""analytic_pearson_residuals""].sum(1); ```; Output:; `array([nan, nan, nan, ..., nan, nan, nan])`. #### Versions. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.3 pynndescent==0.5.10. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2496
https://github.com/scverse/scanpy/issues/2496:2199,Testability,log,logging,2199,"rocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, I'm trying to follow [Analytic Pearson residuals](https://www.sc-best-practices.org/preprocessing_visualization/normalization.html); but after getting first 2 nomalizations, I'm stucked with Pearson residuals normalization. It seems like a devided by 0 issue? I don't know. What else I can do to check if the matrix is the problem. already did gene (`min_cells=3`) and cell filtering(`min_genes=200`).; ### Minimal code sample (that we can copy&paste without having any data). ```python; analytic_pearson = sc.experimental.pp.normalize_pearson_residuals(adata, inplace=False); ```. ```pytb; /home/sxykdx/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/experimental/pp/_normalization.py:59: RuntimeWarning: invalid value encountered in divide; residuals = diff / np.sqrt(mu + mu**2 / theta); ```; `analytic_pearson[""X""]` ; Output:; ```py; array([[-0.08038502, -0.10195383, -0.24513291, ..., 1.47699586,; -0.08709449, -0.16926342],; [-0.08623174, -0.109369 , 3.53739781, ..., -0.54014355,; -0.09342913, -0.18157157],; [-0.07625086, -0.09671059, -0.2325321 , ..., -0.47777291,; 12.02085262, 6.06603257],; ...,; [-0.02799957, -0.03551299, -0.08540438, ..., -0.17560885,; -0.03033674, -0.05896328],; [-0.02840246, -0.03602399, -0.08663319, ..., -0.17813493,; -0.03077326, -0.05981169],; [-0.02914286, -0.03696307, -0.08889143, ..., -0.18277714,; -0.03157547, -0.06137084]]); ```. ```py; adata.layers[""analytic_pearson_residuals""] = analytic_pearson[""X""]; adata.layers[""analytic_pearson_residuals""].sum(1); ```; Output:; `array([nan, nan, nan, ..., nan, nan, nan])`. #### Versions. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.3 pynndescent==0.5.10. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2496
https://github.com/scverse/scanpy/issues/2496:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, I'm trying to follow [Analytic Pearson residuals](https://www.sc-best-practices.org/preprocessing_visualization/normalization.html); but after getting first 2 nomalizations, I'm stucked with Pearson residuals normalization. It seems like a devided by 0 issue? I don't know. What else I can do to check if the matrix is the problem. already did gene (`min_cells=3`) and cell filtering(`min_genes=200`).; ### Minimal code sample (that we can copy&paste without having any data). ```python; analytic_pearson = sc.experimental.pp.normalize_pearson_residuals(adata, inplace=False); ```. ```pytb; /home/sxykdx/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/experimental/pp/_normalization.py:59: RuntimeWarning: invalid value encountered in divide; residuals = diff / np.sqrt(mu + mu**2 / theta); ```; `analytic_pearson[""X""]` ; Output:; ```py; array([[-0.08038502, -0.10195383, -0.24513291, ..., 1.47699586,; -0.08709449, -0.16926342],; [-0.08623174, -0.109369 , 3.53739781, ..., -0.54014355,; -0.09342913, -0.18157157],; [-0.07625086, -0.09671059, -0.2325321 , ..., -0.47777291,; 12.02085262, 6.06603257],; ...,; [-0.02799957, -0.03551299, -0.08540438, ..., -0.17560885,; -0.03033674, -0.05896328],; [-0.02840246, -0.03602399, -0.08663319, ..., -0.17813493,; -0.03077326, -0.05981169],; [-0.02914286, -0.03696307, -0.08889143, ..., -0.18277714,; -0.03157547, -0.06137084]]); ```. ```py; adata.layers[""analytic_pearson_residuals""] = analytic_pearson[""X""]; adata.layers[""analytic_pearson_residuals""].sum(1); ```; Output:; `array([nan, nan, nan, ..., nan, nan, nan])`. #### Versio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2496
https://github.com/scverse/scanpy/issues/2496:2095,Usability,learn,learn,2095,"rocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, I'm trying to follow [Analytic Pearson residuals](https://www.sc-best-practices.org/preprocessing_visualization/normalization.html); but after getting first 2 nomalizations, I'm stucked with Pearson residuals normalization. It seems like a devided by 0 issue? I don't know. What else I can do to check if the matrix is the problem. already did gene (`min_cells=3`) and cell filtering(`min_genes=200`).; ### Minimal code sample (that we can copy&paste without having any data). ```python; analytic_pearson = sc.experimental.pp.normalize_pearson_residuals(adata, inplace=False); ```. ```pytb; /home/sxykdx/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/experimental/pp/_normalization.py:59: RuntimeWarning: invalid value encountered in divide; residuals = diff / np.sqrt(mu + mu**2 / theta); ```; `analytic_pearson[""X""]` ; Output:; ```py; array([[-0.08038502, -0.10195383, -0.24513291, ..., 1.47699586,; -0.08709449, -0.16926342],; [-0.08623174, -0.109369 , 3.53739781, ..., -0.54014355,; -0.09342913, -0.18157157],; [-0.07625086, -0.09671059, -0.2325321 , ..., -0.47777291,; 12.02085262, 6.06603257],; ...,; [-0.02799957, -0.03551299, -0.08540438, ..., -0.17560885,; -0.03033674, -0.05896328],; [-0.02840246, -0.03602399, -0.08663319, ..., -0.17813493,; -0.03077326, -0.05981169],; [-0.02914286, -0.03696307, -0.08889143, ..., -0.18277714,; -0.03157547, -0.06137084]]); ```. ```py; adata.layers[""analytic_pearson_residuals""] = analytic_pearson[""X""]; adata.layers[""analytic_pearson_residuals""].sum(1); ```; Output:; `array([nan, nan, nan, ..., nan, nan, nan])`. #### Versions. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.3 pynndescent==0.5.10. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2496
https://github.com/scverse/scanpy/issues/2497:676,Availability,error,error,676,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am following all the steps from the PBMC3k tutorial (https://scanpy.readthedocs.io/en/latest/tutorials/pbmc3k.html).; I ran the wilcoxon method for finding marker genes and saved the object to a .h5ad file, after which I reloaded the object from the file and the log1p dict appears to be empty for some reason. I checked the object before saving it to the file and it had the 'base' key whereas after loading it back it was missing, causing the error below. . ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.read(results_file); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names; pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals']}).head(5); sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20); ```. ```pytb; KeyError Traceback (most recent call last); Input In [57], in <cell line: 1>(); ----> 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20). File /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2497
https://github.com/scverse/scanpy/issues/2497:4265,Deployability,update,updated,4265,"_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. #### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.2.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 0.8.3; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.9.11; ipykernel 6.13.0; ipython_genutils 0.2.0; ipywidgets 8.0.2; jedi 0.18.1; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.8.10; llvmlite 0.39.1; louvain 0.7.1; matplotlib 3.6.0; matplotlib_inline NA; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.56.2; numpy 1.23.0; packaging 21.3; pandas 1.4.3; parso 0.8.3; patsy 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.29; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.7; pyparsing 3.0.8; pytz 2022.1; ruamel NA; scipy 1.9.1; seaborn 0.12.0; session_info 1.0.0; six 1.16.0; sklearn 1.1.2; stack_data 0.2.0; statsmodels 0.13.2; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.1; tqdm 4.64.1; traitlets 5.1.1; typing_extensions NA; umap 0.5.3; wcwidth 0.2.5; yaml 5.3.1; zmq 22.3.0; -----; IPython 8.2.0; jupyter_client 7.2.2; jupyter_core 4.9.2; notebook 6.4.10; -----; Python 3.10.2 (v3.10.2:a58ebcc701, Jan 13 2022, 14:50:16) [Clang 13.0.0 (clang-1300.0.29.30)]; macOS-13.3.1-x86_64-i386-64bit; -----; Session information updated at 2023-05-30 21:48; ```. </details>. Any help would be appreciated! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2497
https://github.com/scverse/scanpy/issues/2497:632,Performance,load,loading,632,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am following all the steps from the PBMC3k tutorial (https://scanpy.readthedocs.io/en/latest/tutorials/pbmc3k.html).; I ran the wilcoxon method for finding marker genes and saved the object to a .h5ad file, after which I reloaded the object from the file and the log1p dict appears to be empty for some reason. I checked the object before saving it to the file and it had the 'base' key whereas after loading it back it was missing, causing the error below. . ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.read(results_file); pd.DataFrame(adata.uns['rank_genes_groups']['names']).head(5); result = adata.uns['rank_genes_groups']; groups = result['names'].dtype.names; pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals']}).head(5); sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20); ```. ```pytb; KeyError Traceback (most recent call last); Input In [57], in <cell line: 1>(); ----> 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20). File /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2497
https://github.com/scverse/scanpy/issues/2497:2073,Testability,log,logreg,2073,"l.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20); ```. ```pytb; KeyError Traceback (most recent call last); Input In [57], in <cell line: 1>(); ----> 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20). File /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. #### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.2.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 0.8.3; h5py 3.7.0; hypergeom_ufunc NA; ig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2497
https://github.com/scverse/scanpy/issues/2497:2087,Testability,log,logg,2087,"l.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20); ```. ```pytb; KeyError Traceback (most recent call last); Input In [57], in <cell line: 1>(); ----> 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20). File /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. #### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.2.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 0.8.3; h5py 3.7.0; hypergeom_ufunc NA; ig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2497
https://github.com/scverse/scanpy/issues/2497:2180,Testability,log,logarithmize,2180,"'], n_genes=20); ```. ```pytb; KeyError Traceback (most recent call last); Input In [57], in <cell line: 1>(); ----> 1 sc.tl.rank_genes_groups(adata, 'leiden', groups=['0'], reference='1', method='wilcoxon'); 2 sc.pl.rank_genes_groups(adata, groups=['0'], n_genes=20). File /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scanpy/tools/_rank_genes_groups.py:590, in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. #### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.2.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 0.8.3; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.9.11; ipykernel 6.13.0; ipython_genutils 0.2.0; ipywidgets 8.0.2; jedi 0.18.1; joblib 1.2.0; kiwisolver 1.4.4; leidenal",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2497
https://github.com/scverse/scanpy/issues/2497:2665,Testability,log,log,2665,"nkby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 580 adata.uns[key_added] = {}; 581 adata.uns[key_added]['params'] = dict(; 582 groupby=groupby,; 583 reference=reference,; (...); 587 corr_method=corr_method,; 588 ); --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts); 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':; 593 logg.warning(; 594 ""It seems you use rank_genes_groups on the raw count data. ""; 595 ""Please logarithmize your data before calling rank_genes_groups.""; 596 ). File /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scanpy/tools/_rank_genes_groups.py:93, in _RankGenes.__init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts); 82 def __init__(; 83 self,; 84 adata,; (...); 90 comp_pts=False,; 91 ):; ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:; 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])); 95 else:. KeyError: 'base'; ```. #### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.2.0; appnope 0.1.3; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 0.8.3; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.9.11; ipykernel 6.13.0; ipython_genutils 0.2.0; ipywidgets 8.0.2; jedi 0.18.1; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.8.10; llvmlite 0.39.1; louvain 0.7.1; matplotlib 3.6.0; matplotlib_inline NA; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.56.2; numpy 1.23.0; packaging 21.3; pandas 1.4.3; parso 0.8.3; patsy 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.29; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_trac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2497
https://github.com/scverse/scanpy/issues/2499:32,Availability,error,error,32,"Hi,; I am getting the following error when trying to plot my spatial data. ```py; with mpl.rc_context({'axes.facecolor': 'black',; 'figure.figsize': [4.5, 5]}):; ; sc.pl.spatial(slide, cmap='magma',; color=[""AC-like"", ""Astro"", ""B_T_NK"", ""Inhib.neurons"", ""Micro_Macro"", ""Neurons"", ""OC-like"", ""Oligo"", ""Pericyte""], ; ncols=3, size=1.3, ; img_key='hires',; # limit color scale at 99.2% quantile of cell abundance; vmin=0, vmax='p99.2' ; ); ```. ```pytb; TypeError Traceback (most recent call last); Cell In[11], line 14; 10 # plot in spatial coordinates; 11 with mpl.rc_context({'axes.facecolor': 'black',; 12 'figure.figsize': [4.5, 5]}):; ---> 14 sc.pl.spatial(slide, cmap='magma',; 15 # show first 8 cell types; 16 color=[""AC-like"", ""Astro"", ""B_T_NK"", ""Inhib.neurons"", ""Micro_Macro"", ""Neurons"", ""OC-like"", ""Oligo"", ""Pericyte""], ; 17 ncols=3, size=1.3, ; 18 img_key=None,; 19 # limit color scale at 99.2% quantile of cell abundance; 20 vmin=0, vmax='p99.2' ; 21 ). File ~/.local/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:993, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs); 990 cmap_img = None; 991 circle_radius = size * scale_factor * spot_size * 0.5; --> 993 axs = embedding(; 994 adata,; 995 basis=basis,; 996 scale_factor=scale_factor,; 997 size=circle_radius,; 998 na_color=na_color,; 999 show=False,; 1000 save=False,; 1001 **kwargs,; 1002 ); 1003 if not isinstance(axs, list):; 1004 axs = [axs]. File ~/.local/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:169, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, ou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2499
https://github.com/scverse/scanpy/issues/2500:1885,Deployability,update,updated,1885,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import anndata as ad; import scanpy as sc. adata = ad.AnnData(np.random.poisson(0.2, (100, 200))); sc.pp.normalize_per_cell(adata, 1e6); ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/scottgigante/envs/immunaISR/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 527, in normalize_per_cell; normalize_per_cell(adata.X, counts_per_cell_after, counts_per_cell); File ""/Users/scottgigante/envs/immunaISR/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 562, in normalize_per_cell; counts_per_cell /= counts_per_cell_after; numpy.core._exceptions.UFuncTypeError: Cannot cast ufunc 'divide' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'; ```. #### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; cffi 1.15.1; cloudpickle 2.2.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1; dill 0.3.6; google NA; h5py 3.8.0; importlib_resources NA; joblib 1.3.0.dev0; kiwisolver 1.4.4; llvmlite 0.40.0; matplotlib 3.7.1; mpl_toolkits NA; mpmath 1.3.0; natsort 8.3.1; numba 0.57.0; numpy 1.24.3; packaging 23.1; pandas 2.0.2; psutil 5.9.5; pyarrow 12.0.0; pyparsing 3.0.9; pytz 2023.3; scipy 1.10.1; session_info 1.0.0; six 1.16.0; sklearn 1.2.2; sympy 1.11.1; threadpoolctl 3.1.0; torch 2.0.0; tqdm 4.65.0; typing_extensions NA; yaml 6.0; zipp NA; -----; Python 3.8.10 (v3.8.10:3d8993a744, May 3 2021, 08:55:58) [Clang 6.0 (clang-600.0.57)]; macOS-10.16-x86_64-i386-64bit; -----; Session information updated at 2023-06-05 12:34; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2500
https://github.com/scverse/scanpy/issues/2501:307,Availability,down,downstream,307,"> . Hi, @jlause . There's a issue when using `normalize_pearson_residuals`, it seems that we can't calculated the `log2foldchange` in `rank_genes_groups` will be failed. That's because `np.expm1` can't restore the `adata.X` after `normalize_pearson_residuals`. Could you solve this issue that completed the downstream currently?. <img width=""770"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/46667721/a8e64ab1-360d-43a2-a07b-a766049bcbcd"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2501
https://github.com/scverse/scanpy/pull/2502:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2502
https://github.com/scverse/scanpy/pull/2502:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2502
https://github.com/scverse/scanpy/issues/2506:359,Availability,error,errors,359,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When trying to compute neighbors with default settings, I'm getting errors in slurm jobs, as the code tries to allocate all available cores on a node. I tried to control the number of cores available by setting `scanpy._settings.ScanpyConfig.n_jobs`, however I found that this setting does not get used in the offending function `compute_neighbors_umap`, where the following gets called. https://github.com/scverse/scanpy/blob/9cab8cfa4033d3f47a36c7bb816b2c9fae5cfdc6/scanpy/neighbors/__init__.py#L314-L322. The `nearest_neighbors` function from the `umap` provides the parameter `n_jobs`, which is set to -1 (i.e. all cores) by default. https://github.com/lmcinnes/umap/blob/e0cff20b392192f2b62fcc1843c9cb9ca2c9ee27/umap/umap_.py#L255-L266. However, as a user I would expect the number of cores to be defined by the ScanpyConfig.; I assume this could also cause the kernel dying unintentionally in other work setups when users aren't aware of the number of cores the function is requesting. ### Minimal code sample. ```python; import scanpy as sc; sc._settings.ScanpyConfig(n_jobs=1). ad = sc.read('quite_large_h5ad_file'); sc.pp.pca(ad); sc.pp.neighbors(ad); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:212, in Pool.__init__(self, processes, initializer, initargs, maxtasksperchild, context); 211 try:; --> 212 self._repopulate_pool(); 213 except Exception:. File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:303, in Pool._repopulate_pool(self); 302 def _repopulate_pool(self):; --> 303 return sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2506
https://github.com/scverse/scanpy/issues/2506:415,Availability,avail,available,415,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When trying to compute neighbors with default settings, I'm getting errors in slurm jobs, as the code tries to allocate all available cores on a node. I tried to control the number of cores available by setting `scanpy._settings.ScanpyConfig.n_jobs`, however I found that this setting does not get used in the offending function `compute_neighbors_umap`, where the following gets called. https://github.com/scverse/scanpy/blob/9cab8cfa4033d3f47a36c7bb816b2c9fae5cfdc6/scanpy/neighbors/__init__.py#L314-L322. The `nearest_neighbors` function from the `umap` provides the parameter `n_jobs`, which is set to -1 (i.e. all cores) by default. https://github.com/lmcinnes/umap/blob/e0cff20b392192f2b62fcc1843c9cb9ca2c9ee27/umap/umap_.py#L255-L266. However, as a user I would expect the number of cores to be defined by the ScanpyConfig.; I assume this could also cause the kernel dying unintentionally in other work setups when users aren't aware of the number of cores the function is requesting. ### Minimal code sample. ```python; import scanpy as sc; sc._settings.ScanpyConfig(n_jobs=1). ad = sc.read('quite_large_h5ad_file'); sc.pp.pca(ad); sc.pp.neighbors(ad); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:212, in Pool.__init__(self, processes, initializer, initargs, maxtasksperchild, context); 211 try:; --> 212 self._repopulate_pool(); 213 except Exception:. File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:303, in Pool._repopulate_pool(self); 302 def _repopulate_pool(self):; --> 303 return sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2506
https://github.com/scverse/scanpy/issues/2506:481,Availability,avail,available,481,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When trying to compute neighbors with default settings, I'm getting errors in slurm jobs, as the code tries to allocate all available cores on a node. I tried to control the number of cores available by setting `scanpy._settings.ScanpyConfig.n_jobs`, however I found that this setting does not get used in the offending function `compute_neighbors_umap`, where the following gets called. https://github.com/scverse/scanpy/blob/9cab8cfa4033d3f47a36c7bb816b2c9fae5cfdc6/scanpy/neighbors/__init__.py#L314-L322. The `nearest_neighbors` function from the `umap` provides the parameter `n_jobs`, which is set to -1 (i.e. all cores) by default. https://github.com/lmcinnes/umap/blob/e0cff20b392192f2b62fcc1843c9cb9ca2c9ee27/umap/umap_.py#L255-L266. However, as a user I would expect the number of cores to be defined by the ScanpyConfig.; I assume this could also cause the kernel dying unintentionally in other work setups when users aren't aware of the number of cores the function is requesting. ### Minimal code sample. ```python; import scanpy as sc; sc._settings.ScanpyConfig(n_jobs=1). ad = sc.read('quite_large_h5ad_file'); sc.pp.pca(ad); sc.pp.neighbors(ad); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:212, in Pool.__init__(self, processes, initializer, initargs, maxtasksperchild, context); 211 try:; --> 212 self._repopulate_pool(); 213 except Exception:. File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:303, in Pool._repopulate_pool(self); 302 def _repopulate_pool(self):; --> 303 return sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2506
https://github.com/scverse/scanpy/issues/2506:1461,Availability,Error,Error,1461,"number of cores available by setting `scanpy._settings.ScanpyConfig.n_jobs`, however I found that this setting does not get used in the offending function `compute_neighbors_umap`, where the following gets called. https://github.com/scverse/scanpy/blob/9cab8cfa4033d3f47a36c7bb816b2c9fae5cfdc6/scanpy/neighbors/__init__.py#L314-L322. The `nearest_neighbors` function from the `umap` provides the parameter `n_jobs`, which is set to -1 (i.e. all cores) by default. https://github.com/lmcinnes/umap/blob/e0cff20b392192f2b62fcc1843c9cb9ca2c9ee27/umap/umap_.py#L255-L266. However, as a user I would expect the number of cores to be defined by the ScanpyConfig.; I assume this could also cause the kernel dying unintentionally in other work setups when users aren't aware of the number of cores the function is requesting. ### Minimal code sample. ```python; import scanpy as sc; sc._settings.ScanpyConfig(n_jobs=1). ad = sc.read('quite_large_h5ad_file'); sc.pp.pca(ad); sc.pp.neighbors(ad); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:212, in Pool.__init__(self, processes, initializer, initargs, maxtasksperchild, context); 211 try:; --> 212 self._repopulate_pool(); 213 except Exception:. File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:303, in Pool._repopulate_pool(self); 302 def _repopulate_pool(self):; --> 303 return self._repopulate_pool_static(self._ctx, self.Process,; 304 self._processes,; 305 self._pool, self._inqueue,; 306 self._outqueue, self._initializer,; 307 self._initargs,; 308 self._maxtasksperchild,; 309 self._wrap_exception). File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:326, in Pool._repopulate_pool_static(ctx, Process, processes, pool, inqueue, outqueue, initializer, initargs, maxtasksperchild, wrap_exception); 325 w.daemon = True; -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2506
https://github.com/scverse/scanpy/issues/2506:402,Energy Efficiency,allocate,allocate,402,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When trying to compute neighbors with default settings, I'm getting errors in slurm jobs, as the code tries to allocate all available cores on a node. I tried to control the number of cores available by setting `scanpy._settings.ScanpyConfig.n_jobs`, however I found that this setting does not get used in the offending function `compute_neighbors_umap`, where the following gets called. https://github.com/scverse/scanpy/blob/9cab8cfa4033d3f47a36c7bb816b2c9fae5cfdc6/scanpy/neighbors/__init__.py#L314-L322. The `nearest_neighbors` function from the `umap` provides the parameter `n_jobs`, which is set to -1 (i.e. all cores) by default. https://github.com/lmcinnes/umap/blob/e0cff20b392192f2b62fcc1843c9cb9ca2c9ee27/umap/umap_.py#L255-L266. However, as a user I would expect the number of cores to be defined by the ScanpyConfig.; I assume this could also cause the kernel dying unintentionally in other work setups when users aren't aware of the number of cores the function is requesting. ### Minimal code sample. ```python; import scanpy as sc; sc._settings.ScanpyConfig(n_jobs=1). ad = sc.read('quite_large_h5ad_file'); sc.pp.pca(ad); sc.pp.neighbors(ad); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:212, in Pool.__init__(self, processes, initializer, initargs, maxtasksperchild, context); 211 try:; --> 212 self._repopulate_pool(); 213 except Exception:. File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:303, in Pool._repopulate_pool(self); 302 def _repopulate_pool(self):; --> 303 return sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2506
https://github.com/scverse/scanpy/issues/2506:8511,Energy Efficiency,Schedul,Schedule,8511,"erating = self._original_iterator is not None; 1088 while self.dispatch_one_batch(iterator):. File ~/tools/mambaforge/envs/scanpy/lib/python3.9/site-packages/joblib/parallel.py:901, in Parallel.dispatch_one_batch(self, iterator); 899 return False; 900 else:; --> 901 self._dispatch(tasks); 902 return True. File ~/tools/mambaforge/envs/scanpy/lib/python3.9/site-packages/joblib/parallel.py:819, in Parallel._dispatch(self, batch); 817 with self._lock:; 818 job_idx = len(self._jobs); --> 819 job = self._backend.apply_async(batch, callback=cb); 820 # A job can complete so quickly than its callback is; 821 # called before we get here, causing self._jobs to; 822 # grow. To ensure correct results ordering, .insert is; 823 # used (rather than .append) in the following line; 824 self._jobs.insert(job_idx, job). File ~/tools/mambaforge/envs/scanpy/lib/python3.9/site-packages/joblib/_parallel_backends.py:252, in PoolManagerMixin.apply_async(self, func, callback); 250 def apply_async(self, func, callback=None):; 251 """"""Schedule a func to be run""""""; --> 252 return self._get_pool().apply_async(; 253 SafeFunction(func), callback=callback). File ~/tools/mambaforge/envs/scanpy/lib/python3.9/site-packages/joblib/_parallel_backends.py:407, in ThreadingBackend._get_pool(self); 401 """"""Lazily initialize the thread pool; 402 ; 403 The actual pool of worker threads is only initialized at the first; 404 call to apply_async.; 405 """"""; 406 if self._pool is None:; --> 407 self._pool = ThreadPool(self._n_jobs); 408 return self._pool. File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:927, in ThreadPool.__init__(self, processes, initializer, initargs); 926 def __init__(self, processes=None, initializer=None, initargs=()):; --> 927 Pool.__init__(self, processes, initializer, initargs). File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:216, in Pool.__init__(self, processes, initializer, initargs, maxtasksperchild, context); 214 for p in self._pool:; 215 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2506
https://github.com/scverse/scanpy/issues/2506:8591,Safety,Safe,SafeFunction,8591,"aforge/envs/scanpy/lib/python3.9/site-packages/joblib/parallel.py:901, in Parallel.dispatch_one_batch(self, iterator); 899 return False; 900 else:; --> 901 self._dispatch(tasks); 902 return True. File ~/tools/mambaforge/envs/scanpy/lib/python3.9/site-packages/joblib/parallel.py:819, in Parallel._dispatch(self, batch); 817 with self._lock:; 818 job_idx = len(self._jobs); --> 819 job = self._backend.apply_async(batch, callback=cb); 820 # A job can complete so quickly than its callback is; 821 # called before we get here, causing self._jobs to; 822 # grow. To ensure correct results ordering, .insert is; 823 # used (rather than .append) in the following line; 824 self._jobs.insert(job_idx, job). File ~/tools/mambaforge/envs/scanpy/lib/python3.9/site-packages/joblib/_parallel_backends.py:252, in PoolManagerMixin.apply_async(self, func, callback); 250 def apply_async(self, func, callback=None):; 251 """"""Schedule a func to be run""""""; --> 252 return self._get_pool().apply_async(; 253 SafeFunction(func), callback=callback). File ~/tools/mambaforge/envs/scanpy/lib/python3.9/site-packages/joblib/_parallel_backends.py:407, in ThreadingBackend._get_pool(self); 401 """"""Lazily initialize the thread pool; 402 ; 403 The actual pool of worker threads is only initialized at the first; 404 call to apply_async.; 405 """"""; 406 if self._pool is None:; --> 407 self._pool = ThreadPool(self._n_jobs); 408 return self._pool. File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:927, in ThreadPool.__init__(self, processes, initializer, initargs); 926 def __init__(self, processes=None, initializer=None, initargs=()):; --> 927 Pool.__init__(self, processes, initializer, initargs). File ~/tools/mambaforge/envs/scanpy/lib/python3.9/multiprocessing/pool.py:216, in Pool.__init__(self, processes, initializer, initargs, maxtasksperchild, context); 214 for p in self._pool:; 215 if p.exitcode is None:; --> 216 p.terminate(); 217 for p in self._pool:; 218 p.join(). AttributeError: 'DummyPr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2506
https://github.com/scverse/scanpy/pull/2507:88,Usability,guid,guidelines,88,addresses #2506. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2507
https://github.com/scverse/scanpy/pull/2507:119,Usability,guid,guide,119,addresses #2506. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2507
https://github.com/scverse/scanpy/pull/2508:155,Usability,guid,guidelines,155,"Upon Numba compatibility with python3.11, scanpy is now compatible with python3.11. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2508
https://github.com/scverse/scanpy/pull/2508:186,Usability,guid,guide,186,"Upon Numba compatibility with python3.11, scanpy is now compatible with python3.11. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2508
https://github.com/scverse/scanpy/pull/2509:148,Usability,guid,guidelines,148,"Added examples for stacked violin plots, tracksplots and clustered heatmaps. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2509
https://github.com/scverse/scanpy/pull/2509:179,Usability,guid,guide,179,"Added examples for stacked violin plots, tracksplots and clustered heatmaps. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2509
https://github.com/scverse/scanpy/pull/2512:200,Availability,avail,available,200,"This PR is for #2444 . The project ""heatgraphy"" mentioned in the issue is renamed to ""Marsilea"", https://github.com/Marsilea-viz/marsilea. The previous link to the image mentioned in the issue is not available anymore. Please refer to [this link](https://marsilea.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html). I added a minimum example in the `external` part. Here is a code example of using the plotting function. Remember to install Marsilea before proceeding:. ```shell; pip install marsilea; ```. ```python; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); adata.var[""gene_names""] = adata.var.index. t = sc.external.pl.MarsileaHeatmap(adata, vmin=-2, vmax=2, center=0, label=""Expression""); t.add_right(""bulk_labels"", ""colors"", size=.2, label=""Cell Lables""); t.add_dendrogram(""right"", add_base=False, add_meta=True); t.h_groupby(""bulk_labels""); t.add_top(""n_counts"", ""bar"", show_value=False, label=""Counts""). genes = ['CDK6', 'UQCRFS1', 'SH2D2A', 'CD63', 'CEP152',; 'SIAH2', 'LY86', 'HSPB1', 'POLR2G', 'IGBP1']. t.add_bottom(""gene_names"", ""annot"", mark=genes); t.add_title(""Expression Heatmap""); t.legend(); t.show(); ```; If everything goes well, it should display something like this:. ![download](https://github.com/scverse/scanpy/assets/23433306/eb089061-b9ef-4d49-a2e0-fb3adcf06cd7)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2512
https://github.com/scverse/scanpy/pull/2512:1216,Availability,down,download,1216,"This PR is for #2444 . The project ""heatgraphy"" mentioned in the issue is renamed to ""Marsilea"", https://github.com/Marsilea-viz/marsilea. The previous link to the image mentioned in the issue is not available anymore. Please refer to [this link](https://marsilea.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html). I added a minimum example in the `external` part. Here is a code example of using the plotting function. Remember to install Marsilea before proceeding:. ```shell; pip install marsilea; ```. ```python; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); adata.var[""gene_names""] = adata.var.index. t = sc.external.pl.MarsileaHeatmap(adata, vmin=-2, vmax=2, center=0, label=""Expression""); t.add_right(""bulk_labels"", ""colors"", size=.2, label=""Cell Lables""); t.add_dendrogram(""right"", add_base=False, add_meta=True); t.h_groupby(""bulk_labels""); t.add_top(""n_counts"", ""bar"", show_value=False, label=""Counts""). genes = ['CDK6', 'UQCRFS1', 'SH2D2A', 'CD63', 'CEP152',; 'SIAH2', 'LY86', 'HSPB1', 'POLR2G', 'IGBP1']. t.add_bottom(""gene_names"", ""annot"", mark=genes); t.add_title(""Expression Heatmap""); t.legend(); t.show(); ```; If everything goes well, it should display something like this:. ![download](https://github.com/scverse/scanpy/assets/23433306/eb089061-b9ef-4d49-a2e0-fb3adcf06cd7)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2512
https://github.com/scverse/scanpy/pull/2512:439,Deployability,install,install,439,"This PR is for #2444 . The project ""heatgraphy"" mentioned in the issue is renamed to ""Marsilea"", https://github.com/Marsilea-viz/marsilea. The previous link to the image mentioned in the issue is not available anymore. Please refer to [this link](https://marsilea.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html). I added a minimum example in the `external` part. Here is a code example of using the plotting function. Remember to install Marsilea before proceeding:. ```shell; pip install marsilea; ```. ```python; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); adata.var[""gene_names""] = adata.var.index. t = sc.external.pl.MarsileaHeatmap(adata, vmin=-2, vmax=2, center=0, label=""Expression""); t.add_right(""bulk_labels"", ""colors"", size=.2, label=""Cell Lables""); t.add_dendrogram(""right"", add_base=False, add_meta=True); t.h_groupby(""bulk_labels""); t.add_top(""n_counts"", ""bar"", show_value=False, label=""Counts""). genes = ['CDK6', 'UQCRFS1', 'SH2D2A', 'CD63', 'CEP152',; 'SIAH2', 'LY86', 'HSPB1', 'POLR2G', 'IGBP1']. t.add_bottom(""gene_names"", ""annot"", mark=genes); t.add_title(""Expression Heatmap""); t.legend(); t.show(); ```; If everything goes well, it should display something like this:. ![download](https://github.com/scverse/scanpy/assets/23433306/eb089061-b9ef-4d49-a2e0-fb3adcf06cd7)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2512
https://github.com/scverse/scanpy/pull/2512:490,Deployability,install,install,490,"This PR is for #2444 . The project ""heatgraphy"" mentioned in the issue is renamed to ""Marsilea"", https://github.com/Marsilea-viz/marsilea. The previous link to the image mentioned in the issue is not available anymore. Please refer to [this link](https://marsilea.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html). I added a minimum example in the `external` part. Here is a code example of using the plotting function. Remember to install Marsilea before proceeding:. ```shell; pip install marsilea; ```. ```python; import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); adata.var[""gene_names""] = adata.var.index. t = sc.external.pl.MarsileaHeatmap(adata, vmin=-2, vmax=2, center=0, label=""Expression""); t.add_right(""bulk_labels"", ""colors"", size=.2, label=""Cell Lables""); t.add_dendrogram(""right"", add_base=False, add_meta=True); t.h_groupby(""bulk_labels""); t.add_top(""n_counts"", ""bar"", show_value=False, label=""Counts""). genes = ['CDK6', 'UQCRFS1', 'SH2D2A', 'CD63', 'CEP152',; 'SIAH2', 'LY86', 'HSPB1', 'POLR2G', 'IGBP1']. t.add_bottom(""gene_names"", ""annot"", mark=genes); t.add_title(""Expression Heatmap""); t.legend(); t.show(); ```; If everything goes well, it should display something like this:. ![download](https://github.com/scverse/scanpy/assets/23433306/eb089061-b9ef-4d49-a2e0-fb3adcf06cd7)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2512
https://github.com/scverse/scanpy/pull/2515:12,Testability,test,tests,12,Fix the dev tests. `square_distances` are not longer an argument in sklearn 1.3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2515
https://github.com/scverse/scanpy/pull/2518:87,Deployability,release,release,87,"So we cant forget adding them, thereby ensuring bugfixes make it into the next bugfix release (including CI fixes)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2518
https://github.com/scverse/scanpy/issues/2519:132,Safety,detect,detection,132,"Goals:. - flexibility in creation; - Neighbor querying API; - Harmonize storage of backends querying indices. 	- use it in doublet detection and scanorama reimplementations. Current solution: `method` arg. https://github.com/scverse/scanpy/blob/ed8e1401d39068782f2435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L32. - if `use_dense_distances`: [`sklearn.metrics.pairwise_distances`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html); - if `method == 'rapids'`: [`cuml.neighbors.NearestNeighbors`](https://docs.rapids.ai/api/cuml/stable/api/#cuml.neighbors.NearestNeighbors); - otherwise: [`umap.umap_.nearest_neighbors`](https://umap-learn.readthedocs.io/en/latest/api.html#umap.umap_.nearest_neighbors); - if `method == 'gauss'`: use umap distances, overwrite its connectivities. ## Evaluating options. See [ann-benchmarks.com](https://ann-benchmarks.com/index.html#datasets). Build time vs query time is not straightforward, see https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180389432 and https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180747770. > If, however, you are simply interested in knn-graph construction then you can get that from pynndescent in less time than even the index construction time (since the prepare phase isn't required, but is a non-trivial part of the index construction time). Plots for index building are on individual dataset pages, like [glove-100-angular](https://ann-benchmarks.com/glove-100-angular_10_angular.html). <details>; <summary>Used metrics</summary>. https://github.com/scverse/scanpy/blob/ed8e1401d39068782f2435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L35-L56. </details>. Interesting:. Name | Demo | wheels: Platforms | wheels: Python | Search speed | Index build; --- | --- | --- | --- | --- | ---; [NMSLIB](https://github.com/nmslib/nmslib) | [6 notebooks](https://github.com/nmslib/nmslib/blob/master/python_bindings/notebooks/README.md) | [Linux wheels](",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2519
https://github.com/scverse/scanpy/issues/2519:859,Testability,benchmark,benchmarks,859,"Goals:. - flexibility in creation; - Neighbor querying API; - Harmonize storage of backends querying indices. 	- use it in doublet detection and scanorama reimplementations. Current solution: `method` arg. https://github.com/scverse/scanpy/blob/ed8e1401d39068782f2435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L32. - if `use_dense_distances`: [`sklearn.metrics.pairwise_distances`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html); - if `method == 'rapids'`: [`cuml.neighbors.NearestNeighbors`](https://docs.rapids.ai/api/cuml/stable/api/#cuml.neighbors.NearestNeighbors); - otherwise: [`umap.umap_.nearest_neighbors`](https://umap-learn.readthedocs.io/en/latest/api.html#umap.umap_.nearest_neighbors); - if `method == 'gauss'`: use umap distances, overwrite its connectivities. ## Evaluating options. See [ann-benchmarks.com](https://ann-benchmarks.com/index.html#datasets). Build time vs query time is not straightforward, see https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180389432 and https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180747770. > If, however, you are simply interested in knn-graph construction then you can get that from pynndescent in less time than even the index construction time (since the prepare phase isn't required, but is a non-trivial part of the index construction time). Plots for index building are on individual dataset pages, like [glove-100-angular](https://ann-benchmarks.com/glove-100-angular_10_angular.html). <details>; <summary>Used metrics</summary>. https://github.com/scverse/scanpy/blob/ed8e1401d39068782f2435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L35-L56. </details>. Interesting:. Name | Demo | wheels: Platforms | wheels: Python | Search speed | Index build; --- | --- | --- | --- | --- | ---; [NMSLIB](https://github.com/nmslib/nmslib) | [6 notebooks](https://github.com/nmslib/nmslib/blob/master/python_bindings/notebooks/README.md) | [Linux wheels](",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2519
https://github.com/scverse/scanpy/issues/2519:887,Testability,benchmark,benchmarks,887,"Goals:. - flexibility in creation; - Neighbor querying API; - Harmonize storage of backends querying indices. 	- use it in doublet detection and scanorama reimplementations. Current solution: `method` arg. https://github.com/scverse/scanpy/blob/ed8e1401d39068782f2435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L32. - if `use_dense_distances`: [`sklearn.metrics.pairwise_distances`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html); - if `method == 'rapids'`: [`cuml.neighbors.NearestNeighbors`](https://docs.rapids.ai/api/cuml/stable/api/#cuml.neighbors.NearestNeighbors); - otherwise: [`umap.umap_.nearest_neighbors`](https://umap-learn.readthedocs.io/en/latest/api.html#umap.umap_.nearest_neighbors); - if `method == 'gauss'`: use umap distances, overwrite its connectivities. ## Evaluating options. See [ann-benchmarks.com](https://ann-benchmarks.com/index.html#datasets). Build time vs query time is not straightforward, see https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180389432 and https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180747770. > If, however, you are simply interested in knn-graph construction then you can get that from pynndescent in less time than even the index construction time (since the prepare phase isn't required, but is a non-trivial part of the index construction time). Plots for index building are on individual dataset pages, like [glove-100-angular](https://ann-benchmarks.com/glove-100-angular_10_angular.html). <details>; <summary>Used metrics</summary>. https://github.com/scverse/scanpy/blob/ed8e1401d39068782f2435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L35-L56. </details>. Interesting:. Name | Demo | wheels: Platforms | wheels: Python | Search speed | Index build; --- | --- | --- | --- | --- | ---; [NMSLIB](https://github.com/nmslib/nmslib) | [6 notebooks](https://github.com/nmslib/nmslib/blob/master/python_bindings/notebooks/README.md) | [Linux wheels](",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2519
https://github.com/scverse/scanpy/issues/2519:1009,Testability,benchmark,benchmarks,1009,"; - Neighbor querying API; - Harmonize storage of backends querying indices. 	- use it in doublet detection and scanorama reimplementations. Current solution: `method` arg. https://github.com/scverse/scanpy/blob/ed8e1401d39068782f2435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L32. - if `use_dense_distances`: [`sklearn.metrics.pairwise_distances`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html); - if `method == 'rapids'`: [`cuml.neighbors.NearestNeighbors`](https://docs.rapids.ai/api/cuml/stable/api/#cuml.neighbors.NearestNeighbors); - otherwise: [`umap.umap_.nearest_neighbors`](https://umap-learn.readthedocs.io/en/latest/api.html#umap.umap_.nearest_neighbors); - if `method == 'gauss'`: use umap distances, overwrite its connectivities. ## Evaluating options. See [ann-benchmarks.com](https://ann-benchmarks.com/index.html#datasets). Build time vs query time is not straightforward, see https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180389432 and https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180747770. > If, however, you are simply interested in knn-graph construction then you can get that from pynndescent in less time than even the index construction time (since the prepare phase isn't required, but is a non-trivial part of the index construction time). Plots for index building are on individual dataset pages, like [glove-100-angular](https://ann-benchmarks.com/glove-100-angular_10_angular.html). <details>; <summary>Used metrics</summary>. https://github.com/scverse/scanpy/blob/ed8e1401d39068782f2435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L35-L56. </details>. Interesting:. Name | Demo | wheels: Platforms | wheels: Python | Search speed | Index build; --- | --- | --- | --- | --- | ---; [NMSLIB](https://github.com/nmslib/nmslib) | [6 notebooks](https://github.com/nmslib/nmslib/blob/master/python_bindings/notebooks/README.md) | [Linux wheels](https://pypi.org/project/nmslib/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2519
https://github.com/scverse/scanpy/issues/2519:1091,Testability,benchmark,benchmarks,1091,"ices. 	- use it in doublet detection and scanorama reimplementations. Current solution: `method` arg. https://github.com/scverse/scanpy/blob/ed8e1401d39068782f2435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L32. - if `use_dense_distances`: [`sklearn.metrics.pairwise_distances`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html); - if `method == 'rapids'`: [`cuml.neighbors.NearestNeighbors`](https://docs.rapids.ai/api/cuml/stable/api/#cuml.neighbors.NearestNeighbors); - otherwise: [`umap.umap_.nearest_neighbors`](https://umap-learn.readthedocs.io/en/latest/api.html#umap.umap_.nearest_neighbors); - if `method == 'gauss'`: use umap distances, overwrite its connectivities. ## Evaluating options. See [ann-benchmarks.com](https://ann-benchmarks.com/index.html#datasets). Build time vs query time is not straightforward, see https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180389432 and https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180747770. > If, however, you are simply interested in knn-graph construction then you can get that from pynndescent in less time than even the index construction time (since the prepare phase isn't required, but is a non-trivial part of the index construction time). Plots for index building are on individual dataset pages, like [glove-100-angular](https://ann-benchmarks.com/glove-100-angular_10_angular.html). <details>; <summary>Used metrics</summary>. https://github.com/scverse/scanpy/blob/ed8e1401d39068782f2435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L35-L56. </details>. Interesting:. Name | Demo | wheels: Platforms | wheels: Python | Search speed | Index build; --- | --- | --- | --- | --- | ---; [NMSLIB](https://github.com/nmslib/nmslib) | [6 notebooks](https://github.com/nmslib/nmslib/blob/master/python_bindings/notebooks/README.md) | [Linux wheels](https://pypi.org/project/nmslib/2.1.1/#files) |[Outdated (3.9)](https://github.com/nmslib/nmslib/issues/5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2519
https://github.com/scverse/scanpy/issues/2519:1490,Testability,benchmark,benchmarks,1490,"etrics.pairwise_distances.html); - if `method == 'rapids'`: [`cuml.neighbors.NearestNeighbors`](https://docs.rapids.ai/api/cuml/stable/api/#cuml.neighbors.NearestNeighbors); - otherwise: [`umap.umap_.nearest_neighbors`](https://umap-learn.readthedocs.io/en/latest/api.html#umap.umap_.nearest_neighbors); - if `method == 'gauss'`: use umap distances, overwrite its connectivities. ## Evaluating options. See [ann-benchmarks.com](https://ann-benchmarks.com/index.html#datasets). Build time vs query time is not straightforward, see https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180389432 and https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180747770. > If, however, you are simply interested in knn-graph construction then you can get that from pynndescent in less time than even the index construction time (since the prepare phase isn't required, but is a non-trivial part of the index construction time). Plots for index building are on individual dataset pages, like [glove-100-angular](https://ann-benchmarks.com/glove-100-angular_10_angular.html). <details>; <summary>Used metrics</summary>. https://github.com/scverse/scanpy/blob/ed8e1401d39068782f2435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L35-L56. </details>. Interesting:. Name | Demo | wheels: Platforms | wheels: Python | Search speed | Index build; --- | --- | --- | --- | --- | ---; [NMSLIB](https://github.com/nmslib/nmslib) | [6 notebooks](https://github.com/nmslib/nmslib/blob/master/python_bindings/notebooks/README.md) | [Linux wheels](https://pypi.org/project/nmslib/2.1.1/#files) |[Outdated (3.9)](https://github.com/nmslib/nmslib/issues/529) | top | slow; [ScaNN](https://github.com/google-research/google-research/tree/master/scann#readme) | [notebook](https://github.com/google-research/google-research/blob/master/scann/docs/example.ipynb) | [All wheels](https://pypi.org/project/scann/1.2.9/#files) | [Slightly outdated (3.10)](https://github.com/google-research/google-resear",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2519
https://github.com/scverse/scanpy/issues/2519:403,Usability,learn,learn,403,"Goals:. - flexibility in creation; - Neighbor querying API; - Harmonize storage of backends querying indices. 	- use it in doublet detection and scanorama reimplementations. Current solution: `method` arg. https://github.com/scverse/scanpy/blob/ed8e1401d39068782f2435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L32. - if `use_dense_distances`: [`sklearn.metrics.pairwise_distances`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html); - if `method == 'rapids'`: [`cuml.neighbors.NearestNeighbors`](https://docs.rapids.ai/api/cuml/stable/api/#cuml.neighbors.NearestNeighbors); - otherwise: [`umap.umap_.nearest_neighbors`](https://umap-learn.readthedocs.io/en/latest/api.html#umap.umap_.nearest_neighbors); - if `method == 'gauss'`: use umap distances, overwrite its connectivities. ## Evaluating options. See [ann-benchmarks.com](https://ann-benchmarks.com/index.html#datasets). Build time vs query time is not straightforward, see https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180389432 and https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180747770. > If, however, you are simply interested in knn-graph construction then you can get that from pynndescent in less time than even the index construction time (since the prepare phase isn't required, but is a non-trivial part of the index construction time). Plots for index building are on individual dataset pages, like [glove-100-angular](https://ann-benchmarks.com/glove-100-angular_10_angular.html). <details>; <summary>Used metrics</summary>. https://github.com/scverse/scanpy/blob/ed8e1401d39068782f2435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L35-L56. </details>. Interesting:. Name | Demo | wheels: Platforms | wheels: Python | Search speed | Index build; --- | --- | --- | --- | --- | ---; [NMSLIB](https://github.com/nmslib/nmslib) | [6 notebooks](https://github.com/nmslib/nmslib/blob/master/python_bindings/notebooks/README.md) | [Linux wheels](",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2519
https://github.com/scverse/scanpy/issues/2519:680,Usability,learn,learn,680,"Goals:. - flexibility in creation; - Neighbor querying API; - Harmonize storage of backends querying indices. 	- use it in doublet detection and scanorama reimplementations. Current solution: `method` arg. https://github.com/scverse/scanpy/blob/ed8e1401d39068782f2435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L32. - if `use_dense_distances`: [`sklearn.metrics.pairwise_distances`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html); - if `method == 'rapids'`: [`cuml.neighbors.NearestNeighbors`](https://docs.rapids.ai/api/cuml/stable/api/#cuml.neighbors.NearestNeighbors); - otherwise: [`umap.umap_.nearest_neighbors`](https://umap-learn.readthedocs.io/en/latest/api.html#umap.umap_.nearest_neighbors); - if `method == 'gauss'`: use umap distances, overwrite its connectivities. ## Evaluating options. See [ann-benchmarks.com](https://ann-benchmarks.com/index.html#datasets). Build time vs query time is not straightforward, see https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180389432 and https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180747770. > If, however, you are simply interested in knn-graph construction then you can get that from pynndescent in less time than even the index construction time (since the prepare phase isn't required, but is a non-trivial part of the index construction time). Plots for index building are on individual dataset pages, like [glove-100-angular](https://ann-benchmarks.com/glove-100-angular_10_angular.html). <details>; <summary>Used metrics</summary>. https://github.com/scverse/scanpy/blob/ed8e1401d39068782f2435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L35-L56. </details>. Interesting:. Name | Demo | wheels: Platforms | wheels: Python | Search speed | Index build; --- | --- | --- | --- | --- | ---; [NMSLIB](https://github.com/nmslib/nmslib) | [6 notebooks](https://github.com/nmslib/nmslib/blob/master/python_bindings/notebooks/README.md) | [Linux wheels](",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2519
https://github.com/scverse/scanpy/issues/2519:1161,Usability,simpl,simply,1161,"435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L32. - if `use_dense_distances`: [`sklearn.metrics.pairwise_distances`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html); - if `method == 'rapids'`: [`cuml.neighbors.NearestNeighbors`](https://docs.rapids.ai/api/cuml/stable/api/#cuml.neighbors.NearestNeighbors); - otherwise: [`umap.umap_.nearest_neighbors`](https://umap-learn.readthedocs.io/en/latest/api.html#umap.umap_.nearest_neighbors); - if `method == 'gauss'`: use umap distances, overwrite its connectivities. ## Evaluating options. See [ann-benchmarks.com](https://ann-benchmarks.com/index.html#datasets). Build time vs query time is not straightforward, see https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180389432 and https://github.com/erikbern/ann-benchmarks/issues/207#issuecomment-1180747770. > If, however, you are simply interested in knn-graph construction then you can get that from pynndescent in less time than even the index construction time (since the prepare phase isn't required, but is a non-trivial part of the index construction time). Plots for index building are on individual dataset pages, like [glove-100-angular](https://ann-benchmarks.com/glove-100-angular_10_angular.html). <details>; <summary>Used metrics</summary>. https://github.com/scverse/scanpy/blob/ed8e1401d39068782f2435d258b33fce4f7b4a9e/scanpy/neighbors/__init__.py#L35-L56. </details>. Interesting:. Name | Demo | wheels: Platforms | wheels: Python | Search speed | Index build; --- | --- | --- | --- | --- | ---; [NMSLIB](https://github.com/nmslib/nmslib) | [6 notebooks](https://github.com/nmslib/nmslib/blob/master/python_bindings/notebooks/README.md) | [Linux wheels](https://pypi.org/project/nmslib/2.1.1/#files) |[Outdated (3.9)](https://github.com/nmslib/nmslib/issues/529) | top | slow; [ScaNN](https://github.com/google-research/google-research/tree/master/scann#readme) | [notebook](https://github.com/google-research/google-re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2519
https://github.com/scverse/scanpy/pull/2525:28,Testability,test,tests,28,Backport PR #2521: Fix paga tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2525
https://github.com/scverse/scanpy/issues/2526:427,Availability,avail,available,427,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. In #2235, more gradually enabled some so far disabled tests. Before, all tests in `TestPreprocessingDistributed` were disabled with the available optional dependencies we run our tests with:. https://github.com/scverse/scanpy/blob/06802b459648a219a10f74243efe4d6c2f912016/scanpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistribut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:944,Availability,Error,Error,944,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. In #2235, more gradually enabled some so far disabled tests. Before, all tests in `TestPreprocessingDistributed` were disabled with the available optional dependencies we run our tests with:. https://github.com/scverse/scanpy/blob/06802b459648a219a10f74243efe4d6c2f912016/scanpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistribut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:1774,Availability,FAILURE,FAILURES,1774,"imal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:2844,Availability,toler,tolerance,2844,"===========================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=0; E ; E Mismatched elements: 688287 / 9999000 (6.88%); E Max absolute difference: 573.4154; E Max relative difference: 11.335767; E x: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],...; E y: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],... scanpy/tests/test_preprocessing_distributed.py:64: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------------------; normalizing by total count per cell; filtered out dask.array<sum-aggregate, shape=(), dtype=int64, chunksize=(), chunktype=numpy.ndarray> cells that have less than 1 counts; finished (0:00:00): normalized adata.X and added 'n_counts', counts per cell before normalization (adata.obs); normalizing by total count per cell; filtered out 1 ce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:5720,Deployability,update,updated,5720,"s per cell before normalization (adata.obs); normalizing by total count per cell; filtered out 1 cells that have less than 1 counts; finished (0:00:00): normalized adata.X and added 'n_counts', counts per cell before normalization (adata.obs); =================================================================================================== short test summary info ====================================================================================================; FAILED scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] - AssertionError: ; ======================================================================================== 1 failed, 985 deselected, 11 warnings in 3.74s ========================================================================================; ```. ### Versions. <details>. ```; -----; anndata 0.9.0rc2.dev43+g21a76088; scanpy 1.10.0.dev117+g6b9e734f; -----; PIL 9.1.1; asciitree NA; awkward 2.2.1; awkward_cpp NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.2.1; cycler 0.10.0; cython_runtime NA; dask 2023.5.0; dateutil 2.8.2; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.17.3; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; importlib_resources NA; jinja2 3.1.2; joblib 1.1.0; kiwisolver 1.4.3; leidenalg 0.9.1; llvmlite 0.38.1; markupsafe 2.1.1; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.2; numcodecs 0.10.2; numpy 1.22.4; packaging 21.3; pandas 2.0.2; pkg_resources NA; psutil 5.9.1; pyparsing 3.0.9; pytz 2022.1; scipy 1.8.1; session_info 1.0.0; setuptools 67.8.0; setuptools_scm NA; six 1.16.0; sklearn 1.1.1; sphinxcontrib NA; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zarr 2.12.0; zipp NA; -----; Python 3.8.17 (default, Jun 17 2023, 20:09:37) [GCC 13.1.1 20230429]; Linux-6.3.8-zen1-1-zen-x86_64-with-glibc2.34; -----; Session information updated at 2023-06-23 14:29. ```; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:446,Integrability,depend,dependencies,446,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. In #2235, more gradually enabled some so far disabled tests. Before, all tests in `TestPreprocessingDistributed` were disabled with the available optional dependencies we run our tests with:. https://github.com/scverse/scanpy/blob/06802b459648a219a10f74243efe4d6c2f912016/scanpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistribut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:1384,Modifiability,config,configfile,1384,"l tests in `TestPreprocessingDistributed` were disabled with the available optional dependencies we run our tests with:. https://github.com/scverse/scanpy/blob/06802b459648a219a10f74243efe4d6c2f912016/scanpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs  n_va",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:1431,Modifiability,plugin,plugins,1431," available optional dependencies we run our tests with:. https://github.com/scverse/scanpy/blob/06802b459648a219a10f74243efe4d6c2f912016/scanpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:1308,Performance,cache,cachedir,1308,"ned?. In #2235, more gradually enabled some so far disabled tests. Before, all tests in `TestPreprocessingDistributed` were disabled with the available optional dependencies we run our tests with:. https://github.com/scverse/scanpy/blob/06802b459648a219a10f74243efe4d6c2f912016/scanpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs  n_vars = 9999  1000; o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:345,Testability,test,tests,345,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. In #2235, more gradually enabled some so far disabled tests. Before, all tests in `TestPreprocessingDistributed` were disabled with the available optional dependencies we run our tests with:. https://github.com/scverse/scanpy/blob/06802b459648a219a10f74243efe4d6c2f912016/scanpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistribut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:364,Testability,test,tests,364,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. In #2235, more gradually enabled some so far disabled tests. Before, all tests in `TestPreprocessingDistributed` were disabled with the available optional dependencies we run our tests with:. https://github.com/scverse/scanpy/blob/06802b459648a219a10f74243efe4d6c2f912016/scanpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistribut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:374,Testability,Test,TestPreprocessingDistributed,374,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. In #2235, more gradually enabled some so far disabled tests. Before, all tests in `TestPreprocessingDistributed` were disabled with the available optional dependencies we run our tests with:. https://github.com/scverse/scanpy/blob/06802b459648a219a10f74243efe4d6c2f912016/scanpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistribut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:470,Testability,test,tests,470,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. In #2235, more gradually enabled some so far disabled tests. Before, all tests in `TestPreprocessingDistributed` were disabled with the available optional dependencies we run our tests with:. https://github.com/scverse/scanpy/blob/06802b459648a219a10f74243efe4d6c2f912016/scanpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistribut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:570,Testability,test,tests,570,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. In #2235, more gradually enabled some so far disabled tests. Before, all tests in `TestPreprocessingDistributed` were disabled with the available optional dependencies we run our tests with:. https://github.com/scverse/scanpy/blob/06802b459648a219a10f74243efe4d6c2f912016/scanpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistribut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:633,Testability,test,tests,633,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. In #2235, more gradually enabled some so far disabled tests. Before, all tests in `TestPreprocessingDistributed` were disabled with the available optional dependencies we run our tests with:. https://github.com/scverse/scanpy/blob/06802b459648a219a10f74243efe4d6c2f912016/scanpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistribut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:670,Testability,test,tests,670,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. In #2235, more gradually enabled some so far disabled tests. Before, all tests in `TestPreprocessingDistributed` were disabled with the available optional dependencies we run our tests with:. https://github.com/scverse/scanpy/blob/06802b459648a219a10f74243efe4d6c2f912016/scanpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistribut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:778,Testability,test,tests,778,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. In #2235, more gradually enabled some so far disabled tests. Before, all tests in `TestPreprocessingDistributed` were disabled with the available optional dependencies we run our tests with:. https://github.com/scverse/scanpy/blob/06802b459648a219a10f74243efe4d6c2f912016/scanpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistribut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:1069,Testability,test,test,1069,"not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. In #2235, more gradually enabled some so far disabled tests. Before, all tests in `TestPreprocessingDistributed` were disabled with the available optional dependencies we run our tests with:. https://github.com/scverse/scanpy/blob/06802b459648a219a10f74243efe4d6c2f912016/scanpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] _______________________________________________________",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:1412,Testability,test,testpaths,1412," available optional dependencies we run our tests with:. https://github.com/scverse/scanpy/blob/06802b459648a219a10f74243efe4d6c2f912016/scanpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:1550,Testability,test,tests,1550,"canpy/tests/test_preprocessing_distributed.py#L15-L22. now, the dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken fo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:1591,Testability,Test,TestPreprocessingDistributed,1591,"e dask tests are enabled and only the zappy tests are disabled:. https://github.com/scverse/scanpy/blob/6b9e734f4979a8ba450c0eaa052451f98b000753/scanpy/tests/test_preprocessing_distributed.py#L18-L31. ### Minimal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materializ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:1975,Testability,Test,TestPreprocessingDistributed,1975,"imal code sample. ```bash; pytest -v --disable-warnings -k test_normalize_per_cell[dask] --runxfail; ```. ### Error output. ```pytb; ===================================================================================================== test session starts ======================================================================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:2133,Testability,test,tests,2133,"=======================================================; platform linux -- Python 3.8.17, pytest-7.3.1, pluggy-1.0.0 -- /home/phil/Dev/Python/venvs/single-cell/bin/python; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=0; E ; E Mismatched elements: 688287 / 9999000 (6.88%); E Max absolute difference: 573.4154; E Max relative difference: 11.335767; E x: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],...; E y: array([[0., 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:2170,Testability,Test,TestPreprocessingDistributed,2170,"ython; cachedir: .pytest_cache; rootdir: /home/phil/Dev/Python/Single Cell/scanpy; configfile: pyproject.toml; testpaths: scanpy; plugins: cov-4.1.0, nunit-1.0.3, memray-1.4.0, xdist-3.3.1; collected 986 items / 985 deselected / 1 selected . scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=0; E ; E Mismatched elements: 688287 / 9999000 (6.88%); E Max absolute difference: 573.4154; E Max relative difference: 11.335767; E x: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],...; E y: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],... scanpy/tests/test_preprocessing_distributed.py:64: AssertionError; ---",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:2551,Testability,Test,Test,2551,"tPreprocessingDistributed::test_normalize_per_cell[dask] FAILED [100%]. =========================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=0; E ; E Mismatched elements: 688287 / 9999000 (6.88%); E Max absolute difference: 573.4154; E Max relative difference: 11.335767; E x: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],...; E y: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],... scanpy/tests/test_preprocessing_distributed.py:64: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------------------; normalizing by total count per cell; filtered out dask.array<sum-aggre",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:2681,Testability,assert,assert,2681,"===================================================================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=0; E ; E Mismatched elements: 688287 / 9999000 (6.88%); E Max absolute difference: 573.4154; E Max relative difference: 11.335767; E x: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],...; E y: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],... scanpy/tests/test_preprocessing_distributed.py:64: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------------------; normalizing by total count per cell; filtered out dask.array<sum-aggregate, shape=(), dtype=int64, chunksize=(), chunktype=numpy.ndarray> cells that ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:2717,Testability,assert,assert,2717,"===================================================== FAILURES ===========================================================================================================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=0; E ; E Mismatched elements: 688287 / 9999000 (6.88%); E Max absolute difference: 573.4154; E Max relative difference: 11.335767; E x: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],...; E y: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],... scanpy/tests/test_preprocessing_distributed.py:64: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------------------; normalizing by total count per cell; filtered out dask.array<sum-aggregate, shape=(), dtype=int64, chunksize=(), chunktype=numpy.ndarray> cells that have less than 1 counts; finished (0:00:00): nor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:2811,Testability,Assert,AssertionError,2811,"===========================; __________________________________________________________________________________ TestPreprocessingDistributed.test_normalize_per_cell[dask] __________________________________________________________________________________. self = <scanpy.tests.test_preprocessing_distributed.TestPreprocessingDistributed object at 0x7fdd21f2e9d0>, adata = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=0; E ; E Mismatched elements: 688287 / 9999000 (6.88%); E Max absolute difference: 573.4154; E Max relative difference: 11.335767; E x: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],...; E y: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],... scanpy/tests/test_preprocessing_distributed.py:64: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------------------; normalizing by total count per cell; filtered out dask.array<sum-aggregate, shape=(), dtype=int64, chunksize=(), chunktype=numpy.ndarray> cells that have less than 1 counts; finished (0:00:00): normalized adata.X and added 'n_counts', counts per cell before normalization (adata.obs); normalizing by total count per cell; filtered out 1 ce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:3238,Testability,test,tests,3238,"h n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; adata_dist = AnnData object with n_obs  n_vars = 9999  1000; obs: 'n_counts'; var: 'gene_ids'; uns: 'dist-mode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=0; E ; E Mismatched elements: 688287 / 9999000 (6.88%); E Max absolute difference: 573.4154; E Max relative difference: 11.335767; E x: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],...; E y: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],... scanpy/tests/test_preprocessing_distributed.py:64: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------------------; normalizing by total count per cell; filtered out dask.array<sum-aggregate, shape=(), dtype=int64, chunksize=(), chunktype=numpy.ndarray> cells that have less than 1 counts; finished (0:00:00): normalized adata.X and added 'n_counts', counts per cell before normalization (adata.obs); normalizing by total count per cell; filtered out 1 cells that have less than 1 counts; finished (0:00:00): normalized adata.X and added 'n_counts', counts per cell before normalization (adata.obs); =================================================================================================== short test summary info ====================================================================================================; FAILED scanpy/tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:3282,Testability,Assert,AssertionError,3282,"ode'. def test_normalize_per_cell(self, adata, adata_dist):; if adata_dist.uns[""dist-mode""] == ""dask"":; pytest.xfail(""TODO: Test broken for dask""); normalize_per_cell(adata_dist); result = materialize_as_ndarray(adata_dist.X); normalize_per_cell(adata); assert result.shape == adata.shape; assert result.shape == (adata.n_obs, adata.n_vars); > npt.assert_allclose(result, adata.X); E AssertionError: ; E Not equal to tolerance rtol=1e-07, atol=0; E ; E Mismatched elements: 688287 / 9999000 (6.88%); E Max absolute difference: 573.4154; E Max relative difference: 11.335767; E x: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],...; E y: array([[0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],... scanpy/tests/test_preprocessing_distributed.py:64: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------------------; normalizing by total count per cell; filtered out dask.array<sum-aggregate, shape=(), dtype=int64, chunksize=(), chunktype=numpy.ndarray> cells that have less than 1 counts; finished (0:00:00): normalized adata.X and added 'n_counts', counts per cell before normalization (adata.obs); normalizing by total count per cell; filtered out 1 cells that have less than 1 counts; finished (0:00:00): normalized adata.X and added 'n_counts', counts per cell before normalization (adata.obs); =================================================================================================== short test summary info ====================================================================================================; FAILED scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] - AssertionError: ; ==========================================================",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:4114,Testability,test,test,4114,".., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],... scanpy/tests/test_preprocessing_distributed.py:64: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------------------; normalizing by total count per cell; filtered out dask.array<sum-aggregate, shape=(), dtype=int64, chunksize=(), chunktype=numpy.ndarray> cells that have less than 1 counts; finished (0:00:00): normalized adata.X and added 'n_counts', counts per cell before normalization (adata.obs); normalizing by total count per cell; filtered out 1 cells that have less than 1 counts; finished (0:00:00): normalized adata.X and added 'n_counts', counts per cell before normalization (adata.obs); =================================================================================================== short test summary info ====================================================================================================; FAILED scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] - AssertionError: ; ======================================================================================== 1 failed, 985 deselected, 11 warnings in 3.74s ========================================================================================; ```. ### Versions. <details>. ```; -----; anndata 0.9.0rc2.dev43+g21a76088; scanpy 1.10.0.dev117+g6b9e734f; -----; PIL 9.1.1; asciitree NA; awkward 2.2.1; awkward_cpp NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.2.1; cycler 0.10.0; cython_runtime NA; dask 2023.5.0; dateutil 2.8.2; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.17.3; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; importlib_resources NA; jinja2 3.1.2; joblib 1.1.0; kiwisolver 1.4.3; leidenalg 0.9.1; llvmlite 0.38.1; markupsafe 2.1.1; matplotlib 3.7.1; mpl_toolki",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:4248,Testability,test,tests,4248,".., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],; E [0., 0., 0., ..., 0., 0., 0.],... scanpy/tests/test_preprocessing_distributed.py:64: AssertionError; ----------------------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------------------; normalizing by total count per cell; filtered out dask.array<sum-aggregate, shape=(), dtype=int64, chunksize=(), chunktype=numpy.ndarray> cells that have less than 1 counts; finished (0:00:00): normalized adata.X and added 'n_counts', counts per cell before normalization (adata.obs); normalizing by total count per cell; filtered out 1 cells that have less than 1 counts; finished (0:00:00): normalized adata.X and added 'n_counts', counts per cell before normalization (adata.obs); =================================================================================================== short test summary info ====================================================================================================; FAILED scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] - AssertionError: ; ======================================================================================== 1 failed, 985 deselected, 11 warnings in 3.74s ========================================================================================; ```. ### Versions. <details>. ```; -----; anndata 0.9.0rc2.dev43+g21a76088; scanpy 1.10.0.dev117+g6b9e734f; -----; PIL 9.1.1; asciitree NA; awkward 2.2.1; awkward_cpp NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.2.1; cycler 0.10.0; cython_runtime NA; dask 2023.5.0; dateutil 2.8.2; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.17.3; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; importlib_resources NA; jinja2 3.1.2; joblib 1.1.0; kiwisolver 1.4.3; leidenalg 0.9.1; llvmlite 0.38.1; markupsafe 2.1.1; matplotlib 3.7.1; mpl_toolki",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:4289,Testability,Test,TestPreprocessingDistributed,4289,"------ Captured stderr call -----------------------------------------------------------------------------------------------------; normalizing by total count per cell; filtered out dask.array<sum-aggregate, shape=(), dtype=int64, chunksize=(), chunktype=numpy.ndarray> cells that have less than 1 counts; finished (0:00:00): normalized adata.X and added 'n_counts', counts per cell before normalization (adata.obs); normalizing by total count per cell; filtered out 1 cells that have less than 1 counts; finished (0:00:00): normalized adata.X and added 'n_counts', counts per cell before normalization (adata.obs); =================================================================================================== short test summary info ====================================================================================================; FAILED scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] - AssertionError: ; ======================================================================================== 1 failed, 985 deselected, 11 warnings in 3.74s ========================================================================================; ```. ### Versions. <details>. ```; -----; anndata 0.9.0rc2.dev43+g21a76088; scanpy 1.10.0.dev117+g6b9e734f; -----; PIL 9.1.1; asciitree NA; awkward 2.2.1; awkward_cpp NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.2.1; cycler 0.10.0; cython_runtime NA; dask 2023.5.0; dateutil 2.8.2; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.17.3; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; importlib_resources NA; jinja2 3.1.2; joblib 1.1.0; kiwisolver 1.4.3; leidenalg 0.9.1; llvmlite 0.38.1; markupsafe 2.1.1; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.2; numcodecs 0.10.2; numpy 1.22.4; packaging 21.3; pandas 2.0.2; pkg_resources NA; psutil 5.9.1; pyparsing 3.0.9; pytz 2022.1; scipy 1.8.1; session_info 1.0.0; setuptools 67.8.0; setuptools_scm NA; s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/issues/2526:4351,Testability,Assert,AssertionError,4351,"------ Captured stderr call -----------------------------------------------------------------------------------------------------; normalizing by total count per cell; filtered out dask.array<sum-aggregate, shape=(), dtype=int64, chunksize=(), chunktype=numpy.ndarray> cells that have less than 1 counts; finished (0:00:00): normalized adata.X and added 'n_counts', counts per cell before normalization (adata.obs); normalizing by total count per cell; filtered out 1 cells that have less than 1 counts; finished (0:00:00): normalized adata.X and added 'n_counts', counts per cell before normalization (adata.obs); =================================================================================================== short test summary info ====================================================================================================; FAILED scanpy/tests/test_preprocessing_distributed.py::TestPreprocessingDistributed::test_normalize_per_cell[dask] - AssertionError: ; ======================================================================================== 1 failed, 985 deselected, 11 warnings in 3.74s ========================================================================================; ```. ### Versions. <details>. ```; -----; anndata 0.9.0rc2.dev43+g21a76088; scanpy 1.10.0.dev117+g6b9e734f; -----; PIL 9.1.1; asciitree NA; awkward 2.2.1; awkward_cpp NA; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cloudpickle 2.2.1; cycler 0.10.0; cython_runtime NA; dask 2023.5.0; dateutil 2.8.2; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.17.3; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; importlib_resources NA; jinja2 3.1.2; joblib 1.1.0; kiwisolver 1.4.3; leidenalg 0.9.1; llvmlite 0.38.1; markupsafe 2.1.1; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.2; numcodecs 0.10.2; numpy 1.22.4; packaging 21.3; pandas 2.0.2; pkg_resources NA; psutil 5.9.1; pyparsing 3.0.9; pytz 2022.1; scipy 1.8.1; session_info 1.0.0; setuptools 67.8.0; setuptools_scm NA; s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2526
https://github.com/scverse/scanpy/pull/2527:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2527
https://github.com/scverse/scanpy/pull/2527:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2527
https://github.com/scverse/scanpy/pull/2528:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2528
https://github.com/scverse/scanpy/pull/2528:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2528
https://github.com/scverse/scanpy/pull/2529:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2529
https://github.com/scverse/scanpy/pull/2529:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2529
https://github.com/scverse/scanpy/issues/2531:1820,Availability,Error,Error,1820,"1. Here is the output from the header logger:. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.24.3 scipy==1.9.1 pandas==2.0.2 scikit-learn==1.2.2 statsmodels==0.14.0 python-igraph==0.10.4 louvain==0.8.0 pynndescent==0.5.10. ### Minimal code sample. ```python; #Follow the same as the tutorial, or as a minimum example:. import numpy as np; import pandas as pd; import scanpy as sc. adata = sc.datasets.pbmc3k(); adata.var_names_make_unique() ; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); adata.var['mt'] = adata.var_names.str.startswith('MT-'); sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); adata = adata[adata.obs.n_genes_by_counts < 2500, :]; adata = adata[adata.obs.pct_counts_mt < 5, :]; sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); sc.tl.pca(adata, svd_solver='arpack'); ```. ### Error output; No error output, it just hangs; ```pytb. ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; CoreFoundation NA; Foundation NA; PIL 9.5.0; PyObjCTools NA; anyio NA; appnope 0.1.3; argcomplete NA; asttokens NA; attr 23.1.0; babel 2.12.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2023.05.07; cffi 1.15.1; charset_normalizer 3.1.0; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; fastjsonschema NA; google NA; h5py 3.9.0; hypergeom_ufunc NA; idna 3.4; igraph 0.10.4; importlib_resources NA; ipykernel 6.23.2; ipython_genutils 0.2.0; ipywidgets 8.0.6; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.6.0; jupyterlab_server 2.23.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; louvain 0.8.0; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.4.0; nb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531
https://github.com/scverse/scanpy/issues/2531:1837,Availability,error,error,1837,"1. Here is the output from the header logger:. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.24.3 scipy==1.9.1 pandas==2.0.2 scikit-learn==1.2.2 statsmodels==0.14.0 python-igraph==0.10.4 louvain==0.8.0 pynndescent==0.5.10. ### Minimal code sample. ```python; #Follow the same as the tutorial, or as a minimum example:. import numpy as np; import pandas as pd; import scanpy as sc. adata = sc.datasets.pbmc3k(); adata.var_names_make_unique() ; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); adata.var['mt'] = adata.var_names.str.startswith('MT-'); sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); adata = adata[adata.obs.n_genes_by_counts < 2500, :]; adata = adata[adata.obs.pct_counts_mt < 5, :]; sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); sc.tl.pca(adata, svd_solver='arpack'); ```. ### Error output; No error output, it just hangs; ```pytb. ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; CoreFoundation NA; Foundation NA; PIL 9.5.0; PyObjCTools NA; anyio NA; appnope 0.1.3; argcomplete NA; asttokens NA; attr 23.1.0; babel 2.12.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2023.05.07; cffi 1.15.1; charset_normalizer 3.1.0; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; fastjsonschema NA; google NA; h5py 3.9.0; hypergeom_ufunc NA; idna 3.4; igraph 0.10.4; importlib_resources NA; ipykernel 6.23.2; ipython_genutils 0.2.0; ipywidgets 8.0.6; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.6.0; jupyterlab_server 2.23.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; louvain 0.8.0; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.4.0; nb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531
https://github.com/scverse/scanpy/issues/2531:4067,Deployability,update,updated,4067," beta_ufunc NA; binom_ufunc NA; certifi 2023.05.07; cffi 1.15.1; charset_normalizer 3.1.0; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; fastjsonschema NA; google NA; h5py 3.9.0; hypergeom_ufunc NA; idna 3.4; igraph 0.10.4; importlib_resources NA; ipykernel 6.23.2; ipython_genutils 0.2.0; ipywidgets 8.0.6; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.6.0; jupyterlab_server 2.23.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; louvain 0.8.0; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.4.0; nbformat 5.9.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.57.0; numexpr 2.8.4; numpy 1.24.3; objc 9.2; overrides NA; packaging 23.1; pandas 2.0.2; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.6.0; prometheus_client NA; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.1.0; pyrsistent NA; pythonjsonlogger NA; pytz 2023.3; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; scipy 1.9.1; send2trash NA; session_info 1.0.0; setuptools 68.0.0; six 1.16.0; sklearn 1.2.2; sniffio 1.3.0; socks 1.7.1; stack_data 0.6.2; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; torch 1.12.1; tornado 6.3.2; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; urllib3 2.0.3; wcwidth 0.2.6; websocket 1.6.0; yaml 6.0; zipp NA; zmq 25.1.0; zoneinfo NA; -----; IPython 8.14.0; jupyter_client 8.2.0; jupyter_core 5.3.1; jupyterlab 4.0.2; notebook 6.5.4; -----; Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:42:20) [Clang 14.0.6 ]; macOS-12.6.6-x86_64-i386-64bit; -----; Session information updated at 2023-06-23 18:00. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531
https://github.com/scverse/scanpy/issues/2531:882,Testability,log,logger,882,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I just made a new environment with the latest version of scanpy (1.9.3), and was trying to run some basic analysis and the pca function is hanging and taking forever, when it used to be basically instantaneous. I tried reproducing it with the the simple tutorial and it is still hanging when I try to run PCA (takes longer than 10 minutes on the simple example dataset in the tutorial, I eventually just have to kill the process). . Not sure at all what the issue is, but wanted to bring it to your attention. This does not happen when using scanpy 1.9.1. Here is the output from the header logger:. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.24.3 scipy==1.9.1 pandas==2.0.2 scikit-learn==1.2.2 statsmodels==0.14.0 python-igraph==0.10.4 louvain==0.8.0 pynndescent==0.5.10. ### Minimal code sample. ```python; #Follow the same as the tutorial, or as a minimum example:. import numpy as np; import pandas as pd; import scanpy as sc. adata = sc.datasets.pbmc3k(); adata.var_names_make_unique() ; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); adata.var['mt'] = adata.var_names.str.startswith('MT-'); sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); adata = adata[adata.obs.n_genes_by_counts < 2500, :]; adata = adata[adata.obs.pct_counts_mt < 5, :]; sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); sc.tl.pca(adata, svd_solver='arpack'); ```. ### Error output; No error output, it just hangs; ```pytb. ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; CoreFoundation NA; Foundation NA; PIL 9.5.0; PyO",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531
https://github.com/scverse/scanpy/issues/2531:538,Usability,simpl,simple,538,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I just made a new environment with the latest version of scanpy (1.9.3), and was trying to run some basic analysis and the pca function is hanging and taking forever, when it used to be basically instantaneous. I tried reproducing it with the the simple tutorial and it is still hanging when I try to run PCA (takes longer than 10 minutes on the simple example dataset in the tutorial, I eventually just have to kill the process). . Not sure at all what the issue is, but wanted to bring it to your attention. This does not happen when using scanpy 1.9.1. Here is the output from the header logger:. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.24.3 scipy==1.9.1 pandas==2.0.2 scikit-learn==1.2.2 statsmodels==0.14.0 python-igraph==0.10.4 louvain==0.8.0 pynndescent==0.5.10. ### Minimal code sample. ```python; #Follow the same as the tutorial, or as a minimum example:. import numpy as np; import pandas as pd; import scanpy as sc. adata = sc.datasets.pbmc3k(); adata.var_names_make_unique() ; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); adata.var['mt'] = adata.var_names.str.startswith('MT-'); sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); adata = adata[adata.obs.n_genes_by_counts < 2500, :]; adata = adata[adata.obs.pct_counts_mt < 5, :]; sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); sc.tl.pca(adata, svd_solver='arpack'); ```. ### Error output; No error output, it just hangs; ```pytb. ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; CoreFoundation NA; Foundation NA; PIL 9.5.0; PyO",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531
https://github.com/scverse/scanpy/issues/2531:637,Usability,simpl,simple,637,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I just made a new environment with the latest version of scanpy (1.9.3), and was trying to run some basic analysis and the pca function is hanging and taking forever, when it used to be basically instantaneous. I tried reproducing it with the the simple tutorial and it is still hanging when I try to run PCA (takes longer than 10 minutes on the simple example dataset in the tutorial, I eventually just have to kill the process). . Not sure at all what the issue is, but wanted to bring it to your attention. This does not happen when using scanpy 1.9.1. Here is the output from the header logger:. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.24.3 scipy==1.9.1 pandas==2.0.2 scikit-learn==1.2.2 statsmodels==0.14.0 python-igraph==0.10.4 louvain==0.8.0 pynndescent==0.5.10. ### Minimal code sample. ```python; #Follow the same as the tutorial, or as a minimum example:. import numpy as np; import pandas as pd; import scanpy as sc. adata = sc.datasets.pbmc3k(); adata.var_names_make_unique() ; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); adata.var['mt'] = adata.var_names.str.startswith('MT-'); sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); adata = adata[adata.obs.n_genes_by_counts < 2500, :]; adata = adata[adata.obs.pct_counts_mt < 5, :]; sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); sc.tl.pca(adata, svd_solver='arpack'); ```. ### Error output; No error output, it just hangs; ```pytb. ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; CoreFoundation NA; Foundation NA; PIL 9.5.0; PyO",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531
https://github.com/scverse/scanpy/issues/2531:980,Usability,learn,learn,980,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I just made a new environment with the latest version of scanpy (1.9.3), and was trying to run some basic analysis and the pca function is hanging and taking forever, when it used to be basically instantaneous. I tried reproducing it with the the simple tutorial and it is still hanging when I try to run PCA (takes longer than 10 minutes on the simple example dataset in the tutorial, I eventually just have to kill the process). . Not sure at all what the issue is, but wanted to bring it to your attention. This does not happen when using scanpy 1.9.1. Here is the output from the header logger:. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.24.3 scipy==1.9.1 pandas==2.0.2 scikit-learn==1.2.2 statsmodels==0.14.0 python-igraph==0.10.4 louvain==0.8.0 pynndescent==0.5.10. ### Minimal code sample. ```python; #Follow the same as the tutorial, or as a minimum example:. import numpy as np; import pandas as pd; import scanpy as sc. adata = sc.datasets.pbmc3k(); adata.var_names_make_unique() ; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); adata.var['mt'] = adata.var_names.str.startswith('MT-'); sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); adata = adata[adata.obs.n_genes_by_counts < 2500, :]; adata = adata[adata.obs.pct_counts_mt < 5, :]; sc.pp.normalize_total(adata, target_sum=1e4); sc.pp.log1p(adata); sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5); sc.tl.pca(adata, svd_solver='arpack'); ```. ### Error output; No error output, it just hangs; ```pytb. ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; CoreFoundation NA; Foundation NA; PIL 9.5.0; PyO",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2531
https://github.com/scverse/scanpy/pull/2535:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.272  v0.0.275](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.272...v0.0.275); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2535
https://github.com/scverse/scanpy/pull/2536:1890,Availability,mask,mask,1890," more predictability at the expense of backwards compatibility*? Especially the euclidean condition makes not much sense IMHO; - Another piece of weird logic: *Where to allow`knn=False`*? It would make sense for e.g. the scipy knn transformer with `algorithm='kd_tree'`  ; https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L614-L617; - I also changed `method` to only mean connectivity method. `transformer_cls` alone now determines how to calculate distances. ### TODO. - [x] split of sklearn-ann part into own issue/PR; - [x] figure out what the `_more_tags` methods are ; - [x] allow specifying algorithm and/or backend; - [x] revert 75c6670, move connectivities code out of backends; - [x] switch our stuff to KNeighborsTransformer; - [x] unify selection: algorithm+backend, metric, connectivity (maybe separate out connectivity); - [x] figure out how to do connectivities: can mode be changed after fit? *no, we just use umap connectivities as before*; - [x] check out where we have coverage; - is there paga specific stuff? *not in the parts I changed*; - gauss: dense matrix when knn=True (build a symmetric mask, ) *not covered, but also the logic shouldnt have changed*; - pre-computed in umap transformer; handling of disconnected components in umap (indices == -1) *replaced with our own implementation, see below*; - add tests; - [x] pyknndescent (we already depend on it through umap). Maybe in another PR?. - [ ] maybe store index in unified way?; - [ ] for umap: use `UMAP(precomputed_knn=...)` instead of `compute_connectivities`?; - [ ] unifiy transformer args, e.g. verbose. ## Implementation. ### The way it used to be. Our default use case was basically a thin wrapper around umaps `nearest_neighbors` function, which in turn is a thin wrapper around PyNNDescent. We did some special casing around euclidean distance and small data sizes. That special casing reduced our test coverage: . - we dont actually tes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:2658,Energy Efficiency,reduce,reduced,2658,"be changed after fit? *no, we just use umap connectivities as before*; - [x] check out where we have coverage; - is there paga specific stuff? *not in the parts I changed*; - gauss: dense matrix when knn=True (build a symmetric mask, ) *not covered, but also the logic shouldnt have changed*; - pre-computed in umap transformer; handling of disconnected components in umap (indices == -1) *replaced with our own implementation, see below*; - add tests; - [x] pyknndescent (we already depend on it through umap). Maybe in another PR?. - [ ] maybe store index in unified way?; - [ ] for umap: use `UMAP(precomputed_knn=...)` instead of `compute_connectivities`?; - [ ] unifiy transformer args, e.g. verbose. ## Implementation. ### The way it used to be. Our default use case was basically a thin wrapper around umaps `nearest_neighbors` function, which in turn is a thin wrapper around PyNNDescent. We did some special casing around euclidean distance and small data sizes. That special casing reduced our test coverage: . - we dont actually test umaps pynndescent codepath at all (just the fast `precomputed` path for small data); - umaps `precomputed` code does some weird things to its knn `indices` array, which we dont test for: ; ![grafik](https://github.com/scverse/scanpy/assets/291575/7f36cafe-98fb-48cc-9e35-3972fad65a3e). The logic was:. - if small data (<8000) and euclidean metric or knn==False, calculate `pairwise_distances`; - if knn=True, then sparsify that matrix by pulling out KNN using `_get_indices_distances_from_dense_matrix` and converting that into a sparse one; - if not, run `umap.nearest_neighbors`.; - if even smaller data (<4000), calculate `pairwise_distances` like above and run `umap.nearest_neighbors` with `metric='precomputed'`. its internal logic then does the same as `_get_indices_distances_from_dense_matrix`; - else run `umap.nearest_neighbors` directly, which simply runs PyNNDescent with `n_trees` and `n_iters` set with a heuristic. ### now the logi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:2149,Integrability,depend,depend,2149," more predictability at the expense of backwards compatibility*? Especially the euclidean condition makes not much sense IMHO; - Another piece of weird logic: *Where to allow`knn=False`*? It would make sense for e.g. the scipy knn transformer with `algorithm='kd_tree'`  ; https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L614-L617; - I also changed `method` to only mean connectivity method. `transformer_cls` alone now determines how to calculate distances. ### TODO. - [x] split of sklearn-ann part into own issue/PR; - [x] figure out what the `_more_tags` methods are ; - [x] allow specifying algorithm and/or backend; - [x] revert 75c6670, move connectivities code out of backends; - [x] switch our stuff to KNeighborsTransformer; - [x] unify selection: algorithm+backend, metric, connectivity (maybe separate out connectivity); - [x] figure out how to do connectivities: can mode be changed after fit? *no, we just use umap connectivities as before*; - [x] check out where we have coverage; - is there paga specific stuff? *not in the parts I changed*; - gauss: dense matrix when knn=True (build a symmetric mask, ) *not covered, but also the logic shouldnt have changed*; - pre-computed in umap transformer; handling of disconnected components in umap (indices == -1) *replaced with our own implementation, see below*; - add tests; - [x] pyknndescent (we already depend on it through umap). Maybe in another PR?. - [ ] maybe store index in unified way?; - [ ] for umap: use `UMAP(precomputed_knn=...)` instead of `compute_connectivities`?; - [ ] unifiy transformer args, e.g. verbose. ## Implementation. ### The way it used to be. Our default use case was basically a thin wrapper around umaps `nearest_neighbors` function, which in turn is a thin wrapper around PyNNDescent. We did some special casing around euclidean distance and small data sizes. That special casing reduced our test coverage: . - we dont actually tes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:2459,Integrability,wrap,wrapper,2459,"NeighborsTransformer; - [x] unify selection: algorithm+backend, metric, connectivity (maybe separate out connectivity); - [x] figure out how to do connectivities: can mode be changed after fit? *no, we just use umap connectivities as before*; - [x] check out where we have coverage; - is there paga specific stuff? *not in the parts I changed*; - gauss: dense matrix when knn=True (build a symmetric mask, ) *not covered, but also the logic shouldnt have changed*; - pre-computed in umap transformer; handling of disconnected components in umap (indices == -1) *replaced with our own implementation, see below*; - add tests; - [x] pyknndescent (we already depend on it through umap). Maybe in another PR?. - [ ] maybe store index in unified way?; - [ ] for umap: use `UMAP(precomputed_knn=...)` instead of `compute_connectivities`?; - [ ] unifiy transformer args, e.g. verbose. ## Implementation. ### The way it used to be. Our default use case was basically a thin wrapper around umaps `nearest_neighbors` function, which in turn is a thin wrapper around PyNNDescent. We did some special casing around euclidean distance and small data sizes. That special casing reduced our test coverage: . - we dont actually test umaps pynndescent codepath at all (just the fast `precomputed` path for small data); - umaps `precomputed` code does some weird things to its knn `indices` array, which we dont test for: ; ![grafik](https://github.com/scverse/scanpy/assets/291575/7f36cafe-98fb-48cc-9e35-3972fad65a3e). The logic was:. - if small data (<8000) and euclidean metric or knn==False, calculate `pairwise_distances`; - if knn=True, then sparsify that matrix by pulling out KNN using `_get_indices_distances_from_dense_matrix` and converting that into a sparse one; - if not, run `umap.nearest_neighbors`.; - if even smaller data (<4000), calculate `pairwise_distances` like above and run `umap.nearest_neighbors` with `metric='precomputed'`. its internal logic then does the same as `_get_indices_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:2535,Integrability,wrap,wrapper,2535,"NeighborsTransformer; - [x] unify selection: algorithm+backend, metric, connectivity (maybe separate out connectivity); - [x] figure out how to do connectivities: can mode be changed after fit? *no, we just use umap connectivities as before*; - [x] check out where we have coverage; - is there paga specific stuff? *not in the parts I changed*; - gauss: dense matrix when knn=True (build a symmetric mask, ) *not covered, but also the logic shouldnt have changed*; - pre-computed in umap transformer; handling of disconnected components in umap (indices == -1) *replaced with our own implementation, see below*; - add tests; - [x] pyknndescent (we already depend on it through umap). Maybe in another PR?. - [ ] maybe store index in unified way?; - [ ] for umap: use `UMAP(precomputed_knn=...)` instead of `compute_connectivities`?; - [ ] unifiy transformer args, e.g. verbose. ## Implementation. ### The way it used to be. Our default use case was basically a thin wrapper around umaps `nearest_neighbors` function, which in turn is a thin wrapper around PyNNDescent. We did some special casing around euclidean distance and small data sizes. That special casing reduced our test coverage: . - we dont actually test umaps pynndescent codepath at all (just the fast `precomputed` path for small data); - umaps `precomputed` code does some weird things to its knn `indices` array, which we dont test for: ; ![grafik](https://github.com/scverse/scanpy/assets/291575/7f36cafe-98fb-48cc-9e35-3972fad65a3e). The logic was:. - if small data (<8000) and euclidean metric or knn==False, calculate `pairwise_distances`; - if knn=True, then sparsify that matrix by pulling out KNN using `_get_indices_distances_from_dense_matrix` and converting that into a sparse one; - if not, run `umap.nearest_neighbors`.; - if even smaller data (<4000), calculate `pairwise_distances` like above and run `umap.nearest_neighbors` with `metric='precomputed'`. its internal logic then does the same as `_get_indices_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:3801,Performance,optimiz,optimization,3801,"cted components in umap (indices == -1) *replaced with our own implementation, see below*; - add tests; - [x] pyknndescent (we already depend on it through umap). Maybe in another PR?. - [ ] maybe store index in unified way?; - [ ] for umap: use `UMAP(precomputed_knn=...)` instead of `compute_connectivities`?; - [ ] unifiy transformer args, e.g. verbose. ## Implementation. ### The way it used to be. Our default use case was basically a thin wrapper around umaps `nearest_neighbors` function, which in turn is a thin wrapper around PyNNDescent. We did some special casing around euclidean distance and small data sizes. That special casing reduced our test coverage: . - we dont actually test umaps pynndescent codepath at all (just the fast `precomputed` path for small data); - umaps `precomputed` code does some weird things to its knn `indices` array, which we dont test for: ; ![grafik](https://github.com/scverse/scanpy/assets/291575/7f36cafe-98fb-48cc-9e35-3972fad65a3e). The logic was:. - if small data (<8000) and euclidean metric or knn==False, calculate `pairwise_distances`; - if knn=True, then sparsify that matrix by pulling out KNN using `_get_indices_distances_from_dense_matrix` and converting that into a sparse one; - if not, run `umap.nearest_neighbors`.; - if even smaller data (<4000), calculate `pairwise_distances` like above and run `umap.nearest_neighbors` with `metric='precomputed'`. its internal logic then does the same as `_get_indices_distances_from_dense_matrix`; - else run `umap.nearest_neighbors` directly, which simply runs PyNNDescent with `n_trees` and `n_iters` set with a heuristic. ### now the logic is. - if small data (for either definition of small), calculate `pairwise_distances`, sparsify on demand. (this covers both our previous optimization and the umap `'precomputed'` code path); - else run a KNN transformer. if the old `'umap'` method was chosen, pick the same parameters mentioned aboveto the `PyNNDescent` transformer. ---. Fixes #2519",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:716,Safety,predict,predictability,716,"[`sklearn.neighbors.KNeighborsTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsTransformer.html) is a good abstraction for KNN calculations. We could follow the suggestion here, then finish this PR https://github.com/frankier/sklearn-ann/issues/8#issuecomment-1609553421. ### For reviewing. - most functions were moved unchanged; - I extensively changed https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L471; - This uncovered very grown-over-time logic: https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L522-L523 ; *Should we change that logic for more predictability at the expense of backwards compatibility*? Especially the euclidean condition makes not much sense IMHO; - Another piece of weird logic: *Where to allow`knn=False`*? It would make sense for e.g. the scipy knn transformer with `algorithm='kd_tree'`  ; https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L614-L617; - I also changed `method` to only mean connectivity method. `transformer_cls` alone now determines how to calculate distances. ### TODO. - [x] split of sklearn-ann part into own issue/PR; - [x] figure out what the `_more_tags` methods are ; - [x] allow specifying algorithm and/or backend; - [x] revert 75c6670, move connectivities code out of backends; - [x] switch our stuff to KNeighborsTransformer; - [x] unify selection: algorithm+backend, metric, connectivity (maybe separate out connectivity); - [x] figure out how to do connectivities: can mode be changed after fit? *no, we just use umap connectivities as before*; - [x] check out where we have coverage; - is there paga specific stuff? *not in the parts I changed*; - gauss: dense matrix when knn=True (build a symmetric mask, ) *not covered, but also the logic shouldnt have changed*; - pre-computed in umap transformer; handlin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:550,Testability,log,logic,550,"[`sklearn.neighbors.KNeighborsTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsTransformer.html) is a good abstraction for KNN calculations. We could follow the suggestion here, then finish this PR https://github.com/frankier/sklearn-ann/issues/8#issuecomment-1609553421. ### For reviewing. - most functions were moved unchanged; - I extensively changed https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L471; - This uncovered very grown-over-time logic: https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L522-L523 ; *Should we change that logic for more predictability at the expense of backwards compatibility*? Especially the euclidean condition makes not much sense IMHO; - Another piece of weird logic: *Where to allow`knn=False`*? It would make sense for e.g. the scipy knn transformer with `algorithm='kd_tree'`  ; https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L614-L617; - I also changed `method` to only mean connectivity method. `transformer_cls` alone now determines how to calculate distances. ### TODO. - [x] split of sklearn-ann part into own issue/PR; - [x] figure out what the `_more_tags` methods are ; - [x] allow specifying algorithm and/or backend; - [x] revert 75c6670, move connectivities code out of backends; - [x] switch our stuff to KNeighborsTransformer; - [x] unify selection: algorithm+backend, metric, connectivity (maybe separate out connectivity); - [x] figure out how to do connectivities: can mode be changed after fit? *no, we just use umap connectivities as before*; - [x] check out where we have coverage; - is there paga specific stuff? *not in the parts I changed*; - gauss: dense matrix when knn=True (build a symmetric mask, ) *not covered, but also the logic shouldnt have changed*; - pre-computed in umap transformer; handlin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:701,Testability,log,logic,701,"[`sklearn.neighbors.KNeighborsTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsTransformer.html) is a good abstraction for KNN calculations. We could follow the suggestion here, then finish this PR https://github.com/frankier/sklearn-ann/issues/8#issuecomment-1609553421. ### For reviewing. - most functions were moved unchanged; - I extensively changed https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L471; - This uncovered very grown-over-time logic: https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L522-L523 ; *Should we change that logic for more predictability at the expense of backwards compatibility*? Especially the euclidean condition makes not much sense IMHO; - Another piece of weird logic: *Where to allow`knn=False`*? It would make sense for e.g. the scipy knn transformer with `algorithm='kd_tree'`  ; https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L614-L617; - I also changed `method` to only mean connectivity method. `transformer_cls` alone now determines how to calculate distances. ### TODO. - [x] split of sklearn-ann part into own issue/PR; - [x] figure out what the `_more_tags` methods are ; - [x] allow specifying algorithm and/or backend; - [x] revert 75c6670, move connectivities code out of backends; - [x] switch our stuff to KNeighborsTransformer; - [x] unify selection: algorithm+backend, metric, connectivity (maybe separate out connectivity); - [x] figure out how to do connectivities: can mode be changed after fit? *no, we just use umap connectivities as before*; - [x] check out where we have coverage; - is there paga specific stuff? *not in the parts I changed*; - gauss: dense matrix when knn=True (build a symmetric mask, ) *not covered, but also the logic shouldnt have changed*; - pre-computed in umap transformer; handlin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:864,Testability,log,logic,864,"[`sklearn.neighbors.KNeighborsTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsTransformer.html) is a good abstraction for KNN calculations. We could follow the suggestion here, then finish this PR https://github.com/frankier/sklearn-ann/issues/8#issuecomment-1609553421. ### For reviewing. - most functions were moved unchanged; - I extensively changed https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L471; - This uncovered very grown-over-time logic: https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L522-L523 ; *Should we change that logic for more predictability at the expense of backwards compatibility*? Especially the euclidean condition makes not much sense IMHO; - Another piece of weird logic: *Where to allow`knn=False`*? It would make sense for e.g. the scipy knn transformer with `algorithm='kd_tree'`  ; https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L614-L617; - I also changed `method` to only mean connectivity method. `transformer_cls` alone now determines how to calculate distances. ### TODO. - [x] split of sklearn-ann part into own issue/PR; - [x] figure out what the `_more_tags` methods are ; - [x] allow specifying algorithm and/or backend; - [x] revert 75c6670, move connectivities code out of backends; - [x] switch our stuff to KNeighborsTransformer; - [x] unify selection: algorithm+backend, metric, connectivity (maybe separate out connectivity); - [x] figure out how to do connectivities: can mode be changed after fit? *no, we just use umap connectivities as before*; - [x] check out where we have coverage; - is there paga specific stuff? *not in the parts I changed*; - gauss: dense matrix when knn=True (build a symmetric mask, ) *not covered, but also the logic shouldnt have changed*; - pre-computed in umap transformer; handlin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:1927,Testability,log,logic,1927," more predictability at the expense of backwards compatibility*? Especially the euclidean condition makes not much sense IMHO; - Another piece of weird logic: *Where to allow`knn=False`*? It would make sense for e.g. the scipy knn transformer with `algorithm='kd_tree'`  ; https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L614-L617; - I also changed `method` to only mean connectivity method. `transformer_cls` alone now determines how to calculate distances. ### TODO. - [x] split of sklearn-ann part into own issue/PR; - [x] figure out what the `_more_tags` methods are ; - [x] allow specifying algorithm and/or backend; - [x] revert 75c6670, move connectivities code out of backends; - [x] switch our stuff to KNeighborsTransformer; - [x] unify selection: algorithm+backend, metric, connectivity (maybe separate out connectivity); - [x] figure out how to do connectivities: can mode be changed after fit? *no, we just use umap connectivities as before*; - [x] check out where we have coverage; - is there paga specific stuff? *not in the parts I changed*; - gauss: dense matrix when knn=True (build a symmetric mask, ) *not covered, but also the logic shouldnt have changed*; - pre-computed in umap transformer; handling of disconnected components in umap (indices == -1) *replaced with our own implementation, see below*; - add tests; - [x] pyknndescent (we already depend on it through umap). Maybe in another PR?. - [ ] maybe store index in unified way?; - [ ] for umap: use `UMAP(precomputed_knn=...)` instead of `compute_connectivities`?; - [ ] unifiy transformer args, e.g. verbose. ## Implementation. ### The way it used to be. Our default use case was basically a thin wrapper around umaps `nearest_neighbors` function, which in turn is a thin wrapper around PyNNDescent. We did some special casing around euclidean distance and small data sizes. That special casing reduced our test coverage: . - we dont actually tes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:2111,Testability,test,tests,2111," more predictability at the expense of backwards compatibility*? Especially the euclidean condition makes not much sense IMHO; - Another piece of weird logic: *Where to allow`knn=False`*? It would make sense for e.g. the scipy knn transformer with `algorithm='kd_tree'`  ; https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L614-L617; - I also changed `method` to only mean connectivity method. `transformer_cls` alone now determines how to calculate distances. ### TODO. - [x] split of sklearn-ann part into own issue/PR; - [x] figure out what the `_more_tags` methods are ; - [x] allow specifying algorithm and/or backend; - [x] revert 75c6670, move connectivities code out of backends; - [x] switch our stuff to KNeighborsTransformer; - [x] unify selection: algorithm+backend, metric, connectivity (maybe separate out connectivity); - [x] figure out how to do connectivities: can mode be changed after fit? *no, we just use umap connectivities as before*; - [x] check out where we have coverage; - is there paga specific stuff? *not in the parts I changed*; - gauss: dense matrix when knn=True (build a symmetric mask, ) *not covered, but also the logic shouldnt have changed*; - pre-computed in umap transformer; handling of disconnected components in umap (indices == -1) *replaced with our own implementation, see below*; - add tests; - [x] pyknndescent (we already depend on it through umap). Maybe in another PR?. - [ ] maybe store index in unified way?; - [ ] for umap: use `UMAP(precomputed_knn=...)` instead of `compute_connectivities`?; - [ ] unifiy transformer args, e.g. verbose. ## Implementation. ### The way it used to be. Our default use case was basically a thin wrapper around umaps `nearest_neighbors` function, which in turn is a thin wrapper around PyNNDescent. We did some special casing around euclidean distance and small data sizes. That special casing reduced our test coverage: . - we dont actually tes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:2670,Testability,test,test,2670,"be changed after fit? *no, we just use umap connectivities as before*; - [x] check out where we have coverage; - is there paga specific stuff? *not in the parts I changed*; - gauss: dense matrix when knn=True (build a symmetric mask, ) *not covered, but also the logic shouldnt have changed*; - pre-computed in umap transformer; handling of disconnected components in umap (indices == -1) *replaced with our own implementation, see below*; - add tests; - [x] pyknndescent (we already depend on it through umap). Maybe in another PR?. - [ ] maybe store index in unified way?; - [ ] for umap: use `UMAP(precomputed_knn=...)` instead of `compute_connectivities`?; - [ ] unifiy transformer args, e.g. verbose. ## Implementation. ### The way it used to be. Our default use case was basically a thin wrapper around umaps `nearest_neighbors` function, which in turn is a thin wrapper around PyNNDescent. We did some special casing around euclidean distance and small data sizes. That special casing reduced our test coverage: . - we dont actually test umaps pynndescent codepath at all (just the fast `precomputed` path for small data); - umaps `precomputed` code does some weird things to its knn `indices` array, which we dont test for: ; ![grafik](https://github.com/scverse/scanpy/assets/291575/7f36cafe-98fb-48cc-9e35-3972fad65a3e). The logic was:. - if small data (<8000) and euclidean metric or knn==False, calculate `pairwise_distances`; - if knn=True, then sparsify that matrix by pulling out KNN using `_get_indices_distances_from_dense_matrix` and converting that into a sparse one; - if not, run `umap.nearest_neighbors`.; - if even smaller data (<4000), calculate `pairwise_distances` like above and run `umap.nearest_neighbors` with `metric='precomputed'`. its internal logic then does the same as `_get_indices_distances_from_dense_matrix`; - else run `umap.nearest_neighbors` directly, which simply runs PyNNDescent with `n_trees` and `n_iters` set with a heuristic. ### now the logi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:2707,Testability,test,test,2707,"t in the parts I changed*; - gauss: dense matrix when knn=True (build a symmetric mask, ) *not covered, but also the logic shouldnt have changed*; - pre-computed in umap transformer; handling of disconnected components in umap (indices == -1) *replaced with our own implementation, see below*; - add tests; - [x] pyknndescent (we already depend on it through umap). Maybe in another PR?. - [ ] maybe store index in unified way?; - [ ] for umap: use `UMAP(precomputed_knn=...)` instead of `compute_connectivities`?; - [ ] unifiy transformer args, e.g. verbose. ## Implementation. ### The way it used to be. Our default use case was basically a thin wrapper around umaps `nearest_neighbors` function, which in turn is a thin wrapper around PyNNDescent. We did some special casing around euclidean distance and small data sizes. That special casing reduced our test coverage: . - we dont actually test umaps pynndescent codepath at all (just the fast `precomputed` path for small data); - umaps `precomputed` code does some weird things to its knn `indices` array, which we dont test for: ; ![grafik](https://github.com/scverse/scanpy/assets/291575/7f36cafe-98fb-48cc-9e35-3972fad65a3e). The logic was:. - if small data (<8000) and euclidean metric or knn==False, calculate `pairwise_distances`; - if knn=True, then sparsify that matrix by pulling out KNN using `_get_indices_distances_from_dense_matrix` and converting that into a sparse one; - if not, run `umap.nearest_neighbors`.; - if even smaller data (<4000), calculate `pairwise_distances` like above and run `umap.nearest_neighbors` with `metric='precomputed'`. its internal logic then does the same as `_get_indices_distances_from_dense_matrix`; - else run `umap.nearest_neighbors` directly, which simply runs PyNNDescent with `n_trees` and `n_iters` set with a heuristic. ### now the logic is. - if small data (for either definition of small), calculate `pairwise_distances`, sparsify on demand. (this covers both our previous optimiz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:2892,Testability,test,test,2892,"t in the parts I changed*; - gauss: dense matrix when knn=True (build a symmetric mask, ) *not covered, but also the logic shouldnt have changed*; - pre-computed in umap transformer; handling of disconnected components in umap (indices == -1) *replaced with our own implementation, see below*; - add tests; - [x] pyknndescent (we already depend on it through umap). Maybe in another PR?. - [ ] maybe store index in unified way?; - [ ] for umap: use `UMAP(precomputed_knn=...)` instead of `compute_connectivities`?; - [ ] unifiy transformer args, e.g. verbose. ## Implementation. ### The way it used to be. Our default use case was basically a thin wrapper around umaps `nearest_neighbors` function, which in turn is a thin wrapper around PyNNDescent. We did some special casing around euclidean distance and small data sizes. That special casing reduced our test coverage: . - we dont actually test umaps pynndescent codepath at all (just the fast `precomputed` path for small data); - umaps `precomputed` code does some weird things to its knn `indices` array, which we dont test for: ; ![grafik](https://github.com/scverse/scanpy/assets/291575/7f36cafe-98fb-48cc-9e35-3972fad65a3e). The logic was:. - if small data (<8000) and euclidean metric or knn==False, calculate `pairwise_distances`; - if knn=True, then sparsify that matrix by pulling out KNN using `_get_indices_distances_from_dense_matrix` and converting that into a sparse one; - if not, run `umap.nearest_neighbors`.; - if even smaller data (<4000), calculate `pairwise_distances` like above and run `umap.nearest_neighbors` with `metric='precomputed'`. its internal logic then does the same as `_get_indices_distances_from_dense_matrix`; - else run `umap.nearest_neighbors` directly, which simply runs PyNNDescent with `n_trees` and `n_iters` set with a heuristic. ### now the logic is. - if small data (for either definition of small), calculate `pairwise_distances`, sparsify on demand. (this covers both our previous optimiz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:3005,Testability,log,logic,3005,"sconnected components in umap (indices == -1) *replaced with our own implementation, see below*; - add tests; - [x] pyknndescent (we already depend on it through umap). Maybe in another PR?. - [ ] maybe store index in unified way?; - [ ] for umap: use `UMAP(precomputed_knn=...)` instead of `compute_connectivities`?; - [ ] unifiy transformer args, e.g. verbose. ## Implementation. ### The way it used to be. Our default use case was basically a thin wrapper around umaps `nearest_neighbors` function, which in turn is a thin wrapper around PyNNDescent. We did some special casing around euclidean distance and small data sizes. That special casing reduced our test coverage: . - we dont actually test umaps pynndescent codepath at all (just the fast `precomputed` path for small data); - umaps `precomputed` code does some weird things to its knn `indices` array, which we dont test for: ; ![grafik](https://github.com/scverse/scanpy/assets/291575/7f36cafe-98fb-48cc-9e35-3972fad65a3e). The logic was:. - if small data (<8000) and euclidean metric or knn==False, calculate `pairwise_distances`; - if knn=True, then sparsify that matrix by pulling out KNN using `_get_indices_distances_from_dense_matrix` and converting that into a sparse one; - if not, run `umap.nearest_neighbors`.; - if even smaller data (<4000), calculate `pairwise_distances` like above and run `umap.nearest_neighbors` with `metric='precomputed'`. its internal logic then does the same as `_get_indices_distances_from_dense_matrix`; - else run `umap.nearest_neighbors` directly, which simply runs PyNNDescent with `n_trees` and `n_iters` set with a heuristic. ### now the logic is. - if small data (for either definition of small), calculate `pairwise_distances`, sparsify on demand. (this covers both our previous optimization and the umap `'precomputed'` code path); - else run a KNN transformer. if the old `'umap'` method was chosen, pick the same parameters mentioned aboveto the `PyNNDescent` transformer. ---. Fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:3447,Testability,log,logic,3447,"cted components in umap (indices == -1) *replaced with our own implementation, see below*; - add tests; - [x] pyknndescent (we already depend on it through umap). Maybe in another PR?. - [ ] maybe store index in unified way?; - [ ] for umap: use `UMAP(precomputed_knn=...)` instead of `compute_connectivities`?; - [ ] unifiy transformer args, e.g. verbose. ## Implementation. ### The way it used to be. Our default use case was basically a thin wrapper around umaps `nearest_neighbors` function, which in turn is a thin wrapper around PyNNDescent. We did some special casing around euclidean distance and small data sizes. That special casing reduced our test coverage: . - we dont actually test umaps pynndescent codepath at all (just the fast `precomputed` path for small data); - umaps `precomputed` code does some weird things to its knn `indices` array, which we dont test for: ; ![grafik](https://github.com/scverse/scanpy/assets/291575/7f36cafe-98fb-48cc-9e35-3972fad65a3e). The logic was:. - if small data (<8000) and euclidean metric or knn==False, calculate `pairwise_distances`; - if knn=True, then sparsify that matrix by pulling out KNN using `_get_indices_distances_from_dense_matrix` and converting that into a sparse one; - if not, run `umap.nearest_neighbors`.; - if even smaller data (<4000), calculate `pairwise_distances` like above and run `umap.nearest_neighbors` with `metric='precomputed'`. its internal logic then does the same as `_get_indices_distances_from_dense_matrix`; - else run `umap.nearest_neighbors` directly, which simply runs PyNNDescent with `n_trees` and `n_iters` set with a heuristic. ### now the logic is. - if small data (for either definition of small), calculate `pairwise_distances`, sparsify on demand. (this covers both our previous optimization and the umap `'precomputed'` code path); - else run a KNN transformer. if the old `'umap'` method was chosen, pick the same parameters mentioned aboveto the `PyNNDescent` transformer. ---. Fixes #2519",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:3658,Testability,log,logic,3658,"cted components in umap (indices == -1) *replaced with our own implementation, see below*; - add tests; - [x] pyknndescent (we already depend on it through umap). Maybe in another PR?. - [ ] maybe store index in unified way?; - [ ] for umap: use `UMAP(precomputed_knn=...)` instead of `compute_connectivities`?; - [ ] unifiy transformer args, e.g. verbose. ## Implementation. ### The way it used to be. Our default use case was basically a thin wrapper around umaps `nearest_neighbors` function, which in turn is a thin wrapper around PyNNDescent. We did some special casing around euclidean distance and small data sizes. That special casing reduced our test coverage: . - we dont actually test umaps pynndescent codepath at all (just the fast `precomputed` path for small data); - umaps `precomputed` code does some weird things to its knn `indices` array, which we dont test for: ; ![grafik](https://github.com/scverse/scanpy/assets/291575/7f36cafe-98fb-48cc-9e35-3972fad65a3e). The logic was:. - if small data (<8000) and euclidean metric or knn==False, calculate `pairwise_distances`; - if knn=True, then sparsify that matrix by pulling out KNN using `_get_indices_distances_from_dense_matrix` and converting that into a sparse one; - if not, run `umap.nearest_neighbors`.; - if even smaller data (<4000), calculate `pairwise_distances` like above and run `umap.nearest_neighbors` with `metric='precomputed'`. its internal logic then does the same as `_get_indices_distances_from_dense_matrix`; - else run `umap.nearest_neighbors` directly, which simply runs PyNNDescent with `n_trees` and `n_iters` set with a heuristic. ### now the logic is. - if small data (for either definition of small), calculate `pairwise_distances`, sparsify on demand. (this covers both our previous optimization and the umap `'precomputed'` code path); - else run a KNN transformer. if the old `'umap'` method was chosen, pick the same parameters mentioned aboveto the `PyNNDescent` transformer. ---. Fixes #2519",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:59,Usability,learn,learn,59,"[`sklearn.neighbors.KNeighborsTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsTransformer.html) is a good abstraction for KNN calculations. We could follow the suggestion here, then finish this PR https://github.com/frankier/sklearn-ann/issues/8#issuecomment-1609553421. ### For reviewing. - most functions were moved unchanged; - I extensively changed https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L471; - This uncovered very grown-over-time logic: https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L522-L523 ; *Should we change that logic for more predictability at the expense of backwards compatibility*? Especially the euclidean condition makes not much sense IMHO; - Another piece of weird logic: *Where to allow`knn=False`*? It would make sense for e.g. the scipy knn transformer with `algorithm='kd_tree'`  ; https://github.com/scverse/scanpy/blob/73915b4bd0dc84108df08ad83ec28e627a9a0e0d/scanpy/neighbors/__init__.py#L614-L617; - I also changed `method` to only mean connectivity method. `transformer_cls` alone now determines how to calculate distances. ### TODO. - [x] split of sklearn-ann part into own issue/PR; - [x] figure out what the `_more_tags` methods are ; - [x] allow specifying algorithm and/or backend; - [x] revert 75c6670, move connectivities code out of backends; - [x] switch our stuff to KNeighborsTransformer; - [x] unify selection: algorithm+backend, metric, connectivity (maybe separate out connectivity); - [x] figure out how to do connectivities: can mode be changed after fit? *no, we just use umap connectivities as before*; - [x] check out where we have coverage; - is there paga specific stuff? *not in the parts I changed*; - gauss: dense matrix when knn=True (build a symmetric mask, ) *not covered, but also the logic shouldnt have changed*; - pre-computed in umap transformer; handlin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2536:3571,Usability,simpl,simply,3571,"cted components in umap (indices == -1) *replaced with our own implementation, see below*; - add tests; - [x] pyknndescent (we already depend on it through umap). Maybe in another PR?. - [ ] maybe store index in unified way?; - [ ] for umap: use `UMAP(precomputed_knn=...)` instead of `compute_connectivities`?; - [ ] unifiy transformer args, e.g. verbose. ## Implementation. ### The way it used to be. Our default use case was basically a thin wrapper around umaps `nearest_neighbors` function, which in turn is a thin wrapper around PyNNDescent. We did some special casing around euclidean distance and small data sizes. That special casing reduced our test coverage: . - we dont actually test umaps pynndescent codepath at all (just the fast `precomputed` path for small data); - umaps `precomputed` code does some weird things to its knn `indices` array, which we dont test for: ; ![grafik](https://github.com/scverse/scanpy/assets/291575/7f36cafe-98fb-48cc-9e35-3972fad65a3e). The logic was:. - if small data (<8000) and euclidean metric or knn==False, calculate `pairwise_distances`; - if knn=True, then sparsify that matrix by pulling out KNN using `_get_indices_distances_from_dense_matrix` and converting that into a sparse one; - if not, run `umap.nearest_neighbors`.; - if even smaller data (<4000), calculate `pairwise_distances` like above and run `umap.nearest_neighbors` with `metric='precomputed'`. its internal logic then does the same as `_get_indices_distances_from_dense_matrix`; - else run `umap.nearest_neighbors` directly, which simply runs PyNNDescent with `n_trees` and `n_iters` set with a heuristic. ### now the logic is. - if small data (for either definition of small), calculate `pairwise_distances`, sparsify on demand. (this covers both our previous optimization and the umap `'precomputed'` code path); - else run a KNN transformer. if the old `'umap'` method was chosen, pick the same parameters mentioned aboveto the `PyNNDescent` transformer. ---. Fixes #2519",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2536
https://github.com/scverse/scanpy/pull/2537:37,Modifiability,config,config,37,"The CLI option is different from the config option . no review necessary, simple fix",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2537
https://github.com/scverse/scanpy/pull/2537:75,Usability,simpl,simple,75,"The CLI option is different from the config option . no review necessary, simple fix",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2537
https://github.com/scverse/scanpy/issues/2539:970,Availability,Error,Error,970,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When working on one of the notebooks in `spatialdata-notebooks` I noticed that for `library_id` in `scatterplots.py` the type hints are inconsistent. Specifically here it is indicated to be either `Empty` or `str`:. https://github.com/scverse/scanpy/blob/cd7f6c57d4abb49947fa31a945e9a21b833e6e15/scanpy/plotting/_tools/scatterplots.py#L921. While here the type hint includes `None`:; https://github.com/scverse/scanpy/blob/cd7f6c57d4abb49947fa31a945e9a21b833e6e15/scanpy/plotting/_tools/scatterplots.py#L1287. I think the case should be that None should be included. Very minor, but just noticed it so I thought to open an issue. ### Minimal code sample. ```python; NA; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; asciitree NA; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dask 2023.5.1; dateutil 2.8.2; defusedxml 0.7.1; entrypoints 0.4; fasteners 0.18; h5py 3.8.0; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.40.0; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; msgpack 1.0.5; natsort 8.3.1; nt NA; numba 0.57.0; numcodecs 0.11.0; numpy 1.24.3; packaging 23.1; pandas 1.5.3; psutil 5.9.5; pyarrow 12.0.0; pyparsing 3.0.9; pythoncom NA; pytz 2023.3; pywintypes NA; scipy 1.10.1; session_info 1.0.0; setuptools 67.7.2; six 1.16.0; sklearn 1.2.2; sphinxcontrib NA; tblib 1.7.0; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; typing_extensions NA; win32api NA; win32com NA; yaml 6.0; zarr 2.14.2; zipp NA; zoneinfo NA; -----; Python 3.10.11 | packaged by conda-forge | (main, May 10 2023, 18:51:25) [MSC v.1934 64 bit (AMD64)]; Windows-10-10.0.22621-SP0. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2539
https://github.com/scverse/scanpy/issues/2540:728,Availability,Error,Error,728,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When trying to produce a violin plot using `pl.rank_genes_groups_violin()` of the ranked genes and passing `gene_symbols=""gene_symbols""` I get a `KeyError`. However `pl.rank_genes_groups()` works fine with the option `gene_symbols=""gene_symbols""` and the same `adata` object. ### Minimal code sample. ```python; sc.pl.rank_genes_groups_violin(; adata, groups=cell_types, n_genes=15, strip=False, gene_symbols=""gene_symbols""; ); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[258], line 1; ----> 1 sc.pl.rank_genes_groups_violin(; 2 adata, groups=cell_types, n_genes=15, strip=False, gene_symbols=""gene_symbols""; 3 ). File ~/.conda/envs/scirpy/lib/python3.10/site-packages/scanpy/plotting/_tools/__init__.py:1157, in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save); 1155 if isinstance(_gene_names, np.ndarray):; 1156 _gene_names = _gene_names.tolist(); -> 1157 df = obs_df(adata, _gene_names, use_raw=use_raw, gene_symbols=gene_symbols); 1158 new_gene_names = df.columns; 1159 df['hue'] = adata.obs[groups_key].astype(str).values. File ~/.conda/envs/scirpy/lib/python3.10/site-packages/scanpy/get/get.py:272, in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 269 else:; 270 alias_index = None; --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(; 273 adata.obs,; 274 var.index,; 275 ""obs"",; 276 keys,; 277 alias_index=alias_index,; 278 use_raw=use_raw,; 279 ); 281 # Make df; 282 df = pd.DataFrame(index=adata.obs_names). File ~/.conda/envs/scirpy/lib/python3.10/site-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2540
https://github.com/scverse/scanpy/issues/2540:4713,Deployability,update,updated,4713,"_symbols'].""; ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; Levenshtein 0.21.0; PIL 9.5.0; adjustText NA; airr 1.4.1; asttokens NA; awkward 2.2.2; awkward_cpp NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; certifi 2023.05.07; cffi 1.15.1; charset_normalizer 3.1.0; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 1.2.0; h5py 3.8.0; hypergeom_ufunc NA; idna 3.4; igraph 0.10.4; invgauss_ufunc NA; ipykernel 6.22.0; ipywidgets 8.0.6; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.39.1; matplotlib 3.7.1; matplotlib_inline 0.1.6; mpl_toolkits NA; mudata 0.2.3; muon 0.1.5; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; networkx 3.1; numba 0.56.4; numpy 1.23.5; packaging 23.1; pandas 1.5.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.2.0; pooch v1.7.0; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pytz 2023.3; rapidfuzz 2.15.1; requests 2.28.2; scipy 1.10.1; scirpy 0.13.1.dev2+g4ed908b; seaborn 0.12.2; session_info 1.0.0; setuptools 67.7.1; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; socks 1.7.1; squarify NA; stack_data 0.6.2; statsmodels 0.13.5; texttable 1.6.7; threadpoolctl 3.1.0; torch 1.12.1.post201; tornado 6.3; tqdm 4.65.0; tracerlib NA; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; urllib3 1.26.15; wcwidth 0.2.6; yaml 6.0; yamlordereddictloader NA; zmq 25.0.2; zoneinfo NA; -----; IPython 8.13.2; jupyter_client 8.2.0; jupyter_core 5.3.0; -----; Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]; Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-glibc2.17; -----; Session information updated at 2023-06-28 18:02; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2540
https://github.com/scverse/scanpy/issues/2542:327,Availability,error,error,327,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I tried to import scanpy and got an error. ### Minimal code sample. ```python; import scanpy as sc; ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""C:\Users\zacha\PycharmProjects\CellAssign\pipeline.py"", line 2, in <module>; import scanpy as sc; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\scanpy\__init__.py"", line 6, in <module>; from ._utils import check_versions; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\scanpy\_utils\__init__.py"", line 21, in <module>; from anndata import AnnData, __version__ as anndata_version; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\anndata\__init__.py"", line 7, in <module>; from ._core.anndata import AnnData; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\anndata\_core\anndata.py"", line 17, in <module>; import h5py; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\h5py\__init__.py"", line 33, in <module>; from . import version; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\h5py\version.py"", line 15, in <module>; from . import h5 as _h5; File ""h5py\h5.pyx"", line 1, in init h5py.h5; ImportError: DLL load failed while importing defs: The specified procedure could not be found.; ```. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2542
https://github.com/scverse/scanpy/issues/2542:400,Availability,Error,Error,400,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I tried to import scanpy and got an error. ### Minimal code sample. ```python; import scanpy as sc; ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""C:\Users\zacha\PycharmProjects\CellAssign\pipeline.py"", line 2, in <module>; import scanpy as sc; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\scanpy\__init__.py"", line 6, in <module>; from ._utils import check_versions; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\scanpy\_utils\__init__.py"", line 21, in <module>; from anndata import AnnData, __version__ as anndata_version; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\anndata\__init__.py"", line 7, in <module>; from ._core.anndata import AnnData; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\anndata\_core\anndata.py"", line 17, in <module>; import h5py; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\h5py\__init__.py"", line 33, in <module>; from . import version; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\h5py\version.py"", line 15, in <module>; from . import h5 as _h5; File ""h5py\h5.pyx"", line 1, in init h5py.h5; ImportError: DLL load failed while importing defs: The specified procedure could not be found.; ```. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2542
https://github.com/scverse/scanpy/issues/2542:507,Deployability,pipeline,pipeline,507,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I tried to import scanpy and got an error. ### Minimal code sample. ```python; import scanpy as sc; ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""C:\Users\zacha\PycharmProjects\CellAssign\pipeline.py"", line 2, in <module>; import scanpy as sc; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\scanpy\__init__.py"", line 6, in <module>; from ._utils import check_versions; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\scanpy\_utils\__init__.py"", line 21, in <module>; from anndata import AnnData, __version__ as anndata_version; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\anndata\__init__.py"", line 7, in <module>; from ._core.anndata import AnnData; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\anndata\_core\anndata.py"", line 17, in <module>; import h5py; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\h5py\__init__.py"", line 33, in <module>; from . import version; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\h5py\version.py"", line 15, in <module>; from . import h5 as _h5; File ""h5py\h5.pyx"", line 1, in init h5py.h5; ImportError: DLL load failed while importing defs: The specified procedure could not be found.; ```. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2542
https://github.com/scverse/scanpy/issues/2542:1456,Performance,load,load,1456,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I tried to import scanpy and got an error. ### Minimal code sample. ```python; import scanpy as sc; ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""C:\Users\zacha\PycharmProjects\CellAssign\pipeline.py"", line 2, in <module>; import scanpy as sc; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\scanpy\__init__.py"", line 6, in <module>; from ._utils import check_versions; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\scanpy\_utils\__init__.py"", line 21, in <module>; from anndata import AnnData, __version__ as anndata_version; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\anndata\__init__.py"", line 7, in <module>; from ._core.anndata import AnnData; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\anndata\_core\anndata.py"", line 17, in <module>; import h5py; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\h5py\__init__.py"", line 33, in <module>; from . import version; File ""C:\Users\zacha\.conda\envs\CellAssign\lib\site-packages\h5py\version.py"", line 15, in <module>; from . import h5 as _h5; File ""h5py\h5.pyx"", line 1, in init h5py.h5; ImportError: DLL load failed while importing defs: The specified procedure could not be found.; ```. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2542
https://github.com/scverse/scanpy/pull/2544:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.275  v0.0.276](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.275...v0.0.276); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2544
https://github.com/scverse/scanpy/pull/2546:240,Availability,error,error,240,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Fixes error if the `log1p` dict doesn't have a `base` key. Fixes https://github.com/scverse/scanpy/issues/2497, fixes https://github.com/scverse/scanpy-tutorials/issues/65, fixes https://github.com/scverse/scanpy/issues/2181",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2546
https://github.com/scverse/scanpy/pull/2546:71,Usability,guid,guidelines,71,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Fixes error if the `log1p` dict doesn't have a `base` key. Fixes https://github.com/scverse/scanpy/issues/2497, fixes https://github.com/scverse/scanpy-tutorials/issues/65, fixes https://github.com/scverse/scanpy/issues/2181",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2546
https://github.com/scverse/scanpy/pull/2546:102,Usability,guid,guide,102,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Fixes error if the `log1p` dict doesn't have a `base` key. Fixes https://github.com/scverse/scanpy/issues/2497, fixes https://github.com/scverse/scanpy-tutorials/issues/65, fixes https://github.com/scverse/scanpy/issues/2181",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2546
https://github.com/scverse/scanpy/issues/2547:346,Availability,error,error,346,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Running the highly_variable_genes function produced an error. ### Minimal code sample. ```python; sc.pp.highly_variable_genes(test_adata, min_mean=0.0125, max_mean=3, min_disp=0.25); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[101], line 2; 1 # Identify highly-variable genes and plot; ----> 2 sc.pp.highly_variable_genes(test_adata, min_mean=0.0125, max_mean=3, min_disp=0.25). File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/scanpy/preprocessing/_highly_variable_genes.py:440, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 428 return _highly_variable_genes_seurat_v3(; 429 adata,; 430 layer=layer,; (...); 436 inplace=inplace,; 437 ); 439 if batch_key is None:; --> 440 df = _highly_variable_genes_single_batch(; 441 adata,; 442 layer=layer,; 443 min_disp=min_disp,; 444 max_disp=max_disp,; 445 min_mean=min_mean,; 446 max_mean=max_mean,; 447 n_top_genes=n_top_genes,; 448 n_bins=n_bins,; 449 flavor=flavor,; 450 ); 451 else:; 452 sanitize_anndata(adata). File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/scanpy/preprocessing/_highly_variable_genes.py:223, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 219 # retrieve those genes that have nan std, these are the ones where; 220 # only a single gene fell in the bin and implicitly set them to have; 221 # a normalized disperion of 1; 222 one_gene_per_bin = disp_std_bin.isnull(); --> 223 gen_indices = np.where(one_gene_per_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2547
https://github.com/scverse/scanpy/issues/2547:483,Availability,Error,Error,483,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Running the highly_variable_genes function produced an error. ### Minimal code sample. ```python; sc.pp.highly_variable_genes(test_adata, min_mean=0.0125, max_mean=3, min_disp=0.25); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[101], line 2; 1 # Identify highly-variable genes and plot; ----> 2 sc.pp.highly_variable_genes(test_adata, min_mean=0.0125, max_mean=3, min_disp=0.25). File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/scanpy/preprocessing/_highly_variable_genes.py:440, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 428 return _highly_variable_genes_seurat_v3(; 429 adata,; 430 layer=layer,; (...); 436 inplace=inplace,; 437 ); 439 if batch_key is None:; --> 440 df = _highly_variable_genes_single_batch(; 441 adata,; 442 layer=layer,; 443 min_disp=min_disp,; 444 max_disp=max_disp,; 445 min_mean=min_mean,; 446 max_mean=max_mean,; 447 n_top_genes=n_top_genes,; 448 n_bins=n_bins,; 449 flavor=flavor,; 450 ); 451 else:; 452 sanitize_anndata(adata). File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/scanpy/preprocessing/_highly_variable_genes.py:223, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 219 # retrieve those genes that have nan std, these are the ones where; 220 # only a single gene fell in the bin and implicitly set them to have; 221 # a normalized disperion of 1; 222 one_gene_per_bin = disp_std_bin.isnull(); --> 223 gen_indices = np.where(one_gene_per_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2547
https://github.com/scverse/scanpy/issues/2547:7481,Deployability,update,updated,7481," igraph 0.10.4; importlib_resources NA; ipykernel 6.23.1; ipython_genutils 0.2.0; ipywidgets 8.0.6; jax 0.4.12; jaxlib 0.4.12; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; lightning 2.0.3; lightning_cloud NA; lightning_fabric 2.0.3; lightning_utilities 0.8.0; llvmlite 0.40.0; louvain 0.8.0; matplotlib 3.7.1; matplotlib_inline 0.1.6; ml_collections NA; ml_dtypes 0.2.0; mpl_toolkits NA; mpmath 1.3.0; msgpack 1.0.5; mudata 0.2.3; multidict 6.0.4; multipart 0.0.6; multipledispatch 0.6.0; natsort 8.3.1; numba 0.57.0; numpy 1.24.3; numpyro 0.12.1; nvfuser NA; opt_einsum v3.3.0; optax 0.1.5; ordered_set 4.1.0; packaging 23.1; pandas 2.0.2; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.3; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydantic 1.10.9; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 1.4.2; pygments 2.15.1; pyparsing 3.0.9; pyro 1.8.5; pytorch_lightning 2.0.3; pytz 2023.3; requests 2.31.0; rich NA; scipy 1.10.1; scvi 1.0.0; seaborn 0.12.2; session_info 1.0.0; setuptools 67.7.2; six 1.16.0; sklearn 1.2.2; sniffio 1.3.0; socks 1.7.1; soupsieve 2.3.2.post1; sparse 0.14.0; sphinxcontrib NA; stack_data 0.6.2; starlette 0.22.0; statsmodels 0.14.0; sympy 1.12; texttable 1.6.7; threadpoolctl 3.1.0; toml 0.10.2; toolz 0.12.0; torch 2.0.1+cu117; torchmetrics 0.11.4; tornado 6.3.2; tqdm 4.65.0; traitlets 5.9.0; tree 0.1.8; typing_extensions NA; urllib3 2.0.3; uvicorn 0.22.0; wcwidth 0.2.6; websocket 1.5.3; websockets 11.0.3; wrapt 1.15.0; xarray 2023.5.0; yaml 6.0; yarl 1.9.2; zmq 25.1.0; zoneinfo NA; -----; IPython 8.14.0; jupyter_client 8.2.0; jupyter_core 5.3.1; notebook 6.5.4; -----; Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:17) [GCC 12.2.0]; Linux-4.18.0-425.19.2.el8_7.x86_64-x86_64-with-glibc2.27; -----; Session information updated at 2023-07-06 03:56; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2547
https://github.com/scverse/scanpy/issues/2547:7144,Integrability,wrap,wrapt,7144," igraph 0.10.4; importlib_resources NA; ipykernel 6.23.1; ipython_genutils 0.2.0; ipywidgets 8.0.6; jax 0.4.12; jaxlib 0.4.12; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.9.1; lightning 2.0.3; lightning_cloud NA; lightning_fabric 2.0.3; lightning_utilities 0.8.0; llvmlite 0.40.0; louvain 0.8.0; matplotlib 3.7.1; matplotlib_inline 0.1.6; ml_collections NA; ml_dtypes 0.2.0; mpl_toolkits NA; mpmath 1.3.0; msgpack 1.0.5; mudata 0.2.3; multidict 6.0.4; multipart 0.0.6; multipledispatch 0.6.0; natsort 8.3.1; numba 0.57.0; numpy 1.24.3; numpyro 0.12.1; nvfuser NA; opt_einsum v3.3.0; optax 0.1.5; ordered_set 4.1.0; packaging 23.1; pandas 2.0.2; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.3; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pycparser 2.21; pydantic 1.10.9; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pydot 1.4.2; pygments 2.15.1; pyparsing 3.0.9; pyro 1.8.5; pytorch_lightning 2.0.3; pytz 2023.3; requests 2.31.0; rich NA; scipy 1.10.1; scvi 1.0.0; seaborn 0.12.2; session_info 1.0.0; setuptools 67.7.2; six 1.16.0; sklearn 1.2.2; sniffio 1.3.0; socks 1.7.1; soupsieve 2.3.2.post1; sparse 0.14.0; sphinxcontrib NA; stack_data 0.6.2; starlette 0.22.0; statsmodels 0.14.0; sympy 1.12; texttable 1.6.7; threadpoolctl 3.1.0; toml 0.10.2; toolz 0.12.0; torch 2.0.1+cu117; torchmetrics 0.11.4; tornado 6.3.2; tqdm 4.65.0; traitlets 5.9.0; tree 0.1.8; typing_extensions NA; urllib3 2.0.3; uvicorn 0.22.0; wcwidth 0.2.6; websocket 1.5.3; websockets 11.0.3; wrapt 1.15.0; xarray 2023.5.0; yaml 6.0; yarl 1.9.2; zmq 25.1.0; zoneinfo NA; -----; IPython 8.14.0; jupyter_client 8.2.0; jupyter_core 5.3.1; notebook 6.5.4; -----; Python 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 18:08:17) [GCC 12.2.0]; Linux-4.18.0-425.19.2.el8_7.x86_64-x86_64-with-glibc2.27; -----; Session information updated at 2023-07-06 03:56; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2547
https://github.com/scverse/scanpy/issues/2547:669,Modifiability,variab,variable,669,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Running the highly_variable_genes function produced an error. ### Minimal code sample. ```python; sc.pp.highly_variable_genes(test_adata, min_mean=0.0125, max_mean=3, min_disp=0.25); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[101], line 2; 1 # Identify highly-variable genes and plot; ----> 2 sc.pp.highly_variable_genes(test_adata, min_mean=0.0125, max_mean=3, min_disp=0.25). File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/scanpy/preprocessing/_highly_variable_genes.py:440, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 428 return _highly_variable_genes_seurat_v3(; 429 adata,; 430 layer=layer,; (...); 436 inplace=inplace,; 437 ); 439 if batch_key is None:; --> 440 df = _highly_variable_genes_single_batch(; 441 adata,; 442 layer=layer,; 443 min_disp=min_disp,; 444 max_disp=max_disp,; 445 min_mean=min_mean,; 446 max_mean=max_mean,; 447 n_top_genes=n_top_genes,; 448 n_bins=n_bins,; 449 flavor=flavor,; 450 ); 451 else:; 452 sanitize_anndata(adata). File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/scanpy/preprocessing/_highly_variable_genes.py:223, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 219 # retrieve those genes that have nan std, these are the ones where; 220 # only a single gene fell in the bin and implicitly set them to have; 221 # a normalized disperion of 1; 222 one_gene_per_bin = disp_std_bin.isnull(); --> 223 gen_indices = np.where(one_gene_per_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2547
https://github.com/scverse/scanpy/issues/2547:2238,Safety,avoid,avoid,2238,"le_genes_single_batch(; 441 adata,; 442 layer=layer,; 443 min_disp=min_disp,; 444 max_disp=max_disp,; 445 min_mean=min_mean,; 446 max_mean=max_mean,; 447 n_top_genes=n_top_genes,; 448 n_bins=n_bins,; 449 flavor=flavor,; 450 ); 451 else:; 452 sanitize_anndata(adata). File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/scanpy/preprocessing/_highly_variable_genes.py:223, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 219 # retrieve those genes that have nan std, these are the ones where; 220 # only a single gene fell in the bin and implicitly set them to have; 221 # a normalized disperion of 1; 222 one_gene_per_bin = disp_std_bin.isnull(); --> 223 gen_indices = np.where(one_gene_per_bin[df['mean_bin'].values])[0].tolist(); 224 if len(gen_indices) > 0:; 225 logg.debug(; 226 f'Gene indices {gen_indices} fell into a single bin: their '; 227 'normalized dispersion was set to 1.\n '; 228 'Decreasing `n_bins` will likely avoid this effect.'; 229 ). File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/pandas/core/series.py:1033, in Series.__getitem__(self, key); 1030 key = np.asarray(key, dtype=bool); 1031 return self._get_values(key); -> 1033 return self._get_with(key). File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/pandas/core/series.py:1073, in Series._get_with(self, key); 1070 return self.iloc[key]; 1072 # handle the dup indexing case GH#4246; -> 1073 return self.loc[key]. File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/pandas/core/indexing.py:1103, in _LocationIndexer.__getitem__(self, key); 1100 axis = self.axis or 0; 1102 maybe_callable = com.apply_if_callable(key, self.obj); -> 1103 return self._getitem_axis(maybe_callable, axis=axis). File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/pandas/core/indexing.py:1332, in _LocIndexer._getitem_axis(self, key, axis); 1329 if hasattr(key, ""ndim"") and key.ndim > 1:; 1330 raise ValueError(""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2547
https://github.com/scverse/scanpy/issues/2547:2076,Testability,log,logg,2076,"); 428 return _highly_variable_genes_seurat_v3(; 429 adata,; 430 layer=layer,; (...); 436 inplace=inplace,; 437 ); 439 if batch_key is None:; --> 440 df = _highly_variable_genes_single_batch(; 441 adata,; 442 layer=layer,; 443 min_disp=min_disp,; 444 max_disp=max_disp,; 445 min_mean=min_mean,; 446 max_mean=max_mean,; 447 n_top_genes=n_top_genes,; 448 n_bins=n_bins,; 449 flavor=flavor,; 450 ); 451 else:; 452 sanitize_anndata(adata). File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/scanpy/preprocessing/_highly_variable_genes.py:223, in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 219 # retrieve those genes that have nan std, these are the ones where; 220 # only a single gene fell in the bin and implicitly set them to have; 221 # a normalized disperion of 1; 222 one_gene_per_bin = disp_std_bin.isnull(); --> 223 gen_indices = np.where(one_gene_per_bin[df['mean_bin'].values])[0].tolist(); 224 if len(gen_indices) > 0:; 225 logg.debug(; 226 f'Gene indices {gen_indices} fell into a single bin: their '; 227 'normalized dispersion was set to 1.\n '; 228 'Decreasing `n_bins` will likely avoid this effect.'; 229 ). File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/pandas/core/series.py:1033, in Series.__getitem__(self, key); 1030 key = np.asarray(key, dtype=bool); 1031 return self._get_values(key); -> 1033 return self._get_with(key). File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/pandas/core/series.py:1073, in Series._get_with(self, key); 1070 return self.iloc[key]; 1072 # handle the dup indexing case GH#4246; -> 1073 return self.loc[key]. File /opt/conda/envs/cell2loc_env/lib/python3.11/site-packages/pandas/core/indexing.py:1103, in _LocationIndexer.__getitem__(self, key); 1100 axis = self.axis or 0; 1102 maybe_callable = com.apply_if_callable(key, self.obj); -> 1103 return self._getitem_axis(maybe_callable, axis=axis). File /opt/conda/envs/cell2loc_env/lib/pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2547
https://github.com/scverse/scanpy/pull/2548:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2548
https://github.com/scverse/scanpy/pull/2548:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2548
https://github.com/scverse/scanpy/pull/2549:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2549
https://github.com/scverse/scanpy/pull/2549:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2549
https://github.com/scverse/scanpy/issues/2550:396,Testability,log,logfoldchanges,396,"### What kind of feature would you like to request?. Additional function parameters . ### Please describe your wishes. Recently I ran `sc.tl.rank_genes_groups(adata_t, 'leiden_res1', method='wilcoxon', pts=True)` on my datasets, then I plot `sc.pl.rank_genes_groups(adata_t, n_genes=25, sharey=False, ncols=3, )`. . I found ribo genes rank top in some groups. Then I want to filtering results by logfoldchanges, pvals_adj, like Seurat's `FindAllMarkers` did, so I ran `sc.get.rank_genes_groups_df(adata_t, group=None, pval_cutoff=0.01, log2fc_min=1)`, and the ribo genes are filtered successfully. Can function `sc.pl.rank_genes_groups` add filtering params lilke pvals_adj, pct_nt_group, pct_nz_reference which are really useful to filter meaningless genes?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2550
https://github.com/scverse/scanpy/issues/2551:458,Availability,error,error,458,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi there , I encountered a problem while using sc.read_h5ad to read the ""ReplogleWeissman2022_K562_essential.h5ad ""datasets . At first I supposed it is an AnnDataRead error: Above error raised while reading key '/X' of type <class 'h5py._hl.dataset.Dataset'> from /. ; But now I believe the main reason is MemoryError : Unable to allocate 9.90 GiB for an array with shape (310385, 8563) and data type float32 . However, I am running this on a server with about 100 GB of memory , this problem really bothers me , could you please help me with that? Thank you very much !. ### Minimal code sample. ```python; import anndata; import pandas as pd; import scanpy as sc; annData = sc.read_h5ad(""ReplogleWeissman2022_K562_essential.h5ad""); ```. ### Error output. ```pytb; MemoryError Traceback (most recent call last); File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error.<locals>.func_wrapper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File D:\Python3.10.9\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad.<locals>.callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\methods.py:323, in read_array(elem, _reader); 319 @_REGISTRY.register_read(H5Array, IOSpec(""array"", ""0.2.0"")); 320 @_REGISTRY.register_read(ZarrArray, IOSpec(""array"", ""0.2.0"")); 321 @_REGISTRY.regist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551
https://github.com/scverse/scanpy/issues/2551:471,Availability,error,error,471,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi there , I encountered a problem while using sc.read_h5ad to read the ""ReplogleWeissman2022_K562_essential.h5ad ""datasets . At first I supposed it is an AnnDataRead error: Above error raised while reading key '/X' of type <class 'h5py._hl.dataset.Dataset'> from /. ; But now I believe the main reason is MemoryError : Unable to allocate 9.90 GiB for an array with shape (310385, 8563) and data type float32 . However, I am running this on a server with about 100 GB of memory , this problem really bothers me , could you please help me with that? Thank you very much !. ### Minimal code sample. ```python; import anndata; import pandas as pd; import scanpy as sc; annData = sc.read_h5ad(""ReplogleWeissman2022_K562_essential.h5ad""); ```. ### Error output. ```pytb; MemoryError Traceback (most recent call last); File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error.<locals>.func_wrapper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File D:\Python3.10.9\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad.<locals>.callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\methods.py:323, in read_array(elem, _reader); 319 @_REGISTRY.register_read(H5Array, IOSpec(""array"", ""0.2.0"")); 320 @_REGISTRY.register_read(ZarrArray, IOSpec(""array"", ""0.2.0"")); 321 @_REGISTRY.regist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551
https://github.com/scverse/scanpy/issues/2551:1034,Availability,Error,Error,1034,"are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi there , I encountered a problem while using sc.read_h5ad to read the ""ReplogleWeissman2022_K562_essential.h5ad ""datasets . At first I supposed it is an AnnDataRead error: Above error raised while reading key '/X' of type <class 'h5py._hl.dataset.Dataset'> from /. ; But now I believe the main reason is MemoryError : Unable to allocate 9.90 GiB for an array with shape (310385, 8563) and data type float32 . However, I am running this on a server with about 100 GB of memory , this problem really bothers me , could you please help me with that? Thank you very much !. ### Minimal code sample. ```python; import anndata; import pandas as pd; import scanpy as sc; annData = sc.read_h5ad(""ReplogleWeissman2022_K562_essential.h5ad""); ```. ### Error output. ```pytb; MemoryError Traceback (most recent call last); File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error.<locals>.func_wrapper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File D:\Python3.10.9\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad.<locals>.callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\methods.py:323, in read_array(elem, _reader); 319 @_REGISTRY.register_read(H5Array, IOSpec(""array"", ""0.2.0"")); 320 @_REGISTRY.register_read(ZarrArray, IOSpec(""array"", ""0.2.0"")); 321 @_REGISTRY.register_read(ZarrArray, IOSpec(""string-arr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551
https://github.com/scverse/scanpy/issues/2551:6427,Availability,error,error,6427,"rn AnnData(; 224 **{; 225 # This is covering up backwards compat in the anndata initializer; 226 # In most cases we should be able to call `func(elen[k])` instead; --> 227 k: read_dispatched(elem[k], callback); 228 for k in elem.keys(); 229 if not k.startswith(""raw.""); 230 }; 231 ); 232 elif elem_name.startswith(""/raw.""):; 233 return None. File D:\Python3.10.9\lib\site-packages\anndata\experimental\__init__.py:58, in read_dispatched(elem, callback); 54 from anndata._io.specs import Reader, _REGISTRY; 56 reader = Reader(_REGISTRY, callback=callback); ---> 58 return reader.read_elem(elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:204, in report_read_key_on_error.<locals>.func_wrapper(*args, **kwargs); 202 return func(*args, **kwargs); 203 except Exception as e:; --> 204 re_raise_error(e, elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:188, in report_read_key_on_error.<locals>.re_raise_error(e, elem); 186 else:; 187 parent = _get_parent(elem); --> 188 raise AnnDataReadError(; 189 f""Above error raised while reading key {elem.name!r} of ""; 190 f""type {type(elem)} from {parent}.""; 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.dataset.Dataset'> from /.; ```. ### Versions. <details>. ```; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; asttokens NA; astunparse 1.6.3; backcall 0.2.0; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; google NA; h5py 3.8.0; ipykernel 6.22.0; ipython_genutils 0.2.0; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.40.1; matplotlib 3.7.1; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; ntsecuritycon NA; numba 0.57.1; numpy 1.23.5; opt_einsum v3.3.0; packaging 23.1; pandas 2.0.0; parso 0.8.3; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.2.0; prompt_toolkit 3.0.38; psutil 5.9.5; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551
https://github.com/scverse/scanpy/issues/2551:6557,Availability,error,error,6557,"atched(elem[k], callback); 228 for k in elem.keys(); 229 if not k.startswith(""raw.""); 230 }; 231 ); 232 elif elem_name.startswith(""/raw.""):; 233 return None. File D:\Python3.10.9\lib\site-packages\anndata\experimental\__init__.py:58, in read_dispatched(elem, callback); 54 from anndata._io.specs import Reader, _REGISTRY; 56 reader = Reader(_REGISTRY, callback=callback); ---> 58 return reader.read_elem(elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:204, in report_read_key_on_error.<locals>.func_wrapper(*args, **kwargs); 202 return func(*args, **kwargs); 203 except Exception as e:; --> 204 re_raise_error(e, elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:188, in report_read_key_on_error.<locals>.re_raise_error(e, elem); 186 else:; 187 parent = _get_parent(elem); --> 188 raise AnnDataReadError(; 189 f""Above error raised while reading key {elem.name!r} of ""; 190 f""type {type(elem)} from {parent}.""; 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type <class 'h5py._hl.dataset.Dataset'> from /.; ```. ### Versions. <details>. ```; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; asttokens NA; astunparse 1.6.3; backcall 0.2.0; cffi 1.15.1; colorama 0.4.6; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; google NA; h5py 3.8.0; ipykernel 6.22.0; ipython_genutils 0.2.0; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.40.1; matplotlib 3.7.1; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; ntsecuritycon NA; numba 0.57.1; numpy 1.23.5; opt_einsum v3.3.0; packaging 23.1; pandas 2.0.0; parso 0.8.3; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.2.0; prompt_toolkit 3.0.38; psutil 5.9.5; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.0.9; pythoncom NA; pytz 2023.3; pywin32_bootstrap NA; pywin32_system32 NA; pywintypes NA; sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551
https://github.com/scverse/scanpy/issues/2551:621,Energy Efficiency,allocate,allocate,621,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi there , I encountered a problem while using sc.read_h5ad to read the ""ReplogleWeissman2022_K562_essential.h5ad ""datasets . At first I supposed it is an AnnDataRead error: Above error raised while reading key '/X' of type <class 'h5py._hl.dataset.Dataset'> from /. ; But now I believe the main reason is MemoryError : Unable to allocate 9.90 GiB for an array with shape (310385, 8563) and data type float32 . However, I am running this on a server with about 100 GB of memory , this problem really bothers me , could you please help me with that? Thank you very much !. ### Minimal code sample. ```python; import anndata; import pandas as pd; import scanpy as sc; annData = sc.read_h5ad(""ReplogleWeissman2022_K562_essential.h5ad""); ```. ### Error output. ```pytb; MemoryError Traceback (most recent call last); File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error.<locals>.func_wrapper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File D:\Python3.10.9\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad.<locals>.callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\methods.py:323, in read_array(elem, _reader); 319 @_REGISTRY.register_read(H5Array, IOSpec(""array"", ""0.2.0"")); 320 @_REGISTRY.register_read(ZarrArray, IOSpec(""array"", ""0.2.0"")); 321 @_REGISTRY.regist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551
https://github.com/scverse/scanpy/issues/2551:2587,Energy Efficiency,allocate,allocate,2587,"ib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad.<locals>.callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\methods.py:323, in read_array(elem, _reader); 319 @_REGISTRY.register_read(H5Array, IOSpec(""array"", ""0.2.0"")); 320 @_REGISTRY.register_read(ZarrArray, IOSpec(""array"", ""0.2.0"")); 321 @_REGISTRY.register_read(ZarrArray, IOSpec(""string-array"", ""0.2.0"")); 322 def read_array(elem, _reader):; --> 323 return elem[()]. File h5py\_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py\_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File D:\Python3.10.9\lib\site-packages\h5py\_hl\dataset.py:768, in Dataset.__getitem__(self, args, new_dtype); 767 try:; --> 768 return self._fast_reader.read(args); 769 except TypeError:. File h5py\_selector.pyx:368, in h5py._selector.Reader.read(). File h5py\_selector.pyx:342, in h5py._selector.Reader.make_array(). MemoryError: Unable to allocate 9.90 GiB for an array with shape (310385, 8563) and data type float32. The above exception was the direct cause of the following exception:. AnnDataReadError Traceback (most recent call last); Cell In[2], line 4; 2 import pandas as pd; 3 import scanpy as sc; ----> 4 annData = sc.read_h5ad(""ReplogleWeissman2022_K562_essential.h5ad""). File D:\Python3.10.9\lib\site-packages\anndata\_io\h5ad.py:243, in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 240 return read_dataframe(elem); 241 return func(elem); --> 243 adata = read_dispatched(f, callback=callback); 245 # Backwards compat (should figure out which version); 246 if ""raw.X"" in f:. File D:\Python3.10.9\lib\site-packages\anndata\experimental\__init__.py:58, in read_dispatched(elem, callback); 54 from anndata._io.specs import Reader, _REGISTRY; 56 reader = Reader(_REGISTRY, callback=callback); ---> 58 return reader.read_elem(elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\utils.py:204, in repo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551
https://github.com/scverse/scanpy/issues/2551:2169,Integrability,wrap,wrapper,2169,"port_read_key_on_error.<locals>.func_wrapper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File D:\Python3.10.9\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad.<locals>.callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\methods.py:323, in read_array(elem, _reader); 319 @_REGISTRY.register_read(H5Array, IOSpec(""array"", ""0.2.0"")); 320 @_REGISTRY.register_read(ZarrArray, IOSpec(""array"", ""0.2.0"")); 321 @_REGISTRY.register_read(ZarrArray, IOSpec(""string-array"", ""0.2.0"")); 322 def read_array(elem, _reader):; --> 323 return elem[()]. File h5py\_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py\_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File D:\Python3.10.9\lib\site-packages\h5py\_hl\dataset.py:768, in Dataset.__getitem__(self, args, new_dtype); 767 try:; --> 768 return self._fast_reader.read(args); 769 except TypeError:. File h5py\_selector.pyx:368, in h5py._selector.Reader.read(). File h5py\_selector.pyx:342, in h5py._selector.Reader.make_array(). MemoryError: Unable to allocate 9.90 GiB for an array with shape (310385, 8563) and data type float32. The above exception was the direct cause of the following exception:. AnnDataReadError Traceback (most recent call last); Cell In[2], line 4; 2 import pandas as pd; 3 import scanpy as sc; ----> 4 annData = sc.read_h5ad(""ReplogleWeissman2022_K562_essential.h5ad""). File D:\Python3.10.9\lib\site-packages\anndata\_io\h5ad.py:243, in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 240 return read_dataframe(elem); 241 return func(elem); --> 243 adata = read_dispatched(f, callback=callback)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551
https://github.com/scverse/scanpy/issues/2551:2234,Integrability,wrap,wrapper,2234,"1 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File D:\Python3.10.9\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad.<locals>.callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File D:\Python3.10.9\lib\site-packages\anndata\_io\specs\methods.py:323, in read_array(elem, _reader); 319 @_REGISTRY.register_read(H5Array, IOSpec(""array"", ""0.2.0"")); 320 @_REGISTRY.register_read(ZarrArray, IOSpec(""array"", ""0.2.0"")); 321 @_REGISTRY.register_read(ZarrArray, IOSpec(""string-array"", ""0.2.0"")); 322 def read_array(elem, _reader):; --> 323 return elem[()]. File h5py\_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py\_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File D:\Python3.10.9\lib\site-packages\h5py\_hl\dataset.py:768, in Dataset.__getitem__(self, args, new_dtype); 767 try:; --> 768 return self._fast_reader.read(args); 769 except TypeError:. File h5py\_selector.pyx:368, in h5py._selector.Reader.read(). File h5py\_selector.pyx:342, in h5py._selector.Reader.make_array(). MemoryError: Unable to allocate 9.90 GiB for an array with shape (310385, 8563) and data type float32. The above exception was the direct cause of the following exception:. AnnDataReadError Traceback (most recent call last); Cell In[2], line 4; 2 import pandas as pd; 3 import scanpy as sc; ----> 4 annData = sc.read_h5ad(""ReplogleWeissman2022_K562_essential.h5ad""). File D:\Python3.10.9\lib\site-packages\anndata\_io\h5ad.py:243, in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size); 240 return read_dataframe(elem); 241 return func(elem); --> 243 adata = read_dispatched(f, callback=callback); 245 # Backwards compat (should figure out which version); 246 i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2551
https://github.com/scverse/scanpy/pull/2553:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.276  v0.0.277](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.276...v0.0.277); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2553
https://github.com/scverse/scanpy/issues/2555:108,Performance,cache,cache,108,### What kind of feature would you like to request?. Other?. ### Please describe your wishes. - maybe use [`cache.mkdir()`](https://docs.pytest.org/en/7.1.x/reference/reference.html#std-fixture-cache) for persistent files (data); - set directory to read only in CI during test run,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2555
https://github.com/scverse/scanpy/issues/2555:194,Performance,cache,cache,194,### What kind of feature would you like to request?. Other?. ### Please describe your wishes. - maybe use [`cache.mkdir()`](https://docs.pytest.org/en/7.1.x/reference/reference.html#std-fixture-cache) for persistent files (data); - set directory to read only in CI during test run,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2555
https://github.com/scverse/scanpy/issues/2555:272,Testability,test,test,272,### What kind of feature would you like to request?. Other?. ### Please describe your wishes. - maybe use [`cache.mkdir()`](https://docs.pytest.org/en/7.1.x/reference/reference.html#std-fixture-cache) for persistent files (data); - set directory to read only in CI during test run,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2555
https://github.com/scverse/scanpy/issues/2556:998,Availability,Error,Error,998,"# Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. I have two different datasets, both with raw counts. After using the function `sc.pp.normalize_total` and `sc.pp.log1p` and plotting the data with UMAP coordinates, there is no gene expression in cells coming from one of the datasets. I did the analysis separately (without concatenating) and the same happens. . I thought that maybe is a problem with the data type, but when I checked this, both anndatas.X were np.float32 and sparse.csr_matrixes ( #1612 ). Also, I made sure the anndata matrix related to the problematic dataset has acceptable values and they are not zeros. Any idea about this problem?. ### Minimal code sample. ```python; sc.pp.normalize_total(adata); sc.pp.log1p(adata); ```. ### Error output. _No response_. ### Versions. <details>. ```; anndata 0.9.1; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 9.1.0; anyio NA; astunparse 1.6.3; attr 21.2.0; babel 2.9.1; backcall 0.2.0; brotli NA; certifi 2022.12.07; cffi 1.15.0; charset_normalizer 2.0.12; cloudpickle 2.0.0; cycler 0.10.0; cython_runtime NA; dask 2022.8.1; dateutil 2.8.2; debugpy 1.6.0; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.4; fastjsonschema NA; fsspec 2022.7.1; google NA; h5py 3.4.0; idna 3.3; igraph 0.9.6; ipykernel 6.4.0; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.11.0; jupyterlab_server 2.8.1; kiwisolver 1.3.2; leidenalg 0.8.7; llvmlite 0.38.0; louvain 0.7.0; markupsafe 2.1.1; matplotlib 3.6.0; mpl_toolkits NA; mpmath 1.3.0; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.55.1; numexpr 2.7.3; numpy 1.21.6; nvfuser NA; opt_einsum v3.3.0; packaging 23.1; pandas 1.5.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2556
https://github.com/scverse/scanpy/issues/2556:2326,Usability,simpl,simplejson,2326,code sample. ```python; sc.pp.normalize_total(adata); sc.pp.log1p(adata); ```. ### Error output. _No response_. ### Versions. <details>. ```; anndata 0.9.1; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 9.1.0; anyio NA; astunparse 1.6.3; attr 21.2.0; babel 2.9.1; backcall 0.2.0; brotli NA; certifi 2022.12.07; cffi 1.15.0; charset_normalizer 2.0.12; cloudpickle 2.0.0; cycler 0.10.0; cython_runtime NA; dask 2022.8.1; dateutil 2.8.2; debugpy 1.6.0; decorator 5.0.9; defusedxml 0.7.1; entrypoints 0.4; fastjsonschema NA; fsspec 2022.7.1; google NA; h5py 3.4.0; idna 3.3; igraph 0.9.6; ipykernel 6.4.0; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.11.0; jupyterlab_server 2.8.1; kiwisolver 1.3.2; leidenalg 0.8.7; llvmlite 0.38.0; louvain 0.7.0; markupsafe 2.1.1; matplotlib 3.6.0; mpl_toolkits NA; mpmath 1.3.0; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.55.1; numexpr 2.7.3; numpy 1.21.6; nvfuser NA; opt_einsum v3.3.0; packaging 23.1; pandas 1.5.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.31; psutil 5.9.0; ptyprocess 0.7.0; pvectorc NA; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 2.4.7; pyrsistent NA; pytz 2022.2.1; requests 2.28.1; scipy 1.10.1; send2trash NA; setuptools 67.8.0; simplejson 3.17.6; six 1.16.0; sklearn 1.2.2; sniffio 1.2.0; socks 1.7.1; sparse 0.14.0; storemagic NA; sympy 1.12; tables 3.6.1; tblib 1.7.0; terminado 0.12.1; texttable 1.6.4; threadpoolctl 2.2.0; tlz 0.12.0; toolz 0.12.0; torch 2.0.1+cu117; tornado 6.1; tqdm 4.62.2; traitlets 5.1.0; typing_extensions NA; unicodedata2 NA; urllib3 1.26.9; wcwidth 0.2.5; websocket 1.3.2; yaml 6.0; zipp NA; zmq 22.3.0; zstandard 0.18.0; -----; IPython 7.34.0; jupyter_client 7.3.0; jupyter_core 4.10.0; jupyterlab 3.1.11; notebook 6.4.11; -----; Python 3.8.13 | packaged by conda-forge ; ```. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2556
https://github.com/scverse/scanpy/pull/2560:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/psf/black: 23.3.0  23.7.0](https://github.com/psf/black/compare/23.3.0...23.7.0); - [github.com/astral-sh/ruff-pre-commit: v0.0.277  v0.0.278](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.277...v0.0.278); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2560
https://github.com/scverse/scanpy/issues/2562:785,Availability,Error,Error,785,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I've noticed that `pyproject.toml` refers to the `python-igraph` package in the PyPI repository. This name is deprecated; the `igraph` package is currently called [`igraph`](https://pypi.org/project/igraph). The old package name currently works as a redirect (i.e. it brings in `igraph` as its own sub-dependency), but it will not be maintained in the future. Please switch to referring to `igraph` in `pyproject.toml` and not `python-igraph`. ### Minimal code sample. ```python; N/A; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 10.0.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; h5py 3.9.0; joblib 1.3.1; kiwisolver 1.4.4; llvmlite 0.40.1; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 23.1; pandas 2.0.3; pyparsing 3.0.9; pytz 2023.3; scipy 1.11.1; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.3.0; threadpoolctl 3.2.0; -----; Python 3.11.4 (main, Jun 20 2023, 17:23:00) [Clang 14.0.3 (clang-1403.0.22.14.1)]; macOS-13.2.1-arm64-arm-64bit; -----; Session information updated at 2023-07-19 13:34; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2562
https://github.com/scverse/scanpy/issues/2562:1395,Deployability,update,updated,1395,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I've noticed that `pyproject.toml` refers to the `python-igraph` package in the PyPI repository. This name is deprecated; the `igraph` package is currently called [`igraph`](https://pypi.org/project/igraph). The old package name currently works as a redirect (i.e. it brings in `igraph` as its own sub-dependency), but it will not be maintained in the future. Please switch to referring to `igraph` in `pyproject.toml` and not `python-igraph`. ### Minimal code sample. ```python; N/A; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 10.0.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; h5py 3.9.0; joblib 1.3.1; kiwisolver 1.4.4; llvmlite 0.40.1; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 23.1; pandas 2.0.3; pyparsing 3.0.9; pytz 2023.3; scipy 1.11.1; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.3.0; threadpoolctl 3.2.0; -----; Python 3.11.4 (main, Jun 20 2023, 17:23:00) [Clang 14.0.3 (clang-1403.0.22.14.1)]; macOS-13.2.1-arm64-arm-64bit; -----; Session information updated at 2023-07-19 13:34; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2562
https://github.com/scverse/scanpy/issues/2562:593,Integrability,depend,dependency,593,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I've noticed that `pyproject.toml` refers to the `python-igraph` package in the PyPI repository. This name is deprecated; the `igraph` package is currently called [`igraph`](https://pypi.org/project/igraph). The old package name currently works as a redirect (i.e. it brings in `igraph` as its own sub-dependency), but it will not be maintained in the future. Please switch to referring to `igraph` in `pyproject.toml` and not `python-igraph`. ### Minimal code sample. ```python; N/A; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 10.0.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; h5py 3.9.0; joblib 1.3.1; kiwisolver 1.4.4; llvmlite 0.40.1; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 23.1; pandas 2.0.3; pyparsing 3.0.9; pytz 2023.3; scipy 1.11.1; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.3.0; threadpoolctl 3.2.0; -----; Python 3.11.4 (main, Jun 20 2023, 17:23:00) [Clang 14.0.3 (clang-1403.0.22.14.1)]; macOS-13.2.1-arm64-arm-64bit; -----; Session information updated at 2023-07-19 13:34; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2562
https://github.com/scverse/scanpy/pull/2563:201,Availability,Ping,Pinging,201,"Hi,. Just wanted to start the PR. Passes the tests except one. Also need to deal with solver names since they don't correspond to anything dask uses. Also refactored where the DaskArray mock class is. Pinging @ivirshup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2563
https://github.com/scverse/scanpy/pull/2563:155,Modifiability,refactor,refactored,155,"Hi,. Just wanted to start the PR. Passes the tests except one. Also need to deal with solver names since they don't correspond to anything dask uses. Also refactored where the DaskArray mock class is. Pinging @ivirshup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2563
https://github.com/scverse/scanpy/pull/2563:45,Testability,test,tests,45,"Hi,. Just wanted to start the PR. Passes the tests except one. Also need to deal with solver names since they don't correspond to anything dask uses. Also refactored where the DaskArray mock class is. Pinging @ivirshup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2563
https://github.com/scverse/scanpy/pull/2563:186,Testability,mock,mock,186,"Hi,. Just wanted to start the PR. Passes the tests except one. Also need to deal with solver names since they don't correspond to anything dask uses. Also refactored where the DaskArray mock class is. Pinging @ivirshup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2563
https://github.com/scverse/scanpy/issues/2564:418,Availability,error,error,418,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I installed scanpy as the first package in a brand new conda environment. This worked fine but when importing scanpy I get the error below. It sounds like this is because as of pandas 2.0 `is_categorical` is deprecated: https://stackoverflow.com/questions/76234312/importerror-cannot-import-name-is-categorical-from-pandas-api-types. This issue is also fixed when I downgrade pandas to 1.5.3. ### Minimal code sample. ```python; import scanpy as sc; ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); Untitled-1.ipynb Cell 20 in <cell line: 1>(); ----> 1 import scanpy as sc. File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/__init__.py:18, in <module>; 16 from . import preprocessing as pp; 17 from . import plotting as pl; ---> 18 from . import datasets, logging, queries, external, get; 20 from anndata import AnnData, concat; 21 from anndata import (; 22 read_h5ad,; 23 read_csv,; (...); 29 read_umi_tools,; 30 ). File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/external/__init__.py:4, in <module>; 2 from . import pl; 3 from . import pp; ----> 4 from . import exporting; 6 import sys; 7 from .. import _utils. File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/external/exporting.py:14, in <module>; 12 import matplotlib.pyplot as plt; 13 from anndata import AnnData; ---> 14 from pandas.api.types import is_categorical; 16 from ..preprocessing._utils import _get_mean_var; 17 from .._utils import NeighborsView. ImportError: cannot import name 'is_categorical' from 'pandas.api.types' (/Users/michael/mambaforge/envs/basic_comp_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2564
https://github.com/scverse/scanpy/issues/2564:657,Availability,down,downgrade,657,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I installed scanpy as the first package in a brand new conda environment. This worked fine but when importing scanpy I get the error below. It sounds like this is because as of pandas 2.0 `is_categorical` is deprecated: https://stackoverflow.com/questions/76234312/importerror-cannot-import-name-is-categorical-from-pandas-api-types. This issue is also fixed when I downgrade pandas to 1.5.3. ### Minimal code sample. ```python; import scanpy as sc; ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); Untitled-1.ipynb Cell 20 in <cell line: 1>(); ----> 1 import scanpy as sc. File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/__init__.py:18, in <module>; 16 from . import preprocessing as pp; 17 from . import plotting as pl; ---> 18 from . import datasets, logging, queries, external, get; 20 from anndata import AnnData, concat; 21 from anndata import (; 22 read_h5ad,; 23 read_csv,; (...); 29 read_umi_tools,; 30 ). File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/external/__init__.py:4, in <module>; 2 from . import pl; 3 from . import pp; ----> 4 from . import exporting; 6 import sys; 7 from .. import _utils. File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/external/exporting.py:14, in <module>; 12 import matplotlib.pyplot as plt; 13 from anndata import AnnData; ---> 14 from pandas.api.types import is_categorical; 16 from ..preprocessing._utils import _get_mean_var; 17 from .._utils import NeighborsView. ImportError: cannot import name 'is_categorical' from 'pandas.api.types' (/Users/michael/mambaforge/envs/basic_comp_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2564
https://github.com/scverse/scanpy/issues/2564:750,Availability,Error,Error,750,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I installed scanpy as the first package in a brand new conda environment. This worked fine but when importing scanpy I get the error below. It sounds like this is because as of pandas 2.0 `is_categorical` is deprecated: https://stackoverflow.com/questions/76234312/importerror-cannot-import-name-is-categorical-from-pandas-api-types. This issue is also fixed when I downgrade pandas to 1.5.3. ### Minimal code sample. ```python; import scanpy as sc; ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); Untitled-1.ipynb Cell 20 in <cell line: 1>(); ----> 1 import scanpy as sc. File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/__init__.py:18, in <module>; 16 from . import preprocessing as pp; 17 from . import plotting as pl; ---> 18 from . import datasets, logging, queries, external, get; 20 from anndata import AnnData, concat; 21 from anndata import (; 22 read_h5ad,; 23 read_csv,; (...); 29 read_umi_tools,; 30 ). File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/external/__init__.py:4, in <module>; 2 from . import pl; 3 from . import pp; ----> 4 from . import exporting; 6 import sys; 7 from .. import _utils. File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/external/exporting.py:14, in <module>; 12 import matplotlib.pyplot as plt; 13 from anndata import AnnData; ---> 14 from pandas.api.types import is_categorical; 16 from ..preprocessing._utils import _get_mean_var; 17 from .._utils import NeighborsView. ImportError: cannot import name 'is_categorical' from 'pandas.api.types' (/Users/michael/mambaforge/envs/basic_comp_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2564
https://github.com/scverse/scanpy/issues/2564:293,Deployability,install,installed,293,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I installed scanpy as the first package in a brand new conda environment. This worked fine but when importing scanpy I get the error below. It sounds like this is because as of pandas 2.0 `is_categorical` is deprecated: https://stackoverflow.com/questions/76234312/importerror-cannot-import-name-is-categorical-from-pandas-api-types. This issue is also fixed when I downgrade pandas to 1.5.3. ### Minimal code sample. ```python; import scanpy as sc; ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); Untitled-1.ipynb Cell 20 in <cell line: 1>(); ----> 1 import scanpy as sc. File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/__init__.py:18, in <module>; 16 from . import preprocessing as pp; 17 from . import plotting as pl; ---> 18 from . import datasets, logging, queries, external, get; 20 from anndata import AnnData, concat; 21 from anndata import (; 22 read_h5ad,; 23 read_csv,; (...); 29 read_umi_tools,; 30 ). File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/external/__init__.py:4, in <module>; 2 from . import pl; 3 from . import pp; ----> 4 from . import exporting; 6 import sys; 7 from .. import _utils. File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/external/exporting.py:14, in <module>; 12 import matplotlib.pyplot as plt; 13 from anndata import AnnData; ---> 14 from pandas.api.types import is_categorical; 16 from ..preprocessing._utils import _get_mean_var; 17 from .._utils import NeighborsView. ImportError: cannot import name 'is_categorical' from 'pandas.api.types' (/Users/michael/mambaforge/envs/basic_comp_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2564
https://github.com/scverse/scanpy/issues/2564:4016,Integrability,wrap,wrap,4016,-forge; debugpy 1.5.1 py39hc377ac9_0 anaconda; decorator 5.1.1 pyhd3eb1b0_0 anaconda; dunamai 1.18.0 pyhd8ed1ab_0 conda-forge; entrypoints 0.4 py39hca03da5_0 anaconda; executing 0.8.3 pyhd3eb1b0_0 anaconda; fonttools 4.41.0 py39h0f82c59_0 conda-forge; freetype 2.12.1 hd633e50_1 conda-forge; get_version 3.5.4 pyhd8ed1ab_0 conda-forge; gettext 0.21.1 h0186832_0 conda-forge; git 2.41.0 pl5321h46e2b6d_0 conda-forge; h5py 3.9.0 nompi_py39he9c2634_101 conda-forge; hdf5 1.14.1 nompi_h3aba7b3_100 conda-forge; idna 3.4 pyhd8ed1ab_0 conda-forge; importlib-metadata 6.8.0 pyha770c72_0 conda-forge; importlib_metadata 6.8.0 hd8ed1ab_0 conda-forge; ipykernel 6.9.1 py39hca03da5_0 anaconda; ipython 8.3.0 py39hca03da5_0 anaconda; jedi 0.18.1 py39hca03da5_1 anaconda; joblib 1.3.0 pyhd8ed1ab_1 conda-forge; jupyter_client 7.2.2 py39hca03da5_0 anaconda; jupyter_core 4.10.0 py39hca03da5_0 anaconda; kiwisolver 1.4.4 py39haaf3ac1_1 conda-forge; krb5 1.21.1 h92f50d5_0 conda-forge; lcms2 2.15 hd835a16_1 conda-forge; legacy-api-wrap 1.2 py_0 conda-forge; lerc 4.0.0 h9a09cb3_0 conda-forge; libaec 1.0.6 hb7217d7_1 conda-forge; libblas 3.9.0 17_osxarm64_openblas conda-forge; libbrotlicommon 1.0.9 h1a8c8d9_9 conda-forge; libbrotlidec 1.0.9 h1a8c8d9_9 conda-forge; libbrotlienc 1.0.9 h1a8c8d9_9 conda-forge; libcblas 3.9.0 17_osxarm64_openblas conda-forge; libcurl 8.1.2 hc52a3a8_1 conda-forge; libcxx 16.0.6 h4653b0c_0 conda-forge; libdeflate 1.18 h1a8c8d9_0 conda-forge; libedit 3.1.20191231 hc8eb9b7_2 conda-forge; libev 4.33 h642e427_1 conda-forge; libexpat 2.5.0 hb7217d7_1 conda-forge; libffi 3.4.2 h3422bc3_5 conda-forge; libgfortran 5.0.0 12_2_0_hd922786_31 conda-forge; libgfortran5 12.2.0 h0eea778_31 conda-forge; libiconv 1.17 he4db4b2_0 conda-forge; libjpeg-turbo 2.1.5.1 h1a8c8d9_0 conda-forge; liblapack 3.9.0 17_osxarm64_openblas conda-forge; libllvm14 14.0.6 hd1a9a77_3 conda-forge; libnghttp2 1.52.0 hae82a92_0 conda-forge; libopenblas 0.3.23 openmp_hc731615_0 conda-forge; libpng 1.6.39 h76d750c_,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2564
https://github.com/scverse/scanpy/issues/2564:2704,Performance,cache,cached-property,2704,s plt; 13 from anndata import AnnData; ---> 14 from pandas.api.types import is_categorical; 16 from ..preprocessing._utils import _get_mean_var; 17 from .._utils import NeighborsView. ImportError: cannot import name 'is_categorical' from 'pandas.api.types' (/Users/michael/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/pandas/api/types/__init__.py); ```. ### Versions. <details>. ```; conda list; # packages in environment at /Users/michael/mambaforge/envs/basic_comp_bio:; #; # Name Version Build Channel; anndata 0.9.1 pyhd8ed1ab_0 conda-forge; appnope 0.1.2 py39hca03da5_1001 anaconda; asttokens 2.0.5 pyhd3eb1b0_0 anaconda; backcall 0.2.0 pyhd3eb1b0_0 anaconda; blosc 1.21.4 hc338f07_0 conda-forge; brotli 1.0.9 h1a8c8d9_9 conda-forge; brotli-bin 1.0.9 h1a8c8d9_9 conda-forge; brotli-python 1.0.9 py39h23fbdae_9 conda-forge; bzip2 1.0.8 h3422bc3_4 conda-forge; c-ares 1.19.1 hb547adb_0 conda-forge; c-blosc2 2.10.0 h068da5f_0 conda-forge; ca-certificates 2022.4.26 hca03da5_0 anaconda; cached-property 1.5.2 hd8ed1ab_1 conda-forge; cached_property 1.5.2 pyha770c72_1 conda-forge; certifi 2022.6.15 py39hca03da5_0 anaconda; charset-normalizer 3.2.0 pyhd8ed1ab_0 conda-forge; colorama 0.4.6 pyhd8ed1ab_0 conda-forge; curl 8.1.2 hc52a3a8_1 conda-forge; cycler 0.11.0 pyhd8ed1ab_0 conda-forge; debugpy 1.5.1 py39hc377ac9_0 anaconda; decorator 5.1.1 pyhd3eb1b0_0 anaconda; dunamai 1.18.0 pyhd8ed1ab_0 conda-forge; entrypoints 0.4 py39hca03da5_0 anaconda; executing 0.8.3 pyhd3eb1b0_0 anaconda; fonttools 4.41.0 py39h0f82c59_0 conda-forge; freetype 2.12.1 hd633e50_1 conda-forge; get_version 3.5.4 pyhd8ed1ab_0 conda-forge; gettext 0.21.1 h0186832_0 conda-forge; git 2.41.0 pl5321h46e2b6d_0 conda-forge; h5py 3.9.0 nompi_py39he9c2634_101 conda-forge; hdf5 1.14.1 nompi_h3aba7b3_100 conda-forge; idna 3.4 pyhd8ed1ab_0 conda-forge; importlib-metadata 6.8.0 pyha770c72_0 conda-forge; importlib_metadata 6.8.0 hd8ed1ab_0 conda-forge; ipykernel 6.9.1 py39hca03da5_0 anaconda; ipython 8.3.0 py39,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2564
https://github.com/scverse/scanpy/issues/2564:2660,Security,certificate,certificates,2660,":14, in <module>; 12 import matplotlib.pyplot as plt; 13 from anndata import AnnData; ---> 14 from pandas.api.types import is_categorical; 16 from ..preprocessing._utils import _get_mean_var; 17 from .._utils import NeighborsView. ImportError: cannot import name 'is_categorical' from 'pandas.api.types' (/Users/michael/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/pandas/api/types/__init__.py); ```. ### Versions. <details>. ```; conda list; # packages in environment at /Users/michael/mambaforge/envs/basic_comp_bio:; #; # Name Version Build Channel; anndata 0.9.1 pyhd8ed1ab_0 conda-forge; appnope 0.1.2 py39hca03da5_1001 anaconda; asttokens 2.0.5 pyhd3eb1b0_0 anaconda; backcall 0.2.0 pyhd3eb1b0_0 anaconda; blosc 1.21.4 hc338f07_0 conda-forge; brotli 1.0.9 h1a8c8d9_9 conda-forge; brotli-bin 1.0.9 h1a8c8d9_9 conda-forge; brotli-python 1.0.9 py39h23fbdae_9 conda-forge; bzip2 1.0.8 h3422bc3_4 conda-forge; c-ares 1.19.1 hb547adb_0 conda-forge; c-blosc2 2.10.0 h068da5f_0 conda-forge; ca-certificates 2022.4.26 hca03da5_0 anaconda; cached-property 1.5.2 hd8ed1ab_1 conda-forge; cached_property 1.5.2 pyha770c72_1 conda-forge; certifi 2022.6.15 py39hca03da5_0 anaconda; charset-normalizer 3.2.0 pyhd8ed1ab_0 conda-forge; colorama 0.4.6 pyhd8ed1ab_0 conda-forge; curl 8.1.2 hc52a3a8_1 conda-forge; cycler 0.11.0 pyhd8ed1ab_0 conda-forge; debugpy 1.5.1 py39hc377ac9_0 anaconda; decorator 5.1.1 pyhd3eb1b0_0 anaconda; dunamai 1.18.0 pyhd8ed1ab_0 conda-forge; entrypoints 0.4 py39hca03da5_0 anaconda; executing 0.8.3 pyhd3eb1b0_0 anaconda; fonttools 4.41.0 py39h0f82c59_0 conda-forge; freetype 2.12.1 hd633e50_1 conda-forge; get_version 3.5.4 pyhd8ed1ab_0 conda-forge; gettext 0.21.1 h0186832_0 conda-forge; git 2.41.0 pl5321h46e2b6d_0 conda-forge; h5py 3.9.0 nompi_py39he9c2634_101 conda-forge; hdf5 1.14.1 nompi_h3aba7b3_100 conda-forge; idna 3.4 pyhd8ed1ab_0 conda-forge; importlib-metadata 6.8.0 pyha770c72_0 conda-forge; importlib_metadata 6.8.0 hd8ed1ab_0 conda-forge; ipykernel 6.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2564
https://github.com/scverse/scanpy/issues/2564:1177,Testability,log,logging,1177,"xists on the master branch of scanpy. ### What happened?. I installed scanpy as the first package in a brand new conda environment. This worked fine but when importing scanpy I get the error below. It sounds like this is because as of pandas 2.0 `is_categorical` is deprecated: https://stackoverflow.com/questions/76234312/importerror-cannot-import-name-is-categorical-from-pandas-api-types. This issue is also fixed when I downgrade pandas to 1.5.3. ### Minimal code sample. ```python; import scanpy as sc; ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); Untitled-1.ipynb Cell 20 in <cell line: 1>(); ----> 1 import scanpy as sc. File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/__init__.py:18, in <module>; 16 from . import preprocessing as pp; 17 from . import plotting as pl; ---> 18 from . import datasets, logging, queries, external, get; 20 from anndata import AnnData, concat; 21 from anndata import (; 22 read_h5ad,; 23 read_csv,; (...); 29 read_umi_tools,; 30 ). File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/external/__init__.py:4, in <module>; 2 from . import pl; 3 from . import pp; ----> 4 from . import exporting; 6 import sys; 7 from .. import _utils. File ~/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/scanpy/external/exporting.py:14, in <module>; 12 import matplotlib.pyplot as plt; 13 from anndata import AnnData; ---> 14 from pandas.api.types import is_categorical; 16 from ..preprocessing._utils import _get_mean_var; 17 from .._utils import NeighborsView. ImportError: cannot import name 'is_categorical' from 'pandas.api.types' (/Users/michael/mambaforge/envs/basic_comp_bio/lib/python3.9/site-packages/pandas/api/types/__init__.py); ```. ### Versions. <details>. ```; conda list; # packages in environment at /Users/michael/mambaforge/envs/basic_comp_bio:; #; # Name Version Build Channel; anndata 0.9.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2564
https://github.com/scverse/scanpy/issues/2564:6426,Testability,stub,stubs,6426,matplotlib-base 3.5.3 py39ha500c34_2 conda-forge; matplotlib-inline 0.1.2 pyhd3eb1b0_2 anaconda; munkres 1.0.7 py_1 bioconda; natsort 8.4.0 pyhd8ed1ab_0 conda-forge; ncurses 6.4 h7ea286d_0 conda-forge; nest-asyncio 1.5.5 py39hca03da5_0 anaconda; networkx 3.1 pyhd8ed1ab_0 conda-forge; numba 0.57.1 py39he8ed757_0 conda-forge; numexpr 2.8.4 py39hd28f0be_0 conda-forge; numpy 1.24.4 py39h485cf63_0 conda-forge; openjpeg 2.5.0 hbc2ba62_2 conda-forge; openssl 3.1.1 h53f4e23_1 conda-forge; packaging 23.1 pyhd8ed1ab_0 conda-forge; pandas 2.0.3 py39h6b13a34_1 conda-forge; parso 0.8.3 pyhd3eb1b0_0 anaconda; patsy 0.5.3 pyhd8ed1ab_0 conda-forge; pcre2 10.40 hb34f9b4_0 conda-forge; perl 5.32.1 4_hf2054a2_perl5 conda-forge; pexpect 4.8.0 pyhd3eb1b0_3 anaconda; pickleshare 0.7.5 pyhd3eb1b0_1003 anaconda; pillow 10.0.0 py39h1641143_0 conda-forge; pip 23.2 pyhd8ed1ab_0 conda-forge; platformdirs 3.9.1 pyhd8ed1ab_0 conda-forge; pooch 1.7.0 pyha770c72_3 conda-forge; prompt-toolkit 3.0.20 pyhd3eb1b0_0 anaconda; pthread-stubs 0.4 h27ca646_1001 conda-forge; ptyprocess 0.7.0 pyhd3eb1b0_2 anaconda; pure_eval 0.2.2 pyhd3eb1b0_0 anaconda; py-cpuinfo 9.0.0 pyhd8ed1ab_0 conda-forge; pygments 2.11.2 pyhd3eb1b0_0 anaconda; pynndescent 0.5.10 pyh1a96a4e_0 conda-forge; pyparsing 3.1.0 pyhd8ed1ab_0 conda-forge; pysocks 1.7.1 pyha2e5f31_6 conda-forge; pytables 3.8.0 py39h0da393b_2 conda-forge; python 3.9.16 hea58f1e_0_cpython conda-forge; python-dateutil 2.8.2 pyhd8ed1ab_0 conda-forge; python-tzdata 2023.3 pyhd8ed1ab_0 conda-forge; python_abi 3.9 3_cp39 conda-forge; pytz 2023.3 pyhd8ed1ab_0 conda-forge; pyzmq 22.3.0 py39hc377ac9_2 anaconda; readline 8.2 h92ec313_1 conda-forge; requests 2.31.0 pyhd8ed1ab_0 conda-forge; scanpy 1.7.2 pyhdfd78af_0 bioconda; scikit-learn 1.3.0 py39hd5c4a62_0 conda-forge; scipy 1.11.1 py39ha6b2cbd_0 conda-forge; seaborn 0.12.2 hd8ed1ab_0 conda-forge; seaborn-base 0.12.2 pyhd8ed1ab_0 conda-forge; setuptools 68.0.0 pyhd8ed1ab_0 conda-forge; setuptools-scm 7.1.0 pyhd8ed1ab_0 c,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2564
https://github.com/scverse/scanpy/issues/2564:7168,Usability,learn,learn,7168,_3 anaconda; pickleshare 0.7.5 pyhd3eb1b0_1003 anaconda; pillow 10.0.0 py39h1641143_0 conda-forge; pip 23.2 pyhd8ed1ab_0 conda-forge; platformdirs 3.9.1 pyhd8ed1ab_0 conda-forge; pooch 1.7.0 pyha770c72_3 conda-forge; prompt-toolkit 3.0.20 pyhd3eb1b0_0 anaconda; pthread-stubs 0.4 h27ca646_1001 conda-forge; ptyprocess 0.7.0 pyhd3eb1b0_2 anaconda; pure_eval 0.2.2 pyhd3eb1b0_0 anaconda; py-cpuinfo 9.0.0 pyhd8ed1ab_0 conda-forge; pygments 2.11.2 pyhd3eb1b0_0 anaconda; pynndescent 0.5.10 pyh1a96a4e_0 conda-forge; pyparsing 3.1.0 pyhd8ed1ab_0 conda-forge; pysocks 1.7.1 pyha2e5f31_6 conda-forge; pytables 3.8.0 py39h0da393b_2 conda-forge; python 3.9.16 hea58f1e_0_cpython conda-forge; python-dateutil 2.8.2 pyhd8ed1ab_0 conda-forge; python-tzdata 2023.3 pyhd8ed1ab_0 conda-forge; python_abi 3.9 3_cp39 conda-forge; pytz 2023.3 pyhd8ed1ab_0 conda-forge; pyzmq 22.3.0 py39hc377ac9_2 anaconda; readline 8.2 h92ec313_1 conda-forge; requests 2.31.0 pyhd8ed1ab_0 conda-forge; scanpy 1.7.2 pyhdfd78af_0 bioconda; scikit-learn 1.3.0 py39hd5c4a62_0 conda-forge; scipy 1.11.1 py39ha6b2cbd_0 conda-forge; seaborn 0.12.2 hd8ed1ab_0 conda-forge; seaborn-base 0.12.2 pyhd8ed1ab_0 conda-forge; setuptools 68.0.0 pyhd8ed1ab_0 conda-forge; setuptools-scm 7.1.0 pyhd8ed1ab_0 conda-forge; setuptools_scm 7.1.0 hd8ed1ab_0 conda-forge; sinfo 0.3.1 py_0 conda-forge; six 1.16.0 pyh6c4a22f_0 conda-forge; snappy 1.1.10 h17c5cce_0 conda-forge; stack_data 0.2.0 pyhd3eb1b0_0 anaconda; statsmodels 0.14.0 py39h8a366b7_1 conda-forge; stdlib-list 0.8.0 pyhd8ed1ab_0 conda-forge; tbb 2021.9.0 hffc8910_0 conda-forge; threadpoolctl 3.2.0 pyha21a80b_0 conda-forge; tk 8.6.12 he1e0b03_0 conda-forge; tomli 2.0.1 pyhd8ed1ab_0 conda-forge; tornado 6.1 py39h1a28f6b_0 anaconda; tqdm 4.65.0 pyhd8ed1ab_1 conda-forge; traitlets 5.1.1 pyhd3eb1b0_0 anaconda; typing-extensions 4.7.1 hd8ed1ab_0 conda-forge; typing_extensions 4.7.1 pyha770c72_0 conda-forge; tzdata 2023c h71feb2d_0 conda-forge; umap-learn 0.5.3 py39h2804cbe_1 conda-forge; u,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2564
https://github.com/scverse/scanpy/issues/2564:8115,Usability,learn,learn,8115,2 pyhd3eb1b0_0 anaconda; pynndescent 0.5.10 pyh1a96a4e_0 conda-forge; pyparsing 3.1.0 pyhd8ed1ab_0 conda-forge; pysocks 1.7.1 pyha2e5f31_6 conda-forge; pytables 3.8.0 py39h0da393b_2 conda-forge; python 3.9.16 hea58f1e_0_cpython conda-forge; python-dateutil 2.8.2 pyhd8ed1ab_0 conda-forge; python-tzdata 2023.3 pyhd8ed1ab_0 conda-forge; python_abi 3.9 3_cp39 conda-forge; pytz 2023.3 pyhd8ed1ab_0 conda-forge; pyzmq 22.3.0 py39hc377ac9_2 anaconda; readline 8.2 h92ec313_1 conda-forge; requests 2.31.0 pyhd8ed1ab_0 conda-forge; scanpy 1.7.2 pyhdfd78af_0 bioconda; scikit-learn 1.3.0 py39hd5c4a62_0 conda-forge; scipy 1.11.1 py39ha6b2cbd_0 conda-forge; seaborn 0.12.2 hd8ed1ab_0 conda-forge; seaborn-base 0.12.2 pyhd8ed1ab_0 conda-forge; setuptools 68.0.0 pyhd8ed1ab_0 conda-forge; setuptools-scm 7.1.0 pyhd8ed1ab_0 conda-forge; setuptools_scm 7.1.0 hd8ed1ab_0 conda-forge; sinfo 0.3.1 py_0 conda-forge; six 1.16.0 pyh6c4a22f_0 conda-forge; snappy 1.1.10 h17c5cce_0 conda-forge; stack_data 0.2.0 pyhd3eb1b0_0 anaconda; statsmodels 0.14.0 py39h8a366b7_1 conda-forge; stdlib-list 0.8.0 pyhd8ed1ab_0 conda-forge; tbb 2021.9.0 hffc8910_0 conda-forge; threadpoolctl 3.2.0 pyha21a80b_0 conda-forge; tk 8.6.12 he1e0b03_0 conda-forge; tomli 2.0.1 pyhd8ed1ab_0 conda-forge; tornado 6.1 py39h1a28f6b_0 anaconda; tqdm 4.65.0 pyhd8ed1ab_1 conda-forge; traitlets 5.1.1 pyhd3eb1b0_0 anaconda; typing-extensions 4.7.1 hd8ed1ab_0 conda-forge; typing_extensions 4.7.1 pyha770c72_0 conda-forge; tzdata 2023c h71feb2d_0 conda-forge; umap-learn 0.5.3 py39h2804cbe_1 conda-forge; unicodedata2 15.0.0 py39h02fc5c5_0 conda-forge; urllib3 2.0.3 pyhd8ed1ab_1 conda-forge; wcwidth 0.2.5 pyhd3eb1b0_0 anaconda; wheel 0.40.0 pyhd8ed1ab_1 conda-forge; xorg-libxau 1.0.11 hb547adb_0 conda-forge; xorg-libxdmcp 1.1.3 h27ca646_0 conda-forge; xz 5.2.6 h57fd34a_0 conda-forge; zeromq 4.3.4 hc377ac9_0 anaconda; zipp 3.16.2 pyhd8ed1ab_0 conda-forge; zlib-ng 2.0.7 h1a8c8d9_0 conda-forge; zstd 1.5.2 h4f39d0f_7 conda-forge; ```. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2564
https://github.com/scverse/scanpy/issues/2565:602,Availability,Error,Error,602,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. In scanpy version 1.9.3. ### Minimal code sample. ```python; adata = sc.read_visium(; '/data_disk/ST01/User/zhanghh/project/analysis/GSM6252954/outs/',; count_file='filtered_feature_bc_matrix.h5',; source_image_path='/data_disk/ST01/User/zhanghh/project/GSE206391/GSM6252954_11-V19T12-012-V4.jpg',; ); ```. ### Error output. ```pytb; /data_disk/ST01/Software/conda_env/zhhenv/lib/python3.9/site-packages/anndata/_core/anndata.py:1832: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.; utils.warn_names_duplicates(""var""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/zhanghaihao/.local/lib/python3.9/site-packages/scanpy/readwrite.py"", line 390, in read_visium; raise OSError(f""Could not find '{f}'""); OSError: Could not find '/data_disk/ST01/User/zhanghh/project/analysis/GSM6252954/outs/spatial/tissue_positions_list.csv'; ```. ### Versions. <details>; <summary>Details</summary>. ```; >>> import scanpy; scanpy.logging.print_versions(); -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dot_parser NA; gmpy2 2.1.2; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; importlib_resources NA; invgauss_ufunc NA; joblib 1.1.1; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; matplotlib 3.7.1; mpl_toolkits NA; mpmath 1.2.1; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.57.0; numpy 1.24.3; nvfuser NA; opt_einsum v3.3.0; packaging 23.0; pandas 2.0.1; pkg_resources NA; pydot 1.4.2; pyparsing 3.0.9; pytz 2022.7; scipy 1.10.1; session_info 1.0.0; setuptools 66.0.0; six 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2565
https://github.com/scverse/scanpy/issues/2565:2308,Deployability,update,updated,2308,"adata = sc.read_visium(; '/data_disk/ST01/User/zhanghh/project/analysis/GSM6252954/outs/',; count_file='filtered_feature_bc_matrix.h5',; source_image_path='/data_disk/ST01/User/zhanghh/project/GSE206391/GSM6252954_11-V19T12-012-V4.jpg',; ); ```. ### Error output. ```pytb; /data_disk/ST01/Software/conda_env/zhhenv/lib/python3.9/site-packages/anndata/_core/anndata.py:1832: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.; utils.warn_names_duplicates(""var""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/zhanghaihao/.local/lib/python3.9/site-packages/scanpy/readwrite.py"", line 390, in read_visium; raise OSError(f""Could not find '{f}'""); OSError: Could not find '/data_disk/ST01/User/zhanghh/project/analysis/GSM6252954/outs/spatial/tissue_positions_list.csv'; ```. ### Versions. <details>; <summary>Details</summary>. ```; >>> import scanpy; scanpy.logging.print_versions(); -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dot_parser NA; gmpy2 2.1.2; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; importlib_resources NA; invgauss_ufunc NA; joblib 1.1.1; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; matplotlib 3.7.1; mpl_toolkits NA; mpmath 1.2.1; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.57.0; numpy 1.24.3; nvfuser NA; opt_einsum v3.3.0; packaging 23.0; pandas 2.0.1; pkg_resources NA; pydot 1.4.2; pyparsing 3.0.9; pytz 2022.7; scipy 1.10.1; session_info 1.0.0; setuptools 66.0.0; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; sympy 1.11.1; texttable 1.6.7; threadpoolctl 2.2.0; torch 2.0.1; tqdm 4.65.0; typing_extensions NA; yaml 6.0; zipp NA; zoneinfo NA; -----; Python 3.9.16 (main, Mar 8 2023, 14:00:05) [GCC 11.2.0]; Linux-5.15.0-71-generic-x86_64-with-glibc2.35; -----; Session information updated at 2023-07-20 15:11; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2565
https://github.com/scverse/scanpy/issues/2565:739,Modifiability,Variab,Variable,739,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. In scanpy version 1.9.3. ### Minimal code sample. ```python; adata = sc.read_visium(; '/data_disk/ST01/User/zhanghh/project/analysis/GSM6252954/outs/',; count_file='filtered_feature_bc_matrix.h5',; source_image_path='/data_disk/ST01/User/zhanghh/project/GSE206391/GSM6252954_11-V19T12-012-V4.jpg',; ); ```. ### Error output. ```pytb; /data_disk/ST01/Software/conda_env/zhhenv/lib/python3.9/site-packages/anndata/_core/anndata.py:1832: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.; utils.warn_names_duplicates(""var""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/zhanghaihao/.local/lib/python3.9/site-packages/scanpy/readwrite.py"", line 390, in read_visium; raise OSError(f""Could not find '{f}'""); OSError: Could not find '/data_disk/ST01/User/zhanghh/project/analysis/GSM6252954/outs/spatial/tissue_positions_list.csv'; ```. ### Versions. <details>; <summary>Details</summary>. ```; >>> import scanpy; scanpy.logging.print_versions(); -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dot_parser NA; gmpy2 2.1.2; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; importlib_resources NA; invgauss_ufunc NA; joblib 1.1.1; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; matplotlib 3.7.1; mpl_toolkits NA; mpmath 1.2.1; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.57.0; numpy 1.24.3; nvfuser NA; opt_einsum v3.3.0; packaging 23.0; pandas 2.0.1; pkg_resources NA; pydot 1.4.2; pyparsing 3.0.9; pytz 2022.7; scipy 1.10.1; session_info 1.0.0; setuptools 66.0.0; six 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2565
https://github.com/scverse/scanpy/issues/2565:1291,Testability,log,logging,1291,"canpy version 1.9.3. ### Minimal code sample. ```python; adata = sc.read_visium(; '/data_disk/ST01/User/zhanghh/project/analysis/GSM6252954/outs/',; count_file='filtered_feature_bc_matrix.h5',; source_image_path='/data_disk/ST01/User/zhanghh/project/GSE206391/GSM6252954_11-V19T12-012-V4.jpg',; ); ```. ### Error output. ```pytb; /data_disk/ST01/Software/conda_env/zhhenv/lib/python3.9/site-packages/anndata/_core/anndata.py:1832: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.; utils.warn_names_duplicates(""var""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/zhanghaihao/.local/lib/python3.9/site-packages/scanpy/readwrite.py"", line 390, in read_visium; raise OSError(f""Could not find '{f}'""); OSError: Could not find '/data_disk/ST01/User/zhanghh/project/analysis/GSM6252954/outs/spatial/tissue_positions_list.csv'; ```. ### Versions. <details>; <summary>Details</summary>. ```; >>> import scanpy; scanpy.logging.print_versions(); -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dot_parser NA; gmpy2 2.1.2; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.4; importlib_resources NA; invgauss_ufunc NA; joblib 1.1.1; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; matplotlib 3.7.1; mpl_toolkits NA; mpmath 1.2.1; natsort 8.3.1; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.57.0; numpy 1.24.3; nvfuser NA; opt_einsum v3.3.0; packaging 23.0; pandas 2.0.1; pkg_resources NA; pydot 1.4.2; pyparsing 3.0.9; pytz 2022.7; scipy 1.10.1; session_info 1.0.0; setuptools 66.0.0; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.2; sympy 1.11.1; texttable 1.6.7; threadpoolctl 2.2.0; torch 2.0.1; tqdm 4.65.0; typing_extensions NA; yaml 6.0; zipp NA; zoneinfo NA; -----; Python 3.9.16 (main, Mar 8 2023, 14:00:05) [GCC 11.2.0]; Linux-5.15.0-71-generic-x86_64-with-glibc2.35; -----; Session",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2565
https://github.com/scverse/scanpy/pull/2569:194,Deployability,release,release,194,"\<!-- Please check (- [x]) and fill in the following two boxes --> ; - [x] Closes N/A; - [x] Tests included or not required because:. \<!-- Only check the following box if you did not include release nodes --> ; - [x] Release notes not necessary because: Its a dev process PR. (made comments visible to show what PR authors see). Current design is that the jobs fail, respectively:; - If theres no milestone; - If the Development process label isnt there and the Release notes  checkbox is not checked, and there are not edits to the relevant release notes file. This is how it looks like if that check fails:. ![grafik](https://github.com/scverse/scanpy/assets/291575/08c324a5-a580-4b30-a838-b7f98fa9787e)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2569
https://github.com/scverse/scanpy/pull/2569:220,Deployability,Release,Release,220,"\<!-- Please check (- [x]) and fill in the following two boxes --> ; - [x] Closes N/A; - [x] Tests included or not required because:. \<!-- Only check the following box if you did not include release nodes --> ; - [x] Release notes not necessary because: Its a dev process PR. (made comments visible to show what PR authors see). Current design is that the jobs fail, respectively:; - If theres no milestone; - If the Development process label isnt there and the Release notes  checkbox is not checked, and there are not edits to the relevant release notes file. This is how it looks like if that check fails:. ![grafik](https://github.com/scverse/scanpy/assets/291575/08c324a5-a580-4b30-a838-b7f98fa9787e)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2569
https://github.com/scverse/scanpy/pull/2569:471,Deployability,Release,Release,471,"\<!-- Please check (- [x]) and fill in the following two boxes --> ; - [x] Closes N/A; - [x] Tests included or not required because:. \<!-- Only check the following box if you did not include release nodes --> ; - [x] Release notes not necessary because: Its a dev process PR. (made comments visible to show what PR authors see). Current design is that the jobs fail, respectively:; - If theres no milestone; - If the Development process label isnt there and the Release notes  checkbox is not checked, and there are not edits to the relevant release notes file. This is how it looks like if that check fails:. ![grafik](https://github.com/scverse/scanpy/assets/291575/08c324a5-a580-4b30-a838-b7f98fa9787e)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2569
https://github.com/scverse/scanpy/pull/2569:553,Deployability,release,release,553,"\<!-- Please check (- [x]) and fill in the following two boxes --> ; - [x] Closes N/A; - [x] Tests included or not required because:. \<!-- Only check the following box if you did not include release nodes --> ; - [x] Release notes not necessary because: Its a dev process PR. (made comments visible to show what PR authors see). Current design is that the jobs fail, respectively:; - If theres no milestone; - If the Development process label isnt there and the Release notes  checkbox is not checked, and there are not edits to the relevant release notes file. This is how it looks like if that check fails:. ![grafik](https://github.com/scverse/scanpy/assets/291575/08c324a5-a580-4b30-a838-b7f98fa9787e)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2569
https://github.com/scverse/scanpy/pull/2569:95,Testability,Test,Tests,95,"\<!-- Please check (- [x]) and fill in the following two boxes --> ; - [x] Closes N/A; - [x] Tests included or not required because:. \<!-- Only check the following box if you did not include release nodes --> ; - [x] Release notes not necessary because: Its a dev process PR. (made comments visible to show what PR authors see). Current design is that the jobs fail, respectively:; - If theres no milestone; - If the Development process label isnt there and the Release notes  checkbox is not checked, and there are not edits to the relevant release notes file. This is how it looks like if that check fails:. ![grafik](https://github.com/scverse/scanpy/assets/291575/08c324a5-a580-4b30-a838-b7f98fa9787e)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2569
https://github.com/scverse/scanpy/issues/2570:474,Availability,error,error,474,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I've been having an issue trying to load published single cell data (GEO GSE123366) onto my jupyter notebook. Despite providing the directory where all 3 files are located, I get the error that it cannot find my matrix.mtx.gz file. . ### Minimal code sample. ```python; sc.read_10x_mtx(""GSE123366_Combined""); ```. ### Error output. ```pytb; FileNotFoundError Traceback (most recent call last); Cell In[31], line 1; ----> 1 sc.read_10x_mtx(""GSE123366_Combined"", cache=True). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:490, in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 488 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 489 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 490 adata = read(; 491 str(path),; 492 var_names=var_names,; 493 make_unique=make_unique,; 494 cache=cache,; 495 cache_compression=cache_compression,; 496 prefix=prefix,; 497 ); 498 if genefile_exists or not gex_only:; 499 return adata. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:554, in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 550 """"""; 551 Read mtx from output from Cell Ranger v3 or later versions; 552 """"""; 553 path = Path(path); --> 554 adata = read(; 555 path / f'{prefix}matrix.mtx.gz',; 556 cache=cache,; 557 cache_compression=cache_compression,; 558 ).T # transpose the data; 559 genes = pd.read_csv(path / f'{prefix}features.tsv.gz', header=None, sep='\t'); 560 if var_names == 'gene_symbols':. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:112, in read(filename, backed, sheet, ext, delimiter, first_column_n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570
https://github.com/scverse/scanpy/issues/2570:609,Availability,Error,Error,609,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I've been having an issue trying to load published single cell data (GEO GSE123366) onto my jupyter notebook. Despite providing the directory where all 3 files are located, I get the error that it cannot find my matrix.mtx.gz file. . ### Minimal code sample. ```python; sc.read_10x_mtx(""GSE123366_Combined""); ```. ### Error output. ```pytb; FileNotFoundError Traceback (most recent call last); Cell In[31], line 1; ----> 1 sc.read_10x_mtx(""GSE123366_Combined"", cache=True). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:490, in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 488 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 489 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 490 adata = read(; 491 str(path),; 492 var_names=var_names,; 493 make_unique=make_unique,; 494 cache=cache,; 495 cache_compression=cache_compression,; 496 prefix=prefix,; 497 ); 498 if genefile_exists or not gex_only:; 499 return adata. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:554, in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 550 """"""; 551 Read mtx from output from Cell Ranger v3 or later versions; 552 """"""; 553 path = Path(path); --> 554 adata = read(; 555 path / f'{prefix}matrix.mtx.gz',; 556 cache=cache,; 557 cache_compression=cache_compression,; 558 ).T # transpose the data; 559 genes = pd.read_csv(path / f'{prefix}features.tsv.gz', header=None, sep='\t'); 560 if var_names == 'gene_symbols':. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:112, in read(filename, backed, sheet, ext, delimiter, first_column_n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570
https://github.com/scverse/scanpy/issues/2570:4519,Deployability,update,updated,4519,"y:737, in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 734 return read_h5ad(path_cache); 736 if not is_present:; --> 737 raise FileNotFoundError(f'Did not find file {filename}.'); 738 logg.debug(f'reading {filename}'); 739 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file GSE123366_Combined/matrix.mtx.gz.; ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 10.0.0; appnope 0.1.3; asttokens NA; attr 23.1.0; backcall 0.2.0; boltons NA; cffi 1.15.1; cloudpickle 2.2.1; comm 0.1.3; ctxcore 0.2.0; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.1; dask 2023.7.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; frozendict 2.3.8; h5py 3.9.0; ikarus NA; importlib_resources NA; ipykernel 6.24.0; ipython_genutils 0.2.0; jedi 0.18.2; jinja2 3.1.2; joblib 1.3.1; kiwisolver 1.4.4; llvmlite 0.40.1; lz4 4.3.2; markupsafe 2.1.3; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numexpr 2.8.4; numpy 1.24.4; packaging 23.1; pandas 2.0.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.8.1; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 12.0.1; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.0.9; pyscenic 0.12.1; pytz 2023.3; scipy 1.11.1; session_info 1.0.0; six 1.16.0; sklearn 1.3.0; stack_data 0.6.2; tblib 2.0.0; threadpoolctl 3.2.0; tlz 0.12.1; toolz 0.12.0; tornado 6.3.2; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; wcwidth 0.2.6; yaml 6.0; zipp NA; zmq 25.1.0; zoneinfo NA; -----; IPython 8.14.0; jupyter_client 8.3.0; jupyter_core 5.3.1; notebook 6.5.4; -----; Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]; macOS-10.16-x86_64-i386-64bit; -----; Session information updated at 2023-07-21 20:08; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570
https://github.com/scverse/scanpy/issues/2570:327,Performance,load,load,327,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I've been having an issue trying to load published single cell data (GEO GSE123366) onto my jupyter notebook. Despite providing the directory where all 3 files are located, I get the error that it cannot find my matrix.mtx.gz file. . ### Minimal code sample. ```python; sc.read_10x_mtx(""GSE123366_Combined""); ```. ### Error output. ```pytb; FileNotFoundError Traceback (most recent call last); Cell In[31], line 1; ----> 1 sc.read_10x_mtx(""GSE123366_Combined"", cache=True). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:490, in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 488 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 489 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 490 adata = read(; 491 str(path),; 492 var_names=var_names,; 493 make_unique=make_unique,; 494 cache=cache,; 495 cache_compression=cache_compression,; 496 prefix=prefix,; 497 ); 498 if genefile_exists or not gex_only:; 499 return adata. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:554, in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 550 """"""; 551 Read mtx from output from Cell Ranger v3 or later versions; 552 """"""; 553 path = Path(path); --> 554 adata = read(; 555 path / f'{prefix}matrix.mtx.gz',; 556 cache=cache,; 557 cache_compression=cache_compression,; 558 ).T # transpose the data; 559 genes = pd.read_csv(path / f'{prefix}features.tsv.gz', header=None, sep='\t'); 560 if var_names == 'gene_symbols':. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:112, in read(filename, backed, sheet, ext, delimiter, first_column_n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570
https://github.com/scverse/scanpy/issues/2570:752,Performance,cache,cache,752,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I've been having an issue trying to load published single cell data (GEO GSE123366) onto my jupyter notebook. Despite providing the directory where all 3 files are located, I get the error that it cannot find my matrix.mtx.gz file. . ### Minimal code sample. ```python; sc.read_10x_mtx(""GSE123366_Combined""); ```. ### Error output. ```pytb; FileNotFoundError Traceback (most recent call last); Cell In[31], line 1; ----> 1 sc.read_10x_mtx(""GSE123366_Combined"", cache=True). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:490, in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 488 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 489 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 490 adata = read(; 491 str(path),; 492 var_names=var_names,; 493 make_unique=make_unique,; 494 cache=cache,; 495 cache_compression=cache_compression,; 496 prefix=prefix,; 497 ); 498 if genefile_exists or not gex_only:; 499 return adata. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:554, in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 550 """"""; 551 Read mtx from output from Cell Ranger v3 or later versions; 552 """"""; 553 path = Path(path); --> 554 adata = read(; 555 path / f'{prefix}matrix.mtx.gz',; 556 cache=cache,; 557 cache_compression=cache_compression,; 558 ).T # transpose the data; 559 genes = pd.read_csv(path / f'{prefix}features.tsv.gz', header=None, sep='\t'); 560 if var_names == 'gene_symbols':. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:112, in read(filename, backed, sheet, ext, delimiter, first_column_n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570
https://github.com/scverse/scanpy/issues/2570:892,Performance,cache,cache,892,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I've been having an issue trying to load published single cell data (GEO GSE123366) onto my jupyter notebook. Despite providing the directory where all 3 files are located, I get the error that it cannot find my matrix.mtx.gz file. . ### Minimal code sample. ```python; sc.read_10x_mtx(""GSE123366_Combined""); ```. ### Error output. ```pytb; FileNotFoundError Traceback (most recent call last); Cell In[31], line 1; ----> 1 sc.read_10x_mtx(""GSE123366_Combined"", cache=True). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:490, in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 488 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 489 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 490 adata = read(; 491 str(path),; 492 var_names=var_names,; 493 make_unique=make_unique,; 494 cache=cache,; 495 cache_compression=cache_compression,; 496 prefix=prefix,; 497 ); 498 if genefile_exists or not gex_only:; 499 return adata. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:554, in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 550 """"""; 551 Read mtx from output from Cell Ranger v3 or later versions; 552 """"""; 553 path = Path(path); --> 554 adata = read(; 555 path / f'{prefix}matrix.mtx.gz',; 556 cache=cache,; 557 cache_compression=cache_compression,; 558 ).T # transpose the data; 559 genes = pd.read_csv(path / f'{prefix}features.tsv.gz', header=None, sep='\t'); 560 if var_names == 'gene_symbols':. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:112, in read(filename, backed, sheet, ext, delimiter, first_column_n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570
https://github.com/scverse/scanpy/issues/2570:1173,Performance,cache,cache,1173,"sts on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I've been having an issue trying to load published single cell data (GEO GSE123366) onto my jupyter notebook. Despite providing the directory where all 3 files are located, I get the error that it cannot find my matrix.mtx.gz file. . ### Minimal code sample. ```python; sc.read_10x_mtx(""GSE123366_Combined""); ```. ### Error output. ```pytb; FileNotFoundError Traceback (most recent call last); Cell In[31], line 1; ----> 1 sc.read_10x_mtx(""GSE123366_Combined"", cache=True). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:490, in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 488 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 489 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 490 adata = read(; 491 str(path),; 492 var_names=var_names,; 493 make_unique=make_unique,; 494 cache=cache,; 495 cache_compression=cache_compression,; 496 prefix=prefix,; 497 ); 498 if genefile_exists or not gex_only:; 499 return adata. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:554, in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 550 """"""; 551 Read mtx from output from Cell Ranger v3 or later versions; 552 """"""; 553 path = Path(path); --> 554 adata = read(; 555 path / f'{prefix}matrix.mtx.gz',; 556 cache=cache,; 557 cache_compression=cache_compression,; 558 ).T # transpose the data; 559 genes = pd.read_csv(path / f'{prefix}features.tsv.gz', header=None, sep='\t'); 560 if var_names == 'gene_symbols':. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:112, in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570
https://github.com/scverse/scanpy/issues/2570:1179,Performance,cache,cache,1179,"sts on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I've been having an issue trying to load published single cell data (GEO GSE123366) onto my jupyter notebook. Despite providing the directory where all 3 files are located, I get the error that it cannot find my matrix.mtx.gz file. . ### Minimal code sample. ```python; sc.read_10x_mtx(""GSE123366_Combined""); ```. ### Error output. ```pytb; FileNotFoundError Traceback (most recent call last); Cell In[31], line 1; ----> 1 sc.read_10x_mtx(""GSE123366_Combined"", cache=True). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:490, in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 488 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 489 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 490 adata = read(; 491 str(path),; 492 var_names=var_names,; 493 make_unique=make_unique,; 494 cache=cache,; 495 cache_compression=cache_compression,; 496 prefix=prefix,; 497 ); 498 if genefile_exists or not gex_only:; 499 return adata. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:554, in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 550 """"""; 551 Read mtx from output from Cell Ranger v3 or later versions; 552 """"""; 553 path = Path(path); --> 554 adata = read(; 555 path / f'{prefix}matrix.mtx.gz',; 556 cache=cache,; 557 cache_compression=cache_compression,; 558 ).T # transpose the data; 559 genes = pd.read_csv(path / f'{prefix}features.tsv.gz', header=None, sep='\t'); 560 if var_names == 'gene_symbols':. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:112, in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570
https://github.com/scverse/scanpy/issues/2570:1446,Performance,cache,cache,1446,"x.gz file. . ### Minimal code sample. ```python; sc.read_10x_mtx(""GSE123366_Combined""); ```. ### Error output. ```pytb; FileNotFoundError Traceback (most recent call last); Cell In[31], line 1; ----> 1 sc.read_10x_mtx(""GSE123366_Combined"", cache=True). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:490, in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 488 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 489 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 490 adata = read(; 491 str(path),; 492 var_names=var_names,; 493 make_unique=make_unique,; 494 cache=cache,; 495 cache_compression=cache_compression,; 496 prefix=prefix,; 497 ); 498 if genefile_exists or not gex_only:; 499 return adata. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:554, in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 550 """"""; 551 Read mtx from output from Cell Ranger v3 or later versions; 552 """"""; 553 path = Path(path); --> 554 adata = read(; 555 path / f'{prefix}matrix.mtx.gz',; 556 cache=cache,; 557 cache_compression=cache_compression,; 558 ).T # transpose the data; 559 genes = pd.read_csv(path / f'{prefix}features.tsv.gz', header=None, sep='\t'); 560 if var_names == 'gene_symbols':. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:112, in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,; 115 sheet=sheet,; 116 ext=ext,; 117 delimiter=delimiter,; 118 first_column_names=first_column_names,; 119 backup_url=backup_url,; 120 cache=cache,; 121 cache_compression=cache_compression,; 122 **kwargs,; 123 ); 124 # generate filename and read to dict; 125 filekey = str(filename). File ~/virtualenvs/scell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570
https://github.com/scverse/scanpy/issues/2570:1651,Performance,cache,cache,1651," last); Cell In[31], line 1; ----> 1 sc.read_10x_mtx(""GSE123366_Combined"", cache=True). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:490, in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 488 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 489 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 490 adata = read(; 491 str(path),; 492 var_names=var_names,; 493 make_unique=make_unique,; 494 cache=cache,; 495 cache_compression=cache_compression,; 496 prefix=prefix,; 497 ); 498 if genefile_exists or not gex_only:; 499 return adata. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:554, in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 550 """"""; 551 Read mtx from output from Cell Ranger v3 or later versions; 552 """"""; 553 path = Path(path); --> 554 adata = read(; 555 path / f'{prefix}matrix.mtx.gz',; 556 cache=cache,; 557 cache_compression=cache_compression,; 558 ).T # transpose the data; 559 genes = pd.read_csv(path / f'{prefix}features.tsv.gz', header=None, sep='\t'); 560 if var_names == 'gene_symbols':. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:112, in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,; 115 sheet=sheet,; 116 ext=ext,; 117 delimiter=delimiter,; 118 first_column_names=first_column_names,; 119 backup_url=backup_url,; 120 cache=cache,; 121 cache_compression=cache_compression,; 122 **kwargs,; 123 ); 124 # generate filename and read to dict; 125 filekey = str(filename). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:737, in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570
https://github.com/scverse/scanpy/issues/2570:1657,Performance,cache,cache,1657," last); Cell In[31], line 1; ----> 1 sc.read_10x_mtx(""GSE123366_Combined"", cache=True). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:490, in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 488 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 489 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 490 adata = read(; 491 str(path),; 492 var_names=var_names,; 493 make_unique=make_unique,; 494 cache=cache,; 495 cache_compression=cache_compression,; 496 prefix=prefix,; 497 ); 498 if genefile_exists or not gex_only:; 499 return adata. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:554, in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 550 """"""; 551 Read mtx from output from Cell Ranger v3 or later versions; 552 """"""; 553 path = Path(path); --> 554 adata = read(; 555 path / f'{prefix}matrix.mtx.gz',; 556 cache=cache,; 557 cache_compression=cache_compression,; 558 ).T # transpose the data; 559 genes = pd.read_csv(path / f'{prefix}features.tsv.gz', header=None, sep='\t'); 560 if var_names == 'gene_symbols':. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:112, in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,; 115 sheet=sheet,; 116 ext=ext,; 117 delimiter=delimiter,; 118 first_column_names=first_column_names,; 119 backup_url=backup_url,; 120 cache=cache,; 121 cache_compression=cache_compression,; 122 **kwargs,; 123 ); 124 # generate filename and read to dict; 125 filekey = str(filename). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:737, in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570
https://github.com/scverse/scanpy/issues/2570:2019,Performance,cache,cache,2019,"cache_compression,; 496 prefix=prefix,; 497 ); 498 if genefile_exists or not gex_only:; 499 return adata. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:554, in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 550 """"""; 551 Read mtx from output from Cell Ranger v3 or later versions; 552 """"""; 553 path = Path(path); --> 554 adata = read(; 555 path / f'{prefix}matrix.mtx.gz',; 556 cache=cache,; 557 cache_compression=cache_compression,; 558 ).T # transpose the data; 559 genes = pd.read_csv(path / f'{prefix}features.tsv.gz', header=None, sep='\t'); 560 if var_names == 'gene_symbols':. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:112, in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,; 115 sheet=sheet,; 116 ext=ext,; 117 delimiter=delimiter,; 118 first_column_names=first_column_names,; 119 backup_url=backup_url,; 120 cache=cache,; 121 cache_compression=cache_compression,; 122 **kwargs,; 123 ); 124 # generate filename and read to dict; 125 filekey = str(filename). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:737, in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 734 return read_h5ad(path_cache); 736 if not is_present:; --> 737 raise FileNotFoundError(f'Did not find file {filename}.'); 738 logg.debug(f'reading {filename}'); 739 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file GSE123366_Combined/matrix.mtx.gz.; ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 10.0.0; appnope 0.1.3; asttokens NA; attr 23.1.0; backcall 0.2.0; boltons NA; cffi 1.15.1; cloudpickle 2.2.1; comm 0.1.3; ctxcor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570
https://github.com/scverse/scanpy/issues/2570:2340,Performance,cache,cache,2340,"cache_compression,; 496 prefix=prefix,; 497 ); 498 if genefile_exists or not gex_only:; 499 return adata. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:554, in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 550 """"""; 551 Read mtx from output from Cell Ranger v3 or later versions; 552 """"""; 553 path = Path(path); --> 554 adata = read(; 555 path / f'{prefix}matrix.mtx.gz',; 556 cache=cache,; 557 cache_compression=cache_compression,; 558 ).T # transpose the data; 559 genes = pd.read_csv(path / f'{prefix}features.tsv.gz', header=None, sep='\t'); 560 if var_names == 'gene_symbols':. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:112, in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,; 115 sheet=sheet,; 116 ext=ext,; 117 delimiter=delimiter,; 118 first_column_names=first_column_names,; 119 backup_url=backup_url,; 120 cache=cache,; 121 cache_compression=cache_compression,; 122 **kwargs,; 123 ); 124 # generate filename and read to dict; 125 filekey = str(filename). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:737, in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 734 return read_h5ad(path_cache); 736 if not is_present:; --> 737 raise FileNotFoundError(f'Did not find file {filename}.'); 738 logg.debug(f'reading {filename}'); 739 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file GSE123366_Combined/matrix.mtx.gz.; ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 10.0.0; appnope 0.1.3; asttokens NA; attr 23.1.0; backcall 0.2.0; boltons NA; cffi 1.15.1; cloudpickle 2.2.1; comm 0.1.3; ctxcor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570
https://github.com/scverse/scanpy/issues/2570:2346,Performance,cache,cache,2346,"cache_compression,; 496 prefix=prefix,; 497 ); 498 if genefile_exists or not gex_only:; 499 return adata. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:554, in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 550 """"""; 551 Read mtx from output from Cell Ranger v3 or later versions; 552 """"""; 553 path = Path(path); --> 554 adata = read(; 555 path / f'{prefix}matrix.mtx.gz',; 556 cache=cache,; 557 cache_compression=cache_compression,; 558 ).T # transpose the data; 559 genes = pd.read_csv(path / f'{prefix}features.tsv.gz', header=None, sep='\t'); 560 if var_names == 'gene_symbols':. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:112, in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,; 115 sheet=sheet,; 116 ext=ext,; 117 delimiter=delimiter,; 118 first_column_names=first_column_names,; 119 backup_url=backup_url,; 120 cache=cache,; 121 cache_compression=cache_compression,; 122 **kwargs,; 123 ); 124 # generate filename and read to dict; 125 filekey = str(filename). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:737, in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 734 return read_h5ad(path_cache); 736 if not is_present:; --> 737 raise FileNotFoundError(f'Did not find file {filename}.'); 738 logg.debug(f'reading {filename}'); 739 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file GSE123366_Combined/matrix.mtx.gz.; ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 10.0.0; appnope 0.1.3; asttokens NA; attr 23.1.0; backcall 0.2.0; boltons NA; cffi 1.15.1; cloudpickle 2.2.1; comm 0.1.3; ctxcor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570
https://github.com/scverse/scanpy/issues/2570:2652,Performance,cache,cache,2652,"ession,; 558 ).T # transpose the data; 559 genes = pd.read_csv(path / f'{prefix}features.tsv.gz', header=None, sep='\t'); 560 if var_names == 'gene_symbols':. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:112, in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,; 115 sheet=sheet,; 116 ext=ext,; 117 delimiter=delimiter,; 118 first_column_names=first_column_names,; 119 backup_url=backup_url,; 120 cache=cache,; 121 cache_compression=cache_compression,; 122 **kwargs,; 123 ); 124 # generate filename and read to dict; 125 filekey = str(filename). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:737, in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 734 return read_h5ad(path_cache); 736 if not is_present:; --> 737 raise FileNotFoundError(f'Did not find file {filename}.'); 738 logg.debug(f'reading {filename}'); 739 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file GSE123366_Combined/matrix.mtx.gz.; ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 10.0.0; appnope 0.1.3; asttokens NA; attr 23.1.0; backcall 0.2.0; boltons NA; cffi 1.15.1; cloudpickle 2.2.1; comm 0.1.3; ctxcore 0.2.0; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.1; dask 2023.7.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; frozendict 2.3.8; h5py 3.9.0; ikarus NA; importlib_resources NA; ipykernel 6.24.0; ipython_genutils 0.2.0; jedi 0.18.2; jinja2 3.1.2; joblib 1.3.1; kiwisolver 1.4.4; llvmlite 0.40.1; lz4 4.3.2; markupsafe 2.1.3; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numexpr 2.8.4; numpy 1.24.4; packaging 23.1; pandas 2.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570
https://github.com/scverse/scanpy/issues/2570:2888,Performance,cache,cache,2888,"ib/python3.9/site-packages/scanpy/readwrite.py:112, in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,; 115 sheet=sheet,; 116 ext=ext,; 117 delimiter=delimiter,; 118 first_column_names=first_column_names,; 119 backup_url=backup_url,; 120 cache=cache,; 121 cache_compression=cache_compression,; 122 **kwargs,; 123 ); 124 # generate filename and read to dict; 125 filekey = str(filename). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:737, in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 734 return read_h5ad(path_cache); 736 if not is_present:; --> 737 raise FileNotFoundError(f'Did not find file {filename}.'); 738 logg.debug(f'reading {filename}'); 739 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file GSE123366_Combined/matrix.mtx.gz.; ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 10.0.0; appnope 0.1.3; asttokens NA; attr 23.1.0; backcall 0.2.0; boltons NA; cffi 1.15.1; cloudpickle 2.2.1; comm 0.1.3; ctxcore 0.2.0; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.1; dask 2023.7.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; frozendict 2.3.8; h5py 3.9.0; ikarus NA; importlib_resources NA; ipykernel 6.24.0; ipython_genutils 0.2.0; jedi 0.18.2; jinja2 3.1.2; joblib 1.3.1; kiwisolver 1.4.4; llvmlite 0.40.1; lz4 4.3.2; markupsafe 2.1.3; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numexpr 2.8.4; numpy 1.24.4; packaging 23.1; pandas 2.0.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.8.1; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 12.0.1; pydev_ipython",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570
https://github.com/scverse/scanpy/issues/2570:2842,Testability,log,logg,2842,"'gene_symbols':. File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:112, in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,; 115 sheet=sheet,; 116 ext=ext,; 117 delimiter=delimiter,; 118 first_column_names=first_column_names,; 119 backup_url=backup_url,; 120 cache=cache,; 121 cache_compression=cache_compression,; 122 **kwargs,; 123 ); 124 # generate filename and read to dict; 125 filekey = str(filename). File ~/virtualenvs/scellai2/lib/python3.9/site-packages/scanpy/readwrite.py:737, in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 734 return read_h5ad(path_cache); 736 if not is_present:; --> 737 raise FileNotFoundError(f'Did not find file {filename}.'); 738 logg.debug(f'reading {filename}'); 739 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file GSE123366_Combined/matrix.mtx.gz.; ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 10.0.0; appnope 0.1.3; asttokens NA; attr 23.1.0; backcall 0.2.0; boltons NA; cffi 1.15.1; cloudpickle 2.2.1; comm 0.1.3; ctxcore 0.2.0; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.1; dask 2023.7.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; frozendict 2.3.8; h5py 3.9.0; ikarus NA; importlib_resources NA; ipykernel 6.24.0; ipython_genutils 0.2.0; jedi 0.18.2; jinja2 3.1.2; joblib 1.3.1; kiwisolver 1.4.4; llvmlite 0.40.1; lz4 4.3.2; markupsafe 2.1.3; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numexpr 2.8.4; numpy 1.24.4; packaging 23.1; pandas 2.0.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.8.1; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2570
https://github.com/scverse/scanpy/pull/2573:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.278  v0.0.280](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.278...v0.0.280); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2573
https://github.com/scverse/scanpy/pull/2574:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2574
https://github.com/scverse/scanpy/pull/2574:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2574
https://github.com/scverse/scanpy/pull/2575:12,Testability,test,test-min,12,"- Even our `test-min` extra has `pytest-nunit`, so we dont need a dummy version; - `--internet-tests` can just be replaced by the mark itself.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2575
https://github.com/scverse/scanpy/pull/2575:96,Testability,test,tests,96,"- Even our `test-min` extra has `pytest-nunit`, so we dont need a dummy version; - `--internet-tests` can just be replaced by the mark itself.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2575
https://github.com/scverse/scanpy/pull/2576:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2576
https://github.com/scverse/scanpy/pull/2576:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2576
https://github.com/scverse/scanpy/issues/2578:251,Testability,test,test,251,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. Meta issue tracking scanpy functions without dask support. Related #921. First we should test things more generically:. - [x] add global `array_type` fixture to use in all tests for features below; - #2595. @ivirshup came up with places where we should prioritize dask support:. - [x] `normalize_total`; - seems to work: scverse/scanpy#2466; - has tests: scverse/scanpy#1663; - [x] `log1p`, `normalize_per_cell`, `filter_cells`/`*_genes`:; - [x] accept Dask arrays: scverse/scanpy#283; - [x] Test that they are kept as Dask arrays throughout: scverse/scanpy#2814; - [x] `sc.pp.pca`: scverse/scanpy#2563 scanpy/scanpy#3263; - [ ] `sc.pp.calculate_qc_metrics` #3307; - `sc.pp.highly_variable_genes`:; - [x] scverse/scanpy#2777; - [x] scverse/scanpy#2807; - [ ] scverse/scanpy#2808; - [ ] experimental pearson_residuals flavor; - [x] `sc.tl.rank_genes_groups`: scverse/scanpy#2621; - [ ] Subsample; - [ ] Aggregate: https://flox.readthedocs.io/en/latest/. Later:. - [x] scale; - [ ] nearest-neighbors: https://github.com/dask/dask-ml/issues/982 may need to implement ourselves...; - [ ] umap: implement ourselves?; - [ ] metrics: depednent on squidpy decisions but should be dask-ifiable",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2578
https://github.com/scverse/scanpy/issues/2578:334,Testability,test,tests,334,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. Meta issue tracking scanpy functions without dask support. Related #921. First we should test things more generically:. - [x] add global `array_type` fixture to use in all tests for features below; - #2595. @ivirshup came up with places where we should prioritize dask support:. - [x] `normalize_total`; - seems to work: scverse/scanpy#2466; - has tests: scverse/scanpy#1663; - [x] `log1p`, `normalize_per_cell`, `filter_cells`/`*_genes`:; - [x] accept Dask arrays: scverse/scanpy#283; - [x] Test that they are kept as Dask arrays throughout: scverse/scanpy#2814; - [x] `sc.pp.pca`: scverse/scanpy#2563 scanpy/scanpy#3263; - [ ] `sc.pp.calculate_qc_metrics` #3307; - `sc.pp.highly_variable_genes`:; - [x] scverse/scanpy#2777; - [x] scverse/scanpy#2807; - [ ] scverse/scanpy#2808; - [ ] experimental pearson_residuals flavor; - [x] `sc.tl.rank_genes_groups`: scverse/scanpy#2621; - [ ] Subsample; - [ ] Aggregate: https://flox.readthedocs.io/en/latest/. Later:. - [x] scale; - [ ] nearest-neighbors: https://github.com/dask/dask-ml/issues/982 may need to implement ourselves...; - [ ] umap: implement ourselves?; - [ ] metrics: depednent on squidpy decisions but should be dask-ifiable",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2578
https://github.com/scverse/scanpy/issues/2578:510,Testability,test,tests,510,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. Meta issue tracking scanpy functions without dask support. Related #921. First we should test things more generically:. - [x] add global `array_type` fixture to use in all tests for features below; - #2595. @ivirshup came up with places where we should prioritize dask support:. - [x] `normalize_total`; - seems to work: scverse/scanpy#2466; - has tests: scverse/scanpy#1663; - [x] `log1p`, `normalize_per_cell`, `filter_cells`/`*_genes`:; - [x] accept Dask arrays: scverse/scanpy#283; - [x] Test that they are kept as Dask arrays throughout: scverse/scanpy#2814; - [x] `sc.pp.pca`: scverse/scanpy#2563 scanpy/scanpy#3263; - [ ] `sc.pp.calculate_qc_metrics` #3307; - `sc.pp.highly_variable_genes`:; - [x] scverse/scanpy#2777; - [x] scverse/scanpy#2807; - [ ] scverse/scanpy#2808; - [ ] experimental pearson_residuals flavor; - [x] `sc.tl.rank_genes_groups`: scverse/scanpy#2621; - [ ] Subsample; - [ ] Aggregate: https://flox.readthedocs.io/en/latest/. Later:. - [x] scale; - [ ] nearest-neighbors: https://github.com/dask/dask-ml/issues/982 may need to implement ourselves...; - [ ] umap: implement ourselves?; - [ ] metrics: depednent on squidpy decisions but should be dask-ifiable",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2578
https://github.com/scverse/scanpy/issues/2578:654,Testability,Test,Test,654,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. Meta issue tracking scanpy functions without dask support. Related #921. First we should test things more generically:. - [x] add global `array_type` fixture to use in all tests for features below; - #2595. @ivirshup came up with places where we should prioritize dask support:. - [x] `normalize_total`; - seems to work: scverse/scanpy#2466; - has tests: scverse/scanpy#1663; - [x] `log1p`, `normalize_per_cell`, `filter_cells`/`*_genes`:; - [x] accept Dask arrays: scverse/scanpy#283; - [x] Test that they are kept as Dask arrays throughout: scverse/scanpy#2814; - [x] `sc.pp.pca`: scverse/scanpy#2563 scanpy/scanpy#3263; - [ ] `sc.pp.calculate_qc_metrics` #3307; - `sc.pp.highly_variable_genes`:; - [x] scverse/scanpy#2777; - [x] scverse/scanpy#2807; - [ ] scverse/scanpy#2808; - [ ] experimental pearson_residuals flavor; - [x] `sc.tl.rank_genes_groups`: scverse/scanpy#2621; - [ ] Subsample; - [ ] Aggregate: https://flox.readthedocs.io/en/latest/. Later:. - [x] scale; - [ ] nearest-neighbors: https://github.com/dask/dask-ml/issues/982 may need to implement ourselves...; - [ ] umap: implement ourselves?; - [ ] metrics: depednent on squidpy decisions but should be dask-ifiable",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2578
https://github.com/scverse/scanpy/issues/2579:1007,Availability,Error,Error,1007,"make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I would expect that when you call sc.pp.highly_variable_genes on the same dataset and request the same number of genes, that you would get the same output. The below example suggests that this is not the case. . ### Minimal code sample. ```python; adata_sub = sc.read_h5ad(""your_favourite_object.h5ad""); n_genes = 1491; for i in range(10):; sc.pp.highly_variable_genes(adata_sub, n_top_genes=n_genes). unique_genes = list(adata_sub.var['highly_variable'][adata_sub.var['highly_variable'] == True].index). if i == 0:; all_unique = list(set(unique_genes)); print(f""total {len(all_unique)} unique genes""); else:; all_unique = list(set(all_unique+unique_genes)); print(f""total {len(all_unique)} unique genes""); ```. ### Error output. ```pytb; total 1491 unique genes; total 1814 unique genes; total 2042 unique genes; total 2163 unique genes; total 2237 unique genes; total 2305 unique genes; total 2356 unique genes; total 2401 unique genes; total 2437 unique genes; total 2453 unique genes; ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 8.4.0; asciitree NA; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.02.1; dateutil 2.8.1; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; django 4.1.3; entrypoints 0.4; executing 0.8.3; fasteners 0.18; fsspec 2023.4.0; google NA; h5py 3.6.0; igraph 0.10.6; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.1.2; joblib 1.1.0; jupyter_server 1.13.5; kiwisolver 1.2.0; kneed 0.8.3; leidenalg 0.10.1; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; mis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2579
https://github.com/scverse/scanpy/issues/2579:3290,Deployability,update,updated,3290,"1; scanpy 1.9.3; -----; PIL 8.4.0; asciitree NA; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.02.1; dateutil 2.8.1; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; django 4.1.3; entrypoints 0.4; executing 0.8.3; fasteners 0.18; fsspec 2023.4.0; google NA; h5py 3.6.0; igraph 0.10.6; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.1.2; joblib 1.1.0; jupyter_server 1.13.5; kiwisolver 1.2.0; kneed 0.8.3; leidenalg 0.10.1; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; mishalpy NA; mpl_toolkits NA; mpmath 1.2.1; msgpack 1.0.2; natsort 8.3.1; nbinom_ufunc NA; nt NA; ntsecuritycon NA; numba 0.55.1; numcodecs 0.11.0; numexpr 2.8.1; numpy 1.21.6; opt_einsum v3.3.0; packaging 21.3; pandas 1.4.3; parso 0.8.3; pickleshare 0.7.5; pkg_resources NA; plotly 5.6.0; prompt_toolkit 3.0.20; psutil 5.8.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 2.4.7; pythoncom NA; pytz 2020.1; pywintypes NA; ruamel NA; scipy 1.7.3; seaborn 0.11.2; session_info 1.0.0; setuptools 61.2.0; six 1.15.0; sklearn 1.0.2; snappy NA; sparse 0.14.0; sphinxcontrib NA; stack_data 0.2.0; statsmodels 0.13.2; sympy 1.10.1; tblib 1.7.0; texttable 1.6.7; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.2; torch 2.0.1+cpu; tornado 6.1; tqdm 4.64.0; traitlets 5.9.0; typing_extensions NA; wcwidth 0.2.5; win32api NA; win32com NA; win32security NA; yaml 6.0; zarr 2.14.2; zipp NA; zmq 22.3.0; zope NA; -----; IPython 8.2.0; jupyter_client 6.1.12; jupyter_core 4.9.2; jupyterlab 3.3.2; notebook 6.4.8; -----; Python 3.9.12 (main, Apr 4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.22000-SP0; -----; Session information updated at 2023-07-31 10:13; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2579
https://github.com/scverse/scanpy/issues/2579:1444,Performance,bottleneck,bottleneck,1444," same output. The below example suggests that this is not the case. . ### Minimal code sample. ```python; adata_sub = sc.read_h5ad(""your_favourite_object.h5ad""); n_genes = 1491; for i in range(10):; sc.pp.highly_variable_genes(adata_sub, n_top_genes=n_genes). unique_genes = list(adata_sub.var['highly_variable'][adata_sub.var['highly_variable'] == True].index). if i == 0:; all_unique = list(set(unique_genes)); print(f""total {len(all_unique)} unique genes""); else:; all_unique = list(set(all_unique+unique_genes)); print(f""total {len(all_unique)} unique genes""); ```. ### Error output. ```pytb; total 1491 unique genes; total 1814 unique genes; total 2042 unique genes; total 2163 unique genes; total 2237 unique genes; total 2305 unique genes; total 2356 unique genes; total 2401 unique genes; total 2437 unique genes; total 2453 unique genes; ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 8.4.0; asciitree NA; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.4; cffi 1.15.0; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.02.1; dateutil 2.8.1; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; django 4.1.3; entrypoints 0.4; executing 0.8.3; fasteners 0.18; fsspec 2023.4.0; google NA; h5py 3.6.0; igraph 0.10.6; ipykernel 6.9.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.1.2; joblib 1.1.0; jupyter_server 1.13.5; kiwisolver 1.2.0; kneed 0.8.3; leidenalg 0.10.1; llvmlite 0.38.0; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; mishalpy NA; mpl_toolkits NA; mpmath 1.2.1; msgpack 1.0.2; natsort 8.3.1; nbinom_ufunc NA; nt NA; ntsecuritycon NA; numba 0.55.1; numcodecs 0.11.0; numexpr 2.8.1; numpy 1.21.6; opt_einsum v3.3.0; packaging 21.3; pandas 1.4.3; parso 0.8.3; pickleshare 0.7.5; pkg_resources NA; plotly 5.6.0; prompt_toolkit 3.0.20; psutil 5.8.0; pure_eval 0.2.2; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrenc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2579
https://github.com/scverse/scanpy/issues/2580:514,Availability,error,errored,514,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I was running an older jupyter notebook based on a scanpy tutorial. I had included a call to `scanpy.logging.print_versions()` for debugging purposes. I just ran the code using the the current main branch of scanpy, and it errored out. See below for output. ### Minimal code sample. ```python; import scanpy; scanpy.logging.print_versions(); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[44], line 1; ----> 1 sc.logging.print_versions(). File ~/Documents/Projects/githubPackages/scanpy/scanpy/logging.py:180, in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,; 183 excludes=[; 184 'builtins',; 185 'stdlib_list',; 186 'importlib_metadata',; 187 # Special module present if test coverage being calculated; 188 # https://gitlab.com/joelostblom/session_info/-/issues/10; 189 ""$coverage"",; 190 ],; 191 ). File ~/Desktop/data/env/lib/python3.11/site-packages/session_info/main.py:209, in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones.; 212 try:. KeyError: 'numcodecs'; ```. ### Versions. <details>. The function we are asked to run here is the one that produces the error. As an alternative, I'm pasting the output of `scanpy.settings.set_figure_params(dpi=80, facecolor='white')`, which includes several versions in the output. ```; scanpy==1.10.0.dev88",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2580
https://github.com/scverse/scanpy/issues/2580:642,Availability,Error,Error,642,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I was running an older jupyter notebook based on a scanpy tutorial. I had included a call to `scanpy.logging.print_versions()` for debugging purposes. I just ran the code using the the current main branch of scanpy, and it errored out. See below for output. ### Minimal code sample. ```python; import scanpy; scanpy.logging.print_versions(); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[44], line 1; ----> 1 sc.logging.print_versions(). File ~/Documents/Projects/githubPackages/scanpy/scanpy/logging.py:180, in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,; 183 excludes=[; 184 'builtins',; 185 'stdlib_list',; 186 'importlib_metadata',; 187 # Special module present if test coverage being calculated; 188 # https://gitlab.com/joelostblom/session_info/-/issues/10; 189 ""$coverage"",; 190 ],; 191 ). File ~/Desktop/data/env/lib/python3.11/site-packages/session_info/main.py:209, in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones.; 212 try:. KeyError: 'numcodecs'; ```. ### Versions. <details>. The function we are asked to run here is the one that produces the error. As an alternative, I'm pasting the output of `scanpy.settings.set_figure_params(dpi=80, facecolor='white')`, which includes several versions in the output. ```; scanpy==1.10.0.dev88",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2580
https://github.com/scverse/scanpy/issues/2580:1813,Availability,error,error,1813,"sion of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I was running an older jupyter notebook based on a scanpy tutorial. I had included a call to `scanpy.logging.print_versions()` for debugging purposes. I just ran the code using the the current main branch of scanpy, and it errored out. See below for output. ### Minimal code sample. ```python; import scanpy; scanpy.logging.print_versions(); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[44], line 1; ----> 1 sc.logging.print_versions(). File ~/Documents/Projects/githubPackages/scanpy/scanpy/logging.py:180, in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,; 183 excludes=[; 184 'builtins',; 185 'stdlib_list',; 186 'importlib_metadata',; 187 # Special module present if test coverage being calculated; 188 # https://gitlab.com/joelostblom/session_info/-/issues/10; 189 ""$coverage"",; 190 ],; 191 ). File ~/Desktop/data/env/lib/python3.11/site-packages/session_info/main.py:209, in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones.; 212 try:. KeyError: 'numcodecs'; ```. ### Versions. <details>. The function we are asked to run here is the one that produces the error. As an alternative, I'm pasting the output of `scanpy.settings.set_figure_params(dpi=80, facecolor='white')`, which includes several versions in the output. ```; scanpy==1.10.0.dev88+gedd61302 anndata==0.9.2 umap==0.5.3 numpy==1.24.4 scipy==1.11.1 pandas==2.0.3 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 pynndescent==0.5.10; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2580
https://github.com/scverse/scanpy/issues/2580:1005,Integrability,depend,dependencies,1005,"been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I was running an older jupyter notebook based on a scanpy tutorial. I had included a call to `scanpy.logging.print_versions()` for debugging purposes. I just ran the code using the the current main branch of scanpy, and it errored out. See below for output. ### Minimal code sample. ```python; import scanpy; scanpy.logging.print_versions(); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[44], line 1; ----> 1 sc.logging.print_versions(). File ~/Documents/Projects/githubPackages/scanpy/scanpy/logging.py:180, in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,; 183 excludes=[; 184 'builtins',; 185 'stdlib_list',; 186 'importlib_metadata',; 187 # Special module present if test coverage being calculated; 188 # https://gitlab.com/joelostblom/session_info/-/issues/10; 189 ""$coverage"",; 190 ],; 191 ). File ~/Desktop/data/env/lib/python3.11/site-packages/session_info/main.py:209, in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones.; 212 try:. KeyError: 'numcodecs'; ```. ### Versions. <details>. The function we are asked to run here is the one that produces the error. As an alternative, I'm pasting the output of `scanpy.settings.set_figure_params(dpi=80, facecolor='white')`, which includes several versions in the output. ```; scanpy==1.10.0.dev88+gedd61302 anndata==0.9.2 umap==0.5.3 numpy==1.24.4 scipy==1.11.1 pandas==2.0.3 scikit-learn==1.3.0 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2580
https://github.com/scverse/scanpy/issues/2580:1391,Integrability,depend,dependencies,1391,"sion of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I was running an older jupyter notebook based on a scanpy tutorial. I had included a call to `scanpy.logging.print_versions()` for debugging purposes. I just ran the code using the the current main branch of scanpy, and it errored out. See below for output. ### Minimal code sample. ```python; import scanpy; scanpy.logging.print_versions(); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[44], line 1; ----> 1 sc.logging.print_versions(). File ~/Documents/Projects/githubPackages/scanpy/scanpy/logging.py:180, in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,; 183 excludes=[; 184 'builtins',; 185 'stdlib_list',; 186 'importlib_metadata',; 187 # Special module present if test coverage being calculated; 188 # https://gitlab.com/joelostblom/session_info/-/issues/10; 189 ""$coverage"",; 190 ],; 191 ). File ~/Desktop/data/env/lib/python3.11/site-packages/session_info/main.py:209, in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones.; 212 try:. KeyError: 'numcodecs'; ```. ### Versions. <details>. The function we are asked to run here is the one that produces the error. As an alternative, I'm pasting the output of `scanpy.settings.set_figure_params(dpi=80, facecolor='white')`, which includes several versions in the output. ```; scanpy==1.10.0.dev88+gedd61302 anndata==0.9.2 umap==0.5.3 numpy==1.24.4 scipy==1.11.1 pandas==2.0.3 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 pynndescent==0.5.10; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2580
https://github.com/scverse/scanpy/issues/2580:392,Testability,log,logging,392,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I was running an older jupyter notebook based on a scanpy tutorial. I had included a call to `scanpy.logging.print_versions()` for debugging purposes. I just ran the code using the the current main branch of scanpy, and it errored out. See below for output. ### Minimal code sample. ```python; import scanpy; scanpy.logging.print_versions(); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[44], line 1; ----> 1 sc.logging.print_versions(). File ~/Documents/Projects/githubPackages/scanpy/scanpy/logging.py:180, in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,; 183 excludes=[; 184 'builtins',; 185 'stdlib_list',; 186 'importlib_metadata',; 187 # Special module present if test coverage being calculated; 188 # https://gitlab.com/joelostblom/session_info/-/issues/10; 189 ""$coverage"",; 190 ],; 191 ). File ~/Desktop/data/env/lib/python3.11/site-packages/session_info/main.py:209, in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones.; 212 try:. KeyError: 'numcodecs'; ```. ### Versions. <details>. The function we are asked to run here is the one that produces the error. As an alternative, I'm pasting the output of `scanpy.settings.set_figure_params(dpi=80, facecolor='white')`, which includes several versions in the output. ```; scanpy==1.10.0.dev88",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2580
https://github.com/scverse/scanpy/issues/2580:607,Testability,log,logging,607,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I was running an older jupyter notebook based on a scanpy tutorial. I had included a call to `scanpy.logging.print_versions()` for debugging purposes. I just ran the code using the the current main branch of scanpy, and it errored out. See below for output. ### Minimal code sample. ```python; import scanpy; scanpy.logging.print_versions(); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[44], line 1; ----> 1 sc.logging.print_versions(). File ~/Documents/Projects/githubPackages/scanpy/scanpy/logging.py:180, in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,; 183 excludes=[; 184 'builtins',; 185 'stdlib_list',; 186 'importlib_metadata',; 187 # Special module present if test coverage being calculated; 188 # https://gitlab.com/joelostblom/session_info/-/issues/10; 189 ""$coverage"",; 190 ],; 191 ). File ~/Desktop/data/env/lib/python3.11/site-packages/session_info/main.py:209, in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones.; 212 try:. KeyError: 'numcodecs'; ```. ### Versions. <details>. The function we are asked to run here is the one that produces the error. As an alternative, I'm pasting the output of `scanpy.settings.set_figure_params(dpi=80, facecolor='white')`, which includes several versions in the output. ```; scanpy==1.10.0.dev88",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2580
https://github.com/scverse/scanpy/issues/2580:818,Testability,log,logging,818,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I was running an older jupyter notebook based on a scanpy tutorial. I had included a call to `scanpy.logging.print_versions()` for debugging purposes. I just ran the code using the the current main branch of scanpy, and it errored out. See below for output. ### Minimal code sample. ```python; import scanpy; scanpy.logging.print_versions(); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[44], line 1; ----> 1 sc.logging.print_versions(). File ~/Documents/Projects/githubPackages/scanpy/scanpy/logging.py:180, in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,; 183 excludes=[; 184 'builtins',; 185 'stdlib_list',; 186 'importlib_metadata',; 187 # Special module present if test coverage being calculated; 188 # https://gitlab.com/joelostblom/session_info/-/issues/10; 189 ""$coverage"",; 190 ],; 191 ). File ~/Desktop/data/env/lib/python3.11/site-packages/session_info/main.py:209, in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones.; 212 try:. KeyError: 'numcodecs'; ```. ### Versions. <details>. The function we are asked to run here is the one that produces the error. As an alternative, I'm pasting the output of `scanpy.settings.set_figure_params(dpi=80, facecolor='white')`, which includes several versions in the output. ```; scanpy==1.10.0.dev88",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2580
https://github.com/scverse/scanpy/issues/2580:899,Testability,log,logging,899,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I was running an older jupyter notebook based on a scanpy tutorial. I had included a call to `scanpy.logging.print_versions()` for debugging purposes. I just ran the code using the the current main branch of scanpy, and it errored out. See below for output. ### Minimal code sample. ```python; import scanpy; scanpy.logging.print_versions(); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[44], line 1; ----> 1 sc.logging.print_versions(). File ~/Documents/Projects/githubPackages/scanpy/scanpy/logging.py:180, in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,; 183 excludes=[; 184 'builtins',; 185 'stdlib_list',; 186 'importlib_metadata',; 187 # Special module present if test coverage being calculated; 188 # https://gitlab.com/joelostblom/session_info/-/issues/10; 189 ""$coverage"",; 190 ],; 191 ). File ~/Desktop/data/env/lib/python3.11/site-packages/session_info/main.py:209, in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones.; 212 try:. KeyError: 'numcodecs'; ```. ### Versions. <details>. The function we are asked to run here is the one that produces the error. As an alternative, I'm pasting the output of `scanpy.settings.set_figure_params(dpi=80, facecolor='white')`, which includes several versions in the output. ```; scanpy==1.10.0.dev88",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2580
https://github.com/scverse/scanpy/issues/2580:1154,Testability,test,test,1154,"been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I was running an older jupyter notebook based on a scanpy tutorial. I had included a call to `scanpy.logging.print_versions()` for debugging purposes. I just ran the code using the the current main branch of scanpy, and it errored out. See below for output. ### Minimal code sample. ```python; import scanpy; scanpy.logging.print_versions(); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[44], line 1; ----> 1 sc.logging.print_versions(). File ~/Documents/Projects/githubPackages/scanpy/scanpy/logging.py:180, in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,; 183 excludes=[; 184 'builtins',; 185 'stdlib_list',; 186 'importlib_metadata',; 187 # Special module present if test coverage being calculated; 188 # https://gitlab.com/joelostblom/session_info/-/issues/10; 189 ""$coverage"",; 190 ],; 191 ). File ~/Desktop/data/env/lib/python3.11/site-packages/session_info/main.py:209, in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones.; 212 try:. KeyError: 'numcodecs'; ```. ### Versions. <details>. The function we are asked to run here is the one that produces the error. As an alternative, I'm pasting the output of `scanpy.settings.set_figure_params(dpi=80, facecolor='white')`, which includes several versions in the output. ```; scanpy==1.10.0.dev88+gedd61302 anndata==0.9.2 umap==0.5.3 numpy==1.24.4 scipy==1.11.1 pandas==2.0.3 scikit-learn==1.3.0 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2580
https://github.com/scverse/scanpy/issues/2580:2088,Usability,learn,learn,2088,"sion of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I was running an older jupyter notebook based on a scanpy tutorial. I had included a call to `scanpy.logging.print_versions()` for debugging purposes. I just ran the code using the the current main branch of scanpy, and it errored out. See below for output. ### Minimal code sample. ```python; import scanpy; scanpy.logging.print_versions(); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[44], line 1; ----> 1 sc.logging.print_versions(). File ~/Documents/Projects/githubPackages/scanpy/scanpy/logging.py:180, in print_versions(file); 178 print_versions(); 179 else:; --> 180 session_info.show(; 181 dependencies=True,; 182 html=False,; 183 excludes=[; 184 'builtins',; 185 'stdlib_list',; 186 'importlib_metadata',; 187 # Special module present if test coverage being calculated; 188 # https://gitlab.com/joelostblom/session_info/-/issues/10; 189 ""$coverage"",; 190 ],; 191 ). File ~/Desktop/data/env/lib/python3.11/site-packages/session_info/main.py:209, in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes); 207 for mod_name in clean_modules:; 208 mod_names.append(mod_name); --> 209 mod = sys.modules[mod_name]; 210 # Since modules use different attribute names to store version info,; 211 # try the most common ones.; 212 try:. KeyError: 'numcodecs'; ```. ### Versions. <details>. The function we are asked to run here is the one that produces the error. As an alternative, I'm pasting the output of `scanpy.settings.set_figure_params(dpi=80, facecolor='white')`, which includes several versions in the output. ```; scanpy==1.10.0.dev88+gedd61302 anndata==0.9.2 umap==0.5.3 numpy==1.24.4 scipy==1.11.1 pandas==2.0.3 scikit-learn==1.3.0 statsmodels==0.14.0 igraph==0.10.6 pynndescent==0.5.10; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2580
https://github.com/scverse/scanpy/pull/2581:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.280  v0.0.281](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.280...v0.0.281); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2581
https://github.com/scverse/scanpy/issues/2583:1079,Integrability,wrap,wrapper,1079,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. Another point that I'd like to throw into the scanpy 2.0 discussion: . Right now, many functions have the `inplace` argument, that determines if a function should write back to `adata` or return the result instead. . With this behavior it is hard to make correct type hints. While it is possible with `@overload`, it is cumbersome because it requires to type out the entire function signature twice. When I asked if it is possible to write these overloads in a more concise way [on stackoverflow](https://stackoverflow.com/questions/75757890/python-overload-single-argument?noredirect=1#comment133653817_75757890) several users argued that changing the return type based on an argument is an anti-pattern, and I think they convinced me. . ## Alternative approach; Have two API levels, e.g. ```py; def scanpy.tl.pca(adata: AnnData, **kwargs) -> None: ...; ```; and; ```py; def scanpy.lowlevel.tl.pca(data: np.ndarray | sp.spmatrix, n_pcs) -> np.ndarray: ...; ```. Where the former is a wrapper for the latter. This allows to separate the implementation of the actual method using only numpy/scipy data types from the scverse-specific behavior.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2583
https://github.com/scverse/scanpy/pull/2585:199,Usability,guid,guidelines,199,"Close #2135. Changed the docstring of `pl.violin` to be consistent with the code, and docs of other similar plotting functions. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2585
https://github.com/scverse/scanpy/pull/2585:230,Usability,guid,guide,230,"Close #2135. Changed the docstring of `pl.violin` to be consistent with the code, and docs of other similar plotting functions. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2585
https://github.com/scverse/scanpy/issues/2586:1315,Availability,down,down,1315,"s() on my gene expression data, I do get separate matrices for names, scores, pvals, and pvals_adj. However, the scores don't match the pvals. In other words, with decreasing pvals, we don't always have increasing score. I did check out the description on the main documentations page, and they say they're calculating the zscores underlying the distribution, however if that's the case shouldn't it always be higher with decreasing pval? Also, I went through the code: it looks like they're calculating the scores on the absolute values instead of the real values--why is this? Are the scores basically U1 values corresponding to the pvalues, in whcih case once again lower pvalues should always have higher scores right?; ares calculated from the p-values? What's the relation between the two. I have ran sc.rank_genes_groups() on my gene expression data, and I have generated the matrix for cluster-1 versus the rest, for reference. You can see that one, the pavlues don't increase as we go down the rows; and two, the scores seem kinda arbitrary to the p-values. What am I missing here? Thanks a lot, and sorry for the wordy question. [NOTE: This doesn't just depend on a specific type of clustering technique. Irrespective of whether I try the in-built Leiden clustering technique, or the Schit library, or even cluster the cells randomly, this issue keeps occuring--which makes me think it's ether a bug, or I don't quite understand how the score generation works, maybe both. I've provided a little code snipper below.]. [ClusterOneVsRest.csv](https://github.com/scverse/scanpy/files/12243486/ClusterOneVsRest.csv). ### Minimal code sample. ```python; import pickle; import numpy as np; import pandas as pd; from PIL import Image; import glob; import matplotlib.pyplot as plt; from skimage.morphology import convex_hull_image; from skimage import data, img_as_float; from skimage.util import invert; from scipy.spatial import ConvexHull, convex_hull_plot_2d; from multiprocessing import Pool; i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586
https://github.com/scverse/scanpy/issues/2586:4053,Availability,Error,Error,4053,"orhood_enrichment; import schist as scs; with open('TNBC_41patients_KerenEtAl.pkl', 'rb') as f:; pickle_= pickle.load(f); pickle_=dict(list(pickle_.items())[7:8]); for i in pickle_:; cnt+=1; adata=pickle_[i]; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=3); sc.tl.leiden(adata); scs.inference.planted_model(adata); sc.pp.scale(adata); sc.tl.rank_genes_groups(adata, groupby='ppbm', pts=True, method='wilcoxon'); adata_rankGenes_names, adata_rankGenes_scores, adata_rankGenes_logfoldchanges, adata_rankGenes_pvals, adata_rankGenes_pvals_adj, adata_rankGenes_pts, adata_rankGenes_pts_rest=pd.DataFrame(adata.uns['rank_genes_groups']['names']), pd.DataFrame(adata.uns['rank_genes_groups']['scores']), pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj']), pd.DataFrame(adata.uns['rank_genes_groups']['pts']), pd.DataFrame(adata.uns['rank_genes_groups']['pts_rest']); ```. ### Error output. ```pytb; It's not really an error, it's just unexpected output. 1. https://github.com/scverse/scanpy/issues/701 says the p-values should always decrease as we go down the rows of the output matrix, which would make sense because the scores are ordered in decreasing order. 2. https://github.com/scverse/scanpy/issues/1688 says that higher score should always correspond to lower p-value, but that's not what's happening. 3. The official documentation says: ""Structured array to be indexed by group id storing the z-score underlying the computation of a p-value for each gene for each group. Ordered according to scores."" --> But if that's the case, why are the scores and p-values not perfectly opposite (that is lower score always equals higher p-value. Also, aren't you generating the U-value corresponding to the p-value?); ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 9.0.1; PyQt5 NA; appdirs 1.4.4; appnope 0.1.2; asciitree NA; asttokens NA; atomic",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586
https://github.com/scverse/scanpy/issues/2586:4095,Availability,error,error,4095,"with open('TNBC_41patients_KerenEtAl.pkl', 'rb') as f:; pickle_= pickle.load(f); pickle_=dict(list(pickle_.items())[7:8]); for i in pickle_:; cnt+=1; adata=pickle_[i]; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=3); sc.tl.leiden(adata); scs.inference.planted_model(adata); sc.pp.scale(adata); sc.tl.rank_genes_groups(adata, groupby='ppbm', pts=True, method='wilcoxon'); adata_rankGenes_names, adata_rankGenes_scores, adata_rankGenes_logfoldchanges, adata_rankGenes_pvals, adata_rankGenes_pvals_adj, adata_rankGenes_pts, adata_rankGenes_pts_rest=pd.DataFrame(adata.uns['rank_genes_groups']['names']), pd.DataFrame(adata.uns['rank_genes_groups']['scores']), pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj']), pd.DataFrame(adata.uns['rank_genes_groups']['pts']), pd.DataFrame(adata.uns['rank_genes_groups']['pts_rest']); ```. ### Error output. ```pytb; It's not really an error, it's just unexpected output. 1. https://github.com/scverse/scanpy/issues/701 says the p-values should always decrease as we go down the rows of the output matrix, which would make sense because the scores are ordered in decreasing order. 2. https://github.com/scverse/scanpy/issues/1688 says that higher score should always correspond to lower p-value, but that's not what's happening. 3. The official documentation says: ""Structured array to be indexed by group id storing the z-score underlying the computation of a p-value for each gene for each group. Ordered according to scores."" --> But if that's the case, why are the scores and p-values not perfectly opposite (that is lower score always equals higher p-value. Also, aren't you generating the U-value corresponding to the p-value?); ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 9.0.1; PyQt5 NA; appdirs 1.4.4; appnope 0.1.2; asciitree NA; asttokens NA; atomicwrites 1.4.0; attr 22.1.0; backcall 0.2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586
https://github.com/scverse/scanpy/issues/2586:4229,Availability,down,down,4229,"=1; adata=pickle_[i]; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=3); sc.tl.leiden(adata); scs.inference.planted_model(adata); sc.pp.scale(adata); sc.tl.rank_genes_groups(adata, groupby='ppbm', pts=True, method='wilcoxon'); adata_rankGenes_names, adata_rankGenes_scores, adata_rankGenes_logfoldchanges, adata_rankGenes_pvals, adata_rankGenes_pvals_adj, adata_rankGenes_pts, adata_rankGenes_pts_rest=pd.DataFrame(adata.uns['rank_genes_groups']['names']), pd.DataFrame(adata.uns['rank_genes_groups']['scores']), pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj']), pd.DataFrame(adata.uns['rank_genes_groups']['pts']), pd.DataFrame(adata.uns['rank_genes_groups']['pts_rest']); ```. ### Error output. ```pytb; It's not really an error, it's just unexpected output. 1. https://github.com/scverse/scanpy/issues/701 says the p-values should always decrease as we go down the rows of the output matrix, which would make sense because the scores are ordered in decreasing order. 2. https://github.com/scverse/scanpy/issues/1688 says that higher score should always correspond to lower p-value, but that's not what's happening. 3. The official documentation says: ""Structured array to be indexed by group id storing the z-score underlying the computation of a p-value for each gene for each group. Ordered according to scores."" --> But if that's the case, why are the scores and p-values not perfectly opposite (that is lower score always equals higher p-value. Also, aren't you generating the U-value corresponding to the p-value?); ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 9.0.1; PyQt5 NA; appdirs 1.4.4; appnope 0.1.2; asciitree NA; asttokens NA; atomicwrites 1.4.0; attr 22.1.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; biothings_client 0.3.0; brotli NA; cairo 1.23.0; certifi 2023.07.22; cffi 1.15.1; chardet 4.0.0; charset_normaliz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586
https://github.com/scverse/scanpy/issues/2586:7787,Deployability,update,updated,7787," 0.18.1; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; lazy_loader NA; leidenalg 0.10.1; llvmlite 0.40.0; markupsafe 2.1.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; matplotlib_scalebar 0.8.1; matplotlib_venn 0.11.9; mkl 2.4.0; mpl_toolkits NA; msgpack 1.0.5; multipledispatch 0.6.0; multiscale_spatial_image 0.11.2; mygene 3.2.2; natsort 7.1.1; nbinom_ufunc NA; neighborhood_enrichment NA; networkx 3.1; numba 0.57.0; numcodecs 0.11.0; numpy 1.24.3; ome_zarr NA; openpyxl 3.1.2; packaging 23.0; pandas 2.0.3; param 1.13.0; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.5.2; pooch v1.4.0; prompt_toolkit 3.0.36; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 12.0.1; pycparser 2.21; pyct 0.5.0; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygeos 0.14; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pyproj 3.6.0; pytz 2022.7; pywt 1.4.1; requests 2.31.0; rich NA; rtree 1.0.1; schist v0.7.16; scipy 1.8.0; seaborn 0.12.2; session_info 1.0.0; setuptools 68.0.0; shapely 2.0.1; sip NA; six 1.16.0; skimage 0.20.0; sklearn 1.2.2; socks 1.7.1; spatial_image 0.3.0; spatialdata 0.0.12; sphinxcontrib NA; spyder 5.4.3; spyder_kernels 2.4.3; spydercustomize NA; squidpy 1.3.0; stack_data 0.2.0; statsmodels 0.14.0; tblib 2.0.0; texttable 1.6.7; threadpoolctl 2.2.0; tifffile 2021.7.2; tlz 0.12.0; toolz 0.12.0; tornado 6.3.2; tqdm 4.65.0; traitlets 5.7.1; typing_extensions NA; umap 0.5.3; urllib3 1.26.16; validators 0.20.0; wcwidth 0.2.5; wurlitzer 3.0.2; xarray 2022.12.0; xarray_dataclasses 1.6.0; xarray_schema 0.0.3; xrspatial 0.3.7; yaml 6.0; zarr 2.16.0; zipp NA; zmq 25.1.0; zoneinfo NA; zstandard 0.19.0; -----; IPython 8.12.0; jupyter_client 8.1.0; jupyter_core 5.3.0; -----; Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:50:29) [Clang 14.0.6 ]; macOS-11.6-x86_64-i386-64bit; -----; Session information updated at 2023-08-02 20:20. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586
https://github.com/scverse/scanpy/issues/2586:1485,Integrability,depend,depend,1485,"vals, we don't always have increasing score. I did check out the description on the main documentations page, and they say they're calculating the zscores underlying the distribution, however if that's the case shouldn't it always be higher with decreasing pval? Also, I went through the code: it looks like they're calculating the scores on the absolute values instead of the real values--why is this? Are the scores basically U1 values corresponding to the pvalues, in whcih case once again lower pvalues should always have higher scores right?; ares calculated from the p-values? What's the relation between the two. I have ran sc.rank_genes_groups() on my gene expression data, and I have generated the matrix for cluster-1 versus the rest, for reference. You can see that one, the pavlues don't increase as we go down the rows; and two, the scores seem kinda arbitrary to the p-values. What am I missing here? Thanks a lot, and sorry for the wordy question. [NOTE: This doesn't just depend on a specific type of clustering technique. Irrespective of whether I try the in-built Leiden clustering technique, or the Schit library, or even cluster the cells randomly, this issue keeps occuring--which makes me think it's ether a bug, or I don't quite understand how the score generation works, maybe both. I've provided a little code snipper below.]. [ClusterOneVsRest.csv](https://github.com/scverse/scanpy/files/12243486/ClusterOneVsRest.csv). ### Minimal code sample. ```python; import pickle; import numpy as np; import pandas as pd; from PIL import Image; import glob; import matplotlib.pyplot as plt; from skimage.morphology import convex_hull_image; from skimage import data, img_as_float; from skimage.util import invert; from scipy.spatial import ConvexHull, convex_hull_plot_2d; from multiprocessing import Pool; import time; import math; from collections import Counter; import scanpy as sc; import networkx as nx; import pandas as pd; import numpy as np; import itertools; import random;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586
https://github.com/scverse/scanpy/issues/2586:3170,Performance,load,load,3170,"_float; from skimage.util import invert; from scipy.spatial import ConvexHull, convex_hull_plot_2d; from multiprocessing import Pool; import time; import math; from collections import Counter; import scanpy as sc; import networkx as nx; import pandas as pd; import numpy as np; import itertools; import random; from scipy.stats import mannwhitneyu; import os; import warnings; import pickle; import matplotlib.pyplot as plt; import pandas as pd; import gseapy as gp; from matplotlib import pyplot as plt; from matplotlib_venn import venn2; import mygene; import seaborn as sns; from gseapy import barplot, dotplot; import random; import matplotlib.pyplot as plt; import numpy as np; import decoupler as dc; from numpy.random import default_rng; from copy import deepcopy; import scanpy as sc; import squidpy as sq; import time; from neighborhood_enrichment import neighborhood_enrichment; import schist as scs; with open('TNBC_41patients_KerenEtAl.pkl', 'rb') as f:; pickle_= pickle.load(f); pickle_=dict(list(pickle_.items())[7:8]); for i in pickle_:; cnt+=1; adata=pickle_[i]; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=3); sc.tl.leiden(adata); scs.inference.planted_model(adata); sc.pp.scale(adata); sc.tl.rank_genes_groups(adata, groupby='ppbm', pts=True, method='wilcoxon'); adata_rankGenes_names, adata_rankGenes_scores, adata_rankGenes_logfoldchanges, adata_rankGenes_pvals, adata_rankGenes_pvals_adj, adata_rankGenes_pts, adata_rankGenes_pts_rest=pd.DataFrame(adata.uns['rank_genes_groups']['names']), pd.DataFrame(adata.uns['rank_genes_groups']['scores']), pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj']), pd.DataFrame(adata.uns['rank_genes_groups']['pts']), pd.DataFrame(adata.uns['rank_genes_groups']['pts_rest']); ```. ### Error output. ```pytb; It's not really an error, it's just unexpected output. 1. https://github.com/scverse/scanpy/issues/701 says the ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586
https://github.com/scverse/scanpy/issues/2586:7361,Security,validat,validators,7361," 0.18.1; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; lazy_loader NA; leidenalg 0.10.1; llvmlite 0.40.0; markupsafe 2.1.1; matplotlib 3.5.3; matplotlib_inline 0.1.6; matplotlib_scalebar 0.8.1; matplotlib_venn 0.11.9; mkl 2.4.0; mpl_toolkits NA; msgpack 1.0.5; multipledispatch 0.6.0; multiscale_spatial_image 0.11.2; mygene 3.2.2; natsort 7.1.1; nbinom_ufunc NA; neighborhood_enrichment NA; networkx 3.1; numba 0.57.0; numcodecs 0.11.0; numpy 1.24.3; ome_zarr NA; openpyxl 3.1.2; packaging 23.0; pandas 2.0.3; param 1.13.0; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.5.2; pooch v1.4.0; prompt_toolkit 3.0.36; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 12.0.1; pycparser 2.21; pyct 0.5.0; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygeos 0.14; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pyproj 3.6.0; pytz 2022.7; pywt 1.4.1; requests 2.31.0; rich NA; rtree 1.0.1; schist v0.7.16; scipy 1.8.0; seaborn 0.12.2; session_info 1.0.0; setuptools 68.0.0; shapely 2.0.1; sip NA; six 1.16.0; skimage 0.20.0; sklearn 1.2.2; socks 1.7.1; spatial_image 0.3.0; spatialdata 0.0.12; sphinxcontrib NA; spyder 5.4.3; spyder_kernels 2.4.3; spydercustomize NA; squidpy 1.3.0; stack_data 0.2.0; statsmodels 0.14.0; tblib 2.0.0; texttable 1.6.7; threadpoolctl 2.2.0; tifffile 2021.7.2; tlz 0.12.0; toolz 0.12.0; tornado 6.3.2; tqdm 4.65.0; traitlets 5.7.1; typing_extensions NA; umap 0.5.3; urllib3 1.26.16; validators 0.20.0; wcwidth 0.2.5; wurlitzer 3.0.2; xarray 2022.12.0; xarray_dataclasses 1.6.0; xarray_schema 0.0.3; xrspatial 0.3.7; yaml 6.0; zarr 2.16.0; zipp NA; zmq 25.1.0; zoneinfo NA; zstandard 0.19.0; -----; IPython 8.12.0; jupyter_client 8.1.0; jupyter_core 5.3.0; -----; Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:50:29) [Clang 14.0.6 ]; macOS-11.6-x86_64-i386-64bit; -----; Session information updated at 2023-08-02 20:20. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586
https://github.com/scverse/scanpy/issues/2586:3800,Testability,log,logfoldchanges,3800,"ot; import random; import matplotlib.pyplot as plt; import numpy as np; import decoupler as dc; from numpy.random import default_rng; from copy import deepcopy; import scanpy as sc; import squidpy as sq; import time; from neighborhood_enrichment import neighborhood_enrichment; import schist as scs; with open('TNBC_41patients_KerenEtAl.pkl', 'rb') as f:; pickle_= pickle.load(f); pickle_=dict(list(pickle_.items())[7:8]); for i in pickle_:; cnt+=1; adata=pickle_[i]; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=3); sc.tl.leiden(adata); scs.inference.planted_model(adata); sc.pp.scale(adata); sc.tl.rank_genes_groups(adata, groupby='ppbm', pts=True, method='wilcoxon'); adata_rankGenes_names, adata_rankGenes_scores, adata_rankGenes_logfoldchanges, adata_rankGenes_pvals, adata_rankGenes_pvals_adj, adata_rankGenes_pts, adata_rankGenes_pts_rest=pd.DataFrame(adata.uns['rank_genes_groups']['names']), pd.DataFrame(adata.uns['rank_genes_groups']['scores']), pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals']), pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj']), pd.DataFrame(adata.uns['rank_genes_groups']['pts']), pd.DataFrame(adata.uns['rank_genes_groups']['pts_rest']); ```. ### Error output. ```pytb; It's not really an error, it's just unexpected output. 1. https://github.com/scverse/scanpy/issues/701 says the p-values should always decrease as we go down the rows of the output matrix, which would make sense because the scores are ordered in decreasing order. 2. https://github.com/scverse/scanpy/issues/1688 says that higher score should always correspond to lower p-value, but that's not what's happening. 3. The official documentation says: ""Structured array to be indexed by group id storing the z-score underlying the computation of a p-value for each gene for each group. Ordered according to scores."" --> But if that's the case, why are the scores and p-values not perfectly opposite (that is lower score always",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2586
https://github.com/scverse/scanpy/issues/2587:2842,Availability,Error,Error,2842,"ow. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between both higher as well as lower values than the specified `n_neighbors` (obviously, sometimes it's also the expected `n_neighbors` value). Perhaps I'm misunderstanding something, but this behavior is somewhat counterintuitive to me and not what I expect; happy to be corrected though!. /Alma. ### Minimal code sample. ```python; # Import packages. import scanpy as sc; import anndata as ad; import numpy as np. # set random seed; np.random.seed(42). # create dummy data. adata = ad.AnnData(shape=(1000,1)); adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities; k = 10; sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell; gr = adata.obsp['connectivities']; nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k; np.testing.assert_equal(nn,k); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; anyio NA; arrow 1.2.3; asciitree NA; asttokens NA; attr 23.1.0; babel 2.12.1; backcall 0.2.0; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.0.4; cloudpickle 2.2.1; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dask 2023.5.1; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 1.2.0; fasteners 0.18; fastjsonschema NA; fqdn NA; h5py 3.8.0; idna 3.4; igraph 0.10.4; ipykernel 6.23.1; isoduration NA; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonpointer 2.3; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.6.0; jupyterlab_server 2.22.1; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.1; markupsafe 2.1.2; matplotlib 3.7.1; mpl_toolkits NA; msgpack 1.0.5; natsort 8.3.1; nbformat 5.8.0; numba 0.57.1; numcodecs 0.11.0; numpy 1.23.4; overrides NA; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickle",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:4985,Deployability,update,updated,4985,".1; backcall 0.2.0; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.0.4; cloudpickle 2.2.1; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dask 2023.5.1; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 1.2.0; fasteners 0.18; fastjsonschema NA; fqdn NA; h5py 3.8.0; idna 3.4; igraph 0.10.4; ipykernel 6.23.1; isoduration NA; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonpointer 2.3; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.6.0; jupyterlab_server 2.22.1; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.1; markupsafe 2.1.2; matplotlib 3.7.1; mpl_toolkits NA; msgpack 1.0.5; natsort 8.3.1; nbformat 5.8.0; numba 0.57.1; numcodecs 0.11.0; numpy 1.23.4; overrides NA; packaging 23.1; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.5.1; prometheus_client NA; prompt_toolkit 3.0.38; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 12.0.1; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.0.9; pyrsistent NA; pythonjsonlogger NA; pytz 2023.3; requests 2.28.1; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; scipy 1.10.1; send2trash NA; session_info 1.0.0; setuptools 66.0.0; six 1.16.0; sklearn 1.2.2; sniffio 1.3.0; socks 1.7.1; stack_data 0.6.2; tblib 2.0.0; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; torch 1.13.1; tornado 6.3.2; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; uri_template NA; urllib3 1.26.15; wcwidth 0.2.6; webcolors 1.13; websocket 1.5.2; yaml 6.0; zarr 2.14.2; zipp NA; zmq 25.1.0; zoneinfo NA; -----; IPython 8.13.2; jupyter_client 8.2.0; jupyter_core 5.3.0; jupyterlab 4.0.1; -----; Python 3.10.11 (main, Apr 20 2023, 19:02:41) [GCC 11.2.0]; Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-glibc2.17; -----; Session information updated at 2023-08-02 14:21; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:2805,Testability,test,testing,2805," applied, would sum to `k` for each row. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between both higher as well as lower values than the specified `n_neighbors` (obviously, sometimes it's also the expected `n_neighbors` value). Perhaps I'm misunderstanding something, but this behavior is somewhat counterintuitive to me and not what I expect; happy to be corrected though!. /Alma. ### Minimal code sample. ```python; # Import packages. import scanpy as sc; import anndata as ad; import numpy as np. # set random seed; np.random.seed(42). # create dummy data. adata = ad.AnnData(shape=(1000,1)); adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities; k = 10; sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell; gr = adata.obsp['connectivities']; nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k; np.testing.assert_equal(nn,k); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.4.0; anyio NA; arrow 1.2.3; asciitree NA; asttokens NA; attr 23.1.0; babel 2.12.1; backcall 0.2.0; brotli NA; certifi 2022.12.07; cffi 1.15.1; charset_normalizer 2.0.4; cloudpickle 2.2.1; comm 0.1.3; cycler 0.10.0; cython_runtime NA; dask 2023.5.1; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 1.2.0; fasteners 0.18; fastjsonschema NA; fqdn NA; h5py 3.8.0; idna 3.4; igraph 0.10.4; ipykernel 6.23.1; isoduration NA; jedi 0.18.2; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonpointer 2.3; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.6.0; jupyterlab_server 2.22.1; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.1; markupsafe 2.1.2; matplotlib 3.7.1; mpl_toolkits NA; msgpack 1.0.5; natsort 8.3.1; nbformat 5.8.0; numba 0.57.1; numcodecs 0.11.0; numpy 1.23.4; overrides NA; packaging 23.1; pandas 2.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/pull/2588:15,Modifiability,layers,layers,15,This PR adds `.layers` support for PCA and regress_out.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2588
https://github.com/scverse/scanpy/pull/2589:79,Testability,log,logreg,79,Fixes a bug where the `groups` argument would return a wrongly sorted list for logreg in rank_gene_groups.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2589
https://github.com/scverse/scanpy/pull/2590:1357,Availability,Mask,Mask,1357,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:; 1. No more tuple-indices and related functionality (i.e., scoring pairwise); 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate; 3. Output is `AnnData` object instead of `DataFrame`; 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs; - [x] Aggregate along other axis; - [x] Keep grouping cols in result; - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?); - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?); - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values; - [x] Support for `obsm`, `varm`; - [ ] Directly pass Series to groupby; - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations); - [ ] Mask argument; - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:523,Modifiability,layers,layers,523,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:; 1. No more tuple-indices and related functionality (i.e., scoring pairwise); 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate; 3. Output is `AnnData` object instead of `DataFrame`; 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs; - [x] Aggregate along other axis; - [x] Keep grouping cols in result; - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?); - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?); - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values; - [x] Support for `obsm`, `varm`; - [ ] Directly pass Series to groupby; - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations); - [ ] Mask argument; - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:71,Usability,guid,guidelines,71,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:; 1. No more tuple-indices and related functionality (i.e., scoring pairwise); 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate; 3. Output is `AnnData` object instead of `DataFrame`; 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs; - [x] Aggregate along other axis; - [x] Keep grouping cols in result; - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?); - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?); - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values; - [x] Support for `obsm`, `varm`; - [ ] Directly pass Series to groupby; - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations); - [ ] Mask argument; - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:102,Usability,guid,guide,102,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:; 1. No more tuple-indices and related functionality (i.e., scoring pairwise); 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate; 3. Output is `AnnData` object instead of `DataFrame`; 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs; - [x] Aggregate along other axis; - [x] Keep grouping cols in result; - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?); - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?); - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values; - [x] Support for `obsm`, `varm`; - [ ] Directly pass Series to groupby; - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations); - [ ] Mask argument; - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/issues/2592:333,Availability,Error,Error,333,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python; adata = sc.read_h5ad('./cis_scanpy.h5ad'); ```. ### Error output. ```pytb; OSError Traceback (most recent call last); File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader); 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")); 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")); 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")); 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")); 499 def read_sparse(elem, _reader):; --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self); ...; 189 f""Above error raised while reading key {elem.name!r} of ""; 190 f""type {type(e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:379,Availability,error,error,379,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python; adata = sc.read_h5ad('./cis_scanpy.h5ad'); ```. ### Error output. ```pytb; OSError Traceback (most recent call last); File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader); 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")); 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")); 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")); 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")); 499 def read_sparse(elem, _reader):; --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self); ...; 189 f""Above error raised while reading key {elem.name!r} of ""; 190 f""type {type(e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:426,Availability,error,error,426,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python; adata = sc.read_h5ad('./cis_scanpy.h5ad'); ```. ### Error output. ```pytb; OSError Traceback (most recent call last); File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader); 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")); 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")); 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")); 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")); 499 def read_sparse(elem, _reader):; --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self); ...; 189 f""Above error raised while reading key {elem.name!r} of ""; 190 f""type {type(e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:521,Availability,Error,Error,521,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python; adata = sc.read_h5ad('./cis_scanpy.h5ad'); ```. ### Error output. ```pytb; OSError Traceback (most recent call last); File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader); 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")); 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")); 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")); 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")); 499 def read_sparse(elem, _reader):; --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self); ...; 189 f""Above error raised while reading key {elem.name!r} of ""; 190 f""type {type(e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:1932,Availability,error,error,1932,"apper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader); 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")); 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")); 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")); 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")); 499 def read_sparse(elem, _reader):; --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self); ...; 189 f""Above error raised while reading key {elem.name!r} of ""; 190 f""type {type(elem)} from {parent}.""; 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /.; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; PyQt5 NA; anyio NA; arrow 1.2.3; asttokens NA; attr 23.1.0; attrs 23.1.0; babel 2.12.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.7; brotli 1.0.9; certifi 2023.07.22; cffi 1.15.1; charset_normalizer 3.2.0; colorama 0.4.6; comm 0.1.4; cvxopt 1.3.1; cycler 0.10.0; cython_runtime NA; ...; Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]; Windows-10-10.0.19045-SP0; -----; Session information updated at 2023-08-04 10:17; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2062,Availability,error,error,2062,"apper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader); 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")); 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")); 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")); 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")); 499 def read_sparse(elem, _reader):; --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self); ...; 189 f""Above error raised while reading key {elem.name!r} of ""; 190 f""type {type(elem)} from {parent}.""; 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /.; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; PyQt5 NA; anyio NA; arrow 1.2.3; asttokens NA; attr 23.1.0; attrs 23.1.0; babel 2.12.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.7; brotli 1.0.9; certifi 2023.07.22; cffi 1.15.1; charset_normalizer 3.2.0; colorama 0.4.6; comm 0.1.4; cvxopt 1.3.1; cycler 0.10.0; cython_runtime NA; ...; Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]; Windows-10-10.0.19045-SP0; -----; Session information updated at 2023-08-04 10:17; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2668,Deployability,update,updated,2668,"apper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader); 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")); 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")); 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")); 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")); 499 def read_sparse(elem, _reader):; --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self); ...; 189 f""Above error raised while reading key {elem.name!r} of ""; 190 f""type {type(elem)} from {parent}.""; 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /.; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; PyQt5 NA; anyio NA; arrow 1.2.3; asttokens NA; attr 23.1.0; attrs 23.1.0; babel 2.12.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.7; brotli 1.0.9; certifi 2023.07.22; cffi 1.15.1; charset_normalizer 3.2.0; colorama 0.4.6; comm 0.1.4; cvxopt 1.3.1; cycler 0.10.0; cython_runtime NA; ...; Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]; Windows-10-10.0.19045-SP0; -----; Session information updated at 2023-08-04 10:17; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2340,Performance,bottleneck,bottleneck,2340,"apper(*args, **kwargs); 201 try:; --> 202 return func(*args, **kwargs); 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers); 234 if self.callback is not None:; --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)); 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec); 240 return read_dataframe(elem); --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader); 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")); 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")); 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")); 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")); 499 def read_sparse(elem, _reader):; --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self); ...; 189 f""Above error raised while reading key {elem.name!r} of ""; 190 f""type {type(elem)} from {parent}.""; 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /.; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; PyQt5 NA; anyio NA; arrow 1.2.3; asttokens NA; attr 23.1.0; attrs 23.1.0; babel 2.12.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.7; brotli 1.0.9; certifi 2023.07.22; cffi 1.15.1; charset_normalizer 3.2.0; colorama 0.4.6; comm 0.1.4; cvxopt 1.3.1; cycler 0.10.0; cython_runtime NA; ...; Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]; Windows-10-10.0.19045-SP0; -----; Session information updated at 2023-08-04 10:17; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/pull/2593:26,Testability,test,tests,26,preparation for more dask tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2593
https://github.com/scverse/scanpy/pull/2595:102,Availability,avail,available,102,"Preparation for more thorough testing of dask support. - [x] move `DaskArray` to `_compat` to have it available everywhere; - [x] test everything using `array_type` or similar with the same fixture; - [x] Add Dask support to `is_constant` (which uses above fixture). the code in [scanpy/metrics/_common.py](https://github.com/scverse/scanpy/pull/2595/files#diff-caabb542dafdc95621693d71cb6a514af1457c05926438e307d3f8107bf91401) has been moved from [scanpy/metrics/_gearys_c.py](https://github.com/scverse/scanpy/pull/2595/files#diff-1ff58f43272e7b1451de7df9813a0d20aba57f55b23d38b2d46e309d75c2879b) without changes. the only real meat this has is in [scanpy/_utils/compute/is_constant.py](https://github.com/scverse/scanpy/pull/2595/files#diff-e2c27335c5bfbbfb5ae9ac042c09411bfaca7d22340c257974d5d2bc68aea677):. https://github.com/scverse/scanpy/blob/f4f4185709b438e9cfe56db806a449634e214756/scanpy/_utils/compute/is_constant.py#L127-L134. its not a great implementation since it concatenates everything along an axis, but that makes it trivially correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2595
https://github.com/scverse/scanpy/pull/2595:30,Testability,test,testing,30,"Preparation for more thorough testing of dask support. - [x] move `DaskArray` to `_compat` to have it available everywhere; - [x] test everything using `array_type` or similar with the same fixture; - [x] Add Dask support to `is_constant` (which uses above fixture). the code in [scanpy/metrics/_common.py](https://github.com/scverse/scanpy/pull/2595/files#diff-caabb542dafdc95621693d71cb6a514af1457c05926438e307d3f8107bf91401) has been moved from [scanpy/metrics/_gearys_c.py](https://github.com/scverse/scanpy/pull/2595/files#diff-1ff58f43272e7b1451de7df9813a0d20aba57f55b23d38b2d46e309d75c2879b) without changes. the only real meat this has is in [scanpy/_utils/compute/is_constant.py](https://github.com/scverse/scanpy/pull/2595/files#diff-e2c27335c5bfbbfb5ae9ac042c09411bfaca7d22340c257974d5d2bc68aea677):. https://github.com/scverse/scanpy/blob/f4f4185709b438e9cfe56db806a449634e214756/scanpy/_utils/compute/is_constant.py#L127-L134. its not a great implementation since it concatenates everything along an axis, but that makes it trivially correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2595
https://github.com/scverse/scanpy/pull/2595:130,Testability,test,test,130,"Preparation for more thorough testing of dask support. - [x] move `DaskArray` to `_compat` to have it available everywhere; - [x] test everything using `array_type` or similar with the same fixture; - [x] Add Dask support to `is_constant` (which uses above fixture). the code in [scanpy/metrics/_common.py](https://github.com/scverse/scanpy/pull/2595/files#diff-caabb542dafdc95621693d71cb6a514af1457c05926438e307d3f8107bf91401) has been moved from [scanpy/metrics/_gearys_c.py](https://github.com/scverse/scanpy/pull/2595/files#diff-1ff58f43272e7b1451de7df9813a0d20aba57f55b23d38b2d46e309d75c2879b) without changes. the only real meat this has is in [scanpy/_utils/compute/is_constant.py](https://github.com/scverse/scanpy/pull/2595/files#diff-e2c27335c5bfbbfb5ae9ac042c09411bfaca7d22340c257974d5d2bc68aea677):. https://github.com/scverse/scanpy/blob/f4f4185709b438e9cfe56db806a449634e214756/scanpy/_utils/compute/is_constant.py#L127-L134. its not a great implementation since it concatenates everything along an axis, but that makes it trivially correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2595
https://github.com/scverse/scanpy/pull/2596:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2596
https://github.com/scverse/scanpy/pull/2596:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2596
https://github.com/scverse/scanpy/pull/2597:25,Deployability,release,release,25,Backport PR #2594: 1.9.4 release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2597
https://github.com/scverse/scanpy/pull/2599:28,Testability,test,tests,28,Backport PR #2575: Simplify tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2599
https://github.com/scverse/scanpy/pull/2599:19,Usability,Simpl,Simplify,19,Backport PR #2575: Simplify tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2599
https://github.com/scverse/scanpy/pull/2600:53,Testability,log,logreg,53,Backport PR #2589: Fixed wrong order for groups with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2600
https://github.com/scverse/scanpy/pull/2601:60,Testability,log,logreg,60,"`get.rank_genes_groups_df` didn't work when the method was ""logreg"". Now it works as intended",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2601
https://github.com/scverse/scanpy/pull/2602:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.281  v0.0.282](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.281...v0.0.282); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2602
https://github.com/scverse/scanpy/pull/2605:280,Integrability,depend,dependencies,280,This PR adds the `--doctest-modules` flag to pytest and makes changes necessary to allow the doctests to run. Those changes include:. - Fixing verbosity; - using [pytest-doctestplus](https://github.com/scientific-python/pytest-doctestplus) to skip doctests entirely or when their dependencies are absent; - fixing broken doctests (the bulk of the changes),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2605
https://github.com/scverse/scanpy/pull/2606:57,Testability,log,logreg,57,Backport PR #2601: fixed `get.rank_genes_groups_df` with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2606
https://github.com/scverse/scanpy/issues/2608:1395,Availability,error,error,1395,"cted keyword argument 'data_df'`. This seems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python; # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir; # (the data comes with the palantir repo); import scanpy.external as sce; import scanpy as sc; adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""); sc.pp.filter_cells(adata, min_counts=1000); sc.pp.filter_genes(adata, min_counts=10); sc.pp.normalize_per_cell(adata); sc.pp.log1p(adata); sc.tl.pca(adata, n_comps=300); sc.pp.neighbors(adata, knn=30); sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here; ```. ### Error output. ```pytb; RuntimeError Traceback (most recent call last); RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(); 5 sc.tl.pca(adata, n_comps=300); 6 sc.pp.neighbors(adata, knn=30); ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy); 207 ; 208 # Diffusion maps; --> 209 dm_res = run_diffusion_maps(; 210 data_df=df,; 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; P",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1423,Availability,Error,Error,1423,"ms to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python; # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir; # (the data comes with the palantir repo); import scanpy.external as sce; import scanpy as sc; adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""); sc.pp.filter_cells(adata, min_counts=1000); sc.pp.filter_genes(adata, min_counts=10); sc.pp.normalize_per_cell(adata); sc.pp.log1p(adata); sc.tl.pca(adata, n_comps=300); sc.pp.neighbors(adata, knn=30); sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here; ```. ### Error output. ```pytb; RuntimeError Traceback (most recent call last); RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(); 5 sc.tl.pca(adata, n_comps=300); 6 sc.pp.neighbors(adata, knn=30); ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy); 207 ; 208 # Diffusion maps; --> 209 dm_res = run_diffusion_maps(; 210 data_df=df,; 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; cffi 1.15.1; colorama 0.4.6; c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:3190,Deployability,update,updated,3190,"p.normalize_per_cell(adata); sc.pp.log1p(adata); sc.tl.pca(adata, n_comps=300); sc.pp.neighbors(adata, knn=30); sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here; ```. ### Error output. ```pytb; RuntimeError Traceback (most recent call last); RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(); 5 sc.tl.pca(adata, n_comps=300); 6 sc.pp.neighbors(adata, knn=30); ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy); 207 ; 208 # Diffusion maps; --> 209 dm_res = run_diffusion_maps(; 210 data_df=df,; 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'; ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 10.0.0; cffi 1.15.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; gmpy2 2.1.2; h5py 3.9.0; igraph 0.10.6; importlib_resources NA; joblib 1.3.2; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.40.1; matplotlib 3.7.2; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; numba 0.57.1; numexpr 2.8.5; numpy 1.24.4; opt_einsum v3.3.0; packaging 23.1; pandas 1.5.3; psutil 5.9.5; pyparsing 3.0.9; pytz 2023.3; scipy 1.11.1; session_info 1.0.0; six 1.16.0; sklearn 1.3.0; sympy 1.12; texttable 1.6.7; threadpoolctl 3.2.0; torch 2.0.0; tqdm 4.65.2; typing_extensions NA; wcwidth 0.2.6; yaml 6.0; zipp NA; zoneinfo NA; -----; Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]; Linux-4.18.0-477.15.1.el8_8.x86_64-x86_64-with-glibc2.28; -----; Session information updated at 2023-08-09 17:08; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2609:684,Availability,Error,Error,684,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I believe that the reference for the `score_genes` function is incorrect. It looks to be listed as Satija et al. (2015), which is this paper: [https://doi.org/10.1038/nbt.3192](https://doi.org/10.1038/nbt.3192). If I am not mistaken the correct reference is this paper: [DOI: 10.1126/science.aad0501](https://doi.org/10.1126/science.aad0501). ### Minimal code sample. ```python; N/A; ```. ### Error output. _No response_. ### Versions. N/A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2609
https://github.com/scverse/scanpy/issues/2611:1106,Availability,Error,Error,1106,"ted.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. ; I find this issue really weird because categories_order works just fine when I am generating a dotplot.; Maybe I am missing something fundamental. ### Minimal code sample. ```python; ##code that does not reorder ( I tried both options 'order' and 'categories_order'; sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders; sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.9.3; -----; OpenSSL 19.0.0; PIL 10.0.0; apport_python_hook NA; backcall 0.2.0; certifi 2019.11.28; cffi 1.15.0; chardet 3.0.4; cloudpickle 2.2.1; colorama 0.4.3; colorcet 3.0.1; cryptography 2.8; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.1; dask 2023.5.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; gseapy 1.0.5; h5py 3.7.0; idna 2.8; igraph 0.10.6; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.10.0; llvmlite 0.39.1; lz4 4.3.2; markupsafe 2.1.3; matplotlib 3.6.1; matplotlib_inline NA; more_itertools NA; mpl_toolkits NA; natsort 8.2.0; netifaces 0.10.4; numba 0.56.3; numexpr 2.8.4; numpy 1.23.5; packaging 21.3; pandas 1.5.3; parso 0.8.2; patsy 0.5.3; pexpect 4.6.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.15.0; prompt_toolkit 3.0.20; psutil 5.9.4; ptyprocess 0.7.0; pyarrow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:2927,Deployability,update,updated,2927,"_No response_. ### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.9.3; -----; OpenSSL 19.0.0; PIL 10.0.0; apport_python_hook NA; backcall 0.2.0; certifi 2019.11.28; cffi 1.15.0; chardet 3.0.4; cloudpickle 2.2.1; colorama 0.4.3; colorcet 3.0.1; cryptography 2.8; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.1; dask 2023.5.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; gseapy 1.0.5; h5py 3.7.0; idna 2.8; igraph 0.10.6; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.10.0; llvmlite 0.39.1; lz4 4.3.2; markupsafe 2.1.3; matplotlib 3.6.1; matplotlib_inline NA; more_itertools NA; mpl_toolkits NA; natsort 8.2.0; netifaces 0.10.4; numba 0.56.3; numexpr 2.8.4; numpy 1.23.5; packaging 21.3; pandas 1.5.3; parso 0.8.2; patsy 0.5.3; pexpect 4.6.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.15.0; prompt_toolkit 3.0.20; psutil 5.9.4; ptyprocess 0.7.0; pyarrow 12.0.1; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.10.0; pyparsing 2.4.7; pytz 2022.4; requests 2.22.0; scipy 1.10.1; seaborn 0.12.0; session_info 1.0.0; setuptools 68.0.0; simplejson 3.16.0; sitecustomize NA; six 1.14.0; sklearn 1.3.0; socks 1.7.1; statsmodels 0.14.0; storemagic NA; tblib 2.0.0; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.1; toolz 0.12.0; tornado 6.1; traitlets 5.1.0; typing_extensions NA; urllib3 1.25.8; wcwidth 0.2.5; yaml 5.3.1; zipp NA; zmq 22.3.0; zope NA; -----; IPython 7.28.0; jupyter_client 7.0.6; jupyter_core 4.8.1; notebook 6.4.5; -----; Python 3.8.10 (default, May 26 2023, 14:05:08) [GCC 9.4.0]; Linux-5.15.0-1040-aws-x86_64-with-glibc2.29; -----; Session information updated at 2023-08-11 23:46; sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order); sc.pl.stacked_violin(adata,['GATA3','CD8A','CD; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:2393,Usability,simpl,simplejson,2393,"_No response_. ### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.9.3; -----; OpenSSL 19.0.0; PIL 10.0.0; apport_python_hook NA; backcall 0.2.0; certifi 2019.11.28; cffi 1.15.0; chardet 3.0.4; cloudpickle 2.2.1; colorama 0.4.3; colorcet 3.0.1; cryptography 2.8; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.1; dask 2023.5.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; gseapy 1.0.5; h5py 3.7.0; idna 2.8; igraph 0.10.6; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.1.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.10.0; llvmlite 0.39.1; lz4 4.3.2; markupsafe 2.1.3; matplotlib 3.6.1; matplotlib_inline NA; more_itertools NA; mpl_toolkits NA; natsort 8.2.0; netifaces 0.10.4; numba 0.56.3; numexpr 2.8.4; numpy 1.23.5; packaging 21.3; pandas 1.5.3; parso 0.8.2; patsy 0.5.3; pexpect 4.6.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.15.0; prompt_toolkit 3.0.20; psutil 5.9.4; ptyprocess 0.7.0; pyarrow 12.0.1; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.10.0; pyparsing 2.4.7; pytz 2022.4; requests 2.22.0; scipy 1.10.1; seaborn 0.12.0; session_info 1.0.0; setuptools 68.0.0; simplejson 3.16.0; sitecustomize NA; six 1.14.0; sklearn 1.3.0; socks 1.7.1; statsmodels 0.14.0; storemagic NA; tblib 2.0.0; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.1; toolz 0.12.0; tornado 6.1; traitlets 5.1.0; typing_extensions NA; urllib3 1.25.8; wcwidth 0.2.5; yaml 5.3.1; zipp NA; zmq 22.3.0; zope NA; -----; IPython 7.28.0; jupyter_client 7.0.6; jupyter_core 4.8.1; notebook 6.4.5; -----; Python 3.8.10 (default, May 26 2023, 14:05:08) [GCC 9.4.0]; Linux-5.15.0-1040-aws-x86_64-with-glibc2.29; -----; Session information updated at 2023-08-11 23:46; sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order); sc.pl.stacked_violin(adata,['GATA3','CD8A','CD; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/pull/2614:322,Integrability,rout,route,322,"Partially reverts #2220 to restore CI to a functional state. I will skip the review since this is a revert of a breakage. - broken links are banned again; - the tutorial links are just links again, but using intersphinx and therefore still not broken. A follow up PR can make the tutorials a submodule again if we go that route, but we wont disable link checking again. Not for a PR like this, and not for anything else. PS: one of the `{tutorial}` links wasnt converted to a ``{doc}`/tutorials/` `` link in #2220. Fixed that too.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2614
https://github.com/scverse/scanpy/pull/2615:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. This PR fixes a typo in the docstring of `scanpy.external.pp.scrublet()`: The `obs` column is actually called `predicted_doublet` instead of `predicted_doublets`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2615
https://github.com/scverse/scanpy/pull/2615:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. This PR fixes a typo in the docstring of `scanpy.external.pp.scrublet()`: The `obs` column is actually called `predicted_doublet` instead of `predicted_doublets`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2615
https://github.com/scverse/scanpy/pull/2617:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.282  v0.0.284](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.282...v0.0.284); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2617
https://github.com/scverse/scanpy/pull/2621:315,Testability,Assert,AssertionError,315,"This PR. - makes `_utils.check_nonnegative_integers` work with Dask arrays and with that also `rank_genes_groups`; - Adds type hints that I added while re-familiarizing myself with some APIs; - adds a function pair `lazy_{and,or}` that make it possible to delay checks with dask:. ```py; >>> def fail():; ... raise AssertionError(); >>> # rhs can be a function or dask array; >>> lazy_and(False, fail); False; >>> lazy_and(False, da.array(True).map_blocks(lambda _: fail(), meta=np.bool_(True))); False; >>> # lhs can be a function or dask array for nested use; >>> # when not nested, a lhs function will be called eagerly like in `a() and b`; >>> lazy_and(False, lazy_and(fail, _)); False; >>> # will not create a recursive dask array; >>> lazy_and(da.array(True), da.array(False)).compute(); False; >>> # will complain on invalid use; >>> lazy_and(True, lambda: da.array(...)); 'AssertionError: Use lazy_*(_, da.array(...)) instead of lazy_*(_, lambda: da.array(...)).'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621
https://github.com/scverse/scanpy/pull/2621:881,Testability,Assert,AssertionError,881,"This PR. - makes `_utils.check_nonnegative_integers` work with Dask arrays and with that also `rank_genes_groups`; - Adds type hints that I added while re-familiarizing myself with some APIs; - adds a function pair `lazy_{and,or}` that make it possible to delay checks with dask:. ```py; >>> def fail():; ... raise AssertionError(); >>> # rhs can be a function or dask array; >>> lazy_and(False, fail); False; >>> lazy_and(False, da.array(True).map_blocks(lambda _: fail(), meta=np.bool_(True))); False; >>> # lhs can be a function or dask array for nested use; >>> # when not nested, a lhs function will be called eagerly like in `a() and b`; >>> lazy_and(False, lazy_and(fail, _)); False; >>> # will not create a recursive dask array; >>> lazy_and(da.array(True), da.array(False)).compute(); False; >>> # will complain on invalid use; >>> lazy_and(True, lambda: da.array(...)); 'AssertionError: Use lazy_*(_, da.array(...)) instead of lazy_*(_, lambda: da.array(...)).'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621
https://github.com/scverse/scanpy/issues/2625:462,Usability,guid,guide,462,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. Dear Scanpy Team,. Ive been working with the sc.pl.matrixplot function to visualize my data. I have a specific requirement regarding the placement of the dendrogram and cluster names in the matrix plot, both on the same side. In my current usage of sc.pl.matrixplot, I would like to customize the positioning of the dendrogram and the cluster names. Could you kindly guide me on how to achieve the placement of the dendrogram and cluster names on one side of the matrix plot for reading the plot easier? I would greatly appreciate any insights or suggestions you could provide. Thank you for your time and assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2625
https://github.com/scverse/scanpy/issues/2626:238,Performance,perform,perform,238,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values?. ```py; scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2626:652,Performance,optimiz,optimizer,652,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values?. ```py; scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2627:1175,Availability,Error,Error,1175," scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. After running `sc.external.pp.scrublet` function, the image plot embedding in jupyterlab is missing. And there is a warning,; ```; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.; pl.show(); ```. ### Minimal code sample. ```python. import scanpy as sc; import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25); adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True); sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],; jitter=0.4, multi_panel=True, save=""_before_QC.pdf""); ```. ### Error output. ```pytb; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata); Detected doublet rate = 1.7%; Estimated detectable doublet fraction = 41.1%; Overall doublet rate:; 	Expected = 6.0%; 	Estimated = 4.1%; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.; adata.obs[obs_metrics.columns] = obs_metrics; WARNING: saving figure to file figures/violin_before_QC.pdf; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight; self._figure.tight_layout(*args, **kwargs); /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI bac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:4485,Deployability,update,updated,4485,"1.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.2; dask 2023.2.0; dateutil 2.8.2; debugpy 1.6.8; decorator 5.1.1; defusedxml 0.7.1; executing 1.2.0; fastjsonschema NA; fontTools 4.42.0; fqdn NA; h5py 3.9.0; idna 3.4; igraph 0.10.2; importlib_resources NA; ipykernel 6.25.1; ipywidgets 8.1.0; isoduration NA; jedi 0.19.0; jinja2 3.1.2; joblib 1.3.2; json5 NA; jsonpointer 2.0; jsonschema 4.19.0; jsonschema_specifications NA; jupyter_events 0.7.0; jupyter_server 2.7.1; jupyterlab_server 2.24.0; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.1; lxml 4.9.1; markupsafe 2.1.3; matplotlib 3.7.2; mpl_toolkits NA; natsort 8.4.0; nbformat 5.9.2; numba 0.57.1; numexpr 2.8.4; numpy 1.24.4; overrides NA; packaging 23.1; pandas 2.0.3; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; prometheus_client NA; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 11.0.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.16.1; pyparsing 3.0.9; pythonjsonlogger NA; pytz 2023.3; referencing NA; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rpds NA; scipy 1.10.1; scrublet NA; seaborn 0.12.2; send2trash NA; session_info 1.0.0; setuptools_scm NA; six 1.16.0; sklearn 1.3.0; sniffio 1.3.0; socks 1.7.1; sphinxcontrib NA; stack_data 0.6.2; statsmodels 0.14.0; tblib 1.7.0; texttable 1.6.7; threadpoolctl 3.2.0; tlz 0.12.2; toolz 0.12.0; tornado 6.3.3; traitlets 5.9.0; typing_extensions NA; uri_template NA; urllib3 2.0.4; wcwidth 0.2.6; webcolors 1.13; websocket 1.6.1; yaml 6.0; zipp NA; zmq 25.1.1; -----; IPython 8.7.0; jupyter_client 8.3.0; jupyter_core 5.3.0; jupyterlab 4.0.5; notebook 7.0.2; -----; Python 3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:46:39) [GCC 10.4.0]; Linux-4.18.0-348.7.1.el8_5.x86_64-x86_64-with-glibc2.10; -----; Session information updated at 2023-08-20 12:04; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:1388,Safety,Detect,Detected,1388,"ng. And there is a warning,; ```; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.; pl.show(); ```. ### Minimal code sample. ```python. import scanpy as sc; import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25); adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True); sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],; jitter=0.4, multi_panel=True, save=""_before_QC.pdf""); ```. ### Error output. ```pytb; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata); Detected doublet rate = 1.7%; Estimated detectable doublet fraction = 41.1%; Overall doublet rate:; 	Expected = 6.0%; 	Estimated = 4.1%; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.; adata.obs[obs_metrics.columns] = obs_metrics; WARNING: saving figure to file figures/violin_before_QC.pdf; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight; self._figure.tight_layout(*args, **kwargs); /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.; pl.show(); ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 9.2.0; annoy NA; anyio NA; arrow 1.2.3; asttokens NA; attr 23.1.0; attrs 23.1.0; ba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:1428,Safety,detect,detectable,1428,"onda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.; pl.show(); ```. ### Minimal code sample. ```python. import scanpy as sc; import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25); adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True); sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],; jitter=0.4, multi_panel=True, save=""_before_QC.pdf""); ```. ### Error output. ```pytb; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy.; view_to_actual(adata); Detected doublet rate = 1.7%; Estimated detectable doublet fraction = 41.1%; Overall doublet rate:; 	Expected = 6.0%; 	Estimated = 4.1%; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.; adata.obs[obs_metrics.columns] = obs_metrics; WARNING: saving figure to file figures/violin_before_QC.pdf; /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight; self._figure.tight_layout(*args, **kwargs); /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.; pl.show(); ```. ### Versions. <details>. ```; -----; anndata 0.9.2; scanpy 1.9.3; -----; PIL 9.2.0; annoy NA; anyio NA; arrow 1.2.3; asttokens NA; attr 23.1.0; attrs 23.1.0; babel 2.12.1; backcall 0.2.0; brotli NA; certifi 20",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2628:1719,Availability,Error,Error,1719,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: ; upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python; sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names; result = pd.DataFrame(; {group + '_' + key: results[key][group]; for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []; for i in groups:; group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]; group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}); group['group'] = i; de_results.append(group); de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True); de_results; ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:907,Testability,test,test,907,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: ; upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python; sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names; result = pd.DataFrame(; {group + '_' + key: results[key][group]; for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []; for i in groups:; group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]; group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}); group['group'] = i; de_results.append(group); de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True); de_results; ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:1240,Testability,log,logfoldchanges,1240,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: ; upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python; sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names; result = pd.DataFrame(; {group + '_' + key: results[key][group]; for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []; for i in groups:; group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]; group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}); group['group'] = i; de_results.append(group); de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True); de_results; ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2629:691,Availability,down,down,691,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi! I am not sure if this is a bug... ; Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening?; (Note: The matrix is not sparse). ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; ### Loading and preprocessing data; adata = sc.datasets.pbmc3k_processed(). ### Defining scale function; def mean_var(X, axis=0):; mean = np.mean(X, axis=axis, dtype=np.float64); mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); var = mean_sq - mean**2; # enforce R convention (unbiased estimator) for variance; var *= X.shape[axis] / (X.shape[axis] - 1); return mean, var; def my_scale_function(X, clip=False):; mean, var = mean_var(X, axis=0); X -= mean; std = np.sqrt(var); std[std == 0] = 1; X /= std; if clip:; X = np.clip(X, -10, 10); return np.matrix(X). ### Scanpy scale vs my_scale_function; mtx = adata.X; from scipy.sparse import issparse; print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""); print(""Rescaled with my_scale_function:""); mtx_rescaled = my_scale_function(mtx); print((mtx == mtx_rescaled).all()); print(""Rescaled with scanpy:""); mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True); print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""); print(""\nOriginal matrix:""); print(mtx); print(""\nMatrix rescaled with scanpy:""); print(mtx_rescaled); ```. ### Error ou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:1993,Availability,Error,Error,1993," mean = np.mean(X, axis=axis, dtype=np.float64); mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); var = mean_sq - mean**2; # enforce R convention (unbiased estimator) for variance; var *= X.shape[axis] / (X.shape[axis] - 1); return mean, var; def my_scale_function(X, clip=False):; mean, var = mean_var(X, axis=0); X -= mean; std = np.sqrt(var); std[std == 0] = 1; X /= std; if clip:; X = np.clip(X, -10, 10); return np.matrix(X). ### Scanpy scale vs my_scale_function; mtx = adata.X; from scipy.sparse import issparse; print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""); print(""Rescaled with my_scale_function:""); mtx_rescaled = my_scale_function(mtx); print((mtx == mtx_rescaled).all()); print(""Rescaled with scanpy:""); mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True); print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""); print(""\nOriginal matrix:""); print(mtx); print(""\nMatrix rescaled with scanpy:""); print(mtx_rescaled); ```. ### Error output. ```pytb; mtx is parse=False. Rescaled with my_scale_function:; True; Rescaled with scanpy:; False. Original matrix:; [[-1.71469614e-01 -2.82757759e-01 -4.95753549e-02 ... -1.02923915e-01; -2.09179729e-01 -5.31203270e-01]; [-2.14582354e-01 -3.75530124e-01 -6.44599497e-02 ... -2.92909533e-01; -3.13310266e-01 -5.96654296e-01]; [-3.76887709e-01 -2.97174782e-01 -6.94468468e-02 ... -1.70980677e-01; -1.70931697e-01 1.37899971e+00]; ...; [-2.07089618e-01 -2.52101928e-01 -4.90629673e-02 ... -4.98141423e-02; -1.61111996e-01 2.04149699e+00]; [-1.90328494e-01 -2.27726802e-01 -4.46720645e-02 ... 1.15651824e-03; -1.35240912e-01 -4.82111037e-01]; [-3.33789378e-01 -2.55257130e-01 -6.06345981e-02 ... -8.05590525e-02; -1.30351290e-01 -4.71337825e-01]]. Matrix rescaled with scanpy:; [[-1.7146961e-01 -2.8275776e-01 -4.9575359e-02 ... -1.0292391e-01; -2.0917973e-01 -5.3120327e-01]; [-2.1458235e-01 -3.7553012e-01 -6.4459950e-02 ... -2.9290953e-01; -3.1331027e-01 -5.9665430e-01]; [-3.7688771e-01 -2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:5615,Deployability,update,updated,5615,"ycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; decoupler 1.4.0; defusedxml 0.7.1; dill 0.3.5.1; executing 1.2.0; fastjsonschema NA; fqdn NA; gseapy 1.0.5; h5py 3.9.0; idna 3.4; igraph 0.10.6; ipykernel 6.25.0; isoduration NA; jedi 0.19.0; jinja2 3.1.2; joblib 1.3.1; json5 NA; jsonpointer 2.4; jsonschema 4.18.4; jsonschema_specifications NA; jupyter_events 0.7.0; jupyter_server 2.7.0; jupyterlab_server 2.24.0; kiwisolver 1.4.4; leidenalg 0.10.1; liana 0.1.9; llvmlite 0.40.1; markupsafe 2.1.3; matplotlib 3.6.3; matplotlib_inline 0.1.6; mizani 0.9.2; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; nbformat 5.9.2; numba 0.57.1; numpy 1.24.4; overrides NA; packaging 23.1; pandas 1.5.3; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; plotnine 0.12.2; prometheus_client NA; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 12.0.1; pycparser 2.21; pydeseq2 0.3.5; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.1.1; pythonjsonlogger NA; pytz 2023.3; referencing NA; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rnaxplorer NA; rpds NA; scipy 1.11.1; seaborn 0.12.2; send2trash NA; session_info 1.0.0; sitecustomize NA; six 1.16.0; sklearn 1.3.0; sniffio 1.3.0; sphinxcontrib NA; stack_data 0.6.2; statsmodels 0.14.0; texttable 1.6.7; threadpoolctl 3.2.0; torch 1.13.1+cu117; tornado 6.3.2; tqdm 4.65.0; traitlets 5.9.0; typing_extensions NA; umap 0.5.3; uri_template NA; urllib3 2.0.4; wcwidth 0.2.6; webcolors 1.13; websocket 1.6.1; yaml 6.0.1; zmq 25.1.0; zoneinfo NA; -----; IPython 8.14.0; jupyter_client 8.3.0; jupyter_core 5.3.1; jupyterlab 4.0.3; notebook 7.0.1; -----; Python 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]; Linux-5.15.0-1033-gke-x86_64-with-glibc2.35; -----; Session information updated at 2023-08-21 12:14. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:548,Modifiability,rewrite,rewrite,548,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi! I am not sure if this is a bug... ; Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening?; (Note: The matrix is not sparse). ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; ### Loading and preprocessing data; adata = sc.datasets.pbmc3k_processed(). ### Defining scale function; def mean_var(X, axis=0):; mean = np.mean(X, axis=axis, dtype=np.float64); mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); var = mean_sq - mean**2; # enforce R convention (unbiased estimator) for variance; var *= X.shape[axis] / (X.shape[axis] - 1); return mean, var; def my_scale_function(X, clip=False):; mean, var = mean_var(X, axis=0); X -= mean; std = np.sqrt(var); std[std == 0] = 1; X /= std; if clip:; X = np.clip(X, -10, 10); return np.matrix(X). ### Scanpy scale vs my_scale_function; mtx = adata.X; from scipy.sparse import issparse; print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""); print(""Rescaled with my_scale_function:""); mtx_rescaled = my_scale_function(mtx); print((mtx == mtx_rescaled).all()); print(""Rescaled with scanpy:""); mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True); print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""); print(""\nOriginal matrix:""); print(mtx); print(""\nMatrix rescaled with scanpy:""); print(mtx_rescaled); ```. ### Error ou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:871,Performance,Load,Loading,871,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi! I am not sure if this is a bug... ; Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening?; (Note: The matrix is not sparse). ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; ### Loading and preprocessing data; adata = sc.datasets.pbmc3k_processed(). ### Defining scale function; def mean_var(X, axis=0):; mean = np.mean(X, axis=axis, dtype=np.float64); mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); var = mean_sq - mean**2; # enforce R convention (unbiased estimator) for variance; var *= X.shape[axis] / (X.shape[axis] - 1); return mean, var; def my_scale_function(X, clip=False):; mean, var = mean_var(X, axis=0); X -= mean; std = np.sqrt(var); std[std == 0] = 1; X /= std; if clip:; X = np.clip(X, -10, 10); return np.matrix(X). ### Scanpy scale vs my_scale_function; mtx = adata.X; from scipy.sparse import issparse; print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""); print(""Rescaled with my_scale_function:""); mtx_rescaled = my_scale_function(mtx); print((mtx == mtx_rescaled).all()); print(""Rescaled with scanpy:""); mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True); print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""); print(""\nOriginal matrix:""); print(mtx); print(""\nMatrix rescaled with scanpy:""); print(mtx_rescaled); ```. ### Error ou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:576,Usability,simpl,simple,576,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi! I am not sure if this is a bug... ; Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening?; (Note: The matrix is not sparse). ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; ### Loading and preprocessing data; adata = sc.datasets.pbmc3k_processed(). ### Defining scale function; def mean_var(X, axis=0):; mean = np.mean(X, axis=axis, dtype=np.float64); mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64); var = mean_sq - mean**2; # enforce R convention (unbiased estimator) for variance; var *= X.shape[axis] / (X.shape[axis] - 1); return mean, var; def my_scale_function(X, clip=False):; mean, var = mean_var(X, axis=0); X -= mean; std = np.sqrt(var); std[std == 0] = 1; X /= std; if clip:; X = np.clip(X, -10, 10); return np.matrix(X). ### Scanpy scale vs my_scale_function; mtx = adata.X; from scipy.sparse import issparse; print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""); print(""Rescaled with my_scale_function:""); mtx_rescaled = my_scale_function(mtx); print((mtx == mtx_rescaled).all()); print(""Rescaled with scanpy:""); mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True); print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""); print(""\nOriginal matrix:""); print(mtx); print(""\nMatrix rescaled with scanpy:""); print(mtx_rescaled); ```. ### Error ou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2630:405,Availability,avail,available,405,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. Hello Scanpy team!. In scanpy api documentation I see [some settings](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig), however I don't understand how we are supposed to use n_job and max_memory settings. I would like scanpy to use whatever is available. How can I do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2630
https://github.com/scverse/scanpy/pull/2631:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.284  v0.0.285](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.284...v0.0.285); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2631
https://github.com/scverse/scanpy/issues/2634:414,Availability,down,download,414,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with ; https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this?. ### Minimal code sample. ```python; https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48; ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:831,Availability,Error,Error,831,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with ; https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this?. ### Minimal code sample. ```python; https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48; ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:588,Testability,log,log-fold,588,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with ; https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this?. ### Minimal code sample. ```python; https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48; ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2635:587,Availability,error,error,587,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:; `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python; var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'); sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40); sc.tl.paga(adata_ref, groups = 'cell_type'); sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph; sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'); sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); sc.tl.paga(adata, groups = 'seurat_clusters'); sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph; sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'); ```. ### Error output. ```pytb; ValueError Traceback (most recent call last); <ipython-input-18-6b34a6250614> in <module>; 1 # we map our tabula sapiens cell type labels onto our data; ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 124 labeling_method = labeling_method * len(obs); 125 ; --> 126 ing = Ingest(adata_ref, n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:1515,Availability,Error,Error,1515,"rating neighbor graphs. . When I run ingest I receive the following error message:; `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python; var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'); sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40); sc.tl.paga(adata_ref, groups = 'cell_type'); sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph; sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'); sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); sc.tl.paga(adata, groups = 'seurat_clusters'); sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph; sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'); ```. ### Error output. ```pytb; ValueError Traceback (most recent call last); <ipython-input-18-6b34a6250614> in <module>; 1 # we map our tabula sapiens cell type labels onto our data; ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 124 labeling_method = labeling_method * len(obs); 125 ; --> 126 ing = Ingest(adata_ref, neighbors_key); 127 ing.fit(adata); 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key); 383 ; 384 if neighbors_key in adata.uns:; --> 385 self._init_neighbors(adata, neighbors_key); 386 else:; 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key); 349 else:; 350 self._neigh_random_state = neighbors['params'].get('random_state', 0); --> 351 self._init_pynndescent(neighbors['distances'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3529,Availability,down,downgrade,3529,"scent(neighbors['distances']); 352 ; 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances); 284 ; 285 first_col = np.arange(distances.shape[0])[:, None]; --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))); 287 ; 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out); 425 shapes = {arr.shape for arr in arrays}; 426 if len(shapes) != 1:; --> 427 raise ValueError('all input arrays must have the same shape'); 428 ; 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape; ```. ### Versions. ```; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.8.0; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 7.1.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.1.1; google NA; h5py 3.7.0; ipykernel 5.3.0; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.0; joblib 1.1.0; kiwisolver 1.2.0; llvmlite 0.38.1; matplotlib 3.3.0; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; netifaces 0.11.0; numba 0.55.2; numexpr 2.8.3; numpy 1.20.0; packaging 21.3; pandas 1.1.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.9.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 3.0.8; pytz 2022.1; ruamel N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3508,Deployability,install,installs,3508,"scent(neighbors['distances']); 352 ; 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances); 284 ; 285 first_col = np.arange(distances.shape[0])[:, None]; --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))); 287 ; 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out); 425 shapes = {arr.shape for arr in arrays}; 426 if len(shapes) != 1:; --> 427 raise ValueError('all input arrays must have the same shape'); 428 ; 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape; ```. ### Versions. ```; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.8.0; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 7.1.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.1.1; google NA; h5py 3.7.0; ipykernel 5.3.0; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.0; joblib 1.1.0; kiwisolver 1.2.0; llvmlite 0.38.1; matplotlib 3.3.0; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; netifaces 0.11.0; numba 0.55.2; numexpr 2.8.3; numpy 1.20.0; packaging 21.3; pandas 1.1.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.9.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 3.0.8; pytz 2022.1; ruamel N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3645,Deployability,install,install,3645,"escent(self, distances); 284 ; 285 first_col = np.arange(distances.shape[0])[:, None]; --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))); 287 ; 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out); 425 shapes = {arr.shape for arr in arrays}; 426 if len(shapes) != 1:; --> 427 raise ValueError('all input arrays must have the same shape'); 428 ; 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape; ```. ### Versions. ```; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.8.0; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 7.1.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.1.1; google NA; h5py 3.7.0; ipykernel 5.3.0; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.0; joblib 1.1.0; kiwisolver 1.2.0; llvmlite 0.38.1; matplotlib 3.3.0; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; netifaces 0.11.0; numba 0.55.2; numexpr 2.8.3; numpy 1.20.0; packaging 21.3; pandas 1.1.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.9.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 3.0.8; pytz 2022.1; ruamel NA; scipy 1.7.0; seaborn 0.11.2; setuptools 62.1.0; simplejson 3.17.6; six 1.16.0; sklearn 1.0.1; statsmodels 0.13.2; storemagic NA; tables 3.7.0;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:5056,Deployability,update,updated,5056,"all input arrays must have the same shape'); 428 ; 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape; ```. ### Versions. ```; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.8.0; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 7.1.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.1.1; google NA; h5py 3.7.0; ipykernel 5.3.0; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.0; joblib 1.1.0; kiwisolver 1.2.0; llvmlite 0.38.1; matplotlib 3.3.0; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; netifaces 0.11.0; numba 0.55.2; numexpr 2.8.3; numpy 1.20.0; packaging 21.3; pandas 1.1.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.9.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 3.0.8; pytz 2022.1; ruamel NA; scipy 1.7.0; seaborn 0.11.2; setuptools 62.1.0; simplejson 3.17.6; six 1.16.0; sklearn 1.0.1; statsmodels 0.13.2; storemagic NA; tables 3.7.0; threadpoolctl 3.1.0; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 19.0.1; -----; IPython 7.15.0; jupyter_client 6.1.3; jupyter_core 4.6.3; jupyterlab 2.1.4; notebook 6.1.5; -----; Python 3.7.13 (default, Aug 6 2022, 00:43:34) [GCC 9.2.0]; Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.7-Green_Obsidian; 192 logical CPU cores, x86_64; -----; Session information updated at 2023-08-22 16:49; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:593,Integrability,message,message,593,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:; `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python; var_names = adata_ref.var_names.intersection(adata.var_names); adata_ref = adata_ref[:, var_names]; adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'); sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40); sc.tl.paga(adata_ref, groups = 'cell_type'); sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph; sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'); sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); sc.tl.paga(adata, groups = 'seurat_clusters'); sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph; sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'); ```. ### Error output. ```pytb; ValueError Traceback (most recent call last); <ipython-input-18-6b34a6250614> in <module>; 1 # we map our tabula sapiens cell type labels onto our data; ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 124 labeling_method = labeling_method * len(obs); 125 ; --> 126 ing = Ingest(adata_ref, n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3590,Integrability,message,message,3590,"ib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances); 284 ; 285 first_col = np.arange(distances.shape[0])[:, None]; --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))); 287 ; 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out); 425 shapes = {arr.shape for arr in arrays}; 426 if len(shapes) != 1:; --> 427 raise ValueError('all input arrays must have the same shape'); 428 ; 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape; ```. ### Versions. ```; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.8.0; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 7.1.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.1.1; google NA; h5py 3.7.0; ipykernel 5.3.0; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.0; joblib 1.1.0; kiwisolver 1.2.0; llvmlite 0.38.1; matplotlib 3.3.0; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; netifaces 0.11.0; numba 0.55.2; numexpr 2.8.3; numpy 1.20.0; packaging 21.3; pandas 1.1.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.9.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 3.0.8; pytz 2022.1; ruamel NA; scipy 1.7.0; seaborn 0.11.2; setuptools 62.1.0; simplejson 3.17.6; six 1.16.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3489,Safety,avoid,avoid,3489,"scent(neighbors['distances']); 352 ; 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances); 284 ; 285 first_col = np.arange(distances.shape[0])[:, None]; --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))); 287 ; 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out); 425 shapes = {arr.shape for arr in arrays}; 426 if len(shapes) != 1:; --> 427 raise ValueError('all input arrays must have the same shape'); 428 ; 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape; ```. ### Versions. ```; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.8.0; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 7.1.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.1.1; google NA; h5py 3.7.0; ipykernel 5.3.0; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.0; joblib 1.1.0; kiwisolver 1.2.0; llvmlite 0.38.1; matplotlib 3.3.0; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; netifaces 0.11.0; numba 0.55.2; numexpr 2.8.3; numpy 1.20.0; packaging 21.3; pandas 1.1.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.9.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 3.0.8; pytz 2022.1; ruamel N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:5002,Testability,log,logical,5002,"all input arrays must have the same shape'); 428 ; 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape; ```. ### Versions. ```; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.8.0; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 7.1.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.1.1; google NA; h5py 3.7.0; ipykernel 5.3.0; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.0; joblib 1.1.0; kiwisolver 1.2.0; llvmlite 0.38.1; matplotlib 3.3.0; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; netifaces 0.11.0; numba 0.55.2; numexpr 2.8.3; numpy 1.20.0; packaging 21.3; pandas 1.1.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.9.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 3.0.8; pytz 2022.1; ruamel NA; scipy 1.7.0; seaborn 0.11.2; setuptools 62.1.0; simplejson 3.17.6; six 1.16.0; sklearn 1.0.1; statsmodels 0.13.2; storemagic NA; tables 3.7.0; threadpoolctl 3.1.0; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 19.0.1; -----; IPython 7.15.0; jupyter_client 6.1.3; jupyter_core 4.6.3; jupyterlab 2.1.4; notebook 6.1.5; -----; Python 3.7.13 (default, Aug 6 2022, 00:43:34) [GCC 9.2.0]; Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.7-Green_Obsidian; 192 logical CPU cores, x86_64; -----; Session information updated at 2023-08-22 16:49; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:4543,Usability,simpl,simplejson,4543,"all input arrays must have the same shape'); 428 ; 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape; ```. ### Versions. ```; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.8.0; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 7.1.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.1.1; google NA; h5py 3.7.0; ipykernel 5.3.0; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.0; joblib 1.1.0; kiwisolver 1.2.0; llvmlite 0.38.1; matplotlib 3.3.0; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; netifaces 0.11.0; numba 0.55.2; numexpr 2.8.3; numpy 1.20.0; packaging 21.3; pandas 1.1.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; psutil 5.9.0; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 3.0.8; pytz 2022.1; ruamel NA; scipy 1.7.0; seaborn 0.11.2; setuptools 62.1.0; simplejson 3.17.6; six 1.16.0; sklearn 1.0.1; statsmodels 0.13.2; storemagic NA; tables 3.7.0; threadpoolctl 3.1.0; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 19.0.1; -----; IPython 7.15.0; jupyter_client 6.1.3; jupyter_core 4.6.3; jupyterlab 2.1.4; notebook 6.1.5; -----; Python 3.7.13 (default, Aug 6 2022, 00:43:34) [GCC 9.2.0]; Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.7-Green_Obsidian; 192 logical CPU cores, x86_64; -----; Session information updated at 2023-08-22 16:49; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2636:587,Deployability,release,release,587,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. The tutorial submodule was removed as part of a fix-up pass over the docs by @flying-sheep. The issue at the time was warnings which weren't immediately obvious how to fix. Since there are a number of reasons to prefer the submodule approach over a separate scanpy-tutorials website, I would like to bring it back. The plan is: bring back the submodule. In this PR I'll see if the warnings can be easily fixed. If they can't, they'll be silenced and an issue tracking fixing them for the next release will be opened.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2636
https://github.com/scverse/scanpy/pull/2637:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Fixes #2630,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2637
https://github.com/scverse/scanpy/pull/2637:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Fixes #2630,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2637
https://github.com/scverse/scanpy/pull/2639:240,Deployability,release,release,240,"I went through the PRs and we actually did a good job (at least for the backported ones): Nothing missing!. Regarding the new 1.9.5.md: Even if 1.9.5 will probably not happen, we should just keep the file and fill it as expected, and if we release 1.10 first, we just migrate the by-then-merged changes over and delete the 1.9.5.md. Better to stick to a clean process than improvising and making things confusing.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2639
https://github.com/scverse/scanpy/pull/2641:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2641
https://github.com/scverse/scanpy/pull/2641:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2641
https://github.com/scverse/scanpy/pull/2642:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.285  v0.0.286](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.285...v0.0.286); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2642
https://github.com/scverse/scanpy/issues/2644:142,Deployability,release,release,142,### What kind of feature would you like to request?. Other?. ### Please describe your wishes. Basically using the GitHub UI to create a tag & release should kick of both a PyPI release and also ideally activate that tag on rtd (#2425). We should finish #2569 before that,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2644
https://github.com/scverse/scanpy/issues/2644:177,Deployability,release,release,177,### What kind of feature would you like to request?. Other?. ### Please describe your wishes. Basically using the GitHub UI to create a tag & release should kick of both a PyPI release and also ideally activate that tag on rtd (#2425). We should finish #2569 before that,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2644
https://github.com/scverse/scanpy/issues/2645:570,Availability,Error,Error,570,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:853,Availability,error,error,853,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1056,Availability,error,errors,1056,". - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, key",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1068,Availability,error,error,1068,"onfirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1616,Availability,error,error,1616," strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 645 """"""\; 646 Violin plot.; 647 ; (...); 745 pl.stacked_violin; 746 """"""; 747 import seaborn as sns # Slow import, only import if called; --> 749 sanitize_anndata(adata); 750 use_raw = _check_use_raw(adata, use_raw); 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata); 404 def sanitize_anndata(adata):; 405 """"""Transf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1713,Availability,Error,Error,1713,"dding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 645 """"""\; 646 Violin plot.; 647 ; (...); 745 pl.stacked_violin; 746 """"""; 747 import seaborn as sns # Slow import, only import if called; --> 749 sanitize_anndata(adata); 750 use_raw = _check_use_raw(adata, use_raw); 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata); 404 def sanitize_anndata(adata):; 405 """"""Transform string annotations to categoricals.""""""; --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2925,Availability,error,error,2925,"e error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 645 """"""\; 646 Violin plot.; 647 ; (...); 745 pl.stacked_violin; 746 """"""; 747 import seaborn as sns # Slow import, only import if called; --> 749 sanitize_anndata(adata); 750 use_raw = _check_use_raw(adata, use_raw); 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata); 404 def sanitize_anndata(adata):; 405 """"""Transform string annotations to categoricals.""""""; --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df); 1226 if len(c.categories) >= len(c):; 1227 continue; ...; 1232 ""AnnData, not on this view. You might encounter this""; 1233 ""error message while copying or writing to disk.""; 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'; ```. ### Versions. <details>. ```; anndata 0.7.8; scanpy 1.9.3; -----; PIL 10.0.0; asttokens NA; backcall 0.2.0; clustergrammer2 0.18.0; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7.post1; decorator 5.1.1; executing 1.2.0; google NA; h5py 3.9.0; igraph 0.10.6; importlib_resources NA; ipykernel 6.25.1; ipywidgets 8.1.0; jedi 0.19.0; joblib 1.3.2; kiwisolver 1.4.4; leidenalg 0.9.0; ...; Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]; Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1074,Integrability,message,message,1074,"onfirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2931,Integrability,message,message,2931,"e error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 645 """"""\; 646 Violin plot.; 647 ; (...); 745 pl.stacked_violin; 746 """"""; 747 import seaborn as sns # Slow import, only import if called; --> 749 sanitize_anndata(adata); 750 use_raw = _check_use_raw(adata, use_raw); 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata); 404 def sanitize_anndata(adata):; 405 """"""Transform string annotations to categoricals.""""""; --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df); 1226 if len(c.categories) >= len(c):; 1227 continue; ...; 1232 ""AnnData, not on this view. You might encounter this""; 1233 ""error message while copying or writing to disk.""; 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'; ```. ### Versions. <details>. ```; anndata 0.7.8; scanpy 1.9.3; -----; PIL 10.0.0; asttokens NA; backcall 0.2.0; clustergrammer2 0.18.0; comm 0.1.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7.post1; decorator 5.1.1; executing 1.2.0; google NA; h5py 3.9.0; igraph 0.10.6; importlib_resources NA; ipykernel 6.25.1; ipywidgets 8.1.0; jedi 0.19.0; joblib 1.3.2; kiwisolver 1.4.4; leidenalg 0.9.0; ...; Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]; Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:599,Security,sanitiz,sanitize,599,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2058,Testability,log,log,2058,"ate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python; samples= [ <list of 4 hdf5 files>]; all_adata = []; i = 0; for s in samples:; curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""); curr_adata.var_names_make_unique(); all_adata.append(curr_adata); adata= ad.concat(all_adata); #I get the same type error when I try to do; adata.write('trial.hdf5') ; #or; sc.pl.violin(adata, 'volume'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Cell In[8], line 1; ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 645 """"""\; 646 Violin plot.; 647 ; (...); 745 pl.stacked_violin; 746 """"""; 747 import seaborn as sns # Slow import, only import if called; --> 749 sanitize_anndata(adata); 750 use_raw = _check_use_raw(adata, use_raw); 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata); 404 def sanitize_anndata(adata):; 405 """"""Transform string annotations to categoricals.""""""; --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df); 1226 if len(c.categories) >= len(c):; 1227 continue; ...; 1232 ""AnnData, not on this view. You might encounter this""; 1233 ""error message while copying or writing to disk.""; 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'; ```. ### Versions. <details>. ```; anndata 0.7.8; sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/pull/2646:129,Usability,guid,guidelines,129,added some quotes to make the code copy-able in the docs. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2646
https://github.com/scverse/scanpy/pull/2646:160,Usability,guid,guide,160,added some quotes to make the code copy-able in the docs. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2646
https://github.com/scverse/scanpy/pull/2647:114,Deployability,integrat,integrate,114,"I just found a small mistake in the documentation of `scanorama_integrate`:; **kwargs are passed to assemble, not integrate. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647
https://github.com/scverse/scanpy/pull/2647:114,Integrability,integrat,integrate,114,"I just found a small mistake in the documentation of `scanorama_integrate`:; **kwargs are passed to assemble, not integrate. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647
https://github.com/scverse/scanpy/pull/2647:196,Usability,guid,guidelines,196,"I just found a small mistake in the documentation of `scanorama_integrate`:; **kwargs are passed to assemble, not integrate. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647
https://github.com/scverse/scanpy/pull/2647:227,Usability,guid,guide,227,"I just found a small mistake in the documentation of `scanorama_integrate`:; **kwargs are passed to assemble, not integrate. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647
https://github.com/scverse/scanpy/pull/2648:0,Deployability,Hotfix,Hotfix,0,"Hotfix for rapids nn:. * fixes bug with `random_state` for `RapidsKNNTransformer.__init__`; * now return distance matrix with `self.nn.kneighbors_graph(X_contiguous, mode=""distance"")`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2648
https://github.com/scverse/scanpy/issues/2649:275,Testability,test,test,275,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api; - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png; - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py; # per module setup; ROOT = HERE / '_images'. # individual test; def test_some_plot(image_comparer):; save_and_compare_images = partial(image_comparer, ROOT, tol=15); ...; save_and_compare_images('some_plot'); ... # and maybe; save_and_compare_images('some_plot_x_context'); ```. I propose we arrive here (with `--strict-markers` on):. ```py; # per module setup; @pytest.fixture(scope='module'); def compare_images_root():; """"""Set image root for save_and_compare_images.""""""; return HERE / '_images'. # individual test; @pytest.mark.compare_images_tol(15); def test_some_plot(save_and_compare_images):; ...; save_and_compare_images(); ... # and maybe; save_and_compare_images('x_context'); ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name; 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:354,Testability,test,test,354,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api; - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png; - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py; # per module setup; ROOT = HERE / '_images'. # individual test; def test_some_plot(image_comparer):; save_and_compare_images = partial(image_comparer, ROOT, tol=15); ...; save_and_compare_images('some_plot'); ... # and maybe; save_and_compare_images('some_plot_x_context'); ```. I propose we arrive here (with `--strict-markers` on):. ```py; # per module setup; @pytest.fixture(scope='module'); def compare_images_root():; """"""Set image root for save_and_compare_images.""""""; return HERE / '_images'. # individual test; @pytest.mark.compare_images_tol(15); def test_some_plot(save_and_compare_images):; ...; save_and_compare_images(); ... # and maybe; save_and_compare_images('x_context'); ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name; 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:583,Testability,test,test,583,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api; - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png; - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py; # per module setup; ROOT = HERE / '_images'. # individual test; def test_some_plot(image_comparer):; save_and_compare_images = partial(image_comparer, ROOT, tol=15); ...; save_and_compare_images('some_plot'); ... # and maybe; save_and_compare_images('some_plot_x_context'); ```. I propose we arrive here (with `--strict-markers` on):. ```py; # per module setup; @pytest.fixture(scope='module'); def compare_images_root():; """"""Set image root for save_and_compare_images.""""""; return HERE / '_images'. # individual test; @pytest.mark.compare_images_tol(15); def test_some_plot(save_and_compare_images):; ...; save_and_compare_images(); ... # and maybe; save_and_compare_images('x_context'); ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name; 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:1037,Testability,test,test,1037,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api; - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png; - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py; # per module setup; ROOT = HERE / '_images'. # individual test; def test_some_plot(image_comparer):; save_and_compare_images = partial(image_comparer, ROOT, tol=15); ...; save_and_compare_images('some_plot'); ... # and maybe; save_and_compare_images('some_plot_x_context'); ```. I propose we arrive here (with `--strict-markers` on):. ```py; # per module setup; @pytest.fixture(scope='module'); def compare_images_root():; """"""Set image root for save_and_compare_images.""""""; return HERE / '_images'. # individual test; @pytest.mark.compare_images_tol(15); def test_some_plot(save_and_compare_images):; ...; save_and_compare_images(); ... # and maybe; save_and_compare_images('x_context'); ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name; 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:1384,Testability,test,test,1384,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api; - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png; - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py; # per module setup; ROOT = HERE / '_images'. # individual test; def test_some_plot(image_comparer):; save_and_compare_images = partial(image_comparer, ROOT, tol=15); ...; save_and_compare_images('some_plot'); ... # and maybe; save_and_compare_images('some_plot_x_context'); ```. I propose we arrive here (with `--strict-markers` on):. ```py; # per module setup; @pytest.fixture(scope='module'); def compare_images_root():; """"""Set image root for save_and_compare_images.""""""; return HERE / '_images'. # individual test; @pytest.mark.compare_images_tol(15); def test_some_plot(save_and_compare_images):; ...; save_and_compare_images(); ... # and maybe; save_and_compare_images('x_context'); ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name; 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:1406,Testability,test,test,1406,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api; - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png; - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py; # per module setup; ROOT = HERE / '_images'. # individual test; def test_some_plot(image_comparer):; save_and_compare_images = partial(image_comparer, ROOT, tol=15); ...; save_and_compare_images('some_plot'); ... # and maybe; save_and_compare_images('some_plot_x_context'); ```. I propose we arrive here (with `--strict-markers` on):. ```py; # per module setup; @pytest.fixture(scope='module'); def compare_images_root():; """"""Set image root for save_and_compare_images.""""""; return HERE / '_images'. # individual test; @pytest.mark.compare_images_tol(15); def test_some_plot(save_and_compare_images):; ...; save_and_compare_images(); ... # and maybe; save_and_compare_images('x_context'); ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name; 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:132,Usability,simpl,simplify,132,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api; - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png; - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py; # per module setup; ROOT = HERE / '_images'. # individual test; def test_some_plot(image_comparer):; save_and_compare_images = partial(image_comparer, ROOT, tol=15); ...; save_and_compare_images('some_plot'); ... # and maybe; save_and_compare_images('some_plot_x_context'); ```. I propose we arrive here (with `--strict-markers` on):. ```py; # per module setup; @pytest.fixture(scope='module'); def compare_images_root():; """"""Set image root for save_and_compare_images.""""""; return HERE / '_images'. # individual test; @pytest.mark.compare_images_tol(15); def test_some_plot(save_and_compare_images):; ...; save_and_compare_images(); ... # and maybe; save_and_compare_images('x_context'); ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name; 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/pull/2650:20,Testability,test,tests,20,This should fix the tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2650
https://github.com/scverse/scanpy/pull/2651:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.0.286  v0.0.287](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.286...v0.0.287); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2651
https://github.com/scverse/scanpy/issues/2653:874,Availability,Error,Error,874,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization ; After 1 runs, maximum modularity is Q = 0.794615; After 16 runs, maximum modularity is Q = 0.796318; Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python; from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)); phenograph = external.tl.phenograph ; cluster_ph = phenograph(df.values, k=60, method='leiden')[0]; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.4; -----; PIL 9.5.0; asttokens NA; backcall 0.2.0; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 1.0.0; functions NA; google NA; h5py 3.9.0; igraph 0.10.4; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 8.0.2; jedi 0.18.1; jinja2 3.1.2; joblib 1.3.2; jupyter_server 1.18.1; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.1rc1; markupsafe 2.1.1; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 21.3; pandas 1.4.4; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; plotly 5.14.1; prompt_toolkit 3.0.31; psutil 5.9.2; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 9.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pyparsing 3.0.9; pytz 2022.2.1; scipy 1.11.2; seaborn 0.12.2; session_info 1.0.0; six 1.16.0; sklearn 1.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:2472,Deployability,update,updated,2472,"dularity is Q = 0.796318; Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python; from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)); phenograph = external.tl.phenograph ; cluster_ph = phenograph(df.values, k=60, method='leiden')[0]; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.4; -----; PIL 9.5.0; asttokens NA; backcall 0.2.0; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 1.0.0; functions NA; google NA; h5py 3.9.0; igraph 0.10.4; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 8.0.2; jedi 0.18.1; jinja2 3.1.2; joblib 1.3.2; jupyter_server 1.18.1; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.1rc1; markupsafe 2.1.1; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 21.3; pandas 1.4.4; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; plotly 5.14.1; prompt_toolkit 3.0.31; psutil 5.9.2; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 9.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pyparsing 3.0.9; pytz 2022.2.1; scipy 1.11.2; seaborn 0.12.2; session_info 1.0.0; six 1.16.0; sklearn 1.3.0; stack_data 0.5.0; statsmodels 0.14.0; tblib 1.7.0; texttable 1.6.7; threadpoolctl 3.1.0; tlz 0.12.0; toolz 0.12.0; tornado 6.2; traitlets 5.3.0; typing_extensions NA; wcwidth 0.2.5; xxhash NA; yaml 6.0; zipp NA; zmq 23.2.1; zope NA; -----; IPython 8.4.0; jupyter_client 7.3.5; jupyter_core 4.11.1; jupyterlab 3.4.6; notebook 6.4.12; -----; Python 3.10.6 (main, Aug 9 2022, 08:40:02) [GCC 11.2.0]; Linux-6.2.0-1010-aws-x86_64-with-glibc2.35; -----; Session information updated at 2023-09-05 09:34. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:426,Performance,optimiz,optimization,426,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization ; After 1 runs, maximum modularity is Q = 0.794615; After 16 runs, maximum modularity is Q = 0.796318; Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python; from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)); phenograph = external.tl.phenograph ; cluster_ph = phenograph(df.values, k=60, method='leiden')[0]; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.4; -----; PIL 9.5.0; asttokens NA; backcall 0.2.0; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.3; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 1.0.0; functions NA; google NA; h5py 3.9.0; igraph 0.10.4; ipykernel 6.15.2; ipython_genutils 0.2.0; ipywidgets 8.0.2; jedi 0.18.1; jinja2 3.1.2; joblib 1.3.2; jupyter_server 1.18.1; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.1rc1; markupsafe 2.1.1; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.4.0; numba 0.57.1; numpy 1.24.4; packaging 21.3; pandas 1.4.4; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; plotly 5.14.1; prompt_toolkit 3.0.31; psutil 5.9.2; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 9.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.8.0; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.13.0; pyparsing 3.0.9; pytz 2022.2.1; scipy 1.11.2; seaborn 0.12.2; session_info 1.0.0; six 1.16.0; sklearn 1.3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/pull/2655:115,Availability,down,downstream,115,This PR makes `harmony_integrate` run with 64 bit floats. This makes it reproducible for `neighbors` and therefore downstream clustering,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655
https://github.com/scverse/scanpy/pull/2657:385,Testability,test,tested,385,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; It was unclear if the `groups` argument in `rank_genes_groups()` is equivalent to subsetting when `reference='rest'`(i.e. only the selected groups are tested against each other) or if only those groups are tested but all groups are still used as the reference. This PR adds a note explaining the current behaviour (option 2).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657
https://github.com/scverse/scanpy/pull/2657:440,Testability,test,tested,440,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; It was unclear if the `groups` argument in `rank_genes_groups()` is equivalent to subsetting when `reference='rest'`(i.e. only the selected groups are tested against each other) or if only those groups are tested but all groups are still used as the reference. This PR adds a note explaining the current behaviour (option 2).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657
https://github.com/scverse/scanpy/pull/2657:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; It was unclear if the `groups` argument in `rank_genes_groups()` is equivalent to subsetting when `reference='rest'`(i.e. only the selected groups are tested against each other) or if only those groups are tested but all groups are still used as the reference. This PR adds a note explaining the current behaviour (option 2).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657
https://github.com/scverse/scanpy/pull/2657:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; It was unclear if the `groups` argument in `rank_genes_groups()` is equivalent to subsetting when `reference='rest'`(i.e. only the selected groups are tested against each other) or if only those groups are tested but all groups are still used as the reference. This PR adds a note explaining the current behaviour (option 2).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657
https://github.com/scverse/scanpy/pull/2658:85,Deployability,release,release,85,As it's scheduled to be removed in anndata 0.10.0. This will require a quick bug fix release. It may also require bumping the anndata dependency to >0.8.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2658
https://github.com/scverse/scanpy/pull/2658:8,Energy Efficiency,schedul,scheduled,8,As it's scheduled to be removed in anndata 0.10.0. This will require a quick bug fix release. It may also require bumping the anndata dependency to >0.8.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2658
https://github.com/scverse/scanpy/pull/2658:134,Integrability,depend,dependency,134,As it's scheduled to be removed in anndata 0.10.0. This will require a quick bug fix release. It may also require bumping the anndata dependency to >0.8.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2658
https://github.com/scverse/scanpy/pull/2659:51,Deployability,release,release,51,* Remove use of AnnData constructor dtype kwarg. * release note. * Fix release note. (cherry picked from commit 0b49eebbcf6007e2fa742763e382d99e6a151a78). <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2659
https://github.com/scverse/scanpy/pull/2659:71,Deployability,release,release,71,* Remove use of AnnData constructor dtype kwarg. * release note. * Fix release note. (cherry picked from commit 0b49eebbcf6007e2fa742763e382d99e6a151a78). <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2659
https://github.com/scverse/scanpy/pull/2659:226,Usability,guid,guidelines,226,* Remove use of AnnData constructor dtype kwarg. * release note. * Fix release note. (cherry picked from commit 0b49eebbcf6007e2fa742763e382d99e6a151a78). <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2659
https://github.com/scverse/scanpy/pull/2659:257,Usability,guid,guide,257,* Remove use of AnnData constructor dtype kwarg. * release note. * Fix release note. (cherry picked from commit 0b49eebbcf6007e2fa742763e382d99e6a151a78). <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2659
https://github.com/scverse/scanpy/pull/2660:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2660
https://github.com/scverse/scanpy/pull/2660:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2660
https://github.com/scverse/scanpy/pull/2661:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/psf/black: 23.7.0  23.9.1](https://github.com/psf/black/compare/23.7.0...23.9.1); - [github.com/astral-sh/ruff-pre-commit: v0.0.287  v0.0.292](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.287...v0.0.292); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2661
https://github.com/scverse/scanpy/issues/2662:185,Deployability,integrat,integrate,185,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis?. Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:381,Deployability,integrat,integrate,381,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis?. Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:185,Integrability,integrat,integrate,185,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis?. Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:381,Integrability,integrat,integrate,381,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis?. Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/pull/2664:0,Deployability,update,updates,0,updates the function link to `pp.neighbors` for rapids-singlecell,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2664
https://github.com/scverse/scanpy/issues/2665:804,Availability,Error,Error,804,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes?. Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python; adata2 = sc.datasets.pbmc3k_processed(); sc.tl.paga(adata2, groups='louvain'); sc.pl.paga(adata2); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.5; -----; PIL 8.0.1; backcall 0.2.0; bottleneck 1.3.7; cellrank 1.5.1; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.1; dask 2023.5.0; dateutil 2.8.2; decorator 5.1.1; docrep 0.3.2; google NA; h5py 3.8.0; igraph 0.10.4; importlib_resources NA; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 3.0.3; joblib 1.2.0; kiwisolver 1.3.0; leidenalg 0.9.1; llvmlite 0.34.0; lz4 3.1.10; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.3.1; numba 0.51.2; numexpr 2.8.5; numpy 1.23.5; packaging 23.1; pandas 1.5.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; progressbar 4.2.0; prompt_toolkit 3.0.8; psutil 5.7.2; ptyprocess 0.6.0; pygam 0.8.0; pygments 2.7.2; pygpcca 1.0.4; pyparsing 2.4.7; python_utils NA; pytz 2020.1; ruamel NA; scipy 1.10.1; scvelo 0.2.5; seaborn 0.11.0; session_info 1.0.0; six 1.15.0; sklearn 1.2.2; sphinxcontrib NA; statsmodels 0.12.0; storemagic NA; tblib 1.7.0; texttable 1.6.7; threadpoolctl 2.1.0; tlz 0.12.1; toolz 0.11.1; tornado 6.1; tqdm 4.50.2; traitlets 5.0.5; typ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:2312,Deployability,update,updated,2312,"e output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes?. Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python; adata2 = sc.datasets.pbmc3k_processed(); sc.tl.paga(adata2, groups='louvain'); sc.pl.paga(adata2); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.5; -----; PIL 8.0.1; backcall 0.2.0; bottleneck 1.3.7; cellrank 1.5.1; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.1; dask 2023.5.0; dateutil 2.8.2; decorator 5.1.1; docrep 0.3.2; google NA; h5py 3.8.0; igraph 0.10.4; importlib_resources NA; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 3.0.3; joblib 1.2.0; kiwisolver 1.3.0; leidenalg 0.9.1; llvmlite 0.34.0; lz4 3.1.10; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.3.1; numba 0.51.2; numexpr 2.8.5; numpy 1.23.5; packaging 23.1; pandas 1.5.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; progressbar 4.2.0; prompt_toolkit 3.0.8; psutil 5.7.2; ptyprocess 0.6.0; pygam 0.8.0; pygments 2.7.2; pygpcca 1.0.4; pyparsing 2.4.7; python_utils NA; pytz 2020.1; ruamel NA; scipy 1.10.1; scvelo 0.2.5; seaborn 0.11.0; session_info 1.0.0; six 1.15.0; sklearn 1.2.2; sphinxcontrib NA; statsmodels 0.12.0; storemagic NA; tblib 1.7.0; texttable 1.6.7; threadpoolctl 2.1.0; tlz 0.12.1; toolz 0.11.1; tornado 6.1; tqdm 4.50.2; traitlets 5.0.5; typing_extensions NA; wcwidth 0.2.5; wrapt 1.15.0; yaml 5.3.1; zipp NA; zmq 19.0.2; zope NA; -----; IPython 7.25.0; jupyter_client 6.1.12; jupyter_core 4.7.1; notebook 6.4.0; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-5.4.0-137-generic-x86_64-with-glibc2.10; -----; Session information updated at 2023-09-15 09:42; Running scvelo 0.2.5 (python 3.8.5) on 2023-09-15 09:42. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:2035,Integrability,wrap,wrapt,2035,"e output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes?. Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python; adata2 = sc.datasets.pbmc3k_processed(); sc.tl.paga(adata2, groups='louvain'); sc.pl.paga(adata2); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.5; -----; PIL 8.0.1; backcall 0.2.0; bottleneck 1.3.7; cellrank 1.5.1; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.1; dask 2023.5.0; dateutil 2.8.2; decorator 5.1.1; docrep 0.3.2; google NA; h5py 3.8.0; igraph 0.10.4; importlib_resources NA; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 3.0.3; joblib 1.2.0; kiwisolver 1.3.0; leidenalg 0.9.1; llvmlite 0.34.0; lz4 3.1.10; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.3.1; numba 0.51.2; numexpr 2.8.5; numpy 1.23.5; packaging 23.1; pandas 1.5.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; progressbar 4.2.0; prompt_toolkit 3.0.8; psutil 5.7.2; ptyprocess 0.6.0; pygam 0.8.0; pygments 2.7.2; pygpcca 1.0.4; pyparsing 2.4.7; python_utils NA; pytz 2020.1; ruamel NA; scipy 1.10.1; scvelo 0.2.5; seaborn 0.11.0; session_info 1.0.0; six 1.15.0; sklearn 1.2.2; sphinxcontrib NA; statsmodels 0.12.0; storemagic NA; tblib 1.7.0; texttable 1.6.7; threadpoolctl 2.1.0; tlz 0.12.1; toolz 0.11.1; tornado 6.1; tqdm 4.50.2; traitlets 5.0.5; typing_extensions NA; wcwidth 0.2.5; wrapt 1.15.0; yaml 5.3.1; zipp NA; zmq 19.0.2; zope NA; -----; IPython 7.25.0; jupyter_client 6.1.12; jupyter_core 4.7.1; notebook 6.4.0; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-5.4.0-137-generic-x86_64-with-glibc2.10; -----; Session information updated at 2023-09-15 09:42; Running scvelo 0.2.5 (python 3.8.5) on 2023-09-15 09:42. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:933,Performance,bottleneck,bottleneck,933,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes?. Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python; adata2 = sc.datasets.pbmc3k_processed(); sc.tl.paga(adata2, groups='louvain'); sc.pl.paga(adata2); ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.5; -----; PIL 8.0.1; backcall 0.2.0; bottleneck 1.3.7; cellrank 1.5.1; cffi 1.15.1; cloudpickle 2.2.1; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.1; dask 2023.5.0; dateutil 2.8.2; decorator 5.1.1; docrep 0.3.2; google NA; h5py 3.8.0; igraph 0.10.4; importlib_resources NA; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 3.0.3; joblib 1.2.0; kiwisolver 1.3.0; leidenalg 0.9.1; llvmlite 0.34.0; lz4 3.1.10; markupsafe 2.1.3; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.3.1; numba 0.51.2; numexpr 2.8.5; numpy 1.23.5; packaging 23.1; pandas 1.5.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; progressbar 4.2.0; prompt_toolkit 3.0.8; psutil 5.7.2; ptyprocess 0.6.0; pygam 0.8.0; pygments 2.7.2; pygpcca 1.0.4; pyparsing 2.4.7; python_utils NA; pytz 2020.1; ruamel NA; scipy 1.10.1; scvelo 0.2.5; seaborn 0.11.0; session_info 1.0.0; six 1.15.0; sklearn 1.2.2; sphinxcontrib NA; statsmodels 0.12.0; storemagic NA; tblib 1.7.0; texttable 1.6.7; threadpoolctl 2.1.0; tlz 0.12.1; toolz 0.11.1; tornado 6.1; tqdm 4.50.2; traitlets 5.0.5; typ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2666:653,Availability,Error,Error,653,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python; sc.tl.filter_rank_genes_groups; sc.tl.filter_rank_genes_groups; Both default use; ```. ### Error output. ```pytb; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /; ```. ### Versions. anndata: 0.9.2; scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:749,Availability,error,error,749,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python; sc.tl.filter_rank_genes_groups; sc.tl.filter_rank_genes_groups; Both default use; ```. ### Error output. ```pytb; TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /; ```. ### Versions. anndata: 0.9.2; scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2667:444,Availability,error,error,444,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:781,Deployability,install,install,781,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:485,Integrability,depend,dependency,485,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:656,Integrability,depend,dependency,656,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:450,Testability,log,log,450,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2668:1814,Availability,Error,Error,1814, print(prot.X); ```; Output; ```; before; [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165; -0.05565361]; [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884; 0.03547253]; [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176; -0.05032819]; ...; [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771; -0.01558504]; [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814; 0.0116325 ]; [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189; 0.02879048]]; after; [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232; -0.03857614]; [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566; 0.02458768]; [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355; -0.03488484]; ...; [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253; -0.01080273]; [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221; 0.00806304]; [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191; 0.01995604]]; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.4.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.2; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.6; decorator 5.1.1; entrypoints 0.4; executing 1.2.0; google NA; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.20.2; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.39.1; matplotlib 3.6.3; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; packaging 23.0; pandas 1.5.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.6.2; prompt_toolkit 3.0.36; psutil 5.9.4; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.14.0; pyparsing 3.0.9; pytz 2022.7.1; scipy 1.10.0; s,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:3308,Deployability,update,updated,3308,"03571618 -0.20246665 ... -0.20828792 -0.03336232; -0.03857614]; [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566; 0.02458768]; [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355; -0.03488484]; ...; [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253; -0.01080273]; [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221; 0.00806304]; [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191; 0.01995604]]; ```. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.9.1; -----; PIL 9.4.0; asttokens NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; colorama 0.4.6; comm 0.1.2; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.6; decorator 5.1.1; entrypoints 0.4; executing 1.2.0; google NA; h5py 3.8.0; hypergeom_ufunc NA; igraph 0.10.3; invgauss_ufunc NA; ipykernel 6.20.2; jedi 0.18.2; joblib 1.2.0; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.39.1; matplotlib 3.6.3; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.56.4; numpy 1.23.5; packaging 23.0; pandas 1.5.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.6.2; prompt_toolkit 3.0.36; psutil 5.9.4; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.14.0; pyparsing 3.0.9; pytz 2022.7.1; scipy 1.10.0; session_info 1.0.0; setuptools 66.1.1; six 1.16.0; skewnorm_ufunc NA; sklearn 1.2.1; stack_data 0.6.2; texttable 1.6.7; threadpoolctl 3.1.0; tornado 6.2; traitlets 5.8.1; typing_extensions NA; wcwidth 0.2.6; yaml 6.0; zipp NA; zmq 25.0.0; zoneinfo NA; -----; IPython 8.8.0; jupyter_client 7.4.9; jupyter_core 5.1.5; -----; Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 15:55:03) [GCC 10.4.0]; Linux-4.18.0-425.3.1.el8.x86_64-x86_64-with-glibc2.28; -----; Session information updated at 2023-09-18 17:04; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2669:422,Availability,error,error-in-highly-variable-gene-selection,422,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python; sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""); ```. ### Error output. ```pytb; ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 422 raise ValueError(; 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '; 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'; 425 ); 427 if flavor == 'seurat_v3':; --> 428 return _highly_variable_genes_seurat_v3(; 429 adata,; 430 layer=layer,; 431 n_top_genes=n_top_genes,; 432 batch_key=batch_key,; 433 check_values=check_values,; 434 span=span,; 435 subset=subset,; 436 inplace=inplace,; 437 ); 439 if batch_key is None:; 440 df = _highly_variable_genes_single_batch(; 441 adata,; 442 layer=layer,; (...); 449 flavor=flavor,; 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:729,Availability,error,error,729,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python; sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""); ```. ### Error output. ```pytb; ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 422 raise ValueError(; 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '; 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'; 425 ); 427 if flavor == 'seurat_v3':; --> 428 return _highly_variable_genes_seurat_v3(; 429 adata,; 430 layer=layer,; 431 n_top_genes=n_top_genes,; 432 batch_key=batch_key,; 433 check_values=check_values,; 434 span=span,; 435 subset=subset,; 436 inplace=inplace,; 437 ); 439 if batch_key is None:; 440 df = _highly_variable_genes_single_batch(; 441 adata,; 442 layer=layer,; (...); 449 flavor=flavor,; 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:878,Availability,Error,Error,878,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python; sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""); ```. ### Error output. ```pytb; ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 422 raise ValueError(; 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '; 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'; 425 ); 427 if flavor == 'seurat_v3':; --> 428 return _highly_variable_genes_seurat_v3(; 429 adata,; 430 layer=layer,; 431 n_top_genes=n_top_genes,; 432 batch_key=batch_key,; 433 check_values=check_values,; 434 span=span,; 435 subset=subset,; 436 inplace=inplace,; 437 ); 439 if batch_key is None:; 440 df = _highly_variable_genes_single_batch(; 441 adata,; 442 layer=layer,; (...); 449 flavor=flavor,; 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:3749,Deployability,update,updated,3749,"2 layer=layer,; (...); 449 flavor=flavor,; 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 83 x = np.log10(mean[not_const]); 84 model = loess(x, y, span=span, degree=2); ---> 85 model.fit(); 86 estimat_var[not_const] = model.outputs.fitted_values; 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'; ```. ### Versions. <details>. ```; -----; anndata 0.9.1; scanpy 1.9.3; -----; PIL 9.5.0; asttokens NA; backcall 0.2.0; cffi 1.15.1; comm 0.1.2; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; executing 0.8.3; h5py 3.8.0; igraph 0.10.4; importlib_resources NA; ipykernel 6.19.2; ipython_genutils 0.2.0; jedi 0.18.1; joblib 1.2.0; jupyter_server 1.23.4; kiwisolver 1.4.4; leidenalg 0.9.1; llvmlite 0.40.0; matplotlib 3.7.1; mpl_toolkits NA; natsort 8.3.1; numba 0.57.0; numpy 1.24.3; packaging 23.0; pandas 2.0.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 2.5.2; prompt_toolkit 3.0.36; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.0.9; pytz 2022.7; scipy 1.10.1; session_info 1.0.0; setuptools 66.0.0; six 1.16.0; sklearn 1.2.2; stack_data 0.2.0; texttable 1.6.7; threadpoolctl 3.1.0; tornado 6.2; traitlets 5.7.1; typing_extensions NA; wcwidth 0.2.5; yaml 6.0.1; zipp NA; zmq 25.0.2; -----; IPython 8.12.0; jupyter_client 8.1.0; jupyter_core 5.3.0; jupyterlab 3.5.3; notebook 6.5.4; -----; Python 3.8.16 (default, Mar 2 2023, 03:21:46) [GCC 11.2.0]; Linux-4.15.0-212-generic-x86_64-with-glibc2.17; -----; Session information updated at 2023-09-19 02:18; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:438,Modifiability,variab,variable-gene-selection,438,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python; sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""); ```. ### Error output. ```pytb; ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 422 raise ValueError(; 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '; 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'; 425 ); 427 if flavor == 'seurat_v3':; --> 428 return _highly_variable_genes_seurat_v3(; 429 adata,; 430 layer=layer,; 431 n_top_genes=n_top_genes,; 432 batch_key=batch_key,; 433 check_values=check_values,; 434 span=span,; 435 subset=subset,; 436 inplace=inplace,; 437 ); 439 if batch_key is None:; 440 df = _highly_variable_genes_single_batch(; 441 adata,; 442 layer=layer,; (...); 449 flavor=flavor,; 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:492,Security,access,access,492,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python; sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""); ```. ### Error output. ```pytb; ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 422 raise ValueError(; 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '; 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'; 425 ); 427 if flavor == 'seurat_v3':; --> 428 return _highly_variable_genes_seurat_v3(; 429 adata,; 430 layer=layer,; 431 n_top_genes=n_top_genes,; 432 batch_key=batch_key,; 433 check_values=check_values,; 434 span=span,; 435 subset=subset,; 436 inplace=inplace,; 437 ); 439 if batch_key is None:; 440 df = _highly_variable_genes_single_batch(; 441 adata,; 442 layer=layer,; (...); 449 flavor=flavor,; 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2670:712,Availability,Error,Error,712,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. When I use `sc.pl.scatter` it returns a blank plot. The axis values are alright but the plot itself is empty. There are about 23M cells. Please advise. ![image](https://github.com/scverse/scanpy/assets/32474661/2d858133-6e60-478a-a98c-b0acd8c64700). Thanks and good day. ### Minimal code sample. ```python; sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"", save='_test.png'); ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2670
https://github.com/scverse/scanpy/pull/2671:495,Deployability,update,updated,495,"Dear scanpy-team,. thank you very much for this great package!. Similar to issues [https://github.com/scverse/scanpy/issues/1435](url) and [https://github.com/scverse/scanpy/issues/460](url) I am interested in having an n_components parameter in the sc.tl.tsne function. . Apparently, the commit was made but no pull request was opened back in 2019. I added the necessary parameter to the arguments and passed them via the params_sklearn dict to the respective function. . Documentation is also updated. If you feel there is a need for a separate test, let me know, happy to include one. Best,; Tarik",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2671
https://github.com/scverse/scanpy/pull/2671:547,Testability,test,test,547,"Dear scanpy-team,. thank you very much for this great package!. Similar to issues [https://github.com/scverse/scanpy/issues/1435](url) and [https://github.com/scverse/scanpy/issues/460](url) I am interested in having an n_components parameter in the sc.tl.tsne function. . Apparently, the commit was made but no pull request was opened back in 2019. I added the necessary parameter to the arguments and passed them via the params_sklearn dict to the respective function. . Documentation is also updated. If you feel there is a need for a separate test, let me know, happy to include one. Best,; Tarik",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2671
https://github.com/scverse/scanpy/pull/2672:179,Deployability,release,releases,179,"This PR resolves [Issue #2608](https://github.com/scverse/scanpy/issues/2608) in Scanpy by ensuring compatibility with both [Palantir v1.3.0](https://github.com/dpeerlab/Palantir/releases/tag/v1.3.0) ([function signature](https://github.com/dpeerlab/Palantir/blob/870a9ba88b978a070fd0c29df4d1a3b94b0c9ad9/src/palantir/core.py#L34-L51)) and its [earlier versions](https://github.com/dpeerlab/Palantir/blob/4d4f9fcdbfebcf47b4ca1b7ac8a0fb1b8e5fc089/src/palantir/core.py#L31-L41). This is achieved by substituting the initial keyword argument (`data_df`) with a positional argument. The change aligns with Palantir v1.3.0's new optionality to accept AnnData objects as the first argument, making the keyword `data_df` potentially misleading. Adopting a positional argument ensures compatibility with both new and prior versions of Palantir.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2672
https://github.com/scverse/scanpy/issues/2673:720,Availability,error,error,720,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value.; I don't know why the error occurs, perhaps due to the version of some packages?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""); subadata = adata[: , genelist]; sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[100], line 1; ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds); 931 if issparse(X):; 932 X = X.toarray(); --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names); 934 if obs_keys is not None:; 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy); 712 mgr = dict_to_mgr(; 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no; 714 # attribute ""name""; (...); 719 typ=manager,; 720 ); 721 else:; --> 722 mgr = ndarray_to_mgr(; 723 data,; 724 index,; 725 columns,; 726 dtype=dtype,; 727 copy=copy,; 728 typ=manager,; 729 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1004,Availability,Error,Error,1004,"se make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value.; I don't know why the error occurs, perhaps due to the version of some packages?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""); subadata = adata[: , genelist]; sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[100], line 1; ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds); 931 if issparse(X):; 932 X = X.toarray(); --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names); 934 if obs_keys is not None:; 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy); 712 mgr = dict_to_mgr(; 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no; 714 # attribute ""name""; (...); 719 typ=manager,; 720 ); 721 else:; --> 722 mgr = ndarray_to_mgr(; 723 data,; 724 index,; 725 columns,; 726 dtype=dtype,; 727 copy=copy,; 728 typ=manager,; 729 ); 731 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1745,Availability,error,error,1745,"he version of some packages?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""); subadata = adata[: , genelist]; sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Cell In[100], line 1; ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds); 931 if issparse(X):; 932 X = X.toarray(); --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names); 934 if obs_keys is not None:; 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy); 712 mgr = dict_to_mgr(; 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no; 714 # attribute ""name""; (...); 719 typ=manager,; 720 ); 721 else:; --> 722 mgr = ndarray_to_mgr(; 723 data,; 724 index,; 725 columns,; 726 dtype=dtype,; 727 copy=copy,; 728 typ=manager,; 729 ); 731 # For data is list-like, or Iterable (will consume into list); 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ); 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point; 345 index, columns = _get_axes(; 346 values.shape[0], values.shape[1], index=index, columns=columns; 347 ); --> 349 _check_values_indices_shape_match(values, index, columns); 351 if typ == ""array"":; 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns); 418 passed = val",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:5232,Deployability,update,updated,5232,"4; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.2; dask 2021.04.0; dateutil 2.8.2; debugpy 1.7.0; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; executing 1.2.0; fastcluster 1.2.6; fastjsonschema NA; fqdn NA; fsspec 2023.9.0; google NA; h5py 3.9.0; idna 3.4; igraph 0.10.8; importlib_resources NA; ipykernel 6.25.2; ipython_genutils 0.2.0; isoduration NA; jedi 0.19.0; jinja2 3.1.2; joblib 1.3.2; json5 NA; jsonpointer 2.0; jsonschema 4.19.0; jsonschema_specifications NA; jupyter_server 1.24.0; jupyterlab_server 2.24.0; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.40.1; louvain 0.8.1; markupsafe 2.1.3; matplotlib 3.7.2; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; nbformat 5.9.2; numba 0.57.1; numexpr 2.8.6; numpy 1.24.4; packaging 23.1; pandas 1.5.3; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.17.0; prometheus_client NA; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pyarrow 10.0.1; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.16.1; pyparsing 2.4.7; pytz 2023.3.post1; referencing NA; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rpds NA; scipy 1.10.1; seaborn 0.12.2; send2trash NA; session_info 1.0.0; setuptools 68.2.2; setuptools_scm NA; six 1.16.0; sklearn 1.3.0; sniffio 1.3.0; socks 1.7.1; stack_data 0.6.2; statsmodels 0.14.0; tblib 1.7.0; terminado 0.17.1; texttable 1.6.7; threadpoolctl 3.2.0; tlz 0.12.2; toolz 0.12.0; tornado 6.1; traitlets 5.9.0; typing_extensions NA; uri_template NA; urllib3 1.26.16; wcwidth 0.2.6; webcolors 1.13; websocket 1.6.3; yaml 6.0.1; zipp NA; zmq 25.1.1; -----; IPython 8.12.0; jupyter_client 7.3.4; jupyter_core 4.12.0; jupyterlab 3.6.5; notebook 6.3.0; -----; Python 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]; Linux-3.10.0-862.el7.x86_64-x86_64-with-glibc2.17; -----; Session information updated at 2023-09-27 17:56; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2675:407,Availability,error,error,407,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python; import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>; ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined; ```. ### Versions. <details>. ```. -----; anndata 0.9.2; scanpy 1.9.4; -----; PIL 9.2.0; PyObjCTools NA; appnope 0.1.2; astunparse 1.6.3; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.7; entrypoints 0.4; fsspec 2022.7.1; gmpy2 2.1.2; google NA; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.1; ipykernel 6.15.2; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.9.1; llvmlite 0.38.0; lz4 3.1.3; markupsafe 2.0.1; matplotlib 3.5.2; mpl_toolkits NA; mpmath 1.2.1; natsort 7.1.1; nbinom_ufunc NA; ncf_ufunc NA; numba 0.55.1; numexpr 2.8.4; numpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:843,Availability,Error,Error,843,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python; import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>; ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined; ```. ### Versions. <details>. ```. -----; anndata 0.9.2; scanpy 1.9.4; -----; PIL 9.2.0; PyObjCTools NA; appnope 0.1.2; astunparse 1.6.3; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.7; entrypoints 0.4; fsspec 2022.7.1; gmpy2 2.1.2; google NA; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.1; ipykernel 6.15.2; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.9.1; llvmlite 0.38.0; lz4 3.1.3; markupsafe 2.0.1; matplotlib 3.5.2; mpl_toolkits NA; mpmath 1.2.1; natsort 7.1.1; nbinom_ufunc NA; ncf_ufunc NA; numba 0.55.1; numexpr 2.8.4; numpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:2997,Deployability,update,updated,2997,"ernel_3816/1026803476.py in <module>; ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined; ```. ### Versions. <details>. ```. -----; anndata 0.9.2; scanpy 1.9.4; -----; PIL 9.2.0; PyObjCTools NA; appnope 0.1.2; astunparse 1.6.3; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.7; entrypoints 0.4; fsspec 2022.7.1; gmpy2 2.1.2; google NA; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.1; ipykernel 6.15.2; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.9.1; llvmlite 0.38.0; lz4 3.1.3; markupsafe 2.0.1; matplotlib 3.5.2; mpl_toolkits NA; mpmath 1.2.1; natsort 7.1.1; nbinom_ufunc NA; ncf_ufunc NA; numba 0.55.1; numexpr 2.8.4; numpy 1.21.6; opt_einsum v3.3.0; packaging 21.3; pandas 1.4.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.9.0; prompt_toolkit 3.0.20; psutil 5.9.0; ptyprocess 0.7.0; pyarrow 13.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.0.9; pytz 2022.1; ruamel NA; scipy 1.9.1; session_info 1.0.0; setuptools 63.4.1; six 1.16.0; sklearn 1.0.2; snappy NA; sphinxcontrib NA; storemagic NA; sympy 1.10.1; tblib 1.7.0; texttable 1.6.4; threadpoolctl 2.2.0; tlz 0.11.0; toolz 0.11.2; torch 2.0.1; tornado 6.1; tqdm 4.64.1; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 23.2.0; zope NA; zstandard 0.19.0; -----; IPython 7.31.1; jupyter_client 7.3.4; jupyter_core 4.11.1; jupyterlab 3.4.4; notebook 6.4.12; -----; Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]; macOS-10.16-x86_64-i386-64bit; -----; Session information updated at 2023-09-30 11:34. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:1367,Performance,bottleneck,bottleneck,1367,"eat tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python; import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>; ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined; ```. ### Versions. <details>. ```. -----; anndata 0.9.2; scanpy 1.9.4; -----; PIL 9.2.0; PyObjCTools NA; appnope 0.1.2; astunparse 1.6.3; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.7; entrypoints 0.4; fsspec 2022.7.1; gmpy2 2.1.2; google NA; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.1; ipykernel 6.15.2; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.9.1; llvmlite 0.38.0; lz4 3.1.3; markupsafe 2.0.1; matplotlib 3.5.2; mpl_toolkits NA; mpmath 1.2.1; natsort 7.1.1; nbinom_ufunc NA; ncf_ufunc NA; numba 0.55.1; numexpr 2.8.4; numpy 1.21.6; opt_einsum v3.3.0; packaging 21.3; pandas 1.4.4; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 5.9.0; prompt_toolkit 3.0.20; psutil 5.9.0; ptyprocess 0.7.0; pyarrow 13.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:752,Testability,log,logging,752,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python; import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>; ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined; ```. ### Versions. <details>. ```. -----; anndata 0.9.2; scanpy 1.9.4; -----; PIL 9.2.0; PyObjCTools NA; appnope 0.1.2; astunparse 1.6.3; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.5; cffi 1.15.1; cloudpickle 2.0.0; colorama 0.4.5; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2022.7.0; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.7; entrypoints 0.4; fsspec 2022.7.1; gmpy2 2.1.2; google NA; h5py 3.7.0; hypergeom_ufunc NA; igraph 0.10.1; ipykernel 6.15.2; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 2.11.3; joblib 1.1.0; jupyter_server 1.18.1; kiwisolver 1.4.2; leidenalg 0.9.1; llvmlite 0.38.0; lz4 3.1.3; markupsafe 2.0.1; matplotlib 3.5.2; mpl_toolkits NA; mpmath 1.2.1; natsort 7.1.1; nbinom_ufunc NA; ncf_ufunc NA; numba 0.55.1; numexpr 2.8.4; numpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/pull/2676:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2676
https://github.com/scverse/scanpy/pull/2676:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2676
https://github.com/scverse/scanpy/pull/2677:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2677
https://github.com/scverse/scanpy/pull/2677:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2677
https://github.com/scverse/scanpy/pull/2679:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/pre-commit/pre-commit-hooks: v4.4.0  v4.5.0](https://github.com/pre-commit/pre-commit-hooks/compare/v4.4.0...v4.5.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2679
https://github.com/scverse/scanpy/issues/2680:331,Availability,error,error,331,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python; sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); Cell In[47], line 1; ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 790 if multi_panel and groupby is None and len(ys) == 1:; 791 # This is a quick and dirty way for adapting scales across several; 792 # keys if groupby is None.; 793 y = ys[0]; --> 795 g = sns.catplot(; 796 y=y,; 797 data=obs_tidy,; 798 kind=""violin"",; 799 scale=scale,; 800 col=x,; 801 col_order=keys,; 802 sharey=False,; 803 order=keys,; 804 cut=0,; 805 inner=None,; 806 **kwds,; 807 ); 809 if stripplot:; 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs); 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""); 2930 linecolor = p._complement_color(linecolor, color, p._hue_map); -> 2932 p.plot_violins(; 2933 width=width,; 2934",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:492,Availability,Error,Error,492,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python; sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); Cell In[47], line 1; ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 790 if multi_panel and groupby is None and len(ys) == 1:; 791 # This is a quick and dirty way for adapting scales across several; 792 # keys if groupby is None.; 793 y = ys[0]; --> 795 g = sns.catplot(; 796 y=y,; 797 data=obs_tidy,; 798 kind=""violin"",; 799 scale=scale,; 800 col=x,; 801 col_order=keys,; 802 sharey=False,; 803 order=keys,; 804 cut=0,; 805 inner=None,; 806 **kwds,; 807 ); 809 if stripplot:; 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs); 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""); 2930 linecolor = p._complement_color(linecolor, color, p._hue_map); -> 2932 p.plot_violins(; 2933 width=width,; 2934",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1589,Availability,error,errorbar,1589,"""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 790 if multi_panel and groupby is None and len(ys) == 1:; 791 # This is a quick and dirty way for adapting scales across several; 792 # keys if groupby is None.; 793 y = ys[0]; --> 795 g = sns.catplot(; 796 y=y,; 797 data=obs_tidy,; 798 kind=""violin"",; 799 scale=scale,; 800 col=x,; 801 col_order=keys,; 802 sharey=False,; 803 order=keys,; 804 cut=0,; 805 inner=None,; 806 **kwds,; 807 ); 809 if stripplot:; 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs); 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""); 2930 linecolor = p._complement_color(linecolor, color, p._hue_map); -> 2932 p.plot_violins(; 2933 width=width,; 2934 dodge=dodge,; 2935 gap=gap,; 2936 split=split,; 2937 color=color,; 2938 fill=fill,; 2939 linecolor=linecolor,; 2940 linewidth=linewidth,; 2941 inner=inner,; 2942 density_norm=density_norm,; 2943 common_norm=common_norm,; 2944 kde_kws=kde_kws,; 2945 inner_kws=inner_kws,; 2946 plot_kws=plot_kws,; 2947 ); 2949 elif kind == ""boxen"":; 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws); 1151 legend_artist = _get_patch_legend_artist(fill); 1152 common_kws = {**plot_kws, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5031,Deployability,patch,patch,5031, 1.0.post1; bcrypt 4.0.1; beautifulsoup4 4.12.2; binaryornot 0.4.4; black 23.9.1; bleach 6.1.0; blinker 1.6.3; bokeh 3.2.2; boltons 23.0.0; botocore 1.31.17; brotlipy 0.7.0; cached-property 1.5.2; celltypist 1.6.1; certifi 2023.7.22; cffi 1.16.0; chardet 5.2.0; charset-normalizer 3.3.0; click 8.1.7; cloudpickle 2.2.1; clyent 1.2.2; colorama 0.4.6; colorcet 3.0.1; comm 0.1.4; conda 23.9.0; conda-build 3.27.0; conda-content-trust 0+unknown; conda_index 0.2.3; conda-libmamba-solver 23.9.1; conda-pack 0.6.0; conda-package-handling 2.2.0; conda_package_streaming 0.9.0; conda-repo-cli 1.0.75; conda-token 0.4.0; conda-verify 3.4.2; ConfigArgParse 1.7; connection-pool 0.0.3; constantly 15.1.0; contourpy 1.1.1; cookiecutter 2.4.0; cryptography 40.0.1; cssselect 1.2.0; cycler 0.12.1; cytoolz 0.12.2; daal4py 2023.2.1; dask 2023.9.3; dataclasses 0.8; datasets 2.14.5; datashader 0.15.2; datashape 0.5.4; datrie 0.8.2; debugpy 1.8.0; decorator 5.1.1; decoupler 1.5.0; defusedxml 0.7.1; diff-match-patch 20230430; dill 0.3.7; distlib 0.3.7; distributed 2023.9.3; docopt 0.6.2; docstring-to-markdown 0.12; docutils 0.20.1; dpath 2.1.6; entrypoints 0.4; et-xmlfile 1.1.0; exceptiongroup 1.1.3; executing 1.2.0; fastjsonschema 2.18.1; filelock 3.12.4; flake8 6.0.0; Flask 3.0.0; fonttools 4.43.1; fqdn 1.5.1; frozenlist 1.4.0; fsspec 2023.6.0; future 0.18.3; gensim 4.3.2; gitdb 4.0.10; GitPython 3.1.36; gmpy2 2.1.2; greenlet 3.0.0; h5py 3.9.0; holoviews 1.17.1; huggingface-hub 0.17.3; humanfriendly 10.0; hvplot 0.8.4; hyperlink 21.0.0; idna 3.4; igraph 0.10.4; imagecodecs 2023.1.23; imageio 2.31.1; imagesize 1.4.1; imbalanced-learn 0.11.0; importlib-metadata 6.8.0; importlib-resources 6.1.0; incremental 22.10.0; inflection 0.5.1; iniconfig 2.0.0; intake 0.7.0; intervaltree 3.1.0; ipykernel 6.25.2; ipython 8.16.1; ipython-genutils 0.2.0; ipywidgets 8.1.1; isoduration 20.11.0; isort 5.12.0; itemadapter 0.8.0; itemloaders 1.1.0; itsdangerous 2.1.2; jaraco.classes 3.3.0; jedi 0.18.1; jeepney 0.8.0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:7051,Deployability,update,updater,7051,.0.1; Jinja2 3.1.2; jmespath 1.0.1; joblib 1.3.2; json5 0.9.14; jsonpatch 1.33; jsonpointer 2.4; jsonschema 4.19.1; jsonschema-specifications 2023.7.1; jupyter 1.0.0; jupyter_client 8.3.1; jupyter-console 6.6.3; jupyter_core 5.3.2; jupyter-events 0.7.0; jupyter-lsp 2.2.0; jupyter_server 2.7.3; jupyter_server_terminals 0.4.4; jupyterlab 4.0.6; jupyterlab-pygments 0.2.2; jupyterlab_server 2.25.0; jupyterlab-widgets 3.0.9; keyring 24.2.0; kiwisolver 1.4.5; lazy_loader 0.3; lazy-object-proxy 1.9.0; leidenalg 0.9.1; libarchive-c 5.0; libmambapy 1.5.1; linkify-it-py 2.0.0; llvmlite 0.40.1; locket 1.0.0; lxml 4.9.2; lz4 4.3.2; Markdown 3.5; markdown-it-py 3.0.0; MarkupSafe 2.1.3; matplotlib 3.8.0; matplotlib-inline 0.1.6; mccabe 0.7.0; mdit-py-plugins 0.4.0; mdurl 0.1.0; mistune 3.0.1; mkl-service 2.4.0; more-itertools 10.1.0; mpmath 1.3.0; msgpack 1.0.6; multidict 6.0.4; multipledispatch 0.6.0; multiprocess 0.70.15; munkres 1.1.4; mypy-extensions 1.0.0; natsort 8.4.0; natsort 8.4.0; navigator-updater 0.4.0; nbclient 0.8.0; nbconvert 7.9.2; nbformat 5.9.2; nest-asyncio 1.5.6; networkx 3.1; nltk 3.8.1; notebook 7.0.4; notebook_shim 0.2.3; numba 0.57.1; numexpr 2.8.7; numpy 1.24.4; numpydoc 1.5.0; openpyxl 3.1.2; overrides 7.4.0; packaging 23.2; pandas 2.1.1; pandocfilters 1.5.0; panel 1.2.3; parallel-fastq-dump 0.6.7; param 1.13.0; parsel 1.8.1; parso 0.8.3; partd 1.4.1; pathspec 0.11.2; patsy 0.5.3; pep8 1.7.1; pexpect 4.8.0; pickleshare 0.7.5; Pillow 10.0.1; pip 23.2.1; pkce 1.0.3; pkginfo 1.9.6; pkgutil_resolve_name 1.3.10; plac 1.3.5; platformdirs 3.11.0; plotly 5.17.0; pluggy 1.3.0; ply 3.11; pooch 1.7.0; prometheus-client 0.17.1; prompt-toolkit 3.0.39; Protego 0.3.0; psutil 5.9.5; ptyprocess 0.7.0; PuLP 2.7.0; pure-eval 0.2.2; py-cpuinfo 9.0.0; pyarrow 13.0.0; pyasn1 0.5.0; pyasn1-modules 0.3.0; pycodestyle 2.10.0; pycosat 0.6.6; pycparser 2.21; pyct 0.4.6; pycurl 7.45.1; pydantic 1.10.13; pydeseq2 0.4.1; PyDispatcher 2.0.5; pydocstyle 6.3.0; pyerfa 2.0.0.3; pyflakes 3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1111,Energy Efficiency,adapt,adapting,1111,"make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python; sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); Cell In[47], line 1; ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 790 if multi_panel and groupby is None and len(ys) == 1:; 791 # This is a quick and dirty way for adapting scales across several; 792 # keys if groupby is None.; 793 y = ys[0]; --> 795 g = sns.catplot(; 796 y=y,; 797 data=obs_tidy,; 798 kind=""violin"",; 799 scale=scale,; 800 col=x,; 801 col_order=keys,; 802 sharey=False,; 803 order=keys,; 804 cut=0,; 805 inner=None,; 806 **kwds,; 807 ); 809 if stripplot:; 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs); 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""); 2930 linecolor = p._complement_color(linecolor, color, p._hue_map); -> 2932 p.plot_violins(; 2933 width=width,; 2934 dodge=dod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5448,Energy Efficiency,green,greenlet,5448,-content-trust 0+unknown; conda_index 0.2.3; conda-libmamba-solver 23.9.1; conda-pack 0.6.0; conda-package-handling 2.2.0; conda_package_streaming 0.9.0; conda-repo-cli 1.0.75; conda-token 0.4.0; conda-verify 3.4.2; ConfigArgParse 1.7; connection-pool 0.0.3; constantly 15.1.0; contourpy 1.1.1; cookiecutter 2.4.0; cryptography 40.0.1; cssselect 1.2.0; cycler 0.12.1; cytoolz 0.12.2; daal4py 2023.2.1; dask 2023.9.3; dataclasses 0.8; datasets 2.14.5; datashader 0.15.2; datashape 0.5.4; datrie 0.8.2; debugpy 1.8.0; decorator 5.1.1; decoupler 1.5.0; defusedxml 0.7.1; diff-match-patch 20230430; dill 0.3.7; distlib 0.3.7; distributed 2023.9.3; docopt 0.6.2; docstring-to-markdown 0.12; docutils 0.20.1; dpath 2.1.6; entrypoints 0.4; et-xmlfile 1.1.0; exceptiongroup 1.1.3; executing 1.2.0; fastjsonschema 2.18.1; filelock 3.12.4; flake8 6.0.0; Flask 3.0.0; fonttools 4.43.1; fqdn 1.5.1; frozenlist 1.4.0; fsspec 2023.6.0; future 0.18.3; gensim 4.3.2; gitdb 4.0.10; GitPython 3.1.36; gmpy2 2.1.2; greenlet 3.0.0; h5py 3.9.0; holoviews 1.17.1; huggingface-hub 0.17.3; humanfriendly 10.0; hvplot 0.8.4; hyperlink 21.0.0; idna 3.4; igraph 0.10.4; imagecodecs 2023.1.23; imageio 2.31.1; imagesize 1.4.1; imbalanced-learn 0.11.0; importlib-metadata 6.8.0; importlib-resources 6.1.0; incremental 22.10.0; inflection 0.5.1; iniconfig 2.0.0; intake 0.7.0; intervaltree 3.1.0; ipykernel 6.25.2; ipython 8.16.1; ipython-genutils 0.2.0; ipywidgets 8.1.1; isoduration 20.11.0; isort 5.12.0; itemadapter 0.8.0; itemloaders 1.1.0; itsdangerous 2.1.2; jaraco.classes 3.3.0; jedi 0.18.1; jeepney 0.8.0; jellyfish 1.0.1; Jinja2 3.1.2; jmespath 1.0.1; joblib 1.3.2; json5 0.9.14; jsonpatch 1.33; jsonpointer 2.4; jsonschema 4.19.1; jsonschema-specifications 2023.7.1; jupyter 1.0.0; jupyter_client 8.3.1; jupyter-console 6.6.3; jupyter_core 5.3.2; jupyter-events 0.7.0; jupyter-lsp 2.2.0; jupyter_server 2.7.3; jupyter_server_terminals 0.4.4; jupyterlab 4.0.6; jupyterlab-pygments 0.2.2; jupyterlab_server 2.25.0; jupyt,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:10579,Integrability,wrap,wrapt,10579,c3986-validator 0.1.1; rich 13.6.0; rope 1.10.0; rpds-py 0.10.4; Rtree 1.0.1; ruamel.yaml 0.17.35; ruamel.yaml.clib 0.2.7; ruamel-yaml-conda 0.15.80; s3fs 0.5.1; sacremoses 0.0.53; safetensors 0.3.3; scanpy 1.9.5; scikit-image 0.21.0; scikit-learn 1.3.1; scikit-learn-intelex 20230725.122106; scipy 1.11.3; Scrapy 2.11.0; scrublet 0.2.3; scTE 1.0; scTE 1.0; seaborn 0.13.0; SecretStorage 3.3.3; semver 3.0.1; Send2Trash 1.8.2; service-identity 18.1.0; session-info 1.0.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 6.4.0; smmap 5.0.0; snakemake 7.32.3; sniffio 1.3.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.5; Sphinx 7.2.6; sphinxcontrib-applehelp 1.0.7; sphinxcontrib-devhelp 1.0.5; sphinxcontrib-htmlhelp 2.0.4; sphinxcontrib-jsmath 1.0.1; sphinxcontrib-qthelp 1.0.6; sphinxcontrib-serializinghtml 1.1.9; spyder 5.4.3; spyder-kernels 2.4.4; SQLAlchemy 2.0.21; stack-data 0.6.2; statsmodels 0.14.0; stdlib-list 0.8.0; stopit 1.1.2; sympy 1.12; tables 3.9.1; tabulate 0.9.0; TBB 0.2; tblib 2.0.0; tenacity 8.2.3; terminado 0.17.1; text-unidecode 1.3; textdistance 4.5.0; texttable 1.7.0; threadpoolctl 3.2.0; three-merge 0.1.1; throttler 1.2.2; tifffile 2023.4.12; tinycss2 1.2.1; tldextract 3.6.0; tokenizers 0.14.0; toml 0.10.2; tomli 2.0.1; tomlkit 0.12.1; toolz 0.12.0; toposort 1.10; tornado 6.3.3; tqdm 4.66.1; traitlets 5.11.2; transformers 4.34.0; truststore 0.8.0; Twisted 22.10.0; types-python-dateutil 2.8.19.14; typing_extensions 4.8.0; typing-utils 0.1.0; tzdata 2023.3; uc-micro-py 1.0.1; ujson 5.8.0; umap-learn 0.5.4; uri-template 1.3.0; urllib3 1.26.15; virtualenv 20.24.5; w3lib 2.1.2; watchdog 3.0.0; wcwidth 0.2.8; webcolors 1.13; webencodings 0.5.1; websocket-client 1.6.4; Werkzeug 3.0.0; whatthepatch 1.0.5; wheel 0.38.4; widgetsnbextension 4.0.9; wrapt 1.15.0; wurlitzer 3.0.3; xarray 2023.9.0; xxhash 3.4.1; xyzservices 2023.10.0; yapf 0.24.0; yarl 1.9.2; yte 1.5.1; zict 3.0.0; zipp 3.17.0; zope.interface 6.1; zstandard 0.21.0. ```. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:10730,Integrability,interface,interface,10730,c3986-validator 0.1.1; rich 13.6.0; rope 1.10.0; rpds-py 0.10.4; Rtree 1.0.1; ruamel.yaml 0.17.35; ruamel.yaml.clib 0.2.7; ruamel-yaml-conda 0.15.80; s3fs 0.5.1; sacremoses 0.0.53; safetensors 0.3.3; scanpy 1.9.5; scikit-image 0.21.0; scikit-learn 1.3.1; scikit-learn-intelex 20230725.122106; scipy 1.11.3; Scrapy 2.11.0; scrublet 0.2.3; scTE 1.0; scTE 1.0; seaborn 0.13.0; SecretStorage 3.3.3; semver 3.0.1; Send2Trash 1.8.2; service-identity 18.1.0; session-info 1.0.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 6.4.0; smmap 5.0.0; snakemake 7.32.3; sniffio 1.3.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.5; Sphinx 7.2.6; sphinxcontrib-applehelp 1.0.7; sphinxcontrib-devhelp 1.0.5; sphinxcontrib-htmlhelp 2.0.4; sphinxcontrib-jsmath 1.0.1; sphinxcontrib-qthelp 1.0.6; sphinxcontrib-serializinghtml 1.1.9; spyder 5.4.3; spyder-kernels 2.4.4; SQLAlchemy 2.0.21; stack-data 0.6.2; statsmodels 0.14.0; stdlib-list 0.8.0; stopit 1.1.2; sympy 1.12; tables 3.9.1; tabulate 0.9.0; TBB 0.2; tblib 2.0.0; tenacity 8.2.3; terminado 0.17.1; text-unidecode 1.3; textdistance 4.5.0; texttable 1.7.0; threadpoolctl 3.2.0; three-merge 0.1.1; throttler 1.2.2; tifffile 2023.4.12; tinycss2 1.2.1; tldextract 3.6.0; tokenizers 0.14.0; toml 0.10.2; tomli 2.0.1; tomlkit 0.12.1; toolz 0.12.0; toposort 1.10; tornado 6.3.3; tqdm 4.66.1; traitlets 5.11.2; transformers 4.34.0; truststore 0.8.0; Twisted 22.10.0; types-python-dateutil 2.8.19.14; typing_extensions 4.8.0; typing-utils 0.1.0; tzdata 2023.3; uc-micro-py 1.0.1; ujson 5.8.0; umap-learn 0.5.4; uri-template 1.3.0; urllib3 1.26.15; virtualenv 20.24.5; w3lib 2.1.2; watchdog 3.0.0; wcwidth 0.2.8; webcolors 1.13; webencodings 0.5.1; websocket-client 1.6.4; Werkzeug 3.0.0; whatthepatch 1.0.5; wheel 0.38.4; widgetsnbextension 4.0.9; wrapt 1.15.0; wurlitzer 3.0.3; xarray 2023.9.0; xxhash 3.4.1; xyzservices 2023.10.0; yapf 0.24.0; yarl 1.9.2; yte 1.5.1; zict 3.0.0; zipp 3.17.0; zope.interface 6.1; zstandard 0.21.0. ```. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1111,Modifiability,adapt,adapting,1111,"make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python; sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); Cell In[47], line 1; ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 790 if multi_panel and groupby is None and len(ys) == 1:; 791 # This is a quick and dirty way for adapting scales across several; 792 # keys if groupby is None.; 793 y = ys[0]; --> 795 g = sns.catplot(; 796 y=y,; 797 data=obs_tidy,; 798 kind=""violin"",; 799 scale=scale,; 800 col=x,; 801 col_order=keys,; 802 sharey=False,; 803 order=keys,; 804 cut=0,; 805 inner=None,; 806 **kwds,; 807 ); 809 if stripplot:; 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs); 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""); 2930 linecolor = p._complement_color(linecolor, color, p._hue_map); -> 2932 p.plot_violins(; 2933 width=width,; 2934 dodge=dod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:4668,Modifiability,Config,ConfigArgParse,4668,cffi 23.1.0; argon2-cffi-bindings 21.2.0; array-api-compat 1.4; array-api-compat 1.4; arrow 1.3.0; astroid 2.15.7; astropy 5.3.4; asttokens 2.4.0; async-lru 2.0.4; async-timeout 4.0.3; atomicwrites 1.4.1; attrs 23.1.0; Automat 22.10.0; autopep8 2.0.4; Babel 2.12.1; backcall 0.2.0; backports.functools-lru-cache 1.6.5; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 4.0.1; beautifulsoup4 4.12.2; binaryornot 0.4.4; black 23.9.1; bleach 6.1.0; blinker 1.6.3; bokeh 3.2.2; boltons 23.0.0; botocore 1.31.17; brotlipy 0.7.0; cached-property 1.5.2; celltypist 1.6.1; certifi 2023.7.22; cffi 1.16.0; chardet 5.2.0; charset-normalizer 3.3.0; click 8.1.7; cloudpickle 2.2.1; clyent 1.2.2; colorama 0.4.6; colorcet 3.0.1; comm 0.1.4; conda 23.9.0; conda-build 3.27.0; conda-content-trust 0+unknown; conda_index 0.2.3; conda-libmamba-solver 23.9.1; conda-pack 0.6.0; conda-package-handling 2.2.0; conda_package_streaming 0.9.0; conda-repo-cli 1.0.75; conda-token 0.4.0; conda-verify 3.4.2; ConfigArgParse 1.7; connection-pool 0.0.3; constantly 15.1.0; contourpy 1.1.1; cookiecutter 2.4.0; cryptography 40.0.1; cssselect 1.2.0; cycler 0.12.1; cytoolz 0.12.2; daal4py 2023.2.1; dask 2023.9.3; dataclasses 0.8; datasets 2.14.5; datashader 0.15.2; datashape 0.5.4; datrie 0.8.2; debugpy 1.8.0; decorator 5.1.1; decoupler 1.5.0; defusedxml 0.7.1; diff-match-patch 20230430; dill 0.3.7; distlib 0.3.7; distributed 2023.9.3; docopt 0.6.2; docstring-to-markdown 0.12; docutils 0.20.1; dpath 2.1.6; entrypoints 0.4; et-xmlfile 1.1.0; exceptiongroup 1.1.3; executing 1.2.0; fastjsonschema 2.18.1; filelock 3.12.4; flake8 6.0.0; Flask 3.0.0; fonttools 4.43.1; fqdn 1.5.1; frozenlist 1.4.0; fsspec 2023.6.0; future 0.18.3; gensim 4.3.2; gitdb 4.0.10; GitPython 3.1.36; gmpy2 2.1.2; greenlet 3.0.0; h5py 3.9.0; holoviews 1.17.1; huggingface-hub 0.17.3; humanfriendly 10.0; hvplot 0.8.4; hyperlink 21.0.0; idna 3.4; igraph 0.10.4; imagecodecs 2023.1.23; imageio 2.31.1; imagesize 1.4.1; imbalanced-learn 0.11.0;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:6796,Modifiability,plugin,plugins,6796,.0; intervaltree 3.1.0; ipykernel 6.25.2; ipython 8.16.1; ipython-genutils 0.2.0; ipywidgets 8.1.1; isoduration 20.11.0; isort 5.12.0; itemadapter 0.8.0; itemloaders 1.1.0; itsdangerous 2.1.2; jaraco.classes 3.3.0; jedi 0.18.1; jeepney 0.8.0; jellyfish 1.0.1; Jinja2 3.1.2; jmespath 1.0.1; joblib 1.3.2; json5 0.9.14; jsonpatch 1.33; jsonpointer 2.4; jsonschema 4.19.1; jsonschema-specifications 2023.7.1; jupyter 1.0.0; jupyter_client 8.3.1; jupyter-console 6.6.3; jupyter_core 5.3.2; jupyter-events 0.7.0; jupyter-lsp 2.2.0; jupyter_server 2.7.3; jupyter_server_terminals 0.4.4; jupyterlab 4.0.6; jupyterlab-pygments 0.2.2; jupyterlab_server 2.25.0; jupyterlab-widgets 3.0.9; keyring 24.2.0; kiwisolver 1.4.5; lazy_loader 0.3; lazy-object-proxy 1.9.0; leidenalg 0.9.1; libarchive-c 5.0; libmambapy 1.5.1; linkify-it-py 2.0.0; llvmlite 0.40.1; locket 1.0.0; lxml 4.9.2; lz4 4.3.2; Markdown 3.5; markdown-it-py 3.0.0; MarkupSafe 2.1.3; matplotlib 3.8.0; matplotlib-inline 0.1.6; mccabe 0.7.0; mdit-py-plugins 0.4.0; mdurl 0.1.0; mistune 3.0.1; mkl-service 2.4.0; more-itertools 10.1.0; mpmath 1.3.0; msgpack 1.0.6; multidict 6.0.4; multipledispatch 0.6.0; multiprocess 0.70.15; munkres 1.1.4; mypy-extensions 1.0.0; natsort 8.4.0; natsort 8.4.0; navigator-updater 0.4.0; nbclient 0.8.0; nbconvert 7.9.2; nbformat 5.9.2; nest-asyncio 1.5.6; networkx 3.1; nltk 3.8.1; notebook 7.0.4; notebook_shim 0.2.3; numba 0.57.1; numexpr 2.8.7; numpy 1.24.4; numpydoc 1.5.0; openpyxl 3.1.2; overrides 7.4.0; packaging 23.2; pandas 2.1.1; pandocfilters 1.5.0; panel 1.2.3; parallel-fastq-dump 0.6.7; param 1.13.0; parsel 1.8.1; parso 0.8.3; partd 1.4.1; pathspec 0.11.2; patsy 0.5.3; pep8 1.7.1; pexpect 4.8.0; pickleshare 0.7.5; Pillow 10.0.1; pip 23.2.1; pkce 1.0.3; pkginfo 1.9.6; pkgutil_resolve_name 1.3.10; plac 1.3.5; platformdirs 3.11.0; plotly 5.17.0; pluggy 1.3.0; ply 3.11; pooch 1.7.0; prometheus-client 0.17.1; prompt-toolkit 3.0.39; Protego 0.3.0; psutil 5.9.5; ptyprocess 0.7.0; PuLP 2.7.0; pure-eval,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3981,Performance,cache,cache,3981,"nd:; 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws); --> 420 handles, _ = ax.get_legend_handles_labels(); 421 if handles:; 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.6.0; aiohttp 3.8.6; aioitertools 0.11.0; aiosignal 1.3.1; alabaster 0.7.13; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.0; anaconda-cloud-auth 0.1.4; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anndata 0.10.1; anndata 0.10.0rc1; annoy 1.17.2; anyio 4.0.0; appdirs 1.4.4; argon2-cffi 23.1.0; argon2-cffi-bindings 21.2.0; array-api-compat 1.4; array-api-compat 1.4; arrow 1.3.0; astroid 2.15.7; astropy 5.3.4; asttokens 2.4.0; async-lru 2.0.4; async-timeout 4.0.3; atomicwrites 1.4.1; attrs 23.1.0; Automat 22.10.0; autopep8 2.0.4; Babel 2.12.1; backcall 0.2.0; backports.functools-lru-cache 1.6.5; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 4.0.1; beautifulsoup4 4.12.2; binaryornot 0.4.4; black 23.9.1; bleach 6.1.0; blinker 1.6.3; bokeh 3.2.2; boltons 23.0.0; botocore 1.31.17; brotlipy 0.7.0; cached-property 1.5.2; celltypist 1.6.1; certifi 2023.7.22; cffi 1.16.0; chardet 5.2.0; charset-normalizer 3.3.0; click 8.1.7; cloudpickle 2.2.1; clyent 1.2.2; colorama 0.4.6; colorcet 3.0.1; comm 0.1.4; conda 23.9.0; conda-build 3.27.0; conda-content-trust 0+unknown; conda_index 0.2.3; conda-libmamba-solver 23.9.1; conda-pack 0.6.0; conda-package-handling 2.2.0; conda_package_streaming 0.9.0; conda-repo-cli 1.0.75; conda-token 0.4.0; conda-verify 3.4.2; ConfigArgParse 1.7; connection-pool 0.0.3; constantly 15.1.0; contourpy 1.1.1; cookiecutter 2.4.0; cryptography 40.0.1; cssselect 1.2.0; cycler 0.12.1; cytoolz 0.12.2; daal4py 2023.2.1; dask 2023.9.3; dataclasses 0.8; datasets 2.14.5; datashader 0.15.2; datashape 0.5.4; datrie 0.8.2; debugpy 1.8.0; decorator ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:4209,Performance,cache,cached-property,4209,te 'get_legend_handles_labels'; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.6.0; aiohttp 3.8.6; aioitertools 0.11.0; aiosignal 1.3.1; alabaster 0.7.13; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.0; anaconda-cloud-auth 0.1.4; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anndata 0.10.1; anndata 0.10.0rc1; annoy 1.17.2; anyio 4.0.0; appdirs 1.4.4; argon2-cffi 23.1.0; argon2-cffi-bindings 21.2.0; array-api-compat 1.4; array-api-compat 1.4; arrow 1.3.0; astroid 2.15.7; astropy 5.3.4; asttokens 2.4.0; async-lru 2.0.4; async-timeout 4.0.3; atomicwrites 1.4.1; attrs 23.1.0; Automat 22.10.0; autopep8 2.0.4; Babel 2.12.1; backcall 0.2.0; backports.functools-lru-cache 1.6.5; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 4.0.1; beautifulsoup4 4.12.2; binaryornot 0.4.4; black 23.9.1; bleach 6.1.0; blinker 1.6.3; bokeh 3.2.2; boltons 23.0.0; botocore 1.31.17; brotlipy 0.7.0; cached-property 1.5.2; celltypist 1.6.1; certifi 2023.7.22; cffi 1.16.0; chardet 5.2.0; charset-normalizer 3.3.0; click 8.1.7; cloudpickle 2.2.1; clyent 1.2.2; colorama 0.4.6; colorcet 3.0.1; comm 0.1.4; conda 23.9.0; conda-build 3.27.0; conda-content-trust 0+unknown; conda_index 0.2.3; conda-libmamba-solver 23.9.1; conda-pack 0.6.0; conda-package-handling 2.2.0; conda_package_streaming 0.9.0; conda-repo-cli 1.0.75; conda-token 0.4.0; conda-verify 3.4.2; ConfigArgParse 1.7; connection-pool 0.0.3; constantly 15.1.0; contourpy 1.1.1; cookiecutter 2.4.0; cryptography 40.0.1; cssselect 1.2.0; cycler 0.12.1; cytoolz 0.12.2; daal4py 2023.2.1; dask 2023.9.3; dataclasses 0.8; datasets 2.14.5; datashader 0.15.2; datashape 0.5.4; datrie 0.8.2; debugpy 1.8.0; decorator 5.1.1; decoupler 1.5.0; defusedxml 0.7.1; diff-match-patch 20230430; dill 0.3.7; distlib 0.3.7; distributed 2023.9.3; docopt 0.6.2; docstring-to-markdown 0.12; docutils 0.20.1; dpath 2.1.6; entrypoints 0.4; et-xmlfile 1.1.0; exceptiongroup,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:8619,Performance,queue,queuelib,8619,.0; plotly 5.17.0; pluggy 1.3.0; ply 3.11; pooch 1.7.0; prometheus-client 0.17.1; prompt-toolkit 3.0.39; Protego 0.3.0; psutil 5.9.5; ptyprocess 0.7.0; PuLP 2.7.0; pure-eval 0.2.2; py-cpuinfo 9.0.0; pyarrow 13.0.0; pyasn1 0.5.0; pyasn1-modules 0.3.0; pycodestyle 2.10.0; pycosat 0.6.6; pycparser 2.21; pyct 0.4.6; pycurl 7.45.1; pydantic 1.10.13; pydeseq2 0.4.1; PyDispatcher 2.0.5; pydocstyle 6.3.0; pyerfa 2.0.0.3; pyflakes 3.0.1; Pygments 2.16.1; PyJWT 2.8.0; pylint 2.17.5; pylint-venv 3.0.2; pyls-spyder 0.4.0; pynndescent 0.5.10; pyodbc 4.0.39; pyOpenSSL 23.2.0; pyparsing 3.1.1; PyQt5-sip 12.11.0; PySocks 1.7.1; pytest 7.4.2; python-dateutil 2.8.2; python-dotenv 1.0.0; python-json-logger 2.0.7; python-lsp-black 1.3.0; python-lsp-jsonrpc 1.1.2; python-lsp-server 1.7.2; python-slugify 8.0.1; pytoolconfig 1.2.5; pytz 2023.3.post1; pyviz_comms 3.0.0; PyWavelets 1.4.1; pyxdg 0.28; PyYAML 6.0.1; pyzmq 25.1.1; QDarkStyle 3.1; qstylizer 0.2.2; QtAwesome 1.2.3; qtconsole 5.4.4; QtPy 2.4.0; queuelib 1.6.2; referencing 0.30.2; regex 2023.10.3; requests 2.31.0; requests-file 1.5.1; requests-toolbelt 1.0.0; reretry 0.11.8; rfc3339-validator 0.1.4; rfc3986-validator 0.1.1; rich 13.6.0; rope 1.10.0; rpds-py 0.10.4; Rtree 1.0.1; ruamel.yaml 0.17.35; ruamel.yaml.clib 0.2.7; ruamel-yaml-conda 0.15.80; s3fs 0.5.1; sacremoses 0.0.53; safetensors 0.3.3; scanpy 1.9.5; scikit-image 0.21.0; scikit-learn 1.3.1; scikit-learn-intelex 20230725.122106; scipy 1.11.3; Scrapy 2.11.0; scrublet 0.2.3; scTE 1.0; scTE 1.0; seaborn 0.13.0; SecretStorage 3.3.3; semver 3.0.1; Send2Trash 1.8.2; service-identity 18.1.0; session-info 1.0.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 6.4.0; smmap 5.0.0; snakemake 7.32.3; sniffio 1.3.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.5; Sphinx 7.2.6; sphinxcontrib-applehelp 1.0.7; sphinxcontrib-devhelp 1.0.5; sphinxcontrib-htmlhelp 2.0.4; sphinxcontrib-jsmath 1.0.1; sphinxcontrib-qthelp 1.0.6; sphinxcontrib-serializinghtml 1.1.9; spyder 5,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:9936,Performance,throttle,throttler,9936,c3986-validator 0.1.1; rich 13.6.0; rope 1.10.0; rpds-py 0.10.4; Rtree 1.0.1; ruamel.yaml 0.17.35; ruamel.yaml.clib 0.2.7; ruamel-yaml-conda 0.15.80; s3fs 0.5.1; sacremoses 0.0.53; safetensors 0.3.3; scanpy 1.9.5; scikit-image 0.21.0; scikit-learn 1.3.1; scikit-learn-intelex 20230725.122106; scipy 1.11.3; Scrapy 2.11.0; scrublet 0.2.3; scTE 1.0; scTE 1.0; seaborn 0.13.0; SecretStorage 3.3.3; semver 3.0.1; Send2Trash 1.8.2; service-identity 18.1.0; session-info 1.0.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 6.4.0; smmap 5.0.0; snakemake 7.32.3; sniffio 1.3.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.5; Sphinx 7.2.6; sphinxcontrib-applehelp 1.0.7; sphinxcontrib-devhelp 1.0.5; sphinxcontrib-htmlhelp 2.0.4; sphinxcontrib-jsmath 1.0.1; sphinxcontrib-qthelp 1.0.6; sphinxcontrib-serializinghtml 1.1.9; spyder 5.4.3; spyder-kernels 2.4.4; SQLAlchemy 2.0.21; stack-data 0.6.2; statsmodels 0.14.0; stdlib-list 0.8.0; stopit 1.1.2; sympy 1.12; tables 3.9.1; tabulate 0.9.0; TBB 0.2; tblib 2.0.0; tenacity 8.2.3; terminado 0.17.1; text-unidecode 1.3; textdistance 4.5.0; texttable 1.7.0; threadpoolctl 3.2.0; three-merge 0.1.1; throttler 1.2.2; tifffile 2023.4.12; tinycss2 1.2.1; tldextract 3.6.0; tokenizers 0.14.0; toml 0.10.2; tomli 2.0.1; tomlkit 0.12.1; toolz 0.12.0; toposort 1.10; tornado 6.3.3; tqdm 4.66.1; traitlets 5.11.2; transformers 4.34.0; truststore 0.8.0; Twisted 22.10.0; types-python-dateutil 2.8.19.14; typing_extensions 4.8.0; typing-utils 0.1.0; tzdata 2023.3; uc-micro-py 1.0.1; ujson 5.8.0; umap-learn 0.5.4; uri-template 1.3.0; urllib3 1.26.15; virtualenv 20.24.5; w3lib 2.1.2; watchdog 3.0.0; wcwidth 0.2.8; webcolors 1.13; webencodings 0.5.1; websocket-client 1.6.4; Werkzeug 3.0.0; whatthepatch 1.0.5; wheel 0.38.4; widgetsnbextension 4.0.9; wrapt 1.15.0; wurlitzer 3.0.3; xarray 2023.9.0; xxhash 3.4.1; xyzservices 2023.10.0; yapf 0.24.0; yarl 1.9.2; yte 1.5.1; zict 3.0.0; zipp 3.17.0; zope.interface 6.1; zstandard 0.21.0. ```. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3845,Safety,timeout,timeout,3845,"ages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws); 418 if show_legend:; 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws); --> 420 handles, _ = ax.get_legend_handles_labels(); 421 if handles:; 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.6.0; aiohttp 3.8.6; aioitertools 0.11.0; aiosignal 1.3.1; alabaster 0.7.13; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.0; anaconda-cloud-auth 0.1.4; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anndata 0.10.1; anndata 0.10.0rc1; annoy 1.17.2; anyio 4.0.0; appdirs 1.4.4; argon2-cffi 23.1.0; argon2-cffi-bindings 21.2.0; array-api-compat 1.4; array-api-compat 1.4; arrow 1.3.0; astroid 2.15.7; astropy 5.3.4; asttokens 2.4.0; async-lru 2.0.4; async-timeout 4.0.3; atomicwrites 1.4.1; attrs 23.1.0; Automat 22.10.0; autopep8 2.0.4; Babel 2.12.1; backcall 0.2.0; backports.functools-lru-cache 1.6.5; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 4.0.1; beautifulsoup4 4.12.2; binaryornot 0.4.4; black 23.9.1; bleach 6.1.0; blinker 1.6.3; bokeh 3.2.2; boltons 23.0.0; botocore 1.31.17; brotlipy 0.7.0; cached-property 1.5.2; celltypist 1.6.1; certifi 2023.7.22; cffi 1.16.0; chardet 5.2.0; charset-normalizer 3.3.0; click 8.1.7; cloudpickle 2.2.1; clyent 1.2.2; colorama 0.4.6; colorcet 3.0.1; comm 0.1.4; conda 23.9.0; conda-build 3.27.0; conda-content-trust 0+unknown; conda_index 0.2.3; conda-libmamba-solver 23.9.1; conda-pack 0.6.0; conda-package-handling 2.2.0; conda_package_streaming 0.9.0; conda-repo-cli 1.0.75; conda-token 0.4.0; conda-verify 3.4.2; ConfigArgParse 1.7; connection-pool 0.0.3; constantly 15.1.0; contourpy 1.1.1; cookiecutter 2.4.0; cryptography 40.0.1; cssselect 1.2.0; cycler 0.12.1; cytoolz 0.12.2; daal4py 20",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:8959,Safety,safe,safetensors,8959,0.13; pydeseq2 0.4.1; PyDispatcher 2.0.5; pydocstyle 6.3.0; pyerfa 2.0.0.3; pyflakes 3.0.1; Pygments 2.16.1; PyJWT 2.8.0; pylint 2.17.5; pylint-venv 3.0.2; pyls-spyder 0.4.0; pynndescent 0.5.10; pyodbc 4.0.39; pyOpenSSL 23.2.0; pyparsing 3.1.1; PyQt5-sip 12.11.0; PySocks 1.7.1; pytest 7.4.2; python-dateutil 2.8.2; python-dotenv 1.0.0; python-json-logger 2.0.7; python-lsp-black 1.3.0; python-lsp-jsonrpc 1.1.2; python-lsp-server 1.7.2; python-slugify 8.0.1; pytoolconfig 1.2.5; pytz 2023.3.post1; pyviz_comms 3.0.0; PyWavelets 1.4.1; pyxdg 0.28; PyYAML 6.0.1; pyzmq 25.1.1; QDarkStyle 3.1; qstylizer 0.2.2; QtAwesome 1.2.3; qtconsole 5.4.4; QtPy 2.4.0; queuelib 1.6.2; referencing 0.30.2; regex 2023.10.3; requests 2.31.0; requests-file 1.5.1; requests-toolbelt 1.0.0; reretry 0.11.8; rfc3339-validator 0.1.4; rfc3986-validator 0.1.1; rich 13.6.0; rope 1.10.0; rpds-py 0.10.4; Rtree 1.0.1; ruamel.yaml 0.17.35; ruamel.yaml.clib 0.2.7; ruamel-yaml-conda 0.15.80; s3fs 0.5.1; sacremoses 0.0.53; safetensors 0.3.3; scanpy 1.9.5; scikit-image 0.21.0; scikit-learn 1.3.1; scikit-learn-intelex 20230725.122106; scipy 1.11.3; Scrapy 2.11.0; scrublet 0.2.3; scTE 1.0; scTE 1.0; seaborn 0.13.0; SecretStorage 3.3.3; semver 3.0.1; Send2Trash 1.8.2; service-identity 18.1.0; session-info 1.0.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 6.4.0; smmap 5.0.0; snakemake 7.32.3; sniffio 1.3.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.5; Sphinx 7.2.6; sphinxcontrib-applehelp 1.0.7; sphinxcontrib-devhelp 1.0.5; sphinxcontrib-htmlhelp 2.0.4; sphinxcontrib-jsmath 1.0.1; sphinxcontrib-qthelp 1.0.6; sphinxcontrib-serializinghtml 1.1.9; spyder 5.4.3; spyder-kernels 2.4.4; SQLAlchemy 2.0.21; stack-data 0.6.2; statsmodels 0.14.0; stdlib-list 0.8.0; stopit 1.1.2; sympy 1.12; tables 3.9.1; tabulate 0.9.0; TBB 0.2; tblib 2.0.0; tenacity 8.2.3; terminado 0.17.1; text-unidecode 1.3; textdistance 4.5.0; texttable 1.7.0; threadpoolctl 3.2.0; three-merge 0.1.1; throttler 1.2.2; tifffile 20,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:8759,Security,validat,validator,8759,yprocess 0.7.0; PuLP 2.7.0; pure-eval 0.2.2; py-cpuinfo 9.0.0; pyarrow 13.0.0; pyasn1 0.5.0; pyasn1-modules 0.3.0; pycodestyle 2.10.0; pycosat 0.6.6; pycparser 2.21; pyct 0.4.6; pycurl 7.45.1; pydantic 1.10.13; pydeseq2 0.4.1; PyDispatcher 2.0.5; pydocstyle 6.3.0; pyerfa 2.0.0.3; pyflakes 3.0.1; Pygments 2.16.1; PyJWT 2.8.0; pylint 2.17.5; pylint-venv 3.0.2; pyls-spyder 0.4.0; pynndescent 0.5.10; pyodbc 4.0.39; pyOpenSSL 23.2.0; pyparsing 3.1.1; PyQt5-sip 12.11.0; PySocks 1.7.1; pytest 7.4.2; python-dateutil 2.8.2; python-dotenv 1.0.0; python-json-logger 2.0.7; python-lsp-black 1.3.0; python-lsp-jsonrpc 1.1.2; python-lsp-server 1.7.2; python-slugify 8.0.1; pytoolconfig 1.2.5; pytz 2023.3.post1; pyviz_comms 3.0.0; PyWavelets 1.4.1; pyxdg 0.28; PyYAML 6.0.1; pyzmq 25.1.1; QDarkStyle 3.1; qstylizer 0.2.2; QtAwesome 1.2.3; qtconsole 5.4.4; QtPy 2.4.0; queuelib 1.6.2; referencing 0.30.2; regex 2023.10.3; requests 2.31.0; requests-file 1.5.1; requests-toolbelt 1.0.0; reretry 0.11.8; rfc3339-validator 0.1.4; rfc3986-validator 0.1.1; rich 13.6.0; rope 1.10.0; rpds-py 0.10.4; Rtree 1.0.1; ruamel.yaml 0.17.35; ruamel.yaml.clib 0.2.7; ruamel-yaml-conda 0.15.80; s3fs 0.5.1; sacremoses 0.0.53; safetensors 0.3.3; scanpy 1.9.5; scikit-image 0.21.0; scikit-learn 1.3.1; scikit-learn-intelex 20230725.122106; scipy 1.11.3; Scrapy 2.11.0; scrublet 0.2.3; scTE 1.0; scTE 1.0; seaborn 0.13.0; SecretStorage 3.3.3; semver 3.0.1; Send2Trash 1.8.2; service-identity 18.1.0; session-info 1.0.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 6.4.0; smmap 5.0.0; snakemake 7.32.3; sniffio 1.3.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.5; Sphinx 7.2.6; sphinxcontrib-applehelp 1.0.7; sphinxcontrib-devhelp 1.0.5; sphinxcontrib-htmlhelp 2.0.4; sphinxcontrib-jsmath 1.0.1; sphinxcontrib-qthelp 1.0.6; sphinxcontrib-serializinghtml 1.1.9; spyder 5.4.3; spyder-kernels 2.4.4; SQLAlchemy 2.0.21; stack-data 0.6.2; statsmodels 0.14.0; stdlib-list 0.8.0; stopit 1.1.2; sympy 1.12; tables ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:8784,Security,validat,validator,8784,0; pure-eval 0.2.2; py-cpuinfo 9.0.0; pyarrow 13.0.0; pyasn1 0.5.0; pyasn1-modules 0.3.0; pycodestyle 2.10.0; pycosat 0.6.6; pycparser 2.21; pyct 0.4.6; pycurl 7.45.1; pydantic 1.10.13; pydeseq2 0.4.1; PyDispatcher 2.0.5; pydocstyle 6.3.0; pyerfa 2.0.0.3; pyflakes 3.0.1; Pygments 2.16.1; PyJWT 2.8.0; pylint 2.17.5; pylint-venv 3.0.2; pyls-spyder 0.4.0; pynndescent 0.5.10; pyodbc 4.0.39; pyOpenSSL 23.2.0; pyparsing 3.1.1; PyQt5-sip 12.11.0; PySocks 1.7.1; pytest 7.4.2; python-dateutil 2.8.2; python-dotenv 1.0.0; python-json-logger 2.0.7; python-lsp-black 1.3.0; python-lsp-jsonrpc 1.1.2; python-lsp-server 1.7.2; python-slugify 8.0.1; pytoolconfig 1.2.5; pytz 2023.3.post1; pyviz_comms 3.0.0; PyWavelets 1.4.1; pyxdg 0.28; PyYAML 6.0.1; pyzmq 25.1.1; QDarkStyle 3.1; qstylizer 0.2.2; QtAwesome 1.2.3; qtconsole 5.4.4; QtPy 2.4.0; queuelib 1.6.2; referencing 0.30.2; regex 2023.10.3; requests 2.31.0; requests-file 1.5.1; requests-toolbelt 1.0.0; reretry 0.11.8; rfc3339-validator 0.1.4; rfc3986-validator 0.1.1; rich 13.6.0; rope 1.10.0; rpds-py 0.10.4; Rtree 1.0.1; ruamel.yaml 0.17.35; ruamel.yaml.clib 0.2.7; ruamel-yaml-conda 0.15.80; s3fs 0.5.1; sacremoses 0.0.53; safetensors 0.3.3; scanpy 1.9.5; scikit-image 0.21.0; scikit-learn 1.3.1; scikit-learn-intelex 20230725.122106; scipy 1.11.3; Scrapy 2.11.0; scrublet 0.2.3; scTE 1.0; scTE 1.0; seaborn 0.13.0; SecretStorage 3.3.3; semver 3.0.1; Send2Trash 1.8.2; service-identity 18.1.0; session-info 1.0.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 6.4.0; smmap 5.0.0; snakemake 7.32.3; sniffio 1.3.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.5; Sphinx 7.2.6; sphinxcontrib-applehelp 1.0.7; sphinxcontrib-devhelp 1.0.5; sphinxcontrib-htmlhelp 2.0.4; sphinxcontrib-jsmath 1.0.1; sphinxcontrib-qthelp 1.0.6; sphinxcontrib-serializinghtml 1.1.9; spyder 5.4.3; spyder-kernels 2.4.4; SQLAlchemy 2.0.21; stack-data 0.6.2; statsmodels 0.14.0; stdlib-list 0.8.0; stopit 1.1.2; sympy 1.12; tables 3.9.1; tabulate 0.9.0; TB,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:889,Testability,log,log,889,"make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python; sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True); ```. ### Error output. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); Cell In[47], line 1; ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 790 if multi_panel and groupby is None and len(ys) == 1:; 791 # This is a quick and dirty way for adapting scales across several; 792 # keys if groupby is None.; 793 y = ys[0]; --> 795 g = sns.catplot(; 796 y=y,; 797 data=obs_tidy,; 798 kind=""violin"",; 799 scale=scale,; 800 col=x,; 801 col_order=keys,; 802 sharey=False,; 803 order=keys,; 804 cut=0,; 805 inner=None,; 806 **kwds,; 807 ); 809 if stripplot:; 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs); 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""); 2930 linecolor = p._complement_color(linecolor, color, p._hue_map); -> 2932 p.plot_violins(; 2933 width=width,; 2934 dodge=dod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:8313,Testability,log,logger,8313,as 2.1.1; pandocfilters 1.5.0; panel 1.2.3; parallel-fastq-dump 0.6.7; param 1.13.0; parsel 1.8.1; parso 0.8.3; partd 1.4.1; pathspec 0.11.2; patsy 0.5.3; pep8 1.7.1; pexpect 4.8.0; pickleshare 0.7.5; Pillow 10.0.1; pip 23.2.1; pkce 1.0.3; pkginfo 1.9.6; pkgutil_resolve_name 1.3.10; plac 1.3.5; platformdirs 3.11.0; plotly 5.17.0; pluggy 1.3.0; ply 3.11; pooch 1.7.0; prometheus-client 0.17.1; prompt-toolkit 3.0.39; Protego 0.3.0; psutil 5.9.5; ptyprocess 0.7.0; PuLP 2.7.0; pure-eval 0.2.2; py-cpuinfo 9.0.0; pyarrow 13.0.0; pyasn1 0.5.0; pyasn1-modules 0.3.0; pycodestyle 2.10.0; pycosat 0.6.6; pycparser 2.21; pyct 0.4.6; pycurl 7.45.1; pydantic 1.10.13; pydeseq2 0.4.1; PyDispatcher 2.0.5; pydocstyle 6.3.0; pyerfa 2.0.0.3; pyflakes 3.0.1; Pygments 2.16.1; PyJWT 2.8.0; pylint 2.17.5; pylint-venv 3.0.2; pyls-spyder 0.4.0; pynndescent 0.5.10; pyodbc 4.0.39; pyOpenSSL 23.2.0; pyparsing 3.1.1; PyQt5-sip 12.11.0; PySocks 1.7.1; pytest 7.4.2; python-dateutil 2.8.2; python-dotenv 1.0.0; python-json-logger 2.0.7; python-lsp-black 1.3.0; python-lsp-jsonrpc 1.1.2; python-lsp-server 1.7.2; python-slugify 8.0.1; pytoolconfig 1.2.5; pytz 2023.3.post1; pyviz_comms 3.0.0; PyWavelets 1.4.1; pyxdg 0.28; PyYAML 6.0.1; pyzmq 25.1.1; QDarkStyle 3.1; qstylizer 0.2.2; QtAwesome 1.2.3; qtconsole 5.4.4; QtPy 2.4.0; queuelib 1.6.2; referencing 0.30.2; regex 2023.10.3; requests 2.31.0; requests-file 1.5.1; requests-toolbelt 1.0.0; reretry 0.11.8; rfc3339-validator 0.1.4; rfc3986-validator 0.1.1; rich 13.6.0; rope 1.10.0; rpds-py 0.10.4; Rtree 1.0.1; ruamel.yaml 0.17.35; ruamel.yaml.clib 0.2.7; ruamel-yaml-conda 0.15.80; s3fs 0.5.1; sacremoses 0.0.53; safetensors 0.3.3; scanpy 1.9.5; scikit-image 0.21.0; scikit-learn 1.3.1; scikit-learn-intelex 20230725.122106; scipy 1.11.3; Scrapy 2.11.0; scrublet 0.2.3; scTE 1.0; scTE 1.0; seaborn 0.13.0; SecretStorage 3.3.3; semver 3.0.1; Send2Trash 1.8.2; service-identity 18.1.0; session-info 1.0.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 6.4.0; ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5662,Usability,learn,learn,5662,y 3.4.2; ConfigArgParse 1.7; connection-pool 0.0.3; constantly 15.1.0; contourpy 1.1.1; cookiecutter 2.4.0; cryptography 40.0.1; cssselect 1.2.0; cycler 0.12.1; cytoolz 0.12.2; daal4py 2023.2.1; dask 2023.9.3; dataclasses 0.8; datasets 2.14.5; datashader 0.15.2; datashape 0.5.4; datrie 0.8.2; debugpy 1.8.0; decorator 5.1.1; decoupler 1.5.0; defusedxml 0.7.1; diff-match-patch 20230430; dill 0.3.7; distlib 0.3.7; distributed 2023.9.3; docopt 0.6.2; docstring-to-markdown 0.12; docutils 0.20.1; dpath 2.1.6; entrypoints 0.4; et-xmlfile 1.1.0; exceptiongroup 1.1.3; executing 1.2.0; fastjsonschema 2.18.1; filelock 3.12.4; flake8 6.0.0; Flask 3.0.0; fonttools 4.43.1; fqdn 1.5.1; frozenlist 1.4.0; fsspec 2023.6.0; future 0.18.3; gensim 4.3.2; gitdb 4.0.10; GitPython 3.1.36; gmpy2 2.1.2; greenlet 3.0.0; h5py 3.9.0; holoviews 1.17.1; huggingface-hub 0.17.3; humanfriendly 10.0; hvplot 0.8.4; hyperlink 21.0.0; idna 3.4; igraph 0.10.4; imagecodecs 2023.1.23; imageio 2.31.1; imagesize 1.4.1; imbalanced-learn 0.11.0; importlib-metadata 6.8.0; importlib-resources 6.1.0; incremental 22.10.0; inflection 0.5.1; iniconfig 2.0.0; intake 0.7.0; intervaltree 3.1.0; ipykernel 6.25.2; ipython 8.16.1; ipython-genutils 0.2.0; ipywidgets 8.1.1; isoduration 20.11.0; isort 5.12.0; itemadapter 0.8.0; itemloaders 1.1.0; itsdangerous 2.1.2; jaraco.classes 3.3.0; jedi 0.18.1; jeepney 0.8.0; jellyfish 1.0.1; Jinja2 3.1.2; jmespath 1.0.1; joblib 1.3.2; json5 0.9.14; jsonpatch 1.33; jsonpointer 2.4; jsonschema 4.19.1; jsonschema-specifications 2023.7.1; jupyter 1.0.0; jupyter_client 8.3.1; jupyter-console 6.6.3; jupyter_core 5.3.2; jupyter-events 0.7.0; jupyter-lsp 2.2.0; jupyter_server 2.7.3; jupyter_server_terminals 0.4.4; jupyterlab 4.0.6; jupyterlab-pygments 0.2.2; jupyterlab_server 2.25.0; jupyterlab-widgets 3.0.9; keyring 24.2.0; kiwisolver 1.4.5; lazy_loader 0.3; lazy-object-proxy 1.9.0; leidenalg 0.9.1; libarchive-c 5.0; libmambapy 1.5.1; linkify-it-py 2.0.0; llvmlite 0.40.1; locket 1.0.0; lxml ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:9020,Usability,learn,learn,9020,3.0; pyerfa 2.0.0.3; pyflakes 3.0.1; Pygments 2.16.1; PyJWT 2.8.0; pylint 2.17.5; pylint-venv 3.0.2; pyls-spyder 0.4.0; pynndescent 0.5.10; pyodbc 4.0.39; pyOpenSSL 23.2.0; pyparsing 3.1.1; PyQt5-sip 12.11.0; PySocks 1.7.1; pytest 7.4.2; python-dateutil 2.8.2; python-dotenv 1.0.0; python-json-logger 2.0.7; python-lsp-black 1.3.0; python-lsp-jsonrpc 1.1.2; python-lsp-server 1.7.2; python-slugify 8.0.1; pytoolconfig 1.2.5; pytz 2023.3.post1; pyviz_comms 3.0.0; PyWavelets 1.4.1; pyxdg 0.28; PyYAML 6.0.1; pyzmq 25.1.1; QDarkStyle 3.1; qstylizer 0.2.2; QtAwesome 1.2.3; qtconsole 5.4.4; QtPy 2.4.0; queuelib 1.6.2; referencing 0.30.2; regex 2023.10.3; requests 2.31.0; requests-file 1.5.1; requests-toolbelt 1.0.0; reretry 0.11.8; rfc3339-validator 0.1.4; rfc3986-validator 0.1.1; rich 13.6.0; rope 1.10.0; rpds-py 0.10.4; Rtree 1.0.1; ruamel.yaml 0.17.35; ruamel.yaml.clib 0.2.7; ruamel-yaml-conda 0.15.80; s3fs 0.5.1; sacremoses 0.0.53; safetensors 0.3.3; scanpy 1.9.5; scikit-image 0.21.0; scikit-learn 1.3.1; scikit-learn-intelex 20230725.122106; scipy 1.11.3; Scrapy 2.11.0; scrublet 0.2.3; scTE 1.0; scTE 1.0; seaborn 0.13.0; SecretStorage 3.3.3; semver 3.0.1; Send2Trash 1.8.2; service-identity 18.1.0; session-info 1.0.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 6.4.0; smmap 5.0.0; snakemake 7.32.3; sniffio 1.3.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.5; Sphinx 7.2.6; sphinxcontrib-applehelp 1.0.7; sphinxcontrib-devhelp 1.0.5; sphinxcontrib-htmlhelp 2.0.4; sphinxcontrib-jsmath 1.0.1; sphinxcontrib-qthelp 1.0.6; sphinxcontrib-serializinghtml 1.1.9; spyder 5.4.3; spyder-kernels 2.4.4; SQLAlchemy 2.0.21; stack-data 0.6.2; statsmodels 0.14.0; stdlib-list 0.8.0; stopit 1.1.2; sympy 1.12; tables 3.9.1; tabulate 0.9.0; TBB 0.2; tblib 2.0.0; tenacity 8.2.3; terminado 0.17.1; text-unidecode 1.3; textdistance 4.5.0; texttable 1.7.0; threadpoolctl 3.2.0; three-merge 0.1.1; throttler 1.2.2; tifffile 2023.4.12; tinycss2 1.2.1; tldextract 3.6.0; tokenizers 0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:9040,Usability,learn,learn-intelex,9040,es 3.0.1; Pygments 2.16.1; PyJWT 2.8.0; pylint 2.17.5; pylint-venv 3.0.2; pyls-spyder 0.4.0; pynndescent 0.5.10; pyodbc 4.0.39; pyOpenSSL 23.2.0; pyparsing 3.1.1; PyQt5-sip 12.11.0; PySocks 1.7.1; pytest 7.4.2; python-dateutil 2.8.2; python-dotenv 1.0.0; python-json-logger 2.0.7; python-lsp-black 1.3.0; python-lsp-jsonrpc 1.1.2; python-lsp-server 1.7.2; python-slugify 8.0.1; pytoolconfig 1.2.5; pytz 2023.3.post1; pyviz_comms 3.0.0; PyWavelets 1.4.1; pyxdg 0.28; PyYAML 6.0.1; pyzmq 25.1.1; QDarkStyle 3.1; qstylizer 0.2.2; QtAwesome 1.2.3; qtconsole 5.4.4; QtPy 2.4.0; queuelib 1.6.2; referencing 0.30.2; regex 2023.10.3; requests 2.31.0; requests-file 1.5.1; requests-toolbelt 1.0.0; reretry 0.11.8; rfc3339-validator 0.1.4; rfc3986-validator 0.1.1; rich 13.6.0; rope 1.10.0; rpds-py 0.10.4; Rtree 1.0.1; ruamel.yaml 0.17.35; ruamel.yaml.clib 0.2.7; ruamel-yaml-conda 0.15.80; s3fs 0.5.1; sacremoses 0.0.53; safetensors 0.3.3; scanpy 1.9.5; scikit-image 0.21.0; scikit-learn 1.3.1; scikit-learn-intelex 20230725.122106; scipy 1.11.3; Scrapy 2.11.0; scrublet 0.2.3; scTE 1.0; scTE 1.0; seaborn 0.13.0; SecretStorage 3.3.3; semver 3.0.1; Send2Trash 1.8.2; service-identity 18.1.0; session-info 1.0.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 6.4.0; smmap 5.0.0; snakemake 7.32.3; sniffio 1.3.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.5; Sphinx 7.2.6; sphinxcontrib-applehelp 1.0.7; sphinxcontrib-devhelp 1.0.5; sphinxcontrib-htmlhelp 2.0.4; sphinxcontrib-jsmath 1.0.1; sphinxcontrib-qthelp 1.0.6; sphinxcontrib-serializinghtml 1.1.9; spyder 5.4.3; spyder-kernels 2.4.4; SQLAlchemy 2.0.21; stack-data 0.6.2; statsmodels 0.14.0; stdlib-list 0.8.0; stopit 1.1.2; sympy 1.12; tables 3.9.1; tabulate 0.9.0; TBB 0.2; tblib 2.0.0; tenacity 8.2.3; terminado 0.17.1; text-unidecode 1.3; textdistance 4.5.0; texttable 1.7.0; threadpoolctl 3.2.0; three-merge 0.1.1; throttler 1.2.2; tifffile 2023.4.12; tinycss2 1.2.1; tldextract 3.6.0; tokenizers 0.14.0; toml 0.10.2; tomli 2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:10329,Usability,learn,learn,10329,c3986-validator 0.1.1; rich 13.6.0; rope 1.10.0; rpds-py 0.10.4; Rtree 1.0.1; ruamel.yaml 0.17.35; ruamel.yaml.clib 0.2.7; ruamel-yaml-conda 0.15.80; s3fs 0.5.1; sacremoses 0.0.53; safetensors 0.3.3; scanpy 1.9.5; scikit-image 0.21.0; scikit-learn 1.3.1; scikit-learn-intelex 20230725.122106; scipy 1.11.3; Scrapy 2.11.0; scrublet 0.2.3; scTE 1.0; scTE 1.0; seaborn 0.13.0; SecretStorage 3.3.3; semver 3.0.1; Send2Trash 1.8.2; service-identity 18.1.0; session-info 1.0.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 6.4.0; smmap 5.0.0; snakemake 7.32.3; sniffio 1.3.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.5; Sphinx 7.2.6; sphinxcontrib-applehelp 1.0.7; sphinxcontrib-devhelp 1.0.5; sphinxcontrib-htmlhelp 2.0.4; sphinxcontrib-jsmath 1.0.1; sphinxcontrib-qthelp 1.0.6; sphinxcontrib-serializinghtml 1.1.9; spyder 5.4.3; spyder-kernels 2.4.4; SQLAlchemy 2.0.21; stack-data 0.6.2; statsmodels 0.14.0; stdlib-list 0.8.0; stopit 1.1.2; sympy 1.12; tables 3.9.1; tabulate 0.9.0; TBB 0.2; tblib 2.0.0; tenacity 8.2.3; terminado 0.17.1; text-unidecode 1.3; textdistance 4.5.0; texttable 1.7.0; threadpoolctl 3.2.0; three-merge 0.1.1; throttler 1.2.2; tifffile 2023.4.12; tinycss2 1.2.1; tldextract 3.6.0; tokenizers 0.14.0; toml 0.10.2; tomli 2.0.1; tomlkit 0.12.1; toolz 0.12.0; toposort 1.10; tornado 6.3.3; tqdm 4.66.1; traitlets 5.11.2; transformers 4.34.0; truststore 0.8.0; Twisted 22.10.0; types-python-dateutil 2.8.19.14; typing_extensions 4.8.0; typing-utils 0.1.0; tzdata 2023.3; uc-micro-py 1.0.1; ujson 5.8.0; umap-learn 0.5.4; uri-template 1.3.0; urllib3 1.26.15; virtualenv 20.24.5; w3lib 2.1.2; watchdog 3.0.0; wcwidth 0.2.8; webcolors 1.13; webencodings 0.5.1; websocket-client 1.6.4; Werkzeug 3.0.0; whatthepatch 1.0.5; wheel 0.38.4; widgetsnbextension 4.0.9; wrapt 1.15.0; wurlitzer 3.0.3; xarray 2023.9.0; xxhash 3.4.1; xyzservices 2023.10.0; yapf 0.24.0; yarl 1.9.2; yte 1.5.1; zict 3.0.0; zipp 3.17.0; zope.interface 6.1; zstandard 0.21.0. ```. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2681:1197,Availability,Error,Error,1197,"nal) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`; - Enabled `return_fig`; - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python; import scanpy as sc; import anndata as ad; import pandas as pd; import numpy as np. obs = pd.DataFrame(np.arange(100), ; columns=['a'], ; index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5); adata = ad.AnnData(X=X, obs=obs); sc.tl.pca(adata); sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca; ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]); KeyError: ''; ```. ### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.10.0.dev128+g616d5803; -----; PIL 9.2.0; beta_ufunc NA; binom_ufunc NA; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; h5py 3.7.0; hypergeom_ufunc NA; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.39.1; matplotlib 3.6.2; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.56.3; numpy 1.23.4; packaging 21.3; pandas 1.5.1; pkg_resources NA; pynndescent 0.5.8; pyparsing 3.0.9; pytz 2022.2.1; scipy 1.9.3; session_info 1.0.0; setuptools 65.5.1; six 1.16.0; sklearn 1.1.3; threadpoolctl 3.1.0; typing_extensions NA; zoneinfo NA; -----; Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]; macOS-<redacted>-arm64-arm-64bit; -----; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:2221,Deployability,update,updated,2221,"anpy. ### What happened?. When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`; - Enabled `return_fig`; - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python; import scanpy as sc; import anndata as ad; import pandas as pd; import numpy as np. obs = pd.DataFrame(np.arange(100), ; columns=['a'], ; index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5); adata = ad.AnnData(X=X, obs=obs); sc.tl.pca(adata); sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca; ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]); KeyError: ''; ```. ### Versions. <details>. ```; -----; anndata 0.8.0; scanpy 1.10.0.dev128+g616d5803; -----; PIL 9.2.0; beta_ufunc NA; binom_ufunc NA; colorama 0.4.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; h5py 3.7.0; hypergeom_ufunc NA; joblib 1.2.0; kiwisolver 1.4.4; llvmlite 0.39.1; matplotlib 3.6.2; mpl_toolkits NA; natsort 8.2.0; nbinom_ufunc NA; ncf_ufunc NA; numba 0.56.3; numpy 1.23.4; packaging 21.3; pandas 1.5.1; pkg_resources NA; pynndescent 0.5.8; pyparsing 3.0.9; pytz 2022.2.1; scipy 1.9.3; session_info 1.0.0; setuptools 65.5.1; six 1.16.0; sklearn 1.1.3; threadpoolctl 3.1.0; typing_extensions NA; zoneinfo NA; -----; Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]; macOS-<redacted>-arm64-arm-64bit; -----; Session information updated at 2023-10-11 14:45; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/pull/2682:131,Deployability,integrat,integrate,131,"Checks if current axis is colorbar before trying to set the name, see #2681.; This might not be the best solution and does not yet integrate a unit test. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:131,Integrability,integrat,integrate,131,"Checks if current axis is colorbar before trying to set the name, see #2681.; This might not be the best solution and does not yet integrate a unit test. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:148,Testability,test,test,148,"Checks if current axis is colorbar before trying to set the name, see #2681.; This might not be the best solution and does not yet integrate a unit test. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:225,Usability,guid,guidelines,225,"Checks if current axis is colorbar before trying to set the name, see #2681.; This might not be the best solution and does not yet integrate a unit test. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:256,Usability,guid,guide,256,"Checks if current axis is colorbar before trying to set the name, see #2681.; This might not be the best solution and does not yet integrate a unit test. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2683:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Resolves #1429.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2683
https://github.com/scverse/scanpy/pull/2683:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Resolves #1429.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2683
https://github.com/scverse/scanpy/issues/2685:419,Availability,error,error,419,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python; import numpy as np; import scanpy as sc; import seaborn as sns; from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0; sc.settings.set_figure_params(; dpi=80,; facecolor=""white"",; frameon=False,; ). adata = sc.read_10x_h5(; filename=""filtered_feature_bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546196"",; ). import anndata2ri; import logging. import rpy2.rinterface_lib.callbacks as rcb; import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR); ro.pandas2ri.activate(); anndata2ri.activate(). %load_ext rpy2.ipython. %%R; library(SoupX). adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp); sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp); sc.pp.neighbors(adata_pp); sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX; soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names; genes = adata.var_names; data = adata.X.T. adata_raw = sc.read_10x_h5(; filename=""raw_feature_bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546217"",; ); adata_raw.var_names_make_unique(); data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data; rownames(data) = genes; colnames(data) = cells; # ensure correct sparse format for table of counts and table of droplets; data <- as(data, ""sparseMatrix""); data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX ; sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:949,Availability,ERROR,ERROR,949,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python; import numpy as np; import scanpy as sc; import seaborn as sns; from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0; sc.settings.set_figure_params(; dpi=80,; facecolor=""white"",; frameon=False,; ). adata = sc.read_10x_h5(; filename=""filtered_feature_bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546196"",; ). import anndata2ri; import logging. import rpy2.rinterface_lib.callbacks as rcb; import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR); ro.pandas2ri.activate(); anndata2ri.activate(). %load_ext rpy2.ipython. %%R; library(SoupX). adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp); sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp); sc.pp.neighbors(adata_pp); sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX; soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names; genes = adata.var_names; data = adata.X.T. adata_raw = sc.read_10x_h5(; filename=""raw_feature_bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546217"",; ); adata_raw.var_names_make_unique(); data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data; rownames(data) = genes; colnames(data) = cells; # ensure correct sparse format for table of counts and table of droplets; data <- as(data, ""sparseMatrix""); data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX ; sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:2426,Availability,Error,Error,2426,"bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546217"",; ); adata_raw.var_names_make_unique(); data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data; rownames(data) = genes; colnames(data) = cells; # ensure correct sparse format for table of counts and table of droplets; data <- as(data, ""sparseMatrix""); data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX ; sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object; soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)); sc = setSoupProfile(sc, soupProf); # Set cluster information in SoupChannel; sc = setClusters(sc, soupx_groups). # Estimate contamination fraction; sc = autoEstCont(sc, doPlot=FALSE); # Infer corrected table of counts and rount to integer; out = adjustCounts(sc, roundToInt = TRUE); ```. ### Error output. ```pytb; Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : ; duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.9.5; -----; PIL 10.0.1; anndata2ri 1.2; anyio NA; argcomplete NA; arrow 1.3.0; asttokens NA; attr 23.1.0; babel 2.13.0; backcall 0.2.0; brotli 1.1.0; certifi 2023.07.22; cffi 1.16.0; charset_normalizer 3.3.0; colorama 0.4.6; comm 0.1.4; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; defusedxml 0.7.1; exceptiongroup 1.1.3; executing 1.2.0; fastjsonschema NA; fqdn NA; gmpy2 2.1.2; h5py 3.10.0; idna 3.4; igraph 0.11.2; importlib_resources NA; ipykernel 6.25.2; isoduration NA; jedi 0.19.1; jinja2 3.1.2; joblib 1.3.2; json5 NA; jsonpointer 2.4; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.7.3; jupyterlab_server 2.24.0; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:2449,Availability,Error,Error,2449,"p_url=""https://figshare.com/ndownloader/files/39546217"",; ); adata_raw.var_names_make_unique(); data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data; rownames(data) = genes; colnames(data) = cells; # ensure correct sparse format for table of counts and table of droplets; data <- as(data, ""sparseMatrix""); data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX ; sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object; soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)); sc = setSoupProfile(sc, soupProf); # Set cluster information in SoupChannel; sc = setClusters(sc, soupx_groups). # Estimate contamination fraction; sc = autoEstCont(sc, doPlot=FALSE); # Infer corrected table of counts and rount to integer; out = adjustCounts(sc, roundToInt = TRUE); ```. ### Error output. ```pytb; Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : ; duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.9.5; -----; PIL 10.0.1; anndata2ri 1.2; anyio NA; argcomplete NA; arrow 1.3.0; asttokens NA; attr 23.1.0; babel 2.13.0; backcall 0.2.0; brotli 1.1.0; certifi 2023.07.22; cffi 1.16.0; charset_normalizer 3.3.0; colorama 0.4.6; comm 0.1.4; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; defusedxml 0.7.1; exceptiongroup 1.1.3; executing 1.2.0; fastjsonschema NA; fqdn NA; gmpy2 2.1.2; h5py 3.10.0; idna 3.4; igraph 0.11.2; importlib_resources NA; ipykernel 6.25.2; isoduration NA; jedi 0.19.1; jinja2 3.1.2; joblib 1.3.2; json5 NA; jsonpointer 2.4; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.7.3; jupyterlab_server 2.24.0; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.40.1; markupsafe 2.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:4909,Deployability,update,updated,4909,"ler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; defusedxml 0.7.1; exceptiongroup 1.1.3; executing 1.2.0; fastjsonschema NA; fqdn NA; gmpy2 2.1.2; h5py 3.10.0; idna 3.4; igraph 0.11.2; importlib_resources NA; ipykernel 6.25.2; isoduration NA; jedi 0.19.1; jinja2 3.1.2; joblib 1.3.2; json5 NA; jsonpointer 2.4; jsonschema 4.17.3; jupyter_events 0.6.3; jupyter_server 2.7.3; jupyterlab_server 2.24.0; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.40.1; markupsafe 2.1.3; matplotlib 3.8.0; matplotlib_inline 0.1.6; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; nbformat 5.9.2; numba 0.57.1; numpy 1.24.4; opt_einsum v3.3.0; overrides NA; packaging 23.2; pandas 2.1.1; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.11.0; prometheus_client NA; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.16.1; pynndescent 0.5.10; pyparsing 3.1.1; pyrsistent NA; pythonjsonlogger NA; pytz 2023.3; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; rpy2 3.5.11; scipy 1.11.3; seaborn 0.13.0; send2trash NA; session_info 1.0.0; six 1.16.0; sklearn 1.3.1; sniffio 1.3.0; socks 1.7.1; sparse 0.14.0; stack_data 0.6.2; statsmodels 0.14.0; sympy 1.12; texttable 1.7.0; threadpoolctl 3.2.0; torch 2.0.0; tornado 6.3.3; tqdm 4.66.1; traitlets 5.11.2; typing_extensions NA; tzdata 2023.3; tzlocal NA; umap 0.5.4; uri_template NA; urllib3 2.0.6; wcwidth 0.2.8; webcolors 1.13; websocket 1.6.4; yaml 6.0.1; zipp NA; zmq 25.1.1; zoneinfo NA; -----; IPython 8.16.1; jupyter_client 8.4.0; jupyter_core 5.4.0; jupyterlab 4.0.7; notebook 7.0.5; -----; Python 3.9.18 | packaged by conda-forge | (main, Aug 30 2023, 03:49:32) [GCC 12.3.0]; Linux-3.10.0-1160.95.1.el7.x86_64-x86_64-with-glibc2.17; -----; Session information updated at 2023-10-16 08:14; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:1245,Modifiability,variab,variables,1245,"of scanpy. ### What happened?. Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python; import numpy as np; import scanpy as sc; import seaborn as sns; from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0; sc.settings.set_figure_params(; dpi=80,; facecolor=""white"",; frameon=False,; ). adata = sc.read_10x_h5(; filename=""filtered_feature_bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546196"",; ). import anndata2ri; import logging. import rpy2.rinterface_lib.callbacks as rcb; import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR); ro.pandas2ri.activate(); anndata2ri.activate(). %load_ext rpy2.ipython. %%R; library(SoupX). adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp); sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp); sc.pp.neighbors(adata_pp); sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX; soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names; genes = adata.var_names; data = adata.X.T. adata_raw = sc.read_10x_h5(; filename=""raw_feature_bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546217"",; ); adata_raw.var_names_make_unique(); data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data; rownames(data) = genes; colnames(data) = cells; # ensure correct sparse format for table of counts and table of droplets; data <- as(data, ""sparseMatrix""); data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX ; sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object; soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)); sc = setSoupProfile(sc, soupProf); # Set cluster information in SoupChannel; sc = setClusters(sc, soupx_groups). # Estimate con",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:839,Testability,log,logging,839,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python; import numpy as np; import scanpy as sc; import seaborn as sns; from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0; sc.settings.set_figure_params(; dpi=80,; facecolor=""white"",; frameon=False,; ). adata = sc.read_10x_h5(; filename=""filtered_feature_bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546196"",; ). import anndata2ri; import logging. import rpy2.rinterface_lib.callbacks as rcb; import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR); ro.pandas2ri.activate(); anndata2ri.activate(). %load_ext rpy2.ipython. %%R; library(SoupX). adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp); sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp); sc.pp.neighbors(adata_pp); sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX; soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names; genes = adata.var_names; data = adata.X.T. adata_raw = sc.read_10x_h5(; filename=""raw_feature_bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546217"",; ); adata_raw.var_names_make_unique(); data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data; rownames(data) = genes; colnames(data) = cells; # ensure correct sparse format for table of counts and table of droplets; data <- as(data, ""sparseMatrix""); data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX ; sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:925,Testability,log,logger,925,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python; import numpy as np; import scanpy as sc; import seaborn as sns; from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0; sc.settings.set_figure_params(; dpi=80,; facecolor=""white"",; frameon=False,; ). adata = sc.read_10x_h5(; filename=""filtered_feature_bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546196"",; ). import anndata2ri; import logging. import rpy2.rinterface_lib.callbacks as rcb; import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR); ro.pandas2ri.activate(); anndata2ri.activate(). %load_ext rpy2.ipython. %%R; library(SoupX). adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp); sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp); sc.pp.neighbors(adata_pp); sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX; soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names; genes = adata.var_names; data = adata.X.T. adata_raw = sc.read_10x_h5(; filename=""raw_feature_bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546217"",; ); adata_raw.var_names_make_unique(); data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data; rownames(data) = genes; colnames(data) = cells; # ensure correct sparse format for table of counts and table of droplets; data <- as(data, ""sparseMatrix""); data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX ; sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:941,Testability,log,logging,941,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python; import numpy as np; import scanpy as sc; import seaborn as sns; from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0; sc.settings.set_figure_params(; dpi=80,; facecolor=""white"",; frameon=False,; ). adata = sc.read_10x_h5(; filename=""filtered_feature_bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546196"",; ). import anndata2ri; import logging. import rpy2.rinterface_lib.callbacks as rcb; import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR); ro.pandas2ri.activate(); anndata2ri.activate(). %load_ext rpy2.ipython. %%R; library(SoupX). adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp); sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp); sc.pp.neighbors(adata_pp); sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX; soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names; genes = adata.var_names; data = adata.X.T. adata_raw = sc.read_10x_h5(; filename=""raw_feature_bc_matrix.h5"",; backup_url=""https://figshare.com/ndownloader/files/39546217"",; ); adata_raw.var_names_make_unique(); data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data; rownames(data) = genes; colnames(data) = cells; # ensure correct sparse format for table of counts and table of droplets; data <- as(data, ""sparseMatrix""); data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX ; sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/pull/2687:619,Deployability,release,release,619,"They kept failing. Something upstream (likely numba) or Azures testing machines seem to have become less consistent in calculating this. [This thread](https://github.com/scverse/scanpy/pull/1740#discussion_r596827747) came across that. @ivirshups final statement was. > This bug seems to be based on having nested parallelism and certain reductions. We can avoid it by just not having nested parallelism, which is what I've done for gearys_c. I dont think exact float equality is a reasonable assumption, but if we want to continue to test for it, we need to be able to force numba to be predictable or so. Needs no release note. Added https://github.com/scverse/scanpy/issues/2688 to track this regression",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2687
https://github.com/scverse/scanpy/pull/2687:359,Safety,avoid,avoid,359,"They kept failing. Something upstream (likely numba) or Azures testing machines seem to have become less consistent in calculating this. [This thread](https://github.com/scverse/scanpy/pull/1740#discussion_r596827747) came across that. @ivirshups final statement was. > This bug seems to be based on having nested parallelism and certain reductions. We can avoid it by just not having nested parallelism, which is what I've done for gearys_c. I dont think exact float equality is a reasonable assumption, but if we want to continue to test for it, we need to be able to force numba to be predictable or so. Needs no release note. Added https://github.com/scverse/scanpy/issues/2688 to track this regression",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2687
https://github.com/scverse/scanpy/pull/2687:591,Safety,predict,predictable,591,"They kept failing. Something upstream (likely numba) or Azures testing machines seem to have become less consistent in calculating this. [This thread](https://github.com/scverse/scanpy/pull/1740#discussion_r596827747) came across that. @ivirshups final statement was. > This bug seems to be based on having nested parallelism and certain reductions. We can avoid it by just not having nested parallelism, which is what I've done for gearys_c. I dont think exact float equality is a reasonable assumption, but if we want to continue to test for it, we need to be able to force numba to be predictable or so. Needs no release note. Added https://github.com/scverse/scanpy/issues/2688 to track this regression",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2687
https://github.com/scverse/scanpy/pull/2687:64,Testability,test,testing,64,"They kept failing. Something upstream (likely numba) or Azures testing machines seem to have become less consistent in calculating this. [This thread](https://github.com/scverse/scanpy/pull/1740#discussion_r596827747) came across that. @ivirshups final statement was. > This bug seems to be based on having nested parallelism and certain reductions. We can avoid it by just not having nested parallelism, which is what I've done for gearys_c. I dont think exact float equality is a reasonable assumption, but if we want to continue to test for it, we need to be able to force numba to be predictable or so. Needs no release note. Added https://github.com/scverse/scanpy/issues/2688 to track this regression",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2687
https://github.com/scverse/scanpy/pull/2687:538,Testability,test,test,538,"They kept failing. Something upstream (likely numba) or Azures testing machines seem to have become less consistent in calculating this. [This thread](https://github.com/scverse/scanpy/pull/1740#discussion_r596827747) came across that. @ivirshups final statement was. > This bug seems to be based on having nested parallelism and certain reductions. We can avoid it by just not having nested parallelism, which is what I've done for gearys_c. I dont think exact float equality is a reasonable assumption, but if we want to continue to test for it, we need to be able to force numba to be predictable or so. Needs no release note. Added https://github.com/scverse/scanpy/issues/2688 to track this regression",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2687
https://github.com/scverse/scanpy/issues/2688:796,Availability,Error,Error,796,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Since a few weeks ago (at least), the tests in `test_metrics.py` started failing because the exact equality tests no longer consistently returned the bit-for-bit same float. Something like it has been observed in https://github.com/scverse/scanpy/pull/1740#discussion_r596827747. #2687 disables the exact comparison, but we should figure out why its happening and if we can restore exact precision. ### Minimal code sample. ```console; $ git switch 1.9.5; $ pytest scanpy/tests/test_metrics.py; ```. ### Error output. ```pytb; =================================== FAILURES ===================================; __________________________ test_morans_i_consistency ___________________________. def test_morans_i_consistency():; pbmc = pbmc68k_reduced(); pbmc.layers[""raw""] = pbmc.raw.X.copy(); g = pbmc.obsp[""connectivities""]; ; > assert eq(; sc.metrics.morans_i(g, pbmc.obs[""percent_mito""]),; sc.metrics.morans_i(pbmc, vals=pbmc.obs[""percent_mito""]),; ); E AssertionError: assert False; E + where False = eq(0.13099293222276961, 0.13099293222276967); E + where 0.13099293222276961 = <function morans_i at 0x7f354779d9d0>(<700x700 sparse matrix of type '<class 'numpy.float64'>'\n	with 9992 stored elements in Compressed Sparse Row format>, index\nAAAGCCTGGCTAAC-1 0.023856\nAAATTCGATGCACA-1 0.027458\nAACACGTGGTCTTT-1 0.016819\nAAGTGCACGTGCTA-1 0.011797\nACACGAACGGAGTG-1 0.017277\n ... \nTGGCACCTCCAACA-8 0.008840\nTGTGAGTGCTTTAC-8 0.022068\nTGTTACTGGCGATT-8 0.012821\nTTCAGTACCGGGAA-8 0.014169\nTTGAGGTGGAGAGC-8 0.010886\nName: percent_mito, Length: 700, dtype: float32); E + where <function morans_i at 0x7f354779d9d0> = <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2688
https://github.com/scverse/scanpy/issues/2688:855,Availability,FAILURE,FAILURES,855,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Since a few weeks ago (at least), the tests in `test_metrics.py` started failing because the exact equality tests no longer consistently returned the bit-for-bit same float. Something like it has been observed in https://github.com/scverse/scanpy/pull/1740#discussion_r596827747. #2687 disables the exact comparison, but we should figure out why its happening and if we can restore exact precision. ### Minimal code sample. ```console; $ git switch 1.9.5; $ pytest scanpy/tests/test_metrics.py; ```. ### Error output. ```pytb; =================================== FAILURES ===================================; __________________________ test_morans_i_consistency ___________________________. def test_morans_i_consistency():; pbmc = pbmc68k_reduced(); pbmc.layers[""raw""] = pbmc.raw.X.copy(); g = pbmc.obsp[""connectivities""]; ; > assert eq(; sc.metrics.morans_i(g, pbmc.obs[""percent_mito""]),; sc.metrics.morans_i(pbmc, vals=pbmc.obs[""percent_mito""]),; ); E AssertionError: assert False; E + where False = eq(0.13099293222276961, 0.13099293222276967); E + where 0.13099293222276961 = <function morans_i at 0x7f354779d9d0>(<700x700 sparse matrix of type '<class 'numpy.float64'>'\n	with 9992 stored elements in Compressed Sparse Row format>, index\nAAAGCCTGGCTAAC-1 0.023856\nAAATTCGATGCACA-1 0.027458\nAACACGTGGTCTTT-1 0.016819\nAAGTGCACGTGCTA-1 0.011797\nACACGAACGGAGTG-1 0.017277\n ... \nTGGCACCTCCAACA-8 0.008840\nTGTGAGTGCTTTAC-8 0.022068\nTGTTACTGGCGATT-8 0.012821\nTTCAGTACCGGGAA-8 0.014169\nTTGAGGTGGAGAGC-8 0.010886\nName: percent_mito, Length: 700, dtype: float32); E + where <function morans_i at 0x7f354779d9d0> = <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2688
https://github.com/scverse/scanpy/issues/2688:1048,Modifiability,layers,layers,1048,"e checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Since a few weeks ago (at least), the tests in `test_metrics.py` started failing because the exact equality tests no longer consistently returned the bit-for-bit same float. Something like it has been observed in https://github.com/scverse/scanpy/pull/1740#discussion_r596827747. #2687 disables the exact comparison, but we should figure out why its happening and if we can restore exact precision. ### Minimal code sample. ```console; $ git switch 1.9.5; $ pytest scanpy/tests/test_metrics.py; ```. ### Error output. ```pytb; =================================== FAILURES ===================================; __________________________ test_morans_i_consistency ___________________________. def test_morans_i_consistency():; pbmc = pbmc68k_reduced(); pbmc.layers[""raw""] = pbmc.raw.X.copy(); g = pbmc.obsp[""connectivities""]; ; > assert eq(; sc.metrics.morans_i(g, pbmc.obs[""percent_mito""]),; sc.metrics.morans_i(pbmc, vals=pbmc.obs[""percent_mito""]),; ); E AssertionError: assert False; E + where False = eq(0.13099293222276961, 0.13099293222276967); E + where 0.13099293222276961 = <function morans_i at 0x7f354779d9d0>(<700x700 sparse matrix of type '<class 'numpy.float64'>'\n	with 9992 stored elements in Compressed Sparse Row format>, index\nAAAGCCTGGCTAAC-1 0.023856\nAAATTCGATGCACA-1 0.027458\nAACACGTGGTCTTT-1 0.016819\nAAGTGCACGTGCTA-1 0.011797\nACACGAACGGAGTG-1 0.017277\n ... \nTGGCACCTCCAACA-8 0.008840\nTGTGAGTGCTTTAC-8 0.022068\nTGTTACTGGCGATT-8 0.012821\nTTCAGTACCGGGAA-8 0.014169\nTTGAGGTGGAGAGC-8 0.010886\nName: percent_mito, Length: 700, dtype: float32); E + where <function morans_i at 0x7f354779d9d0> = <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanpy/metrics/__init__.py'>.morans_i; E + wher",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2688
https://github.com/scverse/scanpy/issues/2688:2642,Modifiability,layers,layers,2642,"	with 9992 stored elements in Compressed Sparse Row format>, index\nAAAGCCTGGCTAAC-1 0.023856\nAAATTCGATGCACA-1 0.027458\nAACACGTGGTCTTT-1 0.016819\nAAGTGCACGTGCTA-1 0.011797\nACACGAACGGAGTG-1 0.017277\n ... \nTGGCACCTCCAACA-8 0.008840\nTGTGAGTGCTTTAC-8 0.022068\nTGTTACTGGCGATT-8 0.012821\nTTCAGTACCGGGAA-8 0.014169\nTTGAGGTGGAGAGC-8 0.010886\nName: percent_mito, Length: 700, dtype: float32); E + where <function morans_i at 0x7f354779d9d0> = <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanpy/metrics/__init__.py'>.morans_i; E + where <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanpy/metrics/__init__.py'> = sc.metrics; E + and 0.13099293222276967 = <function morans_i at 0x7f354779d9d0>(AnnData object with n_obs  n_vars = 700  765\n obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'\n var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'\n uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'\n obsm: 'X_pca', 'X_umap'\n varm: 'PCs'\n layers: 'raw'\n obsp: 'distances', 'connectivities', vals=index\nAAAGCCTGGCTAAC-1 0.023856\nAAATTCGATGCACA-1 0.027458\nAACACGTGGTCTTT-1 0.016819\nAAGTGCACGTGCTA-1 0.011797\nACACGAACGGAGTG-1 0.017277\n ... \nTGGCACCTCCAACA-8 0.008840\nTGTGAGTGCTTTAC-8 0.022068\nTGTTACTGGCGATT-8 0.012821\nTTCAGTACCGGGAA-8 0.014169\nTTGAGGTGGAGAGC-8 0.010886\nName: percent_mito, Length: 700, dtype: float32); E + where <function morans_i at 0x7f354779d9d0> = <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanpy/metrics/__init__.py'>.morans_i; E + where <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanpy/metrics/__init__.py'> = sc.metrics. scanpy/tests/test_metrics.py:78: AssertionError; ```. ### Versions. <details>. ```; Package Versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2688
https://github.com/scverse/scanpy/issues/2688:329,Testability,test,tests,329,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Since a few weeks ago (at least), the tests in `test_metrics.py` started failing because the exact equality tests no longer consistently returned the bit-for-bit same float. Something like it has been observed in https://github.com/scverse/scanpy/pull/1740#discussion_r596827747. #2687 disables the exact comparison, but we should figure out why its happening and if we can restore exact precision. ### Minimal code sample. ```console; $ git switch 1.9.5; $ pytest scanpy/tests/test_metrics.py; ```. ### Error output. ```pytb; =================================== FAILURES ===================================; __________________________ test_morans_i_consistency ___________________________. def test_morans_i_consistency():; pbmc = pbmc68k_reduced(); pbmc.layers[""raw""] = pbmc.raw.X.copy(); g = pbmc.obsp[""connectivities""]; ; > assert eq(; sc.metrics.morans_i(g, pbmc.obs[""percent_mito""]),; sc.metrics.morans_i(pbmc, vals=pbmc.obs[""percent_mito""]),; ); E AssertionError: assert False; E + where False = eq(0.13099293222276961, 0.13099293222276967); E + where 0.13099293222276961 = <function morans_i at 0x7f354779d9d0>(<700x700 sparse matrix of type '<class 'numpy.float64'>'\n	with 9992 stored elements in Compressed Sparse Row format>, index\nAAAGCCTGGCTAAC-1 0.023856\nAAATTCGATGCACA-1 0.027458\nAACACGTGGTCTTT-1 0.016819\nAAGTGCACGTGCTA-1 0.011797\nACACGAACGGAGTG-1 0.017277\n ... \nTGGCACCTCCAACA-8 0.008840\nTGTGAGTGCTTTAC-8 0.022068\nTGTTACTGGCGATT-8 0.012821\nTTCAGTACCGGGAA-8 0.014169\nTTGAGGTGGAGAGC-8 0.010886\nName: percent_mito, Length: 700, dtype: float32); E + where <function morans_i at 0x7f354779d9d0> = <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2688
https://github.com/scverse/scanpy/issues/2688:399,Testability,test,tests,399,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Since a few weeks ago (at least), the tests in `test_metrics.py` started failing because the exact equality tests no longer consistently returned the bit-for-bit same float. Something like it has been observed in https://github.com/scverse/scanpy/pull/1740#discussion_r596827747. #2687 disables the exact comparison, but we should figure out why its happening and if we can restore exact precision. ### Minimal code sample. ```console; $ git switch 1.9.5; $ pytest scanpy/tests/test_metrics.py; ```. ### Error output. ```pytb; =================================== FAILURES ===================================; __________________________ test_morans_i_consistency ___________________________. def test_morans_i_consistency():; pbmc = pbmc68k_reduced(); pbmc.layers[""raw""] = pbmc.raw.X.copy(); g = pbmc.obsp[""connectivities""]; ; > assert eq(; sc.metrics.morans_i(g, pbmc.obs[""percent_mito""]),; sc.metrics.morans_i(pbmc, vals=pbmc.obs[""percent_mito""]),; ); E AssertionError: assert False; E + where False = eq(0.13099293222276961, 0.13099293222276967); E + where 0.13099293222276961 = <function morans_i at 0x7f354779d9d0>(<700x700 sparse matrix of type '<class 'numpy.float64'>'\n	with 9992 stored elements in Compressed Sparse Row format>, index\nAAAGCCTGGCTAAC-1 0.023856\nAAATTCGATGCACA-1 0.027458\nAACACGTGGTCTTT-1 0.016819\nAAGTGCACGTGCTA-1 0.011797\nACACGAACGGAGTG-1 0.017277\n ... \nTGGCACCTCCAACA-8 0.008840\nTGTGAGTGCTTTAC-8 0.022068\nTGTTACTGGCGATT-8 0.012821\nTTCAGTACCGGGAA-8 0.014169\nTTGAGGTGGAGAGC-8 0.010886\nName: percent_mito, Length: 700, dtype: float32); E + where <function morans_i at 0x7f354779d9d0> = <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2688
https://github.com/scverse/scanpy/issues/2688:764,Testability,test,tests,764,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Since a few weeks ago (at least), the tests in `test_metrics.py` started failing because the exact equality tests no longer consistently returned the bit-for-bit same float. Something like it has been observed in https://github.com/scverse/scanpy/pull/1740#discussion_r596827747. #2687 disables the exact comparison, but we should figure out why its happening and if we can restore exact precision. ### Minimal code sample. ```console; $ git switch 1.9.5; $ pytest scanpy/tests/test_metrics.py; ```. ### Error output. ```pytb; =================================== FAILURES ===================================; __________________________ test_morans_i_consistency ___________________________. def test_morans_i_consistency():; pbmc = pbmc68k_reduced(); pbmc.layers[""raw""] = pbmc.raw.X.copy(); g = pbmc.obsp[""connectivities""]; ; > assert eq(; sc.metrics.morans_i(g, pbmc.obs[""percent_mito""]),; sc.metrics.morans_i(pbmc, vals=pbmc.obs[""percent_mito""]),; ); E AssertionError: assert False; E + where False = eq(0.13099293222276961, 0.13099293222276967); E + where 0.13099293222276961 = <function morans_i at 0x7f354779d9d0>(<700x700 sparse matrix of type '<class 'numpy.float64'>'\n	with 9992 stored elements in Compressed Sparse Row format>, index\nAAAGCCTGGCTAAC-1 0.023856\nAAATTCGATGCACA-1 0.027458\nAACACGTGGTCTTT-1 0.016819\nAAGTGCACGTGCTA-1 0.011797\nACACGAACGGAGTG-1 0.017277\n ... \nTGGCACCTCCAACA-8 0.008840\nTGTGAGTGCTTTAC-8 0.022068\nTGTTACTGGCGATT-8 0.012821\nTTCAGTACCGGGAA-8 0.014169\nTTGAGGTGGAGAGC-8 0.010886\nName: percent_mito, Length: 700, dtype: float32); E + where <function morans_i at 0x7f354779d9d0> = <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2688
https://github.com/scverse/scanpy/issues/2688:1120,Testability,assert,assert,1120,".; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Since a few weeks ago (at least), the tests in `test_metrics.py` started failing because the exact equality tests no longer consistently returned the bit-for-bit same float. Something like it has been observed in https://github.com/scverse/scanpy/pull/1740#discussion_r596827747. #2687 disables the exact comparison, but we should figure out why its happening and if we can restore exact precision. ### Minimal code sample. ```console; $ git switch 1.9.5; $ pytest scanpy/tests/test_metrics.py; ```. ### Error output. ```pytb; =================================== FAILURES ===================================; __________________________ test_morans_i_consistency ___________________________. def test_morans_i_consistency():; pbmc = pbmc68k_reduced(); pbmc.layers[""raw""] = pbmc.raw.X.copy(); g = pbmc.obsp[""connectivities""]; ; > assert eq(; sc.metrics.morans_i(g, pbmc.obs[""percent_mito""]),; sc.metrics.morans_i(pbmc, vals=pbmc.obs[""percent_mito""]),; ); E AssertionError: assert False; E + where False = eq(0.13099293222276961, 0.13099293222276967); E + where 0.13099293222276961 = <function morans_i at 0x7f354779d9d0>(<700x700 sparse matrix of type '<class 'numpy.float64'>'\n	with 9992 stored elements in Compressed Sparse Row format>, index\nAAAGCCTGGCTAAC-1 0.023856\nAAATTCGATGCACA-1 0.027458\nAACACGTGGTCTTT-1 0.016819\nAAGTGCACGTGCTA-1 0.011797\nACACGAACGGAGTG-1 0.017277\n ... \nTGGCACCTCCAACA-8 0.008840\nTGTGAGTGCTTTAC-8 0.022068\nTGTTACTGGCGATT-8 0.012821\nTTCAGTACCGGGAA-8 0.014169\nTTGAGGTGGAGAGC-8 0.010886\nName: percent_mito, Length: 700, dtype: float32); E + where <function morans_i at 0x7f354779d9d0> = <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanpy/metrics/__init__.py'>.morans_i; E + where <module 'scanpy.metrics' from '/opt/hostedtoolcache/P",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2688
https://github.com/scverse/scanpy/issues/2688:1247,Testability,Assert,AssertionError,1247," of scanpy. ### What happened?. Since a few weeks ago (at least), the tests in `test_metrics.py` started failing because the exact equality tests no longer consistently returned the bit-for-bit same float. Something like it has been observed in https://github.com/scverse/scanpy/pull/1740#discussion_r596827747. #2687 disables the exact comparison, but we should figure out why its happening and if we can restore exact precision. ### Minimal code sample. ```console; $ git switch 1.9.5; $ pytest scanpy/tests/test_metrics.py; ```. ### Error output. ```pytb; =================================== FAILURES ===================================; __________________________ test_morans_i_consistency ___________________________. def test_morans_i_consistency():; pbmc = pbmc68k_reduced(); pbmc.layers[""raw""] = pbmc.raw.X.copy(); g = pbmc.obsp[""connectivities""]; ; > assert eq(; sc.metrics.morans_i(g, pbmc.obs[""percent_mito""]),; sc.metrics.morans_i(pbmc, vals=pbmc.obs[""percent_mito""]),; ); E AssertionError: assert False; E + where False = eq(0.13099293222276961, 0.13099293222276967); E + where 0.13099293222276961 = <function morans_i at 0x7f354779d9d0>(<700x700 sparse matrix of type '<class 'numpy.float64'>'\n	with 9992 stored elements in Compressed Sparse Row format>, index\nAAAGCCTGGCTAAC-1 0.023856\nAAATTCGATGCACA-1 0.027458\nAACACGTGGTCTTT-1 0.016819\nAAGTGCACGTGCTA-1 0.011797\nACACGAACGGAGTG-1 0.017277\n ... \nTGGCACCTCCAACA-8 0.008840\nTGTGAGTGCTTTAC-8 0.022068\nTGTTACTGGCGATT-8 0.012821\nTTCAGTACCGGGAA-8 0.014169\nTTGAGGTGGAGAGC-8 0.010886\nName: percent_mito, Length: 700, dtype: float32); E + where <function morans_i at 0x7f354779d9d0> = <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanpy/metrics/__init__.py'>.morans_i; E + where <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanpy/metrics/__init__.py'> = sc.metrics; E + and 0.13099293222276967 = <function morans_i at 0x7f35",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2688
https://github.com/scverse/scanpy/issues/2688:1263,Testability,assert,assert,1263," of scanpy. ### What happened?. Since a few weeks ago (at least), the tests in `test_metrics.py` started failing because the exact equality tests no longer consistently returned the bit-for-bit same float. Something like it has been observed in https://github.com/scverse/scanpy/pull/1740#discussion_r596827747. #2687 disables the exact comparison, but we should figure out why its happening and if we can restore exact precision. ### Minimal code sample. ```console; $ git switch 1.9.5; $ pytest scanpy/tests/test_metrics.py; ```. ### Error output. ```pytb; =================================== FAILURES ===================================; __________________________ test_morans_i_consistency ___________________________. def test_morans_i_consistency():; pbmc = pbmc68k_reduced(); pbmc.layers[""raw""] = pbmc.raw.X.copy(); g = pbmc.obsp[""connectivities""]; ; > assert eq(; sc.metrics.morans_i(g, pbmc.obs[""percent_mito""]),; sc.metrics.morans_i(pbmc, vals=pbmc.obs[""percent_mito""]),; ); E AssertionError: assert False; E + where False = eq(0.13099293222276961, 0.13099293222276967); E + where 0.13099293222276961 = <function morans_i at 0x7f354779d9d0>(<700x700 sparse matrix of type '<class 'numpy.float64'>'\n	with 9992 stored elements in Compressed Sparse Row format>, index\nAAAGCCTGGCTAAC-1 0.023856\nAAATTCGATGCACA-1 0.027458\nAACACGTGGTCTTT-1 0.016819\nAAGTGCACGTGCTA-1 0.011797\nACACGAACGGAGTG-1 0.017277\n ... \nTGGCACCTCCAACA-8 0.008840\nTGTGAGTGCTTTAC-8 0.022068\nTGTTACTGGCGATT-8 0.012821\nTTCAGTACCGGGAA-8 0.014169\nTTGAGGTGGAGAGC-8 0.010886\nName: percent_mito, Length: 700, dtype: float32); E + where <function morans_i at 0x7f354779d9d0> = <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanpy/metrics/__init__.py'>.morans_i; E + where <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanpy/metrics/__init__.py'> = sc.metrics; E + and 0.13099293222276967 = <function morans_i at 0x7f35",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2688
https://github.com/scverse/scanpy/issues/2688:3379,Testability,test,tests,3379,"re', 'G2M_score', 'phase', 'louvain'\n var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'\n uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'\n obsm: 'X_pca', 'X_umap'\n varm: 'PCs'\n layers: 'raw'\n obsp: 'distances', 'connectivities', vals=index\nAAAGCCTGGCTAAC-1 0.023856\nAAATTCGATGCACA-1 0.027458\nAACACGTGGTCTTT-1 0.016819\nAAGTGCACGTGCTA-1 0.011797\nACACGAACGGAGTG-1 0.017277\n ... \nTGGCACCTCCAACA-8 0.008840\nTGTGAGTGCTTTAC-8 0.022068\nTGTTACTGGCGATT-8 0.012821\nTTCAGTACCGGGAA-8 0.014169\nTTGAGGTGGAGAGC-8 0.010886\nName: percent_mito, Length: 700, dtype: float32); E + where <function morans_i at 0x7f354779d9d0> = <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanpy/metrics/__init__.py'>.morans_i; E + where <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanpy/metrics/__init__.py'> = sc.metrics. scanpy/tests/test_metrics.py:78: AssertionError; ```. ### Versions. <details>. ```; Package Version; ------------------- --------------------; anndata 0.10.2; array-api-compat 1.4; docutils 0.20.1; exceptiongroup 1.1.3; fonttools 4.43.1; h5py 3.10.0; importlib-resources 6.1.0; iniconfig 2.0.0; joblib 1.3.2; kiwisolver 1.4.5; llvmlite 0.41.0; matplotlib 3.8.0; mypy-extensions 1.0.0; natsort 8.4.0; networkx 3.1; numba 0.58.0; numpy 1.25.2; packaging 23.2; pandas 2.1.1; pathspec 0.11.2; patsy 0.5.3; pbr 5.11.1; Pillow 10.1.0; pip 23.2.1; platformdirs 3.11.0; pluggy 1.3.0; profimp 0.1.0; pynndescent 0.5.10; pyparsing 3.1.1; pytest 7.4.2; pytest-nunit 1.0.4; python-dateutil 2.8.2; pytz 2023.3.post1; scanpy 1.9.6.dev4+g6c7dd46e; scikit-learn 1.3.1; scipy 1.11.3; seaborn 0.12.2; session-info 1.0.0; setuptools 58.1.0; setuptools-scm 8.0.4; six 1.16.0; statsmodels 0.14.0; stdlib-list 0.9.0; tbb 2021.10.0; threadpoolctl 3.2.0; tomli 2.0.1; tqdm 4.66.1; typing_extensions 4.8.0; tzdata 2023.3; umap-learn 0.5.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2688
https://github.com/scverse/scanpy/issues/2688:3405,Testability,Assert,AssertionError,3405,"'louvain'\n var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'\n uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'\n obsm: 'X_pca', 'X_umap'\n varm: 'PCs'\n layers: 'raw'\n obsp: 'distances', 'connectivities', vals=index\nAAAGCCTGGCTAAC-1 0.023856\nAAATTCGATGCACA-1 0.027458\nAACACGTGGTCTTT-1 0.016819\nAAGTGCACGTGCTA-1 0.011797\nACACGAACGGAGTG-1 0.017277\n ... \nTGGCACCTCCAACA-8 0.008840\nTGTGAGTGCTTTAC-8 0.022068\nTGTTACTGGCGATT-8 0.012821\nTTCAGTACCGGGAA-8 0.014169\nTTGAGGTGGAGAGC-8 0.010886\nName: percent_mito, Length: 700, dtype: float32); E + where <function morans_i at 0x7f354779d9d0> = <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanpy/metrics/__init__.py'>.morans_i; E + where <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanpy/metrics/__init__.py'> = sc.metrics. scanpy/tests/test_metrics.py:78: AssertionError; ```. ### Versions. <details>. ```; Package Version; ------------------- --------------------; anndata 0.10.2; array-api-compat 1.4; docutils 0.20.1; exceptiongroup 1.1.3; fonttools 4.43.1; h5py 3.10.0; importlib-resources 6.1.0; iniconfig 2.0.0; joblib 1.3.2; kiwisolver 1.4.5; llvmlite 0.41.0; matplotlib 3.8.0; mypy-extensions 1.0.0; natsort 8.4.0; networkx 3.1; numba 0.58.0; numpy 1.25.2; packaging 23.2; pandas 2.1.1; pathspec 0.11.2; patsy 0.5.3; pbr 5.11.1; Pillow 10.1.0; pip 23.2.1; platformdirs 3.11.0; pluggy 1.3.0; profimp 0.1.0; pynndescent 0.5.10; pyparsing 3.1.1; pytest 7.4.2; pytest-nunit 1.0.4; python-dateutil 2.8.2; pytz 2023.3.post1; scanpy 1.9.6.dev4+g6c7dd46e; scikit-learn 1.3.1; scipy 1.11.3; seaborn 0.12.2; session-info 1.0.0; setuptools 58.1.0; setuptools-scm 8.0.4; six 1.16.0; statsmodels 0.14.0; stdlib-list 0.9.0; tbb 2021.10.0; threadpoolctl 3.2.0; tomli 2.0.1; tqdm 4.66.1; typing_extensions 4.8.0; tzdata 2023.3; umap-learn 0.5.4; wheel 0.41.2; zipp 3.17.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2688
https://github.com/scverse/scanpy/issues/2688:4112,Usability,learn,learn,4112,"n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'\n uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'\n obsm: 'X_pca', 'X_umap'\n varm: 'PCs'\n layers: 'raw'\n obsp: 'distances', 'connectivities', vals=index\nAAAGCCTGGCTAAC-1 0.023856\nAAATTCGATGCACA-1 0.027458\nAACACGTGGTCTTT-1 0.016819\nAAGTGCACGTGCTA-1 0.011797\nACACGAACGGAGTG-1 0.017277\n ... \nTGGCACCTCCAACA-8 0.008840\nTGTGAGTGCTTTAC-8 0.022068\nTGTTACTGGCGATT-8 0.012821\nTTCAGTACCGGGAA-8 0.014169\nTTGAGGTGGAGAGC-8 0.010886\nName: percent_mito, Length: 700, dtype: float32); E + where <function morans_i at 0x7f354779d9d0> = <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanpy/metrics/__init__.py'>.morans_i; E + where <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanpy/metrics/__init__.py'> = sc.metrics. scanpy/tests/test_metrics.py:78: AssertionError; ```. ### Versions. <details>. ```; Package Version; ------------------- --------------------; anndata 0.10.2; array-api-compat 1.4; docutils 0.20.1; exceptiongroup 1.1.3; fonttools 4.43.1; h5py 3.10.0; importlib-resources 6.1.0; iniconfig 2.0.0; joblib 1.3.2; kiwisolver 1.4.5; llvmlite 0.41.0; matplotlib 3.8.0; mypy-extensions 1.0.0; natsort 8.4.0; networkx 3.1; numba 0.58.0; numpy 1.25.2; packaging 23.2; pandas 2.1.1; pathspec 0.11.2; patsy 0.5.3; pbr 5.11.1; Pillow 10.1.0; pip 23.2.1; platformdirs 3.11.0; pluggy 1.3.0; profimp 0.1.0; pynndescent 0.5.10; pyparsing 3.1.1; pytest 7.4.2; pytest-nunit 1.0.4; python-dateutil 2.8.2; pytz 2023.3.post1; scanpy 1.9.6.dev4+g6c7dd46e; scikit-learn 1.3.1; scipy 1.11.3; seaborn 0.12.2; session-info 1.0.0; setuptools 58.1.0; setuptools-scm 8.0.4; six 1.16.0; statsmodels 0.14.0; stdlib-list 0.9.0; tbb 2021.10.0; threadpoolctl 3.2.0; tomli 2.0.1; tqdm 4.66.1; typing_extensions 4.8.0; tzdata 2023.3; umap-learn 0.5.4; wheel 0.41.2; zipp 3.17.0; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2688
https://github.com/scverse/scanpy/issues/2688:4374,Usability,learn,learn,4374,"n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'\n uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'\n obsm: 'X_pca', 'X_umap'\n varm: 'PCs'\n layers: 'raw'\n obsp: 'distances', 'connectivities', vals=index\nAAAGCCTGGCTAAC-1 0.023856\nAAATTCGATGCACA-1 0.027458\nAACACGTGGTCTTT-1 0.016819\nAAGTGCACGTGCTA-1 0.011797\nACACGAACGGAGTG-1 0.017277\n ... \nTGGCACCTCCAACA-8 0.008840\nTGTGAGTGCTTTAC-8 0.022068\nTGTTACTGGCGATT-8 0.012821\nTTCAGTACCGGGAA-8 0.014169\nTTGAGGTGGAGAGC-8 0.010886\nName: percent_mito, Length: 700, dtype: float32); E + where <function morans_i at 0x7f354779d9d0> = <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanpy/metrics/__init__.py'>.morans_i; E + where <module 'scanpy.metrics' from '/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/scanpy/metrics/__init__.py'> = sc.metrics. scanpy/tests/test_metrics.py:78: AssertionError; ```. ### Versions. <details>. ```; Package Version; ------------------- --------------------; anndata 0.10.2; array-api-compat 1.4; docutils 0.20.1; exceptiongroup 1.1.3; fonttools 4.43.1; h5py 3.10.0; importlib-resources 6.1.0; iniconfig 2.0.0; joblib 1.3.2; kiwisolver 1.4.5; llvmlite 0.41.0; matplotlib 3.8.0; mypy-extensions 1.0.0; natsort 8.4.0; networkx 3.1; numba 0.58.0; numpy 1.25.2; packaging 23.2; pandas 2.1.1; pathspec 0.11.2; patsy 0.5.3; pbr 5.11.1; Pillow 10.1.0; pip 23.2.1; platformdirs 3.11.0; pluggy 1.3.0; profimp 0.1.0; pynndescent 0.5.10; pyparsing 3.1.1; pytest 7.4.2; pytest-nunit 1.0.4; python-dateutil 2.8.2; pytz 2023.3.post1; scanpy 1.9.6.dev4+g6c7dd46e; scikit-learn 1.3.1; scipy 1.11.3; seaborn 0.12.2; session-info 1.0.0; setuptools 58.1.0; setuptools-scm 8.0.4; six 1.16.0; statsmodels 0.14.0; stdlib-list 0.9.0; tbb 2021.10.0; threadpoolctl 3.2.0; tomli 2.0.1; tqdm 4.66.1; typing_extensions 4.8.0; tzdata 2023.3; umap-learn 0.5.4; wheel 0.41.2; zipp 3.17.0; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2688
https://github.com/scverse/scanpy/pull/2689:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2689
https://github.com/scverse/scanpy/pull/2689:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2689
https://github.com/scverse/scanpy/pull/2691:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2691
https://github.com/scverse/scanpy/pull/2691:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2691
https://github.com/scverse/scanpy/pull/2692:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2692
https://github.com/scverse/scanpy/pull/2692:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2692
https://github.com/scverse/scanpy/pull/2693:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2693
https://github.com/scverse/scanpy/pull/2693:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2693
https://github.com/scverse/scanpy/pull/2694:133,Usability,guid,guidelines,133,This reverts commit 02a0f7ba1ae71d94f7ca8e1e04efec248881c746. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2694
https://github.com/scverse/scanpy/pull/2694:164,Usability,guid,guide,164,This reverts commit 02a0f7ba1ae71d94f7ca8e1e04efec248881c746. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2694
https://github.com/scverse/scanpy/pull/2698:415,Testability,test,tests,415,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Fixes #2668. `sc.pp.highly_variable_genes(adata, flavor='seurat')` modified the used `layer` in some cases, as described in #2668. This PR fixes this behaviour, and adds additional tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2698
https://github.com/scverse/scanpy/pull/2698:71,Usability,guid,guidelines,71,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Fixes #2668. `sc.pp.highly_variable_genes(adata, flavor='seurat')` modified the used `layer` in some cases, as described in #2668. This PR fixes this behaviour, and adds additional tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2698
https://github.com/scverse/scanpy/pull/2698:102,Usability,guid,guide,102,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Fixes #2668. `sc.pp.highly_variable_genes(adata, flavor='seurat')` modified the used `layer` in some cases, as described in #2668. This PR fixes this behaviour, and adds additional tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2698
https://github.com/scverse/scanpy/pull/2699:33,Deployability,release,release,33,Backport PR #2569: Add check for release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2699
https://github.com/scverse/scanpy/pull/2701:418,Deployability,release,release,418,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Tests included or not required because: it's formating; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: it's formatting. Why did we ever configure black?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2701
https://github.com/scverse/scanpy/pull/2701:443,Deployability,Release,Release,443,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Tests included or not required because: it's formating; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: it's formatting. Why did we ever configure black?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2701
https://github.com/scverse/scanpy/pull/2701:513,Modifiability,config,configure,513,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Tests included or not required because: it's formating; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: it's formatting. Why did we ever configure black?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2701
https://github.com/scverse/scanpy/pull/2701:305,Testability,Test,Tests,305,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Tests included or not required because: it's formating; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: it's formatting. Why did we ever configure black?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2701
https://github.com/scverse/scanpy/pull/2701:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Tests included or not required because: it's formating; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: it's formatting. Why did we ever configure black?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2701
https://github.com/scverse/scanpy/pull/2701:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Tests included or not required because: it's formating; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: it's formatting. Why did we ever configure black?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2701
https://github.com/scverse/scanpy/pull/2702:1113,Availability,error,error,1113,"Part of [scanpy 2.0](https://github.com/orgs/scverse/projects/18/views/1). <!-- Please check (- [x]) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. I implemented a Ruff check (PLR0917) for this, but setting `max-positional-args = 3` would make this massive PR even larger, so I opted to do it in a separate one. ## Reviewers. Your main job is to check if the position of the `*` makes sense for each exported function (i.e. the ones with the `@legacy_api` decorator). I tried my best to base it on internal usage of each API, but one placement or the other might be to early. The only real logic changes are in `scanpy/tests/test_package_structure.py`. This PR:. - makes public APIs with more than 5 parameters keyword-only without breaking backwards compatibility (for now); - makes private APIs with more than 5 parameters keyword-only; - checks that we dont internally use the old positional APIs using a warning filter with `action='error'`; - checks that APIs use our convention for the `copy` parameter (`adata` as first param, returns `adata` type or None`); - manually checked that APIs use our convention `filename: Path | str`/`path: Path | str`. ## Follow-up changes. - [ ] Set `max-positional-args = 3`; - [ ] make sure that no new public API gets introduced without being included in the `api_module_names` list; - [ ] enforce convention `show`, `return_fig`, `ax`; - [ ] enforce convention for `random_seed: AnyRandom`; - [ ] https://github.com/scverse/scanpy/issues/2331",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2702
https://github.com/scverse/scanpy/pull/2702:260,Deployability,release,release,260,"Part of [scanpy 2.0](https://github.com/orgs/scverse/projects/18/views/1). <!-- Please check (- [x]) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. I implemented a Ruff check (PLR0917) for this, but setting `max-positional-args = 3` would make this massive PR even larger, so I opted to do it in a separate one. ## Reviewers. Your main job is to check if the position of the `*` makes sense for each exported function (i.e. the ones with the `@legacy_api` decorator). I tried my best to base it on internal usage of each API, but one placement or the other might be to early. The only real logic changes are in `scanpy/tests/test_package_structure.py`. This PR:. - makes public APIs with more than 5 parameters keyword-only without breaking backwards compatibility (for now); - makes private APIs with more than 5 parameters keyword-only; - checks that we dont internally use the old positional APIs using a warning filter with `action='error'`; - checks that APIs use our convention for the `copy` parameter (`adata` as first param, returns `adata` type or None`); - manually checked that APIs use our convention `filename: Path | str`/`path: Path | str`. ## Follow-up changes. - [ ] Set `max-positional-args = 3`; - [ ] make sure that no new public API gets introduced without being included in the `api_module_names` list; - [ ] enforce convention `show`, `return_fig`, `ax`; - [ ] enforce convention for `random_seed: AnyRandom`; - [ ] https://github.com/scverse/scanpy/issues/2331",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2702
https://github.com/scverse/scanpy/pull/2702:285,Deployability,Release,Release,285,"Part of [scanpy 2.0](https://github.com/orgs/scverse/projects/18/views/1). <!-- Please check (- [x]) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. I implemented a Ruff check (PLR0917) for this, but setting `max-positional-args = 3` would make this massive PR even larger, so I opted to do it in a separate one. ## Reviewers. Your main job is to check if the position of the `*` makes sense for each exported function (i.e. the ones with the `@legacy_api` decorator). I tried my best to base it on internal usage of each API, but one placement or the other might be to early. The only real logic changes are in `scanpy/tests/test_package_structure.py`. This PR:. - makes public APIs with more than 5 parameters keyword-only without breaking backwards compatibility (for now); - makes private APIs with more than 5 parameters keyword-only; - checks that we dont internally use the old positional APIs using a warning filter with `action='error'`; - checks that APIs use our convention for the `copy` parameter (`adata` as first param, returns `adata` type or None`); - manually checked that APIs use our convention `filename: Path | str`/`path: Path | str`. ## Follow-up changes. - [ ] Set `max-positional-args = 3`; - [ ] make sure that no new public API gets introduced without being included in the `api_module_names` list; - [ ] enforce convention `show`, `return_fig`, `ax`; - [ ] enforce convention for `random_seed: AnyRandom`; - [ ] https://github.com/scverse/scanpy/issues/2331",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2702
https://github.com/scverse/scanpy/pull/2702:162,Testability,Test,Tests,162,"Part of [scanpy 2.0](https://github.com/orgs/scverse/projects/18/views/1). <!-- Please check (- [x]) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. I implemented a Ruff check (PLR0917) for this, but setting `max-positional-args = 3` would make this massive PR even larger, so I opted to do it in a separate one. ## Reviewers. Your main job is to check if the position of the `*` makes sense for each exported function (i.e. the ones with the `@legacy_api` decorator). I tried my best to base it on internal usage of each API, but one placement or the other might be to early. The only real logic changes are in `scanpy/tests/test_package_structure.py`. This PR:. - makes public APIs with more than 5 parameters keyword-only without breaking backwards compatibility (for now); - makes private APIs with more than 5 parameters keyword-only; - checks that we dont internally use the old positional APIs using a warning filter with `action='error'`; - checks that APIs use our convention for the `copy` parameter (`adata` as first param, returns `adata` type or None`); - manually checked that APIs use our convention `filename: Path | str`/`path: Path | str`. ## Follow-up changes. - [ ] Set `max-positional-args = 3`; - [ ] make sure that no new public API gets introduced without being included in the `api_module_names` list; - [ ] enforce convention `show`, `return_fig`, `ax`; - [ ] enforce convention for `random_seed: AnyRandom`; - [ ] https://github.com/scverse/scanpy/issues/2331",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2702
https://github.com/scverse/scanpy/pull/2702:765,Testability,log,logic,765,"Part of [scanpy 2.0](https://github.com/orgs/scverse/projects/18/views/1). <!-- Please check (- [x]) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. I implemented a Ruff check (PLR0917) for this, but setting `max-positional-args = 3` would make this massive PR even larger, so I opted to do it in a separate one. ## Reviewers. Your main job is to check if the position of the `*` makes sense for each exported function (i.e. the ones with the `@legacy_api` decorator). I tried my best to base it on internal usage of each API, but one placement or the other might be to early. The only real logic changes are in `scanpy/tests/test_package_structure.py`. This PR:. - makes public APIs with more than 5 parameters keyword-only without breaking backwards compatibility (for now); - makes private APIs with more than 5 parameters keyword-only; - checks that we dont internally use the old positional APIs using a warning filter with `action='error'`; - checks that APIs use our convention for the `copy` parameter (`adata` as first param, returns `adata` type or None`); - manually checked that APIs use our convention `filename: Path | str`/`path: Path | str`. ## Follow-up changes. - [ ] Set `max-positional-args = 3`; - [ ] make sure that no new public API gets introduced without being included in the `api_module_names` list; - [ ] enforce convention `show`, `return_fig`, `ax`; - [ ] enforce convention for `random_seed: AnyRandom`; - [ ] https://github.com/scverse/scanpy/issues/2331",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2702
https://github.com/scverse/scanpy/pull/2702:794,Testability,test,tests,794,"Part of [scanpy 2.0](https://github.com/orgs/scverse/projects/18/views/1). <!-- Please check (- [x]) and fill in the following boxes -->; - [ ] Closes #; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. I implemented a Ruff check (PLR0917) for this, but setting `max-positional-args = 3` would make this massive PR even larger, so I opted to do it in a separate one. ## Reviewers. Your main job is to check if the position of the `*` makes sense for each exported function (i.e. the ones with the `@legacy_api` decorator). I tried my best to base it on internal usage of each API, but one placement or the other might be to early. The only real logic changes are in `scanpy/tests/test_package_structure.py`. This PR:. - makes public APIs with more than 5 parameters keyword-only without breaking backwards compatibility (for now); - makes private APIs with more than 5 parameters keyword-only; - checks that we dont internally use the old positional APIs using a warning filter with `action='error'`; - checks that APIs use our convention for the `copy` parameter (`adata` as first param, returns `adata` type or None`); - manually checked that APIs use our convention `filename: Path | str`/`path: Path | str`. ## Follow-up changes. - [ ] Set `max-positional-args = 3`; - [ ] make sure that no new public API gets introduced without being included in the `api_module_names` list; - [ ] enforce convention `show`, `return_fig`, `ax`; - [ ] enforce convention for `random_seed: AnyRandom`; - [ ] https://github.com/scverse/scanpy/issues/2331",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2702
https://github.com/scverse/scanpy/pull/2703:422,Deployability,release,release,422,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #173; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Docs:; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/release-notes/index.html#version-1-10; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet_simulate_doublets.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pl.scrublet_score_distribution.html. ### How to review this PR. I made tests quantitative before this PR, so note that the only change that modified tests is 42143d88a0d499130fac8e5ca60eef0c19163734. In that PR, I make it so there are no longer any duplicate simulated doublets being created. This is necessary to be able to support any neighborhood detection algorithm. I also feel like it makes more sense. This is the only algorithmic change to upstream. Please use your own judgement to check if this makes sense to you. ### TODO:. - [x] remove unused utils (plotting, preprocessing); - [ ] figure out what remaining utils to replace with ours; - [x] PCA/SVD: https://github.com/scverse/scanpy/blob/bf5f1f9343f5729df6f90f7c68363682022e0480/scanpy/preprocessing/_scrublet/__init__.py#L415-L417; - [x] mean_center, normalize_variance, zscore: small enough to be left alone I think; - [ ] get_knn_graph: no need to have multiple implementations here, but our current implementation automatically calculates connectivities, which this doesnt need https://github.com/scverse/scanpy/pull/2723; - [ ] refactor so the class API ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2703
https://github.com/scverse/scanpy/pull/2703:447,Deployability,Release,Release,447,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #173; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Docs:; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/release-notes/index.html#version-1-10; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet_simulate_doublets.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pl.scrublet_score_distribution.html. ### How to review this PR. I made tests quantitative before this PR, so note that the only change that modified tests is 42143d88a0d499130fac8e5ca60eef0c19163734. In that PR, I make it so there are no longer any duplicate simulated doublets being created. This is necessary to be able to support any neighborhood detection algorithm. I also feel like it makes more sense. This is the only algorithmic change to upstream. Please use your own judgement to check if this makes sense to you. ### TODO:. - [x] remove unused utils (plotting, preprocessing); - [ ] figure out what remaining utils to replace with ours; - [x] PCA/SVD: https://github.com/scverse/scanpy/blob/bf5f1f9343f5729df6f90f7c68363682022e0480/scanpy/preprocessing/_scrublet/__init__.py#L415-L417; - [x] mean_center, normalize_variance, zscore: small enough to be left alone I think; - [ ] get_knn_graph: no need to have multiple implementations here, but our current implementation automatically calculates connectivities, which this doesnt need https://github.com/scverse/scanpy/pull/2723; - [ ] refactor so the class API ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2703
https://github.com/scverse/scanpy/pull/2703:549,Deployability,release,release-notes,549,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #173; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Docs:; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/release-notes/index.html#version-1-10; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet_simulate_doublets.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pl.scrublet_score_distribution.html. ### How to review this PR. I made tests quantitative before this PR, so note that the only change that modified tests is 42143d88a0d499130fac8e5ca60eef0c19163734. In that PR, I make it so there are no longer any duplicate simulated doublets being created. This is necessary to be able to support any neighborhood detection algorithm. I also feel like it makes more sense. This is the only algorithmic change to upstream. Please use your own judgement to check if this makes sense to you. ### TODO:. - [x] remove unused utils (plotting, preprocessing); - [ ] figure out what remaining utils to replace with ours; - [x] PCA/SVD: https://github.com/scverse/scanpy/blob/bf5f1f9343f5729df6f90f7c68363682022e0480/scanpy/preprocessing/_scrublet/__init__.py#L415-L417; - [x] mean_center, normalize_variance, zscore: small enough to be left alone I think; - [ ] get_knn_graph: no need to have multiple implementations here, but our current implementation automatically calculates connectivities, which this doesnt need https://github.com/scverse/scanpy/pull/2723; - [ ] refactor so the class API ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2703
https://github.com/scverse/scanpy/pull/2703:1975,Modifiability,refactor,refactor,1975,"ize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #173; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Docs:; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/release-notes/index.html#version-1-10; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet_simulate_doublets.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pl.scrublet_score_distribution.html. ### How to review this PR. I made tests quantitative before this PR, so note that the only change that modified tests is 42143d88a0d499130fac8e5ca60eef0c19163734. In that PR, I make it so there are no longer any duplicate simulated doublets being created. This is necessary to be able to support any neighborhood detection algorithm. I also feel like it makes more sense. This is the only algorithmic change to upstream. Please use your own judgement to check if this makes sense to you. ### TODO:. - [x] remove unused utils (plotting, preprocessing); - [ ] figure out what remaining utils to replace with ours; - [x] PCA/SVD: https://github.com/scverse/scanpy/blob/bf5f1f9343f5729df6f90f7c68363682022e0480/scanpy/preprocessing/_scrublet/__init__.py#L415-L417; - [x] mean_center, normalize_variance, zscore: small enough to be left alone I think; - [ ] get_knn_graph: no need to have multiple implementations here, but our current implementation automatically calculates connectivities, which this doesnt need https://github.com/scverse/scanpy/pull/2723; - [ ] refactor so the class API matches the way we use it ; - [x] switch to dataclass for centralized attr defs; - [x] use non-deprecated random state style; - [x] use our logging instead of print statements",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2703
https://github.com/scverse/scanpy/pull/2703:1226,Safety,detect,detection,1226,"ize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #173; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Docs:; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/release-notes/index.html#version-1-10; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet_simulate_doublets.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pl.scrublet_score_distribution.html. ### How to review this PR. I made tests quantitative before this PR, so note that the only change that modified tests is 42143d88a0d499130fac8e5ca60eef0c19163734. In that PR, I make it so there are no longer any duplicate simulated doublets being created. This is necessary to be able to support any neighborhood detection algorithm. I also feel like it makes more sense. This is the only algorithmic change to upstream. Please use your own judgement to check if this makes sense to you. ### TODO:. - [x] remove unused utils (plotting, preprocessing); - [ ] figure out what remaining utils to replace with ours; - [x] PCA/SVD: https://github.com/scverse/scanpy/blob/bf5f1f9343f5729df6f90f7c68363682022e0480/scanpy/preprocessing/_scrublet/__init__.py#L415-L417; - [x] mean_center, normalize_variance, zscore: small enough to be left alone I think; - [ ] get_knn_graph: no need to have multiple implementations here, but our current implementation automatically calculates connectivities, which this doesnt need https://github.com/scverse/scanpy/pull/2723; - [ ] refactor so the class API matches the way we use it ; - [x] switch to dataclass for centralized attr defs; - [x] use non-deprecated random state style; - [x] use our logging instead of print statements",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2703
https://github.com/scverse/scanpy/pull/2703:324,Testability,Test,Tests,324,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #173; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Docs:; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/release-notes/index.html#version-1-10; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet_simulate_doublets.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pl.scrublet_score_distribution.html. ### How to review this PR. I made tests quantitative before this PR, so note that the only change that modified tests is 42143d88a0d499130fac8e5ca60eef0c19163734. In that PR, I make it so there are no longer any duplicate simulated doublets being created. This is necessary to be able to support any neighborhood detection algorithm. I also feel like it makes more sense. This is the only algorithmic change to upstream. Please use your own judgement to check if this makes sense to you. ### TODO:. - [x] remove unused utils (plotting, preprocessing); - [ ] figure out what remaining utils to replace with ours; - [x] PCA/SVD: https://github.com/scverse/scanpy/blob/bf5f1f9343f5729df6f90f7c68363682022e0480/scanpy/preprocessing/_scrublet/__init__.py#L415-L417; - [x] mean_center, normalize_variance, zscore: small enough to be left alone I think; - [ ] get_knn_graph: no need to have multiple implementations here, but our current implementation automatically calculates connectivities, which this doesnt need https://github.com/scverse/scanpy/pull/2723; - [ ] refactor so the class API ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2703
https://github.com/scverse/scanpy/pull/2703:947,Testability,test,tests,947,"hanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #173; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Docs:; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/release-notes/index.html#version-1-10; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet_simulate_doublets.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pl.scrublet_score_distribution.html. ### How to review this PR. I made tests quantitative before this PR, so note that the only change that modified tests is 42143d88a0d499130fac8e5ca60eef0c19163734. In that PR, I make it so there are no longer any duplicate simulated doublets being created. This is necessary to be able to support any neighborhood detection algorithm. I also feel like it makes more sense. This is the only algorithmic change to upstream. Please use your own judgement to check if this makes sense to you. ### TODO:. - [x] remove unused utils (plotting, preprocessing); - [ ] figure out what remaining utils to replace with ours; - [x] PCA/SVD: https://github.com/scverse/scanpy/blob/bf5f1f9343f5729df6f90f7c68363682022e0480/scanpy/preprocessing/_scrublet/__init__.py#L415-L417; - [x] mean_center, normalize_variance, zscore: small enough to be left alone I think; - [ ] get_knn_graph: no need to have multiple implementations here, but our current implementation automatically calculates connectivities, which this doesnt need https://github.com/scverse/scanpy/pull/2723; - [ ] refactor so the class API matche",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2703
https://github.com/scverse/scanpy/pull/2703:1025,Testability,test,tests,1025,"hanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #173; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Docs:; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/release-notes/index.html#version-1-10; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet_simulate_doublets.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pl.scrublet_score_distribution.html. ### How to review this PR. I made tests quantitative before this PR, so note that the only change that modified tests is 42143d88a0d499130fac8e5ca60eef0c19163734. In that PR, I make it so there are no longer any duplicate simulated doublets being created. This is necessary to be able to support any neighborhood detection algorithm. I also feel like it makes more sense. This is the only algorithmic change to upstream. Please use your own judgement to check if this makes sense to you. ### TODO:. - [x] remove unused utils (plotting, preprocessing); - [ ] figure out what remaining utils to replace with ours; - [x] PCA/SVD: https://github.com/scverse/scanpy/blob/bf5f1f9343f5729df6f90f7c68363682022e0480/scanpy/preprocessing/_scrublet/__init__.py#L415-L417; - [x] mean_center, normalize_variance, zscore: small enough to be left alone I think; - [ ] get_knn_graph: no need to have multiple implementations here, but our current implementation automatically calculates connectivities, which this doesnt need https://github.com/scverse/scanpy/pull/2723; - [ ] refactor so the class API matche",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2703
https://github.com/scverse/scanpy/pull/2703:2141,Testability,log,logging,2141,"ize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #173; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Docs:; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/release-notes/index.html#version-1-10; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet_simulate_doublets.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pl.scrublet_score_distribution.html. ### How to review this PR. I made tests quantitative before this PR, so note that the only change that modified tests is 42143d88a0d499130fac8e5ca60eef0c19163734. In that PR, I make it so there are no longer any duplicate simulated doublets being created. This is necessary to be able to support any neighborhood detection algorithm. I also feel like it makes more sense. This is the only algorithmic change to upstream. Please use your own judgement to check if this makes sense to you. ### TODO:. - [x] remove unused utils (plotting, preprocessing); - [ ] figure out what remaining utils to replace with ours; - [x] PCA/SVD: https://github.com/scverse/scanpy/blob/bf5f1f9343f5729df6f90f7c68363682022e0480/scanpy/preprocessing/_scrublet/__init__.py#L415-L417; - [x] mean_center, normalize_variance, zscore: small enough to be left alone I think; - [ ] get_knn_graph: no need to have multiple implementations here, but our current implementation automatically calculates connectivities, which this doesnt need https://github.com/scverse/scanpy/pull/2723; - [ ] refactor so the class API matches the way we use it ; - [x] switch to dataclass for centralized attr defs; - [x] use non-deprecated random state style; - [x] use our logging instead of print statements",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2703
https://github.com/scverse/scanpy/pull/2703:71,Usability,guid,guidelines,71,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #173; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Docs:; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/release-notes/index.html#version-1-10; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet_simulate_doublets.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pl.scrublet_score_distribution.html. ### How to review this PR. I made tests quantitative before this PR, so note that the only change that modified tests is 42143d88a0d499130fac8e5ca60eef0c19163734. In that PR, I make it so there are no longer any duplicate simulated doublets being created. This is necessary to be able to support any neighborhood detection algorithm. I also feel like it makes more sense. This is the only algorithmic change to upstream. Please use your own judgement to check if this makes sense to you. ### TODO:. - [x] remove unused utils (plotting, preprocessing); - [ ] figure out what remaining utils to replace with ours; - [x] PCA/SVD: https://github.com/scverse/scanpy/blob/bf5f1f9343f5729df6f90f7c68363682022e0480/scanpy/preprocessing/_scrublet/__init__.py#L415-L417; - [x] mean_center, normalize_variance, zscore: small enough to be left alone I think; - [ ] get_knn_graph: no need to have multiple implementations here, but our current implementation automatically calculates connectivities, which this doesnt need https://github.com/scverse/scanpy/pull/2723; - [ ] refactor so the class API ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2703
https://github.com/scverse/scanpy/pull/2703:102,Usability,guid,guide,102,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #173; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:. Docs:; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/release-notes/index.html#version-1-10; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pp.scrublet_simulate_doublets.html; - https://icb-scanpy--2703.com.readthedocs.build/en/2703/api/generated/scanpy.pl.scrublet_score_distribution.html. ### How to review this PR. I made tests quantitative before this PR, so note that the only change that modified tests is 42143d88a0d499130fac8e5ca60eef0c19163734. In that PR, I make it so there are no longer any duplicate simulated doublets being created. This is necessary to be able to support any neighborhood detection algorithm. I also feel like it makes more sense. This is the only algorithmic change to upstream. Please use your own judgement to check if this makes sense to you. ### TODO:. - [x] remove unused utils (plotting, preprocessing); - [ ] figure out what remaining utils to replace with ours; - [x] PCA/SVD: https://github.com/scverse/scanpy/blob/bf5f1f9343f5729df6f90f7c68363682022e0480/scanpy/preprocessing/_scrublet/__init__.py#L415-L417; - [x] mean_center, normalize_variance, zscore: small enough to be left alone I think; - [ ] get_knn_graph: no need to have multiple implementations here, but our current implementation automatically calculates connectivities, which this doesnt need https://github.com/scverse/scanpy/pull/2723; - [ ] refactor so the class API ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2703
https://github.com/scverse/scanpy/pull/2704:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/psf/black: 23.9.1  23.10.0](https://github.com/psf/black/compare/23.9.1...23.10.0); - [github.com/astral-sh/ruff-pre-commit: v0.0.292  v0.1.1](https://github.com/astral-sh/ruff-pre-commit/compare/v0.0.292...v0.1.1); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2704
https://github.com/scverse/scanpy/pull/2705:808,Availability,toler,tolerances,808,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2688; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: just modifying tests. Fixes tests for metrics. Some notes on an in progress PR:. * Previously xfail tests didn't actually fail because nothing was asserted; * This behavior changes with version of numba.; * numba .56<= seems more reproducible, but differences are greater when they occur (e.g. calculating on sparse vs dense); * Ideally want per metric, per calculation tolerances; * Both threading options can differer; * ~~I think single threaded + `fastmath=False` is reproducible, but need to confirm~~  still no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2705
https://github.com/scverse/scanpy/pull/2705:376,Deployability,release,release,376,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2688; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: just modifying tests. Fixes tests for metrics. Some notes on an in progress PR:. * Previously xfail tests didn't actually fail because nothing was asserted; * This behavior changes with version of numba.; * numba .56<= seems more reproducible, but differences are greater when they occur (e.g. calculating on sparse vs dense); * Ideally want per metric, per calculation tolerances; * Both threading options can differer; * ~~I think single threaded + `fastmath=False` is reproducible, but need to confirm~~  still no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2705
https://github.com/scverse/scanpy/pull/2705:401,Deployability,Release,Release,401,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2688; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: just modifying tests. Fixes tests for metrics. Some notes on an in progress PR:. * Previously xfail tests didn't actually fail because nothing was asserted; * This behavior changes with version of numba.; * numba .56<= seems more reproducible, but differences are greater when they occur (e.g. calculating on sparse vs dense); * Ideally want per metric, per calculation tolerances; * Both threading options can differer; * ~~I think single threaded + `fastmath=False` is reproducible, but need to confirm~~  still no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2705
https://github.com/scverse/scanpy/pull/2705:453,Testability,test,tests,453,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2688; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: just modifying tests. Fixes tests for metrics. Some notes on an in progress PR:. * Previously xfail tests didn't actually fail because nothing was asserted; * This behavior changes with version of numba.; * numba .56<= seems more reproducible, but differences are greater when they occur (e.g. calculating on sparse vs dense); * Ideally want per metric, per calculation tolerances; * Both threading options can differer; * ~~I think single threaded + `fastmath=False` is reproducible, but need to confirm~~  still no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2705
https://github.com/scverse/scanpy/pull/2705:466,Testability,test,tests,466,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2688; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: just modifying tests. Fixes tests for metrics. Some notes on an in progress PR:. * Previously xfail tests didn't actually fail because nothing was asserted; * This behavior changes with version of numba.; * numba .56<= seems more reproducible, but differences are greater when they occur (e.g. calculating on sparse vs dense); * Ideally want per metric, per calculation tolerances; * Both threading options can differer; * ~~I think single threaded + `fastmath=False` is reproducible, but need to confirm~~  still no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2705
https://github.com/scverse/scanpy/pull/2705:538,Testability,test,tests,538,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2688; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: just modifying tests. Fixes tests for metrics. Some notes on an in progress PR:. * Previously xfail tests didn't actually fail because nothing was asserted; * This behavior changes with version of numba.; * numba .56<= seems more reproducible, but differences are greater when they occur (e.g. calculating on sparse vs dense); * Ideally want per metric, per calculation tolerances; * Both threading options can differer; * ~~I think single threaded + `fastmath=False` is reproducible, but need to confirm~~  still no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2705
https://github.com/scverse/scanpy/pull/2705:585,Testability,assert,asserted,585,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2688; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: just modifying tests. Fixes tests for metrics. Some notes on an in progress PR:. * Previously xfail tests didn't actually fail because nothing was asserted; * This behavior changes with version of numba.; * numba .56<= seems more reproducible, but differences are greater when they occur (e.g. calculating on sparse vs dense); * Ideally want per metric, per calculation tolerances; * Both threading options can differer; * ~~I think single threaded + `fastmath=False` is reproducible, but need to confirm~~  still no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2705
https://github.com/scverse/scanpy/pull/2705:71,Usability,guid,guidelines,71,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2688; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: just modifying tests. Fixes tests for metrics. Some notes on an in progress PR:. * Previously xfail tests didn't actually fail because nothing was asserted; * This behavior changes with version of numba.; * numba .56<= seems more reproducible, but differences are greater when they occur (e.g. calculating on sparse vs dense); * Ideally want per metric, per calculation tolerances; * Both threading options can differer; * ~~I think single threaded + `fastmath=False` is reproducible, but need to confirm~~  still no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2705
https://github.com/scverse/scanpy/pull/2705:102,Usability,guid,guide,102,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2688; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: just modifying tests. Fixes tests for metrics. Some notes on an in progress PR:. * Previously xfail tests didn't actually fail because nothing was asserted; * This behavior changes with version of numba.; * numba .56<= seems more reproducible, but differences are greater when they occur (e.g. calculating on sparse vs dense); * Ideally want per metric, per calculation tolerances; * Both threading options can differer; * ~~I think single threaded + `fastmath=False` is reproducible, but need to confirm~~  still no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2705
https://github.com/scverse/scanpy/issues/2706:418,Availability,Error,Error,418,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Installation using pip & installation from github repository. ### Minimal code sample. ```python; pip install scanpy; ```. ### Error output. ```pytb; Installing collected packages: tbb, distlib, asciitree, stdlib-list, setuptools-scm, pbr, numcodecs, nodeenv, natsort, igraph, identify, filelock, fasteners, docutils, cfgv, array-api-compat, accessible-pygments, zarr, virtualenv, sphinx, session-info, pytest-nunit, pytest-mock, profimp, mdit-py-plugins, leidenalg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryorn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:1056,Availability,ERROR,ERROR,1056,"hat this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Installation using pip & installation from github repository. ### Minimal code sample. ```python; pip install scanpy; ```. ### Error output. ```pytb; Installing collected packages: tbb, distlib, asciitree, stdlib-list, setuptools-scm, pbr, numcodecs, nodeenv, natsort, igraph, identify, filelock, fasteners, docutils, cfgv, array-api-compat, accessible-pygments, zarr, virtualenv, sphinx, session-info, pytest-nunit, pytest-mock, profimp, mdit-py-plugins, leidenalg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryornot 0.4.4; black 0.0; bleach 4.1.0; bokeh 3.2.1; boltons 23.0.0; botoc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:291,Deployability,Install,Installation,291,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Installation using pip & installation from github repository. ### Minimal code sample. ```python; pip install scanpy; ```. ### Error output. ```pytb; Installing collected packages: tbb, distlib, asciitree, stdlib-list, setuptools-scm, pbr, numcodecs, nodeenv, natsort, igraph, identify, filelock, fasteners, docutils, cfgv, array-api-compat, accessible-pygments, zarr, virtualenv, sphinx, session-info, pytest-nunit, pytest-mock, profimp, mdit-py-plugins, leidenalg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryorn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:316,Deployability,install,installation,316,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Installation using pip & installation from github repository. ### Minimal code sample. ```python; pip install scanpy; ```. ### Error output. ```pytb; Installing collected packages: tbb, distlib, asciitree, stdlib-list, setuptools-scm, pbr, numcodecs, nodeenv, natsort, igraph, identify, filelock, fasteners, docutils, cfgv, array-api-compat, accessible-pygments, zarr, virtualenv, sphinx, session-info, pytest-nunit, pytest-mock, profimp, mdit-py-plugins, leidenalg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryorn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:393,Deployability,install,install,393,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Installation using pip & installation from github repository. ### Minimal code sample. ```python; pip install scanpy; ```. ### Error output. ```pytb; Installing collected packages: tbb, distlib, asciitree, stdlib-list, setuptools-scm, pbr, numcodecs, nodeenv, natsort, igraph, identify, filelock, fasteners, docutils, cfgv, array-api-compat, accessible-pygments, zarr, virtualenv, sphinx, session-info, pytest-nunit, pytest-mock, profimp, mdit-py-plugins, leidenalg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryorn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:441,Deployability,Install,Installing,441,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Installation using pip & installation from github repository. ### Minimal code sample. ```python; pip install scanpy; ```. ### Error output. ```pytb; Installing collected packages: tbb, distlib, asciitree, stdlib-list, setuptools-scm, pbr, numcodecs, nodeenv, natsort, igraph, identify, filelock, fasteners, docutils, cfgv, array-api-compat, accessible-pygments, zarr, virtualenv, sphinx, session-info, pytest-nunit, pytest-mock, profimp, mdit-py-plugins, leidenalg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryorn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:1033,Deployability,install,installation,1033,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Installation using pip & installation from github repository. ### Minimal code sample. ```python; pip install scanpy; ```. ### Error output. ```pytb; Installing collected packages: tbb, distlib, asciitree, stdlib-list, setuptools-scm, pbr, numcodecs, nodeenv, natsort, igraph, identify, filelock, fasteners, docutils, cfgv, array-api-compat, accessible-pygments, zarr, virtualenv, sphinx, session-info, pytest-nunit, pytest-mock, profimp, mdit-py-plugins, leidenalg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryorn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:1105,Deployability,install,installed,1105,"he latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Installation using pip & installation from github repository. ### Minimal code sample. ```python; pip install scanpy; ```. ### Error output. ```pytb; Installing collected packages: tbb, distlib, asciitree, stdlib-list, setuptools-scm, pbr, numcodecs, nodeenv, natsort, igraph, identify, filelock, fasteners, docutils, cfgv, array-api-compat, accessible-pygments, zarr, virtualenv, sphinx, session-info, pytest-nunit, pytest-mock, profimp, mdit-py-plugins, leidenalg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryornot 0.4.4; black 0.0; bleach 4.1.0; bokeh 3.2.1; boltons 23.0.0; botocore 1.29.76; Bottleneck 1.3.5; brotlipy 0.7.0; certifi 2023.7.22; cffi 1.15.1; chardet 4.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:2817,Deployability,patch,patch,2817,topep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryornot 0.4.4; black 0.0; bleach 4.1.0; bokeh 3.2.1; boltons 23.0.0; botocore 1.29.76; Bottleneck 1.3.5; brotlipy 0.7.0; certifi 2023.7.22; cffi 1.15.1; chardet 4.0.0; charset-normalizer 2.0.4; click 8.0.4; cloudpickle 2.2.1; clyent 1.2.2; colorama 0.4.6; colorcet 3.0.1; comm 0.1.2; conda 23.7.4; conda-build 3.26.1; conda-content-trust 0.2.0; conda_index 0.3.0; conda-libmamba-solver 23.7.0; conda-pack 0.6.0; conda-package-handling 2.2.0; conda_package_streaming 0.9.0; conda-repo-cli 1.0.75; conda-token 0.4.0; conda-verify 3.4.2; constantly 15.1.0; contourpy 1.0.5; cookiecutter 1.7.3; cryptography 41.0.3; cssselect 1.1.0; cycler 0.11.0; Cython 3.0.3; cytoolz 0.12.0; daal4py 2023.1.1; dask 2023.6.0; datasets 2.12.0; datashader 0.15.2; datashape 0.5.4; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; diff-match-patch 20200713; dill 0.3.6; distributed 2023.6.0; docstring-to-markdown 0.11; docutils 0.18.1; entrypoints 0.4; et-xmlfile 1.1.0; executing 0.8.3; fastjsonschema 2.16.2; filelock 3.9.0; flake8 6.0.0; Flask 2.2.2; fonttools 4.25.0; frozenlist 1.3.3; fsspec 2023.4.0; future 0.18.3; gensim 4.3.0; glob2 0.7; gmpy2 2.1.2; greenlet 2.0.1; h5py 3.9.0; HeapDict 1.0.1; holoviews 1.17.1; huggingface-hub 0.15.1; hvplot 0.8.4; hyperlink 21.0.0; idna 3.4; imagecodecs 2023.1.23; imageio 2.31.1; imagesize 1.4.1; imbalanced-learn 0.10.1; importlib-metadata 6.0.0; incremental 21.3.0; inflection 0.5.1; iniconfig 1.1.1; intake 0.6.8; intervaltree 3.1.0; ipykernel 6.25.0; ipython 8.15.0; ipython-genutils 0.2.0; ipywidgets 8.0.4; isort 5.9.3; itemadapter 0.3.0; itemloaders 1.0.4; itsdangerous 2.0.1; jaraco.classes 3.2.1; jedi 0.18.1; jeepney 0.7.1; jellyfish 1.0.1; Jinja2 3.1.2; jinja2-time 0.2.0; jmespath 0.10.0; joblib 1.2.0; json5 0.9.6; jsonpatch 1.32; jsonpointer 2.1; jsonschema 4.17.3; jupyter 1.0.0; jupy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:4695,Deployability,update,updater,4695,2-time 0.2.0; jmespath 0.10.0; joblib 1.2.0; json5 0.9.6; jsonpatch 1.32; jsonpointer 2.1; jsonschema 4.17.3; jupyter 1.0.0; jupyter_client 7.4.9; jupyter-console 6.6.3; jupyter_core 5.3.0; jupyter-events 0.6.3; jupyter-server 1.23.4; jupyter_server_fileid 0.9.0; jupyter_server_ydoc 0.8.0; jupyter-ydoc 0.2.4; jupyterlab 3.6.3; jupyterlab-pygments 0.1.2; jupyterlab_server 2.22.0; jupyterlab-widgets 3.0.5; kaleido 0.2.1; keyring 23.13.1; kiwisolver 1.4.4; lazy_loader 0.2; lazy-object-proxy 1.6.0; libarchive-c 2.9; libmambapy 1.5.1; linkify-it-py 2.0.0; llvmlite 0.40.0; lmdb 1.4.1; locket 1.0.0; lxml 4.9.3; lz4 4.3.2; Markdown 3.4.1; markdown-it-py 2.2.0; MarkupSafe 2.1.1; matplotlib 3.7.2; matplotlib-inline 0.1.6; mccabe 0.7.0; mdit-py-plugins 0.3.0; mdurl 0.1.0; mistune 0.8.4; mkl-fft 1.3.8; mkl-random 1.2.4; mkl-service 2.4.0; more-itertools 8.12.0; mpmath 1.3.0; msgpack 1.0.3; multidict 6.0.2; multipledispatch 0.6.0; multiprocess 0.70.14; munkres 1.1.4; mypy-extensions 1.0.0; navigator-updater 0.4.0; nbclassic 0.5.5; nbclient 0.5.13; nbconvert 6.5.4; nbformat 5.9.2; nest-asyncio 1.5.6; networkx 3.1; nltk 3.8.1; notebook 6.5.4; notebook_shim 0.2.2; numba 0.57.1; numexpr 2.8.4; numpy 1.24.3; numpydoc 1.5.0; openpyxl 3.0.10; packaging 23.1; pandas 2.0.3; pandocfilters 1.5.0; panel 1.2.3; param 1.13.0; parsel 1.6.0; parso 0.8.3; partd 1.4.0; pathlib 1.0.1; pathspec 0.10.3; patsy 0.5.3; pep8 1.7.1; pexpect 4.8.0; pickleshare 0.7.5; Pillow 9.4.0; pip 23.2.1; pkce 1.0.3; pkginfo 1.9.6; platformdirs 3.10.0; plotly 5.9.0; pluggy 1.0.0; ply 3.11; poyo 0.5.0; prometheus-client 0.14.1; prompt-toolkit 3.0.36; Protego 0.1.16; psutil 5.9.0; ptyprocess 0.7.0; pure-eval 0.2.2; py-cpuinfo 8.0.0; pyarrow 11.0.0; pyasn1 0.4.8; pyasn1-modules 0.2.8; pycodestyle 2.10.0; pycosat 0.6.4; pycparser 2.21; pyct 0.5.0; pycurl 7.45.2; pydantic 1.10.8; PyDispatcher 2.0.5; pydocstyle 6.3.0; pyerfa 2.0.0; pyflakes 3.0.1; Pygments 2.15.1; PyJWT 2.4.0; pylint 2.16.2; pylint-venv 2.3.0; pyls-spyder 0.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:3136,Energy Efficiency,green,greenlet,3136, 1.15.1; chardet 4.0.0; charset-normalizer 2.0.4; click 8.0.4; cloudpickle 2.2.1; clyent 1.2.2; colorama 0.4.6; colorcet 3.0.1; comm 0.1.2; conda 23.7.4; conda-build 3.26.1; conda-content-trust 0.2.0; conda_index 0.3.0; conda-libmamba-solver 23.7.0; conda-pack 0.6.0; conda-package-handling 2.2.0; conda_package_streaming 0.9.0; conda-repo-cli 1.0.75; conda-token 0.4.0; conda-verify 3.4.2; constantly 15.1.0; contourpy 1.0.5; cookiecutter 1.7.3; cryptography 41.0.3; cssselect 1.1.0; cycler 0.11.0; Cython 3.0.3; cytoolz 0.12.0; daal4py 2023.1.1; dask 2023.6.0; datasets 2.12.0; datashader 0.15.2; datashape 0.5.4; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; diff-match-patch 20200713; dill 0.3.6; distributed 2023.6.0; docstring-to-markdown 0.11; docutils 0.18.1; entrypoints 0.4; et-xmlfile 1.1.0; executing 0.8.3; fastjsonschema 2.16.2; filelock 3.9.0; flake8 6.0.0; Flask 2.2.2; fonttools 4.25.0; frozenlist 1.3.3; fsspec 2023.4.0; future 0.18.3; gensim 4.3.0; glob2 0.7; gmpy2 2.1.2; greenlet 2.0.1; h5py 3.9.0; HeapDict 1.0.1; holoviews 1.17.1; huggingface-hub 0.15.1; hvplot 0.8.4; hyperlink 21.0.0; idna 3.4; imagecodecs 2023.1.23; imageio 2.31.1; imagesize 1.4.1; imbalanced-learn 0.10.1; importlib-metadata 6.0.0; incremental 21.3.0; inflection 0.5.1; iniconfig 1.1.1; intake 0.6.8; intervaltree 3.1.0; ipykernel 6.25.0; ipython 8.15.0; ipython-genutils 0.2.0; ipywidgets 8.0.4; isort 5.9.3; itemadapter 0.3.0; itemloaders 1.0.4; itsdangerous 2.0.1; jaraco.classes 3.2.1; jedi 0.18.1; jeepney 0.7.1; jellyfish 1.0.1; Jinja2 3.1.2; jinja2-time 0.2.0; jmespath 0.10.0; joblib 1.2.0; json5 0.9.6; jsonpatch 1.32; jsonpointer 2.1; jsonschema 4.17.3; jupyter 1.0.0; jupyter_client 7.4.9; jupyter-console 6.6.3; jupyter_core 5.3.0; jupyter-events 0.6.3; jupyter-server 1.23.4; jupyter_server_fileid 0.9.0; jupyter_server_ydoc 0.8.0; jupyter-ydoc 0.2.4; jupyterlab 3.6.3; jupyterlab-pygments 0.1.2; jupyterlab_server 2.22.0; jupyterlab-widgets 3.0.5; kaleido 0.2.1; keyring 23.13.1; kiwisol,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:7763,Integrability,wrap,wrapt,7763,ython-snappy 0.6.1; pytoolconfig 1.2.5; pytz 2023.3.post1; pyviz-comms 2.3.0; PyWavelets 1.4.1; pyxdg 0.27; PyYAML 6.0; pyzmq 23.2.0; QDarkStyle 3.0.2; qstylizer 0.2.2; QtAwesome 1.2.2; qtconsole 5.4.2; QtPy 2.2.0; queuelib 1.5.0; regex 2022.7.9; requests 2.31.0; requests-file 1.5.1; requests-toolbelt 1.0.0; responses 0.13.3; rfc3339-validator 0.1.4; rfc3986-validator 0.1.1; rope 1.7.0; Rtree 1.0.1; ruamel.yaml 0.17.21; ruamel-yaml-conda 0.17.21; s3fs 2023.4.0; safetensors 0.3.2; scikit-image 0.20.0; scikit-learn 1.3.0; scikit-learn-intelex 20230426.111612; scipy 1.11.1; Scrapy 2.8.0; seaborn 0.12.2; SecretStorage 3.3.1; Send2Trash 1.8.0; service-identity 18.1.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 5.2.1; sniffio 1.2.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.4; Sphinx 5.0.2; sphinxcontrib-applehelp 1.0.2; sphinxcontrib-devhelp 1.0.2; sphinxcontrib-htmlhelp 2.0.0; sphinxcontrib-jsmath 1.0.1; sphinxcontrib-qthelp 1.0.3; sphinxcontrib-serializinghtml 1.1.5; spyder 5.4.3; spyder-kernels 2.4.4; SQLAlchemy 1.4.39; stack-data 0.2.0; statsmodels 0.14.0; sympy 1.11.1; tables 3.8.0; tabulate 0.8.10; TBB 0.2; tblib 1.7.0; TELR 1.0; tenacity 8.2.2; terminado 0.17.1; text-unidecode 1.3; textdistance 4.2.1; texttable 1.7.0; threadpoolctl 2.2.0; three-merge 0.1.1; tifffile 2023.4.12; tinycss2 1.2.1; tldextract 3.2.0; tokenizers 0.13.2; toml 0.10.2; tomlkit 0.11.1; toolz 0.12.0; tornado 6.3.2; tqdm 4.65.0; traitlets 5.7.1; transformers 4.32.1; Twisted 22.10.0; typing_extensions 4.7.1; tzdata 2023.3; uc-micro-py 1.0.1; ujson 5.4.0; Unidecode 1.2.0; urllib3 1.26.16; w3lib 1.21.0; watchdog 2.1.6; wcwidth 0.2.5; webencodings 0.5.1; websocket-client 0.58.0; Werkzeug 2.2.3; whatthepatch 1.0.2; wheel 0.38.4; widgetsnbextension 4.0.5; wrapt 1.14.1; wurlitzer 3.0.2; xarray 2023.6.0; xxhash 2.0.2; xyzservices 2022.9.0; y-py 0.5.9; yapf 0.31.0; yarl 1.8.1; ypy-websocket 0.8.2; zict 2.2.0; zipp 3.11.0; zope.interface 5.4.0; zstandard 0.19.0; ```. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:7935,Integrability,interface,interface,7935,ython-snappy 0.6.1; pytoolconfig 1.2.5; pytz 2023.3.post1; pyviz-comms 2.3.0; PyWavelets 1.4.1; pyxdg 0.27; PyYAML 6.0; pyzmq 23.2.0; QDarkStyle 3.0.2; qstylizer 0.2.2; QtAwesome 1.2.2; qtconsole 5.4.2; QtPy 2.2.0; queuelib 1.5.0; regex 2022.7.9; requests 2.31.0; requests-file 1.5.1; requests-toolbelt 1.0.0; responses 0.13.3; rfc3339-validator 0.1.4; rfc3986-validator 0.1.1; rope 1.7.0; Rtree 1.0.1; ruamel.yaml 0.17.21; ruamel-yaml-conda 0.17.21; s3fs 2023.4.0; safetensors 0.3.2; scikit-image 0.20.0; scikit-learn 1.3.0; scikit-learn-intelex 20230426.111612; scipy 1.11.1; Scrapy 2.8.0; seaborn 0.12.2; SecretStorage 3.3.1; Send2Trash 1.8.0; service-identity 18.1.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 5.2.1; sniffio 1.2.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.4; Sphinx 5.0.2; sphinxcontrib-applehelp 1.0.2; sphinxcontrib-devhelp 1.0.2; sphinxcontrib-htmlhelp 2.0.0; sphinxcontrib-jsmath 1.0.1; sphinxcontrib-qthelp 1.0.3; sphinxcontrib-serializinghtml 1.1.5; spyder 5.4.3; spyder-kernels 2.4.4; SQLAlchemy 1.4.39; stack-data 0.2.0; statsmodels 0.14.0; sympy 1.11.1; tables 3.8.0; tabulate 0.8.10; TBB 0.2; tblib 1.7.0; TELR 1.0; tenacity 8.2.2; terminado 0.17.1; text-unidecode 1.3; textdistance 4.2.1; texttable 1.7.0; threadpoolctl 2.2.0; three-merge 0.1.1; tifffile 2023.4.12; tinycss2 1.2.1; tldextract 3.2.0; tokenizers 0.13.2; toml 0.10.2; tomlkit 0.11.1; toolz 0.12.0; tornado 6.3.2; tqdm 4.65.0; traitlets 5.7.1; transformers 4.32.1; Twisted 22.10.0; typing_extensions 4.7.1; tzdata 2023.3; uc-micro-py 1.0.1; ujson 5.4.0; Unidecode 1.2.0; urllib3 1.26.16; w3lib 1.21.0; watchdog 2.1.6; wcwidth 0.2.5; webencodings 0.5.1; websocket-client 0.58.0; Werkzeug 2.2.3; whatthepatch 1.0.2; wheel 0.38.4; widgetsnbextension 4.0.5; wrapt 1.14.1; wurlitzer 3.0.2; xarray 2023.6.0; xxhash 2.0.2; xyzservices 2022.9.0; y-py 0.5.9; yapf 0.31.0; yarl 1.8.1; ypy-websocket 0.8.2; zict 2.2.0; zipp 3.11.0; zope.interface 5.4.0; zstandard 0.19.0; ```. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:738,Modifiability,plugin,plugins,738,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Installation using pip & installation from github repository. ### Minimal code sample. ```python; pip install scanpy; ```. ### Error output. ```pytb; Installing collected packages: tbb, distlib, asciitree, stdlib-list, setuptools-scm, pbr, numcodecs, nodeenv, natsort, igraph, identify, filelock, fasteners, docutils, cfgv, array-api-compat, accessible-pygments, zarr, virtualenv, sphinx, session-info, pytest-nunit, pytest-mock, profimp, mdit-py-plugins, leidenalg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryorn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:4437,Modifiability,plugin,plugins,4437,.8; intervaltree 3.1.0; ipykernel 6.25.0; ipython 8.15.0; ipython-genutils 0.2.0; ipywidgets 8.0.4; isort 5.9.3; itemadapter 0.3.0; itemloaders 1.0.4; itsdangerous 2.0.1; jaraco.classes 3.2.1; jedi 0.18.1; jeepney 0.7.1; jellyfish 1.0.1; Jinja2 3.1.2; jinja2-time 0.2.0; jmespath 0.10.0; joblib 1.2.0; json5 0.9.6; jsonpatch 1.32; jsonpointer 2.1; jsonschema 4.17.3; jupyter 1.0.0; jupyter_client 7.4.9; jupyter-console 6.6.3; jupyter_core 5.3.0; jupyter-events 0.6.3; jupyter-server 1.23.4; jupyter_server_fileid 0.9.0; jupyter_server_ydoc 0.8.0; jupyter-ydoc 0.2.4; jupyterlab 3.6.3; jupyterlab-pygments 0.1.2; jupyterlab_server 2.22.0; jupyterlab-widgets 3.0.5; kaleido 0.2.1; keyring 23.13.1; kiwisolver 1.4.4; lazy_loader 0.2; lazy-object-proxy 1.6.0; libarchive-c 2.9; libmambapy 1.5.1; linkify-it-py 2.0.0; llvmlite 0.40.0; lmdb 1.4.1; locket 1.0.0; lxml 4.9.3; lz4 4.3.2; Markdown 3.4.1; markdown-it-py 2.2.0; MarkupSafe 2.1.1; matplotlib 3.7.2; matplotlib-inline 0.1.6; mccabe 0.7.0; mdit-py-plugins 0.3.0; mdurl 0.1.0; mistune 0.8.4; mkl-fft 1.3.8; mkl-random 1.2.4; mkl-service 2.4.0; more-itertools 8.12.0; mpmath 1.3.0; msgpack 1.0.3; multidict 6.0.2; multipledispatch 0.6.0; multiprocess 0.70.14; munkres 1.1.4; mypy-extensions 1.0.0; navigator-updater 0.4.0; nbclassic 0.5.5; nbclient 0.5.13; nbconvert 6.5.4; nbformat 5.9.2; nest-asyncio 1.5.6; networkx 3.1; nltk 3.8.1; notebook 6.5.4; notebook_shim 0.2.2; numba 0.57.1; numexpr 2.8.4; numpy 1.24.3; numpydoc 1.5.0; openpyxl 3.0.10; packaging 23.1; pandas 2.0.3; pandocfilters 1.5.0; panel 1.2.3; param 1.13.0; parsel 1.6.0; parso 0.8.3; partd 1.4.0; pathlib 1.0.1; pathspec 0.10.3; patsy 0.5.3; pep8 1.7.1; pexpect 4.8.0; pickleshare 0.7.5; Pillow 9.4.0; pip 23.2.1; pkce 1.0.3; pkginfo 1.9.6; platformdirs 3.10.0; plotly 5.9.0; pluggy 1.0.0; ply 3.11; poyo 0.5.0; prometheus-client 0.14.1; prompt-toolkit 3.0.36; Protego 0.1.16; psutil 5.9.0; ptyprocess 0.7.0; pure-eval 0.2.2; py-cpuinfo 8.0.0; pyarrow 11.0.0; pyasn1 0.4.8; pyasn1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:957,Performance,cache,cache,957,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Installation using pip & installation from github repository. ### Minimal code sample. ```python; pip install scanpy; ```. ### Error output. ```pytb; Installing collected packages: tbb, distlib, asciitree, stdlib-list, setuptools-scm, pbr, numcodecs, nodeenv, natsort, igraph, identify, filelock, fasteners, docutils, cfgv, array-api-compat, accessible-pygments, zarr, virtualenv, sphinx, session-info, pytest-nunit, pytest-mock, profimp, mdit-py-plugins, leidenalg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryorn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:1889,Performance,cache,cache,1889,"e-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryornot 0.4.4; black 0.0; bleach 4.1.0; bokeh 3.2.1; boltons 23.0.0; botocore 1.29.76; Bottleneck 1.3.5; brotlipy 0.7.0; certifi 2023.7.22; cffi 1.15.1; chardet 4.0.0; charset-normalizer 2.0.4; click 8.0.4; cloudpickle 2.2.1; clyent 1.2.2; colorama 0.4.6; colorcet 3.0.1; comm 0.1.2; conda 23.7.4; conda-build 3.26.1; conda-content-trust 0.2.0; conda_index 0.3.0; conda-libmamba-solver 23.7.0; conda-pack 0.6.0; conda-package-handling 2.2.0; conda_package_streaming 0.9.0; conda-repo-cli 1.0.75; conda-token 0.4.0; conda-verify 3.4.2; constantly 15.1.0; contourpy 1.0.5; cookiecutter 1.7.3; cryptography 41.0.3; cssselect 1.1.0; cycler 0.11.0; Cython 3.0.3; cytoolz 0.12.0; daal4py 2023.1.1; dask 2023.6.0; datasets 2.12.0; datashader 0.15.2; datashape 0.5.4; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; diff-match-patch 20200713; dill 0.3.6; distributed 2023.6.0; docstring-to-markdo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:2083,Performance,Bottleneck,Bottleneck,2083,It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryornot 0.4.4; black 0.0; bleach 4.1.0; bokeh 3.2.1; boltons 23.0.0; botocore 1.29.76; Bottleneck 1.3.5; brotlipy 0.7.0; certifi 2023.7.22; cffi 1.15.1; chardet 4.0.0; charset-normalizer 2.0.4; click 8.0.4; cloudpickle 2.2.1; clyent 1.2.2; colorama 0.4.6; colorcet 3.0.1; comm 0.1.2; conda 23.7.4; conda-build 3.26.1; conda-content-trust 0.2.0; conda_index 0.3.0; conda-libmamba-solver 23.7.0; conda-pack 0.6.0; conda-package-handling 2.2.0; conda_package_streaming 0.9.0; conda-repo-cli 1.0.75; conda-token 0.4.0; conda-verify 3.4.2; constantly 15.1.0; contourpy 1.0.5; cookiecutter 1.7.3; cryptography 41.0.3; cssselect 1.1.0; cycler 0.11.0; Cython 3.0.3; cytoolz 0.12.0; daal4py 2023.1.1; dask 2023.6.0; datasets 2.12.0; datashader 0.15.2; datashape 0.5.4; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; diff-match-patch 20200713; dill 0.3.6; distributed 2023.6.0; docstring-to-markdown 0.11; docutils 0.18.1; entrypoints 0.4; et-xmlfile 1.1.0; executing 0.8.3; fastjsonschema 2.16.2; filelock 3.9.0; flake8 6.0.0; Flask 2.2.2; fonttools 4.25.0; frozenlist 1.3.3; fsspec 2023.4.0; futur,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:6200,Performance,queue,queuelib,6200,rmdirs 3.10.0; plotly 5.9.0; pluggy 1.0.0; ply 3.11; poyo 0.5.0; prometheus-client 0.14.1; prompt-toolkit 3.0.36; Protego 0.1.16; psutil 5.9.0; ptyprocess 0.7.0; pure-eval 0.2.2; py-cpuinfo 8.0.0; pyarrow 11.0.0; pyasn1 0.4.8; pyasn1-modules 0.2.8; pycodestyle 2.10.0; pycosat 0.6.4; pycparser 2.21; pyct 0.5.0; pycurl 7.45.2; pydantic 1.10.8; PyDispatcher 2.0.5; pydocstyle 6.3.0; pyerfa 2.0.0; pyflakes 3.0.1; Pygments 2.15.1; PyJWT 2.4.0; pylint 2.16.2; pylint-venv 2.3.0; pyls-spyder 0.4.0; pyodbc 4.0.34; pyOpenSSL 23.2.0; pyparsing 3.0.9; PyQt5-sip 12.11.0; pyrsistent 0.18.0; PySocks 1.7.1; pytest 7.4.0; python-dateutil 2.8.2; python-dotenv 0.21.0; python-json-logger 2.0.7; python-lsp-black 1.2.1; python-lsp-jsonrpc 1.0.0; python-lsp-server 1.7.2; python-slugify 5.0.2; python-snappy 0.6.1; pytoolconfig 1.2.5; pytz 2023.3.post1; pyviz-comms 2.3.0; PyWavelets 1.4.1; pyxdg 0.27; PyYAML 6.0; pyzmq 23.2.0; QDarkStyle 3.0.2; qstylizer 0.2.2; QtAwesome 1.2.2; qtconsole 5.4.2; QtPy 2.2.0; queuelib 1.5.0; regex 2022.7.9; requests 2.31.0; requests-file 1.5.1; requests-toolbelt 1.0.0; responses 0.13.3; rfc3339-validator 0.1.4; rfc3986-validator 0.1.1; rope 1.7.0; Rtree 1.0.1; ruamel.yaml 0.17.21; ruamel-yaml-conda 0.17.21; s3fs 2023.4.0; safetensors 0.3.2; scikit-image 0.20.0; scikit-learn 1.3.0; scikit-learn-intelex 20230426.111612; scipy 1.11.1; Scrapy 2.8.0; seaborn 0.12.2; SecretStorage 3.3.1; Send2Trash 1.8.0; service-identity 18.1.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 5.2.1; sniffio 1.2.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.4; Sphinx 5.0.2; sphinxcontrib-applehelp 1.0.2; sphinxcontrib-devhelp 1.0.2; sphinxcontrib-htmlhelp 2.0.0; sphinxcontrib-jsmath 1.0.1; sphinxcontrib-qthelp 1.0.3; sphinxcontrib-serializinghtml 1.1.5; spyder 5.4.3; spyder-kernels 2.4.4; SQLAlchemy 1.4.39; stack-data 0.2.0; statsmodels 0.14.0; sympy 1.11.1; tables 3.8.0; tabulate 0.8.10; TBB 0.2; tblib 1.7.0; TELR 1.0; tenacity 8.2.2; terminado 0.17.1; text-unid,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:1754,Safety,timeout,timeout,1754,"lg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryornot 0.4.4; black 0.0; bleach 4.1.0; bokeh 3.2.1; boltons 23.0.0; botocore 1.29.76; Bottleneck 1.3.5; brotlipy 0.7.0; certifi 2023.7.22; cffi 1.15.1; chardet 4.0.0; charset-normalizer 2.0.4; click 8.0.4; cloudpickle 2.2.1; clyent 1.2.2; colorama 0.4.6; colorcet 3.0.1; comm 0.1.2; conda 23.7.4; conda-build 3.26.1; conda-content-trust 0.2.0; conda_index 0.3.0; conda-libmamba-solver 23.7.0; conda-pack 0.6.0; conda-package-handling 2.2.0; conda_package_streaming 0.9.0; conda-repo-cli 1.0.75; conda-token 0.4.0; conda-verify 3.4.2; constantly 15.1.0; contourpy 1.0.5; cookiecutter 1.7.3; cryptography 41.0.3; cssselect 1.1.0; cycler 0.11.0; Cython 3.0.3; cytoolz 0.12.0; daal4py 2023.1.1; dask 2023.6.0; datasets 2.12.0; datashader 0.15.2; datashape 0.5.4;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:6451,Safety,safe,safetensors,6451,odestyle 2.10.0; pycosat 0.6.4; pycparser 2.21; pyct 0.5.0; pycurl 7.45.2; pydantic 1.10.8; PyDispatcher 2.0.5; pydocstyle 6.3.0; pyerfa 2.0.0; pyflakes 3.0.1; Pygments 2.15.1; PyJWT 2.4.0; pylint 2.16.2; pylint-venv 2.3.0; pyls-spyder 0.4.0; pyodbc 4.0.34; pyOpenSSL 23.2.0; pyparsing 3.0.9; PyQt5-sip 12.11.0; pyrsistent 0.18.0; PySocks 1.7.1; pytest 7.4.0; python-dateutil 2.8.2; python-dotenv 0.21.0; python-json-logger 2.0.7; python-lsp-black 1.2.1; python-lsp-jsonrpc 1.0.0; python-lsp-server 1.7.2; python-slugify 5.0.2; python-snappy 0.6.1; pytoolconfig 1.2.5; pytz 2023.3.post1; pyviz-comms 2.3.0; PyWavelets 1.4.1; pyxdg 0.27; PyYAML 6.0; pyzmq 23.2.0; QDarkStyle 3.0.2; qstylizer 0.2.2; QtAwesome 1.2.2; qtconsole 5.4.2; QtPy 2.2.0; queuelib 1.5.0; regex 2022.7.9; requests 2.31.0; requests-file 1.5.1; requests-toolbelt 1.0.0; responses 0.13.3; rfc3339-validator 0.1.4; rfc3986-validator 0.1.1; rope 1.7.0; Rtree 1.0.1; ruamel.yaml 0.17.21; ruamel-yaml-conda 0.17.21; s3fs 2023.4.0; safetensors 0.3.2; scikit-image 0.20.0; scikit-learn 1.3.0; scikit-learn-intelex 20230426.111612; scipy 1.11.1; Scrapy 2.8.0; seaborn 0.12.2; SecretStorage 3.3.1; Send2Trash 1.8.0; service-identity 18.1.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 5.2.1; sniffio 1.2.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.4; Sphinx 5.0.2; sphinxcontrib-applehelp 1.0.2; sphinxcontrib-devhelp 1.0.2; sphinxcontrib-htmlhelp 2.0.0; sphinxcontrib-jsmath 1.0.1; sphinxcontrib-qthelp 1.0.3; sphinxcontrib-serializinghtml 1.1.5; spyder 5.4.3; spyder-kernels 2.4.4; SQLAlchemy 1.4.39; stack-data 0.2.0; statsmodels 0.14.0; sympy 1.11.1; tables 3.8.0; tabulate 0.8.10; TBB 0.2; tblib 1.7.0; TELR 1.0; tenacity 8.2.2; terminado 0.17.1; text-unidecode 1.3; textdistance 4.2.1; texttable 1.7.0; threadpoolctl 2.2.0; three-merge 0.1.1; tifffile 2023.4.12; tinycss2 1.2.1; tldextract 3.2.0; tokenizers 0.13.2; toml 0.10.2; tomlkit 0.11.1; toolz 0.12.0; tornado 6.3.2; tqdm 4.65.0; traitlets 5.7.1; tran,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:633,Security,access,accessible-pygments,633,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Installation using pip & installation from github repository. ### Minimal code sample. ```python; pip install scanpy; ```. ### Error output. ```pytb; Installing collected packages: tbb, distlib, asciitree, stdlib-list, setuptools-scm, pbr, numcodecs, nodeenv, natsort, igraph, identify, filelock, fasteners, docutils, cfgv, array-api-compat, accessible-pygments, zarr, virtualenv, sphinx, session-info, pytest-nunit, pytest-mock, profimp, mdit-py-plugins, leidenalg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryorn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:6321,Security,validat,validator,6321,tego 0.1.16; psutil 5.9.0; ptyprocess 0.7.0; pure-eval 0.2.2; py-cpuinfo 8.0.0; pyarrow 11.0.0; pyasn1 0.4.8; pyasn1-modules 0.2.8; pycodestyle 2.10.0; pycosat 0.6.4; pycparser 2.21; pyct 0.5.0; pycurl 7.45.2; pydantic 1.10.8; PyDispatcher 2.0.5; pydocstyle 6.3.0; pyerfa 2.0.0; pyflakes 3.0.1; Pygments 2.15.1; PyJWT 2.4.0; pylint 2.16.2; pylint-venv 2.3.0; pyls-spyder 0.4.0; pyodbc 4.0.34; pyOpenSSL 23.2.0; pyparsing 3.0.9; PyQt5-sip 12.11.0; pyrsistent 0.18.0; PySocks 1.7.1; pytest 7.4.0; python-dateutil 2.8.2; python-dotenv 0.21.0; python-json-logger 2.0.7; python-lsp-black 1.2.1; python-lsp-jsonrpc 1.0.0; python-lsp-server 1.7.2; python-slugify 5.0.2; python-snappy 0.6.1; pytoolconfig 1.2.5; pytz 2023.3.post1; pyviz-comms 2.3.0; PyWavelets 1.4.1; pyxdg 0.27; PyYAML 6.0; pyzmq 23.2.0; QDarkStyle 3.0.2; qstylizer 0.2.2; QtAwesome 1.2.2; qtconsole 5.4.2; QtPy 2.2.0; queuelib 1.5.0; regex 2022.7.9; requests 2.31.0; requests-file 1.5.1; requests-toolbelt 1.0.0; responses 0.13.3; rfc3339-validator 0.1.4; rfc3986-validator 0.1.1; rope 1.7.0; Rtree 1.0.1; ruamel.yaml 0.17.21; ruamel-yaml-conda 0.17.21; s3fs 2023.4.0; safetensors 0.3.2; scikit-image 0.20.0; scikit-learn 1.3.0; scikit-learn-intelex 20230426.111612; scipy 1.11.1; Scrapy 2.8.0; seaborn 0.12.2; SecretStorage 3.3.1; Send2Trash 1.8.0; service-identity 18.1.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 5.2.1; sniffio 1.2.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.4; Sphinx 5.0.2; sphinxcontrib-applehelp 1.0.2; sphinxcontrib-devhelp 1.0.2; sphinxcontrib-htmlhelp 2.0.0; sphinxcontrib-jsmath 1.0.1; sphinxcontrib-qthelp 1.0.3; sphinxcontrib-serializinghtml 1.1.5; spyder 5.4.3; spyder-kernels 2.4.4; SQLAlchemy 1.4.39; stack-data 0.2.0; statsmodels 0.14.0; sympy 1.11.1; tables 3.8.0; tabulate 0.8.10; TBB 0.2; tblib 1.7.0; TELR 1.0; tenacity 8.2.2; terminado 0.17.1; text-unidecode 1.3; textdistance 4.2.1; texttable 1.7.0; threadpoolctl 2.2.0; three-merge 0.1.1; tifffile 2023.4.12; tinycss2 1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:6346,Security,validat,validator,6346,; ptyprocess 0.7.0; pure-eval 0.2.2; py-cpuinfo 8.0.0; pyarrow 11.0.0; pyasn1 0.4.8; pyasn1-modules 0.2.8; pycodestyle 2.10.0; pycosat 0.6.4; pycparser 2.21; pyct 0.5.0; pycurl 7.45.2; pydantic 1.10.8; PyDispatcher 2.0.5; pydocstyle 6.3.0; pyerfa 2.0.0; pyflakes 3.0.1; Pygments 2.15.1; PyJWT 2.4.0; pylint 2.16.2; pylint-venv 2.3.0; pyls-spyder 0.4.0; pyodbc 4.0.34; pyOpenSSL 23.2.0; pyparsing 3.0.9; PyQt5-sip 12.11.0; pyrsistent 0.18.0; PySocks 1.7.1; pytest 7.4.0; python-dateutil 2.8.2; python-dotenv 0.21.0; python-json-logger 2.0.7; python-lsp-black 1.2.1; python-lsp-jsonrpc 1.0.0; python-lsp-server 1.7.2; python-slugify 5.0.2; python-snappy 0.6.1; pytoolconfig 1.2.5; pytz 2023.3.post1; pyviz-comms 2.3.0; PyWavelets 1.4.1; pyxdg 0.27; PyYAML 6.0; pyzmq 23.2.0; QDarkStyle 3.0.2; qstylizer 0.2.2; QtAwesome 1.2.2; qtconsole 5.4.2; QtPy 2.2.0; queuelib 1.5.0; regex 2022.7.9; requests 2.31.0; requests-file 1.5.1; requests-toolbelt 1.0.0; responses 0.13.3; rfc3339-validator 0.1.4; rfc3986-validator 0.1.1; rope 1.7.0; Rtree 1.0.1; ruamel.yaml 0.17.21; ruamel-yaml-conda 0.17.21; s3fs 2023.4.0; safetensors 0.3.2; scikit-image 0.20.0; scikit-learn 1.3.0; scikit-learn-intelex 20230426.111612; scipy 1.11.1; Scrapy 2.8.0; seaborn 0.12.2; SecretStorage 3.3.1; Send2Trash 1.8.0; service-identity 18.1.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 5.2.1; sniffio 1.2.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.4; Sphinx 5.0.2; sphinxcontrib-applehelp 1.0.2; sphinxcontrib-devhelp 1.0.2; sphinxcontrib-htmlhelp 2.0.0; sphinxcontrib-jsmath 1.0.1; sphinxcontrib-qthelp 1.0.3; sphinxcontrib-serializinghtml 1.1.5; spyder 5.4.3; spyder-kernels 2.4.4; SQLAlchemy 1.4.39; stack-data 0.2.0; statsmodels 0.14.0; sympy 1.11.1; tables 3.8.0; tabulate 0.8.10; TBB 0.2; tblib 1.7.0; TELR 1.0; tenacity 8.2.2; terminado 0.17.1; text-unidecode 1.3; textdistance 4.2.1; texttable 1.7.0; threadpoolctl 2.2.0; three-merge 0.1.1; tifffile 2023.4.12; tinycss2 1.2.1; tldextract 3.2.0; t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:715,Testability,mock,mock,715,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Installation using pip & installation from github repository. ### Minimal code sample. ```python; pip install scanpy; ```. ### Error output. ```pytb; Installing collected packages: tbb, distlib, asciitree, stdlib-list, setuptools-scm, pbr, numcodecs, nodeenv, natsort, igraph, identify, filelock, fasteners, docutils, cfgv, array-api-compat, accessible-pygments, zarr, virtualenv, sphinx, session-info, pytest-nunit, pytest-mock, profimp, mdit-py-plugins, leidenalg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryorn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:5873,Testability,log,logger,5873,.1; numexpr 2.8.4; numpy 1.24.3; numpydoc 1.5.0; openpyxl 3.0.10; packaging 23.1; pandas 2.0.3; pandocfilters 1.5.0; panel 1.2.3; param 1.13.0; parsel 1.6.0; parso 0.8.3; partd 1.4.0; pathlib 1.0.1; pathspec 0.10.3; patsy 0.5.3; pep8 1.7.1; pexpect 4.8.0; pickleshare 0.7.5; Pillow 9.4.0; pip 23.2.1; pkce 1.0.3; pkginfo 1.9.6; platformdirs 3.10.0; plotly 5.9.0; pluggy 1.0.0; ply 3.11; poyo 0.5.0; prometheus-client 0.14.1; prompt-toolkit 3.0.36; Protego 0.1.16; psutil 5.9.0; ptyprocess 0.7.0; pure-eval 0.2.2; py-cpuinfo 8.0.0; pyarrow 11.0.0; pyasn1 0.4.8; pyasn1-modules 0.2.8; pycodestyle 2.10.0; pycosat 0.6.4; pycparser 2.21; pyct 0.5.0; pycurl 7.45.2; pydantic 1.10.8; PyDispatcher 2.0.5; pydocstyle 6.3.0; pyerfa 2.0.0; pyflakes 3.0.1; Pygments 2.15.1; PyJWT 2.4.0; pylint 2.16.2; pylint-venv 2.3.0; pyls-spyder 0.4.0; pyodbc 4.0.34; pyOpenSSL 23.2.0; pyparsing 3.0.9; PyQt5-sip 12.11.0; pyrsistent 0.18.0; PySocks 1.7.1; pytest 7.4.0; python-dateutil 2.8.2; python-dotenv 0.21.0; python-json-logger 2.0.7; python-lsp-black 1.2.1; python-lsp-jsonrpc 1.0.0; python-lsp-server 1.7.2; python-slugify 5.0.2; python-snappy 0.6.1; pytoolconfig 1.2.5; pytz 2023.3.post1; pyviz-comms 2.3.0; PyWavelets 1.4.1; pyxdg 0.27; PyYAML 6.0; pyzmq 23.2.0; QDarkStyle 3.0.2; qstylizer 0.2.2; QtAwesome 1.2.2; qtconsole 5.4.2; QtPy 2.2.0; queuelib 1.5.0; regex 2022.7.9; requests 2.31.0; requests-file 1.5.1; requests-toolbelt 1.0.0; responses 0.13.3; rfc3339-validator 0.1.4; rfc3986-validator 0.1.1; rope 1.7.0; Rtree 1.0.1; ruamel.yaml 0.17.21; ruamel-yaml-conda 0.17.21; s3fs 2023.4.0; safetensors 0.3.2; scikit-image 0.20.0; scikit-learn 1.3.0; scikit-learn-intelex 20230426.111612; scipy 1.11.1; Scrapy 2.8.0; seaborn 0.12.2; SecretStorage 3.3.1; Send2Trash 1.8.0; service-identity 18.1.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 5.2.1; sniffio 1.2.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.4; Sphinx 5.0.2; sphinxcontrib-applehelp 1.0.2; sphinxcontrib-devhelp 1.0.2; sp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:923,Usability,learn,learn,923,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Installation using pip & installation from github repository. ### Minimal code sample. ```python; pip install scanpy; ```. ### Error output. ```pytb; Installing collected packages: tbb, distlib, asciitree, stdlib-list, setuptools-scm, pbr, numcodecs, nodeenv, natsort, igraph, identify, filelock, fasteners, docutils, cfgv, array-api-compat, accessible-pygments, zarr, virtualenv, sphinx, session-info, pytest-nunit, pytest-mock, profimp, mdit-py-plugins, leidenalg, sphinxext-opengraph, sphinx-design, sphinx-copybutton, sphinx-autodoc-typehints, scanpydoc, pynndescent, pydata-sphinx-theme, pre-commit, myst-parser, anndata, umap-learn, sphinx-book-theme, jupyter-cache, scanpy, nbsphinx, myst-nb; Attempting uninstall: tbb; Found existing installation: TBB 0.2; ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.; ```. ### Versions. <details>. ```; Package Version; ----------------------------- ---------------; aiobotocore 2.5.0; aiofiles 22.1.0; aiohttp 3.8.5; aioitertools 0.7.1; aiosignal 1.2.0; aiosqlite 0.18.0; alabaster 0.7.12; anaconda-anon-usage 0.4.2; anaconda-catalogs 0.2.0; anaconda-client 1.12.1; anaconda-cloud-auth 0.1.3; anaconda-navigator 2.5.0; anaconda-project 0.11.1; anyio 3.5.0; appdirs 1.4.4; argon2-cffi 21.3.0; argon2-cffi-bindings 21.2.0; arrow 1.2.3; astroid 2.14.2; astropy 5.1; asttokens 2.0.5; async-timeout 4.0.2; atomicwrites 1.4.0; attrs 22.1.0; Automat 20.2.0; autopep8 1.6.0; Babel 2.11.0; backcall 0.2.0; backports.functools-lru-cache 1.6.4; backports.tempfile 1.0; backports.weakref 1.0.post1; bcrypt 3.2.0; beautifulsoup4 4.12.2; binaryorn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:3331,Usability,learn,learn,3331,trust 0.2.0; conda_index 0.3.0; conda-libmamba-solver 23.7.0; conda-pack 0.6.0; conda-package-handling 2.2.0; conda_package_streaming 0.9.0; conda-repo-cli 1.0.75; conda-token 0.4.0; conda-verify 3.4.2; constantly 15.1.0; contourpy 1.0.5; cookiecutter 1.7.3; cryptography 41.0.3; cssselect 1.1.0; cycler 0.11.0; Cython 3.0.3; cytoolz 0.12.0; daal4py 2023.1.1; dask 2023.6.0; datasets 2.12.0; datashader 0.15.2; datashape 0.5.4; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; diff-match-patch 20200713; dill 0.3.6; distributed 2023.6.0; docstring-to-markdown 0.11; docutils 0.18.1; entrypoints 0.4; et-xmlfile 1.1.0; executing 0.8.3; fastjsonschema 2.16.2; filelock 3.9.0; flake8 6.0.0; Flask 2.2.2; fonttools 4.25.0; frozenlist 1.3.3; fsspec 2023.4.0; future 0.18.3; gensim 4.3.0; glob2 0.7; gmpy2 2.1.2; greenlet 2.0.1; h5py 3.9.0; HeapDict 1.0.1; holoviews 1.17.1; huggingface-hub 0.15.1; hvplot 0.8.4; hyperlink 21.0.0; idna 3.4; imagecodecs 2023.1.23; imageio 2.31.1; imagesize 1.4.1; imbalanced-learn 0.10.1; importlib-metadata 6.0.0; incremental 21.3.0; inflection 0.5.1; iniconfig 1.1.1; intake 0.6.8; intervaltree 3.1.0; ipykernel 6.25.0; ipython 8.15.0; ipython-genutils 0.2.0; ipywidgets 8.0.4; isort 5.9.3; itemadapter 0.3.0; itemloaders 1.0.4; itsdangerous 2.0.1; jaraco.classes 3.2.1; jedi 0.18.1; jeepney 0.7.1; jellyfish 1.0.1; Jinja2 3.1.2; jinja2-time 0.2.0; jmespath 0.10.0; joblib 1.2.0; json5 0.9.6; jsonpatch 1.32; jsonpointer 2.1; jsonschema 4.17.3; jupyter 1.0.0; jupyter_client 7.4.9; jupyter-console 6.6.3; jupyter_core 5.3.0; jupyter-events 0.6.3; jupyter-server 1.23.4; jupyter_server_fileid 0.9.0; jupyter_server_ydoc 0.8.0; jupyter-ydoc 0.2.4; jupyterlab 3.6.3; jupyterlab-pygments 0.1.2; jupyterlab_server 2.22.0; jupyterlab-widgets 3.0.5; kaleido 0.2.1; keyring 23.13.1; kiwisolver 1.4.4; lazy_loader 0.2; lazy-object-proxy 1.6.0; libarchive-c 2.9; libmambapy 1.5.1; linkify-it-py 2.0.0; llvmlite 0.40.0; lmdb 1.4.1; locket 1.0.0; lxml 4.9.3; lz4 4.3.2; Markdown 3.4,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:6498,Usability,learn,learn,6498, 2.21; pyct 0.5.0; pycurl 7.45.2; pydantic 1.10.8; PyDispatcher 2.0.5; pydocstyle 6.3.0; pyerfa 2.0.0; pyflakes 3.0.1; Pygments 2.15.1; PyJWT 2.4.0; pylint 2.16.2; pylint-venv 2.3.0; pyls-spyder 0.4.0; pyodbc 4.0.34; pyOpenSSL 23.2.0; pyparsing 3.0.9; PyQt5-sip 12.11.0; pyrsistent 0.18.0; PySocks 1.7.1; pytest 7.4.0; python-dateutil 2.8.2; python-dotenv 0.21.0; python-json-logger 2.0.7; python-lsp-black 1.2.1; python-lsp-jsonrpc 1.0.0; python-lsp-server 1.7.2; python-slugify 5.0.2; python-snappy 0.6.1; pytoolconfig 1.2.5; pytz 2023.3.post1; pyviz-comms 2.3.0; PyWavelets 1.4.1; pyxdg 0.27; PyYAML 6.0; pyzmq 23.2.0; QDarkStyle 3.0.2; qstylizer 0.2.2; QtAwesome 1.2.2; qtconsole 5.4.2; QtPy 2.2.0; queuelib 1.5.0; regex 2022.7.9; requests 2.31.0; requests-file 1.5.1; requests-toolbelt 1.0.0; responses 0.13.3; rfc3339-validator 0.1.4; rfc3986-validator 0.1.1; rope 1.7.0; Rtree 1.0.1; ruamel.yaml 0.17.21; ruamel-yaml-conda 0.17.21; s3fs 2023.4.0; safetensors 0.3.2; scikit-image 0.20.0; scikit-learn 1.3.0; scikit-learn-intelex 20230426.111612; scipy 1.11.1; Scrapy 2.8.0; seaborn 0.12.2; SecretStorage 3.3.1; Send2Trash 1.8.0; service-identity 18.1.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 5.2.1; sniffio 1.2.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.4; Sphinx 5.0.2; sphinxcontrib-applehelp 1.0.2; sphinxcontrib-devhelp 1.0.2; sphinxcontrib-htmlhelp 2.0.0; sphinxcontrib-jsmath 1.0.1; sphinxcontrib-qthelp 1.0.3; sphinxcontrib-serializinghtml 1.1.5; spyder 5.4.3; spyder-kernels 2.4.4; SQLAlchemy 1.4.39; stack-data 0.2.0; statsmodels 0.14.0; sympy 1.11.1; tables 3.8.0; tabulate 0.8.10; TBB 0.2; tblib 1.7.0; TELR 1.0; tenacity 8.2.2; terminado 0.17.1; text-unidecode 1.3; textdistance 4.2.1; texttable 1.7.0; threadpoolctl 2.2.0; three-merge 0.1.1; tifffile 2023.4.12; tinycss2 1.2.1; tldextract 3.2.0; tokenizers 0.13.2; toml 0.10.2; tomlkit 0.11.1; toolz 0.12.0; tornado 6.3.2; tqdm 4.65.0; traitlets 5.7.1; transformers 4.32.1; Twisted 22.10.0; typing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/issues/2706:6518,Usability,learn,learn-intelex,6518,.45.2; pydantic 1.10.8; PyDispatcher 2.0.5; pydocstyle 6.3.0; pyerfa 2.0.0; pyflakes 3.0.1; Pygments 2.15.1; PyJWT 2.4.0; pylint 2.16.2; pylint-venv 2.3.0; pyls-spyder 0.4.0; pyodbc 4.0.34; pyOpenSSL 23.2.0; pyparsing 3.0.9; PyQt5-sip 12.11.0; pyrsistent 0.18.0; PySocks 1.7.1; pytest 7.4.0; python-dateutil 2.8.2; python-dotenv 0.21.0; python-json-logger 2.0.7; python-lsp-black 1.2.1; python-lsp-jsonrpc 1.0.0; python-lsp-server 1.7.2; python-slugify 5.0.2; python-snappy 0.6.1; pytoolconfig 1.2.5; pytz 2023.3.post1; pyviz-comms 2.3.0; PyWavelets 1.4.1; pyxdg 0.27; PyYAML 6.0; pyzmq 23.2.0; QDarkStyle 3.0.2; qstylizer 0.2.2; QtAwesome 1.2.2; qtconsole 5.4.2; QtPy 2.2.0; queuelib 1.5.0; regex 2022.7.9; requests 2.31.0; requests-file 1.5.1; requests-toolbelt 1.0.0; responses 0.13.3; rfc3339-validator 0.1.4; rfc3986-validator 0.1.1; rope 1.7.0; Rtree 1.0.1; ruamel.yaml 0.17.21; ruamel-yaml-conda 0.17.21; s3fs 2023.4.0; safetensors 0.3.2; scikit-image 0.20.0; scikit-learn 1.3.0; scikit-learn-intelex 20230426.111612; scipy 1.11.1; Scrapy 2.8.0; seaborn 0.12.2; SecretStorage 3.3.1; Send2Trash 1.8.0; service-identity 18.1.0; setuptools 68.0.0; sip 6.6.2; six 1.16.0; smart-open 5.2.1; sniffio 1.2.0; snowballstemmer 2.2.0; sortedcontainers 2.4.0; soupsieve 2.4; Sphinx 5.0.2; sphinxcontrib-applehelp 1.0.2; sphinxcontrib-devhelp 1.0.2; sphinxcontrib-htmlhelp 2.0.0; sphinxcontrib-jsmath 1.0.1; sphinxcontrib-qthelp 1.0.3; sphinxcontrib-serializinghtml 1.1.5; spyder 5.4.3; spyder-kernels 2.4.4; SQLAlchemy 1.4.39; stack-data 0.2.0; statsmodels 0.14.0; sympy 1.11.1; tables 3.8.0; tabulate 0.8.10; TBB 0.2; tblib 1.7.0; TELR 1.0; tenacity 8.2.2; terminado 0.17.1; text-unidecode 1.3; textdistance 4.2.1; texttable 1.7.0; threadpoolctl 2.2.0; three-merge 0.1.1; tifffile 2023.4.12; tinycss2 1.2.1; tldextract 3.2.0; tokenizers 0.13.2; toml 0.10.2; tomlkit 0.11.1; toolz 0.12.0; tornado 6.3.2; tqdm 4.65.0; traitlets 5.7.1; transformers 4.32.1; Twisted 22.10.0; typing_extensions 4.7.1; tzdata 20,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2706
https://github.com/scverse/scanpy/pull/2707:433,Deployability,release,release,433,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: dev process; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev process,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2707
https://github.com/scverse/scanpy/pull/2707:458,Deployability,Release,Release,458,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: dev process; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev process,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2707
https://github.com/scverse/scanpy/pull/2707:323,Testability,Test,Tests,323,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: dev process; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev process,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2707
https://github.com/scverse/scanpy/pull/2707:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: dev process; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev process,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2707
https://github.com/scverse/scanpy/pull/2707:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: dev process; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev process,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2707
https://github.com/scverse/scanpy/issues/2736:179,Integrability,depend,depending,179,"### Please describe your wishes and possible alternatives to achieve the desired result. No key inside 'use_rep' can mean 'X' or 'X_pca' was used for nearest neighbor calculation depending on the number of vars. It's storing things correctly if 'use_rep' is called explicitly. ```py; sc.pp.neighbors(combined_emb, n_neighbors=50); combined_emb.uns[""neighbors""][""params""][""use_rep""] -> KeyError. sc.pp.neighbors(combined_emb, n_neighbors=50, use_rep='X'); combined_emb.uns[""neighbors""][""params""][""use_rep""] -> 'X'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2736
https://github.com/scverse/scanpy/pull/2709:418,Deployability,release,release,418,"Can you give a dict of deprecated functions and there new analogues?; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. <!-- Please check (- [x]) and fill in the following boxes -->; - [ x] Closes #2505 ; - [x ] Tests included or not required because:; Didn't add decorator to any function(don't know which are deprecated); <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2709
https://github.com/scverse/scanpy/pull/2709:443,Deployability,Release,Release,443,"Can you give a dict of deprecated functions and there new analogues?; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. <!-- Please check (- [x]) and fill in the following boxes -->; - [ x] Closes #2505 ; - [x ] Tests included or not required because:; Didn't add decorator to any function(don't know which are deprecated); <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2709
https://github.com/scverse/scanpy/pull/2709:249,Testability,Test,Tests,249,"Can you give a dict of deprecated functions and there new analogues?; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. <!-- Please check (- [x]) and fill in the following boxes -->; - [ x] Closes #2505 ; - [x ] Tests included or not required because:; Didn't add decorator to any function(don't know which are deprecated); <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2709
https://github.com/scverse/scanpy/pull/2710:416,Deployability,release,release,416,"Can you give a dict of deprecated functions and there new analogues?; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2505 ; - [x] Tests included or not required because:; Didn't add decorator to any function(don't know which are deprecated); <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2710
https://github.com/scverse/scanpy/pull/2710:441,Deployability,Release,Release,441,"Can you give a dict of deprecated functions and there new analogues?; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2505 ; - [x] Tests included or not required because:; Didn't add decorator to any function(don't know which are deprecated); <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2710
https://github.com/scverse/scanpy/pull/2710:247,Testability,Test,Tests,247,"Can you give a dict of deprecated functions and there new analogues?; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2505 ; - [x] Tests included or not required because:; Didn't add decorator to any function(don't know which are deprecated); <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2710
https://github.com/scverse/scanpy/pull/2711:416,Deployability,release,release,416,"Can you give a dict of deprecated functions and there new analogues?; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2505 ; - [x] Tests included or not required because:; Didn't add decorator to any function(don't know which are deprecated); <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2711
https://github.com/scverse/scanpy/pull/2711:441,Deployability,Release,Release,441,"Can you give a dict of deprecated functions and there new analogues?; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2505 ; - [x] Tests included or not required because:; Didn't add decorator to any function(don't know which are deprecated); <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2711
https://github.com/scverse/scanpy/pull/2711:247,Testability,Test,Tests,247,"Can you give a dict of deprecated functions and there new analogues?; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2505 ; - [x] Tests included or not required because:; Didn't add decorator to any function(don't know which are deprecated); <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because:; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2711
https://github.com/scverse/scanpy/issues/2712:1083,Usability,clear,clear,1083,"### What kind of feature would you like to request?. Additional function parameters / changed functionality / changed defaults?. ### Please describe your wishes. Hi!. I've been playing around with the add_totals method for dotplot. ; My general issue is that the labels on the barplots showing the number of cells per group is slightly covered by the barplot/too far to the left.; ![image](https://github.com/scverse/scanpy/assets/64251655/d958f7f9-dad7-4d77-8990-6012be58fd2c). I think this could be fixed by changing `ha=""center""` to `ha=""left""` in the _plot_totals function; https://github.com/scverse/scanpy/blob/ec7f92524e6269e9c7370fc94c53ba04230b0bca/scanpy/plotting/_baseplot_class.py#L481. ![image](https://github.com/scverse/scanpy/assets/64251655/009cba65-79d1-4cf7-8de0-3eb2ca4857ce); and then possibly moving the axes of the legends further to the right:; ![image](https://github.com/scverse/scanpy/assets/64251655/666f9821-5f09-4113-bedf-1e9c1c971a27); I'm moving the axis manually, but it would be nice for it to automatically to move the axis, so that it is always a clear visualization.; ```; size_legend_ax = dp.get_axes()[""size_legend_ax""]; size_pos = size_legend_ax.get_position(); size_legend_ax.set_position([size_pos.x0 + 0.05, size_pos.y0, size_pos.width, size_pos.height]). color_legend_ax = dp.get_axes()[""color_legend_ax""]; color_pos = color_legend_ax.get_position(); color_legend_ax.set_position([color_pos.x0 + 0.05, color_pos.y0 - 0.05, color_pos.width, color_pos.height]); ```. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2712
https://github.com/scverse/scanpy/pull/2713:426,Deployability,release,release,426,"Can you give a dict of deprecated functions and there new analogues? ; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. ; ; ; <!-- Please check (- [x]) and fill in the following boxes --> ; - [x] Closes #2505 ; - [x] Tests included or not required because: ; Didn't add decorator to any function(don't know which are deprecated) ; <!-- Only check the following box if you did not include release notes --> ; - [x] Release notes not necessary because: ; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2713
https://github.com/scverse/scanpy/pull/2713:452,Deployability,Release,Release,452,"Can you give a dict of deprecated functions and there new analogues? ; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. ; ; ; <!-- Please check (- [x]) and fill in the following boxes --> ; - [x] Closes #2505 ; - [x] Tests included or not required because: ; Didn't add decorator to any function(don't know which are deprecated) ; <!-- Only check the following box if you did not include release notes --> ; - [x] Release notes not necessary because: ; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2713
https://github.com/scverse/scanpy/pull/2713:255,Testability,Test,Tests,255,"Can you give a dict of deprecated functions and there new analogues? ; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. ; ; ; <!-- Please check (- [x]) and fill in the following boxes --> ; - [x] Closes #2505 ; - [x] Tests included or not required because: ; Didn't add decorator to any function(don't know which are deprecated) ; <!-- Only check the following box if you did not include release notes --> ; - [x] Release notes not necessary because: ; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2713
https://github.com/scverse/scanpy/pull/2714:426,Deployability,release,release,426,"Can you give a dict of deprecated functions and there new analogues? ; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. ; ; ; <!-- Please check (- [x]) and fill in the following boxes --> ; - [x] Closes #2505 ; - [x] Tests included or not required because: ; Didn't add decorator to any function(don't know which are deprecated) ; <!-- Only check the following box if you did not include release notes --> ; - [x] Release notes not necessary because: ; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2714
https://github.com/scverse/scanpy/pull/2714:452,Deployability,Release,Release,452,"Can you give a dict of deprecated functions and there new analogues? ; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. ; ; ; <!-- Please check (- [x]) and fill in the following boxes --> ; - [x] Closes #2505 ; - [x] Tests included or not required because: ; Didn't add decorator to any function(don't know which are deprecated) ; <!-- Only check the following box if you did not include release notes --> ; - [x] Release notes not necessary because: ; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2714
https://github.com/scverse/scanpy/pull/2714:255,Testability,Test,Tests,255,"Can you give a dict of deprecated functions and there new analogues? ; Then we can add f""Use {new_func[deprecated_func]} instead."" for raise FutureWarning. ; ; ; <!-- Please check (- [x]) and fill in the following boxes --> ; - [x] Closes #2505 ; - [x] Tests included or not required because: ; Didn't add decorator to any function(don't know which are deprecated) ; <!-- Only check the following box if you did not include release notes --> ; - [x] Release notes not necessary because: ; Too small issue",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2714
https://github.com/scverse/scanpy/pull/2715:421,Deployability,release,release,421,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: improves an earlier unreleased change. For some reason, PyNNDescent takes >2s to import: https://github.com/lmcinnes/pynndescent/issues/111. This change makes e.g. test collection fast again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2715
https://github.com/scverse/scanpy/pull/2715:446,Deployability,Release,Release,446,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: improves an earlier unreleased change. For some reason, PyNNDescent takes >2s to import: https://github.com/lmcinnes/pynndescent/issues/111. This change makes e.g. test collection fast again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2715
https://github.com/scverse/scanpy/pull/2715:323,Testability,Test,Tests,323,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: improves an earlier unreleased change. For some reason, PyNNDescent takes >2s to import: https://github.com/lmcinnes/pynndescent/issues/111. This change makes e.g. test collection fast again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2715
https://github.com/scverse/scanpy/pull/2715:647,Testability,test,test,647,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: improves an earlier unreleased change. For some reason, PyNNDescent takes >2s to import: https://github.com/lmcinnes/pynndescent/issues/111. This change makes e.g. test collection fast again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2715
https://github.com/scverse/scanpy/pull/2715:71,Usability,guid,guidelines,71,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: improves an earlier unreleased change. For some reason, PyNNDescent takes >2s to import: https://github.com/lmcinnes/pynndescent/issues/111. This change makes e.g. test collection fast again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2715
https://github.com/scverse/scanpy/pull/2715:102,Usability,guid,guide,102,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: improves an earlier unreleased change. For some reason, PyNNDescent takes >2s to import: https://github.com/lmcinnes/pynndescent/issues/111. This change makes e.g. test collection fast again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2715
https://github.com/scverse/scanpy/pull/2716:490,Deployability,release,release,490,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A (infra change for other PRs touching `external`); - [x] Tests included or not required because: works if docs build; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: see above. Adds link targets for `scanpy.external.{pp,tl,pl,}` like they exist for `scanpy.{pp,tl,pl,}`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2716
https://github.com/scverse/scanpy/pull/2716:515,Deployability,Release,Release,515,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A (infra change for other PRs touching `external`); - [x] Tests included or not required because: works if docs build; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: see above. Adds link targets for `scanpy.external.{pp,tl,pl,}` like they exist for `scanpy.{pp,tl,pl,}`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2716
https://github.com/scverse/scanpy/pull/2716:372,Testability,Test,Tests,372,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A (infra change for other PRs touching `external`); - [x] Tests included or not required because: works if docs build; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: see above. Adds link targets for `scanpy.external.{pp,tl,pl,}` like they exist for `scanpy.{pp,tl,pl,}`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2716
https://github.com/scverse/scanpy/pull/2716:71,Usability,guid,guidelines,71,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A (infra change for other PRs touching `external`); - [x] Tests included or not required because: works if docs build; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: see above. Adds link targets for `scanpy.external.{pp,tl,pl,}` like they exist for `scanpy.{pp,tl,pl,}`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2716
https://github.com/scverse/scanpy/pull/2716:102,Usability,guid,guide,102,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A (infra change for other PRs touching `external`); - [x] Tests included or not required because: works if docs build; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: see above. Adds link targets for `scanpy.external.{pp,tl,pl,}` like they exist for `scanpy.{pp,tl,pl,}`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2716
https://github.com/scverse/scanpy/issues/2717:329,Integrability,message,message,329,"External has outlived its usefulness with the emergence of the scverse ecosystem, and should be removed. ^ This text should be expanded. # TODO. - [ ] Finalize methods to keep/ merge into main namespace; - Currently: `scanorama`, `hashsolo`, `scrublet` or equivalent, maybe `bbknn`; - [ ] Make removal plan (probably deprecation message + maybe email to authors) for; - [ ] `harmony`; - [ ] `dca`; - [ ] `magic`; - [ ] `phate`; - [ ] `palantir`; - [ ] `trimap`; - [ ] `sam`; - [ ] `phenograph`; - [ ] `wishbone`; - [ ] `sandbag`; - [ ] `cyclone`; - [ ] Export functionality for; - [ ] `spring_project`; - [ ] `cellbrowser`. ```[tasklist]; ### Sub-issues; - [ ] #173; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2717
https://github.com/scverse/scanpy/issues/2717:231,Security,hash,hashsolo,231,"External has outlived its usefulness with the emergence of the scverse ecosystem, and should be removed. ^ This text should be expanded. # TODO. - [ ] Finalize methods to keep/ merge into main namespace; - Currently: `scanorama`, `hashsolo`, `scrublet` or equivalent, maybe `bbknn`; - [ ] Make removal plan (probably deprecation message + maybe email to authors) for; - [ ] `harmony`; - [ ] `dca`; - [ ] `magic`; - [ ] `phate`; - [ ] `palantir`; - [ ] `trimap`; - [ ] `sam`; - [ ] `phenograph`; - [ ] `wishbone`; - [ ] `sandbag`; - [ ] `cyclone`; - [ ] Export functionality for; - [ ] `spring_project`; - [ ] `cellbrowser`. ```[tasklist]; ### Sub-issues; - [ ] #173; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2717
https://github.com/scverse/scanpy/pull/2718:435,Deployability,release,release,435,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: format change; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: format change,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718
https://github.com/scverse/scanpy/pull/2718:460,Deployability,Release,Release,460,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: format change; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: format change,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718
https://github.com/scverse/scanpy/pull/2718:323,Testability,Test,Tests,323,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: format change; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: format change,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718
https://github.com/scverse/scanpy/pull/2718:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: format change; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: format change,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718
https://github.com/scverse/scanpy/pull/2718:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: format change; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: format change,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2718
https://github.com/scverse/scanpy/pull/2719:464,Deployability,release,release,464,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes https://github.com/scverse/anndata/issues/1210; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2719
https://github.com/scverse/scanpy/pull/2719:489,Deployability,Release,Release,489,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes https://github.com/scverse/anndata/issues/1210; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2719
https://github.com/scverse/scanpy/pull/2719:366,Testability,Test,Tests,366,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes https://github.com/scverse/anndata/issues/1210; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2719
https://github.com/scverse/scanpy/pull/2719:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes https://github.com/scverse/anndata/issues/1210; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2719
https://github.com/scverse/scanpy/pull/2719:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes https://github.com/scverse/anndata/issues/1210; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2719
https://github.com/scverse/scanpy/pull/2720:960,Availability,down,down,960,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2644; - [x] Tests included or not required because: dev workflow; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev workflow. Very simple, following https://docs.pypi.org/trusted-publishers/adding-a-publisher/. The change removes most of the technical parts of making a release including `twine check` which is just done by default by the GH action. The only parts Im not 100% sure about removing are; - When to make a pre-release  I feel like if UR unsure, make one of these wasnt helping here either, so maybe that should just be fleshed out as a section now were down a few sections; - Check the file contents of the wheel should probably go into how to code review a PR that touches the build process, and we dont have any other guides on how to do code reviews, so ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720
https://github.com/scverse/scanpy/pull/2720:436,Deployability,release,release,436,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2644; - [x] Tests included or not required because: dev workflow; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev workflow. Very simple, following https://docs.pypi.org/trusted-publishers/adding-a-publisher/. The change removes most of the technical parts of making a release including `twine check` which is just done by default by the GH action. The only parts Im not 100% sure about removing are; - When to make a pre-release  I feel like if UR unsure, make one of these wasnt helping here either, so maybe that should just be fleshed out as a section now were down a few sections; - Check the file contents of the wheel should probably go into how to code review a PR that touches the build process, and we dont have any other guides on how to do code reviews, so ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720
https://github.com/scverse/scanpy/pull/2720:461,Deployability,Release,Release,461,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2644; - [x] Tests included or not required because: dev workflow; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev workflow. Very simple, following https://docs.pypi.org/trusted-publishers/adding-a-publisher/. The change removes most of the technical parts of making a release including `twine check` which is just done by default by the GH action. The only parts Im not 100% sure about removing are; - When to make a pre-release  I feel like if UR unsure, make one of these wasnt helping here either, so maybe that should just be fleshed out as a section now were down a few sections; - Check the file contents of the wheel should probably go into how to code review a PR that touches the build process, and we dont have any other guides on how to do code reviews, so ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720
https://github.com/scverse/scanpy/pull/2720:656,Deployability,release,release,656,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2644; - [x] Tests included or not required because: dev workflow; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev workflow. Very simple, following https://docs.pypi.org/trusted-publishers/adding-a-publisher/. The change removes most of the technical parts of making a release including `twine check` which is just done by default by the GH action. The only parts Im not 100% sure about removing are; - When to make a pre-release  I feel like if UR unsure, make one of these wasnt helping here either, so maybe that should just be fleshed out as a section now were down a few sections; - Check the file contents of the wheel should probably go into how to code review a PR that touches the build process, and we dont have any other guides on how to do code reviews, so ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720
https://github.com/scverse/scanpy/pull/2720:811,Deployability,release,release,811,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2644; - [x] Tests included or not required because: dev workflow; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev workflow. Very simple, following https://docs.pypi.org/trusted-publishers/adding-a-publisher/. The change removes most of the technical parts of making a release including `twine check` which is just done by default by the GH action. The only parts Im not 100% sure about removing are; - When to make a pre-release  I feel like if UR unsure, make one of these wasnt helping here either, so maybe that should just be fleshed out as a section now were down a few sections; - Check the file contents of the wheel should probably go into how to code review a PR that touches the build process, and we dont have any other guides on how to do code reviews, so ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720
https://github.com/scverse/scanpy/pull/2720:325,Testability,Test,Tests,325,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2644; - [x] Tests included or not required because: dev workflow; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev workflow. Very simple, following https://docs.pypi.org/trusted-publishers/adding-a-publisher/. The change removes most of the technical parts of making a release including `twine check` which is just done by default by the GH action. The only parts Im not 100% sure about removing are; - When to make a pre-release  I feel like if UR unsure, make one of these wasnt helping here either, so maybe that should just be fleshed out as a section now were down a few sections; - Check the file contents of the wheel should probably go into how to code review a PR that touches the build process, and we dont have any other guides on how to do code reviews, so ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720
https://github.com/scverse/scanpy/pull/2720:71,Usability,guid,guidelines,71,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2644; - [x] Tests included or not required because: dev workflow; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev workflow. Very simple, following https://docs.pypi.org/trusted-publishers/adding-a-publisher/. The change removes most of the technical parts of making a release including `twine check` which is just done by default by the GH action. The only parts Im not 100% sure about removing are; - When to make a pre-release  I feel like if UR unsure, make one of these wasnt helping here either, so maybe that should just be fleshed out as a section now were down a few sections; - Check the file contents of the wheel should probably go into how to code review a PR that touches the build process, and we dont have any other guides on how to do code reviews, so ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720
https://github.com/scverse/scanpy/pull/2720:102,Usability,guid,guide,102,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2644; - [x] Tests included or not required because: dev workflow; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev workflow. Very simple, following https://docs.pypi.org/trusted-publishers/adding-a-publisher/. The change removes most of the technical parts of making a release including `twine check` which is just done by default by the GH action. The only parts Im not 100% sure about removing are; - When to make a pre-release  I feel like if UR unsure, make one of these wasnt helping here either, so maybe that should just be fleshed out as a section now were down a few sections; - Check the file contents of the wheel should probably go into how to code review a PR that touches the build process, and we dont have any other guides on how to do code reviews, so ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720
https://github.com/scverse/scanpy/pull/2720:517,Usability,simpl,simple,517,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2644; - [x] Tests included or not required because: dev workflow; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev workflow. Very simple, following https://docs.pypi.org/trusted-publishers/adding-a-publisher/. The change removes most of the technical parts of making a release including `twine check` which is just done by default by the GH action. The only parts Im not 100% sure about removing are; - When to make a pre-release  I feel like if UR unsure, make one of these wasnt helping here either, so maybe that should just be fleshed out as a section now were down a few sections; - Check the file contents of the wheel should probably go into how to code review a PR that touches the build process, and we dont have any other guides on how to do code reviews, so ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720
https://github.com/scverse/scanpy/pull/2720:1132,Usability,guid,guides,1132,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2644; - [x] Tests included or not required because: dev workflow; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev workflow. Very simple, following https://docs.pypi.org/trusted-publishers/adding-a-publisher/. The change removes most of the technical parts of making a release including `twine check` which is just done by default by the GH action. The only parts Im not 100% sure about removing are; - When to make a pre-release  I feel like if UR unsure, make one of these wasnt helping here either, so maybe that should just be fleshed out as a section now were down a few sections; - Check the file contents of the wheel should probably go into how to code review a PR that touches the build process, and we dont have any other guides on how to do code reviews, so ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2720
https://github.com/scverse/scanpy/pull/2722:23,Deployability,release,release,23,Backport PR #2720: Add release workflow,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2722
https://github.com/scverse/scanpy/pull/2724:363,Deployability,release,release,363,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: release prep; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2724
https://github.com/scverse/scanpy/pull/2724:434,Deployability,release,release,434,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: release prep; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2724
https://github.com/scverse/scanpy/pull/2724:459,Deployability,Release,Release,459,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: release prep; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2724
https://github.com/scverse/scanpy/pull/2724:323,Testability,Test,Tests,323,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: release prep; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2724
https://github.com/scverse/scanpy/pull/2724:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: release prep; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2724
https://github.com/scverse/scanpy/pull/2724:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: release prep; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2724
https://github.com/scverse/scanpy/pull/2725:33,Deployability,release,release,33,Backport PR #2724: Prepare 1.9.6 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2725
https://github.com/scverse/scanpy/pull/2726:363,Deployability,Release,Release,363,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: Release documentation; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2726
https://github.com/scverse/scanpy/pull/2726:443,Deployability,release,release,443,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: Release documentation; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2726
https://github.com/scverse/scanpy/pull/2726:468,Deployability,Release,Release,468,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: Release documentation; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2726
https://github.com/scverse/scanpy/pull/2726:323,Testability,Test,Tests,323,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: Release documentation; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2726
https://github.com/scverse/scanpy/pull/2726:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: Release documentation; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2726
https://github.com/scverse/scanpy/pull/2726:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: Release documentation; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2726
https://github.com/scverse/scanpy/pull/2727:433,Deployability,release,release,433,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: dev process; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev process. Filt resulted in the release workflow failing, as it tries to install the packages runtime dependencies. Backporting the switch to hatch fixes that, now building only needs build deps",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2727
https://github.com/scverse/scanpy/pull/2727:458,Deployability,Release,Release,458,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: dev process; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev process. Filt resulted in the release workflow failing, as it tries to install the packages runtime dependencies. Backporting the switch to hatch fixes that, now building only needs build deps",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2727
https://github.com/scverse/scanpy/pull/2727:529,Deployability,release,release,529,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: dev process; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev process. Filt resulted in the release workflow failing, as it tries to install the packages runtime dependencies. Backporting the switch to hatch fixes that, now building only needs build deps",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2727
https://github.com/scverse/scanpy/pull/2727:570,Deployability,install,install,570,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: dev process; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev process. Filt resulted in the release workflow failing, as it tries to install the packages runtime dependencies. Backporting the switch to hatch fixes that, now building only needs build deps",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2727
https://github.com/scverse/scanpy/pull/2727:600,Integrability,depend,dependencies,600,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: dev process; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev process. Filt resulted in the release workflow failing, as it tries to install the packages runtime dependencies. Backporting the switch to hatch fixes that, now building only needs build deps",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2727
https://github.com/scverse/scanpy/pull/2727:323,Testability,Test,Tests,323,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: dev process; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev process. Filt resulted in the release workflow failing, as it tries to install the packages runtime dependencies. Backporting the switch to hatch fixes that, now building only needs build deps",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2727
https://github.com/scverse/scanpy/pull/2727:71,Usability,guid,guidelines,71,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: dev process; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev process. Filt resulted in the release workflow failing, as it tries to install the packages runtime dependencies. Backporting the switch to hatch fixes that, now building only needs build deps",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2727
https://github.com/scverse/scanpy/pull/2727:102,Usability,guid,guide,102,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: dev process; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: dev process. Filt resulted in the release workflow failing, as it tries to install the packages runtime dependencies. Backporting the switch to hatch fixes that, now building only needs build deps",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2727
https://github.com/scverse/scanpy/pull/2728:421,Deployability,release,release,421,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2728
https://github.com/scverse/scanpy/pull/2728:446,Deployability,Release,Release,446,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2728
https://github.com/scverse/scanpy/pull/2728:323,Testability,Test,Tests,323,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2728
https://github.com/scverse/scanpy/pull/2728:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2728
https://github.com/scverse/scanpy/pull/2728:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2728
https://github.com/scverse/scanpy/issues/2729:94,Integrability,Depend,Depends,94,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. Depends on. - https://github.com/scientific-python/pytest-doctestplus/issues/229; - https://github.com/scientific-python/pytest-doctestplus/issues/231; - https://github.com/pytest-dev/pytest/issues/11475; - And after that one has been fixed, Im sure doctestplus also needs to adjust to it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2729
https://github.com/scverse/scanpy/issues/2730:498,Availability,error,error,498,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. RGBA colors that are provided as tuples or lists in `adata.uns[f""{key}_colors""]` are converted to numpy arrays when saving and loading the adata. This leads plots (e.g. `pl.pca` or `pl.umap`) to run into an error (see below). ### Minimal code sample. ```python; adata = sc.datasets.pbmc3k_processed(); adata = adata[adata.obs[""louvain""].isin([""Dendritic cells"",""Megakaryocytes""])].copy(); adata.uns[""louvain_colors""] = [[1, 0, 0, 1], [0, 0, 1, 1]] # or [(1, 0, 0, 1), (0, 0, 1, 1)]; sc.pl.pca(adata, color=""louvain""). adata.write(""./data/pbmc3k_processed_rgba.h5ad""). adata = sc.read(""./data/pbmc3k_processed_rgba.h5ad""); print(type(adata.uns[""louvain_colors""][0])) # --> numpy.ndarray; sc.pl.pca(adata, color=""louvain""); ```. ### Error output. ```pytb; ValueError Traceback (most recent call last); ...; 8 adata = sc.read(""./data/pbmc3k_processed_rgba.h5ad""); 9 print(type(adata.uns[""louvain_colors""][0])) # --> numpy.ndarray; ---> 10 sc.pl.pca(adata, color=""louvain""). File ~/opt/anaconda3/envs/sc_test/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:893, in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 845 """"""\; 846 Scatter plot in PCA coordinates.; 847 ; (...); 890 pp.pca; 891 """"""; 892 if not annotate_var_explained:; --> 893 return embedding(; 894 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 895 ); 896 else:; 897 if 'pca' not in adata.obsm.keys() and 'X_pca' not in adata.obsm.keys():. File ~/opt/anaconda3/envs/sc_test/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:267, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2730
https://github.com/scverse/scanpy/issues/2730:1022,Availability,Error,Error,1022," conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. RGBA colors that are provided as tuples or lists in `adata.uns[f""{key}_colors""]` are converted to numpy arrays when saving and loading the adata. This leads plots (e.g. `pl.pca` or `pl.umap`) to run into an error (see below). ### Minimal code sample. ```python; adata = sc.datasets.pbmc3k_processed(); adata = adata[adata.obs[""louvain""].isin([""Dendritic cells"",""Megakaryocytes""])].copy(); adata.uns[""louvain_colors""] = [[1, 0, 0, 1], [0, 0, 1, 1]] # or [(1, 0, 0, 1), (0, 0, 1, 1)]; sc.pl.pca(adata, color=""louvain""). adata.write(""./data/pbmc3k_processed_rgba.h5ad""). adata = sc.read(""./data/pbmc3k_processed_rgba.h5ad""); print(type(adata.uns[""louvain_colors""][0])) # --> numpy.ndarray; sc.pl.pca(adata, color=""louvain""); ```. ### Error output. ```pytb; ValueError Traceback (most recent call last); ...; 8 adata = sc.read(""./data/pbmc3k_processed_rgba.h5ad""); 9 print(type(adata.uns[""louvain_colors""][0])) # --> numpy.ndarray; ---> 10 sc.pl.pca(adata, color=""louvain""). File ~/opt/anaconda3/envs/sc_test/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:893, in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 845 """"""\; 846 Scatter plot in PCA coordinates.; 847 ; (...); 890 pp.pca; 891 """"""; 892 if not annotate_var_explained:; --> 893 return embedding(; 894 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 895 ); 896 else:; 897 if 'pca' not in adata.obsm.keys() and 'X_pca' not in adata.obsm.keys():. File ~/opt/anaconda3/envs/sc_test/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:267, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimens",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2730
https://github.com/scverse/scanpy/issues/2730:5244,Deployability,update,updated,5244,"lor_map)). File ~/opt/anaconda3/envs/sc_test/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:1214, in _get_palette(adata, values_key, palette); 1212 _utils._set_default_colors_for_categorical_obs(adata, values_key); 1213 else:; -> 1214 _utils._validate_palette(adata, values_key); 1215 return dict(zip(values.categories, adata.uns[color_key])). File ~/opt/anaconda3/envs/sc_test/lib/python3.11/site-packages/scanpy/plotting/_utils.py:357, in _validate_palette(adata, key); 355 _palette.append(color); 356 # Don't modify if nothing changed; --> 357 if _palette is not None and list(_palette) != list(adata.uns[color_key]):; 358 adata.uns[color_key] = _palette. ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); ```. ### Versions. <details>. ```; -----; anndata 0.10.3; scanpy 1.9.6; -----; PIL 10.1.0; appnope 0.1.3; asttokens NA; comm 0.1.4; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.8.0; decorator 5.1.1; executing 2.0.1; h5py 3.10.0; ipykernel 6.26.0; jedi 0.19.1; joblib 1.3.2; kiwisolver 1.4.5; llvmlite 0.41.1; matplotlib 3.8.1; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.58.1; numpy 1.26.1; packaging 23.2; pandas 2.1.1; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; platformdirs 3.11.0; prompt_toolkit 3.0.39; psutil 5.9.5; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.16.1; pyparsing 3.1.1; pytz 2023.3.post1; scipy 1.11.3; session_info 1.0.0; six 1.16.0; sklearn 1.3.2; stack_data 0.6.2; threadpoolctl 3.2.0; tornado 6.3.3; tqdm 4.66.1; traitlets 5.13.0; typing_extensions NA; wcwidth 0.2.9; zmq 25.1.1; -----; IPython 8.17.2; jupyter_client 8.5.0; jupyter_core 5.5.0; -----; Python 3.11.6 | packaged by conda-forge | (main, Oct 3 2023, 10:40:37) [Clang 15.0.7 ]; macOS-14.0-x86_64-i386-64bit; -----; Session information updated at 2023-11-03 17:57; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2730
https://github.com/scverse/scanpy/issues/2730:418,Performance,load,loading,418,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. RGBA colors that are provided as tuples or lists in `adata.uns[f""{key}_colors""]` are converted to numpy arrays when saving and loading the adata. This leads plots (e.g. `pl.pca` or `pl.umap`) to run into an error (see below). ### Minimal code sample. ```python; adata = sc.datasets.pbmc3k_processed(); adata = adata[adata.obs[""louvain""].isin([""Dendritic cells"",""Megakaryocytes""])].copy(); adata.uns[""louvain_colors""] = [[1, 0, 0, 1], [0, 0, 1, 1]] # or [(1, 0, 0, 1), (0, 0, 1, 1)]; sc.pl.pca(adata, color=""louvain""). adata.write(""./data/pbmc3k_processed_rgba.h5ad""). adata = sc.read(""./data/pbmc3k_processed_rgba.h5ad""); print(type(adata.uns[""louvain_colors""][0])) # --> numpy.ndarray; sc.pl.pca(adata, color=""louvain""); ```. ### Error output. ```pytb; ValueError Traceback (most recent call last); ...; 8 adata = sc.read(""./data/pbmc3k_processed_rgba.h5ad""); 9 print(type(adata.uns[""louvain_colors""][0])) # --> numpy.ndarray; ---> 10 sc.pl.pca(adata, color=""louvain""). File ~/opt/anaconda3/envs/sc_test/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:893, in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 845 """"""\; 846 Scatter plot in PCA coordinates.; 847 ; (...); 890 pp.pca; 891 """"""; 892 if not annotate_var_explained:; --> 893 return embedding(; 894 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 895 ); 896 else:; 897 if 'pca' not in adata.obsm.keys() and 'X_pca' not in adata.obsm.keys():. File ~/opt/anaconda3/envs/sc_test/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:267, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2730
https://github.com/scverse/scanpy/pull/2731:643,Deployability,release,release,643,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Added the boolean argument ""add_intercept"" to regress_out, and implemented code to optionally add the intercept back to the residuals in the result of regress_out().; <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes https://github.com/theislab/single-cell-tutorial/issues/35; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2731
https://github.com/scverse/scanpy/pull/2731:668,Deployability,Release,Release,668,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Added the boolean argument ""add_intercept"" to regress_out, and implemented code to optionally add the intercept back to the residuals in the result of regress_out().; <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes https://github.com/theislab/single-cell-tutorial/issues/35; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2731
https://github.com/scverse/scanpy/pull/2731:545,Testability,Test,Tests,545,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Added the boolean argument ""add_intercept"" to regress_out, and implemented code to optionally add the intercept back to the residuals in the result of regress_out().; <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes https://github.com/theislab/single-cell-tutorial/issues/35; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2731
https://github.com/scverse/scanpy/pull/2731:71,Usability,guid,guidelines,71,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Added the boolean argument ""add_intercept"" to regress_out, and implemented code to optionally add the intercept back to the residuals in the result of regress_out().; <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes https://github.com/theislab/single-cell-tutorial/issues/35; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2731
https://github.com/scverse/scanpy/pull/2731:102,Usability,guid,guide,102,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Added the boolean argument ""add_intercept"" to regress_out, and implemented code to optionally add the intercept back to the residuals in the result of regress_out().; <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes https://github.com/theislab/single-cell-tutorial/issues/35; - [ ] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2731
https://github.com/scverse/scanpy/pull/2732:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.1.3  v0.1.4](https://github.com/astral-sh/ruff-pre-commit/compare/v0.1.3...v0.1.4); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2732
https://github.com/scverse/scanpy/pull/2733:199,Deployability,Release,Release,199,"`matplotlib.colormaps` was introduced in v3.5.0, but scanpy currently specifies only v3.4+. Bump it and everything should be fine. - [x] Tests included or not required because: trivial change; - [x] Release notes not necessary because: trivial change. (this is just my own evaluation of triviality; if you want a release notes entry I am happy to add one)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2733
https://github.com/scverse/scanpy/pull/2733:313,Deployability,release,release,313,"`matplotlib.colormaps` was introduced in v3.5.0, but scanpy currently specifies only v3.4+. Bump it and everything should be fine. - [x] Tests included or not required because: trivial change; - [x] Release notes not necessary because: trivial change. (this is just my own evaluation of triviality; if you want a release notes entry I am happy to add one)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2733
https://github.com/scverse/scanpy/pull/2733:137,Testability,Test,Tests,137,"`matplotlib.colormaps` was introduced in v3.5.0, but scanpy currently specifies only v3.4+. Bump it and everything should be fine. - [x] Tests included or not required because: trivial change; - [x] Release notes not necessary because: trivial change. (this is just my own evaluation of triviality; if you want a release notes entry I am happy to add one)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2733
https://github.com/scverse/scanpy/pull/2734:423,Deployability,release,release,423,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2730; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2734
https://github.com/scverse/scanpy/pull/2734:448,Deployability,Release,Release,448,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2730; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2734
https://github.com/scverse/scanpy/pull/2734:325,Testability,Test,Tests,325,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2730; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2734
https://github.com/scverse/scanpy/pull/2734:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2730; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2734
https://github.com/scverse/scanpy/pull/2734:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2730; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2734
https://github.com/scverse/scanpy/pull/2737:421,Deployability,release,release,421,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: small change. And for broken links, I found the working location manually. The only website that doesnt have a working HTTPS version is http://vitessce.io (https://github.com/vitessce/vitessce/issues/1121), which is impressive given the late-90s-look of some of those journal websites.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2737
https://github.com/scverse/scanpy/pull/2737:446,Deployability,Release,Release,446,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: small change. And for broken links, I found the working location manually. The only website that doesnt have a working HTTPS version is http://vitessce.io (https://github.com/vitessce/vitessce/issues/1121), which is impressive given the late-90s-look of some of those journal websites.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2737
https://github.com/scverse/scanpy/pull/2737:323,Testability,Test,Tests,323,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: small change. And for broken links, I found the working location manually. The only website that doesnt have a working HTTPS version is http://vitessce.io (https://github.com/vitessce/vitessce/issues/1121), which is impressive given the late-90s-look of some of those journal websites.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2737
https://github.com/scverse/scanpy/pull/2737:71,Usability,guid,guidelines,71,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: small change. And for broken links, I found the working location manually. The only website that doesnt have a working HTTPS version is http://vitessce.io (https://github.com/vitessce/vitessce/issues/1121), which is impressive given the late-90s-look of some of those journal websites.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2737
https://github.com/scverse/scanpy/pull/2737:102,Usability,guid,guide,102,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: small change. And for broken links, I found the working location manually. The only website that doesnt have a working HTTPS version is http://vitessce.io (https://github.com/vitessce/vitessce/issues/1121), which is impressive given the late-90s-look of some of those journal websites.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2737
https://github.com/scverse/scanpy/pull/2739:514,Deployability,release,release,514,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2680; - [x] Tests included or not required because: this is a longterm fix - failing of this functionality would be captured by existing tests; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2739
https://github.com/scverse/scanpy/pull/2739:539,Deployability,Release,Release,539,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2680; - [x] Tests included or not required because: this is a longterm fix - failing of this functionality would be captured by existing tests; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2739
https://github.com/scverse/scanpy/pull/2739:325,Testability,Test,Tests,325,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2680; - [x] Tests included or not required because: this is a longterm fix - failing of this functionality would be captured by existing tests; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2739
https://github.com/scverse/scanpy/pull/2739:450,Testability,test,tests,450,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2680; - [x] Tests included or not required because: this is a longterm fix - failing of this functionality would be captured by existing tests; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2739
https://github.com/scverse/scanpy/pull/2739:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2680; - [x] Tests included or not required because: this is a longterm fix - failing of this functionality would be captured by existing tests; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2739
https://github.com/scverse/scanpy/pull/2739:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2680; - [x] Tests included or not required because: this is a longterm fix - failing of this functionality would be captured by existing tests; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2739
https://github.com/scverse/scanpy/issues/2740:1149,Availability,Error,Error,1149,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Hi,. I was trying to extract gene expression mean values per Subject, so I have a dataframe with genes in columns, subjects in rows, and the mean values of the expression. . To obtain the mean values for each Subject for the selected genes, I ran the following command:; `adata[(adata.obs['Subject'] == 'Subject_x')][:,['genes_of_interest']].X.mean(axis=0))`. Having a look at the expression of genes in a specific Subject, it looks like this:. ![image](https://github.com/scverse/scanpy/assets/94078098/f9d7443c-3837-4054-b930-4864d07f9434). However, the mean expression value for NTM is 0. and for CRYAB is 1.56, what it doesn't make sense with the heatmap plot. Am I doing wrong in the extraction of mean values?. Thanks!. ### Minimal code sample. ```python; adata[(adata.obs['Subject'] == 'Subject_x')][:,['genes_of_interest']].X.mean(axis=0)); ```. ### Error output. _No response_. ### Versions. <details>. ```; anndata 0.9.1; scanpy 1.8.1; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2740
https://github.com/scverse/scanpy/issues/2741:527,Usability,clear,clear,527,"### What kind of feature would you like to request?. Other?. ### Please describe your wishes. The return fields in the documentation are heterogeneous. E.g. for methods of the same output type scheme, such as [sc.pp.louvain](https://scanpy.readthedocs.io/en/latest/generated/scanpy.tl.louvain.html) and [sc.pp.leiden](https://scanpy.readthedocs.io/en/latest/generated/scanpy.tl.leiden.html), the return fields in the documentation are different. Harmonizing return fields would make navigation through the different tools more clear. One such style could be (tagging @flying-sheep here) to use prose containing a definition list, similar to. > Returns `None` if `copy=False`, otherwise an `AnnData` object. Sets the following:; >; > `.obs['foo']` : `NDArray[np.float64]`; > > Information on foo; >; > `.obs['bar']` : `NDArray[np.float64]`; > > Information on bar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2741
https://github.com/scverse/scanpy/pull/2742:460,Deployability,release,release,460,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2741, Closes #2276; - [x] Tests included or not required because: Only docstring changes; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added. **Notes**. - [x] How does `sc.pp.combat` return `None`? A: when `inplace=True`: it never returns an `AnnData` object though. Hence removed `AnnData` from the return type list. - `sc.pp.normalize` has both `inplace` and `copy` so did not force to harmonize with others; - `sc.pp.pca` allows adata and array/sparsematrix input, so did not force to harmonize with others; - `sc.pp.filter_cells`, `sc.pp.filter_genes` , `sc.pp.subsample` acts on data in different manner (changing dims), so did not force to harmonize with others; - `sc.pp.log1p` , `sc.pp.sqrt` seem to be understandable enough without bloating this up",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2742
https://github.com/scverse/scanpy/pull/2742:485,Deployability,Release,Release,485,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2741, Closes #2276; - [x] Tests included or not required because: Only docstring changes; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added. **Notes**. - [x] How does `sc.pp.combat` return `None`? A: when `inplace=True`: it never returns an `AnnData` object though. Hence removed `AnnData` from the return type list. - `sc.pp.normalize` has both `inplace` and `copy` so did not force to harmonize with others; - `sc.pp.pca` allows adata and array/sparsematrix input, so did not force to harmonize with others; - `sc.pp.filter_cells`, `sc.pp.filter_genes` , `sc.pp.subsample` acts on data in different manner (changing dims), so did not force to harmonize with others; - `sc.pp.log1p` , `sc.pp.sqrt` seem to be understandable enough without bloating this up",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2742
https://github.com/scverse/scanpy/pull/2742:339,Testability,Test,Tests,339,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2741, Closes #2276; - [x] Tests included or not required because: Only docstring changes; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added. **Notes**. - [x] How does `sc.pp.combat` return `None`? A: when `inplace=True`: it never returns an `AnnData` object though. Hence removed `AnnData` from the return type list. - `sc.pp.normalize` has both `inplace` and `copy` so did not force to harmonize with others; - `sc.pp.pca` allows adata and array/sparsematrix input, so did not force to harmonize with others; - `sc.pp.filter_cells`, `sc.pp.filter_genes` , `sc.pp.subsample` acts on data in different manner (changing dims), so did not force to harmonize with others; - `sc.pp.log1p` , `sc.pp.sqrt` seem to be understandable enough without bloating this up",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2742
https://github.com/scverse/scanpy/pull/2742:71,Usability,guid,guidelines,71,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2741, Closes #2276; - [x] Tests included or not required because: Only docstring changes; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added. **Notes**. - [x] How does `sc.pp.combat` return `None`? A: when `inplace=True`: it never returns an `AnnData` object though. Hence removed `AnnData` from the return type list. - `sc.pp.normalize` has both `inplace` and `copy` so did not force to harmonize with others; - `sc.pp.pca` allows adata and array/sparsematrix input, so did not force to harmonize with others; - `sc.pp.filter_cells`, `sc.pp.filter_genes` , `sc.pp.subsample` acts on data in different manner (changing dims), so did not force to harmonize with others; - `sc.pp.log1p` , `sc.pp.sqrt` seem to be understandable enough without bloating this up",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2742
https://github.com/scverse/scanpy/pull/2742:102,Usability,guid,guide,102,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2741, Closes #2276; - [x] Tests included or not required because: Only docstring changes; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added. **Notes**. - [x] How does `sc.pp.combat` return `None`? A: when `inplace=True`: it never returns an `AnnData` object though. Hence removed `AnnData` from the return type list. - `sc.pp.normalize` has both `inplace` and `copy` so did not force to harmonize with others; - `sc.pp.pca` allows adata and array/sparsematrix input, so did not force to harmonize with others; - `sc.pp.filter_cells`, `sc.pp.filter_genes` , `sc.pp.subsample` acts on data in different manner (changing dims), so did not force to harmonize with others; - `sc.pp.log1p` , `sc.pp.sqrt` seem to be understandable enough without bloating this up",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2742
https://github.com/scverse/scanpy/pull/2743:443,Deployability,release,release,443,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2746; - [x] Tests included or not required because: this is a minor fix; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: the related code has not been released by scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2743
https://github.com/scverse/scanpy/pull/2743:468,Deployability,Release,Release,468,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2746; - [x] Tests included or not required because: this is a minor fix; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: the related code has not been released by scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2743
https://github.com/scverse/scanpy/pull/2743:535,Deployability,release,released,535,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2746; - [x] Tests included or not required because: this is a minor fix; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: the related code has not been released by scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2743
https://github.com/scverse/scanpy/pull/2743:325,Testability,Test,Tests,325,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2746; - [x] Tests included or not required because: this is a minor fix; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: the related code has not been released by scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2743
https://github.com/scverse/scanpy/pull/2743:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2746; - [x] Tests included or not required because: this is a minor fix; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: the related code has not been released by scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2743
https://github.com/scverse/scanpy/pull/2743:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes #2746; - [x] Tests included or not required because: this is a minor fix; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: the related code has not been released by scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2743
https://github.com/scverse/scanpy/issues/2744:1648,Availability,Error,Error,1648," dense eigensolver eigh, so if k is not small enough compared to n, it makes no sense to call the LOBPCG code. Moreover, if one calls the LOBPCG algorithm for 5k > n, it would likely break internally, so the code calls the standard function eigh instead. It is not that n should be large for the LOBPCG to work, but rather the ratio n / k should be large. It you call LOBPCG with k=1 and n=10, it works though n is small. The method is intended for extremely large n / k. The workaround was to rerun failed tests until the fixture randomly returned another solver, which isnt great. I therefore simply `xfail` that test for now to not block PRs in https://github.com/scverse/scanpy/pull/2745. ### Minimal code sample. ```bash; # try one of the following to reproduce (if necessary multiple times); pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csr-zero_center-valid]'; pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csc-zero_center-valid]'; ```. ### Error output. (note that since the code is run with `warnings.simplefilter('error')`, the below is an error that fails the test). ```pytb; UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations.; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.10.0.dev156+gd1a2c8f8.d20231110; -----; PIL 10.0.1; asciitree NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2023.10.0; dateutil 2.8.2; fasteners 0.19; h5py 3.10.0; igraph 0.10.8; iniconfig NA; jinja2 3.1.2; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.41.1; markupsafe 2.1.3; matplotlib 3.8.0; mpl_toolkits NA; msgpack 1.0.7; natsort 8.4.0; numba 0.58.1; numcodecs 0.12.1; numpy 1.26.1; packaging 23.2; pandas 2.1.1; pluggy 1.3.0; psutil 5.9.6; py NA; pyparsing 3.1.1; pytest 7.4.3; pytz 2023.3.post1; scipy 1.11.3; session_info 1.0.0; setuptools 68.2.2; setupto",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2744
https://github.com/scverse/scanpy/issues/2744:1724,Availability,error,error,1724,"ll the LOBPCG code. Moreover, if one calls the LOBPCG algorithm for 5k > n, it would likely break internally, so the code calls the standard function eigh instead. It is not that n should be large for the LOBPCG to work, but rather the ratio n / k should be large. It you call LOBPCG with k=1 and n=10, it works though n is small. The method is intended for extremely large n / k. The workaround was to rerun failed tests until the fixture randomly returned another solver, which isnt great. I therefore simply `xfail` that test for now to not block PRs in https://github.com/scverse/scanpy/pull/2745. ### Minimal code sample. ```bash; # try one of the following to reproduce (if necessary multiple times); pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csr-zero_center-valid]'; pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csc-zero_center-valid]'; ```. ### Error output. (note that since the code is run with `warnings.simplefilter('error')`, the below is an error that fails the test). ```pytb; UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations.; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.10.0.dev156+gd1a2c8f8.d20231110; -----; PIL 10.0.1; asciitree NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2023.10.0; dateutil 2.8.2; fasteners 0.19; h5py 3.10.0; igraph 0.10.8; iniconfig NA; jinja2 3.1.2; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.41.1; markupsafe 2.1.3; matplotlib 3.8.0; mpl_toolkits NA; msgpack 1.0.7; natsort 8.4.0; numba 0.58.1; numcodecs 0.12.1; numpy 1.26.1; packaging 23.2; pandas 2.1.1; pluggy 1.3.0; psutil 5.9.6; py NA; pyparsing 3.1.1; pytest 7.4.3; pytz 2023.3.post1; scipy 1.11.3; session_info 1.0.0; setuptools 68.2.2; setuptools_scm NA; six 1.16.0; sklearn 1.3.2; sparse 0.14.0; tblib 3.0.0; texttable 1.7.0; threadpo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2744
https://github.com/scverse/scanpy/issues/2744:1750,Availability,error,error,1750,"ll the LOBPCG code. Moreover, if one calls the LOBPCG algorithm for 5k > n, it would likely break internally, so the code calls the standard function eigh instead. It is not that n should be large for the LOBPCG to work, but rather the ratio n / k should be large. It you call LOBPCG with k=1 and n=10, it works though n is small. The method is intended for extremely large n / k. The workaround was to rerun failed tests until the fixture randomly returned another solver, which isnt great. I therefore simply `xfail` that test for now to not block PRs in https://github.com/scverse/scanpy/pull/2745. ### Minimal code sample. ```bash; # try one of the following to reproduce (if necessary multiple times); pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csr-zero_center-valid]'; pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csc-zero_center-valid]'; ```. ### Error output. (note that since the code is run with `warnings.simplefilter('error')`, the below is an error that fails the test). ```pytb; UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations.; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.10.0.dev156+gd1a2c8f8.d20231110; -----; PIL 10.0.1; asciitree NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2023.10.0; dateutil 2.8.2; fasteners 0.19; h5py 3.10.0; igraph 0.10.8; iniconfig NA; jinja2 3.1.2; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.41.1; markupsafe 2.1.3; matplotlib 3.8.0; mpl_toolkits NA; msgpack 1.0.7; natsort 8.4.0; numba 0.58.1; numcodecs 0.12.1; numpy 1.26.1; packaging 23.2; pandas 2.1.1; pluggy 1.3.0; psutil 5.9.6; py NA; pyparsing 3.1.1; pytest 7.4.3; pytz 2023.3.post1; scipy 1.11.3; session_info 1.0.0; setuptools 68.2.2; setuptools_scm NA; six 1.16.0; sklearn 1.3.2; sparse 0.14.0; tblib 3.0.0; texttable 1.7.0; threadpo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2744
https://github.com/scverse/scanpy/issues/2744:2985,Deployability,update,updated,2985,"th k=1 and n=10, it works though n is small. The method is intended for extremely large n / k. The workaround was to rerun failed tests until the fixture randomly returned another solver, which isnt great. I therefore simply `xfail` that test for now to not block PRs in https://github.com/scverse/scanpy/pull/2745. ### Minimal code sample. ```bash; # try one of the following to reproduce (if necessary multiple times); pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csr-zero_center-valid]'; pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csc-zero_center-valid]'; ```. ### Error output. (note that since the code is run with `warnings.simplefilter('error')`, the below is an error that fails the test). ```pytb; UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations.; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.10.0.dev156+gd1a2c8f8.d20231110; -----; PIL 10.0.1; asciitree NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2023.10.0; dateutil 2.8.2; fasteners 0.19; h5py 3.10.0; igraph 0.10.8; iniconfig NA; jinja2 3.1.2; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.41.1; markupsafe 2.1.3; matplotlib 3.8.0; mpl_toolkits NA; msgpack 1.0.7; natsort 8.4.0; numba 0.58.1; numcodecs 0.12.1; numpy 1.26.1; packaging 23.2; pandas 2.1.1; pluggy 1.3.0; psutil 5.9.6; py NA; pyparsing 3.1.1; pytest 7.4.3; pytz 2023.3.post1; scipy 1.11.3; session_info 1.0.0; setuptools 68.2.2; setuptools_scm NA; six 1.16.0; sklearn 1.3.2; sparse 0.14.0; tblib 3.0.0; texttable 1.7.0; threadpoolctl 3.2.0; tlz 0.12.0; toolz 0.12.0; typing_extensions NA; yaml 6.0.1; zarr 2.16.1; zipp NA; -----; Python 3.11.5 (main, Sep 2 2023, 14:16:33) [GCC 13.2.1 20230801]; Linux-6.6.1-zen1-1-zen-x86_64-with-glibc2.38; -----; Session information updated at 2023-11-10 09:29; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2744
https://github.com/scverse/scanpy/issues/2744:428,Testability,test,test,428,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. The `pca_params` fixture randomly picks one of the possible solvers, but since a little while, the `""lobpcg""` solver fails for our small test data, [as explained by its docs](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.lobpcg.html):. > The LOBPCG code internally solves eigenproblems of the size 3k on every iteration by calling the dense eigensolver eigh, so if k is not small enough compared to n, it makes no sense to call the LOBPCG code. Moreover, if one calls the LOBPCG algorithm for 5k > n, it would likely break internally, so the code calls the standard function eigh instead. It is not that n should be large for the LOBPCG to work, but rather the ratio n / k should be large. It you call LOBPCG with k=1 and n=10, it works though n is small. The method is intended for extremely large n / k. The workaround was to rerun failed tests until the fixture randomly returned another solver, which isnt great. I therefore simply `xfail` that test for now to not block PRs in https://github.com/scverse/scanpy/pull/2745. ### Minimal code sample. ```bash; # try one of the following to reproduce (if necessary multiple times); pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csr-zero_center-valid]'; pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csc-zero_center-valid]'; ```. ### Error output. (note that since the code is run with `warnings.simplefilter('error')`, the below is an error that fails the test). ```pytb; UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations.; ```. ### V",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2744
https://github.com/scverse/scanpy/issues/2744:1159,Testability,test,tests,1159," scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. The `pca_params` fixture randomly picks one of the possible solvers, but since a little while, the `""lobpcg""` solver fails for our small test data, [as explained by its docs](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.lobpcg.html):. > The LOBPCG code internally solves eigenproblems of the size 3k on every iteration by calling the dense eigensolver eigh, so if k is not small enough compared to n, it makes no sense to call the LOBPCG code. Moreover, if one calls the LOBPCG algorithm for 5k > n, it would likely break internally, so the code calls the standard function eigh instead. It is not that n should be large for the LOBPCG to work, but rather the ratio n / k should be large. It you call LOBPCG with k=1 and n=10, it works though n is small. The method is intended for extremely large n / k. The workaround was to rerun failed tests until the fixture randomly returned another solver, which isnt great. I therefore simply `xfail` that test for now to not block PRs in https://github.com/scverse/scanpy/pull/2745. ### Minimal code sample. ```bash; # try one of the following to reproduce (if necessary multiple times); pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csr-zero_center-valid]'; pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csc-zero_center-valid]'; ```. ### Error output. (note that since the code is run with `warnings.simplefilter('error')`, the below is an error that fails the test). ```pytb; UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations.; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.10.0.dev156+gd1a2c8f8.d20231110; -----; PIL 10.0.1; asciitree NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; da",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2744
https://github.com/scverse/scanpy/issues/2744:1268,Testability,test,test,1268,"What happened?. The `pca_params` fixture randomly picks one of the possible solvers, but since a little while, the `""lobpcg""` solver fails for our small test data, [as explained by its docs](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.lobpcg.html):. > The LOBPCG code internally solves eigenproblems of the size 3k on every iteration by calling the dense eigensolver eigh, so if k is not small enough compared to n, it makes no sense to call the LOBPCG code. Moreover, if one calls the LOBPCG algorithm for 5k > n, it would likely break internally, so the code calls the standard function eigh instead. It is not that n should be large for the LOBPCG to work, but rather the ratio n / k should be large. It you call LOBPCG with k=1 and n=10, it works though n is small. The method is intended for extremely large n / k. The workaround was to rerun failed tests until the fixture randomly returned another solver, which isnt great. I therefore simply `xfail` that test for now to not block PRs in https://github.com/scverse/scanpy/pull/2745. ### Minimal code sample. ```bash; # try one of the following to reproduce (if necessary multiple times); pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csr-zero_center-valid]'; pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csc-zero_center-valid]'; ```. ### Error output. (note that since the code is run with `warnings.simplefilter('error')`, the below is an error that fails the test). ```pytb; UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations.; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.10.0.dev156+gd1a2c8f8.d20231110; -----; PIL 10.0.1; asciitree NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2023.10.0; dateutil 2.8.2; fasteners 0.19; h5py 3.10.0; igraph 0.10.8; iniconfig NA; jinja2 3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2744
https://github.com/scverse/scanpy/issues/2744:1477,Testability,test,tests,1477,"t data, [as explained by its docs](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.lobpcg.html):. > The LOBPCG code internally solves eigenproblems of the size 3k on every iteration by calling the dense eigensolver eigh, so if k is not small enough compared to n, it makes no sense to call the LOBPCG code. Moreover, if one calls the LOBPCG algorithm for 5k > n, it would likely break internally, so the code calls the standard function eigh instead. It is not that n should be large for the LOBPCG to work, but rather the ratio n / k should be large. It you call LOBPCG with k=1 and n=10, it works though n is small. The method is intended for extremely large n / k. The workaround was to rerun failed tests until the fixture randomly returned another solver, which isnt great. I therefore simply `xfail` that test for now to not block PRs in https://github.com/scverse/scanpy/pull/2745. ### Minimal code sample. ```bash; # try one of the following to reproduce (if necessary multiple times); pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csr-zero_center-valid]'; pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csc-zero_center-valid]'; ```. ### Error output. (note that since the code is run with `warnings.simplefilter('error')`, the below is an error that fails the test). ```pytb; UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations.; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.10.0.dev156+gd1a2c8f8.d20231110; -----; PIL 10.0.1; asciitree NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2023.10.0; dateutil 2.8.2; fasteners 0.19; h5py 3.10.0; igraph 0.10.8; iniconfig NA; jinja2 3.1.2; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.41.1; markupsafe 2.1.3; matplotlib 3.8.0; mpl_toolkits NA; msgpack 1.0.7; natsort 8.4.0; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2744
https://github.com/scverse/scanpy/issues/2744:1571,Testability,test,tests,1571,"lobpcg.html):. > The LOBPCG code internally solves eigenproblems of the size 3k on every iteration by calling the dense eigensolver eigh, so if k is not small enough compared to n, it makes no sense to call the LOBPCG code. Moreover, if one calls the LOBPCG algorithm for 5k > n, it would likely break internally, so the code calls the standard function eigh instead. It is not that n should be large for the LOBPCG to work, but rather the ratio n / k should be large. It you call LOBPCG with k=1 and n=10, it works though n is small. The method is intended for extremely large n / k. The workaround was to rerun failed tests until the fixture randomly returned another solver, which isnt great. I therefore simply `xfail` that test for now to not block PRs in https://github.com/scverse/scanpy/pull/2745. ### Minimal code sample. ```bash; # try one of the following to reproduce (if necessary multiple times); pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csr-zero_center-valid]'; pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csc-zero_center-valid]'; ```. ### Error output. (note that since the code is run with `warnings.simplefilter('error')`, the below is an error that fails the test). ```pytb; UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations.; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.10.0.dev156+gd1a2c8f8.d20231110; -----; PIL 10.0.1; asciitree NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2023.10.0; dateutil 2.8.2; fasteners 0.19; h5py 3.10.0; igraph 0.10.8; iniconfig NA; jinja2 3.1.2; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.41.1; markupsafe 2.1.3; matplotlib 3.8.0; mpl_toolkits NA; msgpack 1.0.7; natsort 8.4.0; numba 0.58.1; numcodecs 0.12.1; numpy 1.26.1; packaging 23.2; pandas 2.1.1; pluggy 1.3.0; psutil 5.9.6; py N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2744
https://github.com/scverse/scanpy/issues/2744:1771,Testability,test,test,1771,"ll the LOBPCG code. Moreover, if one calls the LOBPCG algorithm for 5k > n, it would likely break internally, so the code calls the standard function eigh instead. It is not that n should be large for the LOBPCG to work, but rather the ratio n / k should be large. It you call LOBPCG with k=1 and n=10, it works though n is small. The method is intended for extremely large n / k. The workaround was to rerun failed tests until the fixture randomly returned another solver, which isnt great. I therefore simply `xfail` that test for now to not block PRs in https://github.com/scverse/scanpy/pull/2745. ### Minimal code sample. ```bash; # try one of the following to reproduce (if necessary multiple times); pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csr-zero_center-valid]'; pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csc-zero_center-valid]'; ```. ### Error output. (note that since the code is run with `warnings.simplefilter('error')`, the below is an error that fails the test). ```pytb; UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations.; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.10.0.dev156+gd1a2c8f8.d20231110; -----; PIL 10.0.1; asciitree NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2023.10.0; dateutil 2.8.2; fasteners 0.19; h5py 3.10.0; igraph 0.10.8; iniconfig NA; jinja2 3.1.2; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.41.1; markupsafe 2.1.3; matplotlib 3.8.0; mpl_toolkits NA; msgpack 1.0.7; natsort 8.4.0; numba 0.58.1; numcodecs 0.12.1; numpy 1.26.1; packaging 23.2; pandas 2.1.1; pluggy 1.3.0; psutil 5.9.6; py NA; pyparsing 3.1.1; pytest 7.4.3; pytz 2023.3.post1; scipy 1.11.3; session_info 1.0.0; setuptools 68.2.2; setuptools_scm NA; six 1.16.0; sklearn 1.3.2; sparse 0.14.0; tblib 3.0.0; texttable 1.7.0; threadpo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2744
https://github.com/scverse/scanpy/issues/2744:1248,Usability,simpl,simply,1248,"What happened?. The `pca_params` fixture randomly picks one of the possible solvers, but since a little while, the `""lobpcg""` solver fails for our small test data, [as explained by its docs](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.lobpcg.html):. > The LOBPCG code internally solves eigenproblems of the size 3k on every iteration by calling the dense eigensolver eigh, so if k is not small enough compared to n, it makes no sense to call the LOBPCG code. Moreover, if one calls the LOBPCG algorithm for 5k > n, it would likely break internally, so the code calls the standard function eigh instead. It is not that n should be large for the LOBPCG to work, but rather the ratio n / k should be large. It you call LOBPCG with k=1 and n=10, it works though n is small. The method is intended for extremely large n / k. The workaround was to rerun failed tests until the fixture randomly returned another solver, which isnt great. I therefore simply `xfail` that test for now to not block PRs in https://github.com/scverse/scanpy/pull/2745. ### Minimal code sample. ```bash; # try one of the following to reproduce (if necessary multiple times); pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csr-zero_center-valid]'; pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csc-zero_center-valid]'; ```. ### Error output. (note that since the code is run with `warnings.simplefilter('error')`, the below is an error that fails the test). ```pytb; UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations.; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.10.0.dev156+gd1a2c8f8.d20231110; -----; PIL 10.0.1; asciitree NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2023.10.0; dateutil 2.8.2; fasteners 0.19; h5py 3.10.0; igraph 0.10.8; iniconfig NA; jinja2 3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2744
https://github.com/scverse/scanpy/issues/2744:1710,Usability,simpl,simplefilter,1710,"ll the LOBPCG code. Moreover, if one calls the LOBPCG algorithm for 5k > n, it would likely break internally, so the code calls the standard function eigh instead. It is not that n should be large for the LOBPCG to work, but rather the ratio n / k should be large. It you call LOBPCG with k=1 and n=10, it works though n is small. The method is intended for extremely large n / k. The workaround was to rerun failed tests until the fixture randomly returned another solver, which isnt great. I therefore simply `xfail` that test for now to not block PRs in https://github.com/scverse/scanpy/pull/2745. ### Minimal code sample. ```bash; # try one of the following to reproduce (if necessary multiple times); pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csr-zero_center-valid]'; pytest --runxfail 'scanpy/tests/test_pca.py::test_pca_warnings[scipy_csc-zero_center-valid]'; ```. ### Error output. (note that since the code is run with `warnings.simplefilter('error')`, the below is an error that fails the test). ```pytb; UserWarning: The problem size 5 minus the constraints size 0 is too small relative to the block size 4. Using a dense eigensolver instead of LOBPCG iterations.No output of the history of the iterations.; ```. ### Versions. <details>. ```; -----; anndata 0.10.2; scanpy 1.10.0.dev156+gd1a2c8f8.d20231110; -----; PIL 10.0.1; asciitree NA; cloudpickle 3.0.0; cycler 0.12.1; cython_runtime NA; dask 2023.10.0; dateutil 2.8.2; fasteners 0.19; h5py 3.10.0; igraph 0.10.8; iniconfig NA; jinja2 3.1.2; joblib 1.3.2; kiwisolver 1.4.5; leidenalg 0.10.1; llvmlite 0.41.1; markupsafe 2.1.3; matplotlib 3.8.0; mpl_toolkits NA; msgpack 1.0.7; natsort 8.4.0; numba 0.58.1; numcodecs 0.12.1; numpy 1.26.1; packaging 23.2; pandas 2.1.1; pluggy 1.3.0; psutil 5.9.6; py NA; pyparsing 3.1.1; pytest 7.4.3; pytz 2023.3.post1; scipy 1.11.3; session_info 1.0.0; setuptools 68.2.2; setuptools_scm NA; six 1.16.0; sklearn 1.3.2; sparse 0.14.0; tblib 3.0.0; texttable 1.7.0; threadpo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2744
https://github.com/scverse/scanpy/pull/2745:421,Deployability,release,release,421,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: fixes tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2745
https://github.com/scverse/scanpy/pull/2745:446,Deployability,Release,Release,446,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: fixes tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2745
https://github.com/scverse/scanpy/pull/2745:323,Testability,Test,Tests,323,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: fixes tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2745
https://github.com/scverse/scanpy/pull/2745:489,Testability,test,tests,489,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: fixes tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2745
https://github.com/scverse/scanpy/pull/2745:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: fixes tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2745
https://github.com/scverse/scanpy/pull/2745:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: fixes tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2745
https://github.com/scverse/scanpy/issues/2746:711,Availability,Error,Error,711,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When reading the `tissue_positions.csv` file generated by SpaceRanger v2.0 or later, `read_visium` reads the header from the second row (with `header=1`), while it should read from the first row instead (with `header=0`). ### Minimal code sample. ```python; positions = pd.read_csv(; files['tissue_positions_file'],; header=0 if tissue_positions_file.name == ""tissue_positions.csv"" else None,; index_col=0,; ); ```. ### Error output. _No response_. ### Versions. <details>. ```; anndata 0.10.2; scanpy 1.10.0.dev157+g9b7f6032; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2746
https://github.com/scverse/scanpy/issues/2747:594,Availability,Error,Error,594,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Since the most recent matplotlib release (3.8.1), the `_get_signature` function seems to have issues. I am not sure why this is the case. I am opening the issue for now and will dig a bit. Could be on my end. ### Minimal code sample. ```python; `pip install ehrapy`. `>>> import ehrapy as ep`; ```. ### Error output. ```pytb; tests/tools/causal/test_dowhy.py:10: in <module>; import ehrapy as ep; ehrapy/__init__.py:14: in <module>; from ehrapy import plot as pl; ehrapy/plot/__init__.py:3: in <module>; from ehrapy.plot._scanpy_pl_api import * # noqa: F403; ehrapy/plot/_scanpy_pl_api.py:1134: in <module>; @_wraps_plot_scatter; ../../miniconda3/envs/ehrapy/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:605: in _wraps_plot_scatter; wrapper_sig = _get_signature(wrapper, eval_str=True); ../../miniconda3/envs/ehrapy/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:590: in _get_signature; lambda: inspect.Signature.empty, get_annotations(obj, eval_str=eval_str); ../../miniconda3/envs/ehrapy/lib/python3.11/inspect.py:276: in get_annotations; return_value = {key:; ../../miniconda3/envs/ehrapy/lib/python3.11/inspect.py:277: in <dictcomp>; value if not isinstance(value, str) else eval(value, globals, locals); <string>:1: in <module>; ???; E NameError: name 'Axes' is not defined; ```. ### Versions. <details>. ```; matplotlib 3.8.1; scanpy 1.9.6; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2747
https://github.com/scverse/scanpy/issues/2747:324,Deployability,release,release,324,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Since the most recent matplotlib release (3.8.1), the `_get_signature` function seems to have issues. I am not sure why this is the case. I am opening the issue for now and will dig a bit. Could be on my end. ### Minimal code sample. ```python; `pip install ehrapy`. `>>> import ehrapy as ep`; ```. ### Error output. ```pytb; tests/tools/causal/test_dowhy.py:10: in <module>; import ehrapy as ep; ehrapy/__init__.py:14: in <module>; from ehrapy import plot as pl; ehrapy/plot/__init__.py:3: in <module>; from ehrapy.plot._scanpy_pl_api import * # noqa: F403; ehrapy/plot/_scanpy_pl_api.py:1134: in <module>; @_wraps_plot_scatter; ../../miniconda3/envs/ehrapy/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:605: in _wraps_plot_scatter; wrapper_sig = _get_signature(wrapper, eval_str=True); ../../miniconda3/envs/ehrapy/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:590: in _get_signature; lambda: inspect.Signature.empty, get_annotations(obj, eval_str=eval_str); ../../miniconda3/envs/ehrapy/lib/python3.11/inspect.py:276: in get_annotations; return_value = {key:; ../../miniconda3/envs/ehrapy/lib/python3.11/inspect.py:277: in <dictcomp>; value if not isinstance(value, str) else eval(value, globals, locals); <string>:1: in <module>; ???; E NameError: name 'Axes' is not defined; ```. ### Versions. <details>. ```; matplotlib 3.8.1; scanpy 1.9.6; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2747
https://github.com/scverse/scanpy/issues/2747:541,Deployability,install,install,541,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Since the most recent matplotlib release (3.8.1), the `_get_signature` function seems to have issues. I am not sure why this is the case. I am opening the issue for now and will dig a bit. Could be on my end. ### Minimal code sample. ```python; `pip install ehrapy`. `>>> import ehrapy as ep`; ```. ### Error output. ```pytb; tests/tools/causal/test_dowhy.py:10: in <module>; import ehrapy as ep; ehrapy/__init__.py:14: in <module>; from ehrapy import plot as pl; ehrapy/plot/__init__.py:3: in <module>; from ehrapy.plot._scanpy_pl_api import * # noqa: F403; ehrapy/plot/_scanpy_pl_api.py:1134: in <module>; @_wraps_plot_scatter; ../../miniconda3/envs/ehrapy/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:605: in _wraps_plot_scatter; wrapper_sig = _get_signature(wrapper, eval_str=True); ../../miniconda3/envs/ehrapy/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:590: in _get_signature; lambda: inspect.Signature.empty, get_annotations(obj, eval_str=eval_str); ../../miniconda3/envs/ehrapy/lib/python3.11/inspect.py:276: in get_annotations; return_value = {key:; ../../miniconda3/envs/ehrapy/lib/python3.11/inspect.py:277: in <dictcomp>; value if not isinstance(value, str) else eval(value, globals, locals); <string>:1: in <module>; ???; E NameError: name 'Axes' is not defined; ```. ### Versions. <details>. ```; matplotlib 3.8.1; scanpy 1.9.6; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2747
https://github.com/scverse/scanpy/issues/2747:1076,Integrability,wrap,wrapper,1076,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Since the most recent matplotlib release (3.8.1), the `_get_signature` function seems to have issues. I am not sure why this is the case. I am opening the issue for now and will dig a bit. Could be on my end. ### Minimal code sample. ```python; `pip install ehrapy`. `>>> import ehrapy as ep`; ```. ### Error output. ```pytb; tests/tools/causal/test_dowhy.py:10: in <module>; import ehrapy as ep; ehrapy/__init__.py:14: in <module>; from ehrapy import plot as pl; ehrapy/plot/__init__.py:3: in <module>; from ehrapy.plot._scanpy_pl_api import * # noqa: F403; ehrapy/plot/_scanpy_pl_api.py:1134: in <module>; @_wraps_plot_scatter; ../../miniconda3/envs/ehrapy/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:605: in _wraps_plot_scatter; wrapper_sig = _get_signature(wrapper, eval_str=True); ../../miniconda3/envs/ehrapy/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:590: in _get_signature; lambda: inspect.Signature.empty, get_annotations(obj, eval_str=eval_str); ../../miniconda3/envs/ehrapy/lib/python3.11/inspect.py:276: in get_annotations; return_value = {key:; ../../miniconda3/envs/ehrapy/lib/python3.11/inspect.py:277: in <dictcomp>; value if not isinstance(value, str) else eval(value, globals, locals); <string>:1: in <module>; ???; E NameError: name 'Axes' is not defined; ```. ### Versions. <details>. ```; matplotlib 3.8.1; scanpy 1.9.6; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2747
https://github.com/scverse/scanpy/issues/2747:617,Testability,test,tests,617,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. Since the most recent matplotlib release (3.8.1), the `_get_signature` function seems to have issues. I am not sure why this is the case. I am opening the issue for now and will dig a bit. Could be on my end. ### Minimal code sample. ```python; `pip install ehrapy`. `>>> import ehrapy as ep`; ```. ### Error output. ```pytb; tests/tools/causal/test_dowhy.py:10: in <module>; import ehrapy as ep; ehrapy/__init__.py:14: in <module>; from ehrapy import plot as pl; ehrapy/plot/__init__.py:3: in <module>; from ehrapy.plot._scanpy_pl_api import * # noqa: F403; ehrapy/plot/_scanpy_pl_api.py:1134: in <module>; @_wraps_plot_scatter; ../../miniconda3/envs/ehrapy/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:605: in _wraps_plot_scatter; wrapper_sig = _get_signature(wrapper, eval_str=True); ../../miniconda3/envs/ehrapy/lib/python3.11/site-packages/scanpy/plotting/_tools/scatterplots.py:590: in _get_signature; lambda: inspect.Signature.empty, get_annotations(obj, eval_str=eval_str); ../../miniconda3/envs/ehrapy/lib/python3.11/inspect.py:276: in get_annotations; return_value = {key:; ../../miniconda3/envs/ehrapy/lib/python3.11/inspect.py:277: in <dictcomp>; value if not isinstance(value, str) else eval(value, globals, locals); <string>:1: in <module>; ???; E NameError: name 'Axes' is not defined; ```. ### Versions. <details>. ```; matplotlib 3.8.1; scanpy 1.9.6; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2747
https://github.com/scverse/scanpy/issues/2748:1816,Availability,Error,Error,1816,"scverse/scanpy/assets/59059267/3dd49231-ed62-4b7f-be1d-a950714667fc"">. but when I change the type of adata.X to float, the value of adata.raw will be changed with adata.X, I get following result; ```py; import numpy as np; import pandas as pd; import anndata as ad; from scipy.sparse import csr_matrix; print(ad.__version__). mtx = np.array([[1.2,2.1,3.9],[2.01,3.99,4.23],[4.21,5.12,6.87],[0,20.12,100.96]]). adata = sc.AnnData(mtx); adata.raw = adata; print(adata); print(adata.X). sc.pp.normalize_total(adata,target_sum=1e4); sc.pp.log1p(adata); print(adata.X) . print(adata.raw.X[0:10,0:10]); ```; I get following result; <img width=""525"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/59059267/5eec641b-3542-471b-be22-51ef8e8f31a8"">. It sems strange for me? Shouldn't I save raw data for float data? Could you give some suggestions? My environment is; <img width=""647"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/59059267/2267345f-1a2b-4708-90f9-d1892adfb42f"">. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.1; scanpy 1.9.5; -----; CoreFoundation NA; Foundation NA; PIL 9.4.0; PyObjCTools NA; anyio NA; appnope 0.1.2; asttokens NA; attr 22.1.0; babel 2.11.0; backcall 0.2.0; bottleneck 1.3.5; brotli NA; certifi 2023.07.22; cffi 1.15.1; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.2; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.6; entrypoints 0.4; executing 0.8.3; fastjsonschema NA; gmpy2 2.1.2; h5py 3.9.0; idna 3.4; igraph 0.10.8; ipykernel 6.25.0; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonpointer 2.1; jsonschema 4.17.3; jupyter_server 1.23.4; jupyterlab_server 2.22.0; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.40.0; louvain 0.8.1; lz4 4.3.2; markupsafe 2.1.1; matplotlib 3.7.2; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; nbformat 5.9.2; numba 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2748
https://github.com/scverse/scanpy/issues/2748:4078,Deployability,update,updated,4078,"; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.2; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.6; entrypoints 0.4; executing 0.8.3; fastjsonschema NA; gmpy2 2.1.2; h5py 3.9.0; idna 3.4; igraph 0.10.8; ipykernel 6.25.0; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonpointer 2.1; jsonschema 4.17.3; jupyter_server 1.23.4; jupyterlab_server 2.22.0; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.40.0; louvain 0.8.1; lz4 4.3.2; markupsafe 2.1.1; matplotlib 3.7.2; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; nbformat 5.9.2; numba 0.57.1; numexpr 2.8.4; numpy 1.24.3; numpydoc 1.5.0; objc 10.0; packaging 23.1; pandas 2.0.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; plotly 5.9.0; prometheus_client NA; prompt_toolkit 3.0.36; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pvectorc NA; pyarrow 11.0.0; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pyparsing 3.0.9; pyrsistent NA; pytz 2023.3.post1; requests 2.31.0; rfc3339_validator 0.1.4; rfc3986_validator 0.1.1; ruamel NA; scipy 1.11.1; send2trash NA; session_info 1.0.0; setuptools 68.0.0; six 1.16.0; sklearn 1.3.0; sniffio 1.2.0; socks 1.7.1; sphinxcontrib NA; stack_data 0.2.0; sympy 1.11.1; tblib 1.7.0; terminado 0.17.1; texttable 1.7.0; threadpoolctl 2.2.0; tlz 0.12.0; toolz 0.12.0; torch 2.1.0; torchgen NA; tornado 6.3.2; tqdm 4.65.0; traitlets 5.7.1; typing_extensions NA; urllib3 1.26.16; wcwidth 0.2.5; websocket 0.58.0; xxhash 2.0.2; yaml 6.0; zipp NA; zmq 23.2.0; zope NA; -----; IPython 8.15.0; jupyter_client 7.4.9; jupyter_core 5.3.0; jupyterlab 3.6.3; notebook 6.5.4; -----; Python 3.11.5 (main, Sep 11 2023, 08:31:25) [Clang 14.0.6 ]; macOS-12.5-arm64-arm-64bit; -----; Session information updated at 2023-11-12 16:47; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2748
https://github.com/scverse/scanpy/issues/2748:2062,Performance,bottleneck,bottleneck,2062,"ort anndata as ad; from scipy.sparse import csr_matrix; print(ad.__version__). mtx = np.array([[1.2,2.1,3.9],[2.01,3.99,4.23],[4.21,5.12,6.87],[0,20.12,100.96]]). adata = sc.AnnData(mtx); adata.raw = adata; print(adata); print(adata.X). sc.pp.normalize_total(adata,target_sum=1e4); sc.pp.log1p(adata); print(adata.X) . print(adata.raw.X[0:10,0:10]); ```; I get following result; <img width=""525"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/59059267/5eec641b-3542-471b-be22-51ef8e8f31a8"">. It sems strange for me? Shouldn't I save raw data for float data? Could you give some suggestions? My environment is; <img width=""647"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/59059267/2267345f-1a2b-4708-90f9-d1892adfb42f"">. ### Error output. _No response_. ### Versions. <details>. ```; -----; anndata 0.10.1; scanpy 1.9.5; -----; CoreFoundation NA; Foundation NA; PIL 9.4.0; PyObjCTools NA; anyio NA; appnope 0.1.2; asttokens NA; attr 22.1.0; babel 2.11.0; backcall 0.2.0; bottleneck 1.3.5; brotli NA; certifi 2023.07.22; cffi 1.15.1; chardet 4.0.0; charset_normalizer 2.0.4; cloudpickle 2.2.1; colorama 0.4.6; comm 0.1.2; cycler 0.10.0; cython_runtime NA; cytoolz 0.12.0; dask 2023.6.0; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; defusedxml 0.7.1; dill 0.3.6; entrypoints 0.4; executing 0.8.3; fastjsonschema NA; gmpy2 2.1.2; h5py 3.9.0; idna 3.4; igraph 0.10.8; ipykernel 6.25.0; ipython_genutils 0.2.0; jedi 0.18.1; jinja2 3.1.2; joblib 1.2.0; json5 NA; jsonpointer 2.1; jsonschema 4.17.3; jupyter_server 1.23.4; jupyterlab_server 2.22.0; kiwisolver 1.4.4; leidenalg 0.10.1; llvmlite 0.40.0; louvain 0.8.1; lz4 4.3.2; markupsafe 2.1.1; matplotlib 3.7.2; mpl_toolkits NA; mpmath 1.3.0; natsort 8.4.0; nbformat 5.9.2; numba 0.57.1; numexpr 2.8.4; numpy 1.24.3; numpydoc 1.5.0; objc 10.0; packaging 23.1; pandas 2.0.3; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; plotly 5.9.0; prometheus_client NA; prompt_toolkit 3.0.36; psutil 5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2748
https://github.com/scverse/scanpy/pull/2749:474,Deployability,release,release,474,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: manual test: check if logo displays in rendered docs; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: unreleased bug. Seems like GitHub renders .svgs even if the namespace isnt there, but browsers dont.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2749
https://github.com/scverse/scanpy/pull/2749:499,Deployability,Release,Release,499,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: manual test: check if logo displays in rendered docs; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: unreleased bug. Seems like GitHub renders .svgs even if the namespace isnt there, but browsers dont.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2749
https://github.com/scverse/scanpy/pull/2749:323,Testability,Test,Tests,323,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: manual test: check if logo displays in rendered docs; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: unreleased bug. Seems like GitHub renders .svgs even if the namespace isnt there, but browsers dont.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2749
https://github.com/scverse/scanpy/pull/2749:370,Testability,test,test,370,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: manual test: check if logo displays in rendered docs; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: unreleased bug. Seems like GitHub renders .svgs even if the namespace isnt there, but browsers dont.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2749
https://github.com/scverse/scanpy/pull/2749:385,Testability,log,logo,385,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: manual test: check if logo displays in rendered docs; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: unreleased bug. Seems like GitHub renders .svgs even if the namespace isnt there, but browsers dont.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2749
https://github.com/scverse/scanpy/pull/2749:71,Usability,guid,guidelines,71,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: manual test: check if logo displays in rendered docs; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: unreleased bug. Seems like GitHub renders .svgs even if the namespace isnt there, but browsers dont.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2749
https://github.com/scverse/scanpy/pull/2749:102,Usability,guid,guide,102,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because: manual test: check if logo displays in rendered docs; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: unreleased bug. Seems like GitHub renders .svgs even if the namespace isnt there, but browsers dont.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2749
https://github.com/scverse/scanpy/pull/2750:421,Deployability,release,release,421,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: internal API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2750
https://github.com/scverse/scanpy/pull/2750:446,Deployability,Release,Release,446,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: internal API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2750
https://github.com/scverse/scanpy/pull/2750:323,Testability,Test,Tests,323,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: internal API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2750
https://github.com/scverse/scanpy/pull/2750:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: internal API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2750
https://github.com/scverse/scanpy/pull/2750:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included or not required because:; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: internal API,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2750
https://github.com/scverse/scanpy/pull/2753:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/astral-sh/ruff-pre-commit: v0.1.4  v0.1.5](https://github.com/astral-sh/ruff-pre-commit/compare/v0.1.4...v0.1.5); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2753
https://github.com/scverse/scanpy/issues/2754:356,Availability,error,error,356,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. hello, why dose my code ""sc.pp.filter_genes(adata, min_cells=3)"" error after running ""sc.pp.filter_cells(adata, min_genes=200)""?. ### Minimal code sample. ```python; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); ```. ### Error output. ```pytb; ERROR:. /root/anaconda3/envs/c2s/lib/python3.11/site-packages/scanpy/preprocessing/_simple.py:250: ImplicitModificationWarning: Trying to modify attribute .var of view, initializing view as actual.; /root/anaconda3/envs/c2s/lib/python3.11/site-packages/anndata/_core/views.py:79: ImplicitModificationWarning: Trying to modify attribute .var of view, initializing view as actual.; ____________________________________________________________________________________________________; AND the process is out of memory. [17371499.406473] Out of memory: Killed process 465550 (python) total-vm:132596812kB, anon-rss:129055148kB, file-rss:0kB, shmem-rss:0kB, UID:0 pgtables:253640kB oom_score_adj:0; ```. ### Versions. <details>; scanpy 1.9.5; python 3.11.6. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2754
https://github.com/scverse/scanpy/issues/2754:548,Availability,Error,Error,548,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. hello, why dose my code ""sc.pp.filter_genes(adata, min_cells=3)"" error after running ""sc.pp.filter_cells(adata, min_genes=200)""?. ### Minimal code sample. ```python; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); ```. ### Error output. ```pytb; ERROR:. /root/anaconda3/envs/c2s/lib/python3.11/site-packages/scanpy/preprocessing/_simple.py:250: ImplicitModificationWarning: Trying to modify attribute .var of view, initializing view as actual.; /root/anaconda3/envs/c2s/lib/python3.11/site-packages/anndata/_core/views.py:79: ImplicitModificationWarning: Trying to modify attribute .var of view, initializing view as actual.; ____________________________________________________________________________________________________; AND the process is out of memory. [17371499.406473] Out of memory: Killed process 465550 (python) total-vm:132596812kB, anon-rss:129055148kB, file-rss:0kB, shmem-rss:0kB, UID:0 pgtables:253640kB oom_score_adj:0; ```. ### Versions. <details>; scanpy 1.9.5; python 3.11.6. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2754
https://github.com/scverse/scanpy/issues/2754:571,Availability,ERROR,ERROR,571,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. hello, why dose my code ""sc.pp.filter_genes(adata, min_cells=3)"" error after running ""sc.pp.filter_cells(adata, min_genes=200)""?. ### Minimal code sample. ```python; sc.pp.filter_cells(adata, min_genes=200); sc.pp.filter_genes(adata, min_cells=3); ```. ### Error output. ```pytb; ERROR:. /root/anaconda3/envs/c2s/lib/python3.11/site-packages/scanpy/preprocessing/_simple.py:250: ImplicitModificationWarning: Trying to modify attribute .var of view, initializing view as actual.; /root/anaconda3/envs/c2s/lib/python3.11/site-packages/anndata/_core/views.py:79: ImplicitModificationWarning: Trying to modify attribute .var of view, initializing view as actual.; ____________________________________________________________________________________________________; AND the process is out of memory. [17371499.406473] Out of memory: Killed process 465550 (python) total-vm:132596812kB, anon-rss:129055148kB, file-rss:0kB, shmem-rss:0kB, UID:0 pgtables:253640kB oom_score_adj:0; ```. ### Versions. <details>; scanpy 1.9.5; python 3.11.6. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2754
https://github.com/scverse/scanpy/issues/2755:672,Availability,Error,Error,672,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When using sc.pl.highest_expr_genes, seaborn throws a FutureWarning. Specifically:. envs/scanpy/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead. ### Minimal code sample. ```python; sc.pl.highest_expr_genes(adata, n_top=20, ); ```. ### Error output. ```pytb; envs/scanpy/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead; ```. ### Versions. <details>. ```; -----; anndata 0.10.3; scanpy 1.9.6; -----; PIL 10.1.0; asttokens NA; backcall 0.2.0; comm 0.1.2; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 0.8.3; h5py 3.10.0; ipykernel 6.25.0; jedi 0.18.1; joblib 1.3.2; kiwisolver 1.4.5; llvmlite 0.41.1; matplotlib 3.8.1; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.58.1; numpy 1.26.2; packaging 23.1; pandas 2.1.3; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; prompt_toolkit 3.0.36; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.1.1; pytz 2023.3.post1; scipy 1.11.3; seaborn 0.12.2; session_info 1.0.0; six 1.16.0; sklearn 1.3.2; stack_data 0.2.0; statsmodels 0.14.0; threadpoolctl 3.2.0; tornado 6.3.3; tqdm 4.66.1; traitlets 5.7.1; umap 0.5.4; wcwidth 0.2.5; zmq 25.1.0; -----; IPython 8.15.0; jupyter_client 8.6.0; jupyter_core 5.5.0; ---",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2755
https://github.com/scverse/scanpy/issues/2755:2134,Deployability,update,updated,2134,"f scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. When using sc.pl.highest_expr_genes, seaborn throws a FutureWarning. Specifically:. envs/scanpy/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead. ### Minimal code sample. ```python; sc.pl.highest_expr_genes(adata, n_top=20, ); ```. ### Error output. ```pytb; envs/scanpy/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead; ```. ### Versions. <details>. ```; -----; anndata 0.10.3; scanpy 1.9.6; -----; PIL 10.1.0; asttokens NA; backcall 0.2.0; comm 0.1.2; cycler 0.12.1; cython_runtime NA; dateutil 2.8.2; debugpy 1.6.7; decorator 5.1.1; executing 0.8.3; h5py 3.10.0; ipykernel 6.25.0; jedi 0.18.1; joblib 1.3.2; kiwisolver 1.4.5; llvmlite 0.41.1; matplotlib 3.8.1; matplotlib_inline 0.1.6; mpl_toolkits NA; natsort 8.4.0; numba 0.58.1; numpy 1.26.2; packaging 23.1; pandas 2.1.3; parso 0.8.3; patsy 0.5.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; platformdirs 3.10.0; prompt_toolkit 3.0.36; psutil 5.9.0; ptyprocess 0.7.0; pure_eval 0.2.2; pydev_ipython NA; pydevconsole NA; pydevd 2.9.5; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.15.1; pynndescent 0.5.10; pyparsing 3.1.1; pytz 2023.3.post1; scipy 1.11.3; seaborn 0.12.2; session_info 1.0.0; six 1.16.0; sklearn 1.3.2; stack_data 0.2.0; statsmodels 0.14.0; threadpoolctl 3.2.0; tornado 6.3.3; tqdm 4.66.1; traitlets 5.7.1; umap 0.5.4; wcwidth 0.2.5; zmq 25.1.0; -----; IPython 8.15.0; jupyter_client 8.6.0; jupyter_core 5.5.0; -----; Python 3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]; Linux-6.2.0-1018-gcp-x86_64-with-glibc2.37; -----; Session information updated at 2023-11-15 20:32; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2755
https://github.com/scverse/scanpy/pull/2756:396,Deployability,release,release,396,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: Modifies unreleased features. I made the code and comments/docs more explicit about when the nearest-neighbor-is-cell-itself comes into play and when it doesnt, and tested a bunch of our utilities. @mumichae this might make it fast for your code; You can install this branch using. ```bash; pip install -U 'scanpy@git+https://github.com/scverse/scanpy.git@improve-neighbors-shortcut'; ```. | | Before | After |; | --------- |--------|--------|; | small data | ![master](https://github.com/scverse/scanpy/assets/291575/d79a7bbd-548d-4aea-9cff-6ee44ca544ac) | ![shortcut](https://github.com/scverse/scanpy/assets/291575/d802b0d5-09e3-4002-862f-4ae4c368b061) |; | bigger data | ![master](https://github.com/scverse/scanpy/assets/291575/627ccd9f-7a42-44be-81d9-7796e54e54b0) | ![shortcut](https://github.com/scverse/scanpy/assets/291575/000b06a4-1c6c-496b-9fda-b479414e182c)|",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2756
https://github.com/scverse/scanpy/pull/2756:421,Deployability,Release,Release,421,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: Modifies unreleased features. I made the code and comments/docs more explicit about when the nearest-neighbor-is-cell-itself comes into play and when it doesnt, and tested a bunch of our utilities. @mumichae this might make it fast for your code; You can install this branch using. ```bash; pip install -U 'scanpy@git+https://github.com/scverse/scanpy.git@improve-neighbors-shortcut'; ```. | | Before | After |; | --------- |--------|--------|; | small data | ![master](https://github.com/scverse/scanpy/assets/291575/d79a7bbd-548d-4aea-9cff-6ee44ca544ac) | ![shortcut](https://github.com/scverse/scanpy/assets/291575/d802b0d5-09e3-4002-862f-4ae4c368b061) |; | bigger data | ![master](https://github.com/scverse/scanpy/assets/291575/627ccd9f-7a42-44be-81d9-7796e54e54b0) | ![shortcut](https://github.com/scverse/scanpy/assets/291575/000b06a4-1c6c-496b-9fda-b479414e182c)|",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2756
https://github.com/scverse/scanpy/pull/2756:714,Deployability,install,install,714,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: Modifies unreleased features. I made the code and comments/docs more explicit about when the nearest-neighbor-is-cell-itself comes into play and when it doesnt, and tested a bunch of our utilities. @mumichae this might make it fast for your code; You can install this branch using. ```bash; pip install -U 'scanpy@git+https://github.com/scverse/scanpy.git@improve-neighbors-shortcut'; ```. | | Before | After |; | --------- |--------|--------|; | small data | ![master](https://github.com/scverse/scanpy/assets/291575/d79a7bbd-548d-4aea-9cff-6ee44ca544ac) | ![shortcut](https://github.com/scverse/scanpy/assets/291575/d802b0d5-09e3-4002-862f-4ae4c368b061) |; | bigger data | ![master](https://github.com/scverse/scanpy/assets/291575/627ccd9f-7a42-44be-81d9-7796e54e54b0) | ![shortcut](https://github.com/scverse/scanpy/assets/291575/000b06a4-1c6c-496b-9fda-b479414e182c)|",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2756
https://github.com/scverse/scanpy/pull/2756:754,Deployability,install,install,754,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: Modifies unreleased features. I made the code and comments/docs more explicit about when the nearest-neighbor-is-cell-itself comes into play and when it doesnt, and tested a bunch of our utilities. @mumichae this might make it fast for your code; You can install this branch using. ```bash; pip install -U 'scanpy@git+https://github.com/scverse/scanpy.git@improve-neighbors-shortcut'; ```. | | Before | After |; | --------- |--------|--------|; | small data | ![master](https://github.com/scverse/scanpy/assets/291575/d79a7bbd-548d-4aea-9cff-6ee44ca544ac) | ![shortcut](https://github.com/scverse/scanpy/assets/291575/d802b0d5-09e3-4002-862f-4ae4c368b061) |; | bigger data | ![master](https://github.com/scverse/scanpy/assets/291575/627ccd9f-7a42-44be-81d9-7796e54e54b0) | ![shortcut](https://github.com/scverse/scanpy/assets/291575/000b06a4-1c6c-496b-9fda-b479414e182c)|",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2756
https://github.com/scverse/scanpy/pull/2756:323,Testability,Test,Tests,323,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: Modifies unreleased features. I made the code and comments/docs more explicit about when the nearest-neighbor-is-cell-itself comes into play and when it doesnt, and tested a bunch of our utilities. @mumichae this might make it fast for your code; You can install this branch using. ```bash; pip install -U 'scanpy@git+https://github.com/scverse/scanpy.git@improve-neighbors-shortcut'; ```. | | Before | After |; | --------- |--------|--------|; | small data | ![master](https://github.com/scverse/scanpy/assets/291575/d79a7bbd-548d-4aea-9cff-6ee44ca544ac) | ![shortcut](https://github.com/scverse/scanpy/assets/291575/d802b0d5-09e3-4002-862f-4ae4c368b061) |; | bigger data | ![master](https://github.com/scverse/scanpy/assets/291575/627ccd9f-7a42-44be-81d9-7796e54e54b0) | ![shortcut](https://github.com/scverse/scanpy/assets/291575/000b06a4-1c6c-496b-9fda-b479414e182c)|",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2756
https://github.com/scverse/scanpy/pull/2756:624,Testability,test,tested,624,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: Modifies unreleased features. I made the code and comments/docs more explicit about when the nearest-neighbor-is-cell-itself comes into play and when it doesnt, and tested a bunch of our utilities. @mumichae this might make it fast for your code; You can install this branch using. ```bash; pip install -U 'scanpy@git+https://github.com/scverse/scanpy.git@improve-neighbors-shortcut'; ```. | | Before | After |; | --------- |--------|--------|; | small data | ![master](https://github.com/scverse/scanpy/assets/291575/d79a7bbd-548d-4aea-9cff-6ee44ca544ac) | ![shortcut](https://github.com/scverse/scanpy/assets/291575/d802b0d5-09e3-4002-862f-4ae4c368b061) |; | bigger data | ![master](https://github.com/scverse/scanpy/assets/291575/627ccd9f-7a42-44be-81d9-7796e54e54b0) | ![shortcut](https://github.com/scverse/scanpy/assets/291575/000b06a4-1c6c-496b-9fda-b479414e182c)|",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2756
https://github.com/scverse/scanpy/pull/2756:71,Usability,guid,guidelines,71,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: Modifies unreleased features. I made the code and comments/docs more explicit about when the nearest-neighbor-is-cell-itself comes into play and when it doesnt, and tested a bunch of our utilities. @mumichae this might make it fast for your code; You can install this branch using. ```bash; pip install -U 'scanpy@git+https://github.com/scverse/scanpy.git@improve-neighbors-shortcut'; ```. | | Before | After |; | --------- |--------|--------|; | small data | ![master](https://github.com/scverse/scanpy/assets/291575/d79a7bbd-548d-4aea-9cff-6ee44ca544ac) | ![shortcut](https://github.com/scverse/scanpy/assets/291575/d802b0d5-09e3-4002-862f-4ae4c368b061) |; | bigger data | ![master](https://github.com/scverse/scanpy/assets/291575/627ccd9f-7a42-44be-81d9-7796e54e54b0) | ![shortcut](https://github.com/scverse/scanpy/assets/291575/000b06a4-1c6c-496b-9fda-b479414e182c)|",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2756
https://github.com/scverse/scanpy/pull/2756:102,Usability,guid,guide,102,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [x] Closes N/A; - [x] Tests included; <!-- Only check the following box if you did not include release notes -->; - [x] Release notes not necessary because: Modifies unreleased features. I made the code and comments/docs more explicit about when the nearest-neighbor-is-cell-itself comes into play and when it doesnt, and tested a bunch of our utilities. @mumichae this might make it fast for your code; You can install this branch using. ```bash; pip install -U 'scanpy@git+https://github.com/scverse/scanpy.git@improve-neighbors-shortcut'; ```. | | Before | After |; | --------- |--------|--------|; | small data | ![master](https://github.com/scverse/scanpy/assets/291575/d79a7bbd-548d-4aea-9cff-6ee44ca544ac) | ![shortcut](https://github.com/scverse/scanpy/assets/291575/d802b0d5-09e3-4002-862f-4ae4c368b061) |; | bigger data | ![master](https://github.com/scverse/scanpy/assets/291575/627ccd9f-7a42-44be-81d9-7796e54e54b0) | ![shortcut](https://github.com/scverse/scanpy/assets/291575/000b06a4-1c6c-496b-9fda-b479414e182c)|",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2756
https://github.com/scverse/scanpy/pull/2757:399,Availability,failure,failure,399,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [X] Fixes #1867; - [X] Tests included or not required because: New tests included which catch the failure mode described in #1867. Current implementation fails these.; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added entry in release notes. Addresses issue #1867 with a fix as outlined by @jlause and tests which catch the failure mode detected and nicely demonstrated by @jlause.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2757
https://github.com/scverse/scanpy/pull/2757:700,Availability,failure,failure,700,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [X] Fixes #1867; - [X] Tests included or not required because: New tests included which catch the failure mode described in #1867. Current implementation fails these.; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added entry in release notes. Addresses issue #1867 with a fix as outlined by @jlause and tests which catch the failure mode detected and nicely demonstrated by @jlause.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2757
https://github.com/scverse/scanpy/pull/2757:526,Deployability,release,release,526,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [X] Fixes #1867; - [X] Tests included or not required because: New tests included which catch the failure mode described in #1867. Current implementation fails these.; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added entry in release notes. Addresses issue #1867 with a fix as outlined by @jlause and tests which catch the failure mode detected and nicely demonstrated by @jlause.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2757
https://github.com/scverse/scanpy/pull/2757:551,Deployability,Release,Release,551,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [X] Fixes #1867; - [X] Tests included or not required because: New tests included which catch the failure mode described in #1867. Current implementation fails these.; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added entry in release notes. Addresses issue #1867 with a fix as outlined by @jlause and tests which catch the failure mode detected and nicely demonstrated by @jlause.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2757
https://github.com/scverse/scanpy/pull/2757:603,Deployability,release,release,603,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [X] Fixes #1867; - [X] Tests included or not required because: New tests included which catch the failure mode described in #1867. Current implementation fails these.; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added entry in release notes. Addresses issue #1867 with a fix as outlined by @jlause and tests which catch the failure mode detected and nicely demonstrated by @jlause.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2757
https://github.com/scverse/scanpy/pull/2757:713,Safety,detect,detected,713,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [X] Fixes #1867; - [X] Tests included or not required because: New tests included which catch the failure mode described in #1867. Current implementation fails these.; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added entry in release notes. Addresses issue #1867 with a fix as outlined by @jlause and tests which catch the failure mode detected and nicely demonstrated by @jlause.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2757
https://github.com/scverse/scanpy/pull/2757:324,Testability,Test,Tests,324,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [X] Fixes #1867; - [X] Tests included or not required because: New tests included which catch the failure mode described in #1867. Current implementation fails these.; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added entry in release notes. Addresses issue #1867 with a fix as outlined by @jlause and tests which catch the failure mode detected and nicely demonstrated by @jlause.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2757
https://github.com/scverse/scanpy/pull/2757:368,Testability,test,tests,368,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [X] Fixes #1867; - [X] Tests included or not required because: New tests included which catch the failure mode described in #1867. Current implementation fails these.; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added entry in release notes. Addresses issue #1867 with a fix as outlined by @jlause and tests which catch the failure mode detected and nicely demonstrated by @jlause.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2757
https://github.com/scverse/scanpy/pull/2757:678,Testability,test,tests,678,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [X] Fixes #1867; - [X] Tests included or not required because: New tests included which catch the failure mode described in #1867. Current implementation fails these.; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added entry in release notes. Addresses issue #1867 with a fix as outlined by @jlause and tests which catch the failure mode detected and nicely demonstrated by @jlause.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2757
https://github.com/scverse/scanpy/pull/2757:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [X] Fixes #1867; - [X] Tests included or not required because: New tests included which catch the failure mode described in #1867. Current implementation fails these.; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added entry in release notes. Addresses issue #1867 with a fix as outlined by @jlause and tests which catch the failure mode detected and nicely demonstrated by @jlause.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2757
https://github.com/scverse/scanpy/pull/2757:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. <!-- Please check (- [x]) and fill in the following boxes -->; - [X] Fixes #1867; - [X] Tests included or not required because: New tests included which catch the failure mode described in #1867. Current implementation fails these.; <!-- Only check the following box if you did not include release notes -->; - [ ] Release notes not necessary because: Added entry in release notes. Addresses issue #1867 with a fix as outlined by @jlause and tests which catch the failure mode detected and nicely demonstrated by @jlause.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2757
https://github.com/scverse/scanpy/issues/2758:394,Availability,error,error,394,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. While I am using `sc.pp.calculate_qc_metrics(ad, inplace=True)` to get QC metrics, its reported that a error occoured. ; Error message as below. ; ; It might just be because there's something wrong with my data. Does anyone else have a similar situation?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import anndata. # ad = anndata.read_h5ad('mypath'). def scrublet_by_sample(ad, key='samplename'):; """""" do doublet prediction by batch/sample """"""; """""" ad = anndata object """"""; """""" key = sample or batch in ad.obs""""""; sc.pp.calculate_qc_metrics(ad, inplace=True); ads = []; samplenames = ad.obs[key].unique(); for i in samplenames:; adx = ad[ad.obs[key].isin([i])].copy(); print(i,adx.n_obs); sc.external.pp.scrublet(adx,n_prin_comps=min(30,adx.shape[0]-1)); ads.append(adx); adata = ads[0].concatenate(tuple(ads[1:]), join='outer'); return adata. if np.array_equal(arr, np.round(arr)):; ad = scrublet_by_sample(ad, 'sample_ID'); ad.write(qc_h5); qc_md5 = generate_file_md5(qc_h5); print(""QC MD5 Hash:"", qc_md5); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 2, in <module>; File ""<stdin>"", line 5, in scrublet_by_sample; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 306, in calculate_qc_metrics; obs_metrics = describe_obs(; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs; proportions = top_segment_proportions(X, percent_top); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 401, in top_segment_proportions; return top_segment_proportions_sparse_csr(mtx.d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758
https://github.com/scverse/scanpy/issues/2758:412,Availability,Error,Error,412,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. While I am using `sc.pp.calculate_qc_metrics(ad, inplace=True)` to get QC metrics, its reported that a error occoured. ; Error message as below. ; ; It might just be because there's something wrong with my data. Does anyone else have a similar situation?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import anndata. # ad = anndata.read_h5ad('mypath'). def scrublet_by_sample(ad, key='samplename'):; """""" do doublet prediction by batch/sample """"""; """""" ad = anndata object """"""; """""" key = sample or batch in ad.obs""""""; sc.pp.calculate_qc_metrics(ad, inplace=True); ads = []; samplenames = ad.obs[key].unique(); for i in samplenames:; adx = ad[ad.obs[key].isin([i])].copy(); print(i,adx.n_obs); sc.external.pp.scrublet(adx,n_prin_comps=min(30,adx.shape[0]-1)); ads.append(adx); adata = ads[0].concatenate(tuple(ads[1:]), join='outer'); return adata. if np.array_equal(arr, np.round(arr)):; ad = scrublet_by_sample(ad, 'sample_ID'); ad.write(qc_h5); qc_md5 = generate_file_md5(qc_h5); print(""QC MD5 Hash:"", qc_md5); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 2, in <module>; File ""<stdin>"", line 5, in scrublet_by_sample; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 306, in calculate_qc_metrics; obs_metrics = describe_obs(; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs; proportions = top_segment_proportions(X, percent_top); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 401, in top_segment_proportions; return top_segment_proportions_sparse_csr(mtx.d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758
https://github.com/scverse/scanpy/issues/2758:1345,Availability,Error,Error,1345,"rue)` to get QC metrics, its reported that a error occoured. ; Error message as below. ; ; It might just be because there's something wrong with my data. Does anyone else have a similar situation?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import anndata. # ad = anndata.read_h5ad('mypath'). def scrublet_by_sample(ad, key='samplename'):; """""" do doublet prediction by batch/sample """"""; """""" ad = anndata object """"""; """""" key = sample or batch in ad.obs""""""; sc.pp.calculate_qc_metrics(ad, inplace=True); ads = []; samplenames = ad.obs[key].unique(); for i in samplenames:; adx = ad[ad.obs[key].isin([i])].copy(); print(i,adx.n_obs); sc.external.pp.scrublet(adx,n_prin_comps=min(30,adx.shape[0]-1)); ads.append(adx); adata = ads[0].concatenate(tuple(ads[1:]), join='outer'); return adata. if np.array_equal(arr, np.round(arr)):; ad = scrublet_by_sample(ad, 'sample_ID'); ad.write(qc_h5); qc_md5 = generate_file_md5(qc_h5); print(""QC MD5 Hash:"", qc_md5); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 2, in <module>; File ""<stdin>"", line 5, in scrublet_by_sample; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 306, in calculate_qc_metrics; obs_metrics = describe_obs(; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs; proportions = top_segment_proportions(X, percent_top); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 401, in top_segment_proportions; return top_segment_proportions_sparse_csr(mtx.data, mtx.indptr, np.array(ns)); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758
https://github.com/scverse/scanpy/issues/2758:2344,Availability,error,errors,2344,"ror output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 2, in <module>; File ""<stdin>"", line 5, in scrublet_by_sample; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 306, in calculate_qc_metrics; obs_metrics = describe_obs(; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs; proportions = top_segment_proportions(X, percent_top); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 401, in top_segment_proportions; return top_segment_proportions_sparse_csr(mtx.data, mtx.indptr, np.array(ns)); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<built-in function iadd>) found for signature:; ; >>> iadd(array(bool, 1d, C), array(int64, 1d, C)); ; There are 18 candidate implementations:; - Of which 14 did not match due to:; Overload of function 'iadd': File: <numerous>: Line N/A.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; No match.; - Of which 2 did not match due to:; Overload in function 'NumpyRulesInplaceArrayOperator.generic': File: numba/core/typing/npydecl.py: Line 243.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; Rejected as the implementation raised a specific error:; AttributeError: 'NoneType' object has no attribute 'args'; raised from /home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/typing/npydecl.py:254; - Of which 2 did not match due to:; Operator Overload in function 'iadd': File: unknown: Line unknown.; With argument(s): '(array(bool, 1d, C",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758
https://github.com/scverse/scanpy/issues/2758:3036,Availability,error,error,3036,"y(ns)); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<built-in function iadd>) found for signature:; ; >>> iadd(array(bool, 1d, C), array(int64, 1d, C)); ; There are 18 candidate implementations:; - Of which 14 did not match due to:; Overload of function 'iadd': File: <numerous>: Line N/A.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; No match.; - Of which 2 did not match due to:; Overload in function 'NumpyRulesInplaceArrayOperator.generic': File: numba/core/typing/npydecl.py: Line 243.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; Rejected as the implementation raised a specific error:; AttributeError: 'NoneType' object has no attribute 'args'; raised from /home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/typing/npydecl.py:254; - Of which 2 did not match due to:; Operator Overload in function 'iadd': File: unknown: Line unknown.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; No match for registered cases:; * (int64, int64) -> int64; * (int64, uint64) -> int64; * (uint64, int64) -> int64; * (uint64, uint64) -> uint64; * (float32, float32) -> float32; * (float64, float64) -> float64; * (complex64, complex64) -> complex64; * (complex128, complex128) -> complex128. During: typing of intrinsic-call at /home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py (449). File "".conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 449:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; for j in range(ns.size):; acc += partitioned[:, prev : ns[j]]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758
https://github.com/scverse/scanpy/issues/2758:2388,Deployability,pipeline,pipeline,2388,"ib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 306, in calculate_qc_metrics; obs_metrics = describe_obs(; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs; proportions = top_segment_proportions(X, percent_top); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 401, in top_segment_proportions; return top_segment_proportions_sparse_csr(mtx.data, mtx.indptr, np.array(ns)); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<built-in function iadd>) found for signature:; ; >>> iadd(array(bool, 1d, C), array(int64, 1d, C)); ; There are 18 candidate implementations:; - Of which 14 did not match due to:; Overload of function 'iadd': File: <numerous>: Line N/A.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; No match.; - Of which 2 did not match due to:; Overload in function 'NumpyRulesInplaceArrayOperator.generic': File: numba/core/typing/npydecl.py: Line 243.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; Rejected as the implementation raised a specific error:; AttributeError: 'NoneType' object has no attribute 'args'; raised from /home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/typing/npydecl.py:254; - Of which 2 did not match due to:; Operator Overload in function 'iadd': File: unknown: Line unknown.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; No match for registered cases:; * (int64, int64) -> int64; * (int64, uint64) -> int64; * (uint64, int64) -> int64; * (uint64, uint64) -> uint64; * (flo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758
https://github.com/scverse/scanpy/issues/2758:5134,Deployability,update,updated,5134,"/core/typing/npydecl.py:254; - Of which 2 did not match due to:; Operator Overload in function 'iadd': File: unknown: Line unknown.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; No match for registered cases:; * (int64, int64) -> int64; * (int64, uint64) -> int64; * (uint64, int64) -> int64; * (uint64, uint64) -> uint64; * (float32, float32) -> float32; * (float64, float64) -> float64; * (complex64, complex64) -> complex64; * (complex128, complex128) -> complex128. During: typing of intrinsic-call at /home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py (449). File "".conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 449:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; for j in range(ns.size):; acc += partitioned[:, prev : ns[j]].sum(axis=1); ```. ### Versions. <details>. ```; >>> import scanpy; scanpy.logging.print_versions(); -----; anndata 0.10.2; scanpy 1.9.6; -----; PIL 10.0.1; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; cloudpickle 3.0.0; colorama 0.4.6; cycler 0.12.1; cython_runtime NA; cytoolz 0.12.0; dask 2023.11.0; dateutil 2.8.2; exceptiongroup 1.1.3; fastcore 1.5.29; get_annotations NA; h5py 3.7.0; hypergeom_ufunc NA; importlib_resources NA; invgauss_ufunc NA; joblib 1.3.2; kiwisolver 1.4.4; llvmlite 0.41.1; matplotlib 3.8.1; mkl 2.4.0; mpl_toolkits NA; natsort 8.4.0; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.58.1; numpy 1.23.5; packaging 23.2; pandas 1.2.4; psutil 5.9.0; pycparser 2.21; pyparsing 3.0.9; pytz 2023.3.post1; scDenorm NA; scipy 1.10.1; session_info 1.0.0; setuptools 68.0.0; six 1.16.0; skewnorm_ufunc NA; sklearn 1.3.0; threadpoolctl 3.2.0; tlz 0.12.0; toolz 0.12.0; tqdm 4.66.1; typing_extensions NA; yaml 6.0; zipp NA; -----; Python 3.9.13 (main, Oct 13 2022, 21:15:33) [GCC 11.2.0]; Linux-3.10.0-1160.102.1.el7.x86_64-x86_64-with-glibc2.17; -----; Session information updated at 2023-11-17 16:20; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758
https://github.com/scverse/scanpy/issues/2758:418,Integrability,message,message,418,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. While I am using `sc.pp.calculate_qc_metrics(ad, inplace=True)` to get QC metrics, its reported that a error occoured. ; Error message as below. ; ; It might just be because there's something wrong with my data. Does anyone else have a similar situation?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import anndata. # ad = anndata.read_h5ad('mypath'). def scrublet_by_sample(ad, key='samplename'):; """""" do doublet prediction by batch/sample """"""; """""" ad = anndata object """"""; """""" key = sample or batch in ad.obs""""""; sc.pp.calculate_qc_metrics(ad, inplace=True); ads = []; samplenames = ad.obs[key].unique(); for i in samplenames:; adx = ad[ad.obs[key].isin([i])].copy(); print(i,adx.n_obs); sc.external.pp.scrublet(adx,n_prin_comps=min(30,adx.shape[0]-1)); ads.append(adx); adata = ads[0].concatenate(tuple(ads[1:]), join='outer'); return adata. if np.array_equal(arr, np.round(arr)):; ad = scrublet_by_sample(ad, 'sample_ID'); ad.write(qc_h5); qc_md5 = generate_file_md5(qc_h5); print(""QC MD5 Hash:"", qc_md5); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 2, in <module>; File ""<stdin>"", line 5, in scrublet_by_sample; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 306, in calculate_qc_metrics; obs_metrics = describe_obs(; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs; proportions = top_segment_proportions(X, percent_top); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 401, in top_segment_proportions; return top_segment_proportions_sparse_csr(mtx.d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758
https://github.com/scverse/scanpy/issues/2758:740,Safety,predict,prediction,740,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened?. While I am using `sc.pp.calculate_qc_metrics(ad, inplace=True)` to get QC metrics, its reported that a error occoured. ; Error message as below. ; ; It might just be because there's something wrong with my data. Does anyone else have a similar situation?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import anndata. # ad = anndata.read_h5ad('mypath'). def scrublet_by_sample(ad, key='samplename'):; """""" do doublet prediction by batch/sample """"""; """""" ad = anndata object """"""; """""" key = sample or batch in ad.obs""""""; sc.pp.calculate_qc_metrics(ad, inplace=True); ads = []; samplenames = ad.obs[key].unique(); for i in samplenames:; adx = ad[ad.obs[key].isin([i])].copy(); print(i,adx.n_obs); sc.external.pp.scrublet(adx,n_prin_comps=min(30,adx.shape[0]-1)); ads.append(adx); adata = ads[0].concatenate(tuple(ads[1:]), join='outer'); return adata. if np.array_equal(arr, np.round(arr)):; ad = scrublet_by_sample(ad, 'sample_ID'); ad.write(qc_h5); qc_md5 = generate_file_md5(qc_h5); print(""QC MD5 Hash:"", qc_md5); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 2, in <module>; File ""<stdin>"", line 5, in scrublet_by_sample; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 306, in calculate_qc_metrics; obs_metrics = describe_obs(; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs; proportions = top_segment_proportions(X, percent_top); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 401, in top_segment_proportions; return top_segment_proportions_sparse_csr(mtx.d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758
https://github.com/scverse/scanpy/issues/2758:1319,Security,Hash,Hash,1319," am using `sc.pp.calculate_qc_metrics(ad, inplace=True)` to get QC metrics, its reported that a error occoured. ; Error message as below. ; ; It might just be because there's something wrong with my data. Does anyone else have a similar situation?. ### Minimal code sample. ```python; import scanpy as sc; import numpy as np; import anndata. # ad = anndata.read_h5ad('mypath'). def scrublet_by_sample(ad, key='samplename'):; """""" do doublet prediction by batch/sample """"""; """""" ad = anndata object """"""; """""" key = sample or batch in ad.obs""""""; sc.pp.calculate_qc_metrics(ad, inplace=True); ads = []; samplenames = ad.obs[key].unique(); for i in samplenames:; adx = ad[ad.obs[key].isin([i])].copy(); print(i,adx.n_obs); sc.external.pp.scrublet(adx,n_prin_comps=min(30,adx.shape[0]-1)); ads.append(adx); adata = ads[0].concatenate(tuple(ads[1:]), join='outer'); return adata. if np.array_equal(arr, np.round(arr)):; ad = scrublet_by_sample(ad, 'sample_ID'); ad.write(qc_h5); qc_md5 = generate_file_md5(qc_h5); print(""QC MD5 Hash:"", qc_md5); ```. ### Error output. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 2, in <module>; File ""<stdin>"", line 5, in scrublet_by_sample; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 306, in calculate_qc_metrics; obs_metrics = describe_obs(; File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs; proportions = top_segment_proportions(X, percent_top); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 401, in top_segment_proportions; return top_segment_proportions_sparse_csr(mtx.data, mtx.indptr, np.array(ns)); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758
https://github.com/scverse/scanpy/issues/2758:4100,Testability,log,logging,4100,"aised from /home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/numba/core/typing/npydecl.py:254; - Of which 2 did not match due to:; Operator Overload in function 'iadd': File: unknown: Line unknown.; With argument(s): '(array(bool, 1d, C), array(int64, 1d, C))':; No match for registered cases:; * (int64, int64) -> int64; * (int64, uint64) -> int64; * (uint64, int64) -> int64; * (uint64, uint64) -> uint64; * (float32, float32) -> float32; * (float64, float64) -> float64; * (complex64, complex64) -> complex64; * (complex128, complex128) -> complex128. During: typing of intrinsic-call at /home/sunhao/.conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py (449). File "".conda/envs/h5ad/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 449:; def top_segment_proportions_sparse_csr(data, indptr, ns):; <source elided>; for j in range(ns.size):; acc += partitioned[:, prev : ns[j]].sum(axis=1); ```. ### Versions. <details>. ```; >>> import scanpy; scanpy.logging.print_versions(); -----; anndata 0.10.2; scanpy 1.9.6; -----; PIL 10.0.1; beta_ufunc NA; binom_ufunc NA; cffi 1.15.1; cloudpickle 3.0.0; colorama 0.4.6; cycler 0.12.1; cython_runtime NA; cytoolz 0.12.0; dask 2023.11.0; dateutil 2.8.2; exceptiongroup 1.1.3; fastcore 1.5.29; get_annotations NA; h5py 3.7.0; hypergeom_ufunc NA; importlib_resources NA; invgauss_ufunc NA; joblib 1.3.2; kiwisolver 1.4.4; llvmlite 0.41.1; matplotlib 3.8.1; mkl 2.4.0; mpl_toolkits NA; natsort 8.4.0; nbinom_ufunc NA; ncf_ufunc NA; nct_ufunc NA; ncx2_ufunc NA; numba 0.58.1; numpy 1.23.5; packaging 23.2; pandas 1.2.4; psutil 5.9.0; pycparser 2.21; pyparsing 3.0.9; pytz 2023.3.post1; scDenorm NA; scipy 1.10.1; session_info 1.0.0; setuptools 68.0.0; six 1.16.0; skewnorm_ufunc NA; sklearn 1.3.0; threadpoolctl 3.2.0; tlz 0.12.0; toolz 0.12.0; tqdm 4.66.1; typing_extensions NA; yaml 6.0; zipp NA; -----; Python 3.9.13 (main, Oct 13 2022, 21:15:33) [GCC 11.2.0]; Linux-3.10.0-1160.102.1.el7.x86_64-x86_64-with-glibc2.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2758
